[
  {
    "objectID": "research/overview.html",
    "href": "research/overview.html",
    "title": "Overview",
    "section": "",
    "text": "Overview\n\nMy research interests: an elevator pitch1\n\n\n\n\n\n\nKeywords: algorithms and complexity • graphs • computational social choice • combinatorial games • constraint satisfaction\n\n\n\n\n \n\nMy broad research interest lies in theoretical aspects of computer science. I am specifically interested in understanding the potential and the limitations of computational power. To this end, we use abstractions that model what computers do, as opposed to, say, analyzing a specific configuration or engineering faster hardware. While this approach does not directly advance state of the art computing tech, it does help with understanding what we can and cannot do with the increasing amounts of computing power at our disposal in a tech-agnostic fashion. This means that most lessons will remain relevant even after you’ve upgraded your systems to use the next generation of hardware, and after that too.\nMost of my work concerns the design and analysis of algorithms for computational problems. The problems I work with are usually inspired from applications that someone cares about, for example:\n\nFinding patterns in large networks (e.g, discovering closely-knit communities in friendship networks).\nDetermining who should win an election given a set of votes.\nDistributing resources among people (who may value them differently) in a way that makes everyone happy.\nComing up with strategies to win a game of solo chess.\nFiguring out how to contain the spread of a fire by deploying as few firefighters as possible.\n\nFor some of these scenarios, it may not be immediately obvious what the computational problem is. For example, consider the issue of who must win an election: you would like to create a reasonable mechanism to build a consensus from a set of votes. What would be considered reasonable?\nWell, you could list out some natural properties that you would want your mechanism to satisfy (for instance, if all voters have the same favorite candidate, it would be very unreasonable for the mechanism to not pick such a candidate as a winner). And then you could seek out a mechanism that satisfies all of these properties. This is the so-called axiomatic approach to voting, and the approach has even led to the discovery of some fascinating impossibility results, indicating that some combinations of properties cannot be achieved by any mechanism, no matter how clever. Now, among other aspects, one would hope that mechanisms we come up with can be efficiently implemented. It turns out that many mechanisms that have a lot of appealing properties are complex to implement, and some of my work involves finding ways of making them more accessible.\nWhile some computational problems admit elegant solutions that have fast implementations in the real world, for several others we have substantial theoretical evidence suggesting that such solutions are going to be elusive. This means that for all practical purposes we have to work our way through trade-offs.\n\n\n\nFig. Exploring tradeoffs between the demands of accuracy, speed, and coverage.\n\n\nWhen we think about designing algorithms, we are usually very demanding in how we go about it: we require our algorithms to be fast and accurate on all conceivable inputs. This is asking for quite a bit, and perhaps it is not surprising that we cannot afford this luxury all the time. The good news is that most of the time we can make meaningful progress by relaxing just one of these demands:\n\nGive up on accuracy, but not completely: look for solutions that are good enough (approximation) and/or work with algorithms that report the right solution most of the time (Las-Vegas style randomization).\nGive up on coverage, a little bit: let your algorithms work well on structured inputs. Hopefully the structure is such that it is not too limiting and is interesting enough for some application scenario, and is also enough to give you algorithmic leverage, i.e, there’s enough that you can exploit to make fast and accurate algorithms.\nGive up on speed, to some extent: going beyond the traditional allowance of polynomial time, which is the holy grail of what is considered efficient, takes you places. You could either allow for your algorithms have super-polynomial running times, and optimize as much as possible while being accurate on all inputs (exact algorithms), or allow for bad running times on a bounded subset of instances (Monte-Carlo style randomization).\n\nOne approach that tackles all of these tradeoffs at once is to take what is now called a “multivariate approach” to the analysis of running times, which essentially involves appreciating that to describe a problem instance just in terms of its size is like describing a movie by a rating, which is unfortunate because there’s so much more nuance. And yet we report — and think about — worst-case running times in only terms of the sizes of the instances. Consider, for example, how much more informative it is to think of the running time of BFS as O(n+m) rather than O(n^2), also a valid upper bound2. Notice how the latter fails to convey the fact that the running time of BFS is as good as linear on sparse graphs.\nSo the parameterized approach takes into account problem structure by addressing “secondary” measurements (parameters), apart from the primary measurement of overall input size, that significantly affect problem computational complexity. The central notion of fixed parameter tractability (FPT) is a generalization of polynomial-time based on confining any non-polynomial complexity costs to a function only of these secondary measurements. For instance, if you have an algorithm for vertex cover whose running time is O(2^{\\Delta(G)}) \\cdot n^{O(1)}, where \\Delta(G) is the maximum degree of the input graph3, then notice that you would have solved vertex cover in polynomial time on all graphs whose maximum degree is, say, O(\\log n). Sadly, since we know vertex cover to be NP-complete even when restricted to cubic graphs, this specific goal is a bit of a pipedream, but hopefully you see the potential4 in the process.\nTo illustrate how useful this approach can be, consider the typechecking problem for ML, a programming language for which relatively efficient compilers exist. One of the problems the compiler must solve is the checking of the compatibility of type declarations. This problem is known to be EXP-complete (Henglein and Mairson 1994): let’s just say intractable in the classical world. However, the implementations work well in practice because the ML Type Checking problem admits an algorithm (Lichtenstein and Pnueli 1985) with a running time of O(2^kn), where n is the size of the program and k is the maximum nesting depth of the type declarations. Since normally k is a small constant5, the algorithm is clearly practical on inputs one would expect to encounter in practice.\nBack to why this approach captures algorithmic tradeoffs in the regime of hard problems beautifully. You can think of an algorithm that is FPT in some parameter k as giving you efficient algorithms for that subclass of instances where k is small enough for the algorithm to be efficient. You could also think of it as giving you full coverage but giving up on efficiency as your parameter values loom larger. Finally, you can also devise randomized and/or approximate FPT algorithms, to have the FPT efficiency gains while giving up on accuracy, which may be necessary either for speedups or when working with problems that would not have FPT algorithms otherwise (like we just saw for vertex cover parameterized by maximum degree).\nParameterized (aka multivariate) algorithmics are a wonderfully flexible framework that allows you to dabble in various algorithmic tradeoffs. Once you start thinking in terms of restraining the combinatorial blowups to certain parameters of interest, you’ll probably find that the approach leads you to new ways of looking at the problem! To stay true to the motivations of the field: which is to find ways of “coping with NP-hardness” when said NP-hard problems are ones we need to solve in the real world — one must remember to sanity checck the relevance of the parameters we are working with. An ideal set of parameters would be small for most instances in real-world distributions, but also give you enough flex to devise efficient algorithms.\nFor a delightful history of the field, I recommend (Bodlaender et al. 2012). Also, (Cygan et al. 2015) is a very accessible introduction to the field, only assuming a background in undergraduate algorithms. The FPT Wiki is a community-maintained resource that documents developments in the field as they happen.\nThis framework has been my default way of thinking about algorithms for a while now. In the following, I delve a little further into the specifics of the kinds of problems I have been working on.\n\n\n\n\n\n\nComing Soon\n\n\n\nGames on graphs ⸱ Voting ⸱ Fair Division ⸱ Combinatorial Games ⸱ Backdoors to SAT ⸱ Eliminating Forbidden Subgraphs\n\n\nIncidentally, I am also interested in issues of CS education, mostly from the perspective of a poorly performing practitioner.\n\n\n\n\n\n\n\nReferences\n\nBodlaender, Hans L., Rod Downey, Fedor V. Fomin, and Dániel Marx, eds. 2012. The Multivariate Algorithmic Revolution and Beyond: Essays Dedicated to Michael R. Fellows on the Occasion of His 60th Birthday. Berlin, Heidelberg: Springer-Verlag.\n\n\nCygan, Marek, Fedor V. Fomin, Lukasz Kowalik, Daniel Lokshtanov, Dániel Marx, Marcin Pilipczuk, Michal Pilipczuk, and Saket Saurabh. 2015. Parameterized Algorithms. Springer.\n\n\nHenglein, F., and H. Mairson. 1994. “The Complexity of Type Inference for Higher-Order Typed Lambda Calculi.” J. Functional Programming 4 (4): 435–78.\n\n\nLichtenstein, O., and A. Pnueli. 1985. “Checking That Finite State Concurrent Programs Satisfy Their Linear Specifications.” In Conference Record of the Twelfth Annual ACM Symposium on Principles of Programming Languages, 97–107. ACM; ACM.\n\nFootnotes\n\n\nfor a suitably long elevator ride — assume skyscraper.↩︎\nHere, I am using n and m to denote the number of vertices and edges in the input graph G.↩︎\nOnce again, n denotes the number of vertices in the input graph G.↩︎\nIt would remiss to not point out that several algorithms for vertex cover turn out to be efficient from the parameterized perspective and useful in practice!↩︎\nindeed, if k is not a small constant, you probably have bigger problems anyway↩︎"
  },
  {
    "objectID": "research/publications-arxiv.html",
    "href": "research/publications-arxiv.html",
    "title": "Publications",
    "section": "",
    "text": "Publications on the ArXiV\nDBLP ⸱ Conferences ⸱ Journals ⸱ ArXiV ⸱ Other\n\n \n\n\n\nAgrawal, Akanksha, Sathish Govindarajan, and Neeldhara Misra. 2014. “Vertex Cover Gets Faster and Harder on Low Degree Graphs.” CoRR abs/1404.5566.\n\n\nAravind, N. R., Neeldhara Misra, and Harshil Mittal. 2022. “Chess Is Hard Even for a Single Player.” CoRR abs/2203.14864.\n\n\nChoudhari, Jayesh, Anirban Dasgupta, Neeldhara Misra, and M. S. Ramanujan. 2017. “Saving Critical Nodes with Firefighters Is FPT.” CoRR abs/1705.10923.\n\n\nDas, Bireswar, Murali Krishna Enduri, Neeldhara Misra, and I. Vinod Reddy. 2017. “On Structural Parameterizations of Firefighting.” CoRR abs/1711.10227.\n\n\nDayal, Pratyush, and Neeldhara Misra. 2019. “Deleting to Structured Trees.” CoRR abs/1912.12765.\n\n\nDey, Palash, and Neeldhara Misra. 2016a. “Elicitation for Preferences Single Peaked on Trees.” CoRR abs/1604.04403.\n\n\n———. 2016b. “On the Exact Amount of Missing Information That Makes Finding Possible Winners Hard.” CoRR abs/1610.08407.\n\n\n———. 2016c. “Preference Elicitation for Single Crossing Domain.” CoRR abs/1604.05194.\n\n\nDey, Palash, Neeldhara Misra, and Y. Narahari. 2014a. “Complexity of Kernelization in the Possible Winner Problem.” CoRR abs/1405.3865.\n\n\n———. 2014b. “Detecting Possible Manipulators in Elections.” CoRR abs/1404.2367.\n\n\n———. 2015a. “Frugal Bribery in Voting.” CoRR abs/1504.08248.\n\n\n———. 2015b. “Manipulation Is Harder with Incomplete Votes.” CoRR abs/1504.08256.\n\n\n———. 2015c. “On Choosing Committees Based on Approval Votes in the Presence of Outliers.” CoRR abs/1511.04190.\n\n\n———. 2016. “Complexity of Manipulation with Partial Information in Voting.” CoRR abs/1604.04359.\n\n\nDey, Palash, Neeldhara Misra, Swaprava Nath, and Garima Shakya. 2019. “A Parameterized Perspective on Protecting Elections.” CoRR abs/1905.11838.\n\n\nFomin, Fedor V., Daniel Lokshtanov, Neeldhara Misra, Geevarghese Philip, and Saket Saurabh. 2010. “Hitting Forbidden Minors: Approximation and Kernelization.” CoRR abs/1010.1365.\n\n\nFomin, Fedor V., Daniel Lokshtanov, Neeldhara Misra, and Saket Saurabh. 2012. “Planar f-Deletion: Approximation and Optimal FPT Algorithms.” CoRR abs/1204.4230.\n\n\nGaspers, Serge, Neeldhara Misra, Sebastian Ordyniak, Stefan Szeider, and Stanislav Zivný. 2015. “Backdoors into Heterogeneous Classes of SAT and CSP.” CoRR abs/1509.05725.\n\n\nGowda, Kishen N., Neeldhara Misra, and Vraj Patel. 2020. “A Parameterized Perspective on Attacking and Defending Elections.” CoRR abs/2005.03176.\n\n\nGoyal, Prachi, Vikram Kamat, and Neeldhara Misra. 2013. “On the Parameterized Complexity of the Maximum Edge Coloring Problem.” CoRR abs/1306.2931.\n\n\nKamat, Vikram, and Neeldhara Misra. 2013. “An Erdős–Ko–Rado Theorem for Matchings in the Complete Graph.” CoRR abs/1303.4061.\n\n\nMisra, Neeldhara, and Harshil Mittal. 2020. “Imbalance Parameterized by Twin Cover Revisited.” CoRR abs/2005.03800.\n\n\nMisra, Neeldhara, Harshil Mittal, and Aditi Sethia. 2020. “Red-Blue Point Separation for Points on a Circle.” CoRR abs/2005.06046.\n\n\nMisra, Neeldhara, Manas Mulpuri, Prafullkumar Tale, and Gaurav Viramgami. 2022. “Romeo and Juliet Meeting in Forest Like Regions.” CoRR abs/2210.02582.\n\n\nMisra, Neeldhara, and Saraswati Nanoti. 2022. “Eternal Vertex Cover on Bipartite and Co-Bipartite Graphs.” CoRR abs/2201.03820.\n\n\nMisra, Neeldhara, and Debanuj Nayak. 2021. “On Fair Division with Binary Valuations Respecting Social Networks.” CoRR abs/2111.11528.\n\n\nMisra, Neeldhara, Sebastian Ordyniak, Venkatesh Raman, and Stefan Szeider. 2013. “Upper and Lower Bounds for Weak Backdoor Set Detection.” CoRR abs/1304.5518.\n\n\nMisra, Neeldhara, Geevarghese Philip, Venkatesh Raman, Saket Saurabh, and Somnath Sikdar. 2009. “FPT Algorithms for Connected Feedback Vertex Set.” CoRR abs/0909.3180.\n\n\nMisra, Neeldhara, and I. Vinod Reddy. 2017. “The Parameterized Complexity of Happy Colorings.” CoRR abs/1708.03853.\n\n\nMisra, Neeldhara, Chinmay Sonar, P. R. Vaidyanathan, and Rohit Vaish. 2021. “Equitable Division of a Path.” CoRR abs/2101.09794.\n\n\nRoy, Aniket Basu, Anil Maheshwari, Sathish Govindarajan, Neeldhara Misra, Subhas C. Nandy, and Shreyas Shetty. 2016. “The Runaway Rectangle Escape Problem.” CoRR abs/1603.04210.\n\n\nSonar, Chinmay, Palash Dey, and Neeldhara Misra. 2020. “On the Complexity of Winner Verification and Candidate Winner for Multiwinner Voting Rules.” CoRR abs/2004.13933."
  },
  {
    "objectID": "research/overview-fairdivision.html",
    "href": "research/overview-fairdivision.html",
    "title": "Overview",
    "section": "",
    "text": "Studies of fair division aim to find ways of allocating resources among people (aka agents) — who have preferences over said resources — in such a way that makes everyone happy.\nThat was a loaded statement, and as we will see, there are a number of ways in which it can be made precise.\n The language in this short essay is deliberately informal. Please take a look at some of the references for proper definitions, notation, and etiquette. The goal here is to just convey, briefly, the major lines of inquiry in fair division research.\n\n\nResources, broadly speaking, refer to the thing(s) we want to allocate. It might refer to discrete items (e.g, cars) that are typically infeasible to “break” further, or a continuous object (e.g, a piece of land). In the former setting, one simply models the resources as a finite set, while in the latter, it is convenient to think of the resource as the interval [0,1]. These scenarios are usually called the settings of indivisible goods and cake cutting, respectively.\nAlthough it doesn’t sound like it, a resource may also refer to something not entirely empowering, such as a (usually tiresome) task that needs to be done. Such resources are often called chores.\nIn short: resources are thing(s) that need to be handed out or assigned.\n\n\n\nAgents lie the heart of the problem: to keep things meanigful we assume there’s more than one, and rest assured, things already get interesting with just two of them, although we often have more of them to worry about. These are the folks who are eyeing (or avoiding, depending on the situation) a large share of the resources.\n\n\n\nOur agents have… opinions. They all come with their own perspectives on resources. These preferences can be expressed with a valuation function v, which takes as input a subset of resources and a choice of agent, and reports the value that said agent has for said resources.\nFor instance, in the indivisible setting: if S is a subset of items and a is an agent, we could probe v(S,a) to appreciate the utility that the agent derives if s/he were to be given all the items in S (and nothing else).\n\n\n\n\n\n\nAdditive Valuations\n\n\n\nFor indivisible items, it’s common to assume that valuations are additive, i.e, the value that an agent has for a bundle of items S is the same as the sum of the values that it has for each of the individual items, i.e: v(S,a) = \\sum_{x \\in S}v(\\{x\\},a).\n\n\n\n\n\n\n\n\nNormalized Valuations\n\n\n\nTo make apples-to-apples comparisons between agents, it is common to assume that the values themselves are normalized: imagine that every agent has 100 points that they must use fully to express their desires.\nIn other words, if R is the set of all resources, we have: v(R,a) = 100 for all agents a.\n\n\n\n\n\nAn allocation is simply a partition of our resources into n labeled parts, where the labels correspond to agents. As you might guess, this is to say that the agent a “recieves” the part labeled a. Note that our choice of the word partition implies two important things:\n\nEvery resource is allocated to some agent.\nNo resource is allocated to more than one agent.\n\nThe first point implies that no resources are thrown away, while the second point implies that there is no sharing. Sometimes, we may want to relax these aspects of the definition: this is nonetheless a good place to start.\n\n\n\nAh well. This, as you might have guessed, is: (a) the hard part, and (b) not always possible, depending on your definition. \nThere are several notions of “happiness” proposed in the fair division literature. Suppose we are trying to divide R1 among a set of n agents A whose valuations are given by v, and we have come up with an allocation D. For an agent a, we use D_a to denote the part labeled a in D.\nHere are a few notions suggestive that D is a “desirable” allocation, making everyone in A happy.\n\n\n\n\n\n\n Proportional Division\n\n\n\nThe allocation D is proportional if every agent gets at least their “due” share according to his own value function. In particular, each of the n agents gets a subset of R which they value as at least 1/n of the total value:\n V(D_a,a)\\geqslant V_{a}(R)/n ~~~ \\forall a \\in A.\n\n\n\n\n\n\n\n\n Envy-Freeness\n\n\n\nThe allocation D is envy-free if no agent values someone else’s bundle more than their own: i.e, if an agent a considers agent b’s bundle, they find that they value their own bundle at least as much as they value b’s:\nv(D_a,a) \\geqslant v(D_b,a) ~~~ \\forall a,b \\in A.\n\n\n\n\n\n\n\n\n Equitability\n\n\n\nThe allocation D is equitable if all agents have the same value for their bundles:\nv(D_a,a) = v(D_b,b) ~~~ \\forall a,b \\in A.\n\n\nNotice that if we didn’t insist on D allocating every item to some agent, then we could resort to the happiness-by-Zen approach: in particular, the trivial allocation that gives nobody anything would vacuously satisfy most definitions of happiness. Implicitly, our demand for a “complete” allocation can be thought of as an efficiency requirement, and one could also push the bar on this front. For example, a common efficiency notion, borrowed from economics, is Pareto optimality.\n\n\n\n\n\n\n Pareto Optimality\n\n\n\nThe allocation D is Pareto optimal if no other allocation would make someone better off without making someone else worse off. In other words, for any allocation D^\\prime \\neq D, if there exists an agent a for whom:\n v(D^\\prime_a,a) > v(D_a,a), \nthen there is also an agent b for whom:  v(D^\\prime_b,b) < v(D_b,b). \n\n\nFix any notion of happiness2 — say P, and efficiency — say Q. Two questions are of immediate interest:\n\nDo allocations that satisfy P and Q always exist?\nFor instances that admit allocations that satisfy P and Q, can such allocations be computed efficiently? And can we quickly determine if such allocations do not exist for a given instance?\n\nFor example, notice that allocations in the sense that we defined them (with an implicit requirement of completeness) that are envy-free need not always exist: consider the situation where you have two agents and one item, and both agents value said item at 100. Any complete allocation will assign this item to one of these two agents, making the other envious. The same example shows that we cannot guarantee the existence of complete equitable allocations.\nNon-existence of nice allocations is always a bit of a bummer, so much research has been devoted to reasonable workarounds, for example:\n\nWhat if3 the allocations could be approximately envy-free/equitable?\nWhat if4 the valuations were not completely arbitrary?\nWhat if5 we could introduce some dummy items or money into the systsem to make things work?\nWhat if6 we didn’t have to allocate everything?\nWhat if7 the parts were allowed to overlap?\n\nApart from making sense of reasonable workarounds, research on fair division also aims to understand tradeoffs between fairness and efficiency. Given an allocation, there are ways in which you can measure its welfare — it’s usually a function of the utilities that all agents derive from the allocation. The “gap” between the maximum welfare you can generate if you were not restricted by fairness requirements v/s the best welfare attainable subject to fairness constraints — known as the price of fairness — is also the topic of much research.\nIf any of this piqued your interest, here’s a non-exhaustive list of pointers that I hope will help with finding out more!\n\n\n\n\n\n\n Credits. Many thanks to Rohit Vaish for inputs and pointers!\n\n\n\n\n\n\n\nPart II in the Handbook of Computational Social Choice (Brandt et al. 2016) is a great place to start (the handbook can be downloaded from here).\nFor indivisible goods, (Amanatidis et al. 2022) is an excellent and — at least at the time of this writing — recent survey covering the state of the art and highlighting major open problems.\nSeveral talks in the COMSOC Seminar Series are focused on problems in fair division. Watch out for (among others):\n\nAyumi Igarashi (NII Tokyo): Fair Division of House Chores\nWarut Suksompong (Singapore): Picking Sequences and Monotonicity in Weighted Fair Division\nErel Segal-Halevi (Ariel): Fair Division of Electricity\nMaria Kyropoulou (Essex): On Interim Envy-Free Allocation Lotteries\nAnna Bogomolnaia (Glasgow): Guarantees in Fair Division\nFrancis Su (Harvey Mudd): Multilabeled Versions of Sperner’s and Fan’s Lemmas and Applications\nXiaohui Bei (Nanyang Technological University): Fair Division of Mixed Divisible and Indivisible Goods\nJérôme Lang (Paris): Collective Decision Making under Incomplete Knowledge: Possible and Necessary Solutions\n\nRohit Vaish taught an excellent mini-course on Fair Division at IIT Gandhinagar in 2018:\n\nIntroduction to Cake Cutting \nIntroduction to the setting of Indivisible Goods \nCake Cutting Revisited \nAlgorithms for Indivisible Goods \nOpen Problems \n\nSeveral lectures in the ACM Summer School on Game Theory (by Siddarth Barman and Nidhi Rathi) were on themes related to Fair Division:\n\nAn Introduction to Cake-Cutting \nTwo Algorithms for Finding Proportional Allocations \nEnvy-Freenes and Approximate EF \nSperner’s Lemma and Applications \nCake Cutting with a Secret Agent \nFairness Notions for Indivisible Goods \nComputing EF1 Allocations: Cycle Trading and Round Robin \nAn Introduction to Rent Division \nRent Division and Maximum Weight Matchings \nHall’s Theorem and Maximin Share \n\nCheck out the talks on Algorithms for Fair Division and Collective Welfare by Siddharth Barman (Part 1, Part 2) at Recent Trends in Algorithms, 2022.\nVisualize several fair division algorithms at MatchU, a project by Hadi Hosseini.\nThis is a lovely popular lecture on Cake Cutting by Francis Su."
  },
  {
    "objectID": "research/phdthesis.html",
    "href": "research/phdthesis.html",
    "title": "Overview",
    "section": "",
    "text": "PhD Thesis"
  },
  {
    "objectID": "research/publications-other.html",
    "href": "research/publications-other.html",
    "title": "Publications",
    "section": "",
    "text": "Miscellaneous Publications\nDBLP ⸱ Conferences ⸱ Journals ⸱ ArXiV ⸱ Other\n\n \n\n\n\nMisra, Neeldhara. 2016a. “Alternate Parameterizations.” In Encyclopedia of Algorithms, 64–67.\n\n\n———. 2016b. “Kernelization, Planar f-Deletion.” In Encyclopedia of Algorithms, 1033–36."
  },
  {
    "objectID": "research/publications.html",
    "href": "research/publications.html",
    "title": "Publications",
    "section": "",
    "text": "Publications\nDBLP ⸱ Conferences ⸱ Journals ⸱ ArXiV ⸱ Other\n\n \n\n\n\n\n\n\n\nThese pages are currently work in progress: I hope to add pointers to slides, blogs, and videos associated with these papers in due course!"
  },
  {
    "objectID": "research/people.html",
    "href": "research/people.html",
    "title": "People",
    "section": "",
    "text": "People\n\n \n\n\nPostDocPhDMastersProject StudentsInternsJRFs\n\n\n\n\n\n    \n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Jayakrishnan Madathil\n        \n                \n        IITGN Early Career Research Fellow\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2020 — 2021\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Suman Banerjee\n        \n                \n        IITGN PostDoctoral Fellow\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019 — 2020\n    \n\n\n\n\nNo matching items\n\n\n\n\n\n \n\n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        Apeksha Srivastava\n        \n                \n        PhD (Humanities and Social Sciences)\n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2021 — present\n    \n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        Harshil Mittal\n        \n                \n        PhD (Computer Science & Engineering)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2020 — present\n    \n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        Saraswati Nanoti\n        \n                \n        PhD (Mathematics)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2020 — present\n    \n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        Aditi Sethia\n        \n                \n        PhD (Computer Science & Engineering)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019 — present\n    \n\n\n\n\nNo matching items\n\n\n\n\n\n \n\n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        Harshit Chauhan\n        \n                \n        MSc Mathematics\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2021 -- 2023\n    \n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        Argha Sardar\n        \n                \n        MSc Mathematics\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2021 -- 2023\n    \n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        Rasika Ramakrishna\n        \n                \n        MSc Mathematics\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019 -- 2021\n    \n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        Aashima Kaushal\n        \n                \n        MSc Mathematics\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019 -- 2020\n    \n\n        \n        \n        \n        \n        \n                        \n        \n        \n        \n        \n        \n        Chinmay Sonar\n        \n                \n        Dual Degree BTech (ME) & MTech (CSE)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2018 -- 2019\n    \n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        Tanisha\n        \n                \n        MSc Mathematics\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2017 -- 2019\n    \n\n        \n        \n        \n        \n        \n                        \n        \n        \n        \n        \n        \n        Chamanvir Kaur\n        \n                \n        MTech Computer Science & Engineering\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2017 -- 2019\n    \n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        Piyush Rathi\n        \n                \n        MTech Computer Science & Engineering\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2017 -- 2019\n    \n\n        \n        \n        \n        \n        \n                        \n        \n        \n        \n        \n        \n        Aditi Sethia\n        \n                \n        MSc Mathematics\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2017 -- 2019\n    \n\n        \n        \n        \n        \n        \n                        \n        \n        \n        \n        \n        \n        Arshed Nabeel\n        \n                \n        MTech Computer Science (CSA, IISc)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2013 -- 2015\n    \n\n\n\n\nNo matching items\n\n\n\n\n\n \n\n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        Yash More\n        \n                \n        Independent Project (UG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2023\n    \n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        Binita Maity\n        \n                \n        Independent Project (UG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2023\n    \n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        Shrutimoy Das\n        \n                \n        Independent Project (UG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2023\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Shivangi Yadav\n        \n                \n        Independent Project (PG, Mathematics)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Divya Sharma\n        \n                \n        Independent Project (PG, Electrical Engineering)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Sukruta Midigeshi\n        \n                \n        Independent Project (UG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Hrushti Naik\n        \n                \n        Independent Project (UG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Yash More\n        \n                \n        Independent Project (UG)\n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Guru Sharan N\n        \n                \n        Independent Project (PG, Mathematics)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Amey Kulkarni\n        \n                \n        Independent Project (UG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Aditya Pusalkar\n        \n                \n        Independent Project (UG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Aditi Sethia\n        \n                \n        Independent Project (PG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Akash Pareek\n        \n                \n        Independent Project (PG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Manas Mulpuri\n        \n                \n        Independent Project (UG)\n        \n        \n                            \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Viramgami Gaurav\n        \n                \n        Independent Project (UG)\n        \n        \n                            \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Anant Kumar\n        \n                \n        Independent Project (PG, Mathematics)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2021\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Dhara Thakkar\n        \n                \n        Independent Project (PG, Mathematics)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2021\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Dipan Dey\n        \n                \n        Independent Project (PG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2021\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Manas Mulpuri\n        \n                \n        Independent Project (UG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2021\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Viramgami Gaurav\n        \n                \n        Independent Project (UG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2021\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Nipun Mahajan\n        \n                \n        Independent Project (PG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2021\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Mahika Jaguste\n        \n                \n        Independent Project (PG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2021\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Jayesh Malaviya\n        \n                \n        Independent Project (PG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2021\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Chris Francis\n        \n                \n        Independent Project (UG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2020\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Amey Kulkarni\n        \n                \n        Independent Project (UG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2020\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Ritik Dutta\n        \n                \n        Independent Project (UG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2020\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Kousik Loho\n        \n                \n        Independent Project (PG, Physics)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Aditiben Savalia\n        \n                \n        Independent Project (PG, Mathematics)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Vraj Patel\n        \n                \n        Independent Project (UG)\n        \n        \n                            \n        \n        \n        \n        \n        \n    \n    \n        2019\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Kishen Gowda\n        \n                \n        Independent Project (UG)\n        \n        \n                            \n        \n        \n        \n        \n        \n    \n    \n        2019\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Ritik Dutta\n        \n                \n        Independent Project (UG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Debanuj Nayak\n        \n                \n        Independent Project (UG)\n        \n        \n                            \n        \n        \n        \n        \n        \n    \n    \n        2019\n    \n\n        \n        \n            \n        \n        \n                        \n        \n        \n        \n        \n        \n        Chinmay Sonar\n        \n                \n        Independent Project (UG)\n        \n        \n                            \n        \n        \n        \n        \n        \n    \n    \n        2017\n    \n\n        \n        \n            \n        \n        \n                        \n        \n        \n        \n        \n        \n        P R Vaidyanathan\n        \n                \n        Independent Project (UG)\n        \n        \n                            \n        \n        \n        \n        \n        \n    \n    \n        2017\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Ankita Shah\n        \n                \n        Independent Project (PG, HSS)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2017\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Aparna Nampoothiri\n        \n                \n        Independent Project (PG, HSS)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2017\n    \n\n        \n        \n            \n        \n        \n                        \n        \n        \n        \n        \n        \n        Akash Pallath\n        \n                \n        Independent Project (UG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2017\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Gagan Kanojia\n        \n                \n        Independent Project (PG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2016\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Shivdutt Sharma\n        \n                \n        Independent Project (PG)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2016\n    \n\n\n\n\nNo matching items\n\n\n\n\n\n \n\n\n\n\n    \n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Subhajit Pramanik\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Elizabeth Mary Mathew\n        \n                \n        Google Explore CSR Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Vaishnavi Gaurav\n        \n                \n        Google Explore CSR Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Tanushree Shetty\n        \n                \n        Google Explore CSR Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2022\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Rutvik Rahul Page\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Varad Pimpalkhute\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Shivam Mishra\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Kavel Baruah\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Radhika Vyas\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Dhruvesh Asnani\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Sarath Chandra\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Prudhvi Raj\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Hitesh Kumar\n        \n                \n        Research Intern\n        \n        \n                            \n        \n        \n        \n        \n        \n    \n    \n        2018\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Foram Lakhani\n        \n                \n        Research Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2017\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Raj Rajvir\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2017\n    \n\n        \n        \n            \n        \n        \n                        \n        \n        \n        \n        \n        \n        Anurag Sanyal\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2017\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Aashay Sandansing\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2016\n    \n\n        \n        \n            \n        \n        \n                        \n        \n        \n        \n        \n        \n        Akash Pallath\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2016\n    \n\n        \n        \n            \n        \n        \n                        \n        \n        \n        \n        \n        \n        Chinmay Sonar\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2016\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Purvil Jani\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2016\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Sneha Garuda\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2016\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Jainil Vachhani\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2016\n    \n\n        \n        \n            \n        \n        \n        \n        \n        \n        \n        \n        Paritosh Yadav\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2016\n    \n\n        \n        \n            \n        \n        \n                        \n        \n        \n        \n        \n        \n        Tushar Anchan\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2016\n    \n\n        \n        \n            \n        \n        \n                        \n        \n        \n        \n        \n        \n        P R Vaidyanathan\n        \n                \n        SRIP Intern\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2016\n    \n\n        \n        \n            \n        \n        \n                        \n        \n        \n        \n        \n        \n        Harman Singh\n        \n                \n        Research Intern (CSA, IISc)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2014\n    \n\n        \n        \n            \n        \n        \n                        \n        \n        \n        \n        \n        \n        Shreyas Shetty\n        \n                \n        Project Assistant (CSA, IISc)\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2014\n    \n\n\n\n\nNo matching items\n\n\n\n\n\n \n\n\n\n\n    \n        \n        \n            \n        \n        \n                        \n        \n        \n        \n        \n        \n        Harshil Mittal\n        \n                \n        Junior Research Fellow\n        \n        \n        \n        \n        \n        \n        \n    \n    \n        2019\n    \n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nJayakrishnan Madathil\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nSuman Banerjee\n\n\n\n \n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n×\n\n \n\n\nApeksha Srivastava\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nHarshil Mittal\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nSaraswati Nanoti\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAditi Sethia\n\n\n\n \n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n×\n\n \n\n\nHarshit Chauhan\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nArgha Sardar\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nRasika Ramakrishna\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAashima Kaushal\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nChinmay Sonar\n\n\n\n \n\n\nGraduate Student  University of California, Santa Barbara\n\n\n                   \n\n\n\n\n\n\n\n×\n\n \n\n\nTanisha\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nChamanvir Kaur\n\n\n\n \n\n\nFull-Stack Developer  TOMIA\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nPiyush Rathi\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAditi Sethia\n\n\n\n \n\n\nGraduate Student  Indian Institute of Technology, Gandhinagar\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nArshed Nabeel\n\n\n\n \n\n\nResearch Engineer  Netradyne\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n×\n\n \n\n\nYash More\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nBinita Maity\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nShrutimoy Das\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nShivangi Yadav\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nDivya Sharma\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nSukruta Midigeshi\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nHrushti Naik\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nYash More\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nGuru Sharan N\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAmey Kulkarni\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAditya Pusalkar\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAditi Sethia\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAkash Pareek\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nManas Mulpuri\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nViramgami Gaurav\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAnant Kumar\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nDhara Thakkar\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nDipan Dey\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nManas Mulpuri\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nViramgami Gaurav\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nNipun Mahajan\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nMahika Jaguste\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nJayesh Malaviya\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nChris Francis\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAmey Kulkarni\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nRitik Dutta\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nKousik Loho\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAditiben Savalia\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nVraj Patel\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nKishen Gowda\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nRitik Dutta\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nDebanuj Nayak\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nChinmay Sonar\n\n\n\n \n\n\nGraduate Student  University of California, Santa Barbara\n\n\n                   \n\n\n\n\n\n\n\n×\n\n \n\n\nP R Vaidyanathan\n\n\n\n \n\n\nGraduate Student  TU Wien\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAnkita Shah\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAparna Nampoothiri\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAkash Pallath\n\n\n\n \n\n\nGraduate Student  University of Pennsylvania\n\n\n                   \n\n\n\n\n\n\n\n×\n\n \n\n\nGagan Kanojia\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nShivdutt Sharma\n\n\n\n \n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n×\n\n \n\n\nSubhajit Pramanik\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nElizabeth Mary Mathew\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nVaishnavi Gaurav\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nTanushree Shetty\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nRutvik Rahul Page\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nVarad Pimpalkhute\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nShivam Mishra\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nKavel Baruah\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nRadhika Vyas\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nDhruvesh Asnani\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nSarath Chandra\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nPrudhvi Raj\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nHitesh Kumar\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nForam Lakhani\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nRaj Rajvir\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAnurag Sanyal\n\n\n\n \n\n\nMasters Student  Simon Fraser University\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAashay Sandansing\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nAkash Pallath\n\n\n\n \n\n\nGraduate Student  University of Pennsylvania\n\n\n                   \n\n\n\n\n\n\n\n×\n\n \n\n\nChinmay Sonar\n\n\n\n \n\n\nGraduate Student  University of California, Santa Barbara\n\n\n                   \n\n\n\n\n\n\n\n×\n\n \n\n\nPurvil Jani\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nSneha Garuda\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nJainil Vachhani\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nParitosh Yadav\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nTushar Anchan\n\n\n\n \n\n\nSoftware Engineer  Expedia Group\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nP R Vaidyanathan\n\n\n\n \n\n\nGraduate Student  TU Wien\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nHarman Singh\n\n\n\n \n\n\nProduct Fellow  Razorpay\n\n\n\n\n\n\n\n\n\n×\n\n \n\n\nShreyas Shetty\n\n\n\n \n\n\nData Scientist  Flipkart\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n×\n\n \n\n\nHarshil Mittal\n\n\n\n \n\n\nGraduate Student  Indian Institute of Technology, Gandhinagar\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research/publications-journal.html",
    "href": "research/publications-journal.html",
    "title": "Publications",
    "section": "",
    "text": "Journal Publications\nDBLP ⸱ Conferences ⸱ Journals ⸱ ArXiV ⸱ Other\n\n \n\n\n\nAgrawal, A., N. R. Aravind, S. Kalyanasundaram, A. S. Kare, J. Lauri, N. Misra, and I. V. Reddy. (2020): “Parameterized complexity of happy coloring problems,” Theor. Comput. Sci., 835, 58–81.\n\n\nAshok, P., S. Kolay, N. Misra, and S. Saurabh. (2022): “Exact multi-covering problems with geometric sets,” Theory Comput. Syst., 66, 89–113.\n\n\nBanerjee, S., N. Misra, and S. C. Nandy. (2020): “Color spanning objects: Algorithms and hardness results,” Discret. Appl. Math., 280, 14–22.\n\n\nDas, B., M. K. Enduri, M. Kiyomi, N. Misra, Y. Otachi, I. V. Reddy, and S. Yoshimura. (2019): “On structural parameterizations of firefighting,” Theor. Comput. Sci., 782, 79–90.\n\n\nDey, P., N. Misra, and Y. Narahari. (2016): “Kernelization complexity of possible winner and coalitional manipulation problems in voting,” Theor. Comput. Sci., 616, 111–25.\n\n\n---. (2017): “Frugal bribery in voting,” Theor. Comput. Sci., 676, 15–32.\n\n\n---. (2018): “Complexity of manipulation with partial information in voting,” Theor. Comput. Sci., 726, 78–99.\n\n\n---. (2019): “Parameterized dichotomy of choosing committees based on approval votes in the presence of outliers,” Theor. Comput. Sci., 783, 53–70.\n\n\nDey, P., N. Misra, S. Nath, and G. Shakya. (2021): “A parameterized perspective on protecting elections,” Theor. Comput. Sci., 874, 15–31.\n\n\nFellows, M. R., D. Lokshtanov, N. Misra, M. Mnich, F. A. Rosamond, and S. Saurabh. (2009): “The complexity ecology of parameters: An illustration using bounded max leaf number,” Theory Comput. Syst., 45, 822–48.\n\n\nFomin, F. V., D. Lokshtanov, N. Misra, G. Philip, and S. Saurabh. (2013): “Quadratic upper bounds on the erdős-pósa property for a generalization of packing and covering cycles,” J. Graph Theory, 74, 417–24.\n\n\n---. (2016): “Hitting forbidden minors: Approximation and kernelization,” SIAM J. Discret. Math., 30, 383–410.\n\n\nGaspers, S., N. Misra, S. Ordyniak, S. Szeider, and S. Zivný. (2017): “Backdoors into heterogeneous classes of SAT and CSP,” J. Comput. Syst. Sci., 85, 38–56.\n\n\nGoyal, P., N. Misra, F. Panolan, and M. Zehavi. (2015): “Deterministic algorithms for matching and packing problems based on representative sets,” SIAM J. Discret. Math., 29, 1815–36.\n\n\nHeggernes, P., P. van ’t Hof, D. Marx, N. Misra, and Y. Villanger. (2015): “On the parameterized complexity of finding separators with non-hereditary properties,” Algorithmica, 72, 687–713.\n\n\nLokshtanov, D., N. Misra, and S. Saurabh. (2013): “Imbalance is fixed parameter tractable,” Inf. Process. Lett., 113, 714–18.\n\n\nMisra, N., and H. Mittal. (2021): “Imbalance parameterized by twin cover revisited,” Theor. Comput. Sci., 895, 1–15.\n\n\nMisra, N., H. Moser, V. Raman, S. Saurabh, and S. Sikdar. (2013): “The parameterized complexity of unique coverage and its variants,” Algorithmica, 65, 517–44.\n\n\nMisra, N., N. S. Narayanaswamy, V. Raman, and B. S. Shankar. (2013): “Solving min ones 2-sat as fast as vertex cover,” Theor. Comput. Sci., 506, 115–21.\n\n\nMisra, N., F. Panolan, A. Rai, V. Raman, and S. Saurabh. (2019): “Parameterized algorithms for max colorable induced subgraph problem on perfect graphs,” Algorithmica, 81, 26–46.\n\n\nMisra, N., F. Panolan, and S. Saurabh. (2020): “Subexponential algorithm for d-cluster edge deletion: Exception or rule?” J. Comput. Syst. Sci., 113, 150–62.\n\n\nMisra, N., G. Philip, V. Raman, and S. Saurabh. (2012): “On parameterized independent feedback vertex set,” Theor. Comput. Sci., 461, 65–75.\n\n\n---. (2014): “The kernelization complexity of connected domination in graphs with (no) small cycles,” Algorithmica, 68, 504–30.\n\n\nMisra, N., G. Philip, V. Raman, S. Saurabh, and S. Sikdar. (2012): “FPT algorithms for connected feedback vertex set,” J. Comb. Optim., 24, 131–46.\n\n\nMisra, N., V. Raman, and S. Saurabh. (2011): “Lower bounds on kernelization,” Discret. Optim., 8, 110–28.\n\n\nMisra, N., F. A. Rosamond, and M. Zehavi. (2020): “Special issue \"new frontiers in parameterized complexity and algorithms\": Foreward by the guest editors,” Algorithms, 13, 236."
  },
  {
    "objectID": "research/surveys/index.html",
    "href": "research/surveys/index.html",
    "title": "Searchable Surveys",
    "section": "",
    "text": "Searchable Surveys\n\n \n\nI am working on surveys which are formatted as searchable lists of results. Coming soon, hopefully!"
  },
  {
    "objectID": "research/publications-conference.html",
    "href": "research/publications-conference.html",
    "title": "Publications",
    "section": "",
    "text": "Conference Publications\nDBLP ⸱ Conferences ⸱ Journals ⸱ ArXiV ⸱ Other\n\n \n\n\n\nAgrawal, Akanksha, Sathish Govindarajan, and Neeldhara Misra. 2014. “Vertex Cover Gets Faster and Harder on Low Degree Graphs.” In Computing and Combinatorics - 20th International Conference, COCOON 2014, Atlanta, GA, USA, August 4-6, 2014. Proceedings, edited by Zhipeng Cai, Alex Zelikovsky, and Anu G. Bourgeois, 8591:179–90. Lecture Notes in Computer Science. Springer.\n\n\nAmbalath, Abhimanyu M., Radheshyam Balasundaram, Chintan Rao H., Venkata Koppula, Neeldhara Misra, Geevarghese Philip, and M. S. Ramanujan. 2010. “On the Kernelization Complexity of Colorful Motifs.” In Parameterized and Exact Computation - 5th International Symposium, IPEC 2010, Chennai, India, December 13-15, 2010. Proceedings, edited by Venkatesh Raman and Saket Saurabh, 6478:14–25. Lecture Notes in Computer Science. Springer.\n\n\nAravind, N. R., Neeldhara Misra, and Harshil Mittal. 2022. “Chess Is Hard Even for a Single Player.” In 11th International Conference on Fun with Algorithms, FUN 2022, May 30 to June 3, 2022, Island of Favignana, Sicily, Italy, edited by Pierre Fraigniaud and Yushi Uno, 226:5:1–20. LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum für Informatik.\n\n\nArumugam, S., K. Raja Chandrasekar, Neeldhara Misra, Geevarghese Philip, and Saket Saurabh. 2011. “Algorithmic Aspects of Dominator Colorings in Graphs.” In Combinatorial Algorithms - 22nd International Workshop, IWOCA 2011, Victoria, BC, Canada, July 20-22, 2011, Revised Selected Papers, edited by Costas S. Iliopoulos and William F. Smyth, 7056:19–30. Lecture Notes in Computer Science. Springer.\n\n\nAshok, Pradeesha, Sudeshna Kolay, Neeldhara Misra, and Saket Saurabh. 2015. “Unique Covering Problems with Geometric Sets.” In Computing and Combinatorics - 21st International Conference, COCOON 2015, Beijing, China, August 4-6, 2015, Proceedings, edited by Dachuan Xu, Donglei Du, and Ding-Zhu Du, 9198:548–58. Lecture Notes in Computer Science. Springer.\n\n\nBanerjee, Sandip, Neeldhara Misra, and Subhas C. Nandy. 2016. “Color Spanning Objects: Algorithms and Hardness Results.” In Algorithms and Discrete Applied Mathematics - Second International Conference, CALDAM 2016, Thiruvananthapuram, India, February 18-20, 2016, Proceedings, edited by Sathish Govindarajan and Anil Maheshwari, 9602:37–48. Lecture Notes in Computer Science. Springer.\n\n\nBilò, Davide, Luciano Gualà, Stefano Leucci, and Neeldhara Misra. 2018. “On the Complexity of Two Dots for Narrow Boards and Few Colors.” In 9th International Conference on Fun with Algorithms, FUN 2018, June 13-15, 2018, La Maddalena, Italy, edited by Hiro Ito, Stefano Leonardi, Linda Pagli, and Giuseppe Prencipe, 100:7:1–15. LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum für Informatik.\n\n\nChoudhari, Jayesh, Anirban Dasgupta, Neeldhara Misra, and M. S. Ramanujan. 2017. “Saving Critical Nodes with Firefighters Is FPT.” In 44th International Colloquium on Automata, Languages, and Programming, ICALP 2017, July 10-14, 2017, Warsaw, Poland, edited by Ioannis Chatzigiannakis, Piotr Indyk, Fabian Kuhn, and Anca Muscholl, 80:135:1–13. LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum für Informatik.\n\n\nDas, Bireswar, Murali Krishna Enduri, Neeldhara Misra, and I. Vinod Reddy. 2017. “On Structural Parameterizations of Graph Motif and Chromatic Number.” In Algorithms and Discrete Applied Mathematics - Third International Conference, CALDAM 2017, Sancoale, Goa, India, February 16-18, 2017, Proceedings, edited by Daya Ram Gaur and N. S. Narayanaswamy, 10156:118–29. Lecture Notes in Computer Science. Springer.\n\n\n———. 2018. “On Structural Parameterizations of Firefighting.” In Algorithms and Discrete Applied Mathematics - 4th International Conference, CALDAM 2018, Guwahati, India, February 15-17, 2018, Proceedings, edited by B. S. Panda and Partha P. Goswami, 10743:221–34. Lecture Notes in Computer Science. Springer.\n\n\nDayal, Pratyush, and Neeldhara Misra. 2019. “Deleting to Structured Trees.” In Computing and Combinatorics - 25th International Conference, COCOON 2019, Xi’an, China, July 29-31, 2019, Proceedings, edited by Ding-Zhu Du, Zhenhua Duan, and Cong Tian, 11653:128–39. Lecture Notes in Computer Science. Springer.\n\n\nDey, Palash, Prachi Goyal, and Neeldhara Misra. 2014. “UNO Gets Easier for a Single Player.” In Fun with Algorithms - 7th International Conference, FUN 2014, Lipari Island, Sicily, Italy, July 1-3, 2014. Proceedings, edited by Alfredo Ferro, Fabrizio Luccio, and Peter Widmayer, 8496:147–57. Lecture Notes in Computer Science. Springer.\n\n\nDey, Palash, and Neeldhara Misra. 2016a. “Elicitation for Preferences Single Peaked on Trees.” In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016, New York, NY, USA, 9-15 July 2016, edited by Subbarao Kambhampati, 215–21. IJCAI/AAAI Press.\n\n\n———. 2016b. “Preference Elicitation for Single Crossing Domain.” In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016, New York, NY, USA, 9-15 July 2016, edited by Subbarao Kambhampati, 222–28. IJCAI/AAAI Press.\n\n\n———. 2017. “On the Exact Amount of Missing Information That Makes Finding Possible Winners Hard.” In 42nd International Symposium on Mathematical Foundations of Computer Science, MFCS 2017, August 21-25, 2017 - Aalborg, Denmark, edited by Kim G. Larsen, Hans L. Bodlaender, and Jean-François Raskin, 83:57:1–14. LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum für Informatik.\n\n\nDey, Palash, Neeldhara Misra, and Y. Narahari. 2015a. “Detecting Possible Manipulators in Elections.” In Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2015, Istanbul, Turkey, May 4-8, 2015, edited by Gerhard Weiss, Pinar Yolum, Rafael H. Bordini, and Edith Elkind, 1441–50. ACM.\n\n\n———. 2015b. “Kernelization Complexity of Possible Winner and Coalitional Manipulation Problems in Voting.” In Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2015, Istanbul, Turkey, May 4-8, 2015, edited by Gerhard Weiss, Pinar Yolum, Rafael H. Bordini, and Edith Elkind, 87–96. ACM.\n\n\n———. 2016a. “Complexity of Manipulation with Partial Information in Voting.” In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016, New York, NY, USA, 9-15 July 2016, edited by Subbarao Kambhampati, 229–35. IJCAI/AAAI Press.\n\n\n———. 2016b. “Frugal Bribery in Voting.” In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, February 12-17, 2016, Phoenix, Arizona, USA, edited by Dale Schuurmans and Michael P. Wellman, 2466–72. AAAI Press.\n\n\n———. 2017. “Parameterized Dichotomy of Choosing Committees Based on Approval Votes in the Presence of Outliers.” In Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems, AAMAS 2017, são Paulo, Brazil, May 8-12, 2017, edited by Kate Larson, Michael Winikoff, Sanmay Das, and Edmund H. Durfee, 42–50. ACM.\n\n\nDey, Palash, Neeldhara Misra, Swaprava Nath, and Garima Shakya. 2019. “A Parameterized Perspective on Protecting Elections.” In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019, edited by Sarit Kraus, 238–44. ijcai.org.\n\n\nFellows, Michael R., Daniel Lokshtanov, Neeldhara Misra, Frances A. Rosamond, and Saket Saurabh. 2008. “Graph Layout Problems Parameterized by Vertex Cover.” In Algorithms and Computation, 19th International Symposium, ISAAC 2008, Gold Coast, Australia, December 15-17, 2008. Proceedings, edited by Seok-Hee Hong, Hiroshi Nagamochi, and Takuro Fukunaga, 5369:294–305. Lecture Notes in Computer Science. Springer.\n\n\nFomin, Fedor V., Daniel Lokshtanov, Neeldhara Misra, Geevarghese Philip, and Saket Saurabh. 2011. “Hitting Forbidden Minors: Approximation and Kernelization.” In 28th International Symposium on Theoretical Aspects of Computer Science, STACS 2011, March 10-12, 2011, Dortmund, Germany, edited by Thomas Schwentick and Christoph Dürr, 9:189–200. LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum für Informatik.\n\n\nFomin, Fedor V., Daniel Lokshtanov, Neeldhara Misra, M. S. Ramanujan, and Saket Saurabh. 2015. “Solving d-SAT via Backdoors to Small Treewidth.” In Proceedings of the Twenty-Sixth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2015, San Diego, CA, USA, January 4-6, 2015, edited by Piotr Indyk, 630–41. SIAM.\n\n\nFomin, Fedor V., Daniel Lokshtanov, Neeldhara Misra, and Saket Saurabh. 2012. “Planar f-Deletion: Approximation, Kernelization and Optimal FPT Algorithms.” In 53rd Annual IEEE Symposium on Foundations of Computer Science, FOCS 2012, New Brunswick, NJ, USA, October 20-23, 2012, 470–79. IEEE Computer Society.\n\n\nFomin, Fedor V., Saket Saurabh, and Neeldhara Misra. 2015. “Graph Modification Problems: A Modern Perspective.” In Frontiers in Algorithmics - 9th International Workshop, FAW 2015, Guilin, China, July 3-5, 2015, Proceedings, edited by Jianxin Wang and Chee-Keng Yap, 9130:3–6. Lecture Notes in Computer Science. Springer.\n\n\nGaspers, Serge, Neeldhara Misra, Sebastian Ordyniak, Stefan Szeider, and Stanislav Zivný. 2014. “Backdoors into Heterogeneous Classes of SAT and CSP.” In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, July 27 -31, 2014, Québec City, Québec, Canada, edited by Carla E. Brodley and Peter Stone, 2652–58. AAAI Press.\n\n\nGowda, Kishen N., Neeldhara Misra, and Vraj Patel. 2020. “A Parameterized Perspective on Attacking and Defending Elections.” In Combinatorial Algorithms - 31st International Workshop, IWOCA 2020, Bordeaux, France, June 8-10, 2020, Proceedings, edited by Leszek Gasieniec, Ralf Klasing, and Tomasz Radzik, 12126:277–88. Lecture Notes in Computer Science. Springer.\n\n\nGoyal, Prachi, Vikram Kamat, and Neeldhara Misra. 2013. “On the Parameterized Complexity of the Maximum Edge 2-Coloring Problem.” In Mathematical Foundations of Computer Science 2013 - 38th International Symposium, MFCS 2013, Klosterneuburg, Austria, August 26-30, 2013. Proceedings, edited by Krishnendu Chatterjee and Jirı́ Sgall, 8087:492–503. Lecture Notes in Computer Science. Springer.\n\n\nGoyal, Prachi, Neeldhara Misra, and Fahad Panolan. 2013. “Faster Deterministic Algorithms for r-Dimensional Matching Using Representative Sets.” In IARCS Annual Conference on Foundations of Software Technology and Theoretical Computer Science, FSTTCS 2013, December 12-14, 2013, Guwahati, India, edited by Anil Seth and Nisheeth K. Vishnoi, 24:237–48. LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum für Informatik.\n\n\nGupta, Manoj, Hitesh Kumar, and Neeldhara Misra. 2019. “On the Complexity of Optimal Matching Reconfiguration.” In SOFSEM 2019: Theory and Practice of Computer Science - 45th International Conference on Current Trends in Theory and Practice of Computer Science, Nový Smokovec, Slovakia, January 27-30, 2019, Proceedings, edited by Barbara Catania, Rastislav Královic, Jerzy R. Nawrocki, and Giovanni Pighizzini, 11376:221–33. Lecture Notes in Computer Science. Springer.\n\n\nHeggernes, Pinar, Pim van ’t Hof, Dániel Marx, Neeldhara Misra, and Yngve Villanger. 2012. “On the Parameterized Complexity of Finding Separators with Non-Hereditary Properties.” In Graph-Theoretic Concepts in Computer Science - 38th International Workshop, WG 2012, Jerusalem, Israel, June 26-28, 2012, Revised Selcted Papers, edited by Martin Charles Golumbic, Michal Stern, Avivit Levy, and Gila Morgenstern, 7551:332–43. Lecture Notes in Computer Science. Springer.\n\n\nKalyanakrishnan, Shivaram, Neeldhara Misra, and Aditya Gopalan. 2016. “Randomised Procedures for Initialising and Switching Actions in Policy Iteration.” In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, February 12-17, 2016, Phoenix, Arizona, USA, edited by Dale Schuurmans and Michael P. Wellman, 3145–51. AAAI Press.\n\n\nKamat, Vikram, and Neeldhara Misra. 2015. “Parameterized Algorithms and Kernels for 3-Hitting Set with Parity Constraints.” In Algorithms and Complexity - 9th International Conference, CIAC 2015, Paris, France, May 20-22, 2015. Proceedings, edited by Vangelis Th. Paschos and Peter Widmayer, 9079:249–60. Lecture Notes in Computer Science. Springer.\n\n\nKaur, Chamanvir, and Neeldhara Misra. 2020. “On the Parameterized Complexity of Spanning Trees with Small Vertex Covers.” In Algorithms and Discrete Applied Mathematics - 6th International Conference, CALDAM 2020, Hyderabad, India, February 13-15, 2020, Proceedings, edited by Manoj Changat and Sandip Das, 12016:427–38. Lecture Notes in Computer Science. Springer.\n\n\nLokshtanov, Daniel, Neeldhara Misra, Geevarghese Philip, M. S. Ramanujan, and Saket Saurabh. 2013. “Hardness of r-Dominating Set on Graphs of Diameter (r + 1).” In Parameterized and Exact Computation - 8th International Symposium, IPEC 2013, Sophia Antipolis, France, September 4-6, 2013, Revised Selected Papers, edited by Gregory Z. Gutin and Stefan Szeider, 8246:255–67. Lecture Notes in Computer Science. Springer.\n\n\nLokshtanov, Daniel, Neeldhara Misra, and Saket Saurabh. 2010. “Imbalance Is Fixed Parameter Tractable.” In Computing and Combinatorics, 16th Annual International Conference, COCOON 2010, Nha Trang, Vietnam, July 19-21, 2010. Proceedings, edited by My T. Thai and Sartaj Sahni, 6196:199–208. Lecture Notes in Computer Science. Springer.\n\n\n———. 2012. “Kernelization - Preprocessing with a Guarantee.” In The Multivariate Algorithmic Revolution and Beyond - Essays Dedicated to Michael r. Fellows on the Occasion of His 60th Birthday, edited by Hans L. Bodlaender, Rod Downey, Fedor V. Fomin, and Dániel Marx, 7370:129–61. Lecture Notes in Computer Science. Springer.\n\n\n———. 2013. “On the Hardness of Eliminating Small Induced Subgraphs by Contracting Edges.” In Parameterized and Exact Computation - 8th International Symposium, IPEC 2013, Sophia Antipolis, France, September 4-6, 2013, Revised Selected Papers, edited by Gregory Z. Gutin and Stefan Szeider, 8246:243–54. Lecture Notes in Computer Science. Springer.\n\n\nMisra, Neeldhara. 2016. “Two Dots Is NP-Complete.” In 8th International Conference on Fun with Algorithms, FUN 2016, June 8-10, 2016, La Maddalena, Italy, edited by Erik D. Demaine and Fabrizio Grandoni, 49:24:1–12. LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum für Informatik.\n\n\n———. 2018. “On the Parameterized Complexity of Colorful Components and Related Problems.” In Combinatorial Algorithms - 29th International Workshop, IWOCA 2018, Singapore, July 16-19, 2018, Proceedings, edited by Costas S. Iliopoulos, Hon Wai Leong, and Wing-Kin Sung, 10979:237–49. Lecture Notes in Computer Science. Springer.\n\n\n———. 2019. “On the Parameterized Complexity of Party Nominations.” In Algorithmic Decision Theory - 6th International Conference, ADT 2019, Durham, NC, USA, October 25-27, 2019, Proceedings, edited by Sasa Pekec and Kristen Brent Venable, 11834:112–25. Lecture Notes in Computer Science. Springer.\n\n\nMisra, Neeldhara, and Harshil Mittal. 2020. “Imbalance Parameterized by Twin Cover Revisited.” In Computing and Combinatorics - 26th International Conference, COCOON 2020, Atlanta, GA, USA, August 29-31, 2020, Proceedings, edited by Donghyun Kim, R. N. Uma, Zhipeng Cai, and Dong Hoon Lee, 12273:162–73. Lecture Notes in Computer Science. Springer.\n\n\nMisra, Neeldhara, Harshil Mittal, and Aditi Sethia. 2020. “Red-Blue Point Separation for Points on a Circle.” In Proceedings of the 32nd Canadian Conference on Computational Geometry, CCCG 2020, August 5-7, 2020, University of Saskatchewan, Saskatoon, Saskatchewan, Canada, edited by J. Mark Keil and Debajyoti Mondal, 266–72.\n\n\nMisra, Neeldhara, Arshed Nabeel, and Harman Singh. 2015. “On the Parameterized Complexity of Minimax Approval Voting.” In Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2015, Istanbul, Turkey, May 4-8, 2015, edited by Gerhard Weiss, Pinar Yolum, Rafael H. Bordini, and Edith Elkind, 97–105. ACM.\n\n\nMisra, Neeldhara, N. S. Narayanaswamy, Venkatesh Raman, and Bal Sri Shankar. 2010. “Solving Minones-2-Sat as Fast as Vertex Cover.” In Mathematical Foundations of Computer Science 2010, 35th International Symposium, MFCS 2010, Brno, Czech Republic, August 23-27, 2010. Proceedings, edited by Petr Hlinený and Antonı́n Kucera, 6281:549–55. Lecture Notes in Computer Science. Springer.\n\n\nMisra, Neeldhara, and Debanuj Nayak. 2022. “On Fair Division with Binary Valuations Respecting Social Networks.” In Algorithms and Discrete Applied Mathematics - 8th International Conference, CALDAM 2022, Puducherry, India, February 10-12, 2022, Proceedings, edited by Niranjan Balachandran and R. Inkulu, 13179:265–78. Lecture Notes in Computer Science. Springer.\n\n\nMisra, Neeldhara, Sebastian Ordyniak, Venkatesh Raman, and Stefan Szeider. 2013. “Upper and Lower Bounds for Weak Backdoor Set Detection.” In Theory and Applications of Satisfiability Testing - SAT 2013 - 16th International Conference, Helsinki, Finland, July 8-12, 2013. Proceedings, edited by Matti Järvisalo and Allen Van Gelder, 7962:394–402. Lecture Notes in Computer Science. Springer.\n\n\nMisra, Neeldhara, Fahad Panolan, Ashutosh Rai, Venkatesh Raman, and Saket Saurabh. 2013. “Parameterized Algorithms for Max Colorable Induced Subgraph Problem on Perfect Graphs.” In Graph-Theoretic Concepts in Computer Science - 39th International Workshop, WG 2013, lübeck, Germany, June 19-21, 2013, Revised Papers, edited by Andreas Brandstädt, Klaus Jansen, and Rüdiger Reischuk, 8165:370–81. Lecture Notes in Computer Science. Springer.\n\n\nMisra, Neeldhara, Fahad Panolan, and Saket Saurabh. 2013. “Subexponential Algorithm for d-Cluster Edge Deletion: Exception or Rule?” In Mathematical Foundations of Computer Science 2013 - 38th International Symposium, MFCS 2013, Klosterneuburg, Austria, August 26-30, 2013. Proceedings, edited by Krishnendu Chatterjee and Jirı́ Sgall, 8087:679–90. Lecture Notes in Computer Science. Springer.\n\n\n———. 2019. “On the Parameterized Complexity of Edge-Linked Paths.” In Computer Science - Theory and Applications - 14th International Computer Science Symposium in Russia, CSR 2019, Novosibirsk, Russia, July 1-5, 2019, Proceedings, edited by René van Bevern and Gregory Kucherov, 11532:286–98. Lecture Notes in Computer Science. Springer.\n\n\nMisra, Neeldhara, Geevarghese Philip, Venkatesh Raman, and Saket Saurabh. 2010. “The Effect of Girth on the Kernelization Complexity of Connected Dominating Set.” In IARCS Annual Conference on Foundations of Software Technology and Theoretical Computer Science, FSTTCS 2010, December 15-18, 2010, Chennai, India, edited by Kamal Lodaya and Meena Mahajan, 8:96–107. LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum für Informatik.\n\n\n———. 2011. “On Parameterized Independent Feedback Vertex Set.” In Computing and Combinatorics - 17th Annual International Conference, COCOON 2011, Dallas, TX, USA, August 14-16, 2011. Proceedings, edited by Bin Fu and Ding-Zhu Du, 6842:98–109. Lecture Notes in Computer Science. Springer.\n\n\nMisra, Neeldhara, Geevarghese Philip, Venkatesh Raman, Saket Saurabh, and Somnath Sikdar. 2010. “FPT Algorithms for Connected Feedback Vertex Set.” In WALCOM: Algorithms and Computation, 4th International Workshop, WALCOM 2010, Dhaka, Bangladesh, February 10-12, 2010. Proceedings, edited by Md. Saidur Rahman and Satoshi Fujita, 5942:269–80. Lecture Notes in Computer Science. Springer.\n\n\nMisra, Neeldhara, Venkatesh Raman, Saket Saurabh, and Somnath Sikdar. 2009. “The Budgeted Unique Coverage Problem and Color-Coding.” In Computer Science - Theory and Applications, Fourth International Computer Science Symposium in Russia, CSR 2009, Novosibirsk, Russia, August 18-23, 2009. Proceedings, edited by Anna E. Frid, Andrey Morozov, Andrey Rybalchenko, and Klaus W. Wagner, 5675:310–21. Lecture Notes in Computer Science. Springer.\n\n\nMisra, Neeldhara, and Piyush Rathi. 2019. “The Parameterized Complexity of Dominating Set and Friends Revisited for Structured Graphs.” In Computer Science - Theory and Applications - 14th International Computer Science Symposium in Russia, CSR 2019, Novosibirsk, Russia, July 1-5, 2019, Proceedings, edited by René van Bevern and Gregory Kucherov, 11532:299–310. Lecture Notes in Computer Science. Springer.\n\n\nMisra, Neeldhara, and I. Vinod Reddy. 2017. “The Parameterized Complexity of Happy Colorings.” In Combinatorial Algorithms - 28th International Workshop, IWOCA 2017, Newcastle, NSW, Australia, July 17-21, 2017, Revised Selected Papers, edited by Ljiljana Brankovic, Joe Ryan, and William F. Smyth, 10765:142–53. Lecture Notes in Computer Science. Springer.\n\n\nMisra, Neeldhara, and Aditi Sethia. 2020. “Fair Division Is Hard Even for Amicable Agents.” In Proceedings of the 21st Italian Conference on Theoretical Computer Science, Ischia, Italy, September 14-16, 2020, edited by Gennaro Cordasco, Luisa Gargano, and Adele A. Rescigno, 2756:202–7. CEUR Workshop Proceedings. CEUR-WS.org.\n\n\n———. 2021. “Fair Division Is Hard Even for Amicable Agents.” In SOFSEM 2021: Theory and Practice of Computer Science - 47th International Conference on Current Trends in Theory and Practice of Computer Science, SOFSEM 2021, Bolzano-Bozen, Italy, January 25-29, 2021, Proceedings, edited by Tomás Bures, Riccardo Dondi, Johann Gamper, Giovanna Guerrini, Tomasz Jurdzinski, Claus Pahl, Florian Sikora, and Prudence W. H. Wong, 12607:421–30. Lecture Notes in Computer Science. Springer.\n\n\nMisra, Neeldhara, and Chinmay Sonar. 2019. “Robustness Radius for Chamberlin-Courant on Restricted Domains.” In SOFSEM 2019: Theory and Practice of Computer Science - 45th International Conference on Current Trends in Theory and Practice of Computer Science, Nový Smokovec, Slovakia, January 27-30, 2019, Proceedings, edited by Barbara Catania, Rastislav Královic, Jerzy R. Nawrocki, and Giovanni Pighizzini, 11376:341–53. Lecture Notes in Computer Science. Springer.\n\n\nMisra, Neeldhara, Chinmay Sonar, and P. R. Vaidyanathan. 2017. “On the Complexity of Chamberlin-Courant on Almost Structured Profiles.” In Algorithmic Decision Theory - 5th International Conference, ADT 2017, Luxembourg, Luxembourg, October 25-27, 2017, Proceedings, edited by Jörg Rothe, 10576:124–38. Lecture Notes in Computer Science. Springer.\n\n\nRajgopal, Ninad, Pradeesha Ashok, Sathish Govindarajan, Abhijit Khopkar, and Neeldhara Misra. 2013. “Hitting and Piercing Rectangles Induced by a Point Set.” In Computing and Combinatorics, 19th International Conference, COCOON 2013, Hangzhou, China, June 21-23, 2013. Proceedings, edited by Ding-Zhu Du and Guochuan Zhang, 7936:221–32. Lecture Notes in Computer Science. Springer.\n\n\nRoy, Aniket Basu, Sathish Govindarajan, Neeldhara Misra, and Shreyas Shetty. 2014. “On the d-Runaway Rectangle Escape Problem.” In Proceedings of the 26th Canadian Conference on Computational Geometry, CCCG 2014, Halifax, Nova Scotia, Canada, 2014. Carleton University, Ottawa, Canada.\n\n\nSonar, Chinmay, Palash Dey, and Neeldhara Misra. 2020. “On the Complexity of Winner Verification and Candidate Winner for Multiwinner Voting Rules.” In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020, edited by Christian Bessiere, 89–95. ijcai.org.\n\n\nVaish, Rohit, Neeldhara Misra, Shivani Agarwal, and Avrim Blum. 2016. “On the Computational Hardness of Manipulating Pairwise Voting Rules.” In Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems, Singapore, May 9-13, 2016, edited by Catholijn M. Jonker, Stacy Marsella, John Thangarajah, and Karl Tuyls, 358–67. ACM."
  },
  {
    "objectID": "poems.html",
    "href": "poems.html",
    "title": "Poems",
    "section": "",
    "text": "This page collects a small number of attempts at what I thought was poetry at the time I wrote it. This was done when I was even more of a kid than I am now. You can subscribe to a feed for this series by clicking here, although I don’t expect to add much :)\nI put these up thanks to being in a foolish inspired mood, having read How to Write One Song (c.f a related podcast).\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nLetting Go\n\n\n\n\n\n\n\n\n\nMay 11, 2023\n\n\n0 min\n\n\n\n\n\n\n\n\nDad\n\n\n\n\n\n\n\n\n\nAug 27, 2012\n\n\n0 min\n\n\n\n\n\n\n\n\nOn the Fence\n\n\n\n\n\n\n\n\n\nApr 23, 2012\n\n\n0 min\n\n\n\n\n\n\n\n\nSprinkles of the Sky\n\n\n\n\n\n\n\n\n\nJan 5, 2011\n\n\n0 min\n\n\n\n\n\n\n\n\nSeek\n\n\n\n\n\n\n\n\n\nApr 3, 2007\n\n\n0 min\n\n\n\n\n\n\n\n\nBloom\n\n\n\n\n\n\n\n\n\nFeb 3, 2005\n\n\n0 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materials/cpnotes/index.html",
    "href": "materials/cpnotes/index.html",
    "title": "Competitive Programming",
    "section": "",
    "text": "Lecture notes coming soon!"
  },
  {
    "objectID": "materials/dsanotes/introduction/index.html",
    "href": "materials/dsanotes/introduction/index.html",
    "title": "Data Structures and Structured Data",
    "section": "",
    "text": "Link to Slides"
  },
  {
    "objectID": "materials/dsanotes/introduction/index.html#wdym-data-structures",
    "href": "materials/dsanotes/introduction/index.html#wdym-data-structures",
    "title": "Data Structures and Structured Data",
    "section": "WDYM, data structures?",
    "text": "WDYM, data structures?\nWe will keep it casual and skip formal definitions for now. 👀\nData structures give us principled ways to stow away information. It’s important to do this nicely based on what you want to do with the information.\nFor example, the notes you might be taking in this class is information. If you have no plans of revisiting them later, you can take them as you please, or better yet, not take them at all!\nHowever, you want your notes optimised for giving you quality company during a 2AM revision session on exam day, competing with Maggi for attention, you want your notes to be competently taken: they don’t have to be neat, and it’s enough for them to be useful.\nOn the other hand, if you are taking notes so that a special someone who will inevitably miss a few classes will almost certainly ask for later, then you would be making notes to impress, and that potentially requires a different approach.\n\n\n\n\n\n\nThroughout this course, we will try to make sense of trade-offs.\n\n\n\nWe’ll equip ourselves with ideas that will ultimately help you decide questions like: how do you organise the clothes in your cupboard?\n\n\n\n\n\n\n\n\n\nThrow ’em in, nobody’s looking\nKeep it where you can find it later\n\n\n\n\nTime to process\nNegligible\nForever\n\n\nTime to retrieve\nForever\nNegligible\n\n\n\nTable 1. No free lunches.\n\n\n\n\n\n\n\n\nThis is in fact a useful framing!\n\n\n\n\n\n\n\n\nTable 1 Revisited. No Free Lunches"
  },
  {
    "objectID": "materials/dsanotes/introduction/index.html#representing-polynomials",
    "href": "materials/dsanotes/introduction/index.html#representing-polynomials",
    "title": "Data Structures and Structured Data",
    "section": "Representing Polynomials",
    "text": "Representing Polynomials\nLet’s say that you are spending a fine evening watching the #LockdownMath playlist from 3blue1brown. The first episode happens to be all about solving quadratics:\n\n\n\nA screenshot from #LockdownMath showing Grant Sanderson solving quadratics.\n\n\nNow, it’s quite natural to want to “write a program”, so to speak, that can take a quadratic equation such as x^2 - 7x + 12 as input and output its two roots.\nGiven that programs running on your phone are able to make suggestions, even if dubious, for what series to binge-watch next on Netflix, finding roots of quadratics should be a fairly benign exercise.\nYou might recall that most programs let you declare variables that can hold on to specific types of information, for instance: numbers, strings, and so forth. Our input doesn’t “look” like a number, so it would be a fair take to simply store it as a string:\npx = \"x^2 - 7x + 12\";\n\n\n\n\n\n\nNow…\n\n\n\n\n\n\n\n\n\nWhile this is a perfectly faithful representation, you can imagine that it would be slightly painful to work with. You would have to write some code that can “pull out” the parts of the string that represent the numbers you care about (in this example, b = -7 and c = 12), so that you can move on to your calculation, which is an expression involving numbers.\nGiven that a quadratic with the leading coefficient normalized to one is uniquely determined by two numbers, it seems a lot simpler to directly represent the polynomial as two integers instead:\npx_b = -7\npx_c = 12\nYou might appreciate that this saves us quite some circus and we can quite directly get to the computation we’re interested in. What if you cared about higher order polynomials? You may want to solve them (even if you run out of expressions for solutions pretty quickly, you might be interested in other ways of getting to the roots), or manipulate them in other ways (for example, by adding or multiplying them).\n\n\n\n\n\n\nFood for thought.\n\n\n\nHow would you represent higher-order polynomials? What about multivariate polynomials? Is there a way that you might be able to capture an algebraic expression for a polynomial without either using strings or just the coefficients?"
  },
  {
    "objectID": "materials/dsanotes/introduction/index.html#representing-a-game---i",
    "href": "materials/dsanotes/introduction/index.html#representing-a-game---i",
    "title": "Data Structures and Structured Data",
    "section": "Representing a Game - I",
    "text": "Representing a Game - I\nThe game of 100 goes like this: I pick a number between 1 and 10, and then you pick one within the next ten numbers, and on and on. The first person to reach 100 wins.\n\n\n\n\n\n\nRecall from class and/or figure out that…\n\n\n\n\n\n\n\n\n\n\n\nSPOILER ALERT\n\n\n\n\n\n...whoever starts has a way of winning the game:\n\n    0. To begin with, I say 1.\n    1. No matter what number you pick, I can say 12.\n    2. No matter what number you pick, I can say 23.\n    3. No matter what number you pick, I can say 34.\n    4. No matter what number you pick, I can say 45.\n    5. No matter what number you pick, I can say 56.\n    6. No matter what number you pick, I can say 67.\n    7. No matter what number you pick, I can say 78.\n    8. No matter what number you pick, I can say 89.\n    9. No matter what number you pick, I can say 100.\n\n\n\n\n\n\nWhat if you want to write a program that mimics the winning strategy?\nNote that this game can go on for at most a 100 steps, and in fact exactly 20 steps (or ten rounds) when you employ said winning strategy. So one way to go about this is to declare 20 variables to track the 20 numbers exchanged between the players. But a moment’s reflection may reveal that you don’t need to store anything at all.\n\n\n\n\n\n\nExercise\n\n\n\nCan you write a program that makes the first move, prompts the user for their moves on their turn, uses the winning strategy discussed above, and uses no variables for explicit storage?"
  },
  {
    "objectID": "materials/dsanotes/introduction/index.html#representing-a-game---ii",
    "href": "materials/dsanotes/introduction/index.html#representing-a-game---ii",
    "title": "Data Structures and Structured Data",
    "section": "Representing a Game - II",
    "text": "Representing a Game - II\nIf you missed the first class you haven’t played the Game of Trust, you are welcome to take a break and experience it now. Let’s recollect the setup:\n\n\n\n\n\nIllustration from an implementation by Nicky Case.\n\n\nSuppose you want to implement your own version of this game, where the program responds to inputs from the user and plays according to a specific, pre-meditated strategy. Remember you have seen some strategies already:\n\n\n\n\n\nA second illustration from the same implementation by Nicky Case.\n\n\nWe reproduce these strategies below:\n\n\n\n\n\n\nPlayer Strategies\n\n\n\n\nCOPYCAT: Hello! I start with Cooperate, and afterwards, I just copy whatever you did in the last round. Meow.\nALWAYS CHEAT: The strong shall eat the weak.\nALWAYS COOPERATE: Let’s be best friends <3\nGRUDGER: Listen, pardner. I’ll start cooperatin’, and keep cooperatin’, but if y’all ever cheat me, I’LL CHEAT YOU BACK TIL THE END OF TARNATION.\nDETECTIVE: First: I analyze you. start: Cooperate, Cheat, Cooperate, Cooperate. If you cheat back, I’ll act like Copycat. If you never cheat back, I’ll act like Always Cheat, to exploit you. Elementary, my dear Watson.\n\n\n\nLet’s say that your program is designed to play 5 rounds and that your program is playing the copycat strategy. To begin with, you might want to declare a couple of variables to keep track of the scores of the players, and ten variables to track the moves of both players in each round. With this, your code may start out looking like this:\nmy_points = 0\nuser_points = 0\n\nuser_move_1 = input(\"Input 1 for Cooperate and 0 for Cheat.\")\n\n//Sanity check input:\nif(user_move_1 != 1 and user_move_1 != 0):\n    express disappointment and abort\n// My first move is to cooperate:\nmy_points += -1\nuser_points += 3\n\nif(user_move_1):\n    my_points += 3\n    user_points -= 1\nNow your next move is determined by the value of user_move_1, so you might proceed as follows.\nuser_move_2 = input(\"Input 1 for Cooperate and 0 for Cheat.\")\n\n//Sanity check input:\nif(user_move_2 != 1 and user_move_2 != 0):\n    express disappointment and abort\n// My next move is based on the user's first:\nif(user_move_1):\n    my_points += -1\n    user_points += 3\n\nif(user_move_2):\n    my_points += 3\n    user_points -= 1\n…and so on and on, you get the drift.\n\n\n\n\n\n\nFood for thought.\n\n\n\nDo you really need ten variables to track the game? If you were instead implementing the always cheat or always cooperate strategy, how many variables would you need? What about the strategies of the grudger and the detective?\n\n\nNow, suppose we come up with our own player, whom we call the majority mover. This player looks at your entire game history, and cooperates if you have cooperated more than you have cheated, and cheats if you have cheated more than you have cooperated, and acts randomly otherwise.\nIt seems like implementing the majority mover strategy would really require keeping track of everything. Or would it? You might observe at this point that it’s enough to keep track of two counts: the number of rounds and the number of moves where the user has cheated: note that it does not matter when the cheats happened in the history of the game.\n\n\n\n\n\n\nYou could also…\n\n\n\n\n\n…track the number of cooperate moves along with the number of rounds; or the number of cheat moves and the number of cooperate moves.\nAt this point it’s a matter of taste :)\n\n\n\nHow about a completely random player? This one chooses a number K between 1 and N uniformly at random (let’s not worry about how this is done for now, because that would be a story for another day), where N is the number of rounds played so far; and mimics the other player’s Kth move. To implement this strategy, you really would need to keep track of the user’s entire game history with the five variables, and also assume that you have a way of picking a number at random.\nFinally, consider that instead of fixing your program to play five rounds — 🥱 — you want to politely ask the user how many rounds they want to play.\n\n\n\n\n\n\nAfter all…\n\n\n\n\n\n\n\n\n\nWell, for the first few players, this is just a matter of upgrading your for loop (which you should have switched to already when you realised that you don’t need all. those. variables.) to use N: and you are done.\n\n\n\n\n\n\nFood for thought.\n\n\n\nHow will you implement this version if you are working with our latest player? If you happen to have a very enthusiastic user who asks for half a million rounds, would you be able to declare that many variables all at once, while your program is running? Notably, you don’t know what the user is going to say ahead of time!"
  },
  {
    "objectID": "materials/dsanotes/introduction/index.html#representing-a-subset-of-a-deck-of-cards",
    "href": "materials/dsanotes/introduction/index.html#representing-a-subset-of-a-deck-of-cards",
    "title": "Data Structures and Structured Data",
    "section": "Representing a subset of a deck of cards",
    "text": "Representing a subset of a deck of cards\nIf you are implementing a card1 game, you might need a mechanism for keeping track of “hands”, or various subsets of cards. Let’s say a hand is a subset of cards. For many games, you would need the ability to be able to quickly:\n\ntell if a particular card belongs to a hand or not,\nadd a card to a hand,\nremove a card from a hand, and\nreplace a card in a hand with another one.\n\nOne way to meet these requirements is to declare a collection of 52 boolean (i.e, true/false or 0/1) variables to represent the hand: the cards in the hand are set to true while cards that don’t belong are set to false.\n\n\n\n\n\n\nFood for thought.\n\n\n\nWhat do you like about this method? What don’t you like about it?\n\n\nHere’a another way, though: you could agree on a notation for the cards in the deck: e.g, a standard one is to use a number, A/J/Q/K to denote the value, and S/C/D/H to denote the suit, so every card can be represented as a pair of characters. For example the Ace of Diamonds would be AD, the five of spades would be 5S and the King of Hearts would be KH. With this in place, you could represent a hand also by simply concatenating these string representations of the cards in the hand.\n\n\n\n\n\n\nFood for thought.\n\n\n\nWhat do you like about this method? What don’t you like about it?\n\n\nNow for this toy example, if you were to implement both methods and clock the time taken to implement the four operations above, you may not notice a major difference. However, for actual applications, you may be in a situation where your subsets (here, the “hands”) may be coming from a large universe (here, the “deck”). On the other hand, you may have a very large number of operations to take care of efficiently.\n\n\n\n\n\n\nFood for thought.\n\n\n\nAre there other ways that you might want to store this kind of information, given the things you want to do are as enlisted above?\n\n\nYour choice of method will again be driven by the requirements: the one thing to keep in mind is that you cannot have it all, but we can usually get pretty damn close!"
  },
  {
    "objectID": "materials/dsanotes/23-trees/index.html",
    "href": "materials/dsanotes/23-trees/index.html",
    "title": "Balanced BSTs",
    "section": "",
    "text": "Suppose we want to store a collection of distinct integers (henceforth, we call them keys, for no good reason except that I can refer to them with the 🔑 emoji) with support for:\n\ninsert(x) insert x into the collection if it is not there already\ndelete(x) deleting x from the collection if it is present\nsearch(x) determine if x belongs to the collection\n\nThe motivation for building binary search trees is to capture a happy middle-ground between the following extremes:\n\nif I store my data fully sorted, then it is hard to insert and delete1, but easy to search2, but\nif I store my data in chaos-mode, then it is easy to insert and delete3, but hard to search4.\n\nBinary search trees are the natural answer to the question:\n\nIf binary search was a data structure, what would it look like?\n\nTo achieve O(\\log n) complexity for search and insertion (and deletion), we want a relatively “loose” sense of structure on the data: it should be fluid enough for insertion and deletion to be manageable, but meaningful enough for searches to be fast.\nOne way to do this is to store everything in a binary tree where every node u stores a key k_u with the assurance that:\n\nall nodes that belong to the subtree rooted at the right child of u have keys whose values are greater than k_u;\nall nodes that belong to the subtree rooted at the left child of u have keys whose values are smaller than k_u.\n\nWith this structure in place, search(x) works exactly as you would expect: if the binary search tree is rooted at r, check if x equals k_r: if yes, then we’ve found what we are looking for, so abort and celebrate; on the other hand, if not, then repeat the following until you’ve either found x or have run out of elements in the tree:\n\nif x is greater than k_r, continue searching in the 🌳 rooted at the right child of r\nif x is smaller than k_r, continue searching in the 🌳 rooted at the left child of r\n\nNotice that if you hit a leaf without a match, you can safely conclude that x does not belong to the collection. Also notice that the complexity of search is proportional to the length of the longest root-to-leaf path in the tree5 in the worst case.\nTo insert(x), first search(x): if x is found, there’s nothing to do; if x is not found, then make note of the leaf where the search stopped — say \\ell: then if x is greater than k_\\ell, introduce a right child of \\ell and assign to it the key value x; on the other hand if x is less than k_\\ell, introduce a left child of \\ell and assign to it the key value x. Notice the tree with the newly added node is still a valid binary search tree.\nWhat about delete(x)? If x is not in the collection, there’s nothing to do. If x does belong to the collection and is associated with a leaf node, then the node can simply be knocked out, no further action required. However, what if the node whose key value is x — say v — is an serious one, with a left and a right child? One possibility is to swap x with an appropriate value ascribed to some leaf node, and then knock out the leaf: which now carries the value of x. Which leaf should we swap with? It’s clear that it can’t be just any leaf: but you could pick the smallest value in the right subtree or the largest value in the left subtree — both of these reside and leaves, and the swaps with them would leave you with a valid BST after the deed is done.\nTo find the smallest value in the right subtree, you can take the right turn from v and then go left until you are stuck. If you prefer the largest value in left subtree instead, take the left turn from v and go right until you are stuck. Either of these should work fine. You can find some examples of deletions in a BST here.\nNotice that the complexity of all three operations are proportional to the height of the tree: so if we can control the height, we control the complexity of these operations! Notice also that the height of a BST — if built by implementing the algorithms above — can be as bad as linear in the number of keys6, which is no good. Play around with this visualization of BSTs to get a feel!"
  },
  {
    "objectID": "materials/dsanotes/23-trees/index.html#trees",
    "href": "materials/dsanotes/23-trees/index.html#trees",
    "title": "Balanced BSTs",
    "section": "(2,3) Trees",
    "text": "(2,3) Trees\nOne way of controlling the height of a BST is to simply demand it: this is called solving a problem by definition :) What if we could insist on having BSTs where the underlying tree structure must have the following additional property:\n\n\nall nodes have either 0 or two children\nall leaves are at the same distance from the root.\n\n\nThis would automatically force the structure of the underlying tree to be complete i.e, if the tree has height h, any node whose distance from the root is less than h must be a branching node (indeed, if not, then it is a leaf by property (1), but then we will have a violation of property (2)). Why is this great? Because if you have n nodes packed into a complete tree of height h, then the height must, in fact, be O(\\log n) — which is what we wanted.\nThere is, however, a small catch with this: such trees may not exist for some values of n, the total number of keys that we are trying to accommodate :( We can fix this in two ways: add some dummy keys with values that either duplicate existing values till we have a feasible number of keys to work with (ugh), or make room for multi-ary search trees (cool!).\nSince we want the elegant approach, let’s push our definition further:\n\n\nall nodes have either 0, two, or three children\nnodes that have two children store one key value and satisfy the standard BST property\nnodes with three children store two key values, say a and b; and further:\n\n\nthe subtree rooted at the left-most child only hosts values smaller than a\nthe subtree rooted at the right-most child only hosts values larger than b\nthe subtree rooted at the middle child only hosts values strictly between a and b\n\n\nall leaves are at the same distance from the root.\n\n\nAdapting search(x) to multi-ary trees is extremely natural.\nIf the tree is rooted at r and r is a node with two children, proceed as before.\nOtherwise, suppose r hosts the values a_r and b_r. Then check if x equals either a_r or b_r: if yes, then we’ve found what we are looking for, so abort and celebrate; on the other hand, if not, then repeat the following until you’ve either found x or have run out of elements in the tree:\n\nif x is greater than b_r, continue searching in the 🌳 rooted at the right-most child of r\nif x is smaller than a_r, continue searching in the 🌳 rooted at the left-mostt child of r\notherwise, continue searching in the 🌳 rooted at the middle child of r\n\nWhat about insert(x)? We search for x as before. If found, there’s nothing to be done. If not, there are two scenarios:\n\nThe search terminates at a leaf that has one key value.\nThe search terminates at a leaf that has two key values.\n\n Note that unlike before, we cannot just have the leaf sprout a child to accommodate the new key value (remember that all leaves have to be at the same distance from the root). So our algorithm pushes upwards, and works as follows:\n\nIf there’s room in the current node (i.e, the node is one with two children or a leaf with one key value), accommodate the new value into that node, reorganizing as necessary. In particular, when a node with two children + one value transforms into one with three children + two values, then the subtrees have to be appropriately reorganized.\nIf there’s no room in the current node, then move up to the parent. If there’s no parent: then you’ve hit the root! If the root turns out to be crowded too, then you’ll have to split the root (note that this causes the height of the tree to increase, but does not happen too often), but if the root has room then follow the procedure in the previous step.\n\n\n\n\n\n\n\nPractice!\n\n\n\nWork through some examples in this (2,3)-tree visualizer and go through the questions here to validate your understanding of the structure of (2,3)-trees."
  },
  {
    "objectID": "materials/dsanotes/debruijn/index.html",
    "href": "materials/dsanotes/debruijn/index.html",
    "title": "On Cards and Graphs",
    "section": "",
    "text": "Link to slides\nLink to a Tweet thread summarizing these notes\nBefore we talk about exploring graphs, we will take a small detour to throw in some motivation. In our discussion here we will establish that knowing how to go around a graph can meaningfully help us pull off a spectacular card trick. I trust that this should leave us sufficiently interested in finding out how we can actually find those Euler tours, which is our next stop.\n\n\n\nA deck with 32 cards is given to someone in the audience.\nAny number of cut shuffles1 are done.\nOnce the audience is satisfied that the deck is suitably shuffled, it is passed to someone, say P, from where the following happens:\nP takes the top card and passes the deck to the next person (Q).\nQ takes the top card and passes the deck to the next person (R).\nR takes the top card and passes the deck to the next person (S).\nS takes the top card and passes the deck to the next person (T).\nAll five people look at their cards without revealing them to anyone else.\nThose who got red cards are requested to stand up.\nAll cards are identified.\n\n\n\n\nInterpreting reds as 1’s and blacks as 0’s, any sequence of five cards is a signal: a bitstring of length 5. This is — at least in principle — enough to ID one of the cards in a 32-card deck, for sure. But to ID the next five cards too? Wow!\nSo to begin with, let’s just focus on ID-ing card. The deck, of course, is setup: the cards appear in a specific order, one whose relevant properties are unperturbed by cut shuffles. Note that we have no control over how many times the deck is cut, so the top card could be effectively anywhere in from the original sequence. So what we need is a sequence of 32 bits:\nb_0, b_1, \\ldots, b_i, \\ldots, b_{31}\nwith the following property. For any i \\in \\{0,\\ldots,31\\}, if B_i denotes2 the substring:\nb_{i}, b_{i+1}, b_{i+2}, b_{i+3}, b_{i+4},\nthen we would very much like that b_i \\neq b_j whenever i \\neq j. This ensures that no matter how many times the deck is cut, when the members of the audience with the red cards stand up, we have a clean and unambiguous signal, which we can pre-relate by our powers of rote memory to the card at position i in said sequence. Because subscripts are read mod 32, note that this is really all we need. For example, here’s a seuquence that does happen to have the property we are after:\n\n00000100101100111110001101110101\n\nThe diagram below shows why cut shuffles still result in sequences where the signal from any location continues to be unique, and in some sense, invariant across shuffles: suppose a position x corresponds to a certain signal S_x before a cut shuffle, then after a cut shuffle, if position x shifts to y, then S_y = S_x. Note that this would not be true if someone, say, enthusiastically riffle shuffled the pack — so do make sure to prevent this at all cost.\n\n\n\nExamples of cut shuffles and why they don’t affect the addressing technique. The first column shows the original sequence, the second shows the proposed cut, and the last shows the final sequence after the cut shuffle is excecuted.\n\n\nThis property makes the sequence a robust device for card discovery: we simply associate a specific card with every 5-length bit string, and position the card corresponding to b_i at location i. By knowing the signature corresponding to the top five cards after any number of cut shuffles, you know where this signal appeared in the original sequence, and by turdging further along in the sequence, you also know the signals for the next five cards.\n\n\n\n\n\n\nYou perhaps see now how you can perform the entire trick:\n\n\n\n\nmemorize the sequence 00000100101100111110001101110101\nassociate† a card with each bit-string of length 5\nmemorize said association\nplace cards as dictated by the sequence and given by the association\nprofit and/or impress\n\n† Note that the association has to respect the semantics of the bitstring: so the 1-positions get red cards and the 0-positions get black (or the other way round if you please, so long as you are consistent in your conventions throughout).\n\n\nNotice that once you can read off one card, having committed the seuqence and the association to memory, you can also read off any of the cards after that. This does seem like a lot of memorizing, but it’s worth it for the impact.\n\n\n\nIf you want to make your life easier, you could use an association that is easy to remember:\n\n\n\nA useful dictionary between 5-bit strings and cards from a standard deck of cards\n\n\nSo getting to the first card is quite straightforward already:\n\nIf the first person is seated, they have a black card, and otherwise they have a red card. But this is immediate anyway from the convention, so not particularly impressive to point out.\n\nWhen the card is black: if the second person is seated, it is a ♣, otherwise a ♠.\nWhen the card is red: if the second person is seated, it is a ⬥, otherwise a ♥.\n\nFinally, the value of the card is just translating the last three bits to their value in decimal (remembering to map all zeroes to eight).\n\nIf you want to really impress with the next four, you could just memorize the whole sequence, but to avoid visible murmuring, you can also exploit a handy feature of this particular sequence that helps you navigate it with only a little bit of mental math.\nIt turns out that if you know b_i (which you do based on who stands up), you can obtain the next bit (i.e, the sixth bit relative to the start of b_i) in the sequence by simply adding the first and third bits from b_i. In other words, the sequence has the following nice pattern: standing anywhere, you can obtain the next bit by taking the sum (mod 2) of the bits that are three and five bits behind wherever you are standing. Go on, verify this for yourself!3\n\n\n\nSo how does this lovely self-working card-trick fit, even if as a detour, into our discussion about graphs?\nLet’s step back for a bit. We pulled out the driver of this whole setup, the sequence:\n\n00000100101100111110001101110101\n\nmuch like a real magician pulls out a real rabbit from a real hat. You very likely raised an eyebrow and wondered about where this sequence came from. It’s a useful exercise to experiment with coming up with one, even if by means of ad-hoc scribbling. As a warmup, it’s worth trying to find one of length eight, where every 3-bit string occurs exactly once4.\nIt turns out that such sequences are in fact rather well-studied, and one way of generating them involves taking a walk in an appropriate graph! In particular, let us go back to our original task of generating a 32-bit sequence like the one shown above, except that we are on our own this time. Consider a graph where we have:\n\na vertex for every bit string of length four, and let us say that the bit string associated with a vertex u is denoted by b_u; and\nan edge from u to v if the corresponding bit strings are all but the same: i.e, the 3-length suffix of u is the same as the 3-length prefix of v.\n\n\n\n\n\n\n\nIf you want to take a look at the graph, it’s right here…\n\n\n\n\n\n…although a bit of a monstrosity!\n\n\n\nThe de Bruijn graph of order 4\n\n\n\n\n\nThe following properties are worth thinking about:\n\n\n\n\n\n\nthe total number of vertices is _____\n\n\n\n\n\nOne for every bit string of length four, so sixteen.\n\n\n\n\n\n\n\n\n\nevery vertex has indegree and outdegree _____\n\n\n\n\n\nFix a vertex v and let s_v denote the last three bits of v. The only outgoing edges are to vertices that represent the bit strings s_v0 and s_v1.\nFix a vertex v and let p_v denote the first three bits of v. The only incoming edges are from vertices that represent the bit strings 0p_v and 1p_v.\n\n\n\n\n\n\n\n\n\nthe total number of edges is _____\n\n\n\n\n\nThere are sixteen vertices and each of them has outdegree two, so the total number of edges is 32. Does that ring a bell yet?\n\n\n\n\n\n\n\n\n\nthere are exactly _____ self-loops\n\n\n\n\n\nConsider a vertex v. Let the bit string associated with v be denoted by WXYZ. For v to be adjacent to itself, we will need XYZ = WXY, which implies that W = X, X = Y, Y = Z.\nSo if W = 1, then we have that WXYZ = 1111 and if W = 0 then we have WXYZ = 0000.\nThese are the only two possible scenarios, so our graph has exactly two self-loops.\n\n\n\nIf you were to take an Euler tour in this graph, i.e, walk around visiting every edge exactly once, then it very naturally spells out a sequence as follows. Start with an empty string. Now as you move around, going from the vertex u to v along the edge (u,v) amounts to essentially “seeing one new bit”: recall that the suffix of u almost fully eats up the prefix of v, leaving one new bit to observe, which is what we tag on to our sequence. Once you have traveled along every edge exactly once, you’ve collected exactly 32 bits, so we have written out a sequence of length 32 by the time we are done5.\nNow: our somewhat outrageous claim is that this infact is a valid de Bruijn sequence! Given that we have written out exactly 32 bits, it is enough to show that any bit sequence of length 5 shows up as a substring in this sequence starting from some position. The main intuition here is the following: suppose you want to “see” the bitstring PQRST in your sequence. Well, at some point in our walk on the graph, we moved from the vertex representing PQRS to the one representing QRST6. This made us add T to whatever sequence we had so far. Let’s rewind our walk a bit and see what happened in the last few steps too:\nLMNO → MNOP → NOPQ → OPQR → PQRS → QRST\nRetracing our steps, here are the bits that would have been triggered by this walk: PQRST, and thus we are almost done. You might say: perhaps the edge from the vertex representing PQRS to the one representing QRST was taken very early on, at the start of the tour, so we don’t have these many steps to retrace: but here’s the thing — we are on a tour, so you can continue walking back past your starting point and the sequence would still have this overall form: it’s just that a few of those bits would be written at the end, rather than at the start, and that just means that we can find our substring wrapped around the end, which is a perfectly valid place to discover it.\nNotice that there was nothing special about this whole process and the numbers four and five: you can generate so-called “de Bruijn sequences of order k”, which are bitstrings of length 2^k with the property that every k-bit string appears exactly once in the sequence as a substring (including wraparoudns), using exactly the same idea.\nSo you should be convinced by now — perhaps after reflecting for a moment or two — that de Bruijn sequences of any order in fact exist, which is not obvious at all from the definition. It turns out that there are actually quite a few of them: 2^{2^{k-1}-k}, to be precise, a formula we know thanks to de Bruijn, after whom the sequences are named.\nYou might wonder if there are other ways of coming up with these sequences, or possibly even enumerating them. These discussions are unfortunately out of scope, but there are several excellent resources for the curious. Much of these notes are based on the third chapter of the book Magical Mathematics: The Mathematical Ideas That Animate Great Magic Tricks which is a treasure of a book. Paraphrasing from this chapter, here is a little about the people behind this trick:\n\nThe origins of this trick go back to Charles T. Jordan in 1919, and the original version required a color pattern of length 6 to identify all the cards. Later William Larson and T. Page Wright came up with another variant involving 52 cards, and 3 people revealing the suits being enough for the magician to pick up the values. In the 1960s, Karl Fulves and, separately, P. Diaconis working with the chemist Ronald Wohl, derived dozens of tricks based on variations and extensions of Jordan’s idea."
  },
  {
    "objectID": "materials/dsanotes/stable-matchings/index.html",
    "href": "materials/dsanotes/stable-matchings/index.html",
    "title": "Stable Matchings",
    "section": "",
    "text": "The Problem\nThe problem of pairing up people and/or resources shows up a lot:\n\nMatching students who graduate high school to seats in various colleges.\nMatching students who graduate college to employers for jobs, internships, residencies, and so on.\nGetting actors and actresses to commit to work together for films amidst various constraints.\nMatching organ donors to patients accounting for constraints of compatibility and timing.\nMatching men and women in a dating/marriage market.\n\nWe are going to look at one particular abstraction that captures many of the scenarios above (among others). Suppose we have a set V = \\{m_1, \\ldots, m_n\\} of n men and W = \\{w_1, \\ldots, w_n\\} of n women, where each man (respectively, woman) has a strict and complete ranking over the women (respectively, men). Our goal is to find a matching between the men and the women, which is to say, a bijection between V and W.\nNow, a natural question at this point is: what kind of matchings do we want to find? Unconstrained, there are plenty of matchings that we can choose from. Which one is the “best”?\nUpon a moment’s reflection you might come up with several ideas. We are going to focus on a fundamental game-theoretic approach to identifying what we desire from the matchings we seek. What we will demand of the matching M that we seek is that there is no man and woman who are unmatched in M who prefer each other over their matched partners. To this end, we first define the notion of a blocking pair with respect to M:\n\n\n\n\n\n\nBlocking Pair\n\n\n\nGiven a matching M between n men and n women, if a \\in V and b \\in W, then (a,b) forms a blocking pair if ALL of the following hold:\n\na and b are not matched to each other in M,\na prefers b over M(a),\nb prefers a over M(b)\n\n\n\nThe presence of a blocking pair (a,b) implies that the matching M is unlikely to “sustain”: a and b both have an incentive to break off the alliances suggested by the matching M and “elope” with each other instead. Thus, matchings that have blocking pairs are called unstable.\n\n\n\n\n\n\nUnstable Matching\n\n\n\nA matching M is said to be unstable if there is a blocking pair with respect to M.\n\n\n\n\n\n\n\n\nAn Example of a Matching with no blocking pairs.\n\n\n\n\n\nConsider the preferences given below (where the first column in each row is the ID of the men and the women, and the remaining columns indicate the rank):\n\n\n\nMen\n1\n2\n3\n4\n\n\n\n\n1\n2\n4\n1\n3\n\n\n2\n3\n1\n4\n2\n\n\n3\n2\n3\n1\n4\n\n\n4\n4\n1\n3\n2\n\n\n\n\n\n\nWomen\n1\n2\n3\n4\n\n\n\n\n1\n2\n1\n4\n3\n\n\n2\n4\n3\n1\n2\n\n\n3\n1\n4\n3\n2\n\n\n4\n2\n1\n4\n3\n\n\n\nand the matching given by: M = (1,4), (2,3), (3,2), (4,1). Notice that this matching has, in fact, no blocking pairs.\n\n\n\n\n\n\n\n\n\nHow many blocking pairs can we have?\n\n\n\nCome up with a stable matching instance that has \\Omega(n^2) blocking pairs. What’s the maximum number possible?\n\n\nA matching without blocking pairs is called stable.\n\n\n\n\n\n\nStable Matching\n\n\n\nA matching M is said to be stable if there are no blocking pairs with respect to M.\n\n\nIt’s easy to verify if a given matching M is stable: for all men m we look up all women w that m ranks higher than M(m), and check if w also ranks m higher than M(w): if yes, then we can declare M unstable since (m,w) is a blocking pair. If we find no blocking pairs after having checked all men m, then we can declare that M is stable.\nThis takes at most O(n^2) time, assuming that ranks can be retrieved in constant time. Thus we have the following.\n\n\n\n\n\n\nVerifying that a matching is stable.\n\n\n\nGiven a matching M between n men and n women and their preferences over each other, it is possible to verify if M is stable in O(n^2) time.\n\n\nThe next natural questions are:\n\nDo stable matchings always exist?\n\nIf yes: can we always find them efficiently?\nIf not: can we efficiently find matchings that minimize the number of blocking pairs?\n\n\nThis is a good place to pause and ponder!\n\n\nDeveloping a Solution\nIt turns out that (somewhat surprisingly!) stable matchings indeed always exist!\nThe algorithm for finding a stable matching works as follows. To begin with, we say that all men and women are single, i.e, unmatched to anyone so far.\nAnticipating our need for stability, we take a greedy approach: the men attempt to match up to their best option by proposing to them. But notice that this may not be immediately workable: possibly multiple men have the same choice for their top option. This puts the ball in the woman’s court, so to speak, and again in the interest of being eventually stable, it’s intuitive that the woman will choose to align with the best offer she has among the proposals she’s recieved.\nAlso, since we finally want everyone to be matched, we will also ensure that proposals are not rejected simply because they seem unattractive in absolute terms: if a woman who’s single recieves one or more proposals, she will accept the best among them, no matter how good or bad they are.\nAfter one round of proposals, the situation is as follows:\n\nsome women (say W_\\star \\subseteq W) recieved one or more proposals and picked the best offer, and are no longer single;\nsome women (say W_0 = W \\setminus W_\\star) recieved no proposals and are still single;\nsome men (say V_\\star \\subseteq V) had their proposals accepted and they are no longer single ;\nsome men (say V_0 = V \\setminus V_\\star) were turned down and are still single.\n\nIf W_0 = \\emptyset, that’s… well, that’s awesome, because what that means is all men had distinct choices for their top preference, and so V_0 = \\emptyset as well and we already have a matching where everyone has their best possible match: so this is clearly very stable and we are done.\nOn the other hand, it’s possible that W_0 \\neq \\emptyset, which is to say that some women are still single, and therefore there are some single men as well. Now, to make progress, single men go back to the drawing board and propose again. Now, a natural question at this point is the following:\n\nShould the currently single men try their luck again with women who’ve rejected them?\n\nWell, since they were rejected for good reason (said women had better offers), and the reason has not gone away, it is clearly a waste of time for men to go back to women who’ve rejected them. So what they do instead is to propose to the next best option. Now: what if their next best option is not a single woman? Well, suppose m decides to not approach w because w is matched to some m^\\star in the first round. Then m will eventually be matched to someone who’s worse than w, and if w happened to prefer m over m^\\star, then (m,w) will eventually be a blocking pair.\nHowever, recall that this is exactly the situation we want to avoid. So we’re going to have m propose to their next best option irrespective of whether they are single or not. From the woman’s perspective, they are going to recieve proposals again, and we’ll let them pick the best offer, even if it means breaking off their current engagement.\nAfter this second round of proposals we again have some single men and women, and some engagements. Note that the following invariant is true:\n\nAny woman who was not single at the end of the first round remains engaged at the end of the second round as well.\n\nMen, on the other hand, may become single again. At this point, we simply continue as before: at the end of every round, the single men continue to propose to their current best option, and the women continue to accept the best offer that they have. We continue this until there are no single men left.\n\n\nThe Algorithm and its Properties\nHere’s pseudocode (borrowed from Wikipedia) summarizing the algorithm, which is due to Gale and Shapley. The version below is morally equivalent to our description above, except that all proposals happen one by one, and it turns out that this way of looking at it simplifies the analysis.\nalgorithm stable_matching is\n    Initialize m ∈ M and w ∈ W to free\n    while ∃ free man m who has a woman w to propose to do\n        w := first woman on m's list to whom m has not yet proposed\n        if ∃ some pair (m', w) then\n            if w prefers m to m' then\n                m' becomes free\n                (m, w) become engaged\n            end if\n        else\n            (m, w) become engaged\n        end if\n    repeat\nIt turns out that this procedure:\n\nterminates in finite time (in fact, after O(n^2) proposals have been made)\noutputs a perfect matching M between the men and the women that has no blocking pairs.\n\nThe first property follows from the fact that men never propose twice to the same woman, so the number of proposals made is \\leqslant n^2 . Also note that no man m is rejected by all women: this can only happen if all the women have found better engagements (which are necessarily distinct — notice that the set of engagments at any stage of the algorithm always forms a valid matching), but there are only n-1 men other than w: so this is not feasible.\nSo we know that the while loop terminates, and that once it does we have a matching M.\nIt remains to show that M is stable. But if M has a blocking pair (m,w), then w was proposed to by m before m proposed to M(w), and since (m,w) are not matched in M, it must be the case that w prefers M(w) over m, so (m,w) cannot be a blocking pair after all.\nThis brings us to the following claim:\n\n\n\n\n\n\nFinding a stable matching\n\n\n\nGiven a matching M between n men and n women and their preferences over each other, it is possible to find a stable matching M in O(n^3) time.\n\n\nThe output of the Gale-Shapley algorithm has a couple of interesting properties. First off, it turns out that the output is not just stable, but also qualitatively very good. Let us define, for a man m, their optimal match as the best woman that m can be matched to in any stable matching. It turns out that M matches all men to their optimal matches!\n\n\n\n\n\n\nThe Men Are Lucky\n\n\n\nLet M be the output of the GS algorithm. For all men m, there is no stable matching M^\\star where m prefers M^\\star(m) over M(m).\n\n\nAlso, the output of GS is weakly Pareto optimal, which is to say that there is no matching (stable or otherwise), where all the men are better off.\n\n\n\n\n\n\nThe GS matching is weakly PO\n\n\n\nLet M be the output of the GS algorithm. There is no matching M^\\star for which it is true that all men m prefer M^\\star(m) over M(m).\n\n\nWe state these claims above without proof. The interested reader should look them up!\n\n\nReferences\nNumberphile video about the algorithm\nNumberphile video about the proof\nNotes on implementation details"
  },
  {
    "objectID": "materials/dsanotes/stable-matchings/index.html#references",
    "href": "materials/dsanotes/stable-matchings/index.html#references",
    "title": "Stable Matchings",
    "section": "References",
    "text": "References\nNumberphile video about the algorithm\nNumberphile video about the proof\nNotes on implementation details"
  },
  {
    "objectID": "materials/dsanotes/index.html",
    "href": "materials/dsanotes/index.html",
    "title": "Data Structures and Algorithms",
    "section": "",
    "text": "Lecture Notes\n\n\non Data Structures and Algorithms\n\n\n \n\nThese are running notes on selected topics in Data Structures and Algorithms.\nI have been developing these as a part of my course on Data Structures and Algorithms at IIT Gandhinagar. Please see the course website for additional materials (e.g, problems and programming challenges).\nAt the time of this writing these notes are largely raw and informal. They certainly do not substitute — but hopefully do supplement — an actual textbook :)\nIf you have any general comments or questions, please leave them below. Thanks!"
  },
  {
    "objectID": "materials/dsanotes/sequences/index.html",
    "href": "materials/dsanotes/sequences/index.html",
    "title": "Representing Sequences",
    "section": "",
    "text": "Link to Slides\nSo far, we have worked with atomic types, which is to say variables that can hold a “single kind of data” for us — like integers, characters, strings, booleans, and so on. Often, however, we need to work with compound types, which is to say, a bunch of these things taken together. For example, you may have sensed that when we spoke of maintaining a set of cards earlier with 52 booleans, it may have been nicer if they could be strung together into a single, unified structure: for one, it saves you having to keep track of a large number of variables, and further, it might be easier — as we will find out — to manipulate the data in response to operations that we may want to support.\nWhen you speak of a bunch of objects, it is useful to agree on whether you interpret the collection as an ordered or unordered set. Consider the following examples:\n\nYour playlist of happy songs\nA stack of cards\nPeople living in a house\nTeams that played in the Asia Cup 2022\nChess pieces on a board mid-game\nPreferences of men and women in the stable marriage problem\nList of marks obtained in all the assessments of a course\n\nWhile some people play their happy songs in shuffle mode, for some the playlist is carefully organized, and the order matters. A stack of cards and chess pieces on a board are clearly collections with a natural sense of order, and one that is very likely to be important. On the other hand, people who live in a particular house or the set of teams that participated in the Asia cup in 2022 can be thought of as sets with no underlying order: of course, if you had to impose one you could cook something up1 (e.g, alphabetical, favorites, and so on). We will focus on storing ordered lists for now and return to sets in due course.\nThere are a few different ways that you can store a list of things in a computer’s memory. Imagine that you are real estate agent and you want to book some houses in a complex for your current and future clients. Stretching your imagination a little bit further, say all houses are numbered from 1 to 1000 and are positioned on a straight line in the natural order (i.e, 2 after 1, 3 after 2, and so on). Some houses are occupied and others are not. If you reserve k houses, management will find some contiguous block of k unoccupied houses and give you the number of the first house in the block. For instance, if you ask for 50 houses, you would get a letter from the management saying 50 houses starting from #420 are yours. If you need 20 more houses later, you would get a letter from the management saying 70 houses starting from #777 are yours. That’s right: they are not obiligied to give you houses #470 to #489, indeed, these may not be avaiailable. They could just give you an additional chunk of 20 houses somewhere else, but sadly that’s not how they roll: them management, them rules. There are also no refunds: you can’t give back reserved houses.\nNow here comes our first dilemma: how many houses do we reserve? Say we have 20 clients: it is clear that we need to reserve at least 20 houses, but should we reserve a few more? Reservations are not free, so we don’t want to reserve a very large number of houses either: remember, there are no refunds. But on the other hand, if we reserve too few, and we end up with more clients than the number of houses we’ve reserved, we will be in a sticky situation — worst case some clients may have to move, which is not ideal. You will have to work on coming up with a reasonable estimate of how many clients you will eventually have, and hope for the best.\n\n\n\nExpanding your reservations can get tricky\n\n\nOver time you find that this business of estimating the number of clients you have is an unpleasant one: both under and overestimates lead to losses, which makes you wonder if there are apartments that have more flexible options. You look around, and why yes, you find a different apartment complex — again a thousand houses on a line neatly numbered 1 to 1000 from left to right, but this time, management reserves one house at a time. You want a new house, you simply ask for one. But there’s a catch: the paperwork here requires you to submit the client’s information, and they directly get their house number. So this is actually quite efficient: the management does all the work and you can reserve exactly what you need. All is well until it’s time for Diwali and you realize you don’t know where your clients are housed, and you can’t send them postcards, sweets, and advertisements.\nYou could, of course, just call your clients and ask them for their house numbers, but then this requires you to maintain some kind of register, and let us just say that you are not good with that kind of thing. So here’s what you do instead: you only keep the first client’s address, because that’s just one thing that’s easy to remember. Then you ask your i-th client to remember the address of the (i+1)-th client: they are slightly bewildered but you tell them it’s for insurance. Now if you want to pay a visit to your \\ell-th client, you just start from your first one, and follow the trail. Peculiar, but works.\n\n\n\nWalking around to find your clients with new management.\n\n\nNote that with the previous maangement this was never a problem: you had a contiguous block of houses that you allocated sequentially, so your i-th client’s house address was always at hand if you were good with arithmetic or had a calculator: simply add (i-1) to the house number of the first client.\nAs analogies go this was both unrealistic and imprefect, but I hope it gives you a sense of the main trade-offs involved in the two ways we have to store sequential data — very roughly speaking:\n\nin contiguous blocks, access is easy, flexibility is hard;\nwith elements all over the place, access is indirect but the structure is relatively flexible.\n\n\n\nQuoting Wikipedia:\n\nAn array is a data structure consisting of a collection of elements (values or variables), each identified by at least one array index or key. An array is stored such that the position of each element can be computed from its index tuple by a mathematical formula.\n\n\nFor example, an array of 10 32-bit (4-byte) integer variables, with indices 0 through 9, may be stored as 10 words at memory addresses 2000, 2004, 2008, …, 2036, (in hexadecimal: 0x7D0, 0x7D4, 0x7D8, …, 0x7F4) so that the element with index i has the address 2000 + (i × 4).\n\nArrays are usually static, which is to say that their sizes are fixed upfront:\n\nAs an example consider the C declaration int anArrayName[10]; which declares a one-dimensional array of ten integers. Here, the array can store ten elements of type int . This array has indices starting from zero through nine. For example, the expressions anArrayName[0] and anArrayName[9] are the first and last elements respectively.\n\nNow if you decide to add an eleventh element to anArrayName, the default situation is that you have an array overflow and the operation is not permitted. However, you could work around this by copying everything in anArrayName to a new array of larger size: this is going to be expensive, but it allows you to expand the size as you go along.\n\n\n\nQuoting Wikipedia:\n\nA linked list is a linear collection of data elements whose order is not given by their physical placement in memory. Instead, each element points to the next. It is a data structure consisting of a collection of nodes which together represent a sequence. In its most basic form, each node contains: data, and a reference (in other words, a link) to the next node in the sequence. This structure allows for efficient insertion or removal of elements from any position in the sequence during iteration.\n\n\nMore complex variants add additional links, allowing more efficient insertion or removal of nodes at arbitrary positions. A drawback of linked lists is that access time is linear (and difficult to pipeline). Faster access, such as random access, is not feasible. Arrays have better cache locality compared to linked lists.\n\n\n\n\nGiven a fully occupied array with n elements v/s a linked list with n elements, here are the costs of some operations that you might want to perform:\n\n\n\n\n\n\n\n\nOperations\nArrays\nSingly Linked List\n\n\n\n\nLooking up the i-th element\ninstant\n\\approx i\n\n\nAdding a new element at the start\n\\approx n2\ninstant\n\n\nAdding a new element at the end\n\\approx n3\ninstant4\n\n\nAdding a new element at the i-th location\n\\approx n\n\\approx min(i,n-i)5\n\n\nRemoving the i-th element\n\\approx n-i\n\\approx min(i,n-i)6\n\n\n\n\n\n\nIn a bid to get the best of both worlds, one often resorts to dynamic arrays — which are resizable arrays that have an average constant expense of insertion and instant lookups always. The way this works is the following: start out with a modest-sized array with room for k elements7, and whenever you overflow, you book a new array which is double the size of the original, which buys you free insert operations for another n steps, where n is the current array size. This way, you can think of every copy operation as “paying forward” for an insert operation, and since the total number of insertions is n, the total number of operations overall is at most 2n, amounting to a total cost that is constant per insertion (by averaging). This is called an amortized analysis. Every insertion is one of two kinds:\n\nlucky: an operation that costs one unit of time, because the array has free space;\nunlucky: an operation that costs n+1 units of time, because the array has overflown and we need to copy n elements before we can perform the insert.\n\nNote that the unlucky operations are few and far between: if we have an unlucky operation of cost n+1, then the next n inserts are going to be lucky. So while the worst-case insertion time can be as bad as the size of the array, the average time is, in fact, constant.\nNote that deleting arbitrary elements remains expensive, we have to clean up the empty spaces created by the deletions.\n\n\n\nThe correct answer is: it depends. If you expect your lists to be heavily manipulated, then linked lists are likely to be the better choice. On the other hand, if yuo are working with a list of a predictable size (or you at least have a known and reasonable upper bound on the size), and direct access is important to you, then arrays are the way to go. If you are dissatisfied with both methods, then consider transforming your unhappiness into motivation for discovering more sophisticated options!"
  },
  {
    "objectID": "materials/dsanotes/graphs/index.html",
    "href": "materials/dsanotes/graphs/index.html",
    "title": "Representing Graphs",
    "section": "",
    "text": "At some point of time in your life, you have likely been challenged to draw a kite-like figure:\n\n\n\nA common drawing challenge.\n\n\nwithout ever lifting your pencil/pen/quill off the paper. You may have noticed that there are figures that are particularly elusive to this persistent style of drawing, while others are pleasingly possible to draw in this fashion.\n\n\n\n\n\n\n(Spoiler) Beth Thomas demonstrating what drawing challenges are doable\n\n\n\n\n\n\n\n\n\n\nThe city of Königsberg in Prussia (now Kaliningrad, Russia) was set on both sides of the Pregel River, and included two large islands—Kneiphof and Lomse—which were connected to each other, and to the two mainland portions of the city, by seven bridges.\n\n\n\n\n\n\nThe Problem\n\n\n\nDevise a walk through the city that would cross each of those bridges once and only once. Try this yourself on a few different maps at Mathigon!\n\n\n\n\n\nKonigsberg Classic: Map of Königsberg in Euler’s time showing the actual layout of the seven bridges, highlighting the river Pregel and the bridges. Image by Bogdan Giuşcă, in the public domain (CC BY-SA 3.0) and sourced from Wikipedia.\n\n\n\n\n\n\n\n\n(Spoiler) Numberphile commentary on the bridges of Königsberg\n\n\n\n\n\n\n\n\n\n\nThe question was addressed and answered by Euler (1736). He did not solve this by “messing around” with all possible ways of walking around the city and checking if any of the walks satisfied the desired criteria. His more systematic approach involved modeling the problem abstractly, and making some key observations that ultimately led to the solution — not just for this problem, but for all problems with a similar framing!\n\n\n\n\n\n\nClassroom Activity with Eulerian Paths\n\n\n\nThe picture below shows a few popular actors, with edges connecting pairs of those who have worked together in a movie together1. The example is designed so that there are exactly two actors who participate in an odd number of pairings.\nWe can work through the “bridges puzzle” on this graph. In the classroom, we all started with the vertex representing Juhi Chawla, “walked around” using every connection exactly once, and the fun effect is that everyone ends up at the vertex representing Rishi Kapoor (or solves the puzzle incorrectly). From here, you can probably begin to guess the role of the two special vertices in the puzzle.\n\n\n\nAn actor collaboration graph\n\n\nThis activity is an adaptation of the example from the Intro to Algorithms course at Udacity, where it appears in the first chapter with the title “A Social Network Magic Trick”.\n\n\nHere’s another similar-sounding and classic problem involving a chessboard, also posed to Euler:\n\n“I found myself one day in a company where, on the occasion of a game of chess, someone proposed this question: To move with a knight through all the squares of a chess board, without ever moving two times to the same square, and beginning with a given square.”\n\nThe origins of this problem — the so-called “Knight’s Tour” — goes all the way back to the 9th century AD, where it is described in Rudraṭa’s Kavyalankara. Here’s an example of a knight’s tour, as seen on Wikipedia:\n\n\n\nAn animated example of a knight’s tour.\n\n\nAlthough deceptively similar to the problem of the bridges, this is a different problem with two important contrasts:\n\nwe were previously not allowed to reuse bridges, here we are not allowed to reuse squares, and\nwe were previously obliged to use every bridge, here we are not required to make every possible move that exists.\n\nGeneralizing from the 8x8 chessboard, you could ask yourself what (n \\times n) boards admit such tours.\n\n\n\n\n\n\n(Spoiler) Numberphile commentary on the knight’s tour"
  },
  {
    "objectID": "materials/dsanotes/graphs/index.html#abstractions-via-graphs",
    "href": "materials/dsanotes/graphs/index.html#abstractions-via-graphs",
    "title": "Representing Graphs",
    "section": "Abstractions via Graphs",
    "text": "Abstractions via Graphs\nIt’s useful to model such problems using graphs (aka networks). And we’re not talking sine curves here — a graph in our context is a structure that represents relationships between entities.\nUsually these relationships are between two entities at a time. Indeed, this is typically already quite a bit to keep track of, hence graphs that do more are said to be hyper. That is to say, graphs that model relationships involving more than two entities in one go are generally called hypergraphs, and they will be a story for another day.\nFor now, we will variously refer to entities as vertices or nodes, and relationships as edges or connections. Come to think of it, graphs are everywhere:\n\n\n\nEntities\nTwo entitites are in a relationship if…\n\n\n\n\nPeople\nthey are in a relationship.\n\n\nCats\nthey have fought each other.\n\n\nActors\nthey have been in a movie together.\n\n\nAirports\nthere is a direct flight between them.\n\n\nLandmasses\nthere is a bridge connecting them.\n\n\nSongs\none of the tunes was copied from the other.\n\n\nSubsets of [42]\none is contained in another.\n\n\nIngredients\nthere is a recipe that uses them together.\n\n\nWebpages\none of them has a link leading to the other.\n\n\nTwitter Users\none of them follows the other2\n\n\nLocations on a Chessboard3\none of them is reachable from the other via a knight move.\n\n\n\nWe usually like to distinguish between graphs where the relationships are potentially one-sided (such as people in a relationship), and those where they are mutual (such as ingredients in a recipe). Edges like these are called directed and undirected, respectively.\nDepending on what the graph is modeling, we may not allow for entities to entertain relationships with themselves (e.g, flights don’t come back to airports they took off from). In other contexts, it makes sense to allow for this (e.g, a set always contains itself). An edge that connects a vertex to itself is called a self-loop4.\nSometimes, it is reasonable that there are multiple edges between a fixed pair of vertices (for example, consider that there are several recipies that use salt and potatoes). Multiple edges are useful to model a multitude of relationships, and are often called multiedges when used.\nA simple graph is one that does not have either self-loops or multiedges.\nFinally, it is worth mentioning that some relationships naturally connect more two entities. For example, in an actor collaboration graph, you would find edges between Amitabh Bachchan, Juhi Chawla, and Shah Rukh Khan. You would also find edges between Akshay Kumar, Dhanush, and Sonam Kapoor. In the first example, there happens to be one film that all three actors feature in together, while this is not the case in the latter, at least at the time of this writing. As such, the graph does not have enough structure to reveal this distinction: it looks exactly the same in both cases!\nFor an actor-collaboration graph, allowing for n-way relationships would make room for accurately capturing information about both actors and movies. Indeed, every movie could be represented by an ‘edge’ — the subset of actors who belonged to the cast. Such graphs are called hypergraphs or set systems.\nWhile hypergraphs are a very useful generalization of graphs, they will be largely out of scope for our discussions in this course. To make up for that, here is a different workaround to capture all the information we have in the actor-collaboration graph example. Instead of having a vertex for every actor, we introduce a vertex for every actor and for every movie. Now, an actor a and a movie m are connected by an edge if a belongs to the cast of m. Observe that this approach can be used to “convert” any hypergraph into a graph.\nA little more terminology before we move on: I promise that we’re almost done introducing new words!\nFor an undirected graph, a vertex u is called a neighbor of a vertex v if (u,v) is an edge. For a directed graph, the presence of the edge (u,v) would make v an out-neighbor of u and u an in-neighbor of v.\nFor an undirected graph, the degree of a vertex v is the number of neighbors of v. For a directed graph, the in-degree and out-degree of v is the number of in-neighbors and out-neighbors of v, respectively."
  },
  {
    "objectID": "materials/dsanotes/graphs/index.html#representing-graphs",
    "href": "materials/dsanotes/graphs/index.html#representing-graphs",
    "title": "Representing Graphs",
    "section": "Representing Graphs",
    "text": "Representing Graphs\nIf you wanted to tell your program about a graph, there are a few different ways you could go about it. Let’s assume that we’re trying to represent a graph G on n nodes, labeled 1 through n, and m edges.\n\n\n\n\n\n\nHow would you do it?\n\n\n\nBefore reading further, it would be worth spending some time thinking about how you would represent a graph. Based on our discussions so far, you might counter this with the question: “Well, what do you need it for?” — and that’s a fair reaction!\nListed below are some fairly common operations that come up when dealing with graphs.\n1. add edge u v\n2. remove edge u v\n3. add vertex v\n4. remove vertex v\n5. is u a neighbor of v?\n6. find degree v\n\n\nEdge Lists. The most natural way is to perhaps just braindump the full list of edges. This gives us all we need to know about G.\nSince this is just a plain list, you could implement it either as an array or as a linked list.\nAdjacency Matrix. The other way is to block off a n \\times n array A of integers. You could then have:\n \\begin{equation*}\n   A[i][j] =\n    \\begin{cases}\n      1 & \\text{if } (i,j) \\in E,\\\\\n      0 & \\text{otherwise.}\n    \\end{cases}\n\\end{equation*}\n\nAdjacency Lists. Finally, you could have an array A of size n, with A[i] pointing to a list of the neighbors of the vertex i if the graph is undirected, and out-neighbors if the graph is directed.\nAgain, since these are just lists, they could be, in principle, implemented either as arrays or linked lists. We will follow the traditional choice of implementing them as lists.\nIt should be no surprise at this point that there is no “right” answer to the choice of representation. You might have noticed, for instance, that an adjacency matrix always reserves n^2 units of space to store G, while the amount of space consumed by the other two representations is proportional to m. Notice that the number of edges in a graph can be as large as \\approx n^2 for simple graphs, so there certainly are graphs for which the space consumption looks the same for all representations. However, for graphs where there aren’t as many edges, then the matrix representation is likely wasteful in terms of space, although you may have other good reasons for sticking to it.\nLet’s classify expenses incurred as follows.\n\nBrilliant. When the procedure only needs constant time.\nDecent. When the procedure always wraps up in, and sometimes needs, time proportional to the maximum degree of the graph.\n(n/m)-tolerable. When the procedure always wraps up in, and sometimes needs, time proportional to the number of vertices/edges in the graph.\n(n/m)-painful. When the procedure always wraps up in, and sometimes needs, time proportional to the number of vertices/edges in the graph squared.\n\nHere’s a run down of how the representations above fare with respect to some of the common operations mentioned in the opening exercise.\n\n\n\nOperations\nAdj. Matrix\nAdj. List\nEdge List\n\n\n\n\nAdding a vertex\nn-Painful\nn-Tolerable\nDecent\n\n\nDeleting a vertex\nn-Painful\nn-Tolerable\nm-Tolerable\n\n\nAdding an edge\nBrilliant\nBrilliant\nBrilliant\n\n\nDeleting an edge\nBrilliant\nDecent\nm-Tolerable\n\n\nFinding degree(v)\nn-Tolerable\nDecent\nm-Tolerable\n\n\nCheck if (u,v) is an edge\nBrilliant\nDecent\nm-Tolerable\n\n\n\nIt would be a good exercise to validate that these claims indeed make sense.\nNow that we’re comfortable with storing graphs, next up, we’ll talk about exploring them."
  },
  {
    "objectID": "materials/dsanotes/eulertours/index.html",
    "href": "materials/dsanotes/eulertours/index.html",
    "title": "Walking Around via Euler Tours",
    "section": "",
    "text": "We revisit the following problem from our introduction to graphs:\nWe also found such traversals useful for computing de Bruijn sequences, so between success on city exploration challenges and impressing with card tricks, there is plenty of motivation to take an Euler tour in a graph.\nIn general, we are given a directed or undirected graph G = (V,E) and we want to know if there is a sequence of edges:\nW := e_0 = (u_0,v_0), \\ldots, e_{m-1} = (u_{m-1},v_{m-1})\nsuch that v_i = u_{i+1 \\mod m} for all i \\in \\{0,1,\\ldots,m-1\\}, and every edge in E features exactly once in this sequence."
  },
  {
    "objectID": "materials/dsanotes/eulertours/index.html#necessary-and-sufficient-conditions",
    "href": "materials/dsanotes/eulertours/index.html#necessary-and-sufficient-conditions",
    "title": "Walking Around via Euler Tours",
    "section": "Necessary and sufficient conditions",
    "text": "Necessary and sufficient conditions\nNote that if such a sequence does exist for a directed graph G, then the indegree of every vertex must equal its outdegree, i.e:\n\nindegree(v) = outdegree(v) for all v \\in V.\n\nLikewise, if such a sequence exists for an undirected graph G, then every vertex must have even degree:\n\ndegree(v) = 2k_v for all v \\in V and some integer k_v.\n\nYou can observe this based on simulating the sequence on the graph and imagining it from the perspective of your favorite vertex v in it. In particular, assume you are walking around in G as dictated by W. Fix your attention on v: every time you “enter” v, via, say the edge e_i, then you must “exit” v via the edge e_{i+1}. If G is directed, e_i is an incoming edge and e_{i+1} is an outgoing edge, and if G is undirected, these are simply two edges incident on v that can be naturally “paired off”. So any successful walk witnesses the claims above.\n\n\n\n\n\n\nThese conditions are necessary, but are they sufficient?\n\n\n\n\n\nIt turns out that you could have graphs where these conditions are true, but there are no Euler tours. This happens when the graph is “disconnected”, i.e, when there is a pair of vertices u and v such that there is no path from u to v. The following are good exercises to work through:\n\nCome up with an example of a graph where the degree conditions are met but there is no Euler tour.\nConvince yourself that if G is connected and satisfies the degree conditions indicated above, you can always find an Euler tour."
  },
  {
    "objectID": "materials/dsanotes/eulertours/index.html#a-naive-algorithm",
    "href": "materials/dsanotes/eulertours/index.html#a-naive-algorithm",
    "title": "Walking Around via Euler Tours",
    "section": "A naive algorithm",
    "text": "A naive algorithm\nNow we turn to the procedural question: knowing what it takes to find an Euler tour, how do we actually find one? First, we get the simple degree-based sanity check out of the way. For undirected graphs we have:\nfor v in V(G):\n    if deg[v] % 2 != 0:\n        return False\nand for directed graphs we have:\nfor v in V(G):\n    if indeg[v] != outdeg[v]:\n        return False\nAssuming we pass these sanity checks, we want to embark on an actual tour. Here’s a reasonable starting point, which essentially amounts to saying that you get to start anywhere, and keep going while you can:\nfind_tour(G,v):\n    // G is the graph\n    // and v is our favorite vertex\n    set curr := v\n    set S := empty\n    while there is an outgoing edge e = (curr,u) which is not in S:\n        add e to S\n        set curr := u\n    return S\nThis is basically a “keep going until stuck” process. By the very nature of the process, the sequence S that we come up with is walkable and does not repeat edges, but it is unclear if this list is exhaustive. Indeed, you should be able to come up with examples of graphs G where G has an Euler tour but find_tour(G) does not output one."
  },
  {
    "objectID": "materials/dsanotes/eulertours/index.html#fixing-the-naive-approach",
    "href": "materials/dsanotes/eulertours/index.html#fixing-the-naive-approach",
    "title": "Walking Around via Euler Tours",
    "section": "Fixing the naive approach",
    "text": "Fixing the naive approach\nHow do we fix this? For one, we need to know if we are done or not: if an edge is missing from S, then that’s a bad sign, and we need to do something about it. How do we know if every edge is enlisted in the output? One way is to compute the length of S: if it falls short of m, we are not done yet.\nBut we also need to know what the missing edges are. We could in principle go through our edge list and ask ourselves if the edge made it to S or not, but that sounds mildly painstaking. Let’s save ourselves the pain with some additional bookkeeping — let’s track the “residual degree” of the vertices: this is the number of edges incident on v that are not yet listed in S. Any vertex with non-zero residual degree gives us concrete hints about missing edges.\nSo for directed graphs we have:\nfind_tour(G,v):\n    init res_deg[v] = outdeg[v]\n    set curr := v\n    set S := empty\n    while there is an outgoing edge e = (curr,u) which is not in S:\n        add e to S\n        res_deg[curr] = res_deg[curr]-1\n        set curr := u\n    return S\nand for undirected graphs we have:\nfind_tour(G,v):\n    init res_deg[v] = deg[v]\n    set curr := v\n    set S := empty\n    while there is an outgoing edge e = (curr,u) which is not in S:\n        add e to S\n        res_deg[curr] = res_deg[curr]-1\n        res_deg[u] = res_deg[u]-1\n        set curr := u\n    return S\nSo now we know when our algorithm is a fail. What’s the fix? Well, let’s approach vertices who are not done yet as per our intel from their res_deg value. We use these vertices to trigger more happy-go-lucky tours:\nfind_tour_fr(G):\n    i := 0\n    marked := emptyset\n    res_deg[v] := outdeg[v]\n    S := list of lists\n    while there is some v with res_deg[v] > 0:\n        let S[i] := find_tour(G,v,marked)\n        add every edge in S_i to marked\n        i = i+1\nSince we need to track visited edges across multiple runs now, we actually inform the find_tour function about the edges already visited from past lives. This is tracked with the marked set.\nSo our updated find_tour function looks like this:\nfind_tour(G,v,marked):\n    set curr := v\n    set S := empty\n    while there is an outgoing edge e = (curr,u)\n    which is not in S or marked:\n        add e to S\n        res_deg[curr] = res_deg[curr]-1\n        set curr := u\n    return S\n(The change is analogous for the version dealing with undirected graphs.)\nWhat we have now is a bunch of fragments, each of which is essentially a walk that begins and ends at the same vertex. Because of our relentless and careful pursuit (c.f. the while condition and the marked set), every edge in G features in exactly one of these fragments. Now it’s just a matter of putting everything together.\nStart with the first fragment S_0. If this is the only fragment we have, that means that our first happy-go-lucky tour was in fact also a lucky one! So we have nothing left to do. Otherwise, there are at least two fragments. Let us look at the set of vertices involved in S_0. The crucial observation is that there must be at least one other fragment, say S_i, that also features some vertex that appears in S_0. Indeed, if this is not the case, then you can argue that S_0 is a sad isolated fragment, and we can actually report that G has no Euler tour.\nOtherwise, find the common vertex between S_0 and S_i, and extend one of them using the other: for example, if v is the common vertex, take a walk in S_0 until you encounter v, and then instead of following along on S_0, take a detour as specified by S_i. Remember if you start on S_i at v, then you will eventurally exhaust S_i by coming back to v: and at this point you can “resume” your walk on S_0. Note that this process welds two fragments at the vertex v thereby reducing the total number of fragments by one. This should count as a sure sign of progress: repeating for as long as possible, we have to do this at most (f-1) many times, where f \\leq \\frac{m}{2} is the total number of fragments.\npatchup():\n    Let S[i] for i in 1, 2, ..., f denote the set of all fragments\n    while f > 1:\n        look for a fragment S[i] that intersects S[0]\n        if S[i] does not exist:\n            return false\n        else:\n            expand S[0] along S[i]\n            remove S[i] from the set of all fragments"
  },
  {
    "objectID": "materials/dsanotes/eulertours/index.html#expenses",
    "href": "materials/dsanotes/eulertours/index.html#expenses",
    "title": "Walking Around via Euler Tours",
    "section": "Expenses",
    "text": "Expenses\nAlthough arguably a naive algorithm, the cool thing about this procedure is that it is guaranteed to work, and the number of steps involved is not terribly bad either. Here’s a naive back-of-the-envelope analysis, assuming G is stored as an adjacency list:\n\nThe degree-based sanity checks are \\approx m since G is stored as an adjacency list.\nConsider find_tour_fr(G):\n\nThe outer while loop runs at most m times since each iteration decreases the residual degree of at least two vertices and the sum of residual degrees is 2m at the start (an analogous argument applies for directed graphs).\nThe inner while loop in find_tour(G,v,marked) is executed at most m times. To find an appropriate edge, we have to go through the negibors of curr and check if the associated edge is already in S or marked. This takes at most (nm) iterations in the worse case, if implemented directly.\nAssuming that S is a linked list and res_deg is an array, the innermost operations are all constant time.\nThe overall cost of a direct implementation is therefore nm^3.\n\nThe patchup procedure involves a outer while loop that runs at most f times if we have f fragments. The looking business to merge fragments will take no more than m units of time: worst case we have to scan all remaining fragments to find a suitable match, and the merger involves updating a few pointers — noting again that the fragments are stored as lists. This is of course a conservative estimate, but it will do. The overall time here is therefore no worse than \\approx m^2 since f \\leq \\frac{m}{2}.\n\nThis gives us m + nm^3 + m^2 in total damages. However, notice that a more careful analysis helps us do better without doing anything substantially different. If you think about find_tour_fr(G) think about how often the instructions:\nadd e to S\nres_deg[curr] = res_deg[curr]-1\nset curr := u\nfrom find_tour(G,v,marked) are actually executed. Every time we execute this set of instructions, we effectively add one edge to the set of marked edges, and since this happens exactly once per edge, these instructions only execute m times overall. Recall that what it takes to enter this loop is the discovery of an unused edge:\nwhile there is an outgoing edge e = (curr,u)\nwhich is not in S or marked\nThis is the bit that took us a while, because we assumed we have to examine all possible edges that go out of curr and then also tally up against S and marked. One way to speed this up is to always commit to pulling out the first element in the adjacency list of the vertex u and then in fact deleting this element from the list. If you are paranoid about subjecting your input to this kind of annihilation, then you can just make a working copy upfront. This way, you can be sure that you can find what you want in constant time, a good case in point to show how the way you store your data can impact the performance of your algorithm.\nBased on the hints above, convince yourself that find_tour_fr(G) in fact has a total expense amounting to \\approx m, modulo constants. With this, our overall cost comes down to \\approx 2m + m^2."
  },
  {
    "objectID": "materials/dsanotes/eulertours/index.html#afterthoughts",
    "href": "materials/dsanotes/eulertours/index.html#afterthoughts",
    "title": "Walking Around via Euler Tours",
    "section": "Afterthoughts",
    "text": "Afterthoughts\nCan we do better? Indeed, it turns out that with a slightly more careful implementation, the business of merging fragments can also be done with an expense proportional to the number of edges. The careful version goes by Hierholzer’s algorithm, and you can read up about this on Wikipedia or watch the video below."
  },
  {
    "objectID": "materials/index.html",
    "href": "materials/index.html",
    "title": "Neeldhara",
    "section": "",
    "text": "Materials\n\n\nLecture Notes for Data Structures and Algorithms  (work in progress)\nLecture Notes for Advanced Algorithms  (coming soon)\nLecture Notes for Getting Started with Competitive Programming  (coming soon)\nLecture Notes for Combinatorial Games  (coming soon)"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Contact\n\n\nAddress\n\nNeeldhara Misra AB 4/305,  IIT Gandhinagar Palaj,  Gandhinagar 382055  India\n\nEmail\n\nneeldhara.misra@gmail.com • neeldhara.m@iitgn.ac.in\n\nIn case you have emailed me and have not heard back: it is typically my bad!\n\n\nI tend to respond either immediately or eventually, so don’t hesitate to send a (n|gr)udging reminder if I have not responded to your email and your context is time-sensitive. My apologies!\n\n\nPhone\n\n+91 79 2395 2490 (Off)"
  },
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "All News",
    "section": "",
    "text": "All News\n\n \n\n\n\n    \n        \n        \n        \n        \n        \n        Finding Perfect Matching Cuts Faster |  Mar 27, 2023\n        \n        \n        \n        \n        \n        Joint work with Yash More ⸱ To Appear at IWOCA 2023 ⸱ Preprint coming soon!\nA cut (X,Y) is a perfect matching cut if and only if each vertex in X has exactly one neighbor in Y and each vertex in Y has exactly one neighbor in X. The computational problem of determining if a graph admits a perfect matching cut is NP-complete, even when restricted to the class of bipartite graphs of maximum degree 3 and arbitrarily large girth. We demonstrate a faster exact exponential time algorithm on general graphs and an even faster algorithm on graphs of maximum degree three that have girth six.\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        CompEd 2023 Dates Announced |  Mar 24, 2023\n        \n        \n        \n        \n        \n        CompEd will be held between December 7-9, 2023, at Hyderabad, India. Check out the call for participation! The deadline for submitting abstracts is Sunday, 7 May.\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        IPEC 2023 Dates Announced |  Mar 20, 2023\n        \n        \n        \n        \n        \n        The International Symposium on Parameterized and Exact Computation (IPEC) is an annual conference covering all aspects of parameterized and exact algorithms and complexity. Its 18th edition will be part of ALGO 2023, which also hosts ESA 2023 and other specialized conferences and workshops. We are excited that ALGO 2023 is planned as an in-person conference and we look forward to seeing you there! ALGO will be held between September 4-8, 2023, at Amsterdam, the Netherlands.\nDo submit your best work to IPEC 2023 --- the abstract submission deadline is June 27th (23:59 AoE).\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        NASI Platinum Jubilee Young Scientist Award |  Jan 5, 2023\n        \n        \n        \n        \n        \n        Recieved the NASI Platinum Jubilee Young Scientist Award. Most grateful to all collaborators and mentors who make this recognition possible.\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        INYAS Membership |  Jan 1, 2023\n        \n        \n        \n        \n        \n        INYAS is the Young Science Academy established by Indian National Science Academy (INSA). Their work in science outreach and popularization has been wide-ranging and very inspiring over the years. It is wonderful and humbling to have been selected as a member this year. Looking forward to pitching in!\n\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        ACM-India CSEd Workshop |  Dec 25, 2022\n        \n        \n        \n        \n        \n        We recently concluded the CSEd Workshop with support from ACM India, NPTEL, and the discipline of CSE at IIT Gandhinagar. The workshop featured talks by Sonia Garcha, Viraj Kumar, Venkatesh Choppella, and N S Kumar. The talks covered various themes, including CSPathshala, refute questions, mapcode, and key takeaways to convey in a data structures course.\nThe materials from the course (including video recordings and slides) can be accessed from here.\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        A Proud Carmelite! |  Dec 15, 2022\n        \n        \n        \n        \n        \n        Mount Carmel College (in Bangalore), my alma mater, is celebrating its Platinum Jubilee this year. A part of this celebration is HERSTORY: \"75 years of scripting success stories of Confident, Competent, & Compassionate Carmelites\".\nI was honored to be among the 75 Carmelites invited for the HERSTORY event today. It was very nostalgic to be back on campus, and the organizers put together an impeccable event that made all of us feel very special. It was humbling to be in inspiring company. I can't thank MCC enough for providing an empowering and fun environment at a crucial stage of my life!\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        GIAN Course on Randomized Methods for Parameterized Algorithms |  Dec 9, 2022\n        \n        \n        \n        \n        \n        We recently concluded the GIAN course on Randomized Methods for Parameterized Algorithms by Daniel Lokshtanov, Professor, Dept of Computer Science, University of California Santa Barbara, between Dec 5—9, 2022. The course consisted of over ten hours of lectures covering modern techniques in randomized algorithms, and five interactive tutorial sessions.\nThe materials from the course (including video recordings and slides) can be accessed from here.\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        NPTEL Registration is Live |  Nov 16, 2022\n        \n        \n        \n        \n        \n        My course on Getting Started with Competitive Programming will run from 23 Jan 2023 to 14 Apr 2023. The deadline to register is 30th January 2023. I hope you have a chance to check it out if it is of interest to you!\n(More generally, the NPTEL Jan 2023 semester is open with courses across engineering, humanities and social sciences. You can enrol in these courses at no cost here and get a certification by taking up a proctored exam for a nominal fee of Rs 1,000 per course.)\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        Romeo and Juliet Meeting in Forest Like Regions |  Sep 20, 2022\n        \n        \n        \n        \n        \n        Joint work with Manas Mulpuri, Prafullkumar Tale, and Gaurav Viramgami ⸱ To Appear at FSTTCS 2022 ⸱ Preprint available from ArXiV\nThe game of rendezvous with adversaries is a game on a graph played by two players: Facilitator and Divider. Facilitator has two agents and Divider has a team of k agents. While the initial positions of Facilitator’s agents are fixed, Divider gets to select the initial positions of his agents. Then, they take turns to move their agents to adjacent vertices (or stay put) with Facilitator’s goal to bring both her agents at same vertex and Divider’s goal to prevent it. The computational question of interest is to determine if Facilitator has a winning strategy against Divider with k agents. In this work, we prove that this problem is hard even when the graph is very close to a forest.\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        Diverse Non Crossing Matchings |  Jun 20, 2022\n        \n        \n        \n        \n        \n        Joint work with Harshil Mittal and Sarasati Nanoti ⸱ To Appear at CCCG 2022\nA perfect matching M on a set P of n points is a collection of line segments with endpoints from P such that every point belongs to exactly one segment. A matching is non-crossing if the line segments do not cross. We introduce a notion of distance between non-crossing matchings, and investigate the complexity of the problem of finding matchings that are far apart with respect to this notion of distance.\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        Solo Chess |  Mar 23, 2022\n        \n        \n        \n        \n        \n        Joint work with N. R. Aravind and Harshil Mittal ⸱ To appear at FUN 2022 ⸱ Preprint available from ArXiV\nWe introduce a generalization of “Solo Chess”, a single-player variant of the game that can be played on chess.com. We show that this version of the game is NP-complete even if played only by rooks with at most two captures left, or only by queens with exactly two captures left. On the other hand, solvable instances of rooks on 1D boards and pawns on 2D boards can efficiently characterized. Find out more on Twitter or at the blog.\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        CSE Open House |  Mar 12, 2022\n        \n        \n        \n        \n        \n        Members of the discipline of Computer Science and Engineering just concluded a virtual open house. You can now find out more about research directions in CSE at IIT Gandhinagar and the research opportunities that we offer. Please share these links with anyone that you think would find them useful!\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        Eternal Vertex Cover |  Mar 11, 2022\n        \n        \n        \n        \n        \n        Joint work with Saraswati Nanoti ⸱ To appear at CSR 2022 ⸱ Preprint available from ArXiV\nEternal Vertex Cover is a dynamic variant of the vertex cover problem. The complexity of the problem on bipartite graphs is open, as is the question of whether the problem admits a polynomial kernel. We settle both these questions by showing that Eternal Vertex Cover is NP-hard and does not admit a polynomial compression even on bipartite graphs of diameter six. We also show that the problem admits a polynomial time algorithm on the class of cobipartite graphs.\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        Imbalance Parameterized by Twin Cover |  Dec 4, 2021\n        \n        \n        \n        \n        \n        Joint work with Harshil Mittal ⸱ Published in Theoretical Computer Science (Dec 2021) ⸱ A shorter version was accepted at COCOON 2020 ⸱ Preprint available from ArXiV\nImbalance is a layout optimization problem, where we would like to order the vertices of a graph so that, roughly speaking, vertices have their neighbors split up as equally as possible on their left and right. We examine the parameterized complexity of the problem with respect to a structural parameter called twin cover.\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        NPTEL Registration is Live |  Dec 1, 2021\n        \n        \n        \n        \n        \n        My course on Getting Started with Competitive Programming will run from 24 Jan 2022 to 15 Apr 2022. The deadline to register is 31st January 2022.\n(More generally, the NPTEL Jan 2022 semester is open with courses across engineering, humanities and social sciences. You can enrol in these courses at no cost here and get a certification by taking up a proctored exam for a nominal fee of Rs 1,000 per course.)\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        FUN 2022 Dates Announced |  Nov 30, 2021\n        \n        \n        \n        \n        \n        Submit your most fun work to FUN 2022! Also spread the word with a retweet :)\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        Local Fair Division |  Nov 22, 2021\n        \n        \n        \n        \n        \n        Joint work with Debanuj Nayak ⸱ Accepted at CALDAM 2022 ⸱ Preprint available from ArXiV.\nThese developments explore the complexity of finding envy-free allocations of indivisible items in settings where envy is only experienced between friends, the valuations over items are binary, and the social network over agents is given by an undirected graph.\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        Two New NPTEL Courses! |  Jul 14, 2021\n        \n        \n        \n        \n        \n        Here’s a Twitter thread with more detailsl\nI'll be co-teaching a couple of new courses this August on the NPTEL platform. The first is about competitive programming (co-taught with Arjun Arul from Codechef) and the second is an introduction to parameterized algorithms (co-taught with Saket Saurabh from IMSc). Both are meant as follow ups to a first undergraduate algorithms course.\n        \n        \n    \n\n\nNo matching items"
  },
  {
    "objectID": "talks/2022-aarohan/index.html#act-i",
    "href": "talks/2022-aarohan/index.html#act-i",
    "title": "Succeeding in Grad School",
    "section": "Act I",
    "text": "Act I\n\n\nBreadth\nv/s\nDepth"
  },
  {
    "objectID": "talks/2022-aarohan/index.html#act-i-1",
    "href": "talks/2022-aarohan/index.html#act-i-1",
    "title": "Succeeding in Grad School",
    "section": "Act I",
    "text": "Act I\n\n\nBreadth\nv/s\nDepth"
  },
  {
    "objectID": "talks/index.html",
    "href": "talks/index.html",
    "title": "Talks",
    "section": "",
    "text": "Talks\n\n \n\nThe slides for most of my talks are available from here, and several recordings are on this Youtube playlist.\n\n\n\n\n\n\nComing Soon\n\n\n\nA few tutorial-style talks are missing from this list, they will be added soon.\n\n\n\n \n\n\nFeaturedAll\n\n\n\n \n\n\n\n\n    \n            \n                \n                    2022\n                \n                \n                    Games of Pursuit and Evasion \n                    STCS Vigyan Vidushi 2022 Distinguished Lecture \n                    TIFR, Mumbai\n                \n                \n                           \n                \n                \n                           \n                \n            \n            \n                \n                    2022\n                \n                \n                    History of Algorithms: The Worst Case and Beyond \n                    History of Ideas 2.0 (Seminar Series) \n                    Virtual (organized by IIT Gandhinagar)\n                \n                \n                           \n                \n                \n                           \n                \n            \n            \n                \n                    2022\n                \n                \n                    Parameterized Approaches to Kemeny Rank Aggregation \n                    Bangalore Theory Seminars \n                    Virtual (organized by CSA, Indian Institute of Science and MSR Bangalore)\n                \n                \n                           \n                \n                \n                           \n                \n            \n            \n                \n                    2020\n                \n                \n                    Fair Division with Minimal Sharing \n                    COMSOC Video Seminar Rump Session \n                    Virtual\n                \n                \n                \n                \n                           \n                \n            \n            \n                \n                    2019\n                \n                \n                    Evolution of Trust \n                    Summer Research Internship Program Seminar Series \n                    IIT Gandhinagar\n                \n                \n                \n                \n                           \n                \n            \n\n\n\nNo matching items\n\n\n\n\n\n \n\n\n\n\n    \n        \n            \n                2022\n            \n            \n                A Few Algorithmic Puzzles (and why you should care) \n                Department Seminar \n                Virtual (organized by SSN College of Engineering)\n            \n            \n                       \n            \n            \n            \n        \n        \n            \n                2022\n            \n            \n                A career in academia - why and why not? \n                ACM-W India Grad Cohort Workshop \n                IIT Jodhpur\n            \n            \n            \n            \n            \n        \n        \n            \n                2022\n            \n            \n                Current Research Directions in Fair Division \n                ACM Goa Chapter Seminar Series \n                Virtual\n            \n            \n            \n            \n            \n        \n        \n            \n                2022\n            \n            \n                Games of Pursuit and Evasion \n                STCS Vigyan Vidushi 2022 Distinguished Lecture \n                TIFR, Mumbai\n            \n            \n                       \n            \n            \n                       \n            \n        \n        \n            \n                2022\n            \n            \n                History of Algorithms: The Worst Case and Beyond \n                History of Ideas 2.0 (Seminar Series) \n                Virtual (organized by IIT Gandhinagar)\n            \n            \n                       \n            \n            \n                       \n            \n        \n        \n            \n                2022\n            \n            \n                On Fair Division with Binary Valuations Respecting Social Networks \n                Workshop on Computation and Economics \n                Ashoka University\n            \n            \n            \n            \n            \n        \n        \n            \n                2022\n            \n            \n                Panel discussion on \"The Source Code: Foundational Literacy Numeracy Digitacy and Beyond\" \n                Raising Learners For India 2040, a Karadi Path event \n                The Shri Ram Universal School, Lodha Lakeshore Greens, Palava\n            \n            \n            \n            \n            \n        \n        \n            \n                2022\n            \n            \n                Parameterized Approaches to Kemeny Rank Aggregation \n                Bangalore Theory Seminars \n                Virtual (organized by CSA, Indian Institute of Science and MSR Bangalore)\n            \n            \n                       \n            \n            \n                       \n            \n        \n        \n            \n                2022\n            \n            \n                Problem Solving with Python \n                Paradox Workshop, a Convocation Event for the IITM Online BSc Degree Program \n                IIT Madras\n            \n            \n            \n            \n            \n        \n        \n            \n                2022\n            \n            \n                Programming Beyond Block Coding \n                Coding Bootcamp for Innovation Club Students \n                Science City Ahmedabad (organized by GUJCOST)\n            \n            \n            \n            \n            \n        \n        \n            \n                2022\n            \n            \n                The Games we Play \n                FDP on Futuristic Technologies in the field of IT \n                LD College of Engineering\n            \n            \n            \n            \n            \n        \n        \n            \n                2021\n            \n            \n                Algorithmic Aspects of Firefighting \n                a short talk given as a part of the INAE webinar series \n                Virtual\n            \n            \n            \n            \n            \n        \n        \n            \n                2021\n            \n            \n                Panel discussion on Women in Computing Panel on PhD Opportunities in India \n                CSA Golden Jubilee lecture series \n                CSA, Indian Institute of Science\n            \n            \n            \n            \n            \n        \n        \n            \n                2021\n            \n            \n                Party Nominations \n                a talk at ReLaX — a Workshop on Games \n                Virtual (organized by Chennai Mathematical Institute)\n            \n            \n            \n            \n            \n        \n        \n            \n                2020\n            \n            \n                Fair Division with Minimal Sharing \n                COMSOC Video Seminar Rump Session \n                Virtual\n            \n            \n            \n            \n                       \n            \n        \n        \n            \n                2020\n            \n            \n                Parameterized Algorithms for Variants of Dominating Set \n                Workshop on Recent Trends Domination in Graphs - Algorithms, Complexity and Applications \n                Virtual (organized by NIT Warangal)\n            \n            \n            \n            \n            \n        \n        \n            \n                2019\n            \n            \n                Chamberlin-Courant on Restricted Domains \n                Recent Trends in Algorithms \n                National Institute of Science Education and Research, Bhubaneswar\n            \n            \n            \n            \n            \n        \n        \n            \n                2019\n            \n            \n                Early Career Researcher Presentation \n                13th Inter-Research-Institute Student Seminar in Computer Science (IRISS) \n                Rajagiri School of Engineering and Technology\n            \n            \n            \n            \n            \n        \n        \n            \n                2019\n            \n            \n                Evolution of Trust \n                Summer Research Internship Program Seminar Series \n                IIT Gandhinagar\n            \n            \n            \n            \n                       \n            \n        \n        \n            \n                2019\n            \n            \n                Explorable Explanations - Interactive Essays \n                Winter Institute in Digital Humanities \n                IIT Gandhinagar\n            \n            \n            \n            \n            \n        \n        \n            \n                2019\n            \n            \n                Firefighting with Critical Nodes \n                CSA50 - Pratiksha Trust Workshop on Theoretical Computer Science \n                CSA, Indian Institute of Science, Bangalore\n            \n            \n            \n            \n            \n        \n        \n            \n                2019\n            \n            \n                On Stable Matchings \n                Keynote Talk at the ACM India Student Chapters Summit \n                Manipal University, Jaipur\n            \n            \n            \n            \n            \n        \n        \n            \n                2018\n            \n            \n                Technical presentation skills versus interpersonal skills (joint presentation with Varsha Apte) \n                First ACM India Grad Cohort Workshop for Women in Computing \n                IIT Bombay\n            \n            \n            \n            \n            \n        \n        \n            \n                2017\n            \n            \n                An Introduction to Parameterized Algorithms \n                Pre-Conference Workshop on Graph Algorithms (13th ADMA Conference) \n                SSN College\n            \n            \n            \n            \n            \n        \n        \n            \n                2017\n            \n            \n                Efficient Algorithms for Hard Problems on Structured Electorates \n                Workshop on Aspects of Computation \n                National University of Singapore\n            \n            \n            \n            \n            \n        \n        \n            \n                2016\n            \n            \n                An Introduction to Computational Social Choice \n                Workshop on Game Theory and Optimization \n                CSA, Indian Institute of Science\n            \n            \n            \n            \n            \n        \n        \n            \n                2016\n            \n            \n                Efficient Algorithms for Hard Problems on Structured Electorates \n                Workshop on Rangoli of Algorithms \n                Chennai Mathematical Institute\n            \n            \n            \n            \n            \n        \n        \n            \n                2016\n            \n            \n                Elicitation for Preferences Single Peaked on Trees \n                CS-Econ Seminar Series \n                Duke University\n            \n            \n            \n            \n            \n        \n        \n            \n                2016\n            \n            \n                Parameterized Algorithms \n                Tutorial Talk \n                Duke University\n            \n            \n            \n            \n            \n        \n        \n            \n                2016\n            \n            \n                Parameterized Algorithms for Computational Social Choice \n                Workshop on Game Theory and Optimization \n                Indian Institute of Science\n            \n            \n            \n            \n            \n        \n        \n            \n                2015\n            \n            \n                Glimpses of Algebraic Graph Theory and Linear Algebra Methods in Combinatorics \n                Workshop on Linear Algebra and Related Topics at the School of Mathematics and Computing Sciences \n                Rani Channamma University, Belagavi\n            \n            \n            \n            \n            \n        \n        \n            \n                2015\n            \n            \n                On the Planar F-Deletion Problem \n                Fourth India-Taiwan Conference on Discrete Mathematics \n                IIT Madras\n            \n            \n            \n            \n            \n        \n        \n            \n                2015\n            \n            \n                Some Algorithmic Excursions \n                Science Academies Education Program, Workshop for Pre-University Students in Elementary Mathematics \n                Christ College, Bangalore\n            \n            \n            \n            \n            \n        \n        \n            \n                2014\n            \n            \n                Iterative Compression for FVS \n                Department  Seminar \n                IIIT Bangalore\n            \n            \n            \n            \n            \n        \n        \n            \n                2014\n            \n            \n                Max $q$-Colorable Induced Subgraph Problem on Perfect Graphs \n                Graph Modification Problems \n                Dagstuhl, Germany\n            \n            \n            \n            \n            \n        \n        \n            \n                2014\n            \n            \n                Parameterized Graph Modification - A Modern Perspective \n                New Developments in Exact Algorithms and Lower Bounds (Pre-FSTTCS Workshop) \n                IIT Delhi\n            \n            \n            \n            \n            \n        \n        \n            \n                2012\n            \n            \n                Connected Dominating Set and Short Cycles \n                Department Seminar \n                Indian Statistical Institute, Bangalore\n            \n            \n            \n            \n            \n        \n        \n            \n                2012\n            \n            \n                From FVS to F-deletion - the Story of a Simple Algorithm \n                Department Seminar \n                VCLA, Technical University of Vienna\n            \n            \n            \n            \n            \n        \n        \n            \n                2012\n            \n            \n                Kernelization \n                Chennai Update Meeting on Parameterized Complexity \n                Institute of Mathematical Sciences, Chennai\n            \n            \n            \n            \n            \n        \n        \n            \n                2012\n            \n            \n                Kernels for Planar F-Deletion \n                Data Reduction and Problem Kernels \n                Dagstuhl, Germany\n            \n            \n            \n            \n            \n        \n        \n            \n                2012\n            \n            \n                Separators with Non-Hereditary Properties \n                Mini-Workshop on Logic, Proofs and Algorithms \n                VCLA, Technical University of Vienna\n            \n            \n            \n            \n            \n        \n        \n            \n                2011\n            \n            \n                Efficient Simplification - Polynomial Time Revisited \n                Department Seminar \n                CSA, Indian Institute of Science\n            \n            \n            \n            \n            \n        \n        \n            \n                2010\n            \n            \n                Connected Dominating Set and Short Cycles \n                Algorithms Seminar Series \n                University of Bergen, Norway\n            \n            \n            \n            \n            \n        \n        \n            \n                2010\n            \n            \n                Efficient Simplification - The (im)possibilities \n                IMPECS School on Parameterized Complexity \n                Institute for Mathematical Sciences\n            \n            \n            \n            \n            \n        \n        \n            \n                2010\n            \n            \n                Expansions for Reductions \n                Workshop on Kernelization \n                Lorentz Center, Netherlands\n            \n            \n            \n            \n            \n        \n        \n            \n                2010\n            \n            \n                Iterative Compression ---  Try, try, till you succeed --- or fail. \n                Kalasalingam University, Madurai, and Institute Seminar Week \n                The Institute of Mathematical Sciences\n            \n            \n            \n            \n            \n        \n        \n            \n                2010\n            \n            \n                Lower Bounds on Kernelization \n                Department Seminar \n                Chalmers University, Sweden\n            \n            \n            \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n×\n\nA Few Algorithmic Puzzles (and why you should care)\n\n\n \n\n\n\n\n\n\n\n\n\n×\n\nA Few Algorithmic Puzzles (and why you should care)\n\n\n \n\n\n\n\n\n\n\n×\n\nThe Games we Play\n\n\n \n\n\n\n\n\n\n\n×\n\nThe Games we Play\n\n\n \n\n\n\n\n\n\n\n×\n\nProgramming Beyond Block Coding\n\n\n \n\n\n\n\n\n\n\n×\n\nProgramming Beyond Block Coding\n\n\n \n\n\n\n\n\n\n\n×\n\nOn Fair Division with Binary Valuations Respecting Social Networks\n\n\n \n\n\n\n\n\n\n\n×\n\nOn Fair Division with Binary Valuations Respecting Social Networks\n\n\n \n\n\n\n\n\n\n\n×\n\nProblem Solving with Python\n\n\n \n\n\n\n\n\n\n\n×\n\nProblem Solving with Python\n\n\n \n\n\n\n\n\n\n\n×\n\nHistory of Algorithms: The Worst Case and Beyond\n\n\n \n\n\n\n\n\n\n\n\n\n×\n\nHistory of Algorithms: The Worst Case and Beyond\n\n\n \n\n\n\n\n\n\n\n\n\n×\n\nGames of Pursuit and Evasion\n\n\n \n\n\n\n\n\n\n\n\n\n×\n\nGames of Pursuit and Evasion\n\n\n \n\n\n\n\n\n\n\n\n\n×\n\nA career in academia - why and why not?\n\n\n \n\n\n\n\n\n\n\n×\n\nA career in academia - why and why not?\n\n\n \n\n\n\n\n\n\n\n×\n\nPanel discussion on “The Source Code: Foundational Literacy Numeracy Digitacy and Beyond”\n\n\n \n\n\n\n\n\n\n\n×\n\nPanel discussion on “The Source Code: Foundational Literacy Numeracy Digitacy and Beyond”\n\n\n \n\n\n\n\n\n\n\n×\n\nParameterized Approaches to Kemeny Rank Aggregation\n\n\n \n\n\n\n\n\n\n\n\n\n×\n\nParameterized Approaches to Kemeny Rank Aggregation\n\n\n \n\n\n\n\n\n\n\n\n\n×\n\nCurrent Research Directions in Fair Division\n\n\n \n\n\n\n\n\n\n\n×\n\nCurrent Research Directions in Fair Division\n\n\n \n\n\n\n\n\n\n\n×\n\nPanel discussion on Women in Computing Panel on PhD Opportunities in India\n\n\n \n\n\n\n\n\n\n\n×\n\nPanel discussion on Women in Computing Panel on PhD Opportunities in India\n\n\n \n\n\n\n\n\n\n\n×\n\nAlgorithmic Aspects of Firefighting\n\n\n \n\n\n\n\n\n\n\n×\n\nAlgorithmic Aspects of Firefighting\n\n\n \n\n\n\n\n\n\n\n×\n\nParty Nominations\n\n\n \n\n\n\n\n\n\n\n×\n\nParty Nominations\n\n\n \n\n\n\n\n\n\n\n×\n\nFair Division with Minimal Sharing\n\n\n \n\n\n\n\n\n\n\n×\n\nFair Division with Minimal Sharing\n\n\n \n\n\n\n\n\n\n\n\n\n×\n\nParameterized Algorithms for Variants of Dominating Set\n\n\n \n\n\n\n\n\n\n\n×\n\nParameterized Algorithms for Variants of Dominating Set\n\n\n \n\n\n\n\n\n\n\n×\n\nExplorable Explanations - Interactive Essays\n\n\n \n\n\n\n\n\n\n\n×\n\nExplorable Explanations - Interactive Essays\n\n\n \n\n\n\n\n\n\n\n×\n\nOn Stable Matchings\n\n\n \n\n\n\n\n\n\n\n×\n\nOn Stable Matchings\n\n\n \n\n\n\n\n\n\n\n×\n\nChamberlin-Courant on Restricted Domains\n\n\n \n\n\n\n\n\n\n\n×\n\nChamberlin-Courant on Restricted Domains\n\n\n \n\n\n\n\n\n\n\n×\n\nFirefighting with Critical Nodes\n\n\n \n\n\n\n\n\n\n\n×\n\nFirefighting with Critical Nodes\n\n\n \n\n\n\n\n\n\n\n×\n\nEarly Career Researcher Presentation\n\n\n \n\n\n\n\n\n\n\n×\n\nEarly Career Researcher Presentation\n\n\n \n\n\n\n\n\n\n\n×\n\nEvolution of Trust\n\n\n \n\n\n\n\n\n\n\n×\n\nEvolution of Trust\n\n\n \n\n\n\n\n\n\n\n\n\n×\n\nTechnical presentation skills versus interpersonal skills (joint presentation with Varsha Apte)\n\n\n \n\n\n\n\n\n\n\n×\n\nTechnical presentation skills versus interpersonal skills (joint presentation with Varsha Apte)\n\n\n \n\n\n\n\n\n\n\n×\n\nAn Introduction to Parameterized Algorithms\n\n\n \n\n\n\n\n\n\n\n×\n\nAn Introduction to Parameterized Algorithms\n\n\n \n\n\n\n\n\n\n\n×\n\nEfficient Algorithms for Hard Problems on Structured Electorates\n\n\n \n\n\n\n\n\n\n\n×\n\nEfficient Algorithms for Hard Problems on Structured Electorates\n\n\n \n\n\n\n\n\n\n\n×\n\nEfficient Algorithms for Hard Problems on Structured Electorates\n\n\n \n\n\n\n\n\n\n\n×\n\nEfficient Algorithms for Hard Problems on Structured Electorates\n\n\n \n\n\n\n\n\n\n\n×\n\nParameterized Algorithms for Computational Social Choice\n\n\n \n\n\n\n\n\n\n\n×\n\nParameterized Algorithms for Computational Social Choice\n\n\n \n\n\n\n\n\n\n\n×\n\nElicitation for Preferences Single Peaked on Trees\n\n\n \n\n\n\n\n\n\n\n×\n\nElicitation for Preferences Single Peaked on Trees\n\n\n \n\n\n\n\n\n\n\n×\n\nParameterized Algorithms\n\n\n \n\n\n\n\n\n\n\n×\n\nParameterized Algorithms\n\n\n \n\n\n\n\n\n\n\n×\n\nAn Introduction to Computational Social Choice\n\n\n \n\n\n\n\n\n\n\n×\n\nAn Introduction to Computational Social Choice\n\n\n \n\n\n\n\n\n\n\n×\n\nOn the Planar F-Deletion Problem\n\n\n \n\n\n\n\n\n\n\n×\n\nOn the Planar F-Deletion Problem\n\n\n \n\n\n\n\n\n\n\n×\n\nGlimpses of Algebraic Graph Theory and Linear Algebra Methods in Combinatorics\n\n\n \n\n\n\n\n\n\n\n×\n\nGlimpses of Algebraic Graph Theory and Linear Algebra Methods in Combinatorics\n\n\n \n\n\n\n\n\n\n\n×\n\nSome Algorithmic Excursions\n\n\n \n\n\n\n\n\n\n\n×\n\nSome Algorithmic Excursions\n\n\n \n\n\n\n\n\n\n\n×\n\nParameterized Graph Modification - A Modern Perspective\n\n\n \n\n\n\n\n\n\n\n×\n\nParameterized Graph Modification - A Modern Perspective\n\n\n \n\n\n\n\n\n\n\n×\n\nIterative Compression for FVS\n\n\n \n\n\n\n\n\n\n\n×\n\nIterative Compression for FVS\n\n\n \n\n\n\n\n\n\n\n×\n\nMax q-Colorable Induced Subgraph Problem on Perfect Graphs\n\n\n \n\n\n\n\n\n\n\n×\n\nMax q-Colorable Induced Subgraph Problem on Perfect Graphs\n\n\n \n\n\n\n\n\n\n\n×\n\nKernels for Planar F-Deletion\n\n\n \n\n\n\n\n\n\n\n×\n\nKernels for Planar F-Deletion\n\n\n \n\n\n\n\n\n\n\n×\n\nSeparators with Non-Hereditary Properties\n\n\n \n\n\n\n\n\n\n\n×\n\nSeparators with Non-Hereditary Properties\n\n\n \n\n\n\n\n\n\n\n×\n\nFrom FVS to F-deletion - the Story of a Simple Algorithm\n\n\n \n\n\n\n\n\n\n\n×\n\nFrom FVS to F-deletion - the Story of a Simple Algorithm\n\n\n \n\n\n\n\n\n\n\n×\n\nKernelization\n\n\n \n\n\n\n\n\n\n\n×\n\nKernelization\n\n\n \n\n\n\n\n\n\n\n×\n\nConnected Dominating Set and Short Cycles\n\n\n \n\n\n\n\n\n\n\n×\n\nConnected Dominating Set and Short Cycles\n\n\n \n\n\n\n\n\n\n\n×\n\nEfficient Simplification - Polynomial Time Revisited\n\n\n \n\n\n\n\n\n\n\n×\n\nEfficient Simplification - Polynomial Time Revisited\n\n\n \n\n\n\n\n\n\n\n×\n\nEfficient Simplification - The (im)possibilities\n\n\n \n\n\n\n\n\n\n\n×\n\nEfficient Simplification - The (im)possibilities\n\n\n \n\n\n\n\n\n\n\n×\n\nExpansions for Reductions\n\n\n \n\n\n\n\n\n\n\n×\n\nExpansions for Reductions\n\n\n \n\n\n\n\n\n\n\n×\n\nConnected Dominating Set and Short Cycles\n\n\n \n\n\n\n\n\n\n\n×\n\nConnected Dominating Set and Short Cycles\n\n\n \n\n\n\n\n\n\n\n×\n\nLower Bounds on Kernelization\n\n\n \n\n\n\n\n\n\n\n×\n\nLower Bounds on Kernelization\n\n\n \n\n\n\n\n\n\n\n×\n\nIterative Compression — Try, try, till you succeed — or fail.\n\n\n \n\n\n\n\n\n\n\n×\n\nIterative Compression — Try, try, till you succeed — or fail.\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/talks-old.html",
    "href": "talks/talks-old.html",
    "title": "Neeldhara",
    "section": "",
    "text": "Year\nTitle\n\n\n\n\n2022\nOn Fair Division with Binary Valuations Respecting Social Networks  Workshop on Computation and Economics, Ashoka University\n\n\n2022\nProblem Solving with Python  a workshop conducted at Paradox, an NPTEL offline Convocation Event, IIT Madras\n\n\n2022\nThe Games we Play  STCS Vigyan Vidushi 2022 Distinguished Lecture, TIFR\n\n\n2022\nA career in academia: why and why not?  ACM-W India Grad Cohort Workshop, IIT Jodhpur\n\n\n2022\nPanel discussion on “The Source Code: Foundational Literacy Numeracy Digitacy and Beyond”  Raising Learners For India 2040, a Karadi Path event\n\n\n2022\nParameterized Approaches to Kemeny Rank Aggregation  Bangalore Theory Seminars, CSA, Indian Institute of Science and MSR Bangalore\n\n\n2022\nCurrent Research Directions in Fair Division  ACM Goa Chapter Seminar Series\n\n\n2021\nPanel discussion on Women in Computing Panel on PhD Opportunities in India  CSA, Indian Institute of Science\n\n\n2021\nAlgorithmic Aspects of Firefighting  a short talk given as a part of the INAE webinar series\n\n\n2021\nParty Nominations  a talk at ReLaX — a Workshop on Games Chennai Mathematical Institute\n\n\n2020\nParameterized Algorithms for Variants of Dominating Set  series of invited lectures in a virtual workshop on  Recent Trends Domination in Graphs - Algorithms, Complexity and Applications,  organized by NIT Warangal\n\n\n2019\nExplorable Explanations: Interactive Essays  Winter Institute in Digital Humanities, IIT Gandhinagar\n\n\n2019\nOn Stable Matchings  Keynote Talk at the ACM India Student Chapters Summit, Manipal University\n\n\n2019\nChamberlin-Courant on Restricted Domains  Recent Trends in Algorithms, National Institute of Science Education and Research, Bhubaneswar\n\n\n2019\nFirefighting with Critical Nodes  CSA50 - Pratiksha Trust Workshop on Theoretical Computer Science,  Indian Institute of Science, Bangalore\n\n\n2019\nEarly Career Researcher Presentation  13th Inter-Research-Institute Student Seminar in Computer Science,  Rajagiri School of Engineering and Technology\n\n\n2018\nTechnical presentation skills versus interpersonal skills  (joint presentation with Varsha Apte)  First ACM India Grad Cohort Workshop for Women in Computing, IIT Bombay\n\n\n2017\nAn Introduction to Parameterized Algorithms  Pre-Conference Workshop on Graph Algorithms (13th ADMA Conference), SSN College\n\n\n2017\nEfficient Algorithms for Hard Problems on Structured Electorates  Invited talk at the workshop on Aspects of Computation, National University of Singapore\n\n\n2016\nEfficient Algorithms for Hard Problems on Structured Electorates  Workshop on Rangoli of Algorithms, Chennai Mathematical Institute\n\n\n2016\nParameterized Algorithms for Computational Social Choice  Workshop on Game Theory and Optimization, Indian Institute of Science\n\n\n2016\nElicitation for Preferences Single Peaked on Trees  CS-Econ Seminar Series, Duke University\n\n\n2016\nParameterized Algorithms  Tutorial Talk, Duke University\n\n\n2016\nAn Introduction to Computational Social Choice  Workshop on Game Theory and Optimization, Indian Institute of Science\n\n\n2015\nOn the Planar F-Deletion Problem  Fourth India-Taiwan Conference on Discrete Mathematics, IIT Madras\n\n\n2015\nGlimpses of Algebraic Graph Theory and Linear Algebra Methods in Combinatorics  Workshop on Linear Algebra and Related Topics at the School of Mathematics and Computing Sciences, Rani Channamma University, Belagavi\n\n\n2015\nSome Algorithmic Excursions  Science Academies’ Education Program, Workshop for Pre-University Students in Elementary Mathematics, at Christ College, Bangalore\n\n\n2014\nParameterized Graph Modification: A Modern Perspective  New Developments in Exact Algorithms and Lower Bounds,  Pre-FSTTCS Workshop, IIT Delhi\n\n\n2014\nIterative Compression for FVS  IIIT Bangalore\n\n\n2014\nMax q-Colorable Induced Subgraph Problem on Perfect Graphs  Graph Modification Problems, Dagstuhl, Germany\n\n\n2012\nKernels for Planar F-Deletion  Data Reduction and Problem Kernels, Dagstuhl, Germany\n\n\n2012\nSeparators with Non-Hereditary Properties  Mini-Workshop on Logic, Proofs and Algorithms, VCLA\n\n\n2012\nFrom FVS to F-deletion: the Story of a Simple Algorithm  VCLA, Technical University of Vienna\n\n\n2012\nKernelization  Chennai Update Meeting on Parameterized Complexity,  Institute of Mathematical Sciences, Chennai\n\n\n2012\nConnected Dominating Set and Short Cycles  Indian Statistical Institute, Bangalore\n\n\n2011\nEfficient Simplification: Polynomial Time Revisited  Indian Institute of Science\n\n\n2010\nEfficient Simplification: The (im)possibilities  IMPECS School on Parameterized Complexity, Institute for Mathematical Sciences\n\n\n2010\nExpansions for Reductions  Workshop on Kernelization, Lorentz Center, Netherlands\n\n\n2010\nConnected Dominating Set and Short Cycles  Algorithms Seminar Series, University of Bergen, Norway\n\n\n2010\nLower Bounds on Kernelization  Chalmers University, Sweden\n\n\n2010\nIterative Compression: Try, try, till you succeed — or fail.  Kalasalingam University, Madurai, and Institute Seminar Week, The Institute of Mathematical Sciences"
  },
  {
    "objectID": "tgif/blue-eyed-islanders-puzzle/index.html",
    "href": "tgif/blue-eyed-islanders-puzzle/index.html",
    "title": "The Blue-Eyed Islanders",
    "section": "",
    "text": "This puzzle is variously attributed (including to “some dude on the street in Boston named Joel”), and was contributed by Manoj Gupta in our first meetup.\n\n\n\nYou can read up on a relatively standard version of the puzzle from Terrance Tao’s blog or here at XKCD.\nAkash proposed a variation where not everyone sees everyone, but people see each other via a graph. What goes on in such a setting? We don’t quite know!\nThe links have pointers to other variants and the blog also sparked a rather long discussion — enjoy thinking about this and looking things up!"
  },
  {
    "objectID": "tgif/look-and-see-sequence/index.html",
    "href": "tgif/look-and-see-sequence/index.html",
    "title": "Look and Say Sequence",
    "section": "",
    "text": "Source: Attributed to Conway.\n [Spoiler Alert] The problem is adapted from the Green Chicken Problems - November 15, 2014 – 36th Competition.\n\n\n\nConway’s see-and-say (or the look-and-say) sequence has fascinated people for years, and is a fun, non-standard example of a sequence. Starting with a_1 = 1, we define a_{n+1} as the sequence obtained by saying the previous sequence aloud. The first few terms are 1, 11 (one one), 21 (two ones), 1211 (one two, one one), 111221 (one one, one two, two ones), 312211 (three ones, two twos, one one).\nWe observe that the largest number in the 2023th term of this sequence is a 7, and coincidentally, 2023 is the 7th year of the Btech program in CSE at IITGN. This coincidence makes us very happy.\nHowever, is our observation correct?"
  },
  {
    "objectID": "tgif/cop-and-robber-on-the-number-line/index.html",
    "href": "tgif/cop-and-robber-on-the-number-line/index.html",
    "title": "Cop and Robber on a Number Line",
    "section": "",
    "text": "H/T to Ashutosh.\n\n\n\nAt time t = 0, a robber is at some point x on the number line. Over time, the robber moves at some uniform speed s to the left or the right from its starting position. There is a cop who can choose to be anywhere on the number line at any point of time. The cop cannot see the robber and does not know the initial location of the robber. The cop also knows nothing about the speed s and direction of movement.\nIf the cop and the robber occupy the same location at the same time instant, then the robber is said to be captured. Does the cop have a strategy to capture the robber in finite time?"
  },
  {
    "objectID": "tgif/estimating-pi/index.html",
    "href": "tgif/estimating-pi/index.html",
    "title": "Estimating Pi",
    "section": "",
    "text": "Sourced from Twitter on Pi Day (this also doubles up as a hint).\n\n\n\nTake two random numbers X and Y between 0 and 1.\nWhat is the probability that the integer nearest to X/Y is even?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\nFolks, here’s one way to reason why this probability should be (5 - pi)/4.Even if the math doesn’t appeal to you, please don’t miss the key lesson at the end! pic.twitter.com/IDEsQCuRVZ\n\n— 10-K Diver (@10kdiver) March 15, 2022"
  },
  {
    "objectID": "tgif/hat-puzzles/index.html",
    "href": "tgif/hat-puzzles/index.html",
    "title": "Hat Puzzles",
    "section": "",
    "text": "We discussed a variety of puzzles in the genre of hat puzzles, which roughly have following story arc:\n\na bunch of (not necessarily finite (!!!)) people are in a location\nall of them are wearing hats of one of c colors, typically c = 2 (we will assume that hats are either red or blue)\nnobody knows the color of their own hat\nfolks can see the colors of other’s hats (but not necessarily all of them; this depends on the setting)\neveryone is tasked with determining/guessing the color of their own hat, and failure to get it right (most of the time) will usually lead to unpleasant outcomes\n\nA traditional special case is the following:\n\nThere are n people standing on a line.\nEveryone can see the colors of the hats of everyone ahead of them.\nA strategy for how one’s own hat color is determined can be coordinated in advance.\nStarting from the person who can see everyone else (and their hats, more importantly), to the person at the end who sees nothing, everyone spells out their guess of the color of their own hat loudly and clearly for everyone else to hear. There is no communication between poeple other than this.\nAll but one person must figure out the color of their hat correctly.\n\n\n\n\n\n\n\nA Strategy for the Finite Case\n\n\n\n\n\nThe first person says “red” if the number of red hats s/he sees is even, and “blue” otherwise. This person may be mistaken about the color of their own hat. However, knowing the rationale for what the first person called out, the second can tally up parities to determine the color of their own hat (e.g, if the first person said red and the second person sees an even number of red hats, they conclude they are wearing a blue hat, otherwise they know they are wearing a read hat; and so on).\n\n\n\nA crazier version is the following:\n\nThere are infinitely many people in a room.\nEveryone can see the colors of the hats of everyone else, but not their own.\nNobody can hear anyone else’s guess.\nEveryone guesses simultaneously.\nIs there a strategy to ensure that infinitely many guesses are correct?\n[Level Up]: Is there a strategy to ensure that at most finitely many guesses are wrong?\n\nThis is fun to think about, and you’re probably going to have to invoke something something axiom of choice something something to tackle the situation! Spoiler Alert!"
  },
  {
    "objectID": "tgif/coming-to-agreement/index.html",
    "href": "tgif/coming-to-agreement/index.html",
    "title": "Coming to Agreement",
    "section": "",
    "text": "Puzzle by Joel David Hamkins.\n\n\n\nThis is apparently a logic puzzle that comes up in admission interviews at Oxford:\n\n\nAn Oxford University admissions interview question. You are a contestant on a game show, known for having perfectly logical contestants. There is another contestant, whom you've never met, but whom you can count on to be perfectly logical, just as logical as you are.\n\n— Joel David Hamkins (@JDHamkins) December 26, 2021\n\n\nThis puzzle has since been featured on the Guardian. The full setting is reproduced below from here. The source also has extended discussions about possible solutions — you have been warned!\nYou are a contestant on a game show, known for having perfectly logical contestants. There is another contestant, whom you’ve never met, but whom you can count on to be perfectly logical, just as logical as you are.\nThe game is cooperative, so either you will both win or both lose, together. Imagine the stakes are very high—perhaps life and death. You and your partner are separated from one another, in different rooms. The game proceeds in turns—round 1, round 2, round 3, as many as desired to implement your strategy.\nOn each round, each contestant may choose either to end the game and announce a color (any color) to the game host or to send a message (any kind of message) to their partner contestant, to be received before the next round. Messages are sent simultaneously, crossing in transit.\nYou win the game if on some round both players opt to end the game and announce a color to the host and furthermore they do so with exactly the same color. That is, you win if you both halt the game on the same round with the same color. lf only one player announces a color, or if both do but the colors don’t match, then the game is over, but you have lost.\nRound 1 is about to begin. What do you do?\nVariations:\nAlternation variation. In this variation of the puzzle, the contestants alternate in their right to send messages—only contestant 1 can send on round 1, then contestant 2 on round 2 and so forth, but still they aim to announce the same color on a round. You are contestant 1—what do you do?\nCollision variation. In this variation, players may opt on each round either to end the game and announce a color, to send a message, or to do nothing. But the new thing is that if both players opt to send a message, then the messages collide and are not delivered, although an error message is generated (so the players know what happened). What do you do?\nPigeon variation. This version is like the alternating turn variation, except that now the contestants are separated at much greater distance, and the messages are sent by carrier pigeon, so neither can be sure that the messages actually arrive. You are contestant 1—what do you do?"
  },
  {
    "objectID": "tgif/hexagon-tiling-with-diamonds/index.html",
    "href": "tgif/hexagon-tiling-with-diamonds/index.html",
    "title": "Tiling a Hexagon with Diamonds",
    "section": "",
    "text": "Source: the back cover of Mathematical Puzzles: A Connoisseur’s Collection Paperback, by Peter Winkler; and h/t to D. Sivakumar for the pointer!\n\n\n\nA large regular hexagon is cut out of a triangular grid and tiled with diamonds (pairs of triangles glued together along an edge). Diamonds come in three varieties, depending on orientation; prove that precisely the same number of each variety must appear in the tiling.\nHere’s the image demonstrating the grid and the individual tiles from the book cover:\n\n\n\nShowing the triangular grid\n\n\nOne attempt is to see if we can peel off layers using induction: the innermost hexagon in the partially color-coded image below corresponds to a base case of sorts; but it’s not clear how one might extend this approach — at least working with a c layers at a time for some constant c — since it’s not clear that every tiling can be split up as a combination of a complete tiling of c outermost layers and the rest.\n\n\n\nExample tiling\n\n\nTurns out that the image on the book’s front cover is a pretty cool hint!\n\n\n\nHint"
  },
  {
    "objectID": "tgif/deaths-dice/index.html",
    "href": "tgif/deaths-dice/index.html",
    "title": "Death’s Dice",
    "section": "",
    "text": "Sourced from @3blue1brown’s Twitter.\n\n\n\n\n\nI'd like to tell you about a game/puzzle to help celebrate today.We'll call it \"Death's Dice\". (1/9) pic.twitter.com/6lportLU9V\n\n— Grant Sanderson (@3blue1brown) March 14, 2022\n\n\nA spoiler-free version of the thread above is reproduced below:\nDeath finds you. You plead with him that it’s too soon, and he agrees to a concession. Every year, he’ll roll a set of dice, and if it turns up snake eyes (both 1’s) he’ll take your life, otherwise, you get one more year.\nBut it’s not necessarily a normal pair of dice.\nOn the first year, both “dice” will only have two sides, numbered 1 and 2. So in that first year, there’s a 25% chance of rolling snake eyes and ending things there.\nOn the second year, he comes with tetrahedral dice, i.e. both are four-sided, numbered 1 through 4, and again only takes your life if he rolls two 1’s.\nThe next year, the dice are six-sided, after that, eight-sided, etc., etc.\nEach year you have a lower and lower chance of dying, but he’ll come back every year with a new set of dice, never stopping.\nYou might think the question now is something like “what’s your expected number of remaining years of life?”\nBut actually, Death gave you a pretty good deal.\nThe better question to ask here is “what’s the probability that you end up immortal?” That is, the probability that Death rolls infinitely many times, with his ever-growing dice, and never once turns up snake eyes.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\n\n\nAn image that shows a square circumscribed inside a circle."
  },
  {
    "objectID": "tgif/minimizing-area/index.html",
    "href": "tgif/minimizing-area/index.html",
    "title": "Minimizing Area",
    "section": "",
    "text": "Source: The second problem in this video.\n\n\n\nThere is a rectangle and a path that goes from the bottom-left corner to the top-right. The path can only move upwards or towards the right. Draw a vertical line L through the rectangle. Now look at the area under the curve to the left of L, and the area above the curve to the right of L. Call this total area A_L. In the example figure below, L is the dotted line and A_L is the shaded area.\n\n\n\nArea associated with the path and a line L.\n\n\nWhat is the line L that minimizes A_L?"
  },
  {
    "objectID": "tgif/windmill/index.html",
    "href": "tgif/windmill/index.html",
    "title": "Windmill",
    "section": "",
    "text": "Source: IMO 2011, C3\n\n\n\n\n\n\nA hard puzzle with a beautiful solution.\n\n\n\n\nThe Problem\n\nLet \\mathcal{S} be a finite set of at least two points in the plane. Assume that no three points of \\mathcal{S} are collinear. By a windmill we mean a process as follows. Start with a line \\ell going through a point P \\in \\mathcal{S}. Rotate \\ell clockwise around the pivot P until the line contains another point Q of \\mathcal{S}. The point Q now takes over as the new pivot. This process continues indefinitely, with the pivot always being a point from \\mathcal{S}.\nShow that for a suitable P \\in \\mathcal{S} and a suitable starting line \\ell containing P, the resulting windmill will visit each point of \\mathcal{S} as a pivot infinitely often.\n\n Spoiler: a neat 3blue1brown video and lesson on the solution."
  },
  {
    "objectID": "tgif/ab-separation/index.html",
    "href": "tgif/ab-separation/index.html",
    "title": "AB Separation",
    "section": "",
    "text": "Shared by @10kdiver.\n\n\n\nA probability puzzle involving tournaments and elimination matches:\n\n\nHere’s a neat probability puzzle — somewhat counter-intuitive: pic.twitter.com/QA6jxaIYFT\n\n— 10-K Diver (@10kdiver) September 23, 2022\n\n\nTo begin with, a clarification: to say that Alex is the best player is to say that Alex will always win a match that he plays; and to say that Bob is the second best player is to say that Bob will win any match that he plays other than one against Alex. The puzzle asks for the probability that Bob emerges the runner up in the tournament. This is indicated in the tweet but the crop seems to hide it.\nSuppose we denote the players \\{a_1,a_2,a_3,a_4,b_1,b_2,b_3,b_4\\}, and say the players are initially matched up like so:\n(a_1,a_2); (a_3,a_4); (b_1,b_2); (b_3,b_4),\nand in particular we have:\n\none of the quarter finals will be between a_p and a_q for p \\in \\{1,2\\} and q \\in \\{3,4\\},\nthe quarter finals will be between b_r and b_s for r \\in \\{1,2\\} and s \\in \\{3,4\\}, and\nthe semi finals will be between an a-player and a b-player.\n\nA moment’s reflection reveals that for Bob to be a runner up, he should not meet Alex in the quarter-finals or earlier. This happens if and only if:\n\neither Alex is one of the a-players and Bob is one of the b-players, or\nBob is one of the a-players and Alex is one of the b-players.\n\nFrom here it is a counting argument. I was distracted by some idea of symmetry and originally jumped to the conclusion that the answer is one-half. Spoiler alert: I quickly learned that it’s not!"
  },
  {
    "objectID": "tgif/index.html",
    "href": "tgif/index.html",
    "title": "Puzzles from the TGIF Group",
    "section": "",
    "text": "This page chronicles puzzles that get shared in the TGIF Puzzle Group, an informal group of puzzle enthusiasts that meets on Fridays at IITGN. Even if you are not at IITGN, you’re welcome to join the discussions over at our Discord server! You can also subscribe to a feed for this series by clicking here.\nThe easiest way to contribute a puzzle to this list is to hop over the Discord server and post it, but you can also drop me a line at mail -AT- neeldhara.com if you prefer.\nTo filter by tags, enter one of the following in the search box:\nprobability • logic • paper • folding • cutting • tiling • graphs • game • chess • geometry\n\n\n\n\n \n\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n    \n        \n        \n            13 Jan, 2023        \n        \n        \n            Look and Say Sequence     \n        \n        \n            \n                    logic  \n            \n                \n                \n\n        \n        \n            06 Jan, 2023        \n        \n        \n            Tiling a Hexagon with Diamonds     \n        \n        \n            \n                    tiling  \n            \n                \n                \n\n        \n        \n            01 Jan, 2023        \n        \n        \n            Cop and Robber on a Number Line     \n        \n        \n            \n                    game  \n            \n                \n                \n\n        \n        \n            01 Jan, 2023        \n        \n        \n            Points and Lines     \n        \n        \n            \n                    geometry  \n            \n                \n                \n\n        \n        \n            10 Dec, 2022        \n        \n        \n            Minimizing Area     \n        \n        \n            \n                    geometry  \n            \n                \n                \n\n        \n        \n            28 Oct, 2022        \n        \n        \n            To Not Checkmate     \n        \n        \n            \n                    chess  \n                    game  \n            \n                \n                \n                \n\n        \n        \n            28 Oct, 2022        \n        \n        \n            HoneyBee Puzzle     \n        \n        \n            \n                    game  \n            \n                \n                \n\n        \n        \n            14 Oct, 2022        \n        \n        \n            Windmill     \n        \n        \n            \n                    geometry  \n            \n                \n                \n\n        \n        \n            14 Oct, 2022        \n        \n        \n            Burning Island     \n        \n        \n            \n                    logic  \n            \n                \n                \n\n        \n        \n            07 Oct, 2022        \n        \n        \n            Hat Puzzles     \n        \n        \n            \n                    logic  \n            \n                \n                \n\n        \n        \n            07 Oct, 2022        \n        \n        \n            AB Separation     \n        \n        \n            \n                    probability  \n            \n                \n                \n\n        \n        \n            07 Oct, 2022        \n        \n        \n            Folding Stamps     \n        \n        \n            \n                    folding  \n                    paper  \n            \n                \n                \n                \n\n        \n        \n            07 Oct, 2022        \n        \n        \n            Making Grids     \n        \n        \n            \n                    tiling  \n            \n                \n                \n\n        \n        \n            07 Oct, 2022        \n        \n        \n            Iwahiro's Square in Bag Puzzle     \n        \n        \n            \n                    folding  \n                    paper  \n            \n                \n                \n                \n\n        \n        \n            25 Mar, 2021        \n        \n        \n            Turn the LED on     \n        \n        \n            \n                    probability  \n            \n                \n                \n\n        \n        \n            25 Mar, 2021        \n        \n        \n            4 Person Gift Exchange     \n        \n        \n            \n                    probability  \n            \n                \n                \n\n        \n        \n            23 Mar, 2021        \n        \n        \n            Conway's Checkers     \n        \n        \n            \n                    game  \n            \n                \n                \n\n        \n        \n            23 Mar, 2021        \n        \n        \n            Coin Tossing     \n        \n        \n            \n                    probability  \n            \n                \n                \n\n        \n        \n            15 Mar, 2021        \n        \n        \n            Estimating Pi     \n        \n        \n            \n                    probability  \n            \n                \n                \n\n        \n        \n            15 Mar, 2021        \n        \n        \n            Coming to Agreement     \n        \n        \n            \n                    logic  \n            \n                \n                \n\n        \n        \n            15 Mar, 2021        \n        \n        \n            Death's Dice     \n        \n        \n            \n                    probability  \n            \n                \n                \n\n        \n        \n            14 Mar, 2021        \n        \n        \n            Find The Puppy     \n        \n        \n            \n                    logic  \n                    game  \n            \n                \n                \n                \n\n        \n        \n            11 Mar, 2021        \n        \n        \n            The Blue-Eyed Islanders     \n        \n        \n            \n                    logic  \n            \n                \n                \n\n        \n        \n            11 Mar, 2021        \n        \n        \n            Lighting Up a Grid     \n        \n        \n            \n                    graphs  \n            \n                \n                \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tgif/turn-the-led-on/index.html",
    "href": "tgif/turn-the-led-on/index.html",
    "title": "Turn the LED on",
    "section": "",
    "text": "Contributed by @10kdiver.\n\n\n\nAnother fun probability puzzle:\n\n\nEach switch has a 50/50 chance of being ON or OFF.The switches are all independent of each other.What’s the probability that the LED is on? pic.twitter.com/idQnJRqFnL\n\n— 10-K Diver (@10kdiver) March 25, 2022"
  },
  {
    "objectID": "tgif/conways-checkers/index.html",
    "href": "tgif/conways-checkers/index.html",
    "title": "Conway’s Checkers",
    "section": "",
    "text": "Puzzle attributed to John Horton Conway.\n\n\n\nSuppose you take the infinite square lattice and put solitaire pieces on all points (x,y) that lie on or below the x-axis. Using solitaire moves, can you reach a position where the point (0,5) is occupied?\nNote: A solitaire move consists in a piece jumping over a neighbouring piece to a vacant square and removing (or “taking”) the neighbouring piece.\nYou can attempt this challenge interactively here.\nHint: if you can’t get there, don’t feel too bad about it.\n\n\n\n\n\n\nSpoilers\n\n\n\n\n\nAn introduction to the problem featuring Zvezdelina Stankova:\n\n\nA description of the original proof based on coming up with an invariant involving the golden ratio:\n\n\nA description of the original proof based on coming up with an invariant involving the golden ratio, but in this case in real-time, while thinking out loud:\n\n\nA description of a more recent proof based on a rather clever and beautiful use of Fibonacci numbers:\n\n\nAnd by the way, if you are really keen on reaching row 5 here’s how you can do it with infinitely many moves!"
  },
  {
    "objectID": "tgif/4-person-gift-exchange/index.html",
    "href": "tgif/4-person-gift-exchange/index.html",
    "title": "4 Person Gift Exchange",
    "section": "",
    "text": "This puzzle by Professor Henk Tijms was contributed by @10kdiver.\n\n\n\nFirst the warm-up edition.\n\n\nHere's a beautiful probability puzzle inspired by Professor Henk Tijms (@Hendrikc44).See if you can solve it. The answer may surprise you!(I'll post a solution tomorrow.) pic.twitter.com/m1c8u0J5MN\n\n— 10-K Diver (@10kdiver) March 23, 2022\n\n\nNow for the harder version.\n\n\n\n\n\n\n\n\n\n\nA number of people will exchange gifts at a holiday party. Each person brings a gift to the party and attaches a label with a unique number to this gift. These numbers are also put on cards, which are deposited in a box and shuffled. Each person at the party then sequentially draws a card from the box, and receives the gift whose label corresponds to the number on the card drawn. If the number corresponds to his or her own gift, the card is returned to the box and the person draws another card. Of course, it is not possible for the last person to draw a second card.\nWhat is the probability that the last person is left with the card corresponding to his or her own present? In the simple case of two people, the probability is zero. The problem is also easy to solve in the case of three people, using a chance tree. It is no restriction to imagine that the persons are numbered as 1, 2 and 3 like the labels of their presents, and that they draw a card in this order. Then person 1 gets either the present with label 2 or the present with label 3, each with a probability of 1/2. If person 1 gets the present with label 3, then the conditional probability of the last person 3 to get his or her own present is zero. If person 1 gets the present with label 2, then the cards with labels 1 and 3 are left and person 2 draws the card with label 1 with probability of 1/2, in which case the last person 3 is left with the card of his or her own present. Therefore the probability that the last person will be left with the card of his or her own present is ½ × 0 + ½ × ½ = ¼.\nThe challenges for this week are these: What is the probability that the card left for the last person corresponds to his or her own present when there are four people at the party? What is the probability when there are five people at the party?\n\n\nSource NB. may be paywalled"
  },
  {
    "objectID": "tgif/folding-stamps/index.html",
    "href": "tgif/folding-stamps/index.html",
    "title": "Folding Stamps",
    "section": "",
    "text": "Source: Dave Richeson @divbyzero and Henry Dudeny.\n\n\n\nThe following is perhaps best attempted with a physical prop.\n\n\nYesterday's puzzles seem to be a hit, so here's another one, due to Henry Dudeny. Fold the paper so the squares end up in numerical order (1 on top, 8 on bottom, sequential in between, not necessarily \"face up\" in the stack, as shown). The first one is easier than the second. pic.twitter.com/oRGXl90mKp\n\n— Dave Richeson (@divbyzero) October 5, 2022\n\n\n\n\n\n\n\n\nHere’s a bit from the original source:\n\n\n\n\n\n\n\n\nScreenshot of a text containing the original problem"
  },
  {
    "objectID": "tgif/making-grids/index.html",
    "href": "tgif/making-grids/index.html",
    "title": "Making Grids",
    "section": "",
    "text": "Source: @algopuzzles and Micheal Brand.\n\n\n\nThis is a tiling puzzle:\n\n\nA tiling problem with wireframes. [Source: Micheal Brand]. #exportober pic.twitter.com/vhhoc0OB9C\n\n— Algorithmic Puzzles (@algopuzzles) October 7, 2022\n\n\nThe lines cannot overlay, I imagine. Here’s a valid looking 2 x 2:\n\n\n\nA 2 x 2 grid made from the given wireframe.\n\n\nMore soon on this as the story develops!"
  },
  {
    "objectID": "tgif/coin-tossing/index.html",
    "href": "tgif/coin-tossing/index.html",
    "title": "Coin Tossing",
    "section": "",
    "text": "Contributed by Monali Shah on the Discord Server.\n\n\n\nSuppose you were to keep flipping a coin until it landed either HTHHT or HHHHH on five consecutive flips. Which of these two sequences would you predict would occur first?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSee here. Also, a shorter sequence (HTT vs HTH) but with a similar element of surprise is explained also in this TED Talk:"
  },
  {
    "objectID": "tgif/find-the-puppy/index.html",
    "href": "tgif/find-the-puppy/index.html",
    "title": "Find The Puppy",
    "section": "",
    "text": "Contributed by Debanuj Nayak.\n\n\n\nThere are 5 boxes with lids kept in a row.\n[] [] [] [] []\nLet’s call them B[1…5].\nThere is a puppy P inside one of these boxes.\nOur goal is to find the puppy.\n[?] [?] [?] [?] [?]\nEvery morning you get a chance to open any one of the boxes. If you find the puppy: great, congrats!\nIf you don’t, tough luck, you have to wait again for the next day. Meanwhile, during the night, the Puppy will move to one of the neighbouring boxes.(can’t stay in same box). Eg:\n[] [P] [] [] [] -> [P] [] [] [] [] or [] [] [P] [] [].\n\nDoes there exist protocols (ways of opening boxes) in which I can guarantee that I can catch the puppy in a finite time?\nIf yes, what is the smallest number of days I have to wait to catch the puppy (Which is the best protocol?)\nHow does this protocol work?\n\n\n\n\n\n\n\nSpoilers: based on our discussion in the second TGIF meetup.\n\n\n\n\n\nHere’s a strategy that uses seven days (h/t: Harshil).\nMorning 1: Open Box 2. If it contains P, we are done. Otherwise, P is in one of Box 1,3,4 or 5.\nMorning 2: Open Box 2. If it contains P, we are done. Otherwise, P is in one of Box 3,4 or 5.\nMorning 3: Open Box 3. If it contains P, we are done. Otherwise, P is in one of Box 2,4 or 5.\nMorning 4: Open Box 4. If it contains P, we are done. Otherwise, P is in one of Box 1,3 or 5.\nMorning 5: Open Box 4. If it contains P, we are done. Otherwise, P is in Box 2.\nMorning 6: Open Box 3. If it contains P, we are done. Otherwise, P is in Box 1.\nMorning 7: Open Box 2. It definitely contains P.\n\nHere’s a strategy that uses six days (h/t: Debanuj):\nFirst Observation: The puppy P alternates between odd and even boxes\nSecond Observation: The puppy P only has one possible choice to go to, if it is in Box 1 or Box n\nLet us assume that P is in an even box i.e. B[2] or B[4] on the first morning.\nMorning 1: Check B[2], if you find P, done. Otherwise, according to the assumption, P is in B[4]\nNight 1: P moves to B[3] or B[5]\nMorning 2: Check B[3], if you find P, done. Otherwise P is in B[5] according to initial assumption.\nNight 2: P moves to B[4], no other choice.\nMorning 3: Check B[4]. If assumption was true, then P must be in B[4]. If you find P, done. If you don’t find P, that means initial assumption was false.\nThus on morning 1, P was in an odd box ⇒ on morning3 (today), P is again in an odd box. Which means tomorrow (morning 4), P must be in an even box.\nNight 3: P moves to B[2] or B[4]\nMorning 4: Now our assumption holds true that P is in an even box, and now you can repeat the procedure we followed on mornings 1,2,3 again on mornings 4,5,6 and we are guaranteed to catch P.\n\n\n\nUnresolved questions:\n\nCan we do this in five days? Or can we show that it’s impossible to come up with a protocol that uses only five days?\nWhat about six boxes? Or seven? Or n?\nIf the moves are equiprobable and the initial choice is uniformly random, what is the expected number of moves executed by either of the strategies above?\nHow much faster can we do this if we are allowed to open two boxes at once?\nQuestion from Bireswar: If the puppy is allowed to stay put, then there’s no protocol to find the puppy even in the trivial setting with two boxes. What if we are allowed to open more than one box? How many more boxes do we need to be able to open per day to catch a potentially non-moving puppy amongst five boxes?"
  },
  {
    "objectID": "tgif/square-in-bag/index.html",
    "href": "tgif/square-in-bag/index.html",
    "title": "Iwahiro’s Square in Bag Puzzle",
    "section": "",
    "text": "Source: Dave Richeson @divbyzero.\n\n\n\nHere’s a very fun packing puzzle.\n\n\nOne of my all-time favorite puzzles: Iwahiro's \"Square in a Bag\" puzzle. Put a square piece of paper (14 cm x 14 cm) completely inside a bag (20 cm x 11 cm) without folding, cutting, or rolling up the paper; it should end up lying completely flat. pic.twitter.com/nGv2TwR8Wp\n\n— Dave Richeson (@divbyzero) October 4, 2022\n\n\nWhen we discussed this in the meetup, it was a little hard to describe what’s allowed and what’s not with the bag. Another thing that was important to emphasize is the side of the bag that is open: I am not sure this is even possible if the bag is sealed on both the long sides and only the short side is the one that is open.\nA quick sanity check with respect to surface areas reassures us of the potential feasibility of the task: the total surface area of the square is indeed smaller than the surface area of the bag. So if you imagine cutting the bag along the short sides, and using it as a gift wrap to cover up the square, that’s very much doable.\nThe other hint was the fact that the length of the diagonal of the square is less than the length of the longer side of the bag. This prompts us to line up the square so that it’s opposite corners align with the long and open edge of the bag.\n\n\n\n\n\n\nSpoiler Alert\n\n\n\n\n\nThe solution does indeed involve starting here and squishing the bag gradually so that it engulfs the square. Here’s a nice video demonstration:\n\n\n\n\n\nWe did wonder about formalizing the question and the process above a little more, but we were not able to come up with any appropriate language. At least as an activity-based puzzle I think the instructions are quite clear:\n\n\nAh. The bag can stretch and fold as much as any ordinary kitchen bag can. And for that matter, the paper can warp and bend as you'd expect it would. But in the end everything will end up flat on the tabletop.\n\n— Dave Richeson (@divbyzero) October 7, 2022\n\n\nIt would be nice to be come up with a procedure that, given the dimensions of the square and the bag, can determine if the square can in fact be accommodated in the bag playing by the rules here. Already here, it was pointed out later that it would have worked with a slightly smaller bag too, and at least for the purpose of getting to this particular solution, all that matters is the proportions of the side lengths.\nIt might also be interesting to think about what happens with other combinations of shapes."
  },
  {
    "objectID": "tgif/to-not-checkmate/index.html",
    "href": "tgif/to-not-checkmate/index.html",
    "title": "To Not Checkmate",
    "section": "",
    "text": "Curious puzzle by Karl Fabel. White to move and not checkmate:\n\n\n\nChessboard Position"
  },
  {
    "objectID": "tgif/burning-island/index.html",
    "href": "tgif/burning-island/index.html",
    "title": "Burning Island",
    "section": "",
    "text": "Source: Math is Fun\n\n\n\n\n\n\nThis is arguably a logic puzzle, in that the solution does not involve any calculation/geometry even though the statement might suggest it.\n\n\n\nA man is stranded on an island covered in forest.\nOne day, when the wind is blowing from the west, lightning strikes the west end of the island and sets fire to the forest. The fire is very violent, burning everything in its path, and without intervention the fire will burn the whole island, killing the man in the process.\nThere are cliffs around the island, so he cannot jump off.\nHow can the man survive the fire? (There are no buckets or any other means to put out the fire)"
  },
  {
    "objectID": "tgif/honeybee-riddle/index.html",
    "href": "tgif/honeybee-riddle/index.html",
    "title": "HoneyBee Puzzle",
    "section": "",
    "text": "Source: TedEd.\n\n\n\nHere’s the premise:\n\nYou’re a biologist on a mission to keep the rare honeybee Apis Trifecta from going extinct. The last 60 bees of the species are in your terrarium. You’ve already constructed wire frames of the appropriate size and shape. Now you need to turn them into working beehives by filling every hex with wax. Can you help the bees create producing hives? Dan Finkel shows how.\n\nThis is very reminiscent of the puzzle about lighting up a grid. The main difference here appears to be that the structure of the base grid is hexagonal, as opposed to being a square grid."
  },
  {
    "objectID": "tgif/points-and-lines/index.html",
    "href": "tgif/points-and-lines/index.html",
    "title": "Points and Lines",
    "section": "",
    "text": "H/T to Ashutosh.\n [Spoiler Alert] This turns out to be a well-known theorem.\n\n\n\nShow that every finite set of points in the Euclidean plane has a line that passes through exactly two of the points or a line that passes through all of them."
  },
  {
    "objectID": "tgif/lighting-up-a-grid/index.html",
    "href": "tgif/lighting-up-a-grid/index.html",
    "title": "Lighting Up a Grid",
    "section": "",
    "text": "This puzzle was sourced from an @algopuzzles tweet.\n\n\n\nHere’s the puzzle:\n\n\nOn an nxn grid a few nodes are set on fire at t=0. The fire spreads like this: if at least two neighboring nodes of node x are lit, then node x will also catch fire in the next time step. What's the minimum number of nodes that have to be lit to burn the entire grid?#exportober\n\n— Algorithmic Puzzles (@algopuzzles) October 18, 2021\n\n\n\n\n\n\n\n\nHere’s an argument for the lower bound by Harshil Mittal.\n\n\n\n\n\nConsider an arbitrary but fixed solution. Let p denote the number of nodes that are lit up at time 0. Let T denote the time taken to lit the entire grid. WLOG, assume that for each 1 \\leq t \\leq T, exactly one new node is lit up at time t.\nAt any time 0 \\leq t \\leq T,\n\nFor every lit node (i,j), let f(i,j,t) denote the number of edges of the node (i,j) that are not shared with another lit node.\nLet g(t) denote the sum of f(i,j,t) over all lit nodes (i,j)\n\nWe show that g(t+1) \\leq g(t) for all 0 \\leq t \\leq T-1.\nLet 0 \\leq t \\leq T-1. Let (u,v) denote the new node which is lit up at time t+1. Let X denote the set of all lit neighbors of (u,v) at time t. For every node (i,j) in X, we have f(i,j,t+1) = f(i,j,t) - 1. Also, note that f(u,v,t+1) = 4-|X|. Therefore, g(t+1) = g(t) - |X| + (4-|X|) = g(t) + 4-2|X|. So, as |X| \\geq 2, we get g(t+1) \\leq g(t).\nNow, we have 4n = g(T) \\leq g(0) \\leq 4p. Thus, n \\leq p, as desired."
  },
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "Archive",
    "section": "",
    "text": "Note Taking Resources\n\n\n\n\n\n\n\n\n\nJun 2, 2023\n\n\n\n\n\n\n\n\nOn Career Choices\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\n\n\n\n\n\n\nLetting Go\n\n\n\n\n\n\n\n\n\nMay 11, 2023\n\n\n\n\n\n\n\n\nCourse Plan Generator\n\n\n\n\n\n\n\n\n\nApr 25, 2023\n\n\n\n\n\n\n\n\n13 Sheep\n\n\n\n\n\n\n\n\n\nMar 26, 2023\n\n\n\n\n\n\n\n\nLetters with Pandoc\n\n\n\n\n\n\n\n\n\nNov 27, 2022\n\n\n\n\n\n\n\n\nThe Only Fair Ranking of IITs\n\n\n\n\n\n\n\n\n\nNov 24, 2022\n\n\n\n\n\n\n\n\nExportober 2022\n\n\n\n\n\n\n\n\n\nOct 7, 2022\n\n\n\n\n\n\n\n\nExternal Communications\n\n\n\n\n\n\n\n\n\nSep 23, 2022\n\n\n\n\n\n\n\n\nSKJ\n\n\n\n\n\n\n\n\n\nSep 23, 2022\n\n\n\n\n\n\n\n\nDog Bunny Puzzle\n\n\n\n\n\n\n\n\n\nSep 19, 2022\n\n\n\n\n\n\n\n\nOn Teaching\n\n\n\n\n\n\n\n\n\nSep 5, 2022\n\n\n\n\n\n\n\n\nSolo Chess\n\n\n\n\n\n\n\n\n\nMar 24, 2022\n\n\n\n\n\n\n\n\nEight Self-Sabotaging Behaviors\n\n\n\n\n\n\n\n\n\nMar 15, 2022\n\n\n\n\n\n\n\n\nKidney Exchanges\n\n\n\n\n\n\n\n\n\nFeb 25, 2022\n\n\n\n\n\n\n\n\nWomen in Mathematics\n\n\n\n\n\n\n\n\n\nFeb 21, 2022\n\n\n\n\n\n\n\n\nOn the Communication Complexity of Equality\n\n\n\n\n\n\n\n\n\nOct 4, 2021\n\n\n\n\n\n\n\n\nTwo approaches to the 15 puzzle\n\n\n\n\n\n\n\n\n\nOct 3, 2021\n\n\n\n\n\n\n\n\nSam I Am\n\n\n\n\n\n\n\n\n\nOct 1, 2021\n\n\n\n\n\n\n\n\nNew Mac\n\n\n\n\n\n\n\n\n\nSep 30, 2021\n\n\n\n\n\n\n\n\nExportober 2021\n\n\n\n\n\n\n\n\n\nSep 25, 2021\n\n\n\n\n\n\n\n\nAbout Exportober\n\n\n\n\n\n\n\n\n\nSep 24, 2021\n\n\n\n\n\n\n\n\nMoving Blocks at CTIS 2021\n\n\n\n\n\n\n\n\n\nSep 21, 2021\n\n\n\n\n\n\n\n\nAn Invitation to Exportober 2021\n\n\n\n\n\n\n\n\n\nSep 19, 2021\n\n\n\n\n\n\n\n\nEnvelope Budgeting with Notion\n\n\n\n\n\n\n\n\n\nSep 18, 2021\n\n\n\n\n\n\n\n\nActually Building a Website with Notion\n\n\n\n\n\n\n\n\n\nSep 12, 2021\n\n\n\n\n\n\n\n\nNotion-powered websites\n\n\n\n\n\n\n\n\n\nSep 11, 2021\n\n\n\n\n\n\n\n\nMassren for fast file renaming\n\n\n\n\n\n\n\n\n\nSep 11, 2020\n\n\n\n\n\n\n\n\nBuilding a first Django App\n\n\n\n\n\n\n\n\n\nJun 12, 2018\n\n\n\n\n\n\n\n\nDad\n\n\n\n\n\n\n\n\n\nAug 27, 2012\n\n\n\n\n\n\n\n\nOn the Fence\n\n\n\n\n\n\n\n\n\nApr 23, 2012\n\n\n\n\n\n\n\n\nSprinkles of the Sky\n\n\n\n\n\n\n\n\n\nJan 5, 2011\n\n\n\n\n\n\n\n\nHow Expensive Can Homework Help Be?\n\n\n\n\n\n\n\n\n\nMay 1, 2010\n\n\n\n\n\n\n\n\nSeek\n\n\n\n\n\n\n\n\n\nApr 3, 2007\n\n\n\n\n\n\n\n\nBloom\n\n\n\n\n\n\n\n\n\nFeb 3, 2005\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neeldhara",
    "section": "",
    "text": "Visualizing Baranyai’s theorem for the case when n=2.\n\n\n\n\n\n\nSmt. Amba and Sri. V S Sastry Chair Associate ProfessorComputer Science and Engineering at IIT Gandhinagar(she/her)\n\n \n\nBlog ⸱ Mastodon ⸱ DBLP ⸱ Contact\n\n \n\nMy broad research interests include — in no particular order: algorithm design, computational social choice, combinatorial games. You can find out more about my work here.\n\n \n\nRecent PCs: FUN 2022, MFCS 2022, IPEC 2022, Compute 2022, CALDAM 2023, IPEC 2023 (co-chair with Magnus Wahlström)"
  },
  {
    "objectID": "index.html#latest-news",
    "href": "index.html#latest-news",
    "title": "Neeldhara",
    "section": "Latest News",
    "text": "Latest News\n\n\n    \n        \n        \n        \n        \n        \n        Finding Perfect Matching Cuts Faster |  Mar 27, 2023\n        \n        \n        \n        \n        \n        Joint work with Yash More ⸱ To Appear at IWOCA 2023 ⸱ Preprint coming soon!\nA cut (X,Y) is a perfect matching cut if and only if each vertex in X has exactly one neighbor in Y and each vertex in Y has exactly one neighbor in X. The computational problem of determining if a graph admits a perfect matching cut is NP-complete, even when restricted to the class of bipartite graphs of maximum degree 3 and arbitrarily large girth. We demonstrate a faster exact exponential time algorithm on general graphs and an even faster algorithm on graphs of maximum degree three that have girth six.\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        CompEd 2023 Dates Announced |  Mar 24, 2023\n        \n        \n        \n        \n        \n        CompEd will be held between December 7-9, 2023, at Hyderabad, India. Check out the call for participation! The deadline for submitting abstracts is Sunday, 7 May.\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        IPEC 2023 Dates Announced |  Mar 20, 2023\n        \n        \n        \n        \n        \n        The International Symposium on Parameterized and Exact Computation (IPEC) is an annual conference covering all aspects of parameterized and exact algorithms and complexity. Its 18th edition will be part of ALGO 2023, which also hosts ESA 2023 and other specialized conferences and workshops. We are excited that ALGO 2023 is planned as an in-person conference and we look forward to seeing you there! ALGO will be held between September 4-8, 2023, at Amsterdam, the Netherlands.\nDo submit your best work to IPEC 2023 --- the abstract submission deadline is June 27th (23:59 AoE).\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        NASI Platinum Jubilee Young Scientist Award |  Jan 5, 2023\n        \n        \n        \n        \n        \n        Recieved the NASI Platinum Jubilee Young Scientist Award. Most grateful to all collaborators and mentors who make this recognition possible.\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        INYAS Membership |  Jan 1, 2023\n        \n        \n        \n        \n        \n        INYAS is the Young Science Academy established by Indian National Science Academy (INSA). Their work in science outreach and popularization has been wide-ranging and very inspiring over the years. It is wonderful and humbling to have been selected as a member this year. Looking forward to pitching in!\n\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        ACM-India CSEd Workshop |  Dec 25, 2022\n        \n        \n        \n        \n        \n        We recently concluded the CSEd Workshop with support from ACM India, NPTEL, and the discipline of CSE at IIT Gandhinagar. The workshop featured talks by Sonia Garcha, Viraj Kumar, Venkatesh Choppella, and N S Kumar. The talks covered various themes, including CSPathshala, refute questions, mapcode, and key takeaways to convey in a data structures course.\nThe materials from the course (including video recordings and slides) can be accessed from here.\n        \n        \n    \n    \n        \n        \n        \n        \n        \n        A Proud Carmelite! |  Dec 15, 2022\n        \n        \n        \n        \n        \n        Mount Carmel College (in Bangalore), my alma mater, is celebrating its Platinum Jubilee this year. A part of this celebration is HERSTORY: \"75 years of scripting success stories of Confident, Competent, & Compassionate Carmelites\".\nI was honored to be among the 75 Carmelites invited for the HERSTORY event today. It was very nostalgic to be back on campus, and the organizers put together an impeccable event that made all of us feel very special. It was humbling to be in inspiring company. I can't thank MCC enough for providing an empowering and fun environment at a crucial stage of my life!\n        \n        \n    \n\n\nNo matching items\n\n\n  \n\n\n All News"
  },
  {
    "objectID": "index.html#latest-posts",
    "href": "index.html#latest-posts",
    "title": "Neeldhara",
    "section": "Latest Posts",
    "text": "Latest Posts\n\n\n\n    \n        \n        \n            02 Jun, 2023        \n        \n        \n            Note Taking Resources     \n        \n        \n                lists\n                \n\n        \n        \n            26 May, 2023        \n        \n        \n            On Career Choices     \n        \n        \n                funda\n                \n\n        \n        \n            11 May, 2023        \n        \n        \n            Letting Go     \n        \n        \n                poem\n                \n\n        \n        \n            25 Apr, 2023        \n        \n        \n            Course Plan Generator     \n        \n        \n                workflow\n                \n\n        \n        \n            26 Mar, 2023        \n        \n        \n            13 Sheep     \n        \n        \n                games\n                exposition\n                \n\n        \n        \n            27 Nov, 2022        \n        \n        \n            Letters with Pandoc     \n        \n        \n                pandoc\n                workflows\n                latex\n                \n\n        \n        \n            24 Nov, 2022        \n        \n        \n            The Only Fair Ranking of IITs     \n        \n        \n                funda\n                \n\n\n\n\nNo matching items\n\n\n  \n\n\n All Posts"
  },
  {
    "objectID": "blog/building-websites-with-notion/index.html",
    "href": "blog/building-websites-with-notion/index.html",
    "title": "Actually Building a Website with Notion",
    "section": "",
    "text": "My attempted overview of options for making websites with Notion does not go into the mechanics of how to setup a site with Notion, so I’m going to post a couple of short walkthroughs of the process here. I’ll demonstrate with both Super and Potion. For Super, I’ll share how I setup my course catalog. With Potion, a natural choice would have been to take you behind the scenes of this blog, but this did involve a little bit of customization that might be a bit distracting, so I’ll just make something quick from scratch for this post.\n\n\nDoesn't look like it's for non-geeks like me 😄 or you may prove otherwise. However, if you can record a 10 min video setting up a basic one, that'll have a greater impact, I believe, if it's already not there.\n\n— Swaprava Nath (@swaprava) September 12, 2021\n\n\n\n\nThe Overall Process\nFor either framework, this is typically a three-step process:\n\nSetup your content in Notion. You can start from scratch, or use one of the templates provided by Super or Potion that feel like a closest match to what you want your website to eventually look like.\nEnable sharing to the web from within Notion — this will generate a link for you.\nCopy this link into Super or Potion.\n\nAt the end of step 2, in fact, you already have a URL that you can share with anyone and, depending on how the content is laid out in Notion, can already look like a decent website.\nWhat step 3 allows you to do, however is:\n\nAdd some styling with CSS.\nAdd custom code snippets (useful, for example, if you want to add things like Google Analytics).\nBe assured that the webpage is good in terms of SEO, performance, etc.\nIf using Super, you can selectively password-protect pages (coming soon to Potion, where you can presently password-protect your whole site if you want to).\nHave automatically generated user-friendly URLs for the individual pages, and if on Potion, you get nice preview images for all your pages as well.\n\nA few optional steps that you might want to consider:\n\nBy default, both Super and Potion will give you a test subdomain to work with. Eventually, you might want the website to be available from your own domain. This is just a matter of adding a couple of A-records and typically can be done from wherever you registered the domain:\n\n\n\n\nYou might want to add custom styles to make the website render uniquely — so you move beyond the standard look-and-feel of a Notion page if you so wish. You could do something on your own here, but the simplest thing is to just borrow the styling from one of the existing templates and tweak it if you want.\nInsert code for Google Analytics (or similar). As an aside, if you are looking for analytics that is user-friendly and privacy-conscious, I’d recommend Fathom.\n\n\n\nA Course Catalog with Super\n\n\n\n\n\n\nHeads up!\n\n\n\nThis content is deprecated because I’ve moved this domain out to a different setup now. So please ignore the links, and hopefully the steps are still useful in principle!\n\n\nLet’s apply this process to an actual website now! I’ll demonstrate how I setup the website at neeldhara.courses. Incidentally, if you want a quick overview without some details that will be specific to my website, you might want to watch the video made by @robhope and pointed out by @traf.\n\n\nHere's a little run through by @robhope on creating a site @super_:https://t.co/SCMdDMRfBd\n\n— traf (@traf) September 12, 2021\n\n\nBack to the setup for neeldhara.courses. You can check out the page on Notion here, but I’ll describe some pieces of it below. First, recall Step 1:\n\n1️⃣ Setup your content in Notion.\n\nI started with the Super template HQ. It looks amazing and is apparently free to use — at least at the time of this writing 😀\nDuplicate this template into Notion. If you like, you can duplicate it twice — one, a copy that you actually work on, and the other could be a copy that you don’t edit but just keep handy in case you need to go back to the original for reference.\nThe first thing I did was to get rid of most of the content, and just retained this section:\n\nwhich, incidentally, will render like this once connected to Super:\n\nNow the next step is to replace the generic content with yours:\n\nSince I’m just starting out, I have added the three courses that I’m teaching this term and they all show up. Eventually, these courses will be filtered out based on the current timing, so that only the current ones show here and the rest get pushed to an archive — which I’m yet to build. But the filter would look something like this in Notion:\n\nAnd for each of those entries, I’d go and setup the course home pages with the content that I have in my typical course homepages. The nice thing about Notion is the wide array of content types that lets you format things nicely. Here are a couple of sections from within Notion:\n\n\nOne thing worth pointing out for this particular setup — for each course, the class plan is just a Notion database, where the columns are:\n\nName (text)\nWeek (single-select with 12 options; one for each week of the course)\nModule (a checkbox property)\nDescription (text)\n\nand the rows either correspond to an overview of a whole week or just one individual lecture, tagged with the week that it happened in.\nOn the course’s homepage, I display this database set to a Gallery view, and filtered to only those entries where the Module option is unchecked. These are intended to be overview pages. This is what it looks like in Notion:\n\nand this is what it will end up looking like on the website, once you’ve gotten to the end of Step 3:\n\nFurther, overview page simply displays the same database again, this time in a list view filtered by the appropriate week:\n\nCheck out the views in Notion and the rendered version side-by-side:\n\n\n\n\n\n\n\n\n\nYou might wonder about the blockquote in the Notion view right at the top of the page. That’s a feature of the HQ template — anything that goes into that first blockquote renders as page navigation on top. I think this now a bit obsolete with Super’s new features on navigation bars, but I still find it handy and use it on most pages. 👍\nSo that’s all of Step 1, getting all your content inside Notion. I’d say this is really the bulk of the process. The process is iterative, so you don’t need literally all your content in before you can move on. However, getting an indicative amount thrown in is, I think, useful.\nOnce you’re done with this bit, up next:\n\n2️⃣ Enable sharing to the web from within Notion — this will generate a link for you.\n\nThis is very easy to do, it’s just a toggle on the top-right corner of your Notion app:\n\nNow for the final step to have everything come together:\n\n3️⃣ Copy this link into Super or Potion.\n\nThis is again quite straightforward, head to Super and just share your page’s public URL, give it a name, and optionally set it up to sync with your domain if you have one.\n\nGiven that we’re using a particular Super template, you would also need to remember to insert the CSS to make the site look as advertised above 😅\nSo remember to add this on the custom code section of your Super dashboard:\n<link rel=\"stylesheet\" href=\"[https://sites.super.so/hq/style.css](https://sites.super.so/hq/style.css)\">\nIf you do just this and are literally following along your site may still look a little different from mine, which is probably because I tweaked the CSS a bit to incorporate fonts of my liking (the fonts in the screenshot are from Google fonts — Andika New Basic and Shadows into Light Two).\nYou might want to take care of some minor things at this stage, such as adding a favicon, a site description that will show up on Google searches, inserting any code you need to for analytics, and so forth.\nThe very first time that you setup your site, you may need to wait for a bit for it to build and render. But after this first time, any edits you make on Notion are reflected automatically on your website — you may need to give it a minute or two, it’s not instantaneous, but trust that the changes will show up. Clear your cache if they don’t even after a couple of minutes.\nSuper generates pretty URLs automatically for all your pages, but because of the slightly peculiar setup I have, involving a particular nested structure and filtered views, I’ve been doing my pretty URLs manually. For example, to go to the second module of Week 5 in the competitive programming course, the URL is:\nhttps://neeldhara.courses/competitive-programming/week-05/mod-02\nThis can be setup quite easily from inside the Super dashboard, and once it’s done once, it’s done for good.\nSo, that’s about it! I’d like to think I covered most major aspects, but if anything is unclear, ping me @neeldhara on Twitter and I’ll be sure to update this appropriately 🙂\n\n\nThe Manim Examples Collection with Potion\nFor the Potion example, I’d like to build out a quick page with latest tweets from @manim_community. Manim is a community-maintained Python library for creating mathematical animations, and the twitter handle pulls in a lot of great examples.\n\n\n\n\n\n\nIncidentally, if you prefer watching a video tutorial, Potion has you covered already…\n\n\n\n\n\n\n\n\n\n\nSo, for step 1, which is to get our content in Notion, I start with a blank slate and populate it with some content:\n\n\nFor Step 2, I simply make this page public, and you can see the Notion version here.\nFor Step 3, I add this page to Potion and just follow step 4 on this page to set this up with a lovely template made by Dr. Gil Pradana (@gildy). This just amounts to copy-pasting some CSS code into the Snippet Injection section of your Potion dashboard. This template treats horizontal line breaks as breakpoints to create cards, and the headings translate into the highlight boxes that you can see from this preview.\nhttps://twitter.com/gildy/status/1403680404092035075?s=20\nAfter connecting my domain, here’s what the website looks like this\nAnd that’s basically it! You have a fully functional page now. 🎉 Changes you make in Notion will reflect instantaneously on Potion!\n\nYou might wonder if there is a way of setting things up so that new tweets from the Manim community handle show up automatically on this website. In principle, this should be possible with a little help from tools like automate.io, Zapier, or Integromat — they can watch for new tweets and append them to the page you are working on, although I’m not sure how to set it up so that they respect the two-column layout that I have here. I figure tweets could also be added to a database and shown with a gallery view instead, but the gallery previews will typically not pick up embedded content, so you might have to go via an intermediate service like Tweetpik or Pikaso instead so you have screenshots for display.\nSo this was Potion - you can probably see the many ways in which Potion and Super are similar to setup. By the way, the templates on these platforms are not mutually compatible — so watch out for the fact that they will not automatically work on the other platform if you are looking to migrate. As far as I can see, neither service has an importer for the other built yet.\nThat said, I hope you have fun making your website with Notion with whatever platform you choose to use! 🎉"
  },
  {
    "objectID": "blog/eight-self-sabotaging-behaviors/index.html",
    "href": "blog/eight-self-sabotaging-behaviors/index.html",
    "title": "Eight Self-Sabotaging Behaviors",
    "section": "",
    "text": "Putting this thread in one place.\n\n🧵 @fortelabs recently finished the opening keynote on the Second Brain summit, which incidentally has a great lineup including a panel discussion on PKM through the lens of ADHD. Ironically, I didn’t quite take notes but I think the themes also feature in this short video:\n\n\nThe live session was fun because of a super engaged chat — everyone had great suggestions for managing some of these (surprisingly common?) behaviors.\nI’ll not share the premise (it’s self-explanatory + there’s the video), but the discussion involved three parts:\n\nwhy it’s an issue;\nwhy-do-we-do-this-to-ourselves;\nhow do we not keep doing it 😀\n\nI’ll share a tweet-length summary of my takeaways.\n\nCaveat I: 280 chars! Twitter isn’t the platform for nuance. 😅\nCaveat II. Should go without saying, but all of this gyaan needs to be tempered with context, which was a frequently used word throughout the session!\n\n\n\n\n\n\n\n\nStarting over (again and again)\n\n\n\n\n\n⚠️  Not learning from previous mistakes.\n🤔  False sense of accomplishment, dopamine hit from a clean slate, FOMO (new tools).\n💡 Start simple, iterate slowly, resist looking at shiny new objects.\n\n\n\n\n\n\n\n\n\nFeeling guilty\n\n\n\n\n\n⚠️  Can’t win when you are at war with yourself.\n🤔  Probably comes from knowing you’ll trip again.\n💡 Extend to yourself the same courtesy and patience you’d show to a friend, consider replacing guilt with curiosity.\n\n\n\n\n\n\n\n\n\nPerfectionism\n\n\n\n\n\n⚠️  Not making mistakes is a risky way to live.\n🤔  Feeds ego, sense of control and safety, and you think you push yourself harder with lofty standards.\n💡 Aim for B+, fail in public and value it — can be a relief to not have to keep up with the perfect image.\n\n\n\n\n\n\n\n\n\nDo all the research first\n\n\n\n\n\n⚠️  When overdone, really procrastination in disguise.\n🤔  Creates an illusion of getting work done. Paranoia associate with diving in without preparation.\n💡 Second brains are not for archival, but production. Iterate often. Timebox research.\n\n\n\n\n\n\n\n\n\nGoing big\n\n\n\n\n\n⚠️  Ambition dominates the public discourse around goal-setting. Big goals are not problematic until they get in the way.\n🤔  Ego boosted, creates a potentially misguided sense of being inspired.\n💡 Break things down, take incremental (read: realistic!) steps.\n\n\n\n\n\n\n\n\n\nDoing it all yourself\n\n\n\n\n\n⚠️  Potentially limiting.\n🤔  A desire for respect or credit, and the sense that nobody can do this as well as me.\n💡 Delegate when appropriate, especially when looking to scale and/or diversify.\n\n\n\n\n\n\n\n\n\nComparing yourself to others\n\n\n\n\n\n⚠️  Potentially depressing.\n🤔  Self-pity, and an excuse to not even try.\n💡 Compare to past you. Read your old journal entries. (Also, journal.)\n\n\n\n\n\n\n\n\n\nPostpone gratification\n\n\n\n\n\n⚠️  For something to be sustainable, it needs to be fun!\n🤔  Traditional positive quality.\n💡 Enjoy the journey because nobody knows the destination. Live in the moment, find joy in the small things, be present. Also, music for instant gratification!\n\n\n\nDo check out the Second Brain Summit for the remaining sessions.\nI think you get a link to a recording if you’re registered for a session, at least this was the case for me with the opening session.\nThe community attending this is also on a slack."
  },
  {
    "objectID": "blog/kidney-exchanges/index.html",
    "href": "blog/kidney-exchanges/index.html",
    "title": "Kidney Exchanges",
    "section": "",
    "text": "This post is based on an excellent (chalk and board!) talk that Palash Dey gave at IIT Gandhinagar today. This is his joint work with Arnab Maiti, to appear as an extended abstract at AAMAS 2022 (preprint here)."
  },
  {
    "objectID": "blog/kidney-exchanges/index.html#background",
    "href": "blog/kidney-exchanges/index.html#background",
    "title": "Kidney Exchanges",
    "section": "Background",
    "text": "Background\nKidney paired donation or paired exchange allows donors to donate their kidneys to compatible patients with the understanding that their patients receive medically compatible kidneys in turn. The central problem in this setting is the clearing problem — which involves matching patients to donors in such a way that a maximum number of patients receive compatible kidneys. We introduce a directed graph as a convenient abstraction for this question, where:\n\neach node v_i = (P_i,D_i) represents a patient-donor pair, and\nwe introduce a directed edge v_i → v_j if the kidney of the donor D_i is compatible with the patient P_j.\n\nObserve that a cycle in this directed graph naturally represents a sequence of feasible exchanges within the cycle. For example, imagine that we have a three-cycle with the edges:\n(P_2,D_2) → (P_5,D_5) → (P_7,D_7) → (P_2,D_2)\nThen we have the following compatible donations:\n\nP_5 is assigned the kidney of donor D_2\nP_7 is assigned the kidney of donor D_5\nP_2 is assigned the kidney of donor D_7\n\nThis accounts for all the patients and donors involved in this cycle and motivates the following question:\n\nGiven a directed graph, what is the largest number of vertices that can be covered by a disjoint union of cycles?\n\nWhile a positive answer to this question will “resolve” all the needs in the system, consider that exchanges along a cycle of length \\ell involve \\ell simultaneous operations to mitigate the risks involved with donors potentially backing out of the exchange agreements.\nThis motivates the following refinement of the previously posed question:\n\nGiven a directed graph, what is the largest number of vertices that can be covered by a disjoint union of cycles, where each cycle is of length \\ell or less?\n\nIf the exchanges are restricted to swaps, that is, \\ell = 2, the problem reduces to finding a maximum matching. However, the problem is NP-complete already when \\ell = 3 (see Theorem 1, Abraham, Blum, and Sandholm; EC 2007).\nWe now generalize the model a little further to account for the presence of altruistic donors, who are donors without a matching patient and are willing to donate to any compatible patient. To account for the presence of such donors, we modify our graph representation as follows:\n\nEach node either:\n\nrepresents a patient-donor pair v_i = (P_i,D_i) or\nrepresents an altruistic donor u_k = D_k^\\star\n\nThe edges are as follows:\n\nWe have a directed edge v_i → v_j if the kidney of the donor D_i is compatible with the patient P_j.\nWe have a directed edge u_k → v_j if the kidney of the donor D_k^\\star is compatible with the patient P_j.\n\n\nIn this setting, note that we can also facilitate exchanges along paths as well, with the paths starting at the altruistic donors. For instance, if we have the path:\n(D_7^\\star) → (P_2,D_2) → (P_5,D_5) → (P_7,D_7) → (P_3,D_3)\nThen we have the following compatible donations:\n\nP_2 is assigned the kidney of donor D_7^\\star\nP_5 is assigned the kidney of donor D_2\nP_7 is assigned the kidney of donor D_5\nP_3 is assigned the kidney of donor D_7\n\nNote that in this situation, the donor D_3 is relieved from any obligation to donate to a patient. We now update our problem statement to reflect the presence of altrustic donors and the possibility of facilitating exchanges along paths:\n\n🤝 Optimal Kidney Exchange Along Short Paths and Cycles\nInput. A directed graph G = (V,E), where \\mathcal{A} \\subseteq V are source vertices; and positive integers \\ell_p, \\ell_c and t.\nOutput. Yes if and only if there is a collection of cycles of length at most \\ell_c each and a collection of paths of length at most \\ell_p each such that the cycles and paths altogether covers t nodes outside of \\mathcal{A}.\n\nThe main claim in the context of this problem is the following:\nThere exists a \\mathcal{O}(2^{\\mathcal{O}(t)} \\cdot \\text{poly}(n)) that decides Optimal Kidney Exchange Along Short Paths and Cycles."
  },
  {
    "objectID": "blog/kidney-exchanges/index.html#an-algorithm-for-oke",
    "href": "blog/kidney-exchanges/index.html#an-algorithm-for-oke",
    "title": "Kidney Exchanges",
    "section": "An Algorithm for OKE",
    "text": "An Algorithm for OKE\nHere’s a high-level description of the algorithm (perhaps best approached with some prior familiarity with color coding). To begin with, notice that we may assume without loss of generality that \\ell_p \\leq t and \\ell_c \\leq t — intuitively, this is because if the permitted cycle and path lengths are longer than the number of patients we hope to cover, then we can simply look for cycles or paths of length t directly to begin with — if we find one, then we are done, and if none exist, then we “might as well” set \\ell_p and/or \\ell_c to t-1.\nNow, if there is a solution that accounts for at least t patients, there is also one that involves at most 2t patients and in particular, also at most t paths. Such a solution engages at most t nodes from \\mathcal{A}. Therefore, if there is a solution, then there is one that spans s \\leq 3t vertices.\nAs is standard for color coding, we guess the correct value of s and randomly partition the vertex set V into s parts. The hope is that each part contains exactly one vertex from the solution (this is a so-called “colorful solution”). The probability that a random partition is a lucky one is (3t)!/(3t)^{(3t)}, which turns out to be at least e^{-3t}. This implies that e^{3t} repetitions ensure a constant success probability.\nGiven that the partition is indeed a lucky one, we can recover the solution using the following dynamic programming semantics. For C \\subseteq [3t] and i \\in [3t], let D[C,i] be TRUE if and only if there is a colorful solution spanning at least i nodes outside \\mathcal{A} in G[V_C], where V_C denotes the subset of vertices colored with colors from C.\nThe recurrence is based on isolating one path or cycle by guessing the set of colors involved in said component and using table lookups to figure out if this can be extended to a full solution.\nIn particular, we have:\nD[C,i] = P[C,i] \\lor Q[C,i],\nwhere\nP[C,i] = \\lor_{(B,j): B \\subseteq C \\text{ and } 1 \\leq j \\leq \\ell_c} [D[C \\setminus B, i - j] \\land f(B,j)]\nand\nQ[C,i] = \\lor_{(B,j): B \\subseteq C \\text{ and } 1 \\leq j \\leq \\ell_p} [D[C \\setminus B, i - j] \\land g(B,j)].\nHere, we have that:\n\nf(B,j) is TRUE if and only if the vertices of B can be covered with a cycle of length j.\ng(B,j) is TRUE if and only if the vertices of B can be covered with a path of length j.\n\nThe truth values of f(B,j) and g(B,j) can be determined directly using standard approaches to finding colorful paths and cycles in time that is single-exponential in j.\nTo claim the overall running time, note that:\n\nThe total number of entries in the table is 2^{O(t)} \\cdot t and each entry can be computed in time \\mathcal{O}^{}\\left(2^{\\mathcal{O}(\\ell)}\\right).\nTherefore, the algorithm outputs the correct decision in \\mathcal{O}^{}\\left(2^{\\mathcal{O}(t)}\\right) time with probability at least e^{-3t},\nBy repeating \\mathcal{O}\\left(e^{3 t}\\right) times, we find the correct decision with constant success probability.\nThe overall running time is \\mathcal{O}^{*}\\left(2^{\\mathcal{O}(t)}\\right)."
  },
  {
    "objectID": "blog/kidney-exchanges/index.html#other-results",
    "href": "blog/kidney-exchanges/index.html#other-results",
    "title": "Kidney Exchanges",
    "section": "Other Results",
    "text": "Other Results\nAs Palash mentioned in his talk, the preprint has more, and here are some highlights of the other results that were established:\n\nOptimal Kidney Exchange Along Short Paths and Cycles is FPT also when parameterized by the treewidth of the underlying graph + maximum length of path \\left(\\ell_{p}\\right)+ maximum length of cycle allowed \\left(\\ell_{c}\\right) and the number of vertex types1 when \\ell_{p} \\leq \\ell_{c}.\nA Monadic second-order formula for the problem is also presented, where the length of the formula is upper bounded by a function of \\ell=\\max \\left\\{\\ell{c}, \\ell_{p}\\right\\}.\nThe problem admits a polynomial kernel with respect to the number of patients receiving kidneys + maximum degree when \\max \\left\\{\\ell_{p}, \\ell_{c}\\right\\} is a constant.\nOn the other hand, the problem does not admit any polynomial kernel parameterized by the number of patients receiving kidneys + maximum degree +\\max \\left\\{\\ell_{p}, \\ell_{c}\\right\\} (under standard assumptions).\nA \\left(16/9+\\epsilon\\right)-approximation algorithm is presented for the case when only cycles of length at most 3 are allowed and no paths are allowed."
  },
  {
    "objectID": "blog/kidney-exchanges/index.html#pointers",
    "href": "blog/kidney-exchanges/index.html#pointers",
    "title": "Kidney Exchanges",
    "section": "Pointers",
    "text": "Pointers\nSome discussion that came up during the talk:\n\nThe so-called dual parameter (n-t), which in this case corresponds to the number of patients who were “left out”, is perhaps a natural parameter to study as well.\nThe notion of a patient without a matching donor seems complementary notion of altrusitic donors. Such patients would be the last vertices on paths kickstarted by altruistic donors. However, this notion likely does not manifest in practice.\n\nIf you’d like to dig deeper, be sure to check out the preprint! A few additional pointers:\n\nThis work closely builds on the works of Xiao and Wang (IJCAI, 2018), who proposed an exact algorithm with running time \\mathcal{O}(2^nn^3) where n is the number of vertices in the underlying graph. They also show an FPT algorithm parameterized by the number of vertex types if we do not have any restriction on the length of cycles and chains.\nLin, Wang, Feng, and Fu (Algorithms, 2019) studied the version of the kidney exchange problem which allows only cycles and developed a randomized parameterized algorithm with respect to the parameter being (number of patients receiving a kidney, maximum allowed length of any cycle).\nAlvin E. Roth was awarded the Nobel Prize in Economic Sciences 2012 (along with Lloyd S. Shapley) in part for his pioneering contributions to the theory and practice of kidney exchange — his biographical account indicates that he had started anticipating the problem even before it emerged as a legal practice. His talk at Simons Institute surveys “fifteen years of history” in the kidney exchange problem, with an emphasis on the game-theoretic aspects. (h/t: Rohit’s blog on this topic.)"
  },
  {
    "objectID": "blog/solo-chess/index.html",
    "href": "blog/solo-chess/index.html",
    "title": "Solo Chess",
    "section": "",
    "text": "Putting this thread in one place.\n\n🧵 on our latest at FUN 2022 with @NRAravind1 and Harshil.\nHave you tried Solo Chess @chesscom yet? It’s addictive — and NP-complete* even when you’re dealing only with rooks!\n*when appropriately generalized\n\n\n\nThe Rules of the Game\n\n\nSo this is a single-player, peg-solitaire-ish chess variant, where you have to clear board by making a sequence of valid captures, albeit starting with unorthodox — and even unrealistic — positions.\n\n\n\nAn example position\n\n\nTo begin with the boards start easy, with a few pieces at a time. Notice, even in the early games, how some positions have just one solution while others may have several.\n\n\n\nMore positions\n\n\nFrom initial plays, you sense that it has a very Hamiltonian-Path-ish vibe, and feels like you’re trying to find a path in some graph 😅 \nWe started with a variant that was simultaneously a generalization and specialization:\n\nn pieces 😎\n♖’s only\n1D boards 🙈\n\nThis, it turns out, is case so special that its trivial - you can sweep all rooks to the extreme left or extreme right of the board, and any position is winning even if every rook can capture exactly once. Less trivial though: how many ways there are to win? 🤔\nWe also ask what happens if every rook had a designated number of captures left. Imagine you have a 1D board and three kinds of rooks:\n\nred rooks cannot move\nblue rooks can move at most once\ngreen rooks can move at most twice\n\n\n\n\n1D Boards\n\n\nWe show that such 1D boards can be cleared if and only if then number of green rooks is at least the number of red rooks. This ties nicely with the intuition that every immovable rook needs to be picked up by a rook that can help another one (i.e, > one move left).\nThis generalizes naturally to rooks with a designated number of moves left, where said number can be anything between 0 and d. Since no other chess piece moves sensibly* across a 1D board, we decided to move on 2D boards from here.\n\nKings + rooks is an easy exercise.\n\nSo if you are still playing with red, blue, and green rooks, then the problem of checking if a given 2D configuration can be cleared up according to solo chess rules turns out to be NP-complete.\nNo Hamiltonian Path though — this one was from bipartite dominating set 😎\n\n\n\nA reduction from bipartite dominating set - I\n\n\n\n\n\nA reduction from bipartite dominating set - II\n\n\nBishops are much the same as rooks, by a 45-degree tilt of the board.\n⚠️ Still open though: what about the case when all pieces have at most two moves left, which is closer to the original spirit of the game?\nWe don’t know yet, although we’d bet it’s hard, I think.\nWhen playing with queens only, however, we can gadget in the behaviors of red and blue pieces. So we do have that Generalized Solo Chess with just queens that can all move at most twice is NP-complete.\nWhat about pawns? Let’s get clarifying assumptions out of the way:\n\nwhite pawns only\nregular captures only since there’s no premise for en passant captures\n\nIn solo chess, pawns are (heavily) constrained bishops: they can only move upwards and to a neighboring diagonal square. Knowing that bishops were hard, but pawns felt simple — we didn’t have a bet either way. 🤔\nWe were pleasantly surprised that the case of pawns is tractable, even when each pawn has a designated* number of moves!\n*at most two.\n\n\n\nLemma for pawns\n\n\nThe algorithm is linear time, too.\nNext: what about knights? We don’t know yet!\n❓ What’s the complexity of solo chess when played only with knights?\nKnights are special because we don’t have to worry about obstructions. So the game can be described by a more general token game on graphs:\n\n\n\nThe Graph Capture Problem\n\n\nWe do show that Graph Capture is hard by a reduction, again from bipartite dominating set. This might hint at the hardness for Solo Chess played with knights only, but we are not betting on this yet.\n\n\n\nAnother reduction from bipartite dominating set - I\n\n\n\n\n\nAnother reduction from bipartite dominating set - II\n\n\nI think these preliminary explorations have left us with more questions than answers:\n\noptimization versions (e.g, clear at least k pieces)\nother constraints (e.g, on distance moved)\nspecial cases (e.g, O(1) pieces per row/column)\nn x c boards, constant c\n\nWhile at it, I’m also curious about how @chesscom generates these puzzles, and if they have a mechanism for generating ones that have unique solutions. Also, is it true that if you throw “enough” pieces on the board, it’s solvable WHP?\nShout out to the skak package for making it easy to bring chess pieces to TikZ. We expect to put up a preprint on ArXiV soon. 👀  Meanwhile, we welcome comments and feedback — and if you read this far, thanks very much!\nPS. Also if you enjoy chess and algorithms, don’t miss Miguel Ambrona’s amazing Chess Unwinnability Analyzer, which also appears at FUN 2022!\n\n\n\nChess Unwinnability\n\n\nYou can find the full list of accepted papers here."
  },
  {
    "objectID": "blog/15-puzzle/index.html",
    "href": "blog/15-puzzle/index.html",
    "title": "Two approaches to the 15 puzzle",
    "section": "",
    "text": "Presenting the 15 puzzle:\n\nThis is a sliding puzzle having 15 square tiles numbered 1–15 in a frame that is 4 tiles high and 4 tiles wide, leaving one unoccupied tile position. Tiles in the same row or column of the open position can be moved by sliding them horizontally or vertically, respectively. The goal of the puzzle is to place the tiles in numerical order.\n\nAccording to Wikipedia, Johnson & Story (1879) used a parity argument to show that half of the starting positions for the n-puzzle are impossible to resolve, no matter how many moves are made. We are going to explore two approaches* parity-based argument to show that the puzzle shown here on the right is unsolvable.\n*I do believe the two proofs are essentially the same with slight differences of language.\n\n\n\nAn example of the 15 puzzle\n\n\nCommon to both approaches is the idea of associating a permutation with every state of the puzzle. For the purposes of this discussion, we will think of a permutation simply as a sequence of elements. To turn the grid layout into a sequence, you could, for instance, line up the rows next to each other, in other words, read off the numbers from left-to-right and top-to-bottom:\n\n\n\nAssociating the puzzle with a permutation\n\n\nSo we think of every puzzle state as a permutation over the set \\{1, 2, \\ldots, 15\\} \\cup \\{\\star\\}, where we use \\star to denote the blank space. For a particular sequence \\sigma and an index 1 \\leq i \\leq 16, we will use \\sigma_i to refer to the element that is at the i^{th} position in the sequence \\sigma.\nA couple of definitions in the context of permutations will be useful:\n\nAn inversion is a pair of elements that is out of their natural order. More precisely, if we have indices i < j such that \\sigma_i > \\sigma_j, then the pair (i,j) indulges in an inversion. Note that the starting state of our puzzle here has exactly one inversion.\nA transposition of locations i and j **is essentially a swap of the elements at positions i and j of a given permutation. So this is an operation performed on a permutation. Let’s say this again with more explicit notation — if we start with \\sigma, then the permutation \\tau obtained from \\sigma by a transposition of i and j is given by the following:\n\n\n\\tau_\\ell = \\begin{cases}\n      \\sigma_j & \\text{if } \\ell = i,\\\\\n      \\sigma_i & \\text{if } \\ell = j,\\\\\n      \\sigma_\\ell & \\text{otherwise.}\n    \\end{cases}\n\nThe identity permutation, which we will denote by \\iota, is special — it’s the following sequence:\n\n\\{1,2,\\ldots,14,15,\\star\\}.\n\nIt turns out that every permutation \\sigma can be obtained from the identity permutation by a sequence of transpositions. This is not terribly hard to see — start with the identity permutation, and repeat the following until the permutation at hand is the one you want to see: find a location i that’s messed up in the current permutation, i.e, it doesn’t have the element you need in there. Find where the element is in the current permutation, and if that’s location j, you could perform a transposition between i and j. This fixes up the location i. In every step, you fix at least one location, and never mess up anything else: so at the end of at most n steps (assuming you are working with a sequence of n elements), you would be done. 🎉\nFor example, suppose the permutation you want to obtain is 3,4,2,1. Here is how the argument above would play out:\n\n1,2,3,4. The first location is messed up, so swap 1 and 3.\n3,2,1,4. The second location is messed up, so swap 2 and 4.\n3,4,1,2. The third location is messed up, so swap 1 and 2.\n3,4,2,1. Now we are done.\n\nNote that this may not be the only way of performing a sequence of transpositions that can morph \\iota into \\sigma — there may be various roads to \\sigma. However, it turns out that no matter what route you take to transform \\iota \\longrightarrow \\sigma, the number of steps you perform will always have the same parity. So specifically, it’s not possible for you to have a series of, say, seventeen transpositions that turn \\iota into \\sigma, and for me to have a series of forty-two transpositions that do the same. We will take this as a cute exercise for the reader as given.\nThis partitions the set of all permutations into two categories:\n\neven permutations: those permutations that are reachable from the identity with an even number of transpositions\nodd permutations: those permutations that are reachable from the identity with an odd number of transpositions\n\nThe fact from the previous paragraph above makes this classification unambiguous.\nAlright, so now we have all the terminology we need to get to the argument about why the puzzle state we started with is unsolvable. We can roll up our sleeves and get started.\n\nThe first line of argument is based on this Numberphile video, and is also the one described in this 1999 American Math Monthly article by Archer. We begin with the observation that every move in the game is really a transposition behind the scenes. In particular, let’s say that we are currently in state s and we perform some move and move to state t. Let’s say the permutation associated with s was \\sigma and the permutation associated with t is \\tau. It’s not hard to see that:\n\n\\tau can be obtained from \\sigma with a single transposition.\n\nNow, note that the permutation corresponding to our target state is the following:\n\n\n\nThe permutation corresponding to our target state\n\n\nIn terms of the game state, notice that the final state has the blank tile at the bottom-right corner, just like we had at the start state. This means that in a hypothetical sequence of moves that morphs the initial game state into this solved state, we must have performed:\n\nan equal number of left and right moves; and\nan equal number of up and down moves.\n\nIf this is not the case — imagine the blank tile traveling through the board as you perform the moves — if the number of times you moved in opposite directions did not exactly cancel, it would be impossible for the blank location to be back at it’s original location.\nSo in any winning sequence, the number of moves performed must be even. This implies that the permutation corresponding to the start state, in particular, can be obtained from the identity permutation with an even number of transformations. That makes the starting permutation an even permutation.\nHowever, the permutation corresponding to the start state that we have been handed out is clearly an odd permutation: it can be obtained from the identtiy permutation by a transposition of the elements at the 14-th and 15-th positions. So, well, no dice! This shows that every solvable state that places a blank tile at the bottom-right corner must correspond to an even permutation. This does not automatically imply that all such states associated with even permutations are solvable* — it just shows that states with blank tiles at the bottom-right corner corresponding to odd permutations are firmly out of reach.\n*It does turns out that all even permutations are in fact solvable.\n\nThe second approach is based on the notion of inversions. This one is based on the Strong Induction lecture in the MITOCW course on Mathematics for Computer Science. For this proof I’ll actually switch to the 3 \\times 3 version of the puzzle because I don’t know how to extend it to the 15-puzzle the case analysis is more manageable for this version:\n\n\n\nA move in the 3 X 3 version of the puzzle\n\n\nAs we said before, the permutation associated with the starting point of the puzzle has exactly one inversion, while the permutation associated with the solved state, which is the identity permutation, has no inversions. So, when you make a move in the puzzle, what happens to the number of inversions?\nAs before, let’s say that we are currently in state s and we perform some move and move to state t. Let’s say the permutation associated with s was \\sigma and the permutation associated with t is \\tau. Let us say that a pair of elements (p,q) is affected by a move in the game if the relative order of p and q is different in the permutations \\sigma and \\tau. Now we have the following:\n\nif we perform a row move, the relative order of all elements corresponding to numbers remains the same — in particular, all affected pairs involve \\star — so the number of inversions in \\tau is exactly the same as the number of inversions in \\sigma.\nif we perform a column move, typically the element that is being moved, say p, ends up effectively jumping over two other elements, say a and b. In this case the following scenarios arise:\n\nNeither (p,a) nor (p,b) is an inversion in \\sigma.\n\n\n\nNeither (p,a) nor (p,b) is an inversion in \\sigma\n\n\n\nIn this case, both (p,a) and (p,b) emerge as new inversions in \\tau, and the total number of inversions in \\tau is two more than the total number of inversions in \\sigma.\n\nBoth (p,a) and (p,b) are inversions in \\sigma.\n\n\n\nBoth (p,a) and (p,b) are inversions in \\sigma\n\n\n\nIn this case, neither (p,a) nor (p,b) are inversions in \\tau — they both get fixed! So the total number of inversions in \\tau is two less than the total number of inversions in \\sigma.\n\nWhile (p,a) is an inversion in \\sigma, (p,b) is not.\n\n\n\nWhile (p,a) is an inversion in \\sigma, (p,b) is not\n\n\n\nIn this case, you fix some, you spoil some — so in \\tau, (p,a) is not an inversion any more, but (p,b) emerges as a new inversion; so the changes cancel and the number of inversions in \\tau is exactly the same as the number of inversions in \\sigma.\n\nWhile (p,a) is not an inversion in \\sigma, (p,b) is one.\n\n\n\nWhile (p,a) is not an inversion in \\sigma, (p,b) is one\n\n\n\nAs before, you fix some, you spoil some just the other way now — so in \\tau, (p,a) is a new inversion, but (p,b) is no longer one; so the changes cancel again and the number of inversions in \\tau is exactly the same as the number of inversions in \\sigma.\n\n\n\nThe long and short of all this is that after every move, the number of inversions either remains the same or changes by two. So no matter how many moves you perform, a state whose associated permutation has an odd number of inversions is going to remain inaccessible.\nTada!\n\nSo there we have it… I have a feeling that a little bit of language connecting transpositions and inversions will really make these proofs quite identical, at least for the 3 \\times 3 case — although I did worry that the first approach seemed to rely rather explicitly on the location of the blank tile while the second one didn’t. It is quite possible that the first one actually demonstrates more than I’m giving it credit for!\nMeanwhile, to be honest, I haven’t thought much about pushing the second line of attack to the 4 \\times 4 case — it seems already that the statement about the change in the number of inversions is no longer true and the change itself is no longer two: in particular, it could apparently go up or down by three or one instead, since the element involved in the action, p is now potentially jumping over three other elements, a, b, and c… so this, at least from an immediate consideration, doesn’t quite take us where we want to go.\nPossibly one has to work with a somewhat different invariant, maybe a notion of inversions that involve triples instead of pairs? Any comments on this would be very welcome, and I’ll have an update once I understand this a little better!"
  },
  {
    "objectID": "blog/django-app/index.html",
    "href": "blog/django-app/index.html",
    "title": "Building a first Django App",
    "section": "",
    "text": "In preparing for a session in a Python workshop (organised for teachers of the CBSE board who are teaching students informatics and computer science in 11th/12th grades, and who have recently had their official syllabus switch from C++ to Python), I finally got around to exploring the process of building a webapp powered by Django. I picked up the excellent Hello Web App book by Tracy Osborn for my preparation. In this post, I am going to document the process — just in case I have to do this again ☕️\nThe tutorial in Hello Web App goes over the process of building a generic “collection of things” with Django. In this tutorial, I’ll focus on a more concrete example, because it was more fun for me to build a tangible concept that I might actually use later.\nSo, I am going to build a collection of talk announcements at IIT Gandhinagar, which I intend to be displayed, on the frontend, as a slideshow. I figure that this website can then be loaded up on any internet-connected display and serve as a virtual notice board. For the frontend design, I’m going to be stealing the Webslides framework, which is a really clean HTML/CSS template for making slideshows powered by Javascript.\n\nQuickstart\nI’m going to handwave the bit about installation. Briefly, I setup Django v2.0.4 in a virtual environment, put the codebase in a git repository, and initialized a Django project via:\ndjango-admin startproject announceiitgn .\nand then a Django app via:\ndjango-admin startapp talks\nIt’s also important to add this app to settings.py, like so:\nINSTALLED_APPS = [\n'talks',\n'django.contrib.admin',\n'django.contrib.auth',\n'django.contrib.contenttypes',\n'django.contrib.sessions',\n'django.contrib.messages',\n'django.contrib.staticfiles',\n]\nand also run a migration command to account for an initial setup for the databases (if you skip this step, Django will prompt you to do it anyway — as I found out by forgetting 😎):\npython [manage.py](http://manage.py/) migrate\nFinally, see your app by running the server! 🎉\npython [manage.py](http://manage.py/) runserver\nYou should see a neat little success page if you navigate to something like http://127.0.0.1:8000/ (the exact URL should be in your console).\nIf you are not sure how to get to this point, I’d suggest looking up an installation/setup guide such as this one from the official documentation or this one from Django Girls.\n\n\nSetting up Templates\nThe first step is to setup a basic HTML template that becomes the frontend. We go into our app directory (which, in my case, is talks) and then make a templates directory inside it, where I make a simple index.html file. Instead of using a skeleton file here, I’m going to take a deep breath and throw in the index.html from the webslides codebase. At this point I know it won’t be a pretty sight, but I’m also optimistic that I can iron it out as I go along 🤕\nI’m going to head over to urls.py and add the following import:\nfrom talks import views\nand then add the following item to urlpatterns, which I understand only vaguely at this point:\npath('',views.index,name='home'),\nWe now need to make sure that views.index actually makes sense, so switch to views.py in the talks directory and add the following:\ndef index(request):\nreturn render(request,'index.html')\nNote that render has already been imported for you from django.shortcuts. For now, I sense that this is the plumbing connecting the directive in urls.py to the meat in the templates directory. Now, navigating again to the webapp, while it’s not exactly pretty (just as predicted), but at least you can see that all the connections are working as intended:\n\n\n\n\n\n\nClick toggle to reveal a full-page screenshot of an unstyled webpage!\n\n\n\n\n\n\n\n\n\nSo it’s time to add the static supporting files for the webslides template. I’m going to create the folder static inside the talks folder. Inside the static folder, copy over the folders css, js and images from the webslides template bundle. Now, we need to make sure that our index.html loads these supporting files from the appropriate location. This is a critical step and will completely transform the way the website is rendered if done correctly. So what we are going to do is add the following line to the top of the file:\n{% load staticfiles %}\nNext, find all instances of anything that looks like:\n<link rel=\"stylesheet\" type='text/css' media='all' href=\"static/css/webslides.css\">\nand change it to:\n<link rel=\"stylesheet\" type='text/css' media='all' href=\"{% static 'css/webslides.css' %}\">\nCareful with getting the quotes and the template tags in place accurately! Also remember to attack every instance of a reference to anything the static/ directory. If you are comfortable with it, this is a near-one-shot find and replace with a regex search.`\nYou could also make this work by using relative paths (i.e., changing the paths to ../css/webslides.css), but using the Django template tags as above is more robust to changes in the directory structure — so in case your static files folder moves around, your code doesn’t have to change.\nNow, for the moment of truth, restart the server:\npython [manage.py](http://manage.py/) runserver\nand revisit your site:\n\nSo there! We’ve managed to render the webslides deck inside of our Django project — which is an awesome start already: 🎉\n\n\nStarting Clean\nOf course, we don’t quite want the index.html file to hold this particular content. I’m going to quickly pick out a slide (from the webslides demonstrations) that looks nice for displaying talk announcements, and get rid of all the original sections and just use this one. Here’s the HTML for the sections that I ended up with, populated with some sample content:\n<section>\n<div class=\"wrap\">\n<div class=\"card-30 bg-white\">\n<div class=\"flex-content\">\n<h2>Talk Title 1\n</h2>\n<p>Speaker Name & Affiliation</p>\n<p class=\"text-intro\">A brief abstract of the talk.\n</p>\n<ul class=\"description\">\n<li><strong class=\"text-label\">Date:</strong> 16 June 2018</li>\n<li>\n<strong class=\"text-label\">Time:</strong> 10:00 AM\n</li>\n<li><strong class=\"text-label\">Venue:</strong> Academic Block 1, Room 101</li>\n</ul>\n</div>\n<!-- end .flex-content-->\n</div>\n<!-- .end .card-50 -->\n</div>\n<!-- .end .wrap -->\n</section>\nOf course, this data would eventually be passed into the template from the database, but let’s render our site anyway and check it out once more before moving on:\n\nIt’s not hard to customize the header from index.html, but I am postponing that for a little bit later.\n\n\nTemplate Inheritance\nIt’s useful to have global-ish aspects of our template separated out into a (presumably traditionally named) base.html template, so we can make spin-offs easily. For example, when we have interviews we like to display room numbers for candidates interviewing for different disciplines on the same day, and some related general information. This page will carry the same overall structure, but we might want to use a slightly different combination of section templates. So let’s rip out the generic stuff from index.html and move it to base.html:\n{% load staticfiles %}\n...bunch of webslides header stuff...\n\n<main role=\"main\">\n  <article id=\"webslides\" class=\"vertical\">\n\n    {% block content %}\n    {% endblock content %}\n\n  </article>\n  <!-- end article -->\n</main>\n<!-- end main -->\n...bunch of webslides footer stuff...\n(Please don’t copy-paste this, work with your own webslides template if you are literally following along! I’ve not dislpayed a bunch of stuff from their index.html in the interest of space.)\nMeanwhile, your index.html now looks like this:\n{% extends 'base.html' %}\n{% load staticfiles %}\n{% block content %}\n<section>\n<div class=\"wrap\">\n<div class=\"card-30 bg-white\">\n<div class=\"flex-content\">\n<h2>Talk Title 1\n</h2>\n<p>Speaker Name & Affiliation</p>\n<p class=\"text-intro\">A brief abstract of the talk.\n</p>\n<ul class=\"description\">\n<li><strong class=\"text-label\">Date:</strong> 16 June 2018</li>\n<li>\n<strong class=\"text-label\">Time:</strong> 10:00 AM\n</li>\n<li><strong class=\"text-label\">Venue:</strong> Academic Block 1, Room 101</li>\n</ul>\n</div>\n<!-- end .flex-content-->\n</div>\n<!-- .end .card-50 -->\n</div>\n<!-- .end .wrap -->\n</section>\n{% endblock content %}\nRemember to make sure that the line:\n{% extends 'base.html' %}\nis the very first thing in your file, and that you add:\n{% load staticfiles %}\nin case you plan to use anything in your static directory in index.html. The power of inheritance becomes a little more evident when you have other files piggybacking on base.html, but I’ll leave that to your imagination for now.\n\n\nSetting up the Database\nWe’re going to start by creating an admin user, by typing the following into the commandline:\npython manage.py createsuperuser\nThis prompts for a username, email and password — nothing out of the ordinary here. Next up is a critical point in this whole exercise, which is to setup the model, or the database schema, for the items we wanted to display. From the HTML above you might have guessed that what I want to define at this point is a talk object with the following attributes:\n\nTalk Title\nSpeaker Name\nVenue\nDate\nTime\n\nTo capture this, add the code below to models.py:\nclass Talk(models.Model):\n    title = models.CharField(max_length=255)\n    speaker = models.CharField(max_length=255)\n    description = models.TextField()\n    venue = models.CharField(max_length=255)\n    date = models.DateField()\n    time = models.TimeField()\nThe field types should be self-explanatory. One type that I did not use was the SlugField, which can be handy if you want every talk to have its own page. For now, we’re keeping it simple. We then ask Django to pick up this updated database plan by running migrations as follows:\npython manage.py makemigrations python manage.py migrate\nWe next get the built-in Django admin interface up to speed with information about our new database, by adding the following lines to admin.py in the Talks folder:\nfrom talks.models import Talk\nclass TalkAdmin(admin.modelAdmin):\nmodel = Thing\nlist_display = ('title','speaker','description','venue','date','time')\nadmin.site.register(Talk, TalkAdmin)\nThe business with the TalkAdmin class is optional, but it lets you do nice things like prepopulate fields where relevant: for instance, if we had a slug field, we could have said something like:\nprepopulated_fields = {'slug'}: ('name',)}\njust after the list_display line above, and you could see the slug getting automatically generated in the admin interface. Speaking of admin interfaces, let’s check ours out — head over to http://127.0.0.1:8000/admin/ and login with your superuser credentials. Here’s what I see:\n\nYou should find your own data in the users table. But the interesting bits are in the Talks table, which is going to look exactly the way we modeled it above when you go to the table and click on the Add Talk button:\n\nNow let’s go ahead and add some sample data in here:\n\nI added this from the admin interface. If you like, you can setup forms for other users to add data to the database, but that’s going to be beyond the scope of our first app. For now, let’s get to tying this all together by getting the data from here to display on the frontend…\n\n\nDisplaying Dynamic Content\nIf you’ve come this far, you are now ready to pull your data into the slideshow that we setup from before. First, let’s get into views.py, pull the data from our database, and pass it on to our template. Modify the file so it looks like this:\nfrom django.shortcuts import render\nfrom talks.models import Talk\n\n#Create your views here.\n\ndef index(request):\ntalks = Talk.objects.all()\nreturn render(request, 'index.html', {\n'talks': talks,\n})\nNext, let’s head back to our index.html file, and adapt our content block:\n{% extends 'base.html' %}\n{% load staticfiles %}\n{% block content %}\n{% for talk in talks %}\n<section>\n<div class=\"wrap\">\n<div class=\"card-30 bg-white\">\n<div class=\"flex-content\">\n<h2>{{ talk.title }}\n</h2>\n<p>{{ talk.speaker }}</p>\n<p class=\"text-intro\">{{ talk.description }}\n</p>\n<ul class=\"description\">\n<li><strong class=\"text-label\">Date:</strong> {{ talk.date }}</li>\n<li>\n<strong class=\"text-label\">Time:</strong> {{ talk.time }}\n</li>\n<li><strong class=\"text-label\">Venue:</strong> {{ talk.venue }}</li>\n</ul>\n</div>\n    <!-- end .flex-content-->\n</div>\n<!-- .end .card-50 -->\n</div>\n<!-- .end .wrap -->\n</section>\n{% endfor %}\n{% endblock content %}\nNote that we’re now using a for loop to go over everything in talks, and replacing our static content with template tags that represent the corresponding data from the database. Django has a lot of interesting ways in which you can format your content (such as dates and times, especially, but even text strings — for instance, they can always be rendered in title case, if you like, and so on). Since the default view here is not bad, I won’t be pursuing this further — but it’s good to know that you can do cool things.\nLet’s check out our site now, to relish the sight of the slides populated with conent from our database:\n\n\n\nFiltering Dynamic Content\nLet’s say we only want to display those talks whose date is not in the past — this is a natural ask, we don’t want our virtual notice board to be cluttered with information about talks from the past (that’s more suitable for a talk archive page), and we also don’t want to have to delete talks from the database manually (two issues with this: the first is that manual is tedious, the second is that it’s nice to keep the data — quite likely the developer of the future archive page will find it useful).\nOne way to do this is to loop through all the talks in our template file, and setup a conditional for whether we display it. The main problem doing it this way is that we are doing waaaay more work than is called for: eventually this database will have thousands of talks, while you probably need to get hold of a dozen or so of them. The more appropriate solution is to setup what is called a filter when you make the database query. After some fiddling around, I finally got to this updated query in my views file:\ntalks = Talk.objects.filter(date__gte=datetime.now()).order_by('date')\nRemember to import datetime for the above to work:\nfrom datetime import datetime\nThe syntax here is almost self-explanatory: we got rid of the .all() and replaced it with a .filter() to indicate that, indeed, we don’t want all records but only those that match the filter criteria. Next, gte stands for greater than or equal to; datetime.now() refers to today’s date; while the order_by directive asks the retrieved objects to be ordered according to a particular field. You can order by this-then-that by simply adding multiple fields separated by commas, and you can reverse the order by adding a leading hyphen (or a “minus”, if you like) to the field name. Try all this out! Also: try to mess around with the query to see what happens when the query returns an empty set of records.\nGoing back to our app, we see that the one talk that was in the past (at the time of this writing) is now gone:\n\n\n\nFinishing Touches\nOne thing I didn’t touch upon was how to pass Python variables into the template. Let’s try this now, by adding a final slide that displays today’s date and a nice background image (which resides in the images/ folder under the static directory). To pull out today’s date, let’s set a variable currdate in our views file, and pass it on to our template, like so:\ndef index(request):\n    talks = Talk.objects.filter(date__gte=datetime.now()).order_by('date')\n    currdate = datetime.now()\n    return render(request, 'index.html', {\n        'talks': talks,\n        'currdate': currdate,\n})\nBack to the template, as before, I picked up a nice-looking section from the vast array of webslide’s demo pages. Carefully add this section after the forloop block ends:\n<section class=\"bg-gradient-v slide-bottom\">\n<span class=\"background light\" style=\"background-image:url('{% static 'images/campus-bg.png' %}')\"></span>\n    <div class=\"wrap\">\n        <div class=\"content-right\">\n            <h3 class=\"alignright\">{{ currdate|date }}</h3>\n        </div>\n    </div>\n<!-- .end .wrap -->\n</section>\nNote the use of {{ currdate|date }} — this displays the value of the variable currdate but formatted so that only the date is displayed (without the trailing date instruction, this would display the date and the time by default). This gives us a cool final slide:\n\nAlso remember to head back to base.html and customize the header so the social media links and the logos are relevant to your setting:\n\n\n\nBeyond the First App\nOur app was, by design, a largely view-only app. In most situations, however, your app will likely have users, so you would want features like:\n\nRegistration (possibly even single-sign ons)\nA Login Flow (optionally, also an onboarding flow)\nReset Password\nThe ability for users to view user-specific data\nThe ability for users to add/edit/delete user-specific data\n\nFor a lot of this you would need to invoke some kind of a customized form interface (different from Django’s built-in admin interface) that allows the user to interact with the database. Covering this is beyond the scope of our discussion, but if you would like to set these things up, I’d suggest continuing your journey with either this Django tutorial series, the official documentation, or Hello Web App. Have fun!"
  },
  {
    "objectID": "blog/on-teaching/index.html",
    "href": "blog/on-teaching/index.html",
    "title": "On Teaching",
    "section": "",
    "text": "A teacher does not teach, a student learns.\n— snippet from this interview of Ustad Zakir Hussain\nI’ll pose some how/what/why questions in the context of teaching."
  },
  {
    "objectID": "blog/on-teaching/index.html#how",
    "href": "blog/on-teaching/index.html#how",
    "title": "On Teaching",
    "section": "How",
    "text": "How\nThe last couple of decades, especially the last few years, have seen dramatic changes in how information is communicated. A lot of learning happens in online communities, for instance, question-and-answer websites like Quora and StackExchange. Thanks to folks who invest time on these platforms, expert help seems to be nearer than ever before. Specialized and snark-free communities on Discord/Slack/Telegram are enabling peer-to-peer learning at global scale. I keep hearing that Quora is not what it used to be, but as long as Thomas Cormen is an active user, I am positive it remains a valuable resource.\nBooks are beginning to be injected with exciting new technology: CodeMirror makes code interactive and runnable, while tools like PythonTutor can help with visualizing what happens behind-the-scenes when code is executed. Say what you want about JavaScript, but the interactivity that it brings to the written medium has helped make reading less passive. Some of my favorite interactive texts include Seeing Theory, Probabilistic Models of Cognition, courses on Brilliant, Mathigon, and essays from Nicky Case, Minute Labs, and others on Explorables.The name “PythonTutor” is slightly misleading, since the website also lets you visualize code snippets written in C, C++, Java, and JavaScript.\n\n\nAnd finally there are the online courses. At the time of this writing, it has been just a little over two decades since MIT’s Open Course Ware opened to the public. The early hype around MOOCs roughly coincided with my years in college and graduate school. As far as I remember, it was quite the thrill to have free-flowing access to online lectures — “taught by the best” — for several of the courses I was supposed to be doing as a part of my curriculum.\n\n\n\n\n\n\nAll this is to say that I walked into a career involving a substantial teaching component with plenty of hesitation. The delivery was/is still largely confined to classroom settings in broadcast mode. It is not entirely clear what this format has to offer over YouTube. Basic interactivity is being increasingly solved with questions built into video players. Peer learning is quite doable with WhatsApp/Slack/Discord groups and local chapter meetups. Scale in the context of assessments is somewhat addressed by peer evaluation. And then there are all the things you can do on YouTube that you can’t do with traditional lectures: find a teacher whose style resonates, find an accent you understand, replay, play at 2x, 0.5x, binge watch, don’t watch…\nSo: what’s the incentive for anyone to show up in a classroom at a fixed time, especially when said time is 8AM? This question became particularly relevant during the pandemic years: once the novelty wore off, almost nobody† showed up to lectures. If I was a student, I’d likely do the same. This remains largely an open problem in my mind, but here are some pointers that have kept me motivated about the conventional format. † Shout out to those of you accounting for the “almost”, thank you!\n\nClassroom = theatre. I am increasingly treating it as a ground for practicing standup and magic skills. I should admit that this isn’t easy for a clinically shy person like myself, but I got used to making a fool of myself fast — that’s served well. I imagine that some of the fun that comes out performance-first lectures is hard to recreate with recordings and notes.\n\n\n\n\n\nTotally. It's almost always a performance, irrespective of the class size. And the more you rehearse, the better it goes. At least that's what works for me.\n\n— Manu Awasthi (@mnwsth) August 24, 2022\n\n\n\n\n\n\n\nSome musings on teaching from a lunch talk awhile back: https://t.co/19vOXpxcjs\n\n— Tim Roughgarden (@Tim_Roughgarden) April 6, 2021\n\n\n\n\n\nIn a classroom setting, I can nudge the audience to discover things for themselves. As far as I know, the interactivity in online materials can help with validating understanding, but not as much with developing it from first principles. My hope is for learners to walk out of a classroom with the confidence that they came up with parts of the material in the textbook on their own.\nAgain, this is hard to do in time-bound fashion, given that a lot of this kind of understanding comes from brooding and hours of messing around. I can only hope to convince the audience that the process is worth the trouble.\nThe opportunity to show that you care. For learners who may have struggles with and beyond the materials — classrooms, labs, and office hours afford opportunities for us to offer help.\nThis was a late realization for me personally: for the longest time, my own sense of self-doubt did not allow me to see that I could potentially be useful to someone else. While self-doubt remains, I have started to compartmentalize it enough to show up for others.\n\nAll this said, I believe online and remote formats have substantial potential for making quality education accessible at scale, and that it is only a matter of time before classrooms in their most conventional forms either become obsolete or a ruse.\n\n\n\n\nI am going to attend college lectures from now on just to increase my attention span. The goal will be to sit for an hour without sleeping or getting distracted from mobile notifications.\n\n— Priyansh Agarwal (@Priyansh_31Dec) September 5, 2022\n\n\n\n\n\nCalvin on 21st Century Education"
  },
  {
    "objectID": "blog/on-teaching/index.html#what",
    "href": "blog/on-teaching/index.html#what",
    "title": "On Teaching",
    "section": "What",
    "text": "What\nIt is also increasingly challenging to formulate a curricula gets people to the bleeding edge starting from the foundations. For instance, there is a growing sentiment that Machine Learning is the new Algorithms (or maybe not). On the other hand, the extent of involvement of “mathematics” in introductory CS courses is also up for debate.\n\n\n\n\n\nCutting Edge\n\n\nHow much theory is needed for competence in practice? How crucial is it to develop competencies that don’t have an immediately visible ROI? How frequently do we rewrite the textbooks based on developments in industry?\nI once read a collection of answers to the question of what every computer science graduate should know on a Q&A site. As an aspiring graduate myself, I figured I should know what I should know. Unfortunately, I remember it as a mostly unnerving experience: it was a list that started with Voronoi diagrams and ended with incompleteness theorems, and a lot of things in between.\nFrom the other side of the fence, for whatever it’s worth — the answer to this question remains elusive, mainly because I think it’s a context-heavy issue. For better or worse, there is a growing interest in computer science, and it will likely remain a non-trivial challenge to find an approach that is both maximally inclusive and sufficiently useful. I can only hope that between ruthless efficiency in teaching things driven purely by need and a curriculum flooded with random adventures, we can find an balance appropriate to our contexts!"
  },
  {
    "objectID": "blog/on-teaching/index.html#why",
    "href": "blog/on-teaching/index.html#why",
    "title": "On Teaching",
    "section": "Why",
    "text": "Why\nGiven that everything that needs to be explained has more or less been done and dusted really well on the interwebs, personally, this is hardest question of the lot. Not from my own POV, that’s the easy bit - as pointed out here, it’s fun to go through the idea exchange process with a captive audience, and in my experience at least one party is sufficiently triggered at the end of it (hopefully in a good way).\n\n\n\nThe satisfaction that you get when you are able to explain a concept to someone who did not know it earlier is immense. Sometimes it could be straightforward, and sometimes it could be frustrating. But the end point is always the same - a smile on the faces of those students. Money can buy all the books, but can’t buy that smile.\nProf Dheeraj Sanghi, “Why I want to be a professor”\n\n\n\n\nOn hope in teaching.\n\n\nI am just not sure if we create enough of a net positive in a traditional classroom setup from a ROI perspective. Given the few good things that the internet has brought us, perhaps it is time to think beyond classrooms and focusing on making existing resources more accessible to everyone who’s interested.\n\n\n\n\nJoin the conversation\n\n\nNew blog, new post:https://t.co/c2lEHM0lTIMeanwhile — happy teachers day to everyone!\n\n— Neeldhara (@neeldhara) September 5, 2022"
  },
  {
    "objectID": "blog/envelope-budgeting-notion/index.html",
    "href": "blog/envelope-budgeting-notion/index.html",
    "title": "Envelope Budgeting with Notion",
    "section": "",
    "text": "YNAB (c.f. r/YNAB) (short for You Need a Budget) is a budgeting application that lets you track and manage your finances. Like most apps in this category, it provides a slick interface to enter all your transactions. YNAB is more than just cataloging transactions and tracking account balances, though. The design here revolves around (and goes beyond) what is called envelope budgeting, which basically boils down to this:\nYou can dig a little deeper into how YNAB works by looking up their four rules here. I am going to try and create an envelope budgeting system in Notion that is loosely inspired by my use of YNAB.\nTo be clear, I don’t expect to stop using YNAB, nor do I expect to replicate many of its sophisticated features. Also, there are some nice envelope budgeting systems on Notion already! For instance, you might want to check out the one here by u/sff_fan_17 or the one here by Ben Smith. These are really neat, but the only reason I’m not just duplicating one of them is that what I have in mind looks slightly different from the setups here. In particular, I would like the transactions to be dated and tied to specific accounts, and I would also like the system here to account for all the inflows and outflows in my actual system. Neither of these templates feature a hierarchy of categories either, which is something that we will attempt to do here.\nIn the first template above, I think the total income is mentioned separately, outside of the database system; and the budget covers a part of the total available income. There are explicit instructions on how to update this month-to-month, so do check this out — perhaps it works for what you might have in mind! The second template explicitly accounts for inflows, and is apparently based on this Google sheet. It does seem that the transactions are missing information about accounts and dates, which could be a little limiting if you wanted to generate a report or a dashboard for a particular period of time. Again, a great starting point, and if it resonates with your kind of setup, it’s definitely worth duplicating and playing with. Both templates are free to access and replicate.\nIncidentally, if you don’t use Notion and are hesitant to try YNAB, you could take a look at their guide to building your own budgeting template — this does not require using YNAB at all and can even be made to work pen and paper. Many people have also recreated YNAB’s core features using their own favourite tools, the most popular among which appears to be Google sheets — see, for example: Aspire Budget (c.f. r/aspirebudgeting) — I have not tried this myself, but it appears to be very feature-rich and neat overall.\nThat said, onto our own YNAB-esque budgeting template in Notion! We’re on our way to something that looks like this:\nIf you want to just skip ahead and play with the template, you can duplicate it by following this link:\nThere are three key pieces to this setup: the first is the categories (these are the labels on the envelopes, if you like), the second is the actual transactions that take take place, and the third is a list of accounts that you have (could be bank accounts, credit accounts, virtual wallets, and so on). You would want the transactions database to be linked to both categories and the accounts. More on the exact table designs below. I’m going to assume some familiarity with Notion terminology, if this is your first time with Notion then some of this may not make sense right away, but if you could just look up how Notion databases work — especially the relational aspect — then I think you’d have all you need to follow along!"
  },
  {
    "objectID": "blog/envelope-budgeting-notion/index.html#budgeting-categories",
    "href": "blog/envelope-budgeting-notion/index.html#budgeting-categories",
    "title": "Envelope Budgeting with Notion",
    "section": "Budgeting Categories",
    "text": "Budgeting Categories\nIt may be natural for this table to just have one row for each category. You probably want to have a small number of higher-order categories (e.g: monthly supplies, services, maintenance, health, investments, etc.) and smaller, more specific ones under these broad umbrellas (e.g, services would likely have sub-categories along the lines of internet, phone, electricity, water, etc.). You can do this by setting up a relation property to the table itself, and have it sync two-way, like so:\n\n\n\nScreenshot 2021-09-18 at 3.29.11 PM.png\n\n\n\n⚡ We want to make a database that captures the categories that our expenses fall under, and the budget that’s available for these categories.\n\nIf you want to see just the higher-order categories nicely, you can setup a gallery view with a filter for the main category to be empty, which would look like this (I’ve disabled the preview and added some icons from notion.vip):\n\n\n\nThe Gallery View\n\n\nNext, we want to specify a budget for each of these categories. We can do this directly for the lower-order categories first. Then, we can have the main category budgets calculated automatically by rolling up the budgets of the corresponding child categories and adding up their budget values. To have a clean view of the budget, you could add a formula column that just adds up the values from the direct budgets and the rollup, like so:\n\n\n\nBudget View\n\n\nYou can add two dummy properties with the text Budgeted: and Remaining: for each row, and set them to show along with the budget in the Gallery view so you get something like this:\n\n\n\nBudgeted and Remaining Labels\n\n\nThere are two natural questions at this point:\n\nHow do we know that we have budgeted what we actually have?\nHow do we know what amounts are remaining at any given point of time in the month?\n\nTo address both of these questions, we will need to flesh out the transactions database, link it to the categories and come back to this. But before that, let’s do a quick detour with an accounts database just to setup the foundation we need for the transactions database."
  },
  {
    "objectID": "blog/envelope-budgeting-notion/index.html#accounts",
    "href": "blog/envelope-budgeting-notion/index.html#accounts",
    "title": "Envelope Budgeting with Notion",
    "section": "Accounts",
    "text": "Accounts\nFor this demonstration, I am just going to add two accounts — one savings bank account and one credit card account:\nThe most natural property we want for the Accounts database would be a balance column. Instead of maintaining this manually, we will just link this with the transactions database and derive the balance by rolling up the relevant transactions.\n\n\n\nAccounts View\n\n\n\n⚡ The accounts database simply has one row for every account you have — these could be savings accounts, credit card accounts, a cash account, or your virtual wallets."
  },
  {
    "objectID": "blog/envelope-budgeting-notion/index.html#transactions",
    "href": "blog/envelope-budgeting-notion/index.html#transactions",
    "title": "Envelope Budgeting with Notion",
    "section": "Transactions",
    "text": "Transactions\nYou might want to optionally add a memo property that lets you add a quick note or explanation for the transaction. However, given that each database entry is also a page, you could also quite flexibly add all the additional information you want to the page corresponding to any transaction. Meanwhile, you might also want to setup relations to other parts of your Notion setup if you find anything relevant — for instance, if you have a books database, or an inventory database, and so on. That said, we’re going to keep it simple here, and here’s an example transaction:\n\n\n\nAn Example Transaction\n\n\n\n⚡ Every transaction has the following: an amount, a payee, the account to which the amount was debited or credited to, the date the transaction happened, and and the expense category that the transaction belonged to. We set these up as columns with the appropriate properties, with the accounts and categories being relational links.\n\nYou’ll notice that I’ve linked to both the child and the parent category for this transaction. It would be nice if the parent category was pulled up automatically — and this is possible with a formula, but as far as I know the formula will not actually link the transaction to the main category. So for now, we assign both categories manually. 🤷‍♀️\nOne quick thing to do now is to go back to the Accounts database and add a rollup property that takes on the sum of the amounts property from the related transactions table, and once done, the balances show up nicely in the gallery view:\n\n\n\n\n\nRollup sum of amounts in accounts\n\n\n\n\n\n\nGallery view of balances\n\n\n\n\nNow we go back to our categories database and rename the relational column to transactions and add a rollup that collects all expenses from the transactions that happened in a particular category, so this is what it looks like:\n\n\n\nCategory view\n\n\nNow add a formula column available that simply adds up the budget and the expense columns so you can find out how much of your budget is still available for use. My formula looks like this:\nprop(\"Final Budget\") + prop(\"Expenses\")\nNote that it might feel more natural to subtract expenses, but my expenses are already negative amount transactions, so I just need to bundle it all together.\n\n\n\nCategory View\n\n\nJust for fun, you could also add a status column that visually indicates how much of your budget you have left. The progress-bar style of the status property here is inspired by this guide, and the formula I used requires a couple of auxiliary columns that calculate the percentage and determine if a half-star should be used or not based on the value of the decimal part. It also first checks that the available balance is in fact positive, if not, it’s going to display a suitably scary warning emoji. I won’t bore you with the specifics here, but you can find the formula in the template that I’ve linked to at the end of this post.\nSo now we are at a point where the remaining amounts are calculated based on the transactions. However, we still have to think about how to link the budgeted amounts to the actual money available. In fact, speaking of money available, I haven’t really touched upon how to handle transactions that are not expenses; i.e, transactions with a positive amount value and that reflect money coming into the system as opposed to leaving it. These are, of course, just regular transactions — but what category do we assign them to? All the ones we have so far really capture spends, not inflows…\nSo, it turns out that YNAB would take all this money and automatically categorize it as unassigned, or to be budgeted. We can mimic this by creating a special category called to be assigned, and have all income-type transactions categorized as such. Typically this would be transactions corresponding to a salary, client payments, refunds, credit from interest, and so forth.\n\n\n\nThe TBA Category\n\n\nNotice that the so-called expenses1 that are now accumulating in this category is actually the total amount of money that came into the system. Incidentally, if you were to just look at the sum of the balance column in the accounts database, that’s the net amount of money in the system at any given point of time.1 Remember that the expenses column just rolled up the transaction amounts in a particular category.\n\n\n\n\nAccounts View\n\n\n\n⚡ Note that transactions that just move money within your accounts, like a credit card payment, don’t need any explicit expense categories.\n\nYou also don’t need to budget separately for credit card payments, because your credit card bill is composed of transactions that were already budgeted for! Even if they were items corresponding to, say, credit card fees, you probably categorized them under Services, for example. So we won’t have a separate budget for credit card bill payments (although I should mention that YNAB does this explicitly and handles it automatically).\nAlright, so it seems like we are nearly there, except that our current situation is the following:\n\nThe amount the to be assigned category is a true reflection of incoming funds.\nThe amounts that we added to our category budgets were setup manually and generally divorced from the reality in the transactions database.\n\n\n⚡ To fix this, we need some way to move funds from the to be assigned category to the other ones.\n\nFor example, let’s say I want to budget 750 for ebooks this month. I could do this by adding a dummy transaction that debits an amount of 750 to the to be assigned category and credits it to the ebooks category. What this means is that when we roll up the amounts from all transactions, we directly obtain the amount remaining for us to spend!\nSo for the very first month, when we have a clean slate, we just have a bunch of such transactions — these won’t have any explicit account associated with them because they aren’t real transactions; and in fact you can always filter your transactions table so that you only see the meaningful ones by setting the condition that the accounts column should be non-empty.\nMeanwhile, here is how we do the budgets for our categories all over again, this time via these virtual transactions:\n\n\n\nBudget Overview\n\n\nIf you go to the to be assigned row in the categories table and look at the rollup value in the expenses column, then you’ll see that it corresponds to either the amount of money that’s still assigned (these are dollars — or in my case, rupees — that don’t have a job yet), or, in case you happen to have overshot the budget, the amount by which you are falling short. In the former situation, the available amount will be a positive number, while in the latter, it’ll be negative.\n\n\n\nTo Be Assigned\n\n\nIdeally, we just want this number to be zero, indicating that everything has been assigned appropriately. To achieve this:\n\nIf your budgets have collectively overshot the amount of money available, re-adjust them them — specifically, reduce some of the amounts — so that this is no longer the case. Of course, I am saying this from a theoretical standpoint; if your situation is that you have real expenses that you don’t have real money for, then you would want to plan for this by bringing the differential amount of money into the system via a loan, and then planning the repayment by budgeting for it as well. Dealing with debt is beyond the scope of this discussion, but I think the YNAB blog, book, and videos go into this at length.\nIf you have money left over, you could either add it to your budgets, giving yourself some extra wiggle room; but I prefer to budget for fixed amounts generally, so in this situation I’ll just add this amount to something I call a Miscellaneous or Scratchpad category. It’s something you can borrow from if you fall short later, it has no particular semantics. Some people like to sweep off any excess money into deposit accounts, and if you do this, then you might want to create those accounts in the system and enter those transactions to get rid of this positive balance.\n\nAt the end of this, you are in a situation where all money is nice and assigned. Since we started off by specifying budgets manually, we should go back and fix some formulas in our database of categories. In particular, here’s what I did to simplify things:\n\nRemove the Available column (previously this was the difference of the manually set budget and the rolled up expenses).\nRename Expenses to Available, since the rollup now just reflects what’s truly available.\n\nI’m going to leave the manually added budgets in — although we won’t use them to calculate what’s truly available any more, they will help us plan our budgets going forward.\nEverything so far should make sense for an initial setup, but what do we do when we have new incoming transactions that need to be assigned to categories? I generally like to do the budgeting exercise once at the start of every month, so any intermediate positive transactions into the system will either remain in the To be assigned category, or if you are OCD about wanting that that category to be set to zero always, you can always push this number out into your scratchpad.\nAt the start of the month (this could be another day and a different frequency; but I do recommend being consistent for simplicity), we need to refuel the categories with the funds available. There are two kinds of things that could happen here, broadly speaking:\n\nFor categories that represent a plan to save up to something, like a vacation, or a category where you feel like you want to have a certain amount of money set aside every month irrespective of how much you spent in the last month, you just want to push budget amount of money into that category via the virtual transactions we discussed earlier.\nFor other categories, which I like to think of as those having rolling budgets, you want to only assign the difference between what was budgeted and what was spent… and hopefully this is a non-negative quantity!\n\nYou could setup a checkbox to indicate which categories have rolling budgets and which ones do not, and then this formula:\nprop(\"IsRolling?\") ? (prop(\"Budget\") - prop(\"Available\")) : prop(\"Budget\")\nwill tell you how much you should budget for next month.\n\n\n\nIn this example, Ebooks are not a rolling category, so even though I need only 628.95 to meet the original budget, I’ll still set aside the full 750, and the amount that will be available will be 871.05. On the other hand, Phone is a rolling category, and presumably my phone-related expenses in the current month added up to 420, so the recommendation is to budget 420 next time so you’ll still have 500 available total.\n\n\nIn this example, Ebooks are not a rolling category, so even though I need only 628.95 to meet the original budget, I’ll still set aside the full 750, and the amount that will be available will be 871.05. On the other hand, Phone is a rolling category, and presumably my phone-related expenses in the current month added up to 420, so the recommendation is to budget 420 next time so you’ll still have 500 available total."
  },
  {
    "objectID": "blog/envelope-budgeting-notion/index.html#the-process-after-setting-up",
    "href": "blog/envelope-budgeting-notion/index.html#the-process-after-setting-up",
    "title": "Envelope Budgeting with Notion",
    "section": "The Process After Setting Up",
    "text": "The Process After Setting Up\nThere are two main times that you’ll interact with this budget: whenever a transaction is made, and once every X days to reset the budgets for the individual categories.\nAdding transactions is reasonably easy, although admittedly it’s probably not as smooth as a specialized app that might have a Siri command to do this for you or a widget that let’s you quick-add things. However, it’s not too bad, especially if you enter it right away. You could also potentially automate this via API integrations, or enter your transactions in your regular app and export them as a CSV and import them into the Notion system once every so often.\n\n\n\nTransaction Table\n\n\nThe budgeting bit is going to be a little more work, especially if you work with a gazillion categories. The formulas will guide to you what needs to be done, but those virtual transactions still need to be added manually. On YNAB, you can do what I described above (adding the deficit to rollup categories and the originally intended budgets to the others) in one click — and there are other options too, for example, you may have moved to a new location and you’re still getting the hang of what you’ll need to set aside for groceries, so YNAB will offer to budget what you spent last month, or your average expenses from the last six months, and so on. Here, since you are assigning things manually, you can definitely tweak as you go; the next month column is just a suggestion.\nYou can probably prepare a CSV file with the default budget amounts and just merge this in at the start of every month if your expenses are super predictable, and just adjust the entries that need adjusting. This will save you some time, but remember that the categories still need to be linked to manually. It’s not too bad for something that happens once a month and that will hopefully bring you some sense of control and awareness 😇\nPerhaps also try and not have a gazillion categories and sub-categories, at least to begin with — it helps to keep things simple, especially when starting out."
  },
  {
    "objectID": "blog/envelope-budgeting-notion/index.html#common-pitfalls",
    "href": "blog/envelope-budgeting-notion/index.html#common-pitfalls",
    "title": "Envelope Budgeting with Notion",
    "section": "Common Pitfalls",
    "text": "Common Pitfalls\nHere are a couple of mistakes I made frequently, even while just setting up this template!\n\nForgetting that transaction amounts corresponding to expenses should be recorded as negative numbers! If this happens very very frequently to you, you could also set this up a little differently — have a checkbox to indicate if a transaction is an expense or an inflow, and always enter a positive number reflecting the amount, and let a formula do the work of adding the sign!\nForgetting to add the parent category — this can mess up the views of what’s available in the high-level categories and cause the numbers to not tally. So if you need to debug your numbers, check for whether you have added both categories to your transactions or not!"
  },
  {
    "objectID": "blog/envelope-budgeting-notion/index.html#dashboards",
    "href": "blog/envelope-budgeting-notion/index.html#dashboards",
    "title": "Envelope Budgeting with Notion",
    "section": "Dashboards",
    "text": "Dashboards\nMost of the action here is happening in the Transactions database. You could create linked copies of this database anywhere you like and filter things out to see what you want. For instance, if you want to keep tabs on the transactions in specific accounts, you could have this on your account pages:\n\n\n\nAccount Overview\n\n\nYou could filter out transactions for a particular month, a particular category (either a top-level category or an atomic one), and so on. I think there’s plenty you can do here, but I am not sure how much of this can be automated. For instance, you might want to generate — or have over email — a monthly report of your expenses across various categories and how did relative to your estimated budgets. This should be possible by leveraging the API and tools like Integromat/Zapier/Automate.io - but I haven’t really explored the possibilities here."
  },
  {
    "objectID": "blog/envelope-budgeting-notion/index.html#missing-features",
    "href": "blog/envelope-budgeting-notion/index.html#missing-features",
    "title": "Envelope Budgeting with Notion",
    "section": "Missing Features",
    "text": "Missing Features\nIt would be nice to have a gallery view of the months of the year showing spends and budgets in each (high-level?) category. For this though I’d need the rows to correspond to months, columns corresponding to categories, which pull up transactions that happened in a particular month from said category.\nEven if I manually linked the transactions database to this calendar one, and made sure each transaction was linked to the correct row, I don’t see how I can split up those transactions across categories, since it’s not possible to add a filter to relational columns or rollups as far as I know. It’s a similar bottleneck going through the Categories database as well. This information is of course implicit in the system, I just can’t think of a neat way of visualizing it.\nThis is possible to do for the current month though:\n\n\n\nMonthly Overview\n\n\nYNAB also has more sophisticated category types — apart from budgets that roll or accumulate, you could have categories that aim to have a certain amount of funds assigned by a certain date and so on. For those who are freelancers with incomes spread over the days of the month, I think YNAB has a lot of little features that allow for a more flexible way of budgeting, which I’m not super familiar with because I’m not in this situation. This is just to say that this setup here may be both limiting and feeing because of how much of the setup is manually done. At least that’s my optimistic view right now 😀\nFinally, YNAB also has an option to reconcile accounts, which is when you declare that the numbers in YNAB match the book balance according to your bank or credit card agency. This is a neat little thing that I like to check off every so often. Here, I suppose you could just glance through the balances on the Accounts database (remember the gallery view from earlier?), but it won’t have the same song-and-dance-y feeling — but maybe this could be a recurring task that you can check off, and hopefully that will feel good 😅\nSo that’s about it! I’d love to hear any feedback on this, and suggestions for improving the setup would be very welcome too. You can duplicate the template from here."
  },
  {
    "objectID": "blog/women-in-mathematics/index.html",
    "href": "blog/women-in-mathematics/index.html",
    "title": "Women in Mathematics",
    "section": "",
    "text": "Here’s a list of books — in no particular order — about women in mathematics (broadly interpreted) largely taken from this thread. The links are mostly to versions of the books on Amazon India. Unfortunately many of them are rather expensive, but hopefully it’s a handy list to share with a librarian you know! Do leave a comment below if you have any additions.\nI’ll also leave this relatively sobering thought (or this one) here with no further comment.\n\nBooks:\n\nComplexities – Women in Mathematics\nWomen in Mathematics – The Addition of Difference\nHow to Free Your Inner Mathematician: Notes on Mathematics and Life\nAda’s Algorithm: How Lord Byron’s Daughter Launched the Digital Age Through the Poetry of Numbers\nWomen Who Count: Honoring African American Women Mathematicians\nWomen Becoming Mathematicians – Creating a Professional Identity in Post–World War II America\nPower in Numbers: The Rebel Women of Mathematics\nMy Remarkable Journey: A Memoir (Katherine Johnson)\nProving It Her Way: Emmy Noether, a Life in Mathematics\nEmmy Noether’s Wonderful Theorem\nLove and Mathematics: Sofya Kovalevskaya (alternate link)\nEinstein’s Wife: The Real Story of Mileva Einstein-Maric\nInventing the Mathematician: Gender, Race, and Our Cultural Understanding of Mathematics\nIn Code: A Mathematical Journey\nAgainst All Odds: Women’s Ways to Mathematical Research Since 1800: 6 (Women in the History of Philosophy and Sciences)\nThe Ascent of Mary Somerville in 19th Century Society\nJulia: A Life in Mathematics (ebook only)\nWomen of Mathematics: A Bio-Bibliographic Sourcebook\nA Celebration of the EDGE Program’s Impact on the Mathematics Community and Beyond\nThose Magnificent Women and their Flying Machines: ISRO’S Mission to Mars\nGirls Coming to Tech!: A History of American Engineering Education for Women\nFifty Years of Women in Mathematics\nx+y: A Mathematician’s Manifesto for Rethinking Gender\n\nIllustrated Books:\n\nMaryam’s Magic: The Story of Mathematician Maryam Mirzakhani\nNothing Stopped Sophie: The Story of Unshakable Mathematician Sophie Germain\nGrace Hopper: Queen of Computer Code\nAda Byron Lovelace and the Thinking Machine\nThe Thrilling Adventures of Lovelace and Babbage: The (Mostly) True Story of the First Computer\nThe Girl With a Mind for Math: The Story of Raye Montague\nHidden Figures: The True Story of Four Black Women and the Space Race\nCounting on Katherine: How Katherine Johnson Put Astronauts on the Moon\nEmmy Noether: The Most Important Mathematician You’ve Never Heard Of\n\nMiscellaneous:\n\nA Tribute to Professor Helena Rasiowa (PDF)\nA Groundbreaking Mathematician on the Gender Politics of Her Field (New Yorker)"
  },
  {
    "objectID": "blog/skj/index.html",
    "href": "blog/skj/index.html",
    "title": "SKJ",
    "section": "",
    "text": "This is the text of a short speech I gave at the farewell event for Prof. Sudhir Jain as he left IITGN for BHU.\n\n\n\nProf. Jain at the farewell event held on the 3rd January, 2022.\n\n\nYou can find out more about Prof. Jain’s own take on the cultural foundations of IIT Gandhinagar here, where he is in conversation with Achal Mehra.\n\n\nCanadian astronaut Chris Hadfield has said that leadership is not about glorious crowning acts. It’s about keeping your team focused on a goal and motivated to do their best to achieve it, especially when the stakes are high and the consequences really matter. It is about laying the groundwork for others’ success, and then standing back and letting them shine. If that sounds familiar, I think it’s because we have lived this experience at IIT Gandhinagar, thanks to Prof. Jain.\nOur guiding principles have been often unconventional — whether it’s about having students first, or choosing to trade short-term gains for the long-term vision. They have sometimes led to decisions that would seem quite inexplicable to anyone who did not have the context. Some of you might remember how early we started the undergraduate program in Computer Science, for example. Ok, so for the record, we started it quite late, at least according to conventional wisdom.\nCrucially, these core values have always been articulated in collaboration, with inputs from all stakeholders, which is what enables our shared conviction in them once they have been established.\nProf. Jain’s vision for IIT Gandhinagar is as precise as it’s bold – he knew exactly what needed to be done for this place to emerge as a model institution. He had recently shared with us his roadmap for IITGN from a dozen years ago. This roadmap committed not to vague ideas but concrete goals, complete with numbers for metrics that are fraught with uncertainty. It’s absolutely stunning how everything panned out almost exactly according to plan!\nOur narrative has many collaborators, including our students, faculty, and staff. And while some of us are relatively inexperienced, Prof. Jain’s trust in everyone has been hugely empowering. It manifests in many concrete ways – starting from wanting for students to be recognized as adults, to turning young colleagues into decision-makers… and this is why all of us have a deep sense of ownership for IITGN.\nAn environment that gives all of us the freedom to experiment and the leeway to fail is extremely enabling. This has led to a wide spectrum of wins, many that are quantifiable and others that are less tangible. If you want to get a sense of how good the times have been, just look around – the sheer beauty and the attention to detail that the campus embodies is an excellent symbolism for the inclusive, thoughtful, and innovative leadership that we have experienced. When it comes to how far we have come, I could go on… pretty much forever, so I’ll defer you to the website for more details.\nIt is impossible to imagine IITGN without you. This is your brainchild through and through. Despite knowing that you’ll not be distancing in spirit, we will miss having you nurture the institution in the hands-on manner that you have always done. Your passion for the IITGN mission – of being a breakout university while operating within the limitations and strengths of the IIT system – is contagious. I am sure you plan to double down on this even though you may have a few distractions going forward.\nI recently watched Maanaadu, a movie based on the idea of a time loop. In such stories, the plot involves the protagonist experiencing the same day over and over again, and their goal, typically, is to find an exit. If there is one day that we could put into a time loop, it would be today, and there would be no need to get out of it.\nIn the meantime – on behalf of all of us, thank you.\nThank you for your commitment, trust, and friendship; for listening patiently, for leading tirelessly, and for fighting the good fight through tough times, and for the good times through tough fights – ok, I’m going to be out of time, here, clearly – so let me just say, thank you for everything."
  },
  {
    "objectID": "blog/homework-help/index.html",
    "href": "blog/homework-help/index.html",
    "title": "How Expensive Can Homework Help Be?",
    "section": "",
    "text": "This post is based on an expository explanation of iterative compression that I attempted at the Institute Seminar Week in 2010, at IMSc.\n\n\n\nTapesh has been struggling lately with the dire task of undergraduate homework. He has been asked to find a vertex cover on 23 vertices - not one more - in a graph that has a thousand vertices. Being the straightforward boy that he is, Tapesh considers writing a program that will try its luck on every possible subset of 23 vertices.\nHe then heads over to Wolfram Alpha to check how long it will be before he’s done examining all the {1000 \\choose 23} possibilities, assuming (rather liberally) that he has at his disposal a computer that can perform 10^{24} operations per second.\nIt turns out that he, and more critically, his professor, would be in for a long, long wait. The algorithm would need time proportional to the age of the universe many times over, and this is decidedly depressing, particularly when one’s expected lifespan appears to be determined by the deadline for turning in homework.\nTapesh now appeals to his very clever cousin, Prodosh, for help.\nProdosh borrows the monstrous graph, and in short order, points out a vertex cover on 24 vertices, using powers evidently beyond what processors with 10^{24} FLOPS can do. Tapesh is thrilled, however…\n“I need to get one with 23, the assignment says not one more —”\n“Time for a smoke,” Prodosh yawns, and then delves into a distracted, pensive mood, with no signs of immediate return.\nTapesh is torn, but he decides to (gulp) show whatever he has so far - after all, it is progress!\nPredictably, Professor Maganlal displays no signs of being impressed, but he grudgingly admits that Tapesh’s solution (which we will call T) is not very far from the correct answer, and points out those vertices in T that happen to partake in the solution that was sought.\nTapesh is back to the drawing board, but with the distinct feeling that he is now armed with enough information to crack the code himself.\nHis solution T is now partitioned into the good part (T_G), that is, all the vertices of T that belong to X, and the bad part (T_B), which are all the vertices that do not belong to X.\n“Aha.”\nNecessarily, all the neighbors of the bad part must belong to X!\nHe checks, and sure enough, the number of vertices in T_G and N(T_B) is an exact, resounding 23. Also, very fortunately, there are no edges in T_B, so he has no trouble swapping T_B for N(T_B) to get to the newer and smaller vertex cover.\nMission accomplished!\nNow more confident, Tapesh wonders if he could have arrived at X all on his own. Indeed, what would he have done without Pradosh’s help? And without Professor Maganlal giving him that partition?\nCome to think of it, the second question has an easy answer. Tapesh would just try all possible partitions of the solution that Pradosh had given him. He would only have to disregard the partitions that didn’t work… and sooner or later, he would hit the one that his Professor so graciously suggested. This would mean examining 2^{24} subsets, a matter of a split second for a personal computer.\nBut - can he replicate Pradosh’s magic on his own?\nTapesh is up into the middle of the night waiting for the brainwave that will make him completely self-dependent, at least in the broad context of finding small vertex covers in large graphs.\nHe is still impressed that he has just found a general scheme for taking a vertex cover of size 24 and bringing it down to 23. Wanting to make the most of the only trick he knew, he wondered if he could use it more than once.\nSo he looked at the 1,000-vertex monstrosity and contemplated the possibility of working with a manageable chunk first. What if he selected an easy subgraph H for isolated consideration? Surely, if G has a vertex cover of 23 vertices, H has one too. So all he would need is to find a vertex cover on 24 vertices, and he already knew how to squish it to one of size 23.\nWhat was the easiest chunk that he could work with? One on which finding a vertex cover of size 24 wasn’t hard?\nBut of course, a subgraph on 24 vertices would be really easy to deal with!\nThe entire graph H would serve as its own vertex cover, would be of size 24 — it couldn’t get easier than that.\nSo Tapesh starts by selecting the first 24 vertices that he can find, and applies his squishing strategy to find a vertex cover on 23 vertices.\nWhat now?\nHe gives the remaining 976 vertices a hesitant look.\nMaybe it was time to grow H to include some more vertices? If Tapesh could get H to eventually morph into being all of G, he would be done!\nBut if he added a whole bunch of new vertices, he would need to do something about finding a vertex cover of size 24 in the bigger H to make progress… but that sounded like work :(\nMaybe, maybe just let in one more vertex into the precious subgraph H? Indeed, there is enough room in the vertex cover of size 23 for one more vertex. So H would grow by a single vertex, and so would the vertex cover - and then Tapesh could squish it again!\nAnd there is no stopping Tapesh from repeating this 975 times more, and each time, the reincarnated H would be one larger than before, and every time he would beat down the vertex cover to one of size 23, till he got to the end.\nBut, Tapesh wonders sleepily, wouldn’t this take awfully long?\nThe squishing was quick, and now it has to be done 977 times altogether… and even at the lesiurely pace of doing one iteration in one second, you would need less than half an hour before you finished.\nNot too shabby — certainly no waiting for universes to come and go!\nIn general, the problem of finding a vertex cover of size k in a graph on n vertices vertices can be done in time:\nO((n-k) \\cdot 2^{k+1})\nfollowing the recipe in this story.\nIf this algorithm aborts, unable to find a vertex cover of size k, it is because a subgraph did not have a vertex cover of size k. Of course, this also means that the entire graph does not have a vertex cover of size k either, so the process makes sense.\nIt is important to note that not every problem is designed to fit this bill, for instance, if the next homework assignment demands a vertex cover that is also connected, the iteration procedure, as it stands, might not be accurate when it reports a negative answer.\nThe next assignment, therefore, potentially leads to a more demanding adventure."
  },
  {
    "objectID": "blog/pandoc-letters/index.html",
    "href": "blog/pandoc-letters/index.html",
    "title": "Letters with Pandoc",
    "section": "",
    "text": "Letter-writing season is around the corner. I recently adapted this pandoc workflow for generating PDF letters by only editing a markdown file. I only made the following minor changes to the original:\n\nFor this to work you will need pandoc and a TeX distribution installed. For a full-fledged TeX distribution check out something like MacTeX and for a minimal variation, see TinyTeX.\n\n\nIncluded the fontawesome5 package so I could add icons alongside the phone number, email, and website in the letterhead.\nChanged ThisULCornerWallPaper to CenterWallPaper and added wpYoffset and wpXoffset so I could get a left margin on the logo (I suppose this could also be done by offsetting the logo in the letterhead.pdf file).\n\nHere’s what the output looks like with some random sample content:\n\n\n\nSample letter produced with the pandoc workflow\n\n\nThe markdown is very simple to edit — most of the information is up in the YAML header, and it looks like this:\nauthor: Fyodor Michailovitch Dostoevsky\ncity: Moscow\nfrom:\n- By the Vladimirkirche\n- care of Pryanischnikof, Grafengasse.\naffiliation1: Add an affiliation\naffiliation2: Potential Additional Information\ncontact: \n- \\faPhone \\ +91 79 1234 1729\n- \\faGlobe \\ https://www.google.com\n- \\faEnvelope \\ nobody@nowhere.com\nto:\n- Michael\n- Someplace\n- with an address\nsubject: An Update\nsalutation: My dearest\ntoname: brother\ncustomdate: 1838-8-9\nWrite the body of the letter in markdown as usual, and generate the PDF by running:\npandoc letter.md -o output.pdf --template=template.tex --pdf-engine=xelatex\nor have a makefile that looks like this:\nTEX = pandoc\nFLAGS = --pdf-engine=xelatex\n\nsrc1 = template.tex letter.txt\nop1 = output\n\nall : $(op1).pdf\n\n$(op1).pdf : $(src1)\n    $(TEX) $(filter-out $<,$^ ) -o $@ --template=$< $(FLAGS)\nFor your first use, you would want to update the images for the letterhead and the signature, and optionally customize the fonts to your liking. Fork this repo to make your own!"
  },
  {
    "objectID": "blog/comms/index.html",
    "href": "blog/comms/index.html",
    "title": "External Communications",
    "section": "",
    "text": "I finish seven years at IIT Gandhinagar today.\nThis year, I also concluded my stint with the Department of External Communications, which feels about as long. Indeed, little did I know that a casual remark that I had made during my interview1, about wanting to be a writer for as long as I can remember, was carefully noted — and magically my service responsibilities would end up being related to my childhood dream. A few days after I joined, I met Achal Mehra, who introduced me to Connections: a four-page newsletter that went places every quarter. In my mind, that conversation kickstarted my collaboration with what everyone fondly calls “comms”. Seven years later, I’m here to report that the journey has been fun and fulfilling in equal measure.\nThrough this post, I’d like to introduce you to the comms team: if you have been to IITGN for an event, read about us in the press, have recieved a newsletter from us, visited our website, or followed our social media: these are the folks who work behind the scenes on these fronts. Being a part of this gang has been a huge inspiration: everyone is talented but always willing to learn; their hard work is driven by a sense of ownership; and there’s plenty of wit to help beat the heat :)\nHere’s collection of some randomly chosen memories: my hat-tip to a stellar team."
  },
  {
    "objectID": "blog/comms/index.html#hatim",
    "href": "blog/comms/index.html#hatim",
    "title": "External Communications",
    "section": "Hatim",
    "text": "Hatim\nHatim joined us in the summer of 2018 and worked with us for four years. This summer, he moved on to join the design unit at ISDM as a Graphic Designer and Video Editor.\nHatim has had a creative flair from the get go. He’s been a part of several exciting projects, including being the person behind the visuals for Alok Kanungo’s book, Glass Crafts in Northern India. Also, here’s a cool trailer he put together very quickly for the ACM-W India Grad Cohort that I was involved in organizing in 2020."
  },
  {
    "objectID": "blog/comms/index.html#dilip",
    "href": "blog/comms/index.html#dilip",
    "title": "External Communications",
    "section": "Dilip",
    "text": "Dilip\nDilip joined us in the summer of 2018. He had a distinct passion for developing mobile and web applications, and indeed, he’s been a huge asset to the web vertical of the team. He’s been relentless in learning new things and has been writing on Medium too.\nWhen we were organizing the ACM-India Annual event and the team was freaking out over having upwards of 1000 registrations, Dilip wrote a mobile app for us — literally overnight — which allowed us to send all participants a QR code that they simply had to show to get through physical registration. It saved us a ton of time. You can find out more about Dilip here."
  },
  {
    "objectID": "blog/comms/index.html#tej",
    "href": "blog/comms/index.html#tej",
    "title": "External Communications",
    "section": "Tej",
    "text": "Tej\nTej joined us in the winter of 2016 as a web developer and has been my officemate. Tej is among the first points of contact for all new faculty at IITGN: their institutional profile pages are set up even before they actually set foot on campus. Tej’s name is synonymous with “website”. If anyone needs one done, whether it’s for their lab, or an event, he’s always been an email away. True to an appropriate mispronouciation of his name2, Tej has remarkable turnaround times, and seems to get things done as fast as you can spell them out.\nOne of my most memorable projects with Tej (along with Dilip, Divyangi, and the rest of the team) is the revamp of the main IITGN website. We went from this:\n\n\n\nThe old IITGN website, here.\n\n\nto this:\n\n\n\nThe current IITGN website, here.\n\n\nin about a year. Despite several very well-intended warnings about how crazy this was, the team picked up the project with cautious courage, and pulled it off. I think I can say with some confidence that the IITGN website is easy on the eyes, and things are not hard to find."
  },
  {
    "objectID": "blog/comms/index.html#apeksha",
    "href": "blog/comms/index.html#apeksha",
    "title": "External Communications",
    "section": "Apeksha",
    "text": "Apeksha\nApeksha joined us in the summer of 2019, just on the heels of completing her MTech in Biological Engineering at IITGN, and stayed with the team for a year. At the time of joining, she was an avid consumer of popular science material, and aspired to make the research at IITGN more broady accessible with her writing. She was a freelance writer already, and was looking for an opportunity to spend some time writing full-time. Her stint with us resulted in a number of articles, and her growth during the time has been remarkable. You can find her writing on her Medium blog.\nThe ACM-W India Grad Cohort event we did in 2020 was a virtual one, and in the tradition of Grad Cohorts, was not recorded. I am grateful that Apeksha stepped up at the time, offered to attend all the sessions, and wrote up comprehensive summaries.\nShe has now joined the Ph.D. program in the Humanities and Social Sciences and is currently researching cognitive aspects of science communication with Frederick Coolidge."
  },
  {
    "objectID": "blog/comms/index.html#dhara",
    "href": "blog/comms/index.html#dhara",
    "title": "External Communications",
    "section": "Dhara",
    "text": "Dhara\nDhara joined us in the summer of 2018, and immediately got to work on managing our social media channels. She also streamlined the process of collecting information: a lot of what we do revolves around robust archival, and IITGN being a happening place does not make this easy! We get dozens of emails every day announcing events of varying scales, updates of various kinds.\nAnticipating that the volume would only get worse, we devised a system for manually cataloging every bit of news in a bunch of Airtable bases. The long-term vision was that the Airtable API exposes this data to anyone who needs it: the web team could draw from it and filter appropriately to display upcoming events, an archival team could write a report generating app that used this as the backend, and so forth. We even had a web app developed by a team of undergraduates that pulled data from these bases to show off upcoming events on a big screen.\nDhara now manually curates information from these databases and runs a weekly internal newsletter collating what’s happened and what’s coming up at IITGN: this has been a major value addition for many. She also serves up the raw data needed for our public quarterly newsletter and annual reports based on this system, which saves everyone a lot of time. Apart from all of this, she is in the driver’s seat for all our major social media channels, and then some… and magically manages to stay on top of everything. You can find her writing on Medium."
  },
  {
    "objectID": "blog/comms/index.html#divyangi",
    "href": "blog/comms/index.html#divyangi",
    "title": "External Communications",
    "section": "Divyangi",
    "text": "Divyangi\nDivyangi joined us in the summer of 2018 and worked with us for three years until the summer of 2021. She was a wizard when it came to scripting for automating tasks, and quickly became the go-to person for departments who were looking to improve their workflows.\nIITGN runs on the Google ecosystem. Divyangi figured out several nice ways of bringing data from spreadsheets to frontends, generating reports, and so forth. She even ran a workshop on Google scripts and related tools as a part of an initiative coordinated by our Staff Development Cell.\nAmong the many projects Divyangi was involved in, one of my favorites was the backend for our rather popular Summer Research Internship Program. The website is powered by WordPress, and provides various interfaces for both interns and mentors to keep track of their applications during the application phase (this runs into tens of thousands of records), and progress during the internship (updates from interns and feedback from mentors are all managed from here). Divyangi, together with Dilip, deeply customized the WordPress instance to provide a number of features that help with running a large-scale program smoothly, with most of the tedious tasks completely automated."
  },
  {
    "objectID": "blog/comms/index.html#chandni",
    "href": "blog/comms/index.html#chandni",
    "title": "External Communications",
    "section": "Chandni",
    "text": "Chandni\nChandni joined us in the summer of 2019 for a year. She was already a very talented photographer at the time of joining us. As our events and activities grew in number and scale, we found very valuable support in Chandni’s presence. Check out her Instagram here!\n\n\n\nA sample of Chandni’s photography"
  },
  {
    "objectID": "blog/comms/index.html#vandana",
    "href": "blog/comms/index.html#vandana",
    "title": "External Communications",
    "section": "Vandana",
    "text": "Vandana\nVandana joined us in the summer of 2017 in the role of a Communications and Media Officer for a year. During this time, she was working closely with local press and media, and ensuring that our stories are filed with them on a regular basis.\nVandana was already passionate about writing and had a keen eye for detail. She filled an important void at the time she joined and immediately setup various important foundations in the context of this role. She expanded our style guide, made a press kit, and developed a starting database of journalists that we could work with: these are all tools that the whole content team uses regularly to this day.\nHer spirit of volunteerism meant that a lot of our content got reviewed and improved across the board: on the website, on our brochures, and so forth. This was also the time when we launched what I think is our best-kept secret: IITGN’s news blog. Vandana, along with the rest of the team, setup a careful pipeline to ensure that everything we capture across press and social media gets a permanent home on the blog. She continues to pitch in remotely, even after moving on from her onsite role with us on campus."
  },
  {
    "objectID": "blog/comms/index.html#shivangi",
    "href": "blog/comms/index.html#shivangi",
    "title": "External Communications",
    "section": "Shivangi",
    "text": "Shivangi\nShivangi joined us in the summer of 2018 in the role of a Communications and Media Officer, picking up from where Vandana left off. She has been synonymous with media and press at IITGN, and is currently our main interface with the press. She has substantially expanded on our network of partners in press, and ensures that we have the visibility we deserve in the local and national news, and even beyond. She is especially diligent about ensuring that regionally-focused news is appropriately translated in the local languages whenever appropriate, a widely appreciated effort.\nShivangi’s style has been remarkably proactive: if anything at IITGN is newsworthy, she makes sure it’s covered. She draws on her substantial experience in the field to bring nuanced insights to the table, and these have served us very well in our overall communications and outreach strategy.\nBeyond coordinating stories for the press, Shivangi also comprehensively tracks IITGN’s presence in the news and other public domains, is closely invovled in the production of the quarterly newsletter and annual reports, and our social media activities as well. Shivangi is, unsurprisingly, an amazing writer, and here’s a performance of hers in a SDC event that was among my favorites."
  },
  {
    "objectID": "blog/comms/index.html#gaurav",
    "href": "blog/comms/index.html#gaurav",
    "title": "External Communications",
    "section": "Gaurav",
    "text": "Gaurav\nGaurav has been around for longer than I have, and he is a founding member of the team. He is among the most versatile people I know: not only does the scope of his work at IITGN go well beyond communications, even within communications his skills span a very wide range: he’s behind the camera, he’s the person behind the design and layouts for some of our best print collaterals, he’s directed and produced a number of videos, and I could go on and on.\nI’ve freely relied on his mentorship: much of the growth that has happened within the team, especially in terms of creative efforts, is thanks to Gaurav’s experience and guidance.\nIf you pick up any of our booklets, there’s a good chance that Gaurav has been involved in engineering the layout and design. Among them, I’ll single out a couple for you to sample: the World Class Faculty brochure looks especially lovely in print, and the 10 on 10 brochure has a bold aesthetic that was a crowd favorite when it was released for our 10-year celebration."
  },
  {
    "objectID": "blog/comms/index.html#devarsh",
    "href": "blog/comms/index.html#devarsh",
    "title": "External Communications",
    "section": "Devarsh",
    "text": "Devarsh\nDevarsh joined us in the summer of 2017, with a background in creative film-making and theatre. He quickly became the go-to person when it came to anything to do with video or photography. Over the years here, he’s grown leaps and bounds in his craft and understanding of all aspects of the process — both work that happens on the field and in post.\nOur YouTube presence was in its nascent stages when Devarsh joined. He’s single-handedly worked on our channel in mission mode from the get go, and it is largely thanks to his efforts that we have a fairly systematic video respository of most major events and talks on campus.\nDevarsh has been involved in several memorable projects. Here’s a video that he shot for our first virtual convocation, which also happened to be among the first virtual convocation events to be held in India (as far as we know)."
  },
  {
    "objectID": "blog/comms/index.html#nostalgia",
    "href": "blog/comms/index.html#nostalgia",
    "title": "External Communications",
    "section": "Nostalgia",
    "text": "Nostalgia\nSome of the early members of the team are not pictured. Apart from everyone above, I had the good fortune to have worked with: Ritu (among other things, was the curator for all the early editions of the quarterly newsletter, Connections, and our annual reports), Dayanand (our first communications and media officer), Maria (our first social media intern), and Khushbu (who took over from Maria and preceded Dhara on managing social media).\nIt would be remiss of me to not give a shout out to the faculty support we have enjoyed over the years. Several colleagues have played major roles in helping out on all aspects of our responsbilities. A special thanks to Achal Mehra, who brought extensive experience to the table, and has been forever generous with his time and advice, and Vasco Trigo, whose inputs for the whole team were extremely timely and valuable.\nI’ll also take this opportunity to thank friends at the Communications department at Duke University — they hosted us in the very early days, and their detailed and candid tour of various operational aspects was massively helpful in setting up a lot of the foundations back here.\nI walked into this gig more or less by accident. I should confess here that I didn’t have a 5-year vision from which I could work backwards to nicely chunked milestones. There were no OKRs or KPIs or whatever else the pros do. A few times, it’s occurred to us that we should have targets, strategies, and systems3. While we never articulated any as far as I can remember, I think we did have a tacitly shared goal: it was to ensure that everyone got what they needed from comms, and that we didn’t make any mistake twice. My biases notwithstanding, I would say we have largely succeded :)\nMy time with this team remains special forever."
  },
  {
    "objectID": "blog/massren/index.html",
    "href": "blog/massren/index.html",
    "title": "Massren for fast file renaming",
    "section": "",
    "text": "My tool of choice for bulk file-renaming has become1 Massren:1 As opposed to, say, GUI clients.\n\nMassren is a command line tool that can be used to rename multiple files using your own text editor. Multiple-rename tools are usually difficult to use from the command line since any regular e xpression needs to be escaped, and each tool uses its own syntax and flavor of regex. The advantage of massren is that you are using the text editor you use every day, and so you can use all the features you are already used to.\n\nSimply navigate to the directory in which your files are and invoke massren. You can easily set it up to use your favorite text editor, so for example, I have mine configured to use VSCode:\nmassren --config editor code\nIf you have a text editor you are comfortable with, then this can lead to all kinds of interesting possibilities, especially when combined with regular expression search.\n\n\n\nUsing Massren, VS Code, and regex for bulk file renaming.\n\n\nThis workflow is especially convenient in combination with an Alfred wokflow to open the current Finder directory in the terminal, such as this one."
  },
  {
    "objectID": "blog/communication-complexity-equality/index.html",
    "href": "blog/communication-complexity-equality/index.html",
    "title": "On the Communication Complexity of Equality",
    "section": "",
    "text": "These are some quick sketchnotes based on  this lecture by Ryan O’Donnell, a part of the  playlist for the awesome CS Theory Toolkit course. You can walk through the arguments below.\n\n\nI should mention that while the Schwartz-Zippel-DeMillo-Lipton lemma is invoked in the notes below, one could make do with just the fact that over any field F, any degree n polynomial has at most n roots, as pointed out by @dsivakumar — thanks!\n\n\nIn the fourth slide from the end, why [DeMillo–Lipton]–Schwartz–Zippel Lemma? You only need that number of roots of a polynomial (over Z mod q) of degree n is no more than n. You don't need D-L/S/Z, which gives a general version for multivariate polynomials, right?\n\n— D. Sivakumar (@dsivakumar) June 6, 2020"
  },
  {
    "objectID": "blog/iit-rankings/index.html",
    "href": "blog/iit-rankings/index.html",
    "title": "The Only Fair Ranking of IITs",
    "section": "",
    "text": "Don’t like the ranking? Try again.\n\n\n\n\n\n\n\nMethodology: adapted from here.\n\n\n\nThe program takes all the available knowledge in the universe and extrapolates a score for each IIT using state of the art algorithmic techniques (i.e., deep guessing). To resolve ties, the program also computes a secondary score which is a random number. The program next computes a weighted average of the two scores - the weight assigned to the first score is based on its scientific value and merit, and is thus zero, and the remaining weight is assigned to the secondary score (i.e., 1). The program then sort and output the departments in decreasing ordering of their weighted scores.\n\n\nInspiration  Check this page for a ranking of computer science departments.\n\n\nimport { shuffle } from \"./shuffle.js\"\n\narr = [\"IIT Kharagpur\", \n\"IIT Bombay\", \n\"IIT Madras\", \n\"IIT Kanpur\", \n\"IIT Delhi\", \n\"IIT Guwahati\", \n\"IIT Roorkee\", \n\"IIT Ropar\", \n\"IIT Bhubaneswar\", \n\"IIT Gandhinagar\", \n\"IIT Hyderabad\", \n\"IIT Jodhpur\", \n\"IIT Patna\", \n\"IIT Indore\", \n\"IIT Mandi\", \n\"IIT (BHU) Varanasi\", \n\"IIT Palakkad\", \n\"IIT Tirupati\", \n\"IIT (ISM) Dhanbad\", \n\"IIT Bhilai\", \n\"IIT Dharwad\", \n\"IIT Jammu\", \n\"IIT Goa\"];\nx = shuffle(arr);\ny = document.getElementById(\"quarto-document-content\");\n\ny.innerHTML += \"1. \" + x[0] + \"<br> 2. \" + x[1] +  \"<br> 3. \" + x[2] +  \"<br> 4. \" + x[3] +  \"<br> 5. \" + x[4] +  \"<br> 6. \" + x[5] +  \"<br> 7. \" + x[6] +  \"<br> 8. \" + x[7] +  \"<br> 9. \" + x[8] +  \"<br> 10. \" + x[9] +  \"<br> 11. \" + x[10] +  \"<br> 12. \" + x[11] +  \"<br> 13. \" + x[12] +  \"<br> 14. \" + x[13] +  \"<br> 15. \" + x[14] +  \"<br> 16. \" + x[15] +  \"<br> 17. \" + x[16] +  \"<br> 18. \" + x[17] +  \"<br> 19. \" + x[18] +  \"<br> 20. \" + x[19] +  \"<br> 21. \" + x[20] +  \"<br> 22. \" + x[21] +  \"<br> 23. \" + x[22];"
  },
  {
    "objectID": "blog/dogs-bunny-puzzle/index.html",
    "href": "blog/dogs-bunny-puzzle/index.html",
    "title": "Dog Bunny Puzzle",
    "section": "",
    "text": "Dog Bunny: A Cute Puzzle\nConrad Barski (@lisperati)’s latest, Dog Bunny Puzzle, had jumped to #1 on HN. The puzzle presents the following somewhat minimalist interface:\n\n\n\nThe Dogs Bunny Puzzle\n\n\nIf you haven’t played it yet, you might want to go ahead and give it a shot first. Most people figured out the mechanics without any explicit instructions. A couple of things that may not be immediately clear, but typically discovered quickly within a few moves:\n\nThe edges are labeled with conditions, and can be used only if all of the said conditions are met.\nThe bunny or dog icons may sometimes cover up what kind of location they are at. You can drag them away to find out!\nMultiple animals can occupy the same spot at a time.\nIt is possible to get into a dead end, a situation from where no legal moves are possible. In the verison of the game that is available at the time of this writing, the game offers no sign that you might be in this situation. This may however change.\n\nAfter winging it on the puzzle, several questions seemed natural:\n\n\n\n\n\n\nWhat’s the smallest number of moves to win?\n\n\n\n\n\nApparently 26.\n\n\n\n\n\n\n\n\n\nCan you write a program to find a solution?\n\n\n\n\n\nYes (Python) and yes (Picat).\n\n\n\n\n\n\n\n\n\nCan a script generate more of these puzzles?\n\n\n\n\n\nIndeed:\n\n\nFor those paying attention, yes I am two days late :(FYI, I also have a program now that can create an infinite number of these puzzles at differing difficultyHow would you rate the puzzle I posted today?\n\n— Conrad Barski (@lisperati) September 17, 2022\n\n\n\n\n\n\n\n\n\n\n\nAre there connections with other well-known puzzles?\n\n\n\n\n\nWhy yes, check out the Wolf puzzle (as pointed out by @RianNeogi) and this Numberphile video about it.\n\n\n\n\n\n\n\n\n\nIs the problem NP-complete?\n\n\n\n\n\nBefore you ask, I am not the only one who’s asking!\n\n\n\nSo the last question may strike you as a bit left-field, but that’s what I’m going to ramble about for the rest of this post :) It turns out that the answer is in the affirmative, and here is a lovely reduction by @lokshtanov showing as much.\n\n\nThe Reduction\nLet’s just set up the game as a computational problem just to be sure that we agree on the abstraction. In fact, we’ll be working with a simpler version that we will call BunnyCarrot.\n\n\n\n\n\n\nBunnyCarrot\n\n\n\nIn the BunnyCarrot problem, the input is a simple undirected graph G = (V,E), subsets B and C of V indicating the initial positions of bunnies and carrots, and a (possibly empty) instruction r_e for every e \\in E, which is a collection of conditions, at least one† of which must be true for the edge e to be “active”.\nThe question is if there is a sequence of movements of bunnies along active edges such that at the end of the sequence, every bunny is located at one of the vertices from C.\n† In the original version of the problem, we need all conditions associated with an edge to be satisfied, not at least one. The construction that we will describe can be easily adapted to this setting as well, but is simpler to describe for this variant :)\n\n\nWe are going to show that BunnyCarrot is NP-complete by reducing from 3SAT. So let \\phi := \\{C_1, \\ldots, C_m\\} be a collection of m 3SAT clauses over variables \\{x_1, \\ldots, x_n\\}. The reduced instance of BunnyCarrot corresponding to \\phi looks like this:\n\n\n\nA cartoon sketch of the reduced instance of BunnyCarrot from 3SAT.\n\n\nWhat we have here is the following in terms of the structure of graph:\n\na path X on m+2 vertices, with the left most vertex in B and the rightmost one in C;\na pair of vertices (u_i,v_i) for every i \\in [n], and an edge between them, where all the u_i’s are in B’ — the vertex u_i represents the literal x_i while the vertex v_i represents the literal \\overline{x_i};\na pair of vertices p and q in C, with p adjacent to all u_i’s and q adjacent to all v_i’s.\n\nNow here be the instructions associated with the edges:\n\nthe edge to the \\ell-th vertex on X is active only if there is a bunny on at least one of the literals present in the clause C_{\\ell-1};\nthe edges between u_i and v_i are active only when there is a bunny on the leftmost vertex of X; and\nfinally, the edges incident on p and q are active only when there is a bunny on the rightmost vertex of X.\n\n\n\nThe Forward Direction\nWe first claim that we can “win” this game if \\phi has a satisfying assignment. Indeed, let \\tau: \\{x_1,\\ldots,x_n\\} \\rightarrow \\{0,1\\} be a truth assignment that satisfies all the clauses of \\phi. Then:\n\nIf \\tau(x_i) = 0, move the bunny on u_i to v_i.\nMove the bunny on the leftmost vertex of the path X to the rightmost vertex: note that all edges are active because \\tau is a satisfying assignment.\nMove all bunnies on u_i’s to p and those on v_i’s to q.\n\n\n\nThe Backward Direction\nNow suppose there is a winning sequence of moves \\sigma. We will show that we can extract from this sequence a satisfying assignment for \\phi, which will firmly establish the equivalence of the generated instance of BunnyCarrot with the OG hard instance \\phi.\nNote that to begin with, all the blue edges are inactive. Now, in the sequence \\sigma, let us say that a step is key if it involves a bunny moving along the first edge of the path X and critical if it involves a bunny moving along the last edge of the path X.\nSuppose the \\ell-th step is the first critical step in \\sigma. Further, suppose that the t-th step is the last key step to occur before the \\ell-th step. Notice that there must be at least one key step before a critical step — we must begin before we can end :)\nNow, for all steps after the t-th step and before the \\ell-th step, note that edges incident to u_i and v_i are inactive for all i \\in [n]. This implies that every step between the t-th and \\ell-th steps involves a bunny moving along X, and in particular, every edge in X is crossed at least once in this phase of the game.\nLet us note the positions of the bunnies who are on the u_i’s and v_i’s after the t-th step is executed. Observe that this naturally translates to an assignment on the variables as follows:\n\n\\begin{equation*}\n    \\tau(x_i) =\n    \\begin{cases}\n      1 & \\text{if } u_i \\in B,\\\\\n      0 & \\text{if } v_i \\in B.\n    \\end{cases}\n\\end{equation*}\n\nWe argue that \\tau must in fact be a satisfying assignment.\nAssume to the contrary: suppose some clause C_k is, in fact, not satisfied by \\tau.\nThen, we claim that the edge connecting the k-th and (k+1)-th vertices is not active.\nAs an example, suppose C_k = \\{x_1,x_2,\\overline{x_3}\\}. Since \\tau does not satisfy C_k, it must be the case that:\n\n\\tau(x_1) = 0 — and hence there is a bunny on v_1;\n\\tau(x_2) = 0 — and hence there is a bunny on v_2;\n\\tau(x_3) = 1 — and hence there is a bunny on u_3.\n\nHowever, the condition for the edge to the (k+1)-th vertex on X to be active is simply that there is a bunny present on at least one of the literals present in the clause C_{k}, i.e, one of u_1, u_2 or v_3. However, because of the structure of the graph, and the fact that all edges incident on p and q are inactive at all times before the first critical step, observe that:\n\nIf there is a bunny on v_1, there is no bunny on u_1.\nIf there is a bunny on v_2, there is no bunny on u_2.\nIf there is a bunny on u_3, there is no bunny on v_3.\n\nBy our assumption that \\tau falsifies C_k, all the premises above are true! So there is an edge on the path X that is not active between the t-th and \\ell-th steps, which violates our understanding that every edge was crossed between these steps. This is a contradiction, and hence \\tau must indeed be a satisfying assignment.\nI’ll just remark here that this construction can be modified so that every vertex in the graph has constant degree, and there is only one vertex in C. It can also be modified to change the “or” condition on the edges to an “and”, by simply separating the conditions out along multiedges.\n\n\nFood for thought\nHere are some more questions :)\n\n\n\n\n\n\n\nWhat’s the complexity of this game when the underlying graph has some simple structure (e.g, a tree)?\nDoes the problem get harder if we introduce attacking entities like wolves?\nCan we come up with an algorithm that runs in polynomial time on instances where there is a valid winning sequence of constant length?\nIs the problem hard even for a constant number of bunnies?\n\n\n\n\nPS. Here’s a sketch of a slighty different reduction from vertex cover. Thanks again to Daniel for sharing the reduction described here! Comments welcome here, or continue the conversation on Twitter!"
  },
  {
    "objectID": "blog/new-mac/index.html",
    "href": "blog/new-mac/index.html",
    "title": "New Mac",
    "section": "",
    "text": "Here’s a list of 50 things1 (with occasional additional context) that I install whenever I’m setting up macOS from scratch.\n\n\n\n\n\n\nvia Setapp\n\n\n\n\n\n\nBartender\nKeeps the menubar clean. Very handy!\nBetter Touch Tool\nI really need to leverage this a lot more, but even simple actions like swipe down with three fingers to close a tab, or tip-tap right left to move between tabs is pretty awesome already. Also use four-finger double tap to make the mouse pointer larger when it’s lost between screens… I’d guess this app can probably subsume a lot of the functionality offered by apps like Keyboard Maestro and Alfred.\niStat Menus\nGood-looking stats in the menubar 👍️\nYoink\nHas to be one of the best shelf apps out there. I know that there are a bunch of others in this space right now (👀, Filepane), however I have been using Yoink for so long that I haven’t considered switching. My common use-cases:\n\nAlfred actions to send-to-Yoink\nUsing Yoink to stash away screenshots before the floating image disappears\nA KM shortcut that can send any Finder item to Yoink\n\nCleanMyMac\nMostly to keep track of file sizes via the Space Lens, and running cleanups once in a while.\nAlternative if using only this feature: Daisy Disk\nDefault Folder X\nUse this all the time to stash away stuff where it belongs to keep Downloads clutter-free. Also the Alfred DFX collection is handy for finding recent items even if not 100% reliable.\nTiming\nUse this to supplement manual time-tracking. Do not use it to its full potential at all, I think a little investment with setting up the right projects etc. can go a long way.\nDropzone\nI mostly use this as a longer-term stash than Yoink. I think there are some very nice possibilities here, but the only things I’ve done with it so far include:\n\nuploading images online\nopening a finder path in a terminal (superseded by an Alfred shortcut)\ndropping files in select locations\nURL shortening\n\nPermute\nHandy for all kinds of (bulk) file conversions.\nText Sniper\nImpressive OCR “from anywhere”. The newer releases of macOS may make this redundant eventually though.\nSwish\nIntuitive gestures for window management. Pretty confident all this can be done in Better Touch Tool (above), but the actions are inspiring, and I’m lazy, so yeah, this is explicitly installed.\nDownie\nUse this for downloading videos from Youtube for offline viewing/listening. Fairly robust.\nIconJar\nIcon collection, enough said. 🎁\nSip\nHandy 🎨 color picker.\nWorld Clock Pro\nVisually appealing world-clock, nice for scheduling stuff across timezones, great screensaver option as well.\nDash\nDocumentation lookup, handy that it works inside VS Code (via an extension).\nMindNode\nLovely mindmaps.\nPDFPen\nAlthough I mostly use Preview, PDFPen is useful for quickly rearranging and removing pages. Not sure about the several other features claimed, I find that it sadly crashes more often than not, so not my default application.\nTextSoap\nOccasional use, but very useful when I do need it for some pesky hidden-unicode-character-removal exercise.\nMathKey\nNiche app - on the rare occasion that I have a complicated LaTeX formula to write, I can write it in the iOS version of this app and receive it on the Mac (I don’t think the desktop app is even necessary for this; the iOS purchase can be bypassed by using the Mac app via Sidecar, but this is where I discovered the app so it makes the list).\nMarked\nPowerful previews for Markdown documents. Lots of interesting export features.\nChronoSync Express\nThis helps with keeping certain folders in sync, and setting up some backup schedules. Nothing that can’t be done with a few scripts (?) and/or Time Machine, but I did end up setting (and forgetting) a few things in here.\n\n\n\n\n\n\n\n\n\n\nGeneral\n\n\n\n\n\n\nNotion\nI’m (admittedly* experimentally) using Notion as my primary PKM tool, and it’s also where I am keeping most of my public-facing content (including this blog). My usage of Notion is gradually expanding in scope to include time/task/finance tracking as well. Too slow.\n*I’ve been in and out of Notion a few times by now, interleaved with fairly committed detours through Obsidian, Craft, and VSCode extensions for several months… I should mention that Craft is now available through Setapp, and that I am tentatively moving to Obsidian.\nBibdesk\nFairly robust reference management that has most of what I need — priority features include speed, reliability, flexibility in generating citekeys and decent auto-filing of papers added to the database (popular free and paid alternatives that I’ve tried briefly: Zotero, Mendeley, Setne, Papers, Readcube, JabRef, Bookends).\nIncidentally, if you are into Obsidian and Zotero, you might enjoy this video.\nMacTeX\nLaTeX and related tools, including TeX-friendly IDEs and reference management tools.\nXcode Tools, pandoc, and homebrew\nNeed these to work with code.\nContexts\nThe app that I miss the first when on a machine that doesn’t have it, next to Alfred. Makes window switching much more search and keyboard-driven.\nAlfred\nApart from using it as a launcher (even for files), I almost use Alfred as a Finder replacement. Here are some of my favorite Alfred workflows:\n\nMenubar Search\nSimple Folder Search (only search for folders)\nCase Switch (combined with send-text-to-Alfred below, this can be quite nifty)\nSymbols Search (unicode goodness)\nSend to Yoink\nQuit Applications\nSend text to Alfred (double-tap the option key)\nColor\nCurrency Exchanges\n\nKeyboard Maestro\nReally elaborate shortcut/automation app. I’ve only scratched the surface with my use cases, but one of the things I really dig about my setup is simulating keypress sequences.\nThe way I do this is to activate a macro group for one action with one keyboard shortcut (e.g, CMD + ;) and then have all macros within that have one-letter or one-letter + one-modifier triggers - basically very easy triggers. This way, I only have to remember a bunch of high-level shortcuts for things in various categories, and from there it’s just a letter (and the same letter can be overloaded in different contexts).\nAs a concrete example, I have a macro group called launchers, and a shortcut within that for launching chrome. So something like CMD+L followed by c would launch Chrome. Although I have to confess that I mostly launch stuff through Alfred still (at the cost of one or two extra keystrokes).\nKeypress-sequence-triggers are native to Better Touch Tool and since BTT supports AppleScript, you could also run KM macros from BTT. I haven’t quite tried this yet.\nMore advice on this here.\nTypinator\nFast snippet expansion - faster than TextExpander (one of the main competitors in this space) in my experience. Recent updates have some rad features, which of course I’m yet to explore and exploit!\n1Password\nReasonably user-friendly and robust password management. Syncs to iOS, but I haven’t managed to leverage it so much on iOS. 1Password is ideal for storing confidential information nicely (IDs, bank stuff, and the like) - if used only for passwords I suppose the Keychain does a good job too.\nFantastical and Calendar\nFantastical is a nice (but expensive!) calendar app, mostly use it because of the calendar sets feature that keeps my time blocking calendars separate from the official one that is public within the organization. Of late, I especially like the way you can join online meetings from the notifications.\nHaving said that, I realized that much of what I was doing with Fantastical was overkill and I’ve switched to the default calendar app for now, and it’s one paid subscription less2 to have.\nOh well: so I am back on Fantastical, I guess I really like the UI! Meanwhile, Busycal is a great alternative if you are on Setapp.\nVS Code\nThis is where I am supposed to be spending most of my time, perhaps next only to Craft/Notion. A few things from my VSCode workflow:\n\nUse different themes for different file types (I mostly dabble in LaTeX, C++, Python, JavaScript, and Markdown)\nLittle utility extensions save a lot of time: e.g, sort lines, increment value at cursor, file management, etc.\nMulticursor-powered find and replace is amazing.\nWorkspaces are handy and I usually launch them from Alfred.\n\nHook\nLooks very promising for cross-linking stuff across apps that have a common context (say, a project). I really need to explore this more!\nUpdate: Hook is now Hookmark, and is alo available through Setapp.\nStream Deck (best with accompanying hardware)\nParticularly useful for switching OBS scenes although I use it less than I thought I would!\nIn particular, I want to explore their VSCode and KM integrations.\nIf without the physical device, Streamdeck does have a nice iOS app that simulates the hardware, but the pricing is based on a subscription model.\nGoogle Chrome\nI can’t make up my mind between Chrome/FF/Brave/Safari. I mostly switch between Chrome and Safari, with a mild preference for Chrome because of it’s more comprehensive extensions space, but I often end up with Safari as default for speed and privacy.\nReadkit\nUse this for RSS, although I’ve mostly migrated away to DEVONthink. Still looking for a nice stand-alone RSS reader though, Readkit doesn’t always render everything the way I expect, sadly.\nOBS\nFor recording and live-streaming videos. Also useful as a virtual camera for meeting apps.\nScreenflow and Camtasia\nFor recording videos, lots of features, still finding my way around them.\nSlack and Discord\nOnline communities. I sometimes wish there was a native app for discourse too (is there?)\nKeynote\nPresentations - main alternative: Beamer + LaTeX + pgf/TikZ; or one of the JS-based slide generator tools from Markdown files (I did use react.js for one entire term).\nDEVONthink\nUse this fairly minimally (especially relative to the possibilities). At the moment DT indexes a couple of key finder folders and pulls in information from a lot of RSS feeds and even Twitter accounts. I try to review the stuff that automatically piles up in DT regularly, but — at the moment — it’s mostly a dumping ground and… messy.\nMicrosoft Teams, Skype, and Zoom\nUse this for classes and online meetings.\nOffice suite: Word/Powerpoint/Excel\nUse it only to open files I receive.\nFruitjuice\nUseful battery health monitoring, discovered the app from a MPU podcast episode IIRC.\nMathsnip\nSurprisingly good LaTeX-aware OCR.\n\n\n\n\n\n\n\n\n\n\nWebapps\n\n\n\n\n\n\nYNAB\nBudgeting and finance management.\nGmail\nUntil I setup Mailmate again, I’m checking email in my browser. 🙈\nGSuite (Docs, Sheets, Slides, and Calendar)\nI use these when others use them.\nZapier, IFTTT, Integromat\nA few automations here and there, still on my bucket list to take full advantage here. Integromat has been great for tracking Exportober contributions, incidentally!\n\n\n\n\n\n\n\n\n\n\nOmissions\n\n\n\n\n\n(aka stuff I used to use but don’t use as much now.)\n\nKarabiner Elements. I was quite taken in by the possibilities offered by “God Mode”, but I realised that I prefer sequential shortcuts - like the ones I managed to setup in KM - to ones powered by arbitrary combinations of simultaneous keypresses.\nMailmate. Will very likely be back in the workflow soon!\nThings. Retired when I switched to “Notion for Everything”. That said, Things is absolutely awesome!\nUlyssess. Replaced by Notion → Craft → Obsidian → Notion.\nBear. Replaced by Notion → Craft → Obsidian → Notion.\nSublime Text. Replaced by VSCode.\n2Do. Replaced by Things a long time ago, but a really nice app!\nShift. Combines many windows in one, basically. Not sure if it was sufficiently useful, living without it and not missing it much.\nIM+. Similar to Shift in scope, although this one is available on Setapp.\n\n\n\n\nWhat’s on your list? Do share in the comments below!\n\n\n\n\nFootnotes\n\n\nNB. This list does not include fonts and scripts — that’s for a separate round up in due course.↩︎\nI have nothing against paid subscriptions for software in general, but Fantastical’s pricing for the feature set does seem to have an unclear cost-benefit tradeoff, at least for users like me. I haven’t missed much since moving on.↩︎"
  },
  {
    "objectID": "blog/moving-blocks-ctis/index.html",
    "href": "blog/moving-blocks-ctis/index.html",
    "title": "Moving Blocks at CTIS 2021",
    "section": "",
    "text": "I am very excited about third conference on Computational Thinking in Schools (CTiS2021)1, a CSpathshala event, that’s coming up from the 29th September to 2nd October 2021 at School of Scholars, Nagpur.\nSome background from the conference website:\n\nThe CTiS (Computational Thinking in Schools) conference is an annual event organised by the ACM (Association of Computing Machinery) and the CSpathshala community. It aims to bring together teachers, educators and researchers to discuss issues of curriculum, pedagogy, policy and implementation, related to bringing computational thinking to schools.\n\nCTiS2021 aims to provide a platform for teachers, educators and experts to share their best practices as well as challenges faced in implementing computational thinking in education. The discussions will focus on integrating CT activities (both plugged and unplugged) in various school subjects, on student learning outcomes and on disseminating findings of CT based experiments or classroom research conducted by teachers and educators across the country.\nOur 4-day conference features key note speakers, Hal Abelson, MIT, USA, Manish Jain, IIT Gandhinagar, Patricia Ordóñez, University of Puerto Rico Río Piedras and Wolfgang Slany, TU Graz, Austria. The conference also features a workshop on CT and inclusion, conducted by Supriya Dey, Vision Empower and Manohar Swaminathan, Microsoft Research, Bengaluru and presentations of selected abstracts with sessions on implementation of computational thinking, fun activities and innovative examples used by teachers in classrooms!\nNeedless to say, I’m looking forward to this very exciting program! As a PC member, I also know that the contributed content is fantastic as well, and the aim of this little writeup is to offer a glimpse into this section of the conference.\nIn particular, I want to share with you a puzzle that was described by Rema Nair, who teaches Computer Science at the Mallya Aditi International School in Bangalore, grades 9-12.\nTo begin with, we have an equal number of blue and green boxes positioned as follows:\n🟦 🟦 🟦 🟩 🟩 🟩\nSo the blue boxes are lined up first from left to right, followed by a space that’s exactly enough to fit one box, and then we have the green boxes lined up after the space. The goal is to arrive at the following position, which is essentially what you would have if the blue and green boxes were to switch positions:\n🟩 🟩 🟩 🟦 🟦 🟦\nThe moves of the boxes are subject to the following rules:\n\nThe boxes from the left (i.e, the blue ones) can only move towards the right, and the boxes from the right (i.e, the green ones) can only move towards the left.\nBoxes can move forward one space, or move two spaces by jumping over/moving past another box of a different colour (never over a box of the same colour).\nThe moves are to be made in one direction only.\n\nThe puzzle is solved when the two sets of boxes have switched positions.\nSo how would you get the boxes to switch positions? Are there multiple ways to do it successfully? If so, which strategy leads to the smallest number of moves? This should be a fun conversation-starter in class — and beyond!\nThis is a great activity with actual boxes in a physical setting, but for now, here’s a quick version that you can try out right here, thanks to Polypad by Mathigon* - be careful to not overlap the boxes one on top of the other, they will end up merging! You can always refresh this page to reset 😀\n*Note that the numbers on the boxes are immaterial; notice that given the constraints on the directions, the relative ordering of the numbers is fixed anyway.\nEnjoy playing for now, and join us at CTiS to meet Rema (and other participants).\n\n\n\n\n\n\nFootnotes\n\n\nRegistration is free but mandatory. The deadline is 28th September. Please head over here to register!↩︎"
  },
  {
    "objectID": "blog/cp/sam-i-am/index.html",
    "href": "blog/cp/sam-i-am/index.html",
    "title": "Sam I Am",
    "section": "",
    "text": "This is mostly about solving Sam I Am (UVa 11419); en route, we will end up discovering Kőnig’s theorem, which is a delightful fact about the special relationship shared by vertex covers and maximum matchings in bipartite graphs."
  },
  {
    "objectID": "blog/cp/sam-i-am/index.html#the-problem",
    "href": "blog/cp/sam-i-am/index.html#the-problem",
    "title": "Sam I Am",
    "section": "The Problem",
    "text": "The Problem\nHere’s an abridged version of the problem statement.\n\nSam is facing a temple which can be described by a m \\times n grid and he has the locations of all enemies in the temple (each location can be thought of as the intersection of a row and a column in this grid).\n\nAll of a sudden, he realizes that he can kill the enemies without entering the temple using the great cannon ball which spits out a gigantic ball bigger than him killing anything it runs into and keeps on rolling until it finally explodes.\nBut the cannonball can only shoot horizontally or vertically and all the enemies along the path of that cannon ball will be killed.\nSam wants to know the minimum number of cannon balls and the positions from which he can shoot the cannonballs to eliminate all enemies from outside that temple. >"
  },
  {
    "objectID": "blog/cp/sam-i-am/index.html#some-initial-observations-with-an-example",
    "href": "blog/cp/sam-i-am/index.html#some-initial-observations-with-an-example",
    "title": "Sam I Am",
    "section": "Some initial observations with an example",
    "text": "Some initial observations with an example\nSo to begin with, we have a grid with some cells identified as locations where Sam’s enemies are positioned, and here’s an example:\n\n\n\nA first example of a configuration of Sam’s enemies location\n\n\nConveniently for us, the enemies don’t move around.\nWe want to hit all of these locations, and what we have at our disposal is giant cannon balls which can destroy all enemies that are positioned on a single row, or a single column. For example, if we were obsessed about only firing along rows, we would need four cannon balls to tackle ’em all, like so:\n\n\n\nA solution were we fire along rows alone\n\n\nIf Sam was superstitious about shooting along columns only, then he would again need four of these cannon balls to take care of everything:\n\n\n\nA solution were we fire along columns alone\n\n\nHowever, our friend Sam is smart, not superstitious! And if there is anything that he is obsessed about, it is ruthlessly optimal destruction! In other words, he wants to fix everything up, but while using the smallest number of cannon balls possible… and if that means mixing up ranks and files, so be it — notice that you can manage with just three once you combine the use of both axes:\n\n\n\nA solution leveraging a combination of rows and columns\n\n\nAnd for this example in particular, notice that three cannon balls are necessary, because we have at least three enemies positioned at locations that share neither a row nor a column, implying that no row-fire or column-fire can handle more than one of these locations at once:\n\n\n\nDemonstrating that three canonballs are in fact necessary\n\n\nSo for this example, we know that:\n\nthree cannon balls are necessary &\nthree cannon balls are sufficient.\n\nIn general, let’s say that two enemy positions are mutually independent if they are on different columns and on different rows. Let k be the size of a largest collection of mutually independent positions. Then it is clear that:\n\nk cannon balls are necessary to handle all enemy locations;\n\nbecause any \\ell fires that handle all enemy locations must in particular handle these k mutually independent ones, and each individual fire can get to (at best) one of them — by definition of what it means for two positions to be mutually independent. So if we have a valid solution involving \\ell cannon balls, then \\ell \\geq k.\nWhat is a less obvious, but considerably fascinating, is the fact that:\n\nthere is always a strategy to hit all locations using just k cannon balls. 🤯\n\nA striking situation, no pun intended — the obvious estimate of what is needed turns out to be enough as well! The easy lower bound has a matching upper bound ❤️"
  },
  {
    "objectID": "blog/cp/sam-i-am/index.html#an-auxiliary-graph",
    "href": "blog/cp/sam-i-am/index.html#an-auxiliary-graph",
    "title": "Sam I Am",
    "section": "An auxiliary graph",
    "text": "An auxiliary graph\nAlright, I think that’s enough with the advertising.\nHow does this work?\nLet’s construct the following graph G = (V,E) associated with the grid and the information about enemy positions:\n\nIntroduce a vertex for every row in the grid; say r_i for 1 \\leq i \\leq m. These are the row vertices.\nIntroduce a vertex for every column in the grid; say c_j for 1 \\leq j \\leq n. These are the column vertices.\n\n\n\n\nThe vertices of the auxiliary graph\n\n\n\nIntroduce the edge (r_i,c_j), 1 \\leq i \\leq n; 1 \\leq j \\leq m if and only if the location at the intersection of the i^{th} row and the j^{th} column corresponds to an enemy position.\n\n\n\n\nThe edges of the auxiliary graph\n\n\n\n\n\nA bipartite graph!\n\n\nObserve that:\n\nAny matching in G (a collection of mutually disjoint edges) corresponds to a collection of mutually independent enemy positions back in the grid.\nWhat we are looking for is a smallest-sized subset S of V(G) such that every edge e in G has at least one of its endpoints in S. Such a subset is called a vertex cover.\n\n\n\n\nA vertex cover\n\n\nSo our claim in the language of grids now translates to:\n\n📝 The size of a maximum matching in G is equal to the size of a minimum vertex cover in G.\n\nin the language of graphs. Keep in mind that as graphs go G, happens to be a bipartite graph; which is to say that its vertex set can be parittioned into two parts† such that every edge has exactly one endpoint in each part.\n† In this example, these parts correspond to subsets of row vertices and column vertices."
  },
  {
    "objectID": "blog/cp/sam-i-am/index.html#bring-in-the-flows",
    "href": "blog/cp/sam-i-am/index.html#bring-in-the-flows",
    "title": "Sam I Am",
    "section": "Bring in the flows",
    "text": "Bring in the flows\nIs this much ado for nothing? We seem to have done some translation work, but there’s no proof of this bold claim in sight just yet… 😬\nFair. So here’s a roadmap for what we plan to do next:\n\nUse the graph G as the basis of a flow network.\nRecall the maxflow-mincut duality.\nProfit. Show the duality that we are interested in by hooking it up the known one.\n\nSo first things first: we are going to setup a flow network around the graph G, and here’s a partial picture of what it looks like:\n\n\n\nThe flow graph\n\n\nHere’s the official description of how we build this up:\n\nStart with the graph G, and orient every edge between a row vertex and a column vertex so that every such edge originates from the row vertex and latches on to the column vertex.\nWe assign infinite capacities to all the edges in G. Go unlimited on the originals! We will even dub these edges original edges going forward.\nAdd a source vertex s and add unit-capacity edges (s,r) for every row vertex r. We will call these edges the row selectors.\nAdd a target vertex t and add unit-capacity edges (c,t) for every column vertex c. We will refer to these edges as column selectors.\n\nThat’s it, that’s the flow network (\\tilde{G},\\kappa) based on G, where I’m using \\kappa to denote the capacity function. Now let’s stare at any valid integral flow in this network — what does it pull out from the middle? 🤔\n\n\n\nA matching hiding in plain sight\n\n\nLet’s make the following quick observations in the context of a valid integral flow f in (\\tilde{G},\\kappa):\n\nThe flow on any edge e from G (i.e, an original edge) is either zero or one. Indeed, if f(e) > 1, then we violate conservation constraints at both endpoints of e.\nFor any row or column vertex, at most one original edge incident to it is used by the flow f. In other words, f(e) = 0 for all but at most one original edge incident to any row or column vertex. Again, if not, combined with the fact that f is integral and that the row and column selectors have unit capacity, we will violate conservation constraints on the vertex under consideration.\n\nBased on these observations, we have that the set of original edges for which f(e) = 1 forms a matching in back in G, and in particular, if f was maximum flow, then this set would correspond to a maximum-sized matching. Now, let’s look at the corresponding mincut by building the residual graph:\n\n\n\nEdges in the residual graph that have a residual capacity of zero are not shown. Also, the original edges that were used by f have infinite residual capacity but their corresponding back-edges have unit capacity, but this distinction is not emphasised in the picture because it’s not particularly relevant to our discussion.\n\n\nEdges in the residual graph that have a residual capacity of zero are not shown. Also, the original edges that were used by f have infinite residual capacity but their corresponding back-edges have unit capacity, but this distinction is not emphasised in the picture because it’s not particularly relevant to our discussion.\nand considering what vertices are reachable from s:\n\n\n\nThe vertices reachable from s are marked green, while all remaining vertices are marked red.\n\n\nThe vertices reachable from s are marked green, while all remaining vertices are marked red.\nIn the residual graph, I would like to draw your attention to:\n\nrow vertices that are unreachable from s,\ncolumn vertices from where it is impossible to reach t.\n\nWe will refer to these vertices as the misfits — they are highlighted for you in the picture below:\n\n\n\nThe misfits\n\n\nNow roll up your sleeves for some magic. Let’s pull up the cut — which we know is in fact a mincut — obtained by considering the set of vertices reachable from s the residual graph corresponding to the maxflow f. In pictures, note how we have attracted some column vertices to the s-side, and pushed away some row vertices to the t-side:\n\n\n\nSome reorganization\n\n\nNote that this is a minimum cut, that is to say, the total capacity of the edges crossing the cut is as small as possible — which means that, in particular, the total capacity is at least (or should that be at most?) finite, and that implies, even more particularly, that none1 of the original edges cross this cut.1 Remember how their capacities were infinite? So they just cannot afford to cross a minimum-capacity cut.\nSo every original edge is confined to the s-camp or the t-camp; but note that every original edge is an edge between a row vertex and a column vertex; so if you put two and two together, you see that, in fact, every edge must be incident to a misfit vertex. This means that the misfits are what we were looking for all along — they form a vertex cover of G!\nSo at least we have some solution. Is this the best we can hope for?\nWhy yes!\nNote that every misfit vertex contributes exactly one unit-capacity edge to the minimum cut: the misfits on the s-side are incident to column selectors, and these edges connect with t on the other side; while misfits on the t-side are incident to row selectors, and these edges connect with s, which is again on the opposite end. So every misfit vertex contributes exactly one edge to the minimum cut — and there are no other edges that cross the cut, so we have the following sequence of equalities:\n\nsize of the proposed solution = #misfits\n#misfits = capacity of the minimum cut\ncapacity of the minimum cut = value of the maximum flow\nvalue of the maximum flow = size of a maximum matching back in G\nsize of a maximum matching back in G = lower bound on our solution\n\nTherefore, we have proposed a solution whose cost matches a lower bound on it, making it optimal! With a slight adjustment of language (dropping misfits in favor of vertex cover), the sequence of inequalities above also shows that the size of a minimum vertex cover in a bipartite graph equals the size of a maximum matching in the graph.\nThis was the relationship I’d promised to cover when we started, and it goes by Kőnig’s theorem in case you’d like to find out more — the argument we came up with here isn’t perhaps the traditional proof, and this is a fact that can be established in several different ways, all fun in their own way ❤️"
  },
  {
    "objectID": "blog/poems/seek/index.html",
    "href": "blog/poems/seek/index.html",
    "title": "Seek",
    "section": "",
    "text": "Seek poetry in a wisp of smoke, or closure in some ashes\nstories below newspaper headlines peace after bygone deadlines\na castle in the air a choice that is fair\nthe absence of regret on a death bed a reason, or otherwise to stay alive —\nand quite likely it will be a quest unfulfilled.\nFind a smile instead, and you will find some strength to stay another day."
  },
  {
    "objectID": "blog/poems/sprinkles-of-the-sky/index.html",
    "href": "blog/poems/sprinkles-of-the-sky/index.html",
    "title": "Sprinkles of the Sky",
    "section": "",
    "text": "A dubious draft of air comes, goes as if wondering if the air’s welcoming\nSoft rays tiptoe by the window as if shy to come inside\nSprinkles of the sky lie in drops of dew as if captive, somewhat pensive\nAnd I snuggle deeper into a distant dream as if I could see a better place to be\n\nI stole the title from a phrase in Hairat, a song that features in Anjaana Anjaani. Incidentally - I am very addicted to the entire album!"
  },
  {
    "objectID": "blog/poems/bloom/index.html",
    "href": "blog/poems/bloom/index.html",
    "title": "Bloom",
    "section": "",
    "text": "Velvet-like violet erupts in a riot on miniscule white canvases harp-like; focused at a bunch of seeds.\nAll trouble to no avail, one day the bee will come and take it all away.\n\nHonorable Mention in the The Binnacle Second Annual Ultra Short Competition."
  },
  {
    "objectID": "blog/poems/on-the-fence/index.html",
    "href": "blog/poems/on-the-fence/index.html",
    "title": "On the Fence",
    "section": "",
    "text": "At least you are dead. To which the ghost said, The grass is not greener here - But it did become paler there…\nAt least you have a chance, To wait for the rains’ dance, To live and fight, To make things right."
  },
  {
    "objectID": "blog/exportober/2022-tracker/index.html#the-tweets",
    "href": "blog/exportober/2022-tracker/index.html#the-tweets",
    "title": "Exportober 2022",
    "section": "The Tweets",
    "text": "The Tweets"
  },
  {
    "objectID": "blog/exportober/2022-tracker/index.html#what-was-this-about-again",
    "href": "blog/exportober/2022-tracker/index.html#what-was-this-about-again",
    "title": "Exportober 2022",
    "section": "What was this about again?",
    "text": "What was this about again?\nYou can find the original announcement here and more specifics clarifying the format (or the lack of it) here. Here’s the short version:\n\nPut up a piece of content everyday between 1st October and 30th October, with the possibility of skipping one day per week;\nPost a link to your content on Twitter with #exportober\nThat’s it, actually. 🤷‍♀️\n\nPsst. It’s quite fine to sign up even if you’re reading this after the 1st of October. The automated tracking exercise here will stop after the 15th of November, so you can be a part of this by just contributing in this window. It certainly does’t have to be daily and it doesn’t have to be 30 things, although I found those to be useful default targets to work with for myself."
  },
  {
    "objectID": "blog/exportober/about/index.html",
    "href": "blog/exportober/about/index.html",
    "title": "About Exportober",
    "section": "",
    "text": "In a massively impulsive move nudged by some Twitter feedback, I recently launched the Exportober challenge.\nThe TL;DR version:\n\nPut up a piece of content* everyday between 27th September and 30th October, with the possibility of skipping one day per week;\nPost a link to your content on Twitter with #exportober\nThat’s it, actually. 🤷‍♀️\n\n\n\n\n\nAnyone else procrastinating on starting a blog, CS or otherwise? Would you be interested in being held mutually accountable for a few weeks to overcome the initial inertia? Do let me know! I’ll try to setup something systematic-looking if there’s interest 🙂\n\n— Neeldhara (@neeldhara) September 19, 2021"
  },
  {
    "objectID": "blog/exportober/about/index.html#whats-allowed-in-exportober",
    "href": "blog/exportober/about/index.html#whats-allowed-in-exportober",
    "title": "About Exportober",
    "section": "What’s allowed in #exportober?",
    "text": "What’s allowed in #exportober?\nI was deliberately vague about the terms-and-conditions that goes with the piece of content piece above. The rules I mentioned were minimal: since there are no restrictions of age, keep the content SFW and generally legal. Other than that, anything goes, for example:\n\nCan I doodle? Yes.\nCan I meme? Yes.\nCan I make a comic? Yes.\nCan I quip? Yes.\nCan I tweet a thread? Yes.\nCan I tweet a single tweet? Yes.\nCan I song and/or hum and/or dance? Yes.\nCan I react? I am unfamiliar with this genre, but yeah, why not?\nCan I just quote? Uhh, ok-fine, sure — maybe be sure to include a reaction?\nCan I commit? Yes, please! Oh, you mean — can it be a GitHub commit? Right, yeah, sure.\n\n\n\n\n\nOne a day is a lot! (Unless tweets count). I used to blog regularly but not even one a week at its peak, I think.\n\n— Rahul Siddharthan (@rsidd120) September 22, 2021\n\n\n\n\n\nin case anyone is looking for inspiration, in true student fashion, i am already planning on cheating by turning all the math puns i have in mind to comics ['ring arthur and his knights of the round table' but where ring arthur is a noncommutative ring without unity]\n\n— tiiiiredddd (@vuisnotabot) September 22, 2021\n\n\n\nAs you can see, there are no restrictions on format or length or quality. It can be whatever you want, and however long or short you want it to be. The point is to get into the habit of putting a bit of yourself into something tangible that you’d want to share.\nSo while you could technically schedule thirty pieces of Harry Potter trivia in advance — that would kind of defeat the purpose."
  },
  {
    "objectID": "blog/exportober/about/index.html#is-this-for-me-whybother-with-exportober",
    "href": "blog/exportober/about/index.html#is-this-for-me-whybother-with-exportober",
    "title": "About Exportober",
    "section": "Is this for me? #whybother with #exportober",
    "text": "Is this for me? #whybother with #exportober\nIn general, I imagine only you would know if this is for you — this may not be a priority or a point of interest for you right now, but if you’re reading this, possibly your interest is at least mildly piqued?\nWhat this is about is setting aside some time for yourself and to participate alongside friends who’re in it for fun and profit:\n\n\nWe often avoid taking action because we think \"I need to learn more,\" but the best way to learn is often by taking action.\n\n— James Clear (@JamesClear) September 23, 2020\n\n\n\nThe fun bit is in the making and sharing.\nThe profit bit is the hope that we trick ourselves into making this a bit of a regular habit for life.\n\nLonger term, you may or may not want to be sharing or publishing on a daily basis. But hopefully, longer term, you are engaged with the process on a regular basis.\nPersonally, there’s almost nothing that I do consistently on a daily basis, not counting the things one needs to do continue being alive. I’d like to see if I can change that a bit1, and apparently doing such things bit by bit — and with some public commitment — is a good idea, hence the micro-nature of the challenge.\n\n\nSo overall I’ve gotten to a point where I’m just afraid to even think about putting something together because I think it’s an unrealistic commitment of time. I’m also really bad at chunking - everything I do of this sort manifests at the wrong end of an all-nighter 🙈\n\n— Neeldhara (@neeldhara) September 19, 2021"
  },
  {
    "objectID": "blog/exportober/about/index.html#i-want-to-be-in-but-i-stoop-no-lower-than-meaningful-masterpieces",
    "href": "blog/exportober/about/index.html#i-want-to-be-in-but-i-stoop-no-lower-than-meaningful-masterpieces",
    "title": "About Exportober",
    "section": "I want to be in, but I stoop no lower than meaningful masterpieces…",
    "text": "I want to be in, but I stoop no lower than meaningful masterpieces…\nHmm. One way that you could still make this work for you is to build out your masterpiece bit by bit. If it’s a tutorial, you could plan it out in advance and work through one coherent section a day. If it’s a sketch, you could share your partial progress as you go along, and even put it together in a timelapse at the end? That would be great to see!\nThere are some types of long-form content that aren’t naturally amenable to this type of chunking; say you want to put together a video exposition, make an origami sculpture, or crochet a Klein bottle. In this situation, you could either use the challenge to document your process and progress; or you could just claim to engage in #exportoberlite with a reduced frequency of production — say once a week, or one masterpiece at the end — you’ll just have to still tweet it out so I can catalog it ❤️\n\n\nI really don’t like the illusion that there is one process for making and that it involves writing every day. Thinking is work to. So is reading. So is doing things that seem unrelated to writing. Our brains are always thinking about what we’re making, whether we’re typing or not\n\n— ChristianAntonGerard (@CAGerardPoet) January 25, 2020\n\n\nAlso, while on the subject of masterpieces, there’s the parable of the pots. On the other hand, everyone does have their own process, and the idea isn’t to force a format: this process is temporary, flexible, and optional 🙌"
  },
  {
    "objectID": "blog/exportober/about/index.html#this-sounds-like-fun-but-i-have-no-idea-what-to-make.",
    "href": "blog/exportober/about/index.html#this-sounds-like-fun-but-i-have-no-idea-what-to-make.",
    "title": "About Exportober",
    "section": "This sounds like fun, but I have no idea what to make.",
    "text": "This sounds like fun, but I have no idea what to make.\nOooh. Maybe just ping on Twitter if you are in this situation. I do imagine that there are folks who have more ideas than they can handle, so if you have the bandwidth, it’ll even out nicely! For some starter inspiration, just in case it is useful, here are some of the post types that I’m planning for the duration of this challenge, in roughly increasing order of desperation:\n\nTrying some of the Chai and Why? experiments and documenting any accidents learnings.\nPuzzles and programming contest roundups.\nLecture notes for classes/talks I’m teaching and/or attending.\nHighlights from whatever podcasts I’m tuned into.\nClean up draft essays from previous lives.\nRandom doodles. And VSCode keyboard shortcuts.\nHot takes on inconsequential debates.2\n\nI also have a few black holes nurtured over time — I’m looking at you, all my Read-It-NeverLater apps, the starred section in my RSS app, my YouTube watchlist, and relatives. Maybe about time to go down some of these rabbit holes with the excuse of commentary to follow.\nSo yes, that’ll be all for now! Let’s see how this goes 🤞 Meanwhile, please hop on and spread the word for all of us? Thank you! 🎉\n\nPS. You might be curious about what participating will look like. I’m trying to setup a separate page for each participant in the challenge that will pull in all your tagged tweets. I’ll share a preview soon!"
  },
  {
    "objectID": "blog/exportober/2021-tracker/index.html#the-tweets",
    "href": "blog/exportober/2021-tracker/index.html#the-tweets",
    "title": "Exportober 2021",
    "section": "The Tweets",
    "text": "The Tweets"
  },
  {
    "objectID": "blog/exportober/2021-tracker/index.html#what-was-this-about-again",
    "href": "blog/exportober/2021-tracker/index.html#what-was-this-about-again",
    "title": "Exportober 2021",
    "section": "What was this about again?",
    "text": "What was this about again?\nYou can find the original announcement here and more specifics clarifying the format (or the lack of it) here. Here’s the short version:\n\nPut up a piece of content everyday between 27th September and 30th October, with the possibility of skipping one day per week;\nPost a link to your content on Twitter with #exportober\nThat’s it, actually. 🤷‍♀️\n\n📝 If you’d like to participate you can sign up below; and if you’d like to help, please encourage everyone participating by checking out the tweets coming in above!\nPsst. It’s quite fine to sign up even if you’re reading this after the 27th of September. The automated tracking exercise here will stop after the 30th of October, so you can be a part of this by just contributing in this window. It certainly does’t have to be daily and it doesn’t have to be 30 things, although I found those to be useful default targets to work with for myself."
  },
  {
    "objectID": "blog/exportober/2021-tracker/index.html#sign-up",
    "href": "blog/exportober/2021-tracker/index.html#sign-up",
    "title": "Exportober 2021",
    "section": "Sign up!",
    "text": "Sign up!\nWhile you can participate simply by using #exportober in your tweets, it’ll be great if you could explicitly enter your Twitter username in the form below, so we can check in on each other! 🤝\nWhile I’m not going to write a Twitter bot that will send you daily reminders over DM, I do hope to create a separate page for each registered participant at the end of the challenge that shows off just their entries in one place, so it’s helpful to know who you are 😀"
  },
  {
    "objectID": "blog/exportober/2021/index.html",
    "href": "blog/exportober/2021/index.html",
    "title": "An Invitation to Exportober 2021",
    "section": "",
    "text": "📝 Update: You can now track everyone’s progress from here!\n\n\n\n\n\n\n\n\n\nYou can also check out a little more about the format, intent and background here.\n\n\n\nAs you can see — at least at the time of this writing — this is a blog under construction with some mild ambition, going by the long list of empty categories on the homepage.\nI’ve heard a lot about the effectiveness of something something public something something accountability, so I’m going to give this a shot: if there’s anyone else who wants a bit of a jumpstart and encouragement for getting into the habit of putting stuff out there, this is for you!\nPresenting the EXPress yOuR Thoughts, i.e, export, challenge.\nHere be some rules, or not, make this your own!\n\nPut something out there — could be an essay, a video, a sketchnote, some code, a piece of music, a photograph — I think the only criteria is that this should be something you put together that you feel compelled to share, and something that can be accessed via a public URL. I suppose quotes and curated round-ups are good too, but ideally you want this to be something that has a bit of you in it.\nShare it on Twitter with #exportober (umm, the export challenge in October 😬 … it had to be something that wasn’t already taken so I can scrape it off and put it up in one place, and everyone participating can keep an eye out on others participating — the general hope is that everyone finds themselves encouraged by everyone else 🎉).\nI’m going to find a way of listing everything that comes up starting 27th September. This gives you five weeks until the end of October. Try and get something up everyday - this puts the challenge in the Export Challenge 😀 That said, allowing ourselves one cheat day per week means that we all hopefully end up with 30 things by the 30th of October. Yays 🤞\nSince I’ll hopefully find a way of tracking all the content tagged this way and automatically pushing it to a page where we can find it all in one place, please don’t put up anything illegal or damaging. Other than this, practically anything goes, but please do respect the basic idea, which is is to build up some positive vibes and keep this a fun exercise!\n\nSo I hope you spend the coming week getting setup — figure out what you want to do and how you’ll do it, and maybe even cheating a little and preparing some buffer content for the rainy days? We’ve already had some great suggestions for tools you can use to get started:\n\n\n\n\nGitHub pages is great for this. I don't use Markdown, but it still works as a quick, lightweight publishing system, automatic ssh setup, etc. Since I store the content on GitHub anyway, everything is nicely unified.\n\n— ShriramKrishnamurthi (@ShriramKMurthi) September 19, 2021\n\n\n\n\n\n\nMay not commit for mutual accountability :) But a suggestion.Instead of blogging platforms, how about markdown/Jupyter notebooks in a github repo and/or short code/docs as github gists?Can use versioning to improve - no need to get the content \"right\" at the first \"publish\".\n\n— A. Sundararajan (@sundararajan_a) September 19, 2021\n\n\n\n\nThrow in your Twitter username in the form below to add your name to the list of people who are thinking about will be participating! The list will evolve automatically below, and I’ll probably clean it out of spurious entries manually every so often. Thanks to everyone who participated! The form is no longer relevant, but you can check out the posts by looking for #exportober on Twitter :)"
  },
  {
    "objectID": "blog/notion-powered-websites/index.html",
    "href": "blog/notion-powered-websites/index.html",
    "title": "Notion-powered websites",
    "section": "",
    "text": "Given that I have been spending most of my time in Notion of late, it made sense to wonder if I could use Notion, directly or otherwise, for whenever I have a need to put something up on a public website — e.g, course pages, event websites, and the like. It should go without saying that there are now a gazillion ways of putting a website together — ranging from Wordpress to modern frameworks that have made good old static sites cool again (I’m looking at you, SSGs on the JAMstack), and a whole bunch of things in between. All of this is way out of scope of this discussion, which is really limited to exploring the most reasonable ways of turning your Notion content into a website and is largely in the spirit of a no-code setup.\n\n\n\n\nIt’s almost like there’s something missing between static HTML and full JavaScript software.\n\n— Wes Souza 🏳️‍🌈⬣ (@__WesSouza) September 1, 2021\n\n\n\n\n\n\n\nYeah, it feels like we are now at a point where it’s easier to make complex websites but somehow oddly harder to make the simple ones!\n\n— Neeldhara (@neeldhara) September 1, 2021\n\n\n\n\n\n💡 Most options here ultimately amount to SSGs in the background, but with varying levels of exposure to what’s happening at the low-level.\n\nThere are a few different options out there if you are interested in this as well, and here’s a handwritten TLDR-summary1 if you find the rest of this little discussion too long:1 TIL that this style of summarization is also called a Pugh chart, thanks to Justin Lai.\n\n\n\nNotion Website Options Compared\n\n\n\nNow for the more detailed run-down:\n\nJust Use Notion\nThe official Notion documentation shows us how to build nice websites with Notion:\n\nThis is a great option for putting together something quick and temporary or for testing something out. It can be free (if you are on the Notion free plan) and/or will cost you nothing on top of what you might be paying for already if you are paying Notion user.\n\n\n\"What's the link to your site?\"\"Oh it's acmedesign dot notion dot site slash dd5a6abe47444a53b7170afd67942d77\"🙅🏾‍♂️🙅🏼🙅🏻‍♀️Now for folks with paid plans, you can set a public home page like https://t.co/tf1bBQcNJy! pic.twitter.com/LFWYQtgloq\n\n— Notion (@NotionHQ) September 21, 2021\n\n\n\n💡 If you have a more serious use-case, however, and are concerned about things like performance, SEO, custom domains, and such, and want to exercise more control over the look and feel of your site, you probably want to move beyond what you can get with xyz.notion.site. Still, a great option — involving no extra costs and right out of the box — and I’d imagine this covers a number of use-cases! 👍\n\n\n\nFruition and Cloudflare Workers\nA popular way to get your domain to point to your Notion setup and customize the look and feel of the final setup just a little bit is via Fruition:\n\nAs mentioned on the website already, one downside is the setup time — but I don’t think this is a very serious drawback at all, it’s a one-time exercise and not very difficult at all given the very clear instructions given on the website. However, I think there is a more significant concern with this option, which was highlighted by @bensomething in this Tweet thread:\n\n\nPerhaps a good example of why you should avoid custom domain solutions for Notion that use those damn Cloudflare worker scripts. But hey, super excited for my new startup (fartup?) to be featured on the Founded by Monzonauts website! @monzo @hugocornejo https://t.co/0FH916uvd2\n\n— Ben Smith (@bensomething) January 26, 2021\n\n\nYou could have a (potentially your) Fruition site intercepted with random content, as is the case here. As Ben points out, it’s much safer to convert your Notion content into a static site:\n\n\nAnything that converts your Notion pages to static versions is fine! It definitely seems like Super's leading the pack, but I'd say a substantial number of people are still using something like Fruition.\n\n— Ben Smith (@bensomething) January 26, 2021\n\n\n\n💡 To summarize what we have with Fruition: it’s probably okay for a small test setup, and it’s a cool experiment — largely free (you might hit up Cloudflare’s limits eventually and be prompted to upgrade) and not much work to setup — but I’d be wary of using it in production for any non-trivial project.\n\n…and so we’re going to explore a few ways of doing that now.\n\n\nnextjs-notion-starter-kit and react-notion-x\nThe nextjs-notion-starterkit is a NextJS template built by @transitive_bs, which is in active use here:\n\nYou can check out the repository here. If you are feeling even braver, you might even want to explore what powers this under the hood, which is the react-notion-x repository here:\n\n\n💡 Using nextjs-notion-starterkit is definitely a whole lot safer than Fruition, but it’s also clearly a whole lot more intensive in terms of setup! This option is great in terms of being free and highly customizable, but is best-suited to those who are already familiar with Next.js and who generally know what they are doing. So if the readme pages on those repositories did not make much sense, it’s probably best to either get some help on the initial setup or move on to more user-friendly, truly no-code options. That’s what we have up next!\n\nreact-notion-x — from a safe distance as far as I am concerned — appears to be very well-documented and actively maintained. The documentation speaks of hosting on Vercel, and my guess is that hosting on Netlify should also be possible. Both of these options have generous free tiers, so this could potentially be a no-cost option, although it’s far from being a true no-code option, at least for the initial setup!\nInterestingly, react-notion-x appears to be supported by Super, and from a quick glance at the source code, it seems like both Super and Potion (which are the last two options that we’ll be getting to) generate static sites using the Next.js framework… chances are that what is in these repositories is suggestive of at least a part of what’s going on behind-the-scenes with Super and Potion.\nMy understanding from exchanges with support at both Super and Potion is that there are differences in the implementation details — there are definitely visible differences that indicate this too, and apparently Super is more closely-knit into the Notion API, but I am not sure what to make of that just yet… it possibly makes their implementation a little less vulnerable to being broken by updates at Notion’s end, but I don’t know enough to say this for sure.\n\n\nSuper\nSuper (on ProductHunt), built by @Traf and @TrillCyborg (Jason Werner) appears to be one of the leading options in terms of a no-code way of porting a Notion page to a website. This will set you back $12/site/month; but you get a substantial feature set in return:\n\nI should point out that some Super templates are premium and will cost separately, but there are some really nice free ones that you can run with right away. One that I really liked happens to be free and is in use on the website I have for my courses. I had a completely painless setup experience and very responsive support on the minor things that I did get stuck on (h/t: @camincoll).\nSites made with Super are performant, SEO-friendly, and fairly customizable. There are only two minor snags I ran into with Super: one is that updates on Notion take some time to reflect on the website (typically a minute or so — this is no big deal in general, but it’s just not real-time, and can feel slow while in testing and development). The other is that their terms of service seem a bit unusually restrictive — for instance, see the discussion initiated by @kulikalov here:\n\n\nThat's a shaky foundation to work with @super_ 😐 pic.twitter.com/yYQYuGZk3u\n\n— Anton Kulikalov 🇺🇦 (@kulikalov) August 27, 2021\n\n\n\n💡 At $12/site/month Super is the most expensive option on this list, but if the combination of performance and convenience is what you are looking for, you might find that it is totally worth it.\n\nFrom Super’s responses in this conversation, I am optimistic that the ToS will change for the better. From my direct experience, my instinct is that there isn’t really anything to worry about here, but if you are someone who cares about the fine print, this is an aspect you might want to be aware of.\n\n\nPotion\nFinally, we have Potion (on ProductHunt), made by @noahwbragg (Noah Bragg), which is yet another way of getting a static site out of your Notion content in a fairly straightforward way:\n\n\n💡 While oversimplified, it is tempting to summarize Potion’s offering as “Super, but cheaper”. See the next section for a more detailed discussion of differences and similarities between the two. Overall, Potion has a very similar feature set and is slightly more affordable in comparison — definitely worth checking out the same way that Super is.\n\nThe pricing is a bit different from Super — it can cost you as little as $6.25/site/month on their 8-sites plan, which will set you back $50/month, and the other two possibilities are $10/month for one site or $25/month for three.\nIn terms of what it does, it feels rather similar to Super, but as I mentioned earlier, I think there are differences in the actual implementation. In particular, one difference that is conspicuous is the way Potion renders changes — much like what happens with Notion’s own public pages, the rendering of changes with Potion happens practically in real-time. This is very helpful, especially when you are working on quick edits, or are testing things out.\nMany other features are at par with Super: the sites created by Potion appear to be equally performant and SEO-friendly; and sites on Potion are customizable in almost the same ways.\nThis page (and the whole blog) is rendered with Potion. Like Super, setup was largely frictionless and I had prompt help whenever I needed it. Potion also has a bunch of templates that work out of the box — a couple of which are premium — but the vast majority of them are available for free and already there are some fairly nice options.\n\n\nPotion v/s Super\nGiven the similarities between Potion and Super, I felt it was worth having a separate discussion comparing the two, and I felt like I could do a brief take on this given that I’ve spent a fair amount of time trying out both and being conflicted about which one to go with! As you can probably tell if you read this far, I could not positively conclude one way or the other, so my setups are split between the two at the moment, and it’ll probably stay this way for a while now 😀\nBack to the comparison — there are a few differences on the minor features, here are a couple of examples off the top of my head:\n\nSuper allows password protection on individual pages, on Potion it’s all-or-none (at least at the time of this writing).\nPotion automatically generates preview images based on titles — this is what shows up when you share a link on, say, Twitter or Discord or WhatsApp. It does this automatically for all pages, even ones within databases.\nI could not get jquery to work in Potion (from trying very briefly), but it worked out fine on Super.\nSuper has a community forum and an arguably restrictive ToS. Potion has neither at the time of this writing.\nPotion’s dashboard has a live preview editor which lets you make simple changes to the CSS and preview them real-time — this may not be something you use often if you have made sophisticated customizations, but for quick edits to the default templates, it’s very handy:\n\n\nSuper has a great dashboard too, there’s a page-by-page breakup on the sidebar and a live preview of the site to the right, which shows up even when the individual pages are password-protected (by design):\n\n\nIn terms of custom code, a small difference is that Super allows you to insert your own content inside both the <head> and <body> tags while Potion is restricted to just the <head> tag. That said, additional possibilities for custom code injection are on Potion’s roadmap.\nThere are differences of implementation under the hood, but I am not aware of the exact details here. Super uses the Notion API and a Content Delivery Network (CDN) - this explains why changes take 1-2 mins to flow through from Notion in Super automatically, but what it does get you is reliable performance at scale. Potion uses Vercel for hosting and generates static sites that feel fast and robust, and also uses a CDN.\n\nHere are some of the things that I think work out rather similarly on both platforms:\n\nAccessible and very friendly support 🤩\nConvenient to setup and use.\nSEO, pretty URLs, custom domains, pretty-URLs, and mostly performant websites.\nCustomized output thanks to the ability to insert your own scripts and CSS.\nPromising roadmaps on both with exciting features on the way 🎉\nBoth options seem generally reliable - I have been monitoring my websites using Fathom and I’ve had a few downtimes reported here and there from both platforms. There was nothing that lasted more than a few minutes at a time. Because both Super and Potion use a CDN, it turns out that even if these services go down, hopefully the sites will still be served as usual.\nYou will find that both have great feedback on ProductHunt (and possibly other platforms too, but PH is the one I’m familiar with).\n\n\n\nShould you use Notion for your website at all?\nWell. In general, if future-proofness is crazy important to you, and you want complete control over how your website renders down to the last pixel — then you might want to consider looking beyond Notion.\n\n\n\n\n\n\nNote\n\n\n\nIndeed, these are early days, in some sense even for Notion, and much more so for all the options listed here. A few ways of turning Notion content into websites have come-and-gone, and that, I think, is in the nature of this kind of a setup.\nAt the moment, all options here other than the native Notion setup will have some obligation to keeping up with changes from the Notion side. I think most options are doing great on this front — as a recent example that comes to mind, globally synced blocks were supported shortly on all platforms after release (you do have to make sure that the pages on which such blocks originate have public access permissions).\nI am definitely keeping my fingers crossed for the long-term viability of these options 🤞 Until then, I’m looking forward to enjoying the convenience of being able to work on my website(s) without getting out of Notion at all, at least hopefully not very much 😎\nIncidentally, Notion’s markdown export is pretty good too, so you could just keep markdown versions of your work as you go along, so in case you decide to port things over into a more direct SSG setup in the future, it would be relatively painless to do.\n\n\nAssuming you are all-in on using Notion for delivering your website, then here’s a summary of your options:\n\nIf you are looking for a free setup:\n\nIf need to use custom domains, and need sites that look and behave like regular websites, then you might want to check out react-notion-x or nextjs-notion-starterkit if you are an expert, but otherwise, the Notion route may not be the best for you.\nIf you are already a Notion user and you just need a URL with content that can go around for a super-specific purpose (i.e, website-y features not so crucial) — you can likely just use Notion’s default facility with a public URL.\n\nIf you have a budget that is compatible with Super and/or Potion, I would definitely recommend either of them - they are both great solutions in this context! There are some nuances in terms of how they are different (e.g, pricing; Super’s apparently deeper integration with the Notion API v/s Potion’s real-time implementation, etc.), and if that level of detail is important to you, you might need to try out both — which is fortunately easy to do — before deciding.\n\n\n\nOther ways of getting a website out of Notion?\nThere are a few options that I didn’t cover here, including, for example, Notion2Blog, Notion Dog, Notelet, Nocodepages (now defunct), and a couple of others that I did evaluate — at least briefly — but I unfortunately can’t remember any more. If you know of other examples, please let me know and I’ll be happy to append them to this list here!\n\n\n💡 Please share your comments on Twitter @neeldhara. Also, special thanks to @camincoll and @noahwbragg for their inputs and help with Super and Potion, respectively! 👋🏽"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Background\n\n \n\n👋 My name is Neeldhara Misra. I am a faculty member with the discipline of Computer Science and Engineering at IIT Gandhinagar. My research interests include the interplay of structural graph theory and graph algorithms; tools and techniques in parameterized complexity; computational perspectives on combinatorial games; voting mechanisms, with a special focus on strategic behaviour; fair allocations of resources.\nI am also keen on understanding means of bringing computational thinking to school education, and using visual tools and narratives for exposition in general.\nIn 2007, I finished a Bachelors in Science in three majors — Computer Science, Mathematics, and Statistics, from Mount Carmel College (Bangalore). The Joint Entrance Screening Test (JEST) was one of the very few national exams that I was eligible to write at this point, and this eventually led me to graduate school — specifically an integrated PhD program — at the Institute for Mathematical Sciences (IMSc).\nAfter graduating from IMSc in 2012, I spent the next three years at the Department of Computer Science and Automation (CSA) at the Indian Institute of Science (IISc).\nOne of the things I enjoy most about my work is the opportunities that it brings to connect with others, so in case you feel similarly and would like to exchange notes, give me a heads up! I am moving from Twitter to Mastodon and am trying to get better at email, so I’ll look forward to hearing from you 🙌\n\n\nClick here for a short bio, suitable for introductions.\n\n \n\n\n \n\n\n\n\n\n\n\n\n2021 — Present\nSmt. Amba and Sri. V S Sastry Chair Associate Professor Computer Science and Engineering Indian Institute of Technology, Gandhinagar\n\n\n2016 — 2022\nAssociate Dean External Communications, Indian Institute of Technology, Gandhinagar\n\n\n2015 — 2021\nAssistant Professor, Computer Science and Engineering Indian Institute of Technology, Gandhinagar\n\n\n2012 — 2015\n2012. Research Associate 2013. DST-INSPIRE Fellow Computer Science & Automation Indian Institute of Science\n\n\n\nEarlier\n2012. Integrated PhD, Institute for Mathematical Sciences (Theoretical Computer Science) 2007. BSc, Mount Carmel College (Computer Science, Mathematics, and Statistics)\n\n CV (Last Updated: ~mid-2022)\n\n\n\n\n\n\n\n\n\n\n \n\n×\n\nNeeldhara Misra is a Smt. Amba and Sri. V S Sastry Chair Associate Professor of Computer Science and Engineering at the Indian Institute of Technology, Gandhinagar. She completed her PhD from the Institute for Mathematical Sciences in 2012 in Theoretical Computer Science. Her research interests include the design and analysis of algorithms and computational social choice. She is also interested in visualizations and other methods to communicate computational thinking at an elementary level. She also enjoys learning about new card tricks, especially self-working ones — even though she can’t remember any!"
  },
  {
    "objectID": "courses/2022/visualscicomm.html",
    "href": "courses/2022/visualscicomm.html",
    "title": "Visual Science Communication | Ipsa Jain",
    "section": "",
    "text": "— Dr Ipsa Jain\n\n\n\n\n\n\nAbout the Course\n\n\n\n\n\nScience can be communicated to a target audience through different avenues including written, visual, audio, and a combination thereof. The use of visual communication through art and illustrations, video, audio-visual content and more, has been noted to have a wider reach and breach new barriers.\nThrough this two-day course, students will engage with science communication through images. They will be introduced to some fundamentals of visual science communication, understand how to tell stories using images, learn to tailor their content to different target audiences, and gain perspectives on how different visual language can impact science communication.\n\n\n\n\n\n\n\n\n\nAbout the Instructor\n\n\n\n\n\nIpsa Jain is a scientist turned illustrator, who uses the visual medium to tell tales of science. She makes images, zines, and books among other things. Her latest book, co-authored with Minhaj Sirajuddin, called Actually, Colors Speak is about coloration in the animal kingdom.\nShe is a Visual Communication faculty at Srishti Manipal Institute, Bangalore. She has collaborated with various institutes like Centre for Cellular and Molecular Biology (CCMB), inStem (CCMB), Azim Premji University and more on projects that centred around science illustrations, video, and sci-art. She also does independent work under the moniker ipsawonders. She works and lives in Bangalore.\nTo know more about her work visit ipsawonders.com or connect with her through Twitter, Linkedin, Instagram or email: ipsajain.31@gmail.com\n\n\n\n\n\n\n\n\n\nDates and Time\n\n\n\n\n\nTentative dates: 5th November and 6th November\nTiming: 11 am to 1:00 pm • lunch break • 2:30pm to 4:00 pm • tea break • 4:30 pm to 6:00 pm\n\n\n\n\n\n\n\n\n\nTarget Audience\n\n\n\n\n\nThe course material is beginner-friendly with ample exercises. The only prerequisite is enthusiasm to learn science communication through art.\n\n\n\n\n\n\n\n\n\nMethodology\n\n\n\n\n\nThe course will be taught in person and will feature in-class practice exercises as well. The sessions will be interactive with lots of drawing (without judgement on skill levels) and peer discussions and critique sessions.\n\n\n\n\n\n\n\n\n\nObjectives\n\n\n\n\n\nThe course aims to help students build conceptual frameworks to understand, appreciate, and critique images in science.\n\n\n\n\n\n\n\n\n\nOutcome\n\n\n\n\n\nThe participants can develop their unique style of science communication and engage with subject matters in a more creative and unencumbered manner. The course will help them develop and polish their ideas for various visual science communication efforts.\n\n\n\n\n\n\n\nDay 1: Images in science\n\nClassification and classical examples\nScientific progress from observational drawings (Haeckel’s images, personal work)\nTransformation of images, meaning making, storytelling (DNA story or Darwin story)\n\nDay 2: Visual Science communication\n\nMediums, audiences, intent-content-context bridges\nComparing visual media for similar content made for different audiences\nClarity vs complexity in scientific work\nGroup activity based on give brief, followed by peer review"
  },
  {
    "objectID": "courses/2022/scicomm.html",
    "href": "courses/2022/scicomm.html",
    "title": "Fundamentals of Science Communication | Siddharth Kankaria",
    "section": "",
    "text": "— Siddharth Kankaria\n\n\n\n\n\n\nAbout the Course\n\n\n\n\n\nScience communication is an act of connecting people with knowledge, emotions and shared experiences within the field of science. It is both an art to be practised creatively as well as a science to be studied systematically.\nThis week-long course will provide an introduction to the theory and practice of science communication and outline some fundamental tenets of communicating science strategically. Using interactive approaches like discussions, games, and activities, this course will provide Early Career Researchers with an introduction to the frameworks, formats and importance of science communication, and equip them to design, implement and evaluate their science communication efforts effectively.\n\n\n\n\n\n\n\n\n\nAbout the Instructor\n\n\n\n\n\nSiddharth Kankaria is a science communication practitioner and researcher working at NCBS Bangalore and the Founder of the SciCommSci Club – a flagship initiative for engaging with the science of science communication. He is keenly interested in developing the research-practice continuum within science communication, contributing to mentorship, capacity-building & DEI efforts, and developing intersectional science engagement practices for the Global South. Connect with him on Twitter or LinkedIn at @SiddhrthKnkaria.\n\n\n\n\n\n\n\n\n\nDates and Time\n\n\n\n\n\n25th July to 29th July 2022 • 4PM — 6PM\n\n\n\n\n\n\n\n\n\nTarget Audience\n\n\n\n\n\nThe course material is beginner-friendly and hands-on. The only prerequisite is enthusiasm to learn science communication.\n\n\n\n\n\n\n\n\n\nMethodology\n\n\n\n\n\nThe course will be taught in person and feature in-class practice exercises as well. A collection of resources will be ready for the students’ reference from the first class onwards.\n\n\n\n\n\n\n\n\n\nObjectives\n\n\n\n\n\nThe course aims to introduce the fundamentals of effective science communication.\n\n\n\n\n\n\n\n\n\nOutcome\n\n\n\n\n\nParticipants will have the skills to craft their own science communication pieces and be able to convey their specialized research work in a manner that is accessible and interesting to a non-specialist, broad audience.\n\n\n\n\n\n\n\nDay 1\n\nDefining SciComm & Public Engagement\nSciComm Strategy & Fundamentals\nExercise: Choose a SC & PE project and develop a strategy zine for it\n\nDay 2\n\nHistory of Science Communication\nSciComm Models\nExercise: Write a 200 word piece describing a suitable model for your SC & PE project\n\nDay 3\n\nImportance of Narratives for SciComm + Storytelling techniques for SciComm\nDealing with Jargon + Metaphors & Analogies + Balancing Accuracy vs. Accessibility\nExercise: Storyboarding a concept for your SC & PE project\n\nDay 4\n\nEthics of doing SciComm\nUnderstanding your SciComm Audiences\nExercise: Write a 300-word profile of a specific target audience for your SC & PE activity \n\nDay 5\n\nExercise: Present your SC & PE project overview with reflections from course modules \nChallenges of doing SciComm in India\nBuilding a SciComm Career in India"
  },
  {
    "objectID": "courses/2022/03-ES242/labs/lab-w02.html",
    "href": "courses/2022/03-ES242/labs/lab-w02.html",
    "title": "ES242. Data Structures and Algorithms I. Week 02 Lab",
    "section": "",
    "text": "Problem 1. Four Points\n\n\n\n\n\nThere is a rectangle in the xy-plane. Each edge of this rectangle is parallel to the 2or y-axis, and its area is not zero.\nGiven the coordinates of three of the four vertices of this rectangle, (P,Q), (A,B), and (X,Y), find the coordinates of the other vertex.\n\n\nAll numbers are between -100 and +100.\nThere uniquely exists a rectangle with all of (P,Q), (A,B), and (X,Y) as vertices, edges parallel to the xor y-axis, and a non-zero area.\nAll values in input are integers.\n\n\n\nInput is given from Standard Input in the following format:\nP Q\nA B\nX Y\n\n\n\nPrint the sought coordinates (x,y) separated by a space in the following format:\nR S\n\n\n\nSample Input 1\n-1 -1\n-1 2\n3 2\nSample Output 1\n3 -1\nThe other vertex of the rectangle with vertices (−1,−1),(−1,2),(3,2) is (3,−1).\n\n\n\n\n\n\n\n\n\n\nProblem 2. Waking Up\n\n\n\n\n\n\n\nOne day, Tina got up at exactly B minutes past A o’clock (in 24-hour clock), and Rahul got up at exactly D minutes and 1 second past C o’clock.\nIf Tina got up earlier than Rahul, print Tina; otherwise, print Rahul.\n\n\n\n\n0 < A < 23\n0 ≤ B ≤ 59\n0< C < 23\n0 ≤ D ≤ 59\nAll values in input are integers.\n\n\n\n\nInput is given from Standard Input in the following format:\nA B C D\n\n\n\nIf Tina got up earlier than Rahul, print Tina; otherwise, print Rahul.\n\n\n\nSample Input 1\n7 0 6 30\nSample Output 1\nRahul\nSample Input 2\n7 30 7 30\nSample Output 2\nTina\n\n\n\n\n\n\n\n\n\n\nProblem 3. Ratings\n\n\n\n\n\nCodeforces separates its users into 4 divisions by their rating:\n\nFor Division 1: 1900 ≤ rating\nFor Division 2: 1600 ≤ rating ≤ 1899\nFor Division 3: 1400 ≤ rating ≤ 1599\nFor Division 4: rating ≤ 1399\n\nGiven a rating, print in which division the rating belongs.\n\n\nThe first line of the input contains an integer 𝑡 (1≤𝑡≤10^4) — the number of testcases.\nThe description of each test consists of one line containing one integer rating (−5000≤rating≤5000).\n\n\n\nFor each test case, output a single line containing the correct division in the format “Division X”, where 𝑋 is an integer between 1 and 4 representing the division for the corresponding rating.\n\n\n\nSample Input 1\n7\n-789\n1299\n1300\n1399\n1400\n1679\n2300\nSample Output 1\nDivision 4\nDivision 4\nDivision 4\nDivision 4\nDivision 3\nDivision 2\nDivision 1\nNote\nFor test cases 1−4, the corresponding ratings are −789, 1299, 1300, 1399, so all of them are in division 4.\nFor the fifth test case, the corresponding rating is 1400, so it is in division 3.\nFor the sixth test case, the corresponding rating is 1679, so it is in division 2.\nFor the seventh test case, the corresponding rating is 2300, so it is in division 1.\n\n\n\n\n\n\n\n\n\n\nProblem 4. Meta Tic-Tac-Toe [Open Ended]\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis is an optional and open-ended problem. Feel free to get creative.\n\n\nExamine the rules of Ultimate Tic Tac Toe and write your own implementation of the game."
  },
  {
    "objectID": "courses/2022/03-ES242/labs/lab-w01.html",
    "href": "courses/2022/03-ES242/labs/lab-w01.html",
    "title": "ES242. Data Structures and Algorithms I. Week 01 Lab",
    "section": "",
    "text": "Problem 1. Finding the Coefficient\n\n\n\n\n\np(x) is a polynomial whose coefficients are between 0 and 9.\nYou are given the value of p(10) and a number d.\nReturn the coefficient of x^d in p(x).\n\n\nThe first line of the input contains a number T, which is the number of test cases.\nThe next 2T lines contain T test cases. Each test case is two lines. The first line is the value of p(10) and the second line is the value of d.\nIt is guaranteed that p(10) will be at most 10^9 and d will be at most 10.\n\n\n\nFor each test case, print a single integer on a new line, which is the coefficient of x^d in p(x). DO NOT output anything else!\n\n\n\nSample Input\n1\n9042\n3\nExpected Output\n9\n\n\n\n\n\n\n\n\n\n\nProblem 2. Finding the Coefficient Redux\n\n\n\n\n\np(x) is a polynomial whose coefficients are either 0 or 1.\nYou are given the value of p(2) and a number d.\nReturn YES if the coefficient of x^d in p(x) is 1 and NO otherwise.\n\n\nThe first line of the input contains a number T, which is the number of test cases.\nThe next 2T lines contain T test cases. Each test case is two lines. The first line is the value of p(2) and the second line is the value of d.\nIt is guaranteed that p(2) will be at most 10^9 and d will be at most the degree of p(x).\n\n\n\nFor each test case, print a single integer on a new line, which is YES or NO depending on if the coefficient of x^d in p(x) is 1 or 0. DO NOT output anything else!\n\n\n\nSample Input\n6\n45\n0\n45\n1\n45\n2\n45\n3\n45\n4\n45\n5\nExpected Output\nYES\nNO\nYES\nYES\nNO\nYES\n\n\n\n\n\n\n\n\n\n\nProblem 3. Game of Trust\n\n\n\n\n\nWrite a simulation for the Game of Trust when played by a copycat player for R rounds.\n\n\nThe first line of the input contains a number T, which is the number of test cases.\nThe next 2T lines contain T test cases. Each test case is two lines. The first line is the value R and the second line is R space-separated integers. The i-th integer on the second line is 1 if the other player cooperated in the i-th round, and 0 otherwise.\n\n\n\nFor each test case, print two space-separated integers on a new line. The first integer is the total number of coins earned by the copycat player, while the second integer is the total number of coins earned by the other player. Note that you have to output the net balance. DO NOT output anything else!\n\n\n\nSample Input\n1\n3\n1 1 1\nExpected Output\n6 6\n\n\n\n\n\n\n\n\n\n\nProblem 4. Game of Trust [Open Ended]\n\n\n\n\n\nThere are no tests or templates for this problem. Implement variations of the Game of Trust and feel free to get creative about I/O, language, and even come up with your own strategies.\nCheck out the Sandbox Page on the interactive essay by Nicky Case for inspiration.\n\n\n\n\n\n\n\n\n\nProblem 5. Validating a Self-Working Card Trick [Open Ended]\n\n\n\n\n\nWatch this video and write a program to validate the mechanics of the card trick shown.\nIn other words, your program should take as input a sequence of cards, with the promise that the number of red cards is equal to the number of black cards, and then “perform” the trick as shown in the video, and verify that the final claim about the number of red cards in the red pile being equal to the number of black cards in the black pile is, in fact, true."
  },
  {
    "objectID": "courses/2022/03-ES242/index.html",
    "href": "courses/2022/03-ES242/index.html",
    "title": "ES 242 | Aug-Nov 2022",
    "section": "",
    "text": "About the Course\n\n\n\n\n\nData structures give us principled ways to stow away information. It’s important to do this nicely based on what you want to do with the information.\nFor example, the notes you might be taking in this class is information. If you have no plans of revisiting them later, you can take them as you please, or better yet, not take them at all!\nHowever, you want your notes optimised for giving you quality company during a 2AM revision session on exam day, competing with Maggi for attention, you want your notes to be competently taken: they don’t have to be neat, and it’s enough for them to be useful.\nOn the other hand, if you are taking notes so that a special someone who will inevitably miss a few classes will almost certainly ask for later, then you would be making notes to impress, and that potentially requires a different approach.\nThroughout this course, we will try to make sense of trade-offs.\n\n\nsequential data (arrays, dynamic arrays, linked lists and variants) • dequeues, stacks, queues • graph representations • graph traversals (BFS/DFS) and applications (connected components, bipartiteness, topological sort) • searching and sorting • heaps • BSTs • (2,3)-trees\n\n\n\n\n\n\n\n\n\n\nTarget Audience\n\n\n\n\n\nThis course is aimed at undergraduates in their first or second year, as a first introduction to data structures and algorithms.\n\n\n\n\n\n\n\n\n\nPrerequisites\n\n\n\n\n\nThe course is largely self-contained. Working familiarity with a programming language will be useful for the labs, where solutions are expected to be written out in C.\n\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\n\n\nOpen Data Structures by Pat Morin\nLecture notes by John Bullinaria\nData Structures Using C & C++ by Aaron M. Tenebaum; Moshe J. Augenstein; Yedidyah Lansam\nData Structures and Algorithms by A. Aho, J. Hopcroft, J. Ullman\nAlgorithms by Jeff Erickson\n\n\n\n\n\n\n\n\n\n\nTimings and Venue\n\n\n\n\n\nLectures on Tuesdays and Wednesdays • 10AM — 11AM • 1/101 Labs on Wednesdays • 4PM — 6PM • 7/108 and 7/109\n\n\n\n\n\n\n\n\n\nTAs and Office hours\n\n\n\n\n\n\n\nBy appointment.\n\n\n\n\nHarshil Mittal (mittal_harshil@iitgn.ac.in)\nSaraswati Nanoti (nanoti_saraswati@iitgn.ac.in)\n\n\n\n\n\nKsheer Agrawal (ksheer.agrawal@iitgn.ac.in)\nProgyan Das (progyan.das@iitgn.ac.in)\nNipun Mahajan (mahajan.n@iitgn.ac.in)\nYash More (yash.mh@iitgn.ac.in)\n\n\n\n\n\nXhitij Choudhary (xhitij.cm@iitgn.ac.in)\nBhavesh Jain (bhavesh.jain@iitgn.ac.in)\n\n\n\n\n\n\n\n\n\n\n\nEvaluation policy\n\n\n\n\n\n\nWeekly Assignments on Google Classroom. 2 * [top 10] = 20\nLab Assignments on repl.it. 1 * [top 10] = 10\nClass participation via Mentimeter. 0.5 points per class capped at 10\nMidsem Exam. 10 (lab) + 10 (theory) = 20\nFinal Exam. 10 (lab) + 15 (theory) = 25\nFour quizzes (two theory, two lab & top 3 outcomes counted). 3 * 5 = 15\n\n\n\n\n\n\n\n\n\n\nRegistration\n\n\n\n\n\nFor IITGN students, (pre-)register through IMS as usual.\nIf you are not from IITGN and are interested in taking up the course, then please send me an email.\nRegistration for the course is now closed. The next edition of this course will be offered in the Jan - Apr 2023 semester.\n\n\n\nNote: contents being actively updated at the time of this writing. Enroled students will find all materials in the Google classroom for this course. Items marked  are coming soon!\n\nLecturesLabsMentimeterAssignmentsQuizzesExams\n\n\n\n\n\n    \n        Date\n        Lecture\n        Slides\n        Notes\n        Video\n    \n    \n                    \n            \n                02 Aug, 2022\n            \n            \n                1. Introduction to Data Structures\n                Data Structures - philosophy and examples • Representing games\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                03 Aug, 2022\n            \n            \n                2. Introduction to Data Structures\n                Representing Sequential Data • Arrays • Lists\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                09 Aug, 2022\n            \n            \n                 Institute Holiday\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                10 Aug, 2022\n            \n            \n                 Quiz 0 (Ungraded)\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                16 Aug, 2022\n            \n            \n                3. Representing Graphs\n                Adjacency Lists • Adjacency Matrices • Edge Lists\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                17 Aug, 2022\n            \n            \n                4. Representing Graphs (contd.)\n                Adjacency Lists • Adjacency Matrices • Edge Lists\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                23 Aug, 2022\n            \n            \n                5. Dequeues\n                Introducing the cardstack data structure • The Gilbreath Shuffle\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                24 Aug, 2022\n            \n            \n                6. Dequeues\n                Queues and Stacks as special cases of Dequeues\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                30 Aug, 2022\n            \n            \n                7. Euler Tours\n                Euler Tour Demonstration • Card trick • de Bruijn sequences • Constructing de Bruijn sequences using Euler Tours\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                31 Aug, 2022\n            \n            \n                8. Euler Tours\n                Computing Euler Tours • Hierholzer's algorithm\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                06 Sep, 2022\n            \n            \n                9. Stable Marriages\n                The Stable Marriage Problem • Gale-Shapley Algorithm\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                07 Sep, 2022\n            \n            \n                10. Stable Marriages\n                Proof of Termination • Bounding the number of proposals • Proving the stability of the output\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                13 Sep, 2022\n            \n            \n                11. Recap Lecture\n                Review of arrays, linked lists, stacks, queues, and graphs\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                14 Sep, 2022\n            \n            \n                 Theory Quiz 01\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                20 Sep, 2022\n            \n            \n                12. Navigating Graphs\n                An introduction to navigating graphs\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                21 Sep, 2022\n            \n            \n                13. Navigating Graphs (BFS)\n                Breadth-First Search • Correctness • Analysis of Running Time\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                11 Oct, 2022\n            \n            \n                14. Navigating Graphs (DFS)\n                Depth-First Search • Pre-Post Intervals\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                12 Oct, 2022\n            \n            \n                15. Navigating Graphs (DFS)\n                Depth-First Search • DFS-based classification of vertices • DFS-based classificaton of edges • Cycles and backedges\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                18 Oct, 2022\n            \n            \n                16. DFS Applications\n                Topological Sort (Algorithm)\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                19 Oct, 2022\n            \n            \n                17. DFS Applications\n                Postorder • Preorder • Topological Sort (Analysis)\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                25 Oct, 2022\n            \n            \n                18. Shortest Paths\n                A teaser the challenges in extending BFS to weighted graphs • Pseudopolynomial running time\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                26 Oct, 2022\n            \n            \n                19. Heaps\n                Selection Sort • Supporting only Insert and FindMin • The challenge of ExtractMin\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                01 Nov, 2022\n            \n            \n                20. Heaps\n                The Heap Property • Insert • FindMin • ExtractMin\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                02 Nov, 2022\n            \n            \n                21. Heaps\n                Representing Heaps with Arrays\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                08 Nov, 2022\n            \n            \n                 Institute Holiday \n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                09 Nov, 2022\n            \n            \n                 Theory Quiz 02\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                15 Nov, 2022\n            \n            \n                22. Heaps Revisited\n                Analysis • Heapify is Linear Time\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                16 Nov, 2022\n            \n            \n                23. Balanced Binary Search Trees\n                (2,3)-Trees • Insertion • Deletion\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                22 Nov, 2022\n            \n            \n                24. Balanced Binary Search Trees\n                (2,3)-Trees Height Analysis\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                23 Nov, 2022\n            \n            \n                25. Recap\n                Review of BFS, DFS, Heaps, and Balanced BSTs\n            \n            \n            \n            \n            \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                03 Aug, 2022\n            \n            \n                W01. Representations\n                Finding the Coefficient Finding the Coefficient Redux Game of Trust Game of Trust [Open Ended] Validating a Self-Working Card Trick [Open Ended]\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    28 Aug, 2022\n            \n        \n                    \n            \n                10 Aug, 2022\n            \n            \n                W02. C Warmup and Recap\n                Four Points  Waking Up  Ratings  Meta Tic-Tac-Toe [Open Ended]\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    28 Aug, 2022\n            \n        \n                    \n            \n                17 Aug, 2022\n            \n            \n                W03. Representing Graphs\n                Swapping Variables  Adjacency Matrix  Edge List  Adjacency List  Getting Even\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    28 Aug, 2022\n            \n        \n                    \n            \n                24 Aug, 2022\n            \n            \n                W04. The Cardstack\n                Print alternate cards  Reverse a list of numbers  Cut shuffle  Overhand Shuffle  de Bruijn sequences\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    11 Sep, 2022\n            \n        \n                    \n            \n                31 Aug, 2022\n            \n            \n                W05. Euler Tours and de Bruijn Sequences\n                Euler Circuit Sanity Check  Highway Orientation  Edge Orientation Puzzle   Generate de Bruin Sequences\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    11 Sep, 2022\n            \n        \n                    \n            \n                07 Sep, 2022\n            \n            \n                W06. Stable Marriages\n                Merge List  Insert Node  Reverse The List  Count Blocking Pairs  Stable Matchings\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    09 Sep, 2022\n            \n        \n                    \n            \n                14 Sep, 2022\n            \n            \n                No Lab\n                Lab Quiz 1 (held on 17 Sep, 2022)\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                21 Sep, 2022\n            \n            \n                W08. Navigating Graphs (BFS)\n                Find My Ancestor!  Longest Path  Unique Servers  Run a Marathon  Just BFS\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    27 Sep, 2022\n            \n        \n                    \n            \n                12 Oct, 2022\n            \n            \n                W09. Practice Lab\n                Cop and Robber  Balanced Brackets  Whispering Joker  Time Series  String Game  Lab Exam (held on 15 Oct, 2022)\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                19 Oct, 2022\n            \n            \n                W10. Navigating Graphs (DFS)\n                2-Colorable Graphs  Topological Sort  Is DAG?  Get Food!\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    01 Nov, 2022\n            \n        \n                    \n            \n                26 Oct, 2022\n            \n            \n                W11. Graph Traversal Applications\n                Learning Languages  Permutation Tree  Make Walls  Palindromic Crosswords\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    01 Nov, 2022\n            \n        \n                    \n            \n                02 Nov, 2022\n            \n            \n                W12. Heaps\n                Heapify  HeapSort  The Unity Project  Largest Number\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    08 Nov, 2022\n            \n        \n                    \n            \n                09 Nov, 2022\n            \n            \n                W13. Practice Lab\n                Visit Me First  Visit Me Last!  Sort a Tree  Predicting Possibility  Can You Register?\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                16 Nov, 2022\n            \n            \n                No Lab\n                Lab Quiz 2 (held on 20 Nov, 2022)\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                23 Nov, 2022\n            \n            \n                W15. Recap Lab\n                Review of Problems  On Writing Tests  Benchmarking\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\nHeads Up\n\n\n\nThese questions are integrated into the lectures and may not make sense standalone. Please check the slides and/or notes for additional context.\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                02 Aug, 2022\n            \n            \n                Introduction to Data Structures\n                Data Structures - philosophy and examples • Representing games\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                03 Aug, 2022\n            \n            \n                Introduction to Data Structures\n                Representing Sequential Data • Arrays • Lists\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                16 Aug, 2022\n            \n            \n                Representing Graphs\n                Adjacency Lists • Adjacency Matrices • Edge Lists\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                17 Aug, 2022\n            \n            \n                Representing Graphs (contd.)\n                Adjacency Lists • Adjacency Matrices • Edge Lists\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                23 Aug, 2022\n            \n            \n                Dequeues\n                Introducing the cardstack data structure • The Gilbreath Shuffle\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                24 Aug, 2022\n            \n            \n                Dequeues\n                Queues and Stacks as special cases of Dequeues\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                30 Aug, 2022\n            \n            \n                Euler Tours\n                Euler Tour Demonstration • Card trick • de Bruijn sequences • Constructing de Bruijn sequences using Euler Tours\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                31 Aug, 2022\n            \n            \n                Euler Tours\n                Computing Euler Tours • Hierholzer's algorithm\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                06 Sep, 2022\n            \n            \n                Stable Marriages\n                The Stable Marriage Problem • Gale-Shapley Algorithm\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                07 Sep, 2022\n            \n            \n                Stable Marriages\n                Proof of Termination • Bounding the number of proposals • Proving the stability of the output\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                13 Sep, 2022\n            \n            \n                Recap Lecture\n                Review of arrays, linked lists, stacks, queues, and graphs\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                20 Sep, 2022\n            \n            \n                Navigating Graphs\n                An introduction to navigating graphs\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                21 Sep, 2022\n            \n            \n                Navigating Graphs (BFS)\n                Breadth-First Search • Correctness • Analysis of Running Time\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                11 Oct, 2022\n            \n            \n                Navigating Graphs (DFS)\n                Depth-First Search • Pre-Post Intervals\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                12 Oct, 2022\n            \n            \n                Navigating Graphs (DFS)\n                Depth-First Search • DFS-based classification of vertices • DFS-based classificaton of edges • Cycles and backedges\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                18 Oct, 2022\n            \n            \n                DFS Applications\n                Topological Sort (Algorithm)\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                19 Oct, 2022\n            \n            \n                DFS Applications\n                Postorder • Preorder • Topological Sort (Analysis)\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                25 Oct, 2022\n            \n            \n                Shortest Paths\n                A teaser the challenges in extending BFS to weighted graphs • Pseudopolynomial running time\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                26 Oct, 2022\n            \n            \n                Heaps\n                Selection Sort • Supporting only Insert and FindMin • The challenge of ExtractMin\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                01 Nov, 2022\n            \n            \n                Heaps\n                The Heap Property • Insert • FindMin • ExtractMin\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                02 Nov, 2022\n            \n            \n                Heaps\n                Representing Heaps with Arrays\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                15 Nov, 2022\n            \n            \n                Heaps Revisited\n                Analysis • Heapify is Linear Time\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                16 Nov, 2022\n            \n            \n                Balanced Binary Search Trees\n                (2,3)-Trees • Insertion • Deletion\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                22 Nov, 2022\n            \n            \n                Balanced Binary Search Trees\n                (2,3)-Trees Height Analysis\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                23 Nov, 2022\n            \n            \n                Recap\n                Review of BFS, DFS, Heaps, and Balanced BSTs\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                10 Aug, 2022\n            \n            \n                Quiz 0\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                10 Aug, 2022\n            \n            \n                Quiz 1\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                10 Aug, 2022\n            \n            \n                Quiz 2\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                20 Nov, 2022\n            \n            \n                Lab Quiz 2\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                28 Sep, 2022\n            \n            \n                MidSem Exam\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    28 Sep, 2022\n            \n        \n                    \n            \n                30 Nov, 2022\n            \n            \n                EndSem Exam\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    30 Nov, 2022\n            \n        \n\n\n\nNo matching items"
  },
  {
    "objectID": "courses/2022/03-ES242/labquiz2.html",
    "href": "courses/2022/03-ES242/labquiz2.html",
    "title": "ES242. Data Structures and Algorithms I. Week 02 Lab",
    "section": "",
    "text": "Problem 1. Unity Project\n\n\n\n\n\nThere are n people partaking in a project X. The capability value of the ith person is denoted as C[i]. The manager of the project has proposed the following algorithm to calculate the capability of the group (to undertake project X):\nOn each turn, choose two people, x and y, with capabilities C[x] and C[y] respectively (with C[x] <= C[y]). A unity procedure is followed:\n\nIf the two have same capability value, remove both.\nElse, person x is removed, and capability of person y changes to C[y]-C[x]\n\nIt is obvious that at the end at most one person shall remain. The capability value of the person is stated as the capability value of the group. If no person remains, capability value of the group is taken as 0.\nYou have the find the minimum possible capability value of the group.\n\n\n\n\n\n\nRemark\n\n\n\nNote that the choice of people for the unite procedure directly affects the final capbility value.\n\n\n\n\nThe first line contains an integer n.  The next line contains n space-separated integers representing C[]\n\n\n\nReturn the minimum possible capability value of the group according to the mentioned algorithm\n\n\n\nSample Input 1\n6\n2 7 4 1 8 1\nSample Output 1\n1\nSample Input 2\n10\n1 3 5 4 6 13 10 9 8 15 16\nSample Output 2\n0\n\n\n\n\n\n\n\n\n\n\nProblem 2. Connect the City\n\n\n\n\n\nBangalore has n locations, and m bidirectional roads between them. The goal is to construct new roads so that there is a route between any two cities.\nYour task is to find out the minimum number of roads required.\n\n\nThe first input line has two integers n and m: the number of cities and roads. The cities are numbered 1,2,...,n.\nAfter that, there are m lines describing the roads. Each line has two integers a and b: there is a road between those cities.\nA road always connects two different cities, and there is at most one road between any two cities.\n\n\n\nPrint an integer k: the number of required roads.\n\n\n\n\n1 \\leq n \\leq 10^5\n1 \\leq m \\leq 2⋅10^5\n1 \\leq a,b \\leq n\n\n\n\n\nSample Input\n4 2\n1 2\n3 4\nSample Output\n1\n\n\n\n\n\n\n\n\n\n\nProblem 3. Spreading News\n\n\n\n\n\nAfter all the dropouts, there are n people left in ES242. The class has students from across different batches and disciplines, so some people know each other while others do not.\nYou want spread a rumor about whether ES242 will be repeated in the next semester. Students who are friends with each other will share any information they get. To get student i to start spread a rumor, you have to pay them in by buying c[i] samosas at Aadhya. Once someone is bribed, s/he tells it to all her/his friends, and they start spreading the rumor to their friends (for free), and so on.\nYou want everyone to catch the rumor. What is the minimum number of samosas you need to buy?\nTake a look at the notes if you think you haven’t understood the problem completely.\n\n\nThe first line contains two integer numbers n and m (1 \\leq n \\leq 10^5, 0 \\leq m \\leq 10^5) — the number of students in the class and the number of pairs of friends.\nThe second line contains n integer numbers c[i] –— the amount of samosas i-th student asks to start spreading the rumor.\nThen m lines follow, each containing a pair of numbers (x[i], y[i]) which represent that characters x[i] and y[i] are friends (1 \\leq x[i], y[i] \\leq n, x[i] \\neq y[i]). It is guaranteed that each pair is listed at most once.\n\n\n\nPrint one number — the minimum number of samosas you have to buy to spread the rumor fully.\n\n\n\nSample Input\n5 2\n2 5 3 4 8\n1 4\n4 5\nSample Output\n10\nSample Input\n10 0\n1 2 3 4 5 6 7 8 9 10\nSample Output\n55\nNote\nIn the first example the best decision is to bribe the first student (he will spread the rumor to fourth student, and the fourth one will spread it to student). You also have to bribe the second and the third students, so they know the rumor.\n\n\n\n\n\n\n\n\n\n\nProblem 4. Predicting Possibility\n\n\n\n\n\nYou are playing a decision making game where the output can be either 1 or 0.\nGiven a N X N matrix, the objective of the game is to predict if it’s possible to reach from a given source to a destination in less than or equal to k moves.\nSome constraints are as follows:\n\nYou can only move to adjacent positions in 1 move.\nYou can only move diagonally across the matrix.\n\nGiven the value of n, and the maximum moves k, determine if you can fulfill the requirement: can you reach from source to destination in less than k moves?\n\n\nThe first line contains an integer n.\nThe second line contains an integer k, denoting the maximum number of moves you can make. \nThe third line contains two space-separated integers, i and j. An entry i j denotes i as the x-coordinate and j as y-coordinate of the source location.\nThe fourth line contains two space-separated integers, m and n. An entry m n denotes m as the x-coordinate and n as y-coordinate of the destination.\n\n\n\nReturn 1 if you can reach from source to destination in less than k moves. Else, return 0.\n\n\n\nSample Input 1\n4\n3\n0 0\n3 1\nSample Output 1\n1\n\n\n\n\n\n\n\n\n\n\nProblem 5. Can You Register?\n\n\n\n\n\nYou are a student in a university U.\nYou can only register in a certain program A, if the following condition is met:\nYou have registered for all courses with the course IDs [0,1... num_courses-1]\nIf there exists at least one i in range [0,1... num_courses-1] for which you cannot register, then you cannot register from the program.\nSome constraints are as follows:\n\nSome courses may have prerequisite courses. For example if i is a prerequisite of course ID j, then you must register for i before j\nYou can not repeat a course, you can only register for a course one.\n\nGiven the value of num_courses, and the prerequisite requirements, determine if you can fulfill the requirement: can you register for A (can you register for all the courses in range num_courses)?\n\n\nThe first line contains an integer num_courses.\nThe second line contains an integer num_prerequisites, denoting the number of prerequisites or conditions you have to fulfil.\nThe next num_prerequisites lines contain 2 space-separated integers i and j. An entry i j denotes course j is a prerequisite for course i.\n\n\n\nReturn YES if you can register for program A. Else, return NO.\n\n\nSample Input 1\n2\n2\n1 0\n0 1\nSample Output 1\nNO"
  },
  {
    "objectID": "courses/2022/03-ES242/midsem-questions.html",
    "href": "courses/2022/03-ES242/midsem-questions.html",
    "title": "ES242. Data Structures and Algorithms I. MidSem Questions",
    "section": "",
    "text": "Problem 1. A Boastful Cop vs a Clever Robber\n\n\n\n\n\nA robber is trying to escape a cop on an undirected graph G. In the beginning, the cop is at a vertex s and the robber is at a vertex t. (You may assume that s and t are distinct.) They take turns making moves, and each knows the location of the other at all times. A move (by either of them) consists of either staying at the current vertex or moving to a neighbouring one.\nThe cop is boastful, so he announces his moves before making them. Specifically:\n\nbefore anyone makes a move, the cop’s first move is announced - so the robber knows where the cop is headed.\nThen, the robber makes an actual move.\nAfter this, each time the cop moves, he must respect the previous announcement (i.e, move to the previously announced vertex), and then decide his next move and announce it.\nThe robber hears the announcements, so she always knows the cop’s next move before making her own. She makes her move.\n\nIf the cop and the robber are at the same vertex after either of them moves, then the robber is caught. Otherwise, the chase is on!\nThe robber chooses her moves optimally to escape. If she cannot escape, she chooses her moves to maximize the total number of moves until she is caught. The cop chooses his moves optimally to try to catch the robber in as few total moves as possible.\nGiven the graph’s layout and the initial locations of both the cop and the robber, find out whether robber will be caught by the cop and, if so, in how many moves. We say that the game is won by the robber if she’s never caught, and by the cop otherwise.\nIn the figures below, the square vertex depicts the initial location of the robber, and the star depicts the initial location of the cop. Indicate what happens under optimal play. If you choose that the cop wins, indicate how many moves the game lasts assuming optimal play. Each move made by each player counts as a distinct move.\n\n[2 marks] Who wins? __________________\n[2 marks] Who wins? __________________\n[2 marks] If the robber starts on a vertex that is a part of a cycle, then which of the following statements is true?\n⭕️ The robber wins this game.\n⭕️ The cop wins this game and the number of moves is equal to the length of the cycle.\n⭕️ The cop wins this game and the number of moves is twice the length of the cycle.\n⭕️ The cop wins this game and the number of moves depends on the initial distance between the cop and the robber.\n⭕️ The outcome depends on where the cop starts.\n[3 marks] Suppose the game is being played on a path (i.e, a graph with vertices u_1, \\ldots, u_n and edges (u_1,u_2), (u_2, u_3), \\cdots, (u_{n-1},u_n). Suppose the cop starts at u_1 and the robber starts at u_n. Which of the following statements is true?\n⭕️ The robber wins this game.\n⭕️ The cop wins this game and the number of moves is n.\n⭕️ The cop wins this game and the number of moves is 2n.\n⭕️ The cop wins this game and the number of moves is 2n-1.\n⭕️ The cop wins this game and the number of moves is 2(n-1).\n[3 marks] Suppose the graph G has a cycle on the vertices vv_1, v_2, \\ldots, v_kand these are the only vertices that belong to any cycle in G. The robber is initially on a vertex uuand the closest vertex on the cycle is vv_1 via the path ((u,p),(p,q),(q,v_1) The cop is initially on a vertex wwand the closest vertex on the cycle is vv_n via the path ((w,r),(r,v_n) Which of the following statements is true? Assume there are no other vertices in the graph G.\n⭕️ The robber wins this game.\n⭕️ The cop wins this game.\nExplain your answer: if you think the robber wins the game, explain how the robber will evade the cop forever, and if you think the cop wins this game, explain what is the sequence of moves in an optimal game. (You can use the space on the next page.)\n\n\n\n\n\n\n\n\n\n\nProblem 2. Cheating the Stable Marriage Algorithm\n\n\n\n\n\nConsider a stable marriage instance with A,B,C being the men and X,Y,Z being the women. The input is the following:\n\n[2 marks] What is the output of the stable matching algorithm for this instance? Assume that the men are proposing.\n[3 marks] Consider again the algorithm where men are proposing. One of the women can misreport her preferences to get a better outcome from this algorithm. Identify the woman and explain what preference she can submit instead of her true preference to improve the output from her perspective.\n\n\n\n\n\n\n\n\n\n\nProblem 3. Preserving Fixed-Points while Sorting\n\n\n\n\n\n[5 marks] When an array is to be sorted, it may happen that some data values start out being in the same position where they should end up. For example, in the array which is originally:\n45,-4,32,0\nthe 32 is right where it will be in the final sorted output:\n-4,0,32,45\nBut as a particular sorting algorithm operates, it might (depending on the algorithm) move such an element out of the position where it belongs and move it back eventually.\nLet’s say that a sorting algorithm respects fixedpoints if it never moves an element that is in its proper position, on any input.\nConsider the following methods of sorting:\nSelection sort. The algorithm divides the input list into two parts: a sorted sublist of items which is built up from left to right at the front (left) of the list and a sublist of the remaining unsorted items that occupy the rest of the list. Initially, the sorted sublist is empty and the unsorted sublist is the entire input list. The algorithm proceeds by finding the smallest element in the unsorted sublist, exchanging (swapping) it with the leftmost unsorted element (putting it in sorted order), and moving the sublist boundaries one element to the right.\nEg: 4 3 2 1 → 1 3 2 4 → 1 2 3 4\nInsertion sort. Insertion sort iterates over the array, consuming one input element each repetition, and grows a sorted output list. At each iteration, insertion sort removes one element from the input data, finds the location it belongs within the sorted list, and inserts it there. It repeats until no input elements remain.\nEg: 4 3 2 1 → 3 4 2 1 → 2 3 4 1 → 1 2 3 4\nWhich of the following statements are true?\n⭕️ Insertion sort does not respect fixedpoints but selection sort does.\n⭕️ Selection sort does not respect fixedpoints but insertion sort does.\n⭕️ Neither insertion sort nor selection sort respects fixed points.\n⭕️ Both insertion sort and selection sort respect fixed points.\nJustify your answer. If you claim that a particular sorting method does not respect fixed points, then give an example. If you claim that an algorithm does respect fixed points, argue why.\n\n\n\n\n\n\n\n\n\nProblem 4. Eliminating Jealousy\n\n\n\n\n\nYou have distributed M objects among N children. The set of objects given to a child is called his or her bundle. Each child has a specific value for their bundle: let us say child k has value v_k for their bundle. Each child also has a value for all the other bundles: so let us say that child k has value v_{k,\\ell} for the bundle that was given to child \\ell.\nWe say that child a is jealous of child b if v_{a,b} > v_a, i.e, s/he values the bundle given to b more than the bundle that s/he has.\nConsider the following directed graph G. Introduce one vertex for every child, and add an edge from a to b if a is jealous of b.\n\n[2 marks] Suppose G has a directed cycle u_1 \\rightarrow u_2 \\rightarrow \\cdots \\rightarrow u_q \\rightarrow u_1. Describe a way to reassign the bundles (without changing them) so that with the new assignment, all the edges in the cycle disappear (i.e, there is no jealousy between u_1 and u_2, between u_2 and u_3, and so on, with respect to the new assignment). Explain your answer on the next page.\n[1 marks] Suppose G has no directed cycles. Is it true that there is a child who is not jealous of anyone?\n⭕️ Yes ⭕️ No ⭕️ Impossible to conclude from the given information\n[1 marks] Suppose G has no directed cycles. Is it true that there is a child who is nobody is jealous of?\n⭕️ Yes ⭕️ No ⭕️ Impossible to conclude from the given information\n\n\n\n\n\n\n\n\n\n\nProblem 5. Make Strongly Connected\n\n\n\n\n\n[2 marks] In the graph below, what is the smallest number of edges you need to add to make the graph strongly connected? Recall that a strongly connected graph is one where there is a path from u to v for any pair of vertices u and v.\n\n\n\n\n\n\n\n\n\nProblem 6. Counting Gifts\n\n\n\n\n\n[2 marks] The following is true for n guests at a party:\n\nIn any group of three guests, there are two guests who do not know each other, and\nIn any groups of seven guests, there are two guests who do know each other.\n\nAt the end of the party, everyone gives a present to all the guests he or she knows.\nProve that the total number of gifts given is at most 6n.\nHint: what can you say about the maximum degree of this graph?"
  },
  {
    "objectID": "courses/2022/csresearch.html",
    "href": "courses/2022/csresearch.html",
    "title": "CS Research 101 | Shashank Srikant",
    "section": "",
    "text": "— Shashank Srikant\n\n\n\n\n\n\nAbout the Course\n\n\n\n\n\nWhen starting off their undergrad degrees in science and engineering, most are fueled by an idealism to do great science. However, no formal resources tell us what research—an established path to great science and engineering—is all about, and how one can get started. As a result, many don’t end up figuring out these details, have no idea what the journey promises to offer, and as a consequence, move on to other well-documented jobs and careers. While there’s nothing wrong with taking up well-documented careers, academia and scholarship loses out on quality talent.\nIn another extreme, among those few who are exposed to the idea of research while still in undergrad, there exists a frenzy to apply to graduate programs by the end of undergrad. And to achieve this, students tend to optimize working on projects which will land them ‘the best possible’ publications and letters from professors. While few successfully discover their interests this way, it generally fails as an approach.\nThis course aims to fast-track the process of learning more about research-first graduate programs and/or jobs. It will nudge you to introspect whether problem solving and research is something you will enjoy, and provide some concrete steps for your discovery. It is not designed to merely provide instructions on applying successfully to graduate programs or advanced degrees. Rather, it aims to introduce you to the realities of doing research, which should in turn help you gauge your preparedness for graduate school or a career in research.\n\n\n\n\n\n\n\n\n\nAbout the Instructor\n\n\n\n\n\nShashank is currently a Ph.D. candidate in computer science at the CS & AI Lab (CSAIL), in the department of Electrical engineering and Computer science (EECS) at MIT. He is advised by Una-May O’Reilly. His research interests are at the intersection of machine learning, program analysis, and cognitive neuroscience. He has published his work at top-tier academic venues and has authored multiple patents.\nPrior to his Ph.D. studies, he was a senior researcher at Aspiring Minds’ research lab, where he helped build, deploy, and manage a number of innovative products involving machine learning. These products are used by >1M job applicants across the world today. In this role, he also helped organize international workshops, led academic collaborations, and helped set up communities in India to participate and engage in ML and data science (http://www.datasciencekids.org, http://ml-india.org).\nHe is also interested in governance, and science education and policy. To understand the nuances of how state governments deliver benefits to the last-mile, he worked with Seva Setu, an organization which aims to bridge the gap between governments and people, for a year in rural Bihar in India.\nDetails on his work can be found on his webpage.\n\n\n\n\n\n\n\n\n\nDates and Time\n\n\n\n\n\n31st October – 5th November • Timing: 6:30PM to 8:30PM • Mode: Online (over Zoom)\n\n\n\n\n\n\n\n\n\nTarget Audience\n\n\n\n\n\nThe course material is beginner-friendly: the only pre-requisite is a willingness to commit time and curiosity about research pursuits in computer science (broadly interpreted).\nThe course is designed for undergraduates in computer science and allied areas in any year looking to plan out their first or second research projects, however, participation is not restricted and all are welcome.\n\n\n\n\n\n\n\n\n\nMethodology\n\n\n\n\n\nThe course will be taught over Zoom and will involve several hands-on assignments. The course has the following three sections, with two modules in each section:\n1.The first section focuses on the various motivations for pursuing research projects, the wrong reasons to take up research, exposure to different research-related careers available.\n2.The second section is about the mechanics of getting started with your first research(-ish) project. We introduce some common set of skills every researcher benefits from—taking initiative, reading and writing code, knowing domain-specific tools, parsing papers, communicating over email, and presenting your work. Also learn about the balances you will likely have to strike as you go along, and prepare with us for battles like imposter syndrome or loneliness you may face.\n\nThe third section covers exploring and approaching research opportunities after having cleared the first two sections. We will have pointers to generic opportunities that you can consider applying to. We will also leave you with suggestions for how to level up from after your first research apprenticeship, including information about preparing for graduate school, and discussions about relevant career options within and beyond academia. Pre-class reading: Each lecture will have a recommended short video or text we expect students to watch/read before attending class.\n\nFinal assessment: The final assessment will involve identifying a project relevant to your interest and skills, and drafting an email expressing your interest in getting started with it.\n\n\n\n\n\n\n\n\n\nObjectives\n\n\n\n\n\nThe course aims to equip students with toolkits to — (a) determine if research projects are well-aligned with their interests and aspirations, and (b) prepare for relevant research opportunities.\n\n\n\n\n\n\n\n\n\nOutcome\n\n\n\n\n\nThe participants will be well-positioned to determine if a career in research is for them; and if yes, also to find and pursue relevant research opportunities.\n\n\n\n\n\n\n\n Course materials also available from here.\n\n\n\nTopics\nResources\n\n\n\n\nDay 1: Motivation::Module 1 - Why research?\n[Notes], [Survey], [Youtube], [Slides]\n\n\nDay 2: Motivation::Module 2 - The fundamentals\n[Notes], [Reading: Taking initative], [Youtube], [Slides]\n\n\nDay 3: Mechanics::Module 3 - Skills 1\n[Notes], [Reading: Working with a professor], [Youtube], [Slides]\n\n\nDay 4: Mechanics::Module 4 - Skills 2\n[Notes], [Reading: Writing emails], [Youtube], [Slides]\n\n\nDay 5: Begin journey::Module 5 - Next steps\n[Notes], [Reading: CS PhD application FAQs], [Youtube], [Slides]\n\n\nDay 5: Begin journey::Module 6 - Resources\n[Notes]\n\n\n\n\n\n\n\n\nShare the URL to your webpage.\nIf you do not have a webpage, make a simple one on Github pages. Let the page just have your name: there’s no need to fill it with any content. See the corresponding course webpage for relevant resources to get started with Github pages.\nMention the names and web URLs of 3 professors in India who you think do interesting work. Importantly, for each professor you list, mention in 1-2 sentences why you selected them. This may be informed by your romantic notion of interests in a few areas of CS – that’s okay.\nPick one paper authored by any one professor you listed in (2) that they have published in the last five years. What area of computer science is this paper from?\nWhere was this paper published? Mention the venue and year.\nRead the abstract of this paper and describe in 3-4 sentences your understanding of what the paper achieves. You do not have to read the whole paper. Attempt to just understand broadly what the paper achieves.\nAsk one question about this paper. This may have been answered in the paper—you do not have to read and understand the whole paper to see if they have already answered it. We want you to demonstrate that you have thought about the content of the paper.\nUse CS Rankings to find out the top publishing venues in the area the paper you read belongs to (e.g. databases, machine vision, etc.).\nUsing CS Rankings, find out the best venues in the following fields of computer science:\n\nComputer architecture\nHuman-computer interface\nGraphics and computational geometry\nComputing education\n\nSee this section in Module 6 of our course webpage for a list of popular areas in computer science.\nFor each area listed, we also document a researcher’s journey who specializes in that area.\nWrite out an email to this professor expressing an interest in working on a project related to this paper. Do not send this email to the professor. Just share the draft of this email with us. You can assume you have already done 1-2 relevant projects and courses even if you haven’t–it’s fine to reference these fictitious experiences in your email to make a case for yourself.\n\nSubmit your responses here."
  },
  {
    "objectID": "courses/2022/userbase/index.html",
    "href": "courses/2022/userbase/index.html",
    "title": "191014K02: Randomized Methods for Approximation and Parameterized Algorithms",
    "section": "",
    "text": "Loading…\n\n\n\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nLoading to-dos…"
  },
  {
    "objectID": "courses/2022/04-GIAN/index.html",
    "href": "courses/2022/04-GIAN/index.html",
    "title": "191014K02: Randomized Methods for Approximation and Parameterized Algorithms",
    "section": "",
    "text": "A GIAN Course by Prof Daniel Lokshtanov\n\n\n\n\n\n\n\n\nAbout the Course\n\n\n\n\n\nMost computational problems that model real-world issues are not known to admit efficient algorithms that are provably correct on all inputs. Many of these problems can be reduced to one of the classical problems called NP-complete problems which are unlikely to admit efficient algorithms in practice, and the issue of whether they do is a fundamental open problem in computer science. Although these problems are very unlikely to be solvable efficiently in the immediate future, computer scientists, over the last few decades, have come up with several “workarounds” to “cope” with NP-hardness.\nTwo fundamental approaches in this program include approximation and fixed- parameter tractability. An approximate algorithm is a way of dealing with NP- completeness for optimization problem. This technique does not guarantee the best solution. The goal of an approximation algorithm is to come as close as possible to the optimum value in a reasonable amount of time which is at most polynomial time. On the other hand, parameterized algorithms aim to restrict the exponential blow-up to an identified parameter of the problem, leading to efficient exact algorithms whenever the said parameter is reasonably small. In recent times, there has been substantial research that involves an interplay of techniques from both approaches as well.\nAll paradigms of algorithm design, including efficient polynomial time algorithms as well as the methods of approximation and parameterization discussed above, are substantially more powerful when combined with techniques based on randomness. Carefully employed, randomization leads to approaches that are faster and easier to implement than their deterministic counterparts, making them particularly well-suited to practice.\nOver the last two decades, sophisticated probabilistic techniques have been developed for a broad range of challenging computing applications. To begin with, this course will introduce the basic probabilistic techniques used in the design of randomized algorithms and in probabilistic analysis of algorithms. The course covers the basic probability theory required for working with these techniques and demonstrates their use in various computing applications, especially in the context of parameterized and approximation algorithms.\nThis course will demonstrate the algorithmic techniques in the context of a variety of combinatorial optimization problems that have significant real-world applications. These include: Longest Path, Minimum Cut, Maximum Cut, Clustering, Vertex Cover, Feedback Vertex Set, and Closest String.\n\n\n\n\n\n\n\n\n\nTarget Audience\n\n\n\n\n\nAnyone who is biting their nails from the NP-completeness cliffhanger at the end of their introduction to algorithms will probably enjoy this course. The course is open to students, postdocs, faculty, industry professionals, and anyone who is interested and is confident about the prerequisites enlisted below.\n\n\n\n\n\n\n\n\n\nPrerequisites\n\n\n\n\n\nThis is a theoretical course that will require mathematical maturity (in particular, the ability to understand and write formal mathematical proofs), and some background in the design and analysis of algorithms.\nProbability Prerequisites\nDiscrete probability spaces • Events • Random variables • Independence (of events, of random variables) • Conditional probability • Expectation of random variable. • Linearity of Expectation • Conditional Expectation (of random variable on event, and on another random variable) • Binomial coefficients (Pascal’s Triangle) • Bernoulli, Binomial, Geometric random variables.\nGeneral Prerequsites\nCorrectness proofs for algorithms • Paradigms: Greedy, DP, Divide and Conquer • Big-Oh and asymptotic runtime analysis • Formulating and solving recurrences • P, NP, NP-completeness\nMath Prerequisites\nLinear algebra (Matrices, vectors, rank, basis, linear independence)\n\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\n\n\nThe Design of Approximation Algorithms • David P. Williamson and David B. Shmoys\nParameterized Algorithms • Marek Cygan, Fedor V. Fomin, Lukasz Kowalik, Daniel Lokshtanov, Daniel Marx, Marcin Pilipczuk, Michal Pilipczuk, and Saket Saurabh\nRandomized Algorithms • Motwani and Raghavan\nBeyond the Worst-Case Analysis of Algorithms • Tim Roughgarden\nAlgorithms • Jeff Erickson\n\n\n\n\n\n\n\n\n\n\nLogistics\n\n\n\n\n\n\n5th December 2022: Registration + Coffee: 9AM to 10AM | Outside 1/101\n5th December 2022: Inaugaral Event: 10AM | 1/101\n\nAddress by Prof. Rajat Moona\n(Director, IITGN)\nAddress by Prof. Anirban Dasgupta\n(Discipline Coordinator, Computer Science and Engineering, IITGN and Local GIAN Coordinator for IITGN)\nAddress by Prof. Saket Saurabh\n(Professor, The Institute of Mathematical Sciences)\n\nLectures: Mon - Thu • 11AM — 12:30PM • 2:30PM — 4PM | Fri • 11AM — 12:30PM\nTutorial: Mon - Thu • 4:30PM — 6PM | Fri • 2:30PM — 4PM\nVenue: Mon - Wed: 1/101 • Thu: 7/101 • Fri: 7/102\n\n\n\nZoom links and invitations to a Whatsapp group and Discord server were sent out to all registered participants.\nRegister here.  Registrations are now closed. You can follow along on Youtube if you missed registering!\n\n\n\n\n\n\n\n\n\n\n\nAbout the Instructor: Daniel Lokshtanov\n\n\n\n\n\n\n\n\nDaniel Lokshtanov is a Professor at the Department of Computer Science at the University of California Santa Barbara, before which he was a Professor at the Department of Informatics at the University of Bergen. He received his PhD in Computer Science (2009), from the University of Bergen. He spent two years (2010- 2012) as a Simons Postdoctoral Fellow at University of California at San Diego.\nHis research interests span a wide area of algorithms, and he has made several fundamental contributions in the areas of exact exponential algorithms, parameterized and fine-grained algorithms and approximation algorithms. He has been awarded the Meltzer Prize for Young Researchers for his work at the University of Bergen. He is a recipient of the Bergen Research Foundation young researcher grant and of an ERC starting grant on parameterized algorithms. He is a co-author of two recently published texts — Kernelization (Cambridge University Press, 2019) and Parameterized Algorithms (Springer, 2015).\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecturesTutorialsMemoriesFeedback\n\n\n\n\n\n    \n        Date\n        Lecture\n        Slides\n        Notes\n        Video\n        Recap\n    \n    \n                    \n            \n                05 Dec, 2022\n            \n            \n                1. Introduction\n                Randomized Algorithms  MaxCut  MinCut\n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n        \n                    \n            \n                05 Dec, 2022\n            \n            \n                2. Linear Programs\n                Algorithm: Vertex Cover LP.  2-Approximation by Deterministic Rounding  Algorithm: Set Cover.  Randomized Rounding for O(log n) approximation.\n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n        \n                    \n            \n                06 Dec, 2022\n            \n            \n                3. Vertex Cover and FVS\n                Randomized 2-Approximation algorithm for Vertex Cover, and an exact exponential algorithm algorithm for Vertex Cover  Randomized 4-Approximation algorithm for FVS and an exact exponential algorithm for FVS  Comments on F-Deletion\n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n        \n                    \n            \n                06 Dec, 2022\n            \n            \n                4. Color Coding\n                Color Coding (k-Path)  Chernoff Bounds  Approximate counting of (K-paths)  Chromatic Coding (Feedback Arc Set on Tournaments and d-Clustering)\n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n        \n                    \n            \n                07 Dec, 2022\n            \n            \n                5. Closest String and Max Cut\n                (1+eps) approximation for Closest String by Randomized Rounding and Local SearchMax Cut on Dense Graphs\n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n        \n                    \n            \n                07 Dec, 2022\n            \n            \n                6. Max Cut and SDP\n                Max Cut on Dense Graphs (continued)  Introduction to Semi-Definite Programs  0.87 approximation for Max Cut on General Graphs \n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n        \n                    \n            \n                08 Dec, 2022\n            \n            \n                7. Algebraic Techniques\n                Isolation Lemma  Cut and Count\n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n        \n                    \n            \n                08 Dec, 2022\n            \n            \n                8. Derandomization\n                Method of Conditional Expectation  Splitters\n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n        \n                    \n            \n                09 Dec, 2022\n            \n            \n                9. Glimpses of Exact Algorithms\n                1.333^n algorithm for 3-SAT  2-approximation for Tournament Feedback Vertex Set\n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n    \n    \n                    \n            \n                05 Dec, 2022\n            \n            \n                Tutorial 1\n                \n            \n            \n                    \n                \n            \n                    \n                \n        \n                    \n            \n                06 Dec, 2022\n            \n            \n                Tutorial 2\n                \n            \n            \n                    \n                \n            \n                    \n                \n        \n                    \n            \n                07 Dec, 2022\n            \n            \n                Tutorial 3\n                \n            \n            \n                    \n                \n            \n                    \n                \n        \n                    \n            \n                08 Dec, 2022\n            \n            \n                Tutorial 4\n                \n            \n            \n                    \n                \n            \n                    \n                \n        \n                    \n            \n                09 Dec, 2022\n            \n            \n                Tutorial 5\n                \n            \n            \n                    \n                \n            \n                    \n                \n        \n\n\n\nNo matching items"
  },
  {
    "objectID": "courses/2022/04-GIAN/notes/D4L1/index.html",
    "href": "courses/2022/04-GIAN/notes/D4L1/index.html",
    "title": "191014K02 | Day 4 Lecture 1",
    "section": "",
    "text": "Back to the Course Page\n\n\nHere’s our key tool for the day!\n\n\n\n\n\n\nIsolation Lemma\n\n\n\nLet U be a universe with |U|=n and let \\cal F be a family of sets over U. Pick a random weight function w: U \\rightarrow\\{1, \\cdots ,W\\}. Then:\n\\operatorname{Pr}[{\\color{indianred}\\cal F \\text{ has a \\textbf{unique} min weight set}}] \\geqslant \\frac{n}{W}\n\n\nCall an element u critical if:\n\nu is in some minimum weight set, and\nif w(u) is increased by 1 then u is no longer in any minimum weight set."
  },
  {
    "objectID": "courses/2022/04-GIAN/notes/D2L2/index.html",
    "href": "courses/2022/04-GIAN/notes/D2L2/index.html",
    "title": "191014K02 | Day 2 Lecture 2",
    "section": "",
    "text": "Back to the Course Page\n Work in progress.\n\nA simple path in a graph is a sequence of distinct vertices u_1, \\ldots, u_\\ell such that all consecutive vertices have an edge between them. We are going to talk about the problem of finding long paths in graphs:\n\n\n\n\n\n\nk-Path\n\n\n\nDoes G have a simple path on k vertices?\n\n\nThis problem is “of course”1 NP-complete.\n\nWhat is the probability that a random coloring with k colors makes a fixed k-path “multicolored”? It’s \\frac{k!}{k^k}, and we claim that this is at least \\frac{1}{e^k}.\n\n\n\n\n\n\nLower bound on the probability of the good event\n\n\n\nClaim 1. \\frac{k!}{k^k} \\geqslant \\frac{1}{e^k}\n\n\n\n\n\n\n\n\nProof by induction:\n\n\n\n\n\n\\begin{aligned}\n\\frac{k^k}{k !} & = \\underbrace{{\\color{indianred}\\frac{(k-1)^{k-1}}{(k-1) !} \\cdot \\frac{(k-1) !}{(k-1)^{k-1}}}}_{1} \\cdot \\frac{k^k}{k!} \\\\\n& ~ \\\\\n& = \\underbrace{{\\color{darkseagreen}\\frac{(k-1)^{k-1}}{(k-1) !}}}_{\\text{Induction Hypothesis}} \\cdot \\frac{(k-1) !}{(k-1)^{k-1}} \\cdot \\frac{k^k}{k!} \\\\\n& \\leqslant {\\color{darkseagreen}e^{k-1}} \\cdot \\frac{(k-1)!}{(k-1)^{k-1}} \\cdot \\frac{k^k}{k!} \\\\\n& ~ \\\\\n& \\leqslant e^{k-1} \\cdot \\frac{{\\color{olivedrab}(k-1)!}}{(k-1)^{k-1}} \\cdot \\frac{{\\color{palevioletred}k^k}}{{\\color{olivedrab}k!}} \\\\\n& \\leqslant e^{k-1} \\cdot {\\color{olivedrab}\\frac{1}{k}} \\cdot \\frac{{\\color{palevioletred}k^{k-1}}}{(k-1)^{k-1}} \\cdot {\\color{palevioletred}k} \\\\\n& \\leqslant e^{k-1} \\cdot \\frac{1}{{\\color{indianred}k}} \\cdot \\frac{k^{k-1}}{(k-1)^{k-1}} \\cdot {\\color{indianred}k} \\\\\n& \\leqslant e^{k-1} \\cdot \\frac{k^{k-1}}{(k-1)^{k-1}} \\\\\n& ~ \\\\\n& =e^{k-1} \\cdot {\\color{darkseagreen}\\left(1+\\frac{1}{k-1}\\right)^{k-1}}\\\\\n& \\leqslant e^{k-1} \\cdot {\\color{darkseagreen}e}\\\\\n& =e^k\n\\end{aligned}\n\n\n\n\n\nThe useful way to recall what the Chernoff bound tells us is the following: for independent 0/1 random variables, the probability that X deviates from its expectation by a large amount is extremely small.\n\n\n\n\n\n\nChernoff Bound (informal)\n\n\n\nIf X is the sum of many independent random variables with “small” values, then X is very very likely to be very close to E[X].\n\n\nThe following is the precise statment:\n\n\n\n\n\n\nChernoff Bound: the Theorem.\n\n\n\nLet X= X_1 + X_2 \\cdots+ X_n where:\n\nthe X_i’s take values from \\{0,1\\}, and\nthe X_i’s is are independent,\n\nthen \\operatorname{Pr}[{\\color{indianred}|X-E[X]| \\geqslant \\varepsilon E[X]}] \\leqslant 2e^{-\\varepsilon^2 \\cdot E[X]/3}\n\n\nAnd here is a useful variation, handy for when you don’t know the expectation, but have upper and lower bounds on it.\n\n\n\n\n\n\nChernoff Bound: a Useful Variation\n\n\n\nThe: Let X= X_1 + X_2 \\ldots+ X_n where:\n\nthe X_i’s take values from \\{0,1\\}\nthe X_i’s are independent\n\nLet \\mu_L \\leqslant E[X] \\leqslant \\mu_H\nThen: \n\\begin{aligned}\n& \\operatorname{Pr}\\left[x-\\mu_H \\geqslant \\varepsilon \\mu_H\\right] \\leqslant e^{-\\varepsilon^2 \\cdot \\mu_H / 3} \\\\\n& \\operatorname{Pr}\\left[\\mu_L-x \\geqslant \\varepsilon \\mu_L\\right] \\leqslant e^{-\\varepsilon^2 \\cdot \\mu_L / 3}\n\\end{aligned}"
  },
  {
    "objectID": "courses/2022/04-GIAN/notes/D1L2/index.html",
    "href": "courses/2022/04-GIAN/notes/D1L2/index.html",
    "title": "191014K02 | Day 1 Lecture 2",
    "section": "",
    "text": "Back to the Course Page\n\n\n\nAn integer linear program involves n variables x_1, x_2, \\ldots, x_n \\in \\mathbb{Z} and a linear objective function to be optimized.\nIn particular, we would like to minimize or maximize a function that looks like: \\sum_{i = 1}^n {\\color{indianred}c_i} x_i,\nsubject to m linear inequalities:\n\\begin{aligned}\na_1^1 x_1+a_2^1 x_2+ \\cdots + a_i^1 x_i + \\cdots+a_n^1 x_n & \\leqslant b_1 \\\\\na_1^2 x_1+a_2^2 x_2+ \\cdots + a_i^2 x_i + \\cdots+a_n^2 x_n & \\leqslant b_2 \\\\\n\\vdots & \\\\\na_1^j x_1+a_2^j x_2+ \\cdots + a_i^j x_i + \\cdots+a_n^3 x_n & \\leqslant b_j\\\\\n\\vdots & \\\\\na_1^m x_1+a_2^m x_2+ \\cdots + a_i^m x_i + \\cdots+a_n^m x_n & \\leqslant b_m.\n\\end{aligned}\nHere {\\color{indianred}c_1,\\cdots,c_n} are some constants in \\mathbb{Z} or \\mathbb{Q}\nSo given the a_i^j’s as input (1 \\leqslant i \\leqslant n; 1 \\leqslant j \\leqslant m), the goal is to set the x_i’s such that:\n\nall the inequalities are satisfied, and\nthe objective function is optimized1."
  },
  {
    "objectID": "courses/2022/04-GIAN/notes/D3L1/index.html",
    "href": "courses/2022/04-GIAN/notes/D3L1/index.html",
    "title": "191014K02 | Day 3 Lecture 1",
    "section": "",
    "text": "Back to the Course Page\n Work in progress.\n\n\n\nFor two strings s_1, s_2 of the same length \\ell, we define the Hamming Distance between S_1 & S_2 to be:\nd\\left(S_1, S_2\\right):=\\left|\\left\\{i: S_1[i] \\neq S_2[i]\\right\\}\\right|\nso, for example, d(horse, force) =2.\nFor a string c and set S of stings of length \\ell:\nd(S, c):=\\max _{t \\in S} d(t,c)\n\n\n\n\n\n\nClosest String [Optimization]\n\n\n\nInput: n strings of length \\ell over an alphabet \\Sigma1\nTask: Find center sting c lot length \\ell such that d(S, c) is minimized\n\n\nGOAL: (1+\\varepsilon) Approximation Algorithm\n\n\nHave an indicator variable for every position p and every letter \\alpha \\in \\Sigma, introduce a binary variable x_{p,\\alpha} with the following semantics:\n\\begin{equation*}\n    x_{p,\\alpha} =\n    \\begin{cases}\n      1 & \\text{if } c[p] = \\alpha\\\\\n      0 & \\text{otherwise.}\n    \\end{cases}\n\\end{equation*}\nThe constraints:\n\nAt every position we have one letter:\n\n\\forall p \\in [\\ell]: \\sum_{\\alpha \\in \\Sigma} x_{p,\\alpha} = 1\n\nWe control the distance:\n\\forall t \\in S: \\quad \\sum_{p=1}^\\ell \\left({\\color{indianred}1-x_{p, t[p]}} \\right) \\leqslant d\n…and ask the ILP to minimize d.\n\n\n\n\n\n\n\nThe distance constraint\n\n\n\n\n\nNote that:\n\\begin{equation*}\n    1 - x_{i,s[i]} =\n    \\begin{cases}\n      0 & \\text{if the solution matches with } s[i] \\text{at location } p,\\\\\n      1 & \\text{otherwise.}\n    \\end{cases}\n\\end{equation*}\n\n\n\nNow, as usual, relax the ILP and solve the associated LP.\nRounding. Think of the OPTLP variable values as “voting” for characters at each position. For example, if \\ell = 5, \\Sigma = \\{A,C,G,T\\}, and the OPTLP values turn out to be:\n\n\n\n\nA\nC\nG\nT\n\n\n\n\n1\n0.9\n0\n0.05\n0.05\n\n\n2\n0.1\n0.2\n0.4\n0.3\n\n\n3\n0.5\n0.1\n0.1\n0.3\n\n\n4\n0.1\n0.7\n0.1\n0.1\n\n\n5\n0.2\n0.2\n0\n0.6\n\n\n\nThen you might be tempted to “round” the solution to AGACT because for each position p \\in [5], the letters A, G, A, C, and T dominate the vote for that position. However: it turns out that this nautral rounding strategy can be arbitrarily bad!\nInstead of picking the top choice, what we do instead is the following: for every position p \\in [\\ell], treat the x_{p,\\alpha}’s as a probability distribution2 over \\Sigma. Now the randomized rounding step involves sampling from this distribution to obtain the solution:\n\nSet c[p] = \\alpha with probability x_{p,\\alpha}.\n\nDefine the indicator random variables q_{p,\\alpha} as indicating for us when c is different from \\alpha at position p, as a stepping stone to capturing distance eventually:\n\\begin{equation*}\n    q_{p,\\alpha} =\n    \\begin{cases}\n      1 & \\text{if } {\\color{indianred}c[p] \\neq \\alpha},\\\\\n      0 & \\text{otherwise}.\n    \\end{cases}\n\\end{equation*}\nThen we have the natural notion of a random variable to capture the distance between the string output by our randomized algorithm and any fixed string t \\in S:\nd[c,t] := \\sum_{p \\in \\ell} q_{p,t[p]}\nIt’s time for our first cool claim.\nFix a t \\in S. What is E[d(c,t)]?\nIt turns out: at most d, and therefore, at most OPTLP, and in turn, at most OPTILP = OPT \n\n\n\n\n\n\nCalculating the Expectation\n\n\n\n\n\n\\begin{aligned}\nE[d(c,t)] & = \\sum_{p \\in [\\ell]} 1 \\cdot {\\color{indianred}\\operatorname{Pr}[c[p] \\neq t[p]]} + 0 \\cdot \\operatorname{Pr}[c[p] \\neq t[p]] \\\\\n& = \\sum_{p \\in [\\ell]} 1 \\cdot \\left({\\color{indianred}1 - x_{p,t[p]}}\\right) \\\\\n& {\\color{darkseagreen}\\leqslant d},\n\\end{aligned}\nwhere the last inequality follows from the second LP constraint.\n\n\n\nNote that d(c,t) is a sum of independent 0/1 random variables whose expectation is upper bounded by OPT. So our useful Chernoff variation applies here,\n\n\n\n\n\n\nChernoff Bound: a Useful Variation (recall)\n\n\n\n\n\nThe: Let X= X_1 + X_2 \\ldots+ X_n where:\n\nthe X_i’s take values from \\{0,1\\}\nthe X_i’s are independent\n\nLet \\mu_L \\leqslant E[X] \\leqslant \\mu_H\nThen: \n\\begin{aligned}\n& \\operatorname{Pr}\\left[x-\\mu_H \\geqslant \\varepsilon \\mu_H\\right] \\leqslant e^{-\\varepsilon^2 \\cdot \\mu_H / 3} \\\\\n& \\operatorname{Pr}\\left[\\mu_L-x \\geqslant \\varepsilon \\mu_L\\right] \\leqslant e^{-\\varepsilon^2 \\cdot \\mu_L / 3}\n\\end{aligned}\n\n\n\n\nand we get the following:\n\n\\operatorname{Pr}[d(c,t)-\\text{OPT} > \\varepsilon \\cdot \\text{OPT}] \\leqslant e^{-\\varepsilon^2 \\text{OPT} / 3}.\n\nNow, applying union bound over all n choices of t \\in S, we get:\n\n\\operatorname{Pr}[{\\color{darkseagreen}d(c,S)} > (1+\\varepsilon) \\cdot \\text{OPT}] \\leqslant \\frac{{\\color{darkseagreen}n}}{e^{\\varepsilon^2 \\text{OPT} / 3}}.\n\nSo, if, for example:\n\\frac{n}{e^{\\varepsilon^2 \\text{OPT} / 3}} \\leqslant \\frac{1}{2},\nthen it’s a win! \n\n\n\n\n\n\nWhat’s the bad situation?\n\n\n\n\n\n\\begin{aligned}\n\\frac{1}{2} & \\leqslant \\frac{n}{e^{\\varepsilon^2 \\text{OPT} / 3}}\\\\\n& ~ \\\\\ne^{\\varepsilon^2 \\text{OPT} / 3} & \\leqslant 2n \\\\\n& ~ \\\\\n\\frac{\\varepsilon^2 \\text{OPT}}{3} & \\leqslant \\ln(2n) \\\\\n& ~ \\\\\n{\\color{indianred}\\text{OPT}} & {\\color{indianred}\\leqslant \\frac{3\\ln(2n)}{\\varepsilon^2}}\n\\end{aligned}\n\n\n\nWe don’t have a win when OPT is really really small, in particular, if:\n\\text{OPT} \\leqslant \\frac{3\\ln(2n)}{\\varepsilon^2}\nWe handle this case with a local search algorithm.\nComing Soon."
  },
  {
    "objectID": "courses/2022/04-GIAN/notes/D4L2/index.html",
    "href": "courses/2022/04-GIAN/notes/D4L2/index.html",
    "title": "191014K02 | Day 4 Lecture 2",
    "section": "",
    "text": "Back to the Course Page\nComing Soon."
  },
  {
    "objectID": "courses/2022/04-GIAN/notes/D2L1/index.html",
    "href": "courses/2022/04-GIAN/notes/D2L1/index.html",
    "title": "191014K02 | Day 2 Lecture 1",
    "section": "",
    "text": "Back to the Course Page\n\n\n\n\n\n\n\n\nVertex Cover [Optimization]\n\n\n\nInput: A graph G = (V,E).\nTask: Find S \\subseteq V(G) such that for all edges (u,v) \\in E(G), \\{u,v\\} \\cap S \\neq \\varnothing and minimize |S|.\n\n\n\n\n\n\n\n\nVertex Cover [Decision Version Edition]\n\n\n\nInput: A graph G = (V,E) and k \\in \\mathbb{Z}^+.\nTask: Find S \\subseteq V(G) such that for all edges (u,v) \\in E(G), \\{u,v\\} \\cap S \\neq \\varnothing and |S| \\leqslant k.\n\n\nThe naive algorithm by brute force — examining all possible subsets — is O(n^k \\cdot m) in damages. Can we do better?\nThe answer turns out to be yes: we can improve from O(n^k \\cdot m) to deterministic 2^k \\cdot n^{O(1)} time, which is fixed-parameter tractable in k.\nHaving said that, we will begin with a very elegant randomized algorithm for Vertex Cover, which essentially picks an edge at random and then, one of its endpoints at random, for as long as it can.\n\n\n\n\n\n\nCute randomized algorithm ALG\n\n\n\nS=\\varnothing\nwhile G-S has at least one edge:\n\npick u,v \\in E(G-S) u.a.r.\npick s \\in\\{u,v\\} u.a.r\nSet S \\leftarrow S \\cup\\{s\\}\n\nOutput S\n\n\nHere are few claims about cute algorithm:\n\nALG always runs in polynomial1 time.\nS is always a vertex cover.\n\\operatorname{Pr}[S is an optimal vertex cover] \\geqslant 1/2^k. \n\nThe first two claims follow quite directly from the operations of the algorithm and the definition of a vertex cover.\nWhat about the third? Well: let OPT be some fixed optimal vertex cover. Suppose |OPT| \\leqslant k. Initially, note that S \\subseteq OPT. In each round, \\operatorname{Pr}[s \\in S] \\geqslant 1/2, since S \\cap \\{u,v\\} \\neq \\varnothing by definition. If s \\in OPT in every round of the algorithm, then S = OPT, which is awesome: and said awesomeness manifests with probability 1/2^k.\nBonus: repeat the algorithm and retain the smallest solution to get an overall constant success probability:\n1-\\left(1-\\frac{1}{2^k}\\right)^{2^k} \\geqslant 1-1 / e.\nApproximation. Do we expect ALG to be a reasonable approximation? It turns out: yes! \nIn particular: we will show that the size of the vertex cover output by ALG is at most twice |OPT| in expectation.\nFor a graph G, define X_G to be the radom variable returning the size of the set S output by the algorithm.\nFor integers k,n define: \nX_{n,k}=\\max_G E[X_G],\n\nwhere the \\max is taken over all graphs with \\leqslant n vertices2 and vertex cover of size \\leqslant k.\nNow let’s analyze the number X_{n,k}. Let G^\\star be the “worst-case graph” that bears witness to the \\max in the definition of X_{n,k}. Run the first step of ALG on G^\\star. Suppose we choose to pick {\\color{indianred}s} in this step. \n\\begin{aligned}\nX_{n,k}=E[X_{G^\\star}] & = {\\color{indianred}1}+\\left(\\frac{1}{2}+\\varepsilon \\right) E\\left[{\\color{darkseagreen}X_{G^\\star-s} \\mid s \\in \\text{OPT}}\\right]+\\left(\\frac{1}{2} - \\varepsilon\\right) E\\left[{\\color{palevioletred}X_{G^\\star-s} \\mid s \\notin \\text {OPT}}\\right] \\\\\n& = 1 + \\left(\\frac{1}{2} + \\varepsilon \\right){\\color{darkseagreen}X_{n, k-1}}+ \\left(\\frac{1}{2} - \\varepsilon \\right){\\color{palevioletred}X_{n-1, k}}\\\\\n& \\leqslant 1 + \\left(\\frac{1}{2} + \\varepsilon \\right){\\color{darkseagreen}X_{n, k-1}}+ \\left(\\frac{1}{2} - \\varepsilon \\right){\\color{dodgerblue}X_{n, k}}\\\\\n& = 1 + \\frac{1}{2} X_{n, k-1} + \\varepsilon \\cdot X_{n, k-1} + \\frac{1}{2} X_{n, k} - \\varepsilon X_{n, k}\\\\\n& \\leqslant 1 + \\frac{1}{2} X_{n, k-1} + \\varepsilon \\cdot {\\color{dodgerblue}X_{n, k}} + \\frac{1}{2} X_{n, k} - \\varepsilon X_{n, k}\\\\\n& = 1 + \\frac{1}{2} X_{n, k-1} + {\\color{indianred}\\varepsilon \\cdot X_{n, k}} + \\frac{1}{2} X_{n, k} - {\\color{indianred}\\varepsilon X_{n, k}}\\\\\n& = 1 + \\frac{1}{2} X_{n, k-1} + \\frac{1}{2} X_{n, k}\n\\end{aligned}\n\nNote that:\n\n X_{n,k} \\geqslant X_{n-1,k} and X_{n,k} \\geqslant X_{n,k-1}.\n\\operatorname{Pr}[s \\in \\text{OPT}] \\geqslant \\frac{1}{2}, in particular we let \\operatorname{Pr}[s \\in \\text{OPT}] = \\frac{1}{2} + \\varepsilon.\n\\operatorname{Pr}[s \\notin \\text{OPT}] = 1 - \\operatorname{Pr}[s \\in \\text{OPT}] = \\frac{1}{2} - \\varepsilon.\n {\\color{darkseagreen}G^\\star-s} is a graph on at most {\\color{darkseagreen}n} vertices with a vertex cover of size {\\color{darkseagreen}\\leqslant k-1}\n {\\color{palevioletred}G^\\star-s} is a graph on at most {\\color{palevioletred}n} vertices with a vertex cover of size {\\color{palevioletred}\\leqslant k}\n\nRearranging terms, we get:\n\\frac{1}{2} X_{n,k} \\leqslant 1 + \\frac{1}{2} X_{n,k-1} \\equiv X_{n,k} \\leqslant 2 + X_{n,k-1}\nExpanding the recurrence, we have: X_{n,k} \\leqslant 2k, as claimed earlier.\n\n\n\nNow we turn to a problem similar to vertex cover, except that we are “killing cycles” instead of “killing edges”.\n\n\n\n\n\n\nFeedback Vertex Set\n\n\n\nInput: A (multi-)3graph G = (V,E).\nTask: Find S \\subseteq V(G) such that G \\setminus S is a forest4, and minimize |S|.\n\n\nIf we try to mimic the cute algorithm from before, we might easily be in trouble: note that the driving observation — that an edge has at least one of its endpoints in the solution with a reasonable enough probability — can fail spectacularly for FVS:\n\n\n\nAn example showing that for “most edges”, both endpoints do not belong to an optimal solution.\n\n\nOne thing about this example is the large number of pendant vertices sticking out prominently, and these clearly contribute to the badness of the situation. Happily, it turns out that we can get rid of these:\n\n\n\n\n\n\nLemma 1. Delete pendant and isolated vertices\n\n\n\nLet G be a multi-graph and v be a vertex of degree \\leqslant 1. Then:\n\nMinFVS of G-\\{v\\} \\leqslant MinFVS of G\n\\forall S \\subseteq V(G)-\\{v\\}:  S is an FVS for G  \\leftrightarrow S is an FVS for G \\setminus \\{v\\} \n\n\n\nConsider graphs with no pendant vertices and fix an optimal FVS S. Is it true that a reasonable fraction of edges are guaranteed to be incident to S? Well… not yet:\n\n\n\n\n\n\nSpoiler\n\n\n\n\n\n\n\n\nAn(other) example showing that for “most edges”, both endpoints do not belong to an optimal solution, even though the graph has no pendant vertices.\n\n\n\n\n\nHowever, continuing our approach of conquering-by-observing-patterns-in-counterexamples, note that the example above has an abundance of vertices that have degree two. Can we get rid of them? Well, isolated and pendant vertices were relatively easy because they don’t even belong to cycles, but that is not quite true for vertices of degree two. Can we still hope to shake them off?\nOne thing about a degree two vertex u is that if there is a cycle that contains u it must contain both its neighbors5. So you might suggest that we can ditch u and just work with its neighbors instead. This intuition, it turns out, can indeed be formalized:\n\n\n\n\n\n\nLemma 2. Short-Circuiting Degree Two Vertices\n\n\n\nLet:\n\nG be a multi-graph,\nu be a vertex of degree 2 that is not a self-loop,\na and b be the neighbors of u (a=b is possible).\n\nLet H be the graph obtained by adding an edge (a,b) to G-\\{u\\}.\nThen:\n\nevery FVS S of G such that u \\notin S is an FVS of H, and\nevery FVS S of H is an FVS of G.\n\n\n\n\n\n\nIllustrating Lemma 2 scenarios.\n\n\nLet us also get rid of self-loops (because we can):\n\n\n\n\n\n\nLemma 3. Removing self-loops\n\n\n\nIf G has a vertex v with a self loop then\n\nEvery FVS S of G contains v\nFor every S containing v: S is an FVS of G \\leftrightarrow S-v is an FVS of G-\\{v\\}\n\n\n\nNow let’s apply Lemmas 1—3 exhaustively, which is to say we keep applying them until none of them are applicable (as opposed to applying them until we feel exhausted  ). Once we are truly stuck, we have a graph H that is: (a) a graph whose minimum degree is three; and (b) equivalent to the original G in the sense that any minimum FVS for H can be extended to a minimum FVS of G by some time travel: just play back the applications of Lemmas 1—3 in reverse order.\nRecall that all this work was to serve our hope for having a cute algorithm for FVS as well. Let’s check in on how we are doing on that front: consider graphs whose minimum degree is three and fix an optimal FVS S. Is it true that a reasonable fraction of edges are guaranteed to be incident to S? Or can we come up with examples to demonstrate otherwise?\nThis is a good place to pause and ponder: play around with examples to see if you can come up with bad cases as before. If you find yourself struggling, it would be for a good reason: we actually now do have the property we were after! Here’s the main claim that we want to make.\n\n\n\n\n\n\nKey Lemma\n\n\n\nLet:\n\nG be a multigraph with no self loops and minimum degree \\geqslant 3,\nS be an FVS of G,\n(u,v) be a random edge in E(G).\n\nThen:\n\\operatorname{Pr}[{\\color{indianred}\\{u, v\\} \\cap S \\neq \\varnothing}] \\geqslant 1/2\n\n\nWe argue this as follows: call an edge good if it has at least one of its endpoints in S, and bad otherwise.\nWe will demonstrate that the number of good edges is at least the number of bad edges: this implies the desired claim.\n\nThe bad edges. Let X := G \\setminus S. The bad edges are precisely E(G[X]).\nThe good edges. Every edge that has one of its endpoints in X and the other in S is a good edge. Recall that G has minimum degree three, because of which:\n\nfor every leaf in G[X], we have at least two good edges, and\nfor vertex that is degree two in G[X], we have at least one good edge.\n\n\nSo at this point, it is enough to show that twice the number of leaves and degree two vertices is at least |E(G[X])| = |X|-1. But this is quite intuitive if we simple stare at the following mildly stronger claim:\n2 \\cdot (\\text{\\# leaves}) + \\text{\\# deg-} 2 \\text{vertices} \\geqslant |X|\nwhich is equivalent to:\n2 \\cdot ({\\color{darkseagreen}\\text{\\# leaves}}) + {\\color{palevioletred}\\text{\\# deg-}2 \\text{vertices}} \\geqslant ({\\color{darkseagreen}\\text{\\# leaves}}) + {\\color{palevioletred}\\text{\\# deg-}2 \\text{ vertices}} + \\text{\\# deg-}(\\geqslant 3) \\text{ vertices}.\nAfter cancelations, we have:\n(\\text{\\# leaves}) \\geqslant \\text{\\# deg-}(\\geqslant 3) \\text{ vertices}.\nNote that this is true! Intuitively, the inequality is suggesting every branching vertex in a tree pays for at least one leaf — this can be formalized by induction on n.\n\n\n\n\n\n\nInduction proof sketch\n\n\n\n\n\nDenote the tree by G and remove a leaf u to obtain H. Apply the induction hypothesis on H.\n\nIf the neighbor of u in G is a degree two vertex, then the number of leaves and high degree vertices are the same in G and H, so the claim follows directly.\nIf the degree of the neighbor in u is three in G, then both quantities in the inequality for H increase by one when we transition from H to G.\nIn the only remaining case, the quantity on the left increases by one when we come to G, which bodes well for the inequality. \n\n\n\n\nAll this was leading up to cute randomized algorithm v2.0 — i.e, adapted for FVS as follows:\n\n\n\n\n\n\nCute randomized algorithm redux\n\n\n\nALG(G)\nPreprocess:\n\nif G is acyclic return \\varnothing\nif \\exists a self loop v RETURN (ALG(G \\setminus \\{v\\})) \\cup \\{v\\}.\nif \\exists a degree one vertex v RETURN ALG(G-\\{v\\}).\nif \\exists a degree two vertex v RETURN ALG(G/\\{v\\}) (c.f. Lemma 2).\n\n\nMindeg-3 instance:\n\npick an edge (u,v) \\in E(G) u.a.r.\npick s \\in \\{u,v\\} u.a.r.\nRETURN (ALG(G \\setminus \\{s\\})) \\cup \\{s\\}\n\n\n\n\n\n\n\n\n\nClaim 1\n\n\n\nALG always returns a FVS of G.\n\n\nThis follows from Lemmas 1—3 and induction on n.\n\n\n\n\n\n\nClaim 2\n\n\n\nIf G has a FVS of size k, then \\operatorname{Pr}[ALG returns an optimal FVS] \\geqslant 1/4^k.\n\n\nThis follows from Lemmas 1—3, the key lemma, and induction on n.\n\n\n\nComing Soon."
  },
  {
    "objectID": "courses/2022/04-GIAN/notes/D5L1/index.html",
    "href": "courses/2022/04-GIAN/notes/D5L1/index.html",
    "title": "191014K02 | Day 5 Lecture 1",
    "section": "",
    "text": "Back to the Course Page\n Work in progress.\n\n\n\n\n\n\n\nTournament Feedback Vertex Set (TFVS)\n\n\n\nInput: A tournament T, w: V(T) \\rightarrow \\mathbb{N}.\nTask: Find S \\subseteq V(T) s.t T - S is acyclic & {\\color{indianred}w(S):=\\sum_{\\sigma \\in S} w(v)} is minimized.\n\n\nSuppose:\n\n|\\text{OPT}| \\geqslant n \\cdot 0.6"
  },
  {
    "objectID": "courses/2022/04-GIAN/notes/D1L1/index.html",
    "href": "courses/2022/04-GIAN/notes/D1L1/index.html",
    "title": "191014K02 | Day 1 Lecture 1",
    "section": "",
    "text": "Back to the Course Page\nComing Soon."
  },
  {
    "objectID": "courses/2022/04-GIAN/notes/D3L2/index.html",
    "href": "courses/2022/04-GIAN/notes/D3L2/index.html",
    "title": "191014K02 | Day 3 Lecture 2",
    "section": "",
    "text": "Back to the Course Page\nComing Soon."
  },
  {
    "objectID": "courses/2022/04-GIAN/tutorials/D2Q/index.html",
    "href": "courses/2022/04-GIAN/tutorials/D2Q/index.html",
    "title": "191014K02 | Day 1 Lecture 1",
    "section": "",
    "text": "Back to the Course Page\n\n\n\n\n\n\n\n\n\nSubgraph Isomorphism\n\n\n\nThe input is an n-vertex graph G and a k-vertex graph H, and the objective is to test whether there exists a subgraph \\widehat{H} of G such that H is isomorphic to \\widehat{H}.\nObserve that k-Path (discussed in class earlier today) is a special case of Subgraph Isomorphism where H is a path on k vertices. The problem of finding a Clique on k vertices is a special case of Subgraph Isomorphism as well, where H is a clique on k vertices. It is believed that Clique is not FPT, and, consequently, we do not expect that the general Subgraph Isomorphism problem to be FPT when parameterized by k.\n\n\n\n\n\n\n\n\nHoeffding’s Inequality\n\n\n\nLet X_1, \\ldots, X_n be independent random variables such that a_i \\leq X_i \\leq b_i almost surely. Consider the sum of these random variables, \nS_n=X_1+\\cdots+X_n .\n Then Hoeffding’s theorem states that, for all t>0, \n\\begin{gathered}\n\\mathrm{P}\\left(S_n-\\mathrm{E}\\left[S_n\\right] \\geq t\\right) \\leq \\exp \\left(-\\frac{2 t^2}{\\sum_{i=1}^n\\left(b_i-a_i\\right)^2}\\right) \\\\\n\\mathrm{P}\\left(\\left|S_n-\\mathrm{E}\\left[S_n\\right]\\right| \\geq t\\right) \\leq 2 \\exp \\left(-\\frac{2 t^2}{\\sum_{i=1}^n\\left(b_i-a_i\\right)^2}\\right)\n\\end{gathered}\n\nHere \\mathrm{E}\\left[S_{\\mathrm{n}}\\right] is the expected value of S_n.\n\n\n\n\n\n\nShow that the number of inclusion minimal vertex covers of size at most k is at most 2^k. (Use the algorithm from class.)\nGeneralize the Vertex Cover algorithm that we saw today to Set Cover in which every element appears in at most d sets.\nFeedback Vertex Set as Hitting Set. Why don’t we get a O(\\log n) approximation for FVS via the O(\\log n) approximation for Set Cover1?\nUse Markov inequality to show that: \n\\operatorname{Pr}[{\\color{indianred}|S| \\leqslant 2 \\cdot |\\text{OPT}|}] \\geqslant \\Omega(1 /|\\text{OPT}|)\n\nCome up with an algorithm to solve an instance of subgraph isomorphism (G, H) in time 2^{d k} k ! n^{\\mathcal{O}(1)} and in time 2^{d k} k^{\\mathcal{O}(d \\log d)} n^{\\mathcal{O}(1)}. Here, |V(G)|=n,|V(H)|=k, and the maximum degree of G is bounded by d.\nGeneralize the color coding approach for Longest Path to: (a) k-Cycle where H is a cycle on k vertices, (b) Tree Subgraph Isomorphism, where H is restricted to being a tree on k vertices.\nDesign a randomized algorithm running in time 2^{O\\left(\\sqrt{k} \\log ^2 k\\right)}+n^{O(1)} for the problem of finding a feedback arc set of size at most k in a tournament on n vertices."
  },
  {
    "objectID": "courses/2022/04-GIAN/tutorials/D1Q/index.html",
    "href": "courses/2022/04-GIAN/tutorials/D1Q/index.html",
    "title": "191014K02 | Day 1 Lecture 1",
    "section": "",
    "text": "Back to the Course Page\n\n\n\n\n\n\n\n\n\nc-approximate mincut\n\n\n\nA c-approximate mincut is a set of at most cr edges if r is the number of edges in a mincut.\n\n\n\n\n\n\n\n\nmin k-way cut\n\n\n\nA minimum k-cut is a smallest set of edges whose removal would partition the graph to at least k connected components\n\n\n\n\n\n\n\n\nG(n,p) graphs\n\n\n\nThe G(n, p) model, due to Erdös and Rényi, has two parameters, n and p. Here n is the number of vertices of the graph and p is the edge probability. For each pair of distinct vertices, v and w, p is the probability that the edge (v, w) is present. The presence of each edge is statistically independent of all other edges. The graph-valued random variable with these parameters is denoted by G(n, p). When we refer to “the graph G(n, p)”, we mean one realization of the random variable.\n\n\n\n\n\n\nGeneralize the mincut argument to c-approximate mincuts.\nGeneralize the mincut argument to min k-way cut.\nProve #min k-cuts is at most n^{O(k)}.\nShow that G(n, 1/2) graphs have:\n\nmany cliques of size 2 \\log n-o(\\log n) in expectation, and\nno cliques of size 2 \\log n+o(\\log n) in expectation (and with high probability).\n\nConsider the following algorithm for finding a minimum cut. Assign a random score to each edge, and compute a minimum spanning tree. Removing the heaviest edge in the tree breaks it into two pieces. Argue that with probability \\omega(1/n^2), those pieces will be the two sides of a minimum cut. Hint: relate this algorithm to the contraction algorithm we did in the class. Also think about Kruskal’s algorithm.\nShow that for every n \\geq 4, there is a simple graph G_n on n vertices that has at least {n \\choose 2} distinct minimum cuts.\nShow that for every n \\geq 3, there is a simple graph G_n on n vertices such that the value of ILPOPT of the vertex cover ILP associated with G_n is at least one less than twice the value of LPOPT of the vertex cover LP associated with G_n, i.e:\n\n\\text{ILPOPT}(G_n) \\geq 2\\cdot \\text{LPOPT}(G_n) - 1.\n\nConsider the Set Cover instance shown in the figure below.\n\nShow that all-half is the unique LPOPT for this instance.\nShow that if you include every set in \\mathcal{F}^\\prime with probability x_s, then the probability that \\mathcal{F}^\\prime covers U is at most 2^{-\\Omega(n)}."
  },
  {
    "objectID": "courses/2022/04-GIAN/tutorials/D5Q/index.html",
    "href": "courses/2022/04-GIAN/tutorials/D5Q/index.html",
    "title": "191014K02 | Day 5 Tutorial",
    "section": "",
    "text": "Back to the Course Page\n\n\n\n\nStart the local search algorithm discussed in class and suppose that initially d(\\gamma, \\beta) \\leqslant d. Consider a random walk from d with down-probability 1/k. Show that \\forall s \\geqslant 0 and j \\geqslant 0: \n\\operatorname{Pr}[{\\color{indianred}d(\\gamma, \\beta) \\leqslant j \\text { in step } s}] \\geqslant \\operatorname{Pr}\\left[P_s \\leqslant j\\right].\n\nWe saw in class that the probability that the walk eventually visits 0 is q_d=\\left(\\frac{1}{k-1}\\right)^d. We want to now show that the probability that this happens in “not too many” i.e, (O(d)) steps, is \\geqslant q_d/2. To this end:\n\nShow that starting at position d+3 the probability of reaching 0 is \\leqslant q_d/8.\nShow that \\forall k, \\exists c such that \\forall d1, after cd steps, the probability of being at position \\leqslant d+3 is \\leqslant q_d/8.\nShow that the probability of reaching 0 from d after at least cd steps is at most q_d/2.\nShow that the probability of reaching 0 from d after at most cd steps is at least q_d/2.\n\nShow that a tournament has a directed cycle if and only if it has a directed triangle.\nDemonstrate a 3-approximation algorithm for the Tournament Feedback Vertex Set problem."
  },
  {
    "objectID": "courses/2022/04-GIAN/tutorials/D4Q/index.html",
    "href": "courses/2022/04-GIAN/tutorials/D4Q/index.html",
    "title": "191014K02 | Day 4 Tutorial",
    "section": "",
    "text": "Back to the Course Page\n\n\n\n\nThe statement of the isolation lemma discussed in class was the following:\nLet U be a universe with |U|=n and let \\cal F be a family of sets over U. Pick a random weight function w: U \\rightarrow\\{1, \\cdots ,W\\}. Then:\n\\operatorname{Pr}[{\\color{indianred}\\cal F \\text{ has a \\textbf{unique} min weight set}}] \\geqslant 1-\\frac{n}{W}\nRecall that we called an element u critical if:\n\nu is in some minimum weight set, and\nif w(u) is increased by 1 then u is no longer in any minimum weight set.\n\nArgue that \\cal F has a unique set of the minimum weight if and only if there are no critical elements.\n:::{.callout-tip} Foo Bar. :::\n\n\n\n\n\n\n\nTip\n\n\n\nFoo Bar.\n\n\n\nDesign a dynamic programming algorithm for Steiner Tree on graphs of bandwidth k with running time k^{O(k)} n^{O(1)}.\nDemonstrate (via a direct argument) that the greedy algorithm for the maxcut problem discussed in class outputs a cut that cuts at least half the edges in the graph.\nRecall the greedy algorithm for Set Cover discussed in class. In each round, show that at least one set S_i \\in F covers at least 1/OPT fraction of uncovered elements.\nWhy did we need to define U to have edges in the k-path algorithm?\nDesign an algorithm for solving the Steiner Tree problem on graphs of bounded FVS.\nDesign an algorithm for the Hamiltonian Path problem on graphs of bounded bandwidth."
  },
  {
    "objectID": "courses/2022/04-GIAN/tutorials/D3Q/index.html",
    "href": "courses/2022/04-GIAN/tutorials/D3Q/index.html",
    "title": "191014K02 | Day 3 Tutorial",
    "section": "",
    "text": "Back to the Course Page\n\n\n\n\n\n\n\n\n\nMax Bisection\n\n\n\nIn the Max Bisection problem we are given a (weighted) graph G=(V, E), and the objective is to find a bisection\nV=S \\cup \\bar{S},|S|=|\\bar{S}|=|V| / 2\nsuch that the number (weight) of edges between S and \\bar{S} is maximized.\n\n\n\n\n\n\n\n\nk-SAT-Local Search\n\n\n\nGiven an instance of k-SAT, find a satisfying assignment that sets at most d variables to true.\n\n\n\n\n\n\nCome up with an instance where the majority rounding idea for the Closest String LP does not give an optimal solution. How much can you push the gap between OPT and the quality of the solution obtained by the greedy rounding.\nShow that the majority rounding idea for the Closest String LP is a valid 2-approximation.\nMake the local search phase for Closest String (discussed in class) work without any knowledge of OPT (i.e, you are not allowed to guess the value of OPT).\nDesign a randomized algorithm for k-SAT-Local Search with running time O(k^d).\nDesign a PTAS for Max Bisection on graphs of minimum degree dn.\nProve that selecting coordinates according to the normal distribution gives unifom distribution on unit sphere.\nProve that the projection of a random unit vector in \\mathbb{R}^d on any plane through the origin has a “u.a.r. direction”."
  },
  {
    "objectID": "courses/2023/01-CS614/index.html",
    "href": "courses/2023/01-CS614/index.html",
    "title": "CS 614 | Jan-Apr 2022",
    "section": "",
    "text": "About the Course\n\n\n\n\n\nThis course will explores the tradeoffs involved in coping with NP-completeness.\nWhen we think about designing algorithms, we are usually very demanding in how we go about it: we require our algorithms to be fast and accurate on all conceivable inputs. This is asking for quite a bit, and perhaps it is not surprising that we cannot afford this luxury all the time. The good news is that most of the time we can make meaningful progress by relaxing just one of these demands:\n\nGive up on accuracy, but not completely: look for solutions that are good enough (approximation) and/or work with algorithms that report the right solution most of the time (Las-Vegas style randomization).\nGive up on coverage, a little bit: let your algorithms work well on structured inputs. Hopefully the structure is such that it is not too limiting and is interesting enough for some application scenario, and is also enough to give you algorithmic leverage, i.e, there’s enough that you can exploit to make fast and accurate algorithms.\nGive up on speed, to some extent: going beyond the traditional allowance of polynomial time, which is the holy grail of what is considered efficient, takes you places. You could either allow for your algorithms have super-polynomial running times, and optimize as much as possible while being accurate on all inputs (exact algorithms), or allow for bad running times on a bounded subset of instances (Monte-Carlo style randomization).\n\nThis course is an introduction to techniques in achieving specific trade-offs, and understanding the theoretical foundations of frameworks that help us establish when certain tradeoffs are simply not feasible.\n\n\n\nFig. Exploring tradeoffs between the demands of accuracy, speed, and coverage.\n\n\n\n\n\n\n\n\n\n\n\nTarget Audience\n\n\n\n\n\nAnyone who is biting their nails from the NP-completeness cliffhanger at the end of their introduction to algorithms will probably enjoy this course.\n\n\n\n\n\n\n\n\n\nPrerequisites\n\n\n\n\n\nThis is a theoretical course that will require mathematical maturity (in particular, the ability to understand and write formal mathematical proofs), and some background in the design and analysis of algorithms. Programming experience is tangentially useful but not necessary. For students of IITGN, this course naturally follows up on DSA-II.\n\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\n\n\nThe Design of Approximation Algorithms • David P. Williamson and David B. Shmoys\nParameterized Algorithms • Marek Cygan, Fedor V. Fomin, Lukasz Kowalik, Daniel Lokshtanov, Daniel Marx, Marcin Pilipczuk, Michal Pilipczuk, and Saket Saurabh\nRandomized Algorithms • Motwani and Raghavan\nBeyond the Worst-Case Analysis of Algorithms • Tim Roughgarden\nAlgorithms • Jeff Erickson\n\nSpecific Pointers:\n\nMatroids: Erickson, the entire chapter and Section 12.2.1 from Parameterized Algorithms.\nVertex Cover:\n\nBranching: see Section 3.1 in Parameterized Algorithms.\nKernels: see Section 2.2.1 for the simple kernel, and Section 2.3.1 for the kernel based on Crown Decomposition in Parameterized Algorithms.\n2-approximation via matchings and LP: Section 21.3 in these notes.\n\nSet Cover:\n\nf-Approximation via LP rounding: Section 1.2 and 1.3 in The Design of Approximation Algorithms.\nRounding a dual solution: Sections 1.4 and 1.5 in The Design of Approximation Algorithms. Also see Chapter A in the appendix for more background on weak duality and complementary slackness.\nGreedy approximation: Section 1.6 in The Design of Approximation Algorithms.\n\nFeedback Vertex Set:\n\nThe O(\\log n)-approximation: Section 7.2 in The Design of Approximation Algorithms.\nThe 2-approximation: Section 14.2 in The Design of Approximation Algorithms.\n\nMiscellaneous\n\nColor Coding: Section 5.2 in Parameterized Algorithms.\nInclusion-Exclusion for Hamiltonian Path: Section 10.1.1 in Parameterized Algorithms.\n\n\n\n\n\n\n\n\n\n\n\nTimings and Venue\n\n\n\n\n\n\nLectures on Mondays: 9PM — 10:30PM (7/206)\nLectures on Wednesdays: 2PM — 3:30PM (7/206)\nOffice Hours: By email.\n\n\n\n\n\n\n\n\n\n\nEvaluation policy\n\n\n\n\n\n\nEach of the three exams account for 20% of the grade.\nEach class will have a quiz worth 2 points. The quizzes will be integrated into the lecture via Mentimeter. The total number of points you can earn through quizzes is capped at 40, and accounts for 40% of the grade.\nThe are three assignments that are not graded but are recommended for practice.\n\n\n\n\n\n\n\n\n\n\nRegister\n\n\n\n\n\nFor IITGN students, (pre-)register through IMS as usual and on Gradescope via course code 485628.\nIf you are not from IITGN and are interested in taking up the course, then please send me an email.\n\n\n\n\nLecturesQuizzesExamsReflections\n\n\n\n\n\n    \n        Date\n        Lecture\n        Slides\n        Notes\n        Video\n    \n    \n                    \n            \n                04 Jan, 2023\n            \n            \n                1. Matroids and Greedy Algorithms - I\n                Matroids - definitions and examples • GreedyBasis Algorithm • Example: Scheduling with Deadlines\n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                09 Jan, 2023\n            \n            \n                2. Matroids and Greedy Algorithms - II\n                Proof of correctness of GreedyBasis\n            \n            \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                11 Jan, 2023\n            \n            \n                3. Matroid Intersection - I\n                Matroid Intersection and Matroid Parity (Section 12.2.1) • Connections with Matchings • 3-Matroid Intersection is NP-complete (Theorem 12.6)\n            \n            \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                16 Jan, 2023\n            \n            \n                4. Matroid Intersection - II\n                A polynomial time algorithm for Matroid Intersection\n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                18 Jan, 2023\n            \n            \n                5. Vertex Cover\n                Definition • Applications • Introduction to Approximation Algorithms • 2-approximation for Vertex Cover via maximal matchings\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                23 Jan, 2023\n            \n            \n                6. Vertex Cover\n                Introduction to Linear Programming • 2-approximation via rounding • A simple randomized algorithm for Vertex Cover\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                25 Jan, 2023\n            \n            \n                7. Vertex Cover\n                Introduction to Fixed-Parameter Tractability • An O(2^k) FPT algorithm by branching\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                01 Feb, 2023\n            \n            \n                8. Vertex Cover\n                Introduction to Kernelization • A Quadratic Kernel for Vertex Cover based on degree reductions\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                02 Feb, 2023\n            \n            \n                9. Vertex Cover\n                A Linear Kernel for Vertex Cover based on the LP formulation\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                13 Feb, 2023\n            \n            \n                10. Set Cover\n                A Greedy Approximation Algorithm • A LP formulation\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                15 Feb, 2023\n            \n            \n                11. Set Cover\n                Dual LP formulation • Weak Duality • Complementary Slackness Conditions • Rounding a Dual Solution\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                20 Feb, 2023\n            \n            \n                12. Detour: Long Path\n                Principle of Inclusion-Exclusion for a poly-space single-exponential algorithm for HAMPATH • Color Coding for Longest Path\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                22 Feb, 2023\n            \n            \n                13. Feedback Vertex Set\n                Dual LP Recap • Introduction to Feedback Vertex Set\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                27 Feb, 2023\n            \n            \n                14. Feedback Vertex Set\n                A first Primal-Dual-based O(log n)-approximation for FVS\n            \n            \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                01 Mar, 2023\n            \n            \n                15. No Class\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                13 Mar, 2023\n            \n            \n                16. Feedback Vertex Set\n                A 2-approximation algorithm for FVS: motivating the formulation\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                15 Mar, 2023\n            \n            \n                17. Feedback Vertex Set\n                A 2-approximation algorithm for FVS: the key combinatorial lemma\n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                20 Mar, 2023\n            \n            \n                18. Feedback Vertex Set\n                Iterative Compression • An O*(3.619^k) algorithm for FVS on general graphs\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                19. Lower Bounds\n                Introduction to NP-completeness • 3-Partition and friends • Multiprocessor Scheduling • Packing rectangles into a rectangle\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                29 Mar, 2023\n            \n            \n                20. Lower Bounds\n                Reductions from 3-Partition\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                03 Apr, 2023\n            \n            \n                21. Lower Bounds\n                SAT and Circuit SAT • CNF SAT • 3SAT • 3SAT-4 • Monotone 3SAT • Polynomial-time variants\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                05 Apr, 2023\n            \n            \n                22. Lower Bounds\n                Schaefer's Dichotomy Theorem • 2-colorable perfect matching\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                10 Apr, 2023\n            \n            \n                23. Lower Bounds\n                Parameterized Intractability • The W-hierarchy • Reductions from CLIQUE\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                12 Apr, 2023\n            \n            \n                24. Lower Bounds\n                Kernel Lower Bounds • Composition and Distillation • Examples of compositions • Parameter preserving transformations\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                17 Apr, 2023\n            \n            \n                25. Lower Bounds\n                The (Strong) Exponential Time Hypothesis • Sparsification Lemma • Implications for parameterized algorithms\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                19 Apr, 2023\n            \n            \n                26. Lower Bounds\n                Reductions based on the ETH\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                24 Apr, 2023\n            \n            \n                27. Lower Bounds\n                Inapproximability Introduction • NP optimization problems • PTAS, APX • Stronger notions of reductions that preserve approximability • APX-hardness of vertex cover\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                26 Apr, 2023\n            \n            \n                28. Lower Bounds\n                Gap Inapproximability • Gap Problems • Gap-producing and gap-preserving reductions • PCP theorem • Unique Games Conjecture\n            \n            \n            \n            \n            \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problems\n        Solutions\n        Due\n    \n    \n                    \n            \n                09 Jan, 2023\n            \n            \n                Matroids and Greedy Algorithms - II\n                Proof of correctness of GreedyBasis\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    09 Jan, 2023\n            \n        \n                    \n            \n                11 Jan, 2023\n            \n            \n                Matroid Intersection - I\n                Matroid Intersection and Matroid Parity (Section 12.2.1) • Connections with Matchings • 3-Matroid Intersection is NP-complete (Theorem 12.6)\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    11 Jan, 2023\n            \n        \n                    \n            \n                16 Jan, 2023\n            \n            \n                Matroid Intersection - II\n                A polynomial time algorithm for Matroid Intersection\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    16 Jan, 2023\n            \n        \n                    \n            \n                18 Jan, 2023\n            \n            \n                Vertex Cover\n                Definition • Applications • Introduction to Approximation Algorithms • 2-approximation for Vertex Cover via maximal matchings\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    18 Jan, 2023\n            \n        \n                    \n            \n                23 Jan, 2023\n            \n            \n                Vertex Cover\n                Introduction to Linear Programming • 2-approximation via rounding • A simple randomized algorithm for Vertex Cover\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    23 Jan, 2023\n            \n        \n                    \n            \n                25 Jan, 2023\n            \n            \n                Vertex Cover\n                Introduction to Fixed-Parameter Tractability • An O(2^k) FPT algorithm by branching\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    25 Jan, 2023\n            \n        \n                    \n            \n                01 Feb, 2023\n            \n            \n                Vertex Cover\n                Introduction to Kernelization • A Quadratic Kernel for Vertex Cover based on degree reductions\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    01 Feb, 2023\n            \n        \n                    \n            \n                03 Feb, 2023\n            \n            \n                Vertex Cover\n                A Linear Kernel for Vertex Cover based on the LP formulation\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    03 Feb, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Set Cover\n                A Greedy Approximation Algorithm • A LP formulation\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Apr, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Detour: Long Path\n                Principle of Inclusion-Exclusion for a poly-space single-exponential algorithm for HAMPATH • Color Coding for Longest Path\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Apr, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Feedback Vertex Set\n                An O(log n)-approximation via primal dual\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Apr, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Feedback Vertex Set\n                A 2-approximation algorithm using a different LP formulation\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Apr, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Feedback Vertex Set\n                Iterative Compression • An O*(3.619^k) algorithm for FVS on general graphs • A polynomial-time algorithm on graphs of maximum degree 3\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Apr, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Lower Bounds\n                Introduction to NP-completeness • 3-Partition and friends • Multiprocessor Scheduling • Packing rectangles into a rectangle\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    27 Mar, 2023\n            \n        \n                    \n            \n                29 Mar, 2023\n            \n            \n                Lower Bounds\n                Reductions from 3-Partition\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    29 Mar, 2023\n            \n        \n                    \n            \n                05 Apr, 2023\n            \n            \n                Lower Bounds\n                Schaefer's Dichotomy Theorem • 2-colorable perfect matching\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    05 Apr, 2023\n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problems\n        Solutions\n        Due\n    \n    \n                    \n            \n                18 Feb, 2023\n            \n            \n                Exam 1\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    18 Feb, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Exam 2\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    09 Apr, 2023\n            \n        \n                    \n            \n                26 Apr, 2023\n            \n            \n                Exam 3\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    27 Apr, 2023\n            \n        \n\n\n\nNo matching items\n\n\n\n\nThis course had seven attendees, and included Btech/Mtech/PhD students.\nI’d like to thank everyone for keeping all the classes — which were all traditional whiteboard lectuers — very interactive, and frequently helping me out with several arguments. Everyone also put in a lot of effort everyone into the various assessments: kudos on your successful completion of the course!"
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L02.html",
    "href": "courses/2023/01-CS614/quizzes/L02.html",
    "title": "CS614. Advanced Algorithms. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer."
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L03.html",
    "href": "courses/2023/01-CS614/quizzes/L03.html",
    "title": "CS614. Advanced Algorithms. L03 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Partition Matroid\n\n\n\nShow that the exchange axiom holds for the Partition Matroid defined in class.\n\n\n\n\n\n\n\n\nProblem 2. Representing the Graphic Matroid\n\n\n\nThe graphic matroid of a graph G can be represented by the following matrix: we have one row for each vertex, and one column for each edge. The column for edge e has +1 in the row for one endpoint, -1 in the row for the other endpoint, and 0 elsewhere; the choice of which endpoint to give which sign is arbitrary.\nArgue that this is a valid representation (i.e, that the forests correspond to linearly independent columns and the subsets of edges that have cycles in them correspond to dependent columns)."
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/A03.html",
    "href": "courses/2023/01-CS614/quizzes/A03.html",
    "title": "CS614. Advanced Algorithms. L03 Solutions.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Partition Matroid\n\n\n\nShow that the exchange axiom holds for the Partition Matroid defined in class.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet (U := U_1 \\cup \\cdots \\cup U_\\ell, \\mathcal{F}) be a partition matroid with budgets a_1,\\ldots,a_\\ell.\nSuppose S, T \\subseteq U_1 \\cup \\cdots \\cup U_\\ell such that S,T \\in \\mathcal{F}, and |T| > |S|.\nThen, there exists at least one part U_i where |T \\cap U_i| > |S \\cap U_i|. Now let x \\in (T \\setminus S) \\cap U_i. Note that S \\cup \\{x\\} \\in \\mathcal{F} since:\n\\begin{equation*}\n    |S \\cap U_j| =\n    \\begin{cases}\n      < a_j & \\text{if } j = i,\\\\\n      \\leqslant a_j & \\text{otherwise}.\n    \\end{cases}\n\\end{equation*}\nand therefore:\n\\begin{equation*}\n    |(S \\cup \\{x\\}) \\cap U_j| =\n    \\begin{cases}\n      |S \\cap U_i| + 1 \\leqslant a_j & \\text{if } j = i,\\\\\n      \\leqslant a_j & \\text{otherwise}.\n    \\end{cases}\n\\end{equation*}\n\n\n\n\n\n\n\n\n\nProblem 2. Representing the Graphic Matroid\n\n\n\nThe graphic matroid of a graph G can be represented by the following matrix: we have one row for each vertex, and one column for each edge. The column for edge e has +1 in the row for one endpoint, -1 in the row for the other endpoint, and 0 elsewhere; the choice of which endpoint to give which sign is arbitrary.\nArgue that this is a valid representation (i.e, that the forests correspond to linearly independent columns and the subsets of edges that have cycles in them correspond to dependent columns).\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSuppose we have a subset of edges that contains a cycle. For simplicity, suppose the cycle is given by:\n\\{pq, qr, rs, st\\}\nNow consider the column vectors c_p, c_q, c_r, c_s:\n\\begin{bmatrix}\nc_p & c_q & c_r & c_s\\\\\n1 & 0 & 0 & -1 \\\\\n-1 & 1 & 0 & 0 \\\\\n0 & -1 & -1 & 0 \\\\\n0 & 0 & 1 & 1\n\\end{bmatrix}\nNote that:\n1 \\cdot c_p + 1 \\cdot c_q + (-1) \\cdot c_r + 1 \\cdot c_s\nis a linear combination with constants (1,1,-1,1) that establish that these vectors are linearly dependent. In general, write down the columns in the order in which they appear on the cycle. If the first entry in the column is not +1, then multiply the column by -1 (except the last column, where we do the reverse: if the first entry is +1, then we multiply the column by -1). This way, we have a situation where every row contains exactly one +1 entry and one -1 entry, and the linear combination sums to 0.\nThis shows that dependent subsets of the matroid correspond to linearly dependent columns of M.\nTo see that independent subsets S \\subseteq E(G) correspond to linearly independent columns, consider the set of columns that correspond to S:\n\\{c_e ~|~ e \\in S\\    }\nSuppose, for the sake of contradiction, that there was some non-trivial linear combination of these columns that vanished, i.e, for non-empty subset T \\subseteq S, there exist constants \\{\\alpha_e\\}_{e \\in T} where:\n\\sum_{e \\in T} \\alpha_e c_e = 0\nBut now consider the subgraph consisting of the edges in T. Note that the minimum degree of T must be two (suppose u \\in T has degree one, and its unique neighbor is v: then consider the entry in the row corresponding to u in the column corresponding to the edge uv: this is non-zero and there is no cancelation possible in the sum above). However, a graph whose minimum degree is two cannot be acyclic, and this is a contradiction."
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/A02.html",
    "href": "courses/2023/01-CS614/quizzes/A02.html",
    "title": "CS614. Advanced Algorithms. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe circuits of the graphic matroid are the cycles of the graph G.\n\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c,d\\} with the edges \\{ab, cd, ad\\}.\nThere are two matchings in this instance:\n\nM_1 := \\{ab,cd\\}\nM_2: \\{ad\\}\n\nHowever, although |M_1| > |M_2|, neither of the edges from M_1 can be added to M_2.\n\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c\\} with the edges \\{ab, ac\\}. There are two independent sets: S_1 := \\{b,c\\} and M_2: \\{a\\}, but neither of the vertices from S_1 can be added to S_2.\n\nIf the independent sets formed a matroid the problem of finding a maximum independent set would not be NP-complete. \n— Comment in class"
  },
  {
    "objectID": "courses/2023/01-NPTEL-CS30/index.html",
    "href": "courses/2023/01-NPTEL-CS30/index.html",
    "title": "NPTEL | CS82 | Jan-Apr 2022",
    "section": "",
    "text": "About the Course\n\n\n\n\n\nThis is a course on algorithm design with a focus on issues of modeling and implementation. Each lecture will be focused entirely on one or two problems that reveal the use of a specific algorithmic technique. The techniques themselves are chosen to be in line with those covered in existing NPTEL courses on data structures and algorithms, so that students who complete those courses can find in this course a natural follow up.\n\n\n\n\n\n\n\n\n\nTarget Audience\n\n\n\n\n\nThis course is intended for anyone who wants to deepen their appreciation for algorithmic techniques that they have learned in a foundational course and/or would like to take a first step towards preparing for coding competitions such as the ICPC.\n\n\n\n\n\n\n\n\n\nPrerequisites\n\n\n\n\n\nThis course assumes some background in the design and analysis of algorithm and a working familiarity with some programming language. Knowing C++ is useful but not required.\n\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\n\nBooks.\n\nAlgorithms by Jeff Erickson\nOpen Data Structures by Pat Morin\nAlgorithms Illuminated by Tim Roughgarden\nAlgorithm Design by J. Kleinberg and E. Tardos\nProblem Solving with Algorithms and Data Structures using C++ by Brad Miller, David Ranum, and Jan Pearce\nProblem Solving with Algorithms and Data Structures using Python by Brad Miller and David Ranum\nThink Data Structures by Allen B. Downey\nSome introductory notes on Design and Analysis of Algorithms (PDF) by Venkatesh Raman\nCompetitive Programming (4th Edition) by Steven Halim, Felix Halim, and Suhendry Effendy\nCompetitive Programmer’s Handbook by Antti Laaksonen\n\n\nOther NPTEL Courses.\n\nDSA with Python by Madhavan Mukund\nDSA by Naveen Garg\n\n\nYouTube Channels.\n\nCodechef\nErrichto\nWilliam Lin\nWilliam Fiset\n\n\nVisualizations.\n\nVisualgo\nOpenDSA\n\n\nBlogs.\n\nPetr Mitrichev\n\n\n\n\n\n\n\n\n\n\nTimings and Venue\n\n\n\n\n\nLectures are pre-recorded. Any remote live sessions will be announced directly over email.\n\n\n\n\n\n\n\n\n\nTAs\n\n\n\n\n\nTBA\n\n\n\n\n\n\n\n\n\nEvaluation policy\n\n\n\n\n\nIf you have taken up this course through Swayam, then you would need to be formally enrolled in the course, and register for the certification exam to get a certificate of completion for the course.\nThe grading policy is as follows.\n\n12.5% of the final grade comes from the weekly quiz-based assignments. The best 8 out of 12 scores are considered.\n12.5% of the final grade comes from the weekly programming assignments, where the weekly score is the average of the programming assignments every week. Again, only the best 8 out of 12 are considered.\n75% of the final grade comes from the final exam, which is held at a physical location and whose format is similar to the weekly quizzes. Please note that there are no programming-based assessments in the final exam.\n\n Important Note. You will be eligible for a certificate only if average assignment score (quizzes and programming assignments combined) \\geq 10/25 and exam score \\geq 30/75. If one of the two criteria is not met, you will not get the certificate even if the final score is \\geq 40/100.\n\n\n\n\n\n\n\n\n\nRegister\n\n\n\n\n\nSign up for the course from here. (Note: enrollment ends on 30 Jan 2023!)\nAlso, you might find the following links useful:\n\nInvitation to the Discord Community\nGitHub repository of solutions to the problems discussed in the lectures\nLink to YouTube Playlist for the course\n\n\n\n\n\nLecturesAssignmentsExams\n\n\n\n\n\n    \n        Date\n        Lecture\n        Slides\n        Notes\n        Video\n    \n    \n                    \n            \n                04 Jan, 2023\n            \n            \n                1. Ad-Hoc and Implementation\n                In this week, we explore some puzzle-based problems in competitive programming. These don’t require any specific algorithmic background, but instead rely on ad-hoc observations and often simple implementations.\n            \n            \n            \n            \n            \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\nThese are some practice assignments: the due date is simply the recommended completion deadline. There is no need to submit these assignments.\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                11 Jan, 2023\n            \n            \n                Assignment 1\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    01 Feb, 2023\n            \n        \n                    \n            \n                20 Feb, 2023\n            \n            \n                Assignment 2\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    20 Mar, 2023\n            \n        \n                    \n            \n                03 Apr, 2023\n            \n            \n                Assignment 3\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    26 Apr, 2023\n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                TBA\n            \n            \n                Exam 1\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n                    \n            \n                TBA\n            \n            \n                Exam 2\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n                    \n            \n                TBA\n            \n            \n                Exam 3\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n\n\n\nNo matching items"
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w02.html",
    "href": "courses/2023/01-ES242/labs/lab-w02.html",
    "title": "ES242. Data Structures and Algorithms I. Week 02 Lab",
    "section": "",
    "text": "Back to course page\n\n\n\n\n\n\nTheme: Arrays and Linked Lists\n\n\n\n\n\n\n\n\n\nProblem 1. Sorting a List\n\n\n\n\n\nYou are given a permutation p1 of length n and a positive integer k \\leq n.\nIn one operation, you:\n\nChoose k distinct elements p_{i_1}, p_{i_2}, \\ldots, p_{i_k}.\nRemove them and then add them sorted in increasing order to the end of the permutation.\n\nFor example, if p=[2,5,1,3,4] and k=2 and you choose 5 and 3 as the elements for the operation, then:\n[2,5,1,3,4] \\rightarrow[2,1,4,3,5].\nFind the minimum number of operations needed to sort the permutation in increasing order. It can be proven that it is always possible to do so.\n\n\nThe first line contains a single integer t\\left(1 \\leq t \\leq 10^4\\right)- the number of test cases. The description of test cases follows.\nThe first line of each test case contains two integers n and k\\left(2 \\leq n \\leq 10^5, 1 \\leq k \\leq n\\right).\nThe second line of each test case contains n integers p_1, p_2, \\ldots, p_n\\left(1 \\leq p_i \\leq n\\right). It is guaranteed that p is a permutation.\nIt is guaranteed that the sum of n over all test cases does not exceed 10^5.\n\n\n\nFor each test case output a single integer - the minimum number of operations needed to sort the permutation. It can be proven that it is always possible to do so.\n\n\n\nSample Input\n4\n3 2\n1 2 3\n3 1\n3 1 2\n4 2\n1 3 2 4\n4 2\n2 3 1 4\nSample Output\n0\n1\n1\n2\nExplanation\nIn the first test case, the permutation is already sorted.\nIn the second test case, you can choose element 3, and the permutation will become sorted as follows: [3,1,2]\\rightarrow[1,2,3].\nIn the third test case, you can choose elements 3 and 4, and the permutation will become sorted as follows: [1,3,2,4]\\rightarrow[1,2,3,4]\nIn the fourth test case, it can be shown that it is impossible to sort the permutation in one operation. However, if you choose elements 2 and 1 in the first operation, and choose elements 3 and 4 in the second operation, the permutation will become sorted as follows: [2,3,1,4]\\rightarrow[3,4,1,2]\\rightarrow[1,2,3,4].\n\n\n\n\n\n\n\n\n\n\nProblem 2. Sorting a List: Challenge the Solution\n\n\n\n\n\nConsider the following algorithm for solving the first problem:\ncurrent = 1\nanswer = 0\nwhile current < n:\n    if the array is sorted:\n        break\n    if current + k - 1 <= n:\n        Apply the operation to the elements [current, current+1, ..., current+k-1]\n    else:\n        Apply the operation to the elements [current, current+1, ..., n] \n    answer += 1\n    current += k\nreturn answer\nGive an example of input where this algorithm fails.\nName your input file tests.txt and make sure it has exactly two lines in the following format:\nN K\np1 p2 ... pn\nwhere the first line consists of two space-separated integers corresponding to N and K and the second line has n space-separated integers that form a permutation. You get a full score on this problem if your input is valid, and it causes the algorithm above to output a sub-optimal solution.\n\n\n\n\n\n\n\n\n\nProblem 3. Maintain a Network\n\n\n\n\n\nYou have just launched a social network for the IITGN community, called GYAN.\nQ operations have been performed since GYAN was launched. The i-th (1 \\leq i \\leq Q) operation is represented by three integers T_i, A_i, and B_i, whose meanings are as follows:\n\nIf T_i=1 : it means that user A_i follows user B_i. If user A_i is already following user B_i at the time of this operation, it does not make any change.\nIf T_i=2 : it means that user A_i unfollows user B_i. If user A_i is not following user B_i at the time of this operation, it does not make any change.\nIf T_i=3 : it means that you are asked to determine if users A_i and B_i are following each other. You need to print Yes if user A_i is following user B_i and user B_i is following user A_i, and No otherwise.\n\nWhen the service was launched, no users were following any users.\nPrint the correct answers for all operations such that T_i=3 in ascending order of i.\n\n\n\n2 \\leq N \\leq 10^4\n1 \\leq Q \\leq 2 \\times 10^5\nT_i=1,2,3(1 \\leq i \\leq Q)\n1 \\leq A_i \\leq N(1 \\leq i \\leq Q)\n1 \\leq B_i \\leq N(1 \\leq i \\leq Q)\nA_i \\neq B_i(1 \\leq i \\leq Q)\nThere exists i(1 \\leq i \\leq Q) such that T_i=3.\nAll values in the input are integers.\n\n\n\n\nThe input is given from Standard Input in the following format: \n\\begin{array}{lll}\nN & Q & \\\\\nT_1 & A_1 & B_1 \\\\\nT_2 & A_2 & B_2 \\\\\n\\vdots & & \\\\\nT_Q & A_Q & B_Q\n\\end{array}\n\n\n\n\nPrint X lines, where X is the number of i ’s (1 \\leq i \\leq Q) such that T_i=3. The j-th (1 \\leq j \\leq X) line should contain the answer to the j-th operation such that T_i=3.\n\n\n\nSample Input\n3 9\n1 1 2\n3 1 2\n1 2 1\n3 1 2\n1 2 3\n1 3 2\n3 1 3\n2 1 2\n3 1 2\nSample Output\nNo\nYes\nNo\nNo\nSample Input\n2 8\n1 1 2\n1 2 1\n3 1 2\n1 1 2\n1 1 2\n1 1 2\n2 1 2\n3 1 2\nSample Output\nYes\nNo\nSample Input\n10 30\n3 1 6\n3 5 4\n1 6 1\n3 1 7\n3 8 4\n1 1 6\n2 4 3\n1 6 5\n1 5 6\n1 1 8\n1 8 1\n2 3 10\n1 7 6\n3 5 6\n1 6 7\n3 6 7\n1 9 5\n3 8 6\n3 3 8\n2 6 9\n1 7 1\n3 10 8\n2 9 2\n1 10 9\n2 6 10\n2 6 8\n3 1 6\n3 1 8\n2 8 5\n1 9 10\nSample Output\nNo\nNo\nNo\nNo\nYes\nYes\nNo\nNo\nNo\nYes\nYes\n\n\n\n\n\n\n\n\n\n\nProblem 4. Stable Matchings\n\n\n\n\n\nThere are n men and n women. Each woman ranks all men in order of her preference (her first choice, her second choice, and so on). Similarly, each man sorts all women according to his preference. The goal is to arrange n marriages in such a way that if a man m prefers some woman w more than his wife, and w prefers m more then her husband a new marriage occurs between w and m. If w prefers her husband more, then she stays married to him. This problem always has a solution and your task is to find one.\n\n\nThe first line contains a positive integer t<=100 indicating the number of test cases. Each test case is an instance of the stable marriage problem defined above. The first line of each test case is a positive integer n<=500 (the number of marriages to find). The next n lines are the woman’s preferences: i-th line contains the number i (which means that this is the list given by the ith woman) and the numbers of men (the first choice of ith woman, the second choice,…). Then, the men’s preferences follow in the same format.\n\n\n\nFor each test case print n lines, where each line contains two numbers m and w, which means that the man number m and the woman number w should get married.\n\n\n\nSample Input\n2\n4\n1 4 3 1 2\n2 2 1 3 4\n3 1 3 4 2\n4 4 3 1 2\n1 3 2 4 1\n2 2 3 1 4\n3 3 1 2 4\n4 3 2 4 1\n7\n1 3 4 2 1 6 7 5\n2 6 4 2 3 5 1 7\n3 6 3 5 7 2 4 1\n4 1 6 3 2 4 7 5\n5 1 6 5 3 4 7 2\n6 1 7 3 4 5 6 2\n7 5 6 2 4 3 7 1\n1 4 5 3 7 2 6 1\n2 5 6 4 7 3 2 1\n3 1 6 5 4 3 7 2\n4 3 5 6 7 2 4 1\n5 1 7 6 4 3 5 2\n6 6 3 7 5 2 4 1\n7 1 7 4 2 6 5 3\nSample Output\n1 3\n2 2\n3 1\n4 4\n1 4\n2 5\n3 1\n4 3\n5 7\n6 6\n7 2\n\n\n\n\n\n\n\n\n\n\nProblem 5. Linked Lists\n\n\n\n\n\n#include<stdio.h>\n#include<stdlib.h>\n\nint main()\n{\n  //node structure\n  struct node\n  {\n      int data;\n      struct node *next;\n  };\n\n  //declaring nodes\n  struct node *head,*middle,*last;\n\n  //allocating memory for each node\n  head   = malloc(sizeof(struct node));\n  middle = malloc(sizeof(struct node));\n  last   = malloc(sizeof(struct node));\n\n  //assigning values to each node\n  head->data   = 10;\n  middle->data = 20;\n  last->data   = 30;\n\n  //connecting each nodes. head->middle->last\n  head->next   = middle;\n  middle->next = last;\n  last->next   = NULL;\n\n  //temp is a reference for head pointer.\n  struct node *temp = head;\n\n  //till the node becomes null, printing each nodes data\n  while(temp != NULL)\n  {\n      printf(\"%d->\",temp->data);\n      temp = temp->next;\n  }\n  printf(\"NULL\");\n\n  return 0;\n}\nExtend the code above to perform the following tasks:\n\nRead a sequence of n numbers from the input, p_1, \\ldots, p_n.\nInsert each of these number at a location where the linked list is still sorted when read from beginning to end.\nFor any given input i, output the number in the linked list that comes before the number i.\n\n\n\nThe first line contains a positive integer n. The second line contains n space-separated integers. The third line contains a positive integer m.\n\n\n\nOutput the number that comes before m in the linked list. It is guaranteed that m is one of the numbers from the second line. If the number happens to be the first element of the list, return -1."
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w01.html",
    "href": "courses/2023/01-ES242/labs/lab-w01.html",
    "title": "ES242. Data Structures and Algorithms I. Week 01 Lab",
    "section": "",
    "text": "Back to course page\n\n\n\n\n\n\nTheme: Practice problems to get used to C syntax.\n\n\n\nLearn C syntax:\n\nInteractive Tutorial\nCodeacademy Lessons\n\nMore practice problems:\n\nTry the first problem in any Codechef/Codeforces contest.\n\n\n\n\n\n\n\nProblem 1. CountDown\n\n\n\n\n\nPrint all non-negative integers less than or equal to N in descending order.\n\n\n\n1 \\leq N \\leq 100\nN is an integer.\n\n\n\n\nThe input is given from Standard Input in the following format:\nN\n\n\n\nPrint X lines, where X is the number of non-negative integers less than or equal to N. For each i = 1, 2, \\ldots, X, the i-th line should contain the i-th greatest non-negative integer less than or equal to N.\n\n\n\nSample Input\n22\nExpected Output\n22\n21\n20\n19\n18\n17\n16\n15\n14\n13\n12\n11\n10\n9\n8\n7\n6\n5\n4\n3\n2\n1\n0\n\n\n\n\n\n\n\n\n\n\nProblem 2. Life Goal\n\n\n\n\n\n\nYou are standing at the origin of a number line. You want to make it to a treasure chest at coordinate X.\nThere is a guard at coordinate Y, who will block you if you encounter him on the way.\nHowever, there is a magic phrase written on a paper which is kept at coordinate Z. If you pick up that paper, then you can whisper the magic phrase to the guard, who will then let you go.\nDetermine whether you can reach the goal. If you can, find the minimum total distance you need to travel to do so.\n\n\n\n−1000 \\leq X,Y,Z \\leq 1000\nX, Y, Z are distinct, and none of them is 0.\nAll values in the input are integers.\n\n\n\n\nThe input is given from Standard Input in the following format:\nX Y Z \n\n\n\nIf you can reach the goal, print the minimum total distance he needs to travel to do so. If he cannot, print -1 instead.\n\n\n\nSample Input\n10 -10 1\nSample Output\n10\nYou can go straight to the goal.\nSample Input\n20 10 -10\nSample Output\n40\nThe goal is beyond the guard. You can get there by first picking up the magic phrase and then getting past the guard.\nSample Input\n100 1 1000\nSample Output\n-1\n\n\n\n\n\n\n\n\n\n\nProblem 3. Game of Trust\n\n\n\n\n\nWrite a simulation for the Game of Trust when played by an always cheat player for R rounds.\n\n\nThe first line of the input contains a number T, which is the number of test cases.\nThe next 2T lines contain T test cases. Each test case is two lines. The first line is the value R and the second line is R space-separated integers. The i-th integer on the second line is 1 if the other player cooperated in the i-th round, and 0 otherwise.\n\n\n\nFor each test case, print two space-separated integers on a new line. The first integer is the total number of coins earned by the always cheat player, while the second integer is the total number of coins earned by the other player. Note that you have to output the net balance. DO NOT output anything else!\n\n\n\nSample Input\n1\n5\n1 1 1 0 1\nExpected Output\n12 -4\n\n\n\n\n\n\n\n\n\n\nProblem 4. Rock Papers Scissors\n\n\n\n\n\nRock Paper Scissors is a game between two players. Each game contains many rounds; in each round, the players each simultaneously choose one of Rock, Paper, or Scissors using a hand shape. Then, a winner for that round is selected: Rock defeats Scissors, Scissors defeats Paper, and Paper defeats Rock. If both players choose the same shape, the round instead ends in a draw.\nYou are preparing for your first big RPS match. Someone has tipped you off with a strategy guide against your opponent on the first match, which consists of many rounds. The strategy guide can be interpreted as follows:\n\nThe first column of the i-th row is what your opponent is going to play in the i-th round: A for Rock, B for Paper, and C for Scissors.\nThe second column of the i-th row is what you should play in response in the i-th round: X for Rock, Y for Paper, and Z for Scissors.\n\nWinning every time would be suspicious, so the responses must have been carefully chosen.\nYour total score is the sum of your scores for each round. The score for a single round is the score for the shape you selected (1 for Rock, 2 for Paper, and 3 for Scissors) plus the score for the outcome of the round (0 if you lost, 3 if the round was a draw, and 6 if you won).\nYour task is to calculate the score you would get if you were to follow the strategy guide.\n\n\nThe first line of the input is a number N, which is the total number of rounds. The next N lines contain two space separated characters. The first character is one of A or B or C, and the second character is one of X or Y or Z.\n\n\n\nThe output shound be a single integer, your total score across all rounds based on the strategy guide.\n\n\n\nSample Input\n3\nA Y\nB X\nC Z\nExpected Output\n15\nThis strategy guide predicts and recommends the following:\n\nIn the first round, your opponent will choose Rock (A), and you should choose Paper (Y). This ends in a win for you with a score of 8 (2 because you chose Paper + 6 because you won).\nIn the second round, your opponent will choose Paper (B), and you should choose Rock (X). This ends in a loss for you with a score of 1 (1 + 0).\nThe third round is a draw with both players choosing Scissors, giving you a score of 3 + 3 = 6.\n\nIn this example, if you were to follow the strategy guide, you would get a total score of 15 (8 + 1 + 6).\n\n\n\n\n\n\n\n\n\n\nProblem 5. Finding the Coefficient\n\n\n\n\n\np(x) is a polynomial whose coefficients are either 0 or 1.\nYou are given the value of p(2) and a number d.\nReturn YES if the coefficient of x^d in p(x) is 1 and NO otherwise.\n\n\nThe first line of the input contains a number T, which is the number of test cases.\nThe next 2T lines contain T test cases. Each test case is two lines. The first line is the value of p(2) and the second line is the value of d.\nIt is guaranteed that p(2) will be at most 10^9 and d will be at most the degree of p(x).\n\n\n\nFor each test case, print a single integer on a new line, which is YES or NO depending on if the coefficient of x^d in p(x) is 1 or 0. DO NOT output anything else!\n\n\n\nSample Input\n6\n45\n0\n45\n1\n45\n2\n45\n3\n45\n4\n45\n5\nExpected Output\nYES\nNO\nYES\nYES\nNO\nYES\n\n\n\n\n\n\n\n\n\n\nProblem 6. Validating a Self-Working Card Trick [Optional]\n\n\n\n\n\nWatch this video and write a program to validate the mechanics of the card trick shown.\nIn other words, your program should take as input a sequence of cards, with the promise that the number of red cards is equal to the number of black cards, and then “perform” the trick as shown in the video, and verify that the final claim about the number of red cards in the red pile being equal to the number of black cards in the black pile is, in fact, true.\n\n\n\n\n\n\n\n\n\nProblem 7. Stable Marriage [Optional]\n\n\n\n\n\nImplement the Stable Marriage algorithm discussed in class. You can practice on this Codechef problem."
  },
  {
    "objectID": "courses/2023/01-ES242/index.html",
    "href": "courses/2023/01-ES242/index.html",
    "title": "ES 242 | Aug-Nov 2022",
    "section": "",
    "text": "About the Course\n\n\n\n\n\nData structures give us principled ways to stow away information. It’s important to do this nicely: and what that means is to work backwards from what you want to do with your information, so that your storage style is optimized for the specific way in which you need to work with your data.\nFor example, the notes you might be taking in this class is a kind of information.\nIf you have no plans of revisiting them later, you can take them as you please, or better yet, not take them at all!\nHowever, you want your notes optimised for giving you quality company during a 2AM revision session on exam day, competing with Maggi for attention, you want your notes to be competently taken: they don’t have to be neat, and it’s enough for them to be useful.\nOn the other hand, if you are taking notes so that a special someone who will inevitably miss a few classes will almost certainly ask for later, then you would be making notes to impress, and that potentially requires a different approach.\nThroughout this course, we will understand such trade-offs in several scenarios.\n\n\nsequential data (arrays, dynamic arrays, linked lists and variants) • dequeues, stacks, queues • graph representations • graph traversals (BFS/DFS) and applications (connected components, bipartiteness, topological sort) • searching and sorting • heaps • BSTs • (2,3)-trees\n\n\n\n\n\n\n\n\n\n\nTarget Audience\n\n\n\n\n\nThis course is aimed at undergraduates in their first or second year, as a first introduction to data structures and algorithms.\n\n\n\n\n\n\n\n\n\nPrerequisites\n\n\n\n\n\nThe course is largely self-contained. Working familiarity with a programming language will be useful for the labs, where solutions are expected to be written out in C.\n\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\n\n\nOpen Data Structures by Pat Morin\nLecture notes by John Bullinaria\nData Structures Using C & C++ by Aaron M. Tenebaum; Moshe J. Augenstein; Yedidyah Lansam\nData Structures and Algorithms by A. Aho, J. Hopcroft, J. Ullman\nAlgorithms by Jeff Erickson\n\n\n\n\n\n\n\n\n\n\nTimings and Venue\n\n\n\n\n\n\nLectures: Tuesdays and Thursdays, 9PM - 10:30PM\nLab: Fridays, 9PM - 10:30PM\nVenue: 1/102 (all sessions)\nNote: Please bring your laptops to all classes.\n\n\n\n\n\n\n\n\n\nTAs and Office hours\n\n\n\n\n\n\n\nBy appointment.\n\n\n\n\nYash More\nGaurav Viramgami\nReuben Devanesan\nXhitij\n\n\n\n\n\n\n\n\n\n\n\nEvaluation policy\n\n\n\n\n\n\nEach of the three exams account for 20% of the grade. The first exam will be pen-and-paper exams, the second exam will be a lab exam, and the third exam will be a viva.\nLabs for Weeks 1 — 4 count for two points each on an all-or-none basis. The seven problems in labs for Weeks 6,8 and 10 have seven problems worth 2 points each. Labs for Weeks 12 and 13 will count for two points each on an all-or-none basis. The total number of points you can earn from quizzes and assignments combined is capped at 20.\nQuizzes 2, 3, and 4 count for 2 points each. Assignments 1, 2, and 3 count for 7 points each. The total number of points you can earn from quizzes and assignments combined is capped at 20.\nThere is no mandatory attendance requirement for this course, although it is strongly recommended that you attend classes, labs, and the ADH sessions.\n\n\n\n\n\n\n\n\n\n\nRegistration & Logistics\n\n\n\n\n\nIf you are at IIT Gandhinagar and would like to take up this course for credit, please fill up this form by midnight on the 30th of December to indicate your interest. \nAll weekly quizzes, labs, and exams will be managed via Gradescope. You can sign up using the entry code G2ZG3X.\nCourse announcements will be posted on this page. They will also be mirrored to this broadcast-only Whatsapp group.\nYou are welcome to post any comments/questions/feedback related to the course in the discussions tab of this page.\n\n\n\nNote: contents being actively updated at the time of this writing.\n\nLecturesLabsQuizzesExamsAnnouncementsDiscussions\n\n\n\n\n\n    \n        Date\n        Lecture\n        Slides\n        Notes\n        Video\n    \n    \n                    \n            \n                03 Jan, 2023\n            \n            \n                1. Introduction to Data Structures [W1]\n                Data Structures - philosophy and examples • Representing games\n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                05 Jan, 2023\n            \n            \n                2. Stable Marriages [W1]\n                The Stable Marriage Problem • Gale-Shapley Algorithm\n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                10 Jan, 2023\n            \n            \n                3. Representing Sequential Data [W2]\n                Arrays • Lists • Implementing the Gale-Shapley Algorithm\n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                12 Jan, 2023\n            \n            \n                4. Representing Graphs [W2]\n                Adjacency Lists • Adjacency Matrices • Edge Lists\n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                17 Jan, 2023\n            \n            \n                5. Dequeues [W3]\n                The Gilbreath Shuffle • Properties of the shuffle\n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                19 Jan, 2023\n            \n            \n                6. Dequeues [W3]\n                Queues and Stacks as special cases of Dequeues\n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                24 Jan, 2023\n            \n            \n                7. Euler Tours [W4]\n                Euler Tour Demonstration • The Bridges of Königsberg\n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                31 Jan, 2023\n            \n            \n                8. Euler Tours [W5]\n                Computing Euler Tours • Hierholzer's algorithm\n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                02 Feb, 2023\n            \n            \n                9. Recap Class [W5]\n                Review of topics covered so far.\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                09 Feb, 2023\n            \n            \n                10. Navigating Graphs (BFS) [W6]\n                Breadth-First Search • Correctness • Analysis of Running Time\n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                14 Feb, 2023\n            \n            \n                11. BFS Applications [W7]\n                Shortest Paths • Pseudopolynomial algorithm for weighted graphs\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                16 Feb, 2023\n            \n            \n                12. Exam [W7]\n                Syllabus: representations, arrays, lists, stacks, queues, dequeues, Euler tours, stable marriages\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                21 Feb, 2023\n            \n            \n                13. Navigating Graphs (DFS) - I [W8]\n                Depth-First Search • Implementation with Stacks\n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                23 Feb, 2023\n            \n            \n                14. Navigating Graphs (DFS) - II [W8]\n                Depth-First Search • DFS-based classification of vertices • DFS-based classificaton of edges • Cycles and backedges\n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                03 Mar, 2023\n            \n            \n                15. BFS and DFS Applications [W9]\n                Testing Bipartiteness • Topological Sort\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                16 Mar, 2023\n            \n            \n                16. Sorting Algorithms [W10]\n                Examples of Sorting Algorithms • Properties of sorting algorithms\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                21 Mar, 2023\n            \n            \n                17. Asymptotics [W10]\n                Comparing Algorithms by Performance • Big-O Notation\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                28 Mar, 2023\n            \n            \n                18. Heaps [W12]\n                Supporting only Insert and FindMin • The challenge of ExtractMin • The Heap Property • Insert • FindMin • ExtractMin\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                06 Apr, 2023\n            \n            \n                19. Heaps [W13]\n                Representing Heaps with Arrays • Analysis: Heapify in Linear Time\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                11 Apr, 2023\n            \n            \n                20. Trees [W14]\n                Rooted Trees • Inorder, Preorder, and Postorder Traversals\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                13 Apr, 2023\n            \n            \n                21. Search [W14]\n                Binary Search • Ternary Search\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                18 Apr, 2023\n            \n            \n                22. Balanced Binary Search Trees [W15]\n                Introduction to BSTs • (2,3)-Trees\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                20 Apr, 2023\n            \n            \n                23. Balanced Binary Search Trees [W15]\n                Insertion in (2,3)-Trees • Analysis of Height\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                25 Apr, 2023\n            \n            \n                24. Balanced Binary Search Trees [W16]\n                Deletion in (2,3)-Trees\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                27 Apr, 2023\n            \n            \n                25. Recap [W16]\n                Review of topics covered so far.\n            \n            \n            \n            \n            \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                06 Jan, 2023\n            \n            \n                W01. Introduction to C\n                CountDown •  Life Goal •  Game of Trust •  Rock Papers Scissors •  Finding the Coefficient •  Validating a Self-Working Card Trick [Optional] •  Stable Marriage [Optional]\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                13 Jan, 2023\n            \n            \n                W02. Lists and Arrays\n                Sorting a List • Sorting a List: Challenge the Solution • Maintain a Network • Stable Matchings\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                20 Jan, 2023\n            \n            \n                W03. The Cardstack\n                Linked Lists • Parentheses • Challenge the Parentheses Solution • Print Alternate Cards\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                27 Jan, 2023\n            \n            \n                W04. Graph Representations and Euler Tours\n                Adjacency Matrix • Adjacency List • Edge List • Sanity Check • Which Way is the Highway? [Optional] • Edge Orientation Puzzle [Optional]\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                03 Feb, 2023\n            \n            \n                W05. Recap Lab\n                Reviewed unsolved and practice problems.\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                10 Feb, 2023\n            \n            \n                W06. Navigating Graphs (BFS)\n                BFS Implementation • Unique Servers\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                17 Feb, 2023\n            \n            \n                W07. No Lab\n                Classes Suspended\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                24 Feb, 2023\n            \n            \n                W08. Navigating Graphs (DFS)\n                DFS Implementation • Is it a DAG?\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                28 Feb, 2023\n            \n            \n                W09. BFS Implementation\n                BFS Implementation Recap\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                02 Mar, 2023\n            \n            \n                W09. DFS Implementation\n                DFS Implementation Recap\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                17 Mar, 2023\n            \n            \n                W10. BFS/DFS Practice Problems\n                Make It Happen • Switching Lines • Prolonged Vacation\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                07 Apr, 2023\n            \n            \n                W13. Heaps\n                Heap operations (ExtractMax, Delete, Insert) • Heapify • Heapsort\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuizzes will be administered online and in the classroom via Gradescope. If a quiz is submitted for evaluation in absence, then it amounts to a violation of the honor code and will result in a disqualification from the course.\nUpdate: The quizzes in the course have been discontinued, and will be replaced with assignments. There will be 12 assignments worth 2 points each that will be made available in due course.\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                05 Jan, 2023\n            \n            \n                Quiz 01\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    05 Jan, 2023\n            \n        \n                    \n            \n                12 Jan, 2023\n            \n            \n                Quiz 02\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    12 Jan, 2023\n            \n        \n                    \n            \n                19 Jan, 2023\n            \n            \n                Quiz 03\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    19 Jan, 2023\n            \n        \n                    \n            \n                24 Jan, 2023\n            \n            \n                Quiz 04\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    24 Jan, 2023\n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                16 Feb, 2023\n            \n            \n                Exam 1\n                Syllabus: representations, arrays, lists, stacks, queues, dequeues, Euler tours, stable marriages\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    16 Feb, 2023\n            \n        \n                    \n            \n            \n            \n                Exam 2 (Lab)\n                Syllabus: arrays, lists, stacks, queues, graphs, BFS/DFS\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n            \n            \n                Exam 3\n                Syllabus: BFS/DFS, heaps, sorting algorithms, tree traversals, 2,3-trees\n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n02/17. Solutions to Exam 1 are now available.\n02/03. Lecture slides and notes up to date for the lectures so far.\n01/25. Solutions to Quiz 04 are now available.\n01/20. Solutions to Quiz 03 are now available.\n01/13. Solutions to Quiz 02 are now available.\n01/11. Materials for the first two weeks (i.e, notes and slides the first four lectures) are now available.\n01/10. Solutions to Quiz 01 are now available.\n01/01. The timings are now fixed. The lectures will be held on Tuesdays and Thursdays, 9PM - 10:30PM while the lab will be during Fridays, 9PM - 10:30PM. The venue for all sessions is AB 1/102. Please bring your laptops to all sessions.\n29/12. The course is open for enrolments and will be available from IMS soon. The timings are TBD. Please fill up this form to indicate your interest in joining the course."
  },
  {
    "objectID": "courses/2023/01-ES242/labquiz2.html",
    "href": "courses/2023/01-ES242/labquiz2.html",
    "title": "ES242. Data Structures and Algorithms I. Week 02 Lab",
    "section": "",
    "text": "Problem 1. Unity Project\n\n\n\n\n\nThere are n people partaking in a project X. The capability value of the ith person is denoted as C[i]. The manager of the project has proposed the following algorithm to calculate the capability of the group (to undertake project X):\nOn each turn, choose two people, x and y, with capabilities C[x] and C[y] respectively (with C[x] <= C[y]). A unity procedure is followed:\n\nIf the two have same capability value, remove both.\nElse, person x is removed, and capability of person y changes to C[y]-C[x]\n\nIt is obvious that at the end at most one person shall remain. The capability value of the person is stated as the capability value of the group. If no person remains, capability value of the group is taken as 0.\nYou have the find the minimum possible capability value of the group.\n\n\n\n\n\n\nRemark\n\n\n\nNote that the choice of people for the unite procedure directly affects the final capbility value.\n\n\n\n\nThe first line contains an integer n.  The next line contains n space-separated integers representing C[]\n\n\n\nReturn the minimum possible capability value of the group according to the mentioned algorithm\n\n\n\nSample Input 1\n6\n2 7 4 1 8 1\nSample Output 1\n1\nSample Input 2\n10\n1 3 5 4 6 13 10 9 8 15 16\nSample Output 2\n0\n\n\n\n\n\n\n\n\n\n\nProblem 2. Connect the City\n\n\n\n\n\nBangalore has n locations, and m bidirectional roads between them. The goal is to construct new roads so that there is a route between any two cities.\nYour task is to find out the minimum number of roads required.\n\n\nThe first input line has two integers n and m: the number of cities and roads. The cities are numbered 1,2,...,n.\nAfter that, there are m lines describing the roads. Each line has two integers a and b: there is a road between those cities.\nA road always connects two different cities, and there is at most one road between any two cities.\n\n\n\nPrint an integer k: the number of required roads.\n\n\n\n\n1 \\leq n \\leq 10^5\n1 \\leq m \\leq 2⋅10^5\n1 \\leq a,b \\leq n\n\n\n\n\nSample Input\n4 2\n1 2\n3 4\nSample Output\n1\n\n\n\n\n\n\n\n\n\n\nProblem 3. Spreading News\n\n\n\n\n\nAfter all the dropouts, there are n people left in ES242. The class has students from across different batches and disciplines, so some people know each other while others do not.\nYou want spread a rumor about whether ES242 will be repeated in the next semester. Students who are friends with each other will share any information they get. To get student i to start spread a rumor, you have to pay them in by buying c[i] samosas at Aadhya. Once someone is bribed, s/he tells it to all her/his friends, and they start spreading the rumor to their friends (for free), and so on.\nYou want everyone to catch the rumor. What is the minimum number of samosas you need to buy?\nTake a look at the notes if you think you haven’t understood the problem completely.\n\n\nThe first line contains two integer numbers n and m (1 \\leq n \\leq 10^5, 0 \\leq m \\leq 10^5) — the number of students in the class and the number of pairs of friends.\nThe second line contains n integer numbers c[i] –— the amount of samosas i-th student asks to start spreading the rumor.\nThen m lines follow, each containing a pair of numbers (x[i], y[i]) which represent that characters x[i] and y[i] are friends (1 \\leq x[i], y[i] \\leq n, x[i] \\neq y[i]). It is guaranteed that each pair is listed at most once.\n\n\n\nPrint one number — the minimum number of samosas you have to buy to spread the rumor fully.\n\n\n\nSample Input\n5 2\n2 5 3 4 8\n1 4\n4 5\nSample Output\n10\nSample Input\n10 0\n1 2 3 4 5 6 7 8 9 10\nSample Output\n55\nNote\nIn the first example the best decision is to bribe the first student (he will spread the rumor to fourth student, and the fourth one will spread it to student). You also have to bribe the second and the third students, so they know the rumor.\n\n\n\n\n\n\n\n\n\n\nProblem 4. Predicting Possibility\n\n\n\n\n\nYou are playing a decision making game where the output can be either 1 or 0.\nGiven a N X N matrix, the objective of the game is to predict if it’s possible to reach from a given source to a destination in less than or equal to k moves.\nSome constraints are as follows:\n\nYou can only move to adjacent positions in 1 move.\nYou can only move diagonally across the matrix.\n\nGiven the value of n, and the maximum moves k, determine if you can fulfill the requirement: can you reach from source to destination in less than k moves?\n\n\nThe first line contains an integer n.\nThe second line contains an integer k, denoting the maximum number of moves you can make. \nThe third line contains two space-separated integers, i and j. An entry i j denotes i as the x-coordinate and j as y-coordinate of the source location.\nThe fourth line contains two space-separated integers, m and n. An entry m n denotes m as the x-coordinate and n as y-coordinate of the destination.\n\n\n\nReturn 1 if you can reach from source to destination in less than k moves. Else, return 0.\n\n\n\nSample Input 1\n4\n3\n0 0\n3 1\nSample Output 1\n1\n\n\n\n\n\n\n\n\n\n\nProblem 5. Can You Register?\n\n\n\n\n\nYou are a student in a university U.\nYou can only register in a certain program A, if the following condition is met:\nYou have registered for all courses with the course IDs [0,1... num_courses-1]\nIf there exists at least one i in range [0,1... num_courses-1] for which you cannot register, then you cannot register from the program.\nSome constraints are as follows:\n\nSome courses may have prerequisite courses. For example if i is a prerequisite of course ID j, then you must register for i before j\nYou can not repeat a course, you can only register for a course one.\n\nGiven the value of num_courses, and the prerequisite requirements, determine if you can fulfill the requirement: can you register for A (can you register for all the courses in range num_courses)?\n\n\nThe first line contains an integer num_courses.\nThe second line contains an integer num_prerequisites, denoting the number of prerequisites or conditions you have to fulfil.\nThe next num_prerequisites lines contain 2 space-separated integers i and j. An entry i j denotes course j is a prerequisite for course i.\n\n\n\nReturn YES if you can register for program A. Else, return NO.\n\n\nSample Input 1\n2\n2\n1 0\n0 1\nSample Output 1\nNO"
  },
  {
    "objectID": "courses/2023/01-ES242/midsem-questions.html",
    "href": "courses/2023/01-ES242/midsem-questions.html",
    "title": "ES242. Data Structures and Algorithms I. MidSem Questions",
    "section": "",
    "text": "Problem 1. A Boastful Cop vs a Clever Robber\n\n\n\n\n\nA robber is trying to escape a cop on an undirected graph G. In the beginning, the cop is at a vertex s and the robber is at a vertex t. (You may assume that s and t are distinct.) They take turns making moves, and each knows the location of the other at all times. A move (by either of them) consists of either staying at the current vertex or moving to a neighbouring one.\nThe cop is boastful, so he announces his moves before making them. Specifically:\n\nbefore anyone makes a move, the cop’s first move is announced - so the robber knows where the cop is headed.\nThen, the robber makes an actual move.\nAfter this, each time the cop moves, he must respect the previous announcement (i.e, move to the previously announced vertex), and then decide his next move and announce it.\nThe robber hears the announcements, so she always knows the cop’s next move before making her own. She makes her move.\n\nIf the cop and the robber are at the same vertex after either of them moves, then the robber is caught. Otherwise, the chase is on!\nThe robber chooses her moves optimally to escape. If she cannot escape, she chooses her moves to maximize the total number of moves until she is caught. The cop chooses his moves optimally to try to catch the robber in as few total moves as possible.\nGiven the graph’s layout and the initial locations of both the cop and the robber, find out whether robber will be caught by the cop and, if so, in how many moves. We say that the game is won by the robber if she’s never caught, and by the cop otherwise.\nIn the figures below, the square vertex depicts the initial location of the robber, and the star depicts the initial location of the cop. Indicate what happens under optimal play. If you choose that the cop wins, indicate how many moves the game lasts assuming optimal play. Each move made by each player counts as a distinct move.\n\n[2 marks] Who wins? __________________\n[2 marks] Who wins? __________________\n[2 marks] If the robber starts on a vertex that is a part of a cycle, then which of the following statements is true?\n⭕️ The robber wins this game.\n⭕️ The cop wins this game and the number of moves is equal to the length of the cycle.\n⭕️ The cop wins this game and the number of moves is twice the length of the cycle.\n⭕️ The cop wins this game and the number of moves depends on the initial distance between the cop and the robber.\n⭕️ The outcome depends on where the cop starts.\n[3 marks] Suppose the game is being played on a path (i.e, a graph with vertices u_1, \\ldots, u_n and edges (u_1,u_2), (u_2, u_3), \\cdots, (u_{n-1},u_n). Suppose the cop starts at u_1 and the robber starts at u_n. Which of the following statements is true?\n⭕️ The robber wins this game.\n⭕️ The cop wins this game and the number of moves is n.\n⭕️ The cop wins this game and the number of moves is 2n.\n⭕️ The cop wins this game and the number of moves is 2n-1.\n⭕️ The cop wins this game and the number of moves is 2(n-1).\n[3 marks] Suppose the graph G has a cycle on the vertices vv_1, v_2, \\ldots, v_kand these are the only vertices that belong to any cycle in G. The robber is initially on a vertex uuand the closest vertex on the cycle is vv_1 via the path ((u,p),(p,q),(q,v_1) The cop is initially on a vertex wwand the closest vertex on the cycle is vv_n via the path ((w,r),(r,v_n) Which of the following statements is true? Assume there are no other vertices in the graph G.\n⭕️ The robber wins this game.\n⭕️ The cop wins this game.\nExplain your answer: if you think the robber wins the game, explain how the robber will evade the cop forever, and if you think the cop wins this game, explain what is the sequence of moves in an optimal game. (You can use the space on the next page.)\n\n\n\n\n\n\n\n\n\n\nProblem 2. Cheating the Stable Marriage Algorithm\n\n\n\n\n\nConsider a stable marriage instance with A,B,C being the men and X,Y,Z being the women. The input is the following:\n\n[2 marks] What is the output of the stable matching algorithm for this instance? Assume that the men are proposing.\n[3 marks] Consider again the algorithm where men are proposing. One of the women can misreport her preferences to get a better outcome from this algorithm. Identify the woman and explain what preference she can submit instead of her true preference to improve the output from her perspective.\n\n\n\n\n\n\n\n\n\n\nProblem 3. Preserving Fixed-Points while Sorting\n\n\n\n\n\n[5 marks] When an array is to be sorted, it may happen that some data values start out being in the same position where they should end up. For example, in the array which is originally:\n45,-4,32,0\nthe 32 is right where it will be in the final sorted output:\n-4,0,32,45\nBut as a particular sorting algorithm operates, it might (depending on the algorithm) move such an element out of the position where it belongs and move it back eventually.\nLet’s say that a sorting algorithm respects fixedpoints if it never moves an element that is in its proper position, on any input.\nConsider the following methods of sorting:\nSelection sort. The algorithm divides the input list into two parts: a sorted sublist of items which is built up from left to right at the front (left) of the list and a sublist of the remaining unsorted items that occupy the rest of the list. Initially, the sorted sublist is empty and the unsorted sublist is the entire input list. The algorithm proceeds by finding the smallest element in the unsorted sublist, exchanging (swapping) it with the leftmost unsorted element (putting it in sorted order), and moving the sublist boundaries one element to the right.\nEg: 4 3 2 1 → 1 3 2 4 → 1 2 3 4\nInsertion sort. Insertion sort iterates over the array, consuming one input element each repetition, and grows a sorted output list. At each iteration, insertion sort removes one element from the input data, finds the location it belongs within the sorted list, and inserts it there. It repeats until no input elements remain.\nEg: 4 3 2 1 → 3 4 2 1 → 2 3 4 1 → 1 2 3 4\nWhich of the following statements are true?\n⭕️ Insertion sort does not respect fixedpoints but selection sort does.\n⭕️ Selection sort does not respect fixedpoints but insertion sort does.\n⭕️ Neither insertion sort nor selection sort respects fixed points.\n⭕️ Both insertion sort and selection sort respect fixed points.\nJustify your answer. If you claim that a particular sorting method does not respect fixed points, then give an example. If you claim that an algorithm does respect fixed points, argue why.\n\n\n\n\n\n\n\n\n\nProblem 4. Eliminating Jealousy\n\n\n\n\n\nYou have distributed M objects among N children. The set of objects given to a child is called his or her bundle. Each child has a specific value for their bundle: let us say child k has value v_k for their bundle. Each child also has a value for all the other bundles: so let us say that child k has value v_{k,\\ell} for the bundle that was given to child \\ell.\nWe say that child a is jealous of child b if v_{a,b} > v_a, i.e, s/he values the bundle given to b more than the bundle that s/he has.\nConsider the following directed graph G. Introduce one vertex for every child, and add an edge from a to b if a is jealous of b.\n\n[2 marks] Suppose G has a directed cycle u_1 \\rightarrow u_2 \\rightarrow \\cdots \\rightarrow u_q \\rightarrow u_1. Describe a way to reassign the bundles (without changing them) so that with the new assignment, all the edges in the cycle disappear (i.e, there is no jealousy between u_1 and u_2, between u_2 and u_3, and so on, with respect to the new assignment). Explain your answer on the next page.\n[1 marks] Suppose G has no directed cycles. Is it true that there is a child who is not jealous of anyone?\n⭕️ Yes ⭕️ No ⭕️ Impossible to conclude from the given information\n[1 marks] Suppose G has no directed cycles. Is it true that there is a child who is nobody is jealous of?\n⭕️ Yes ⭕️ No ⭕️ Impossible to conclude from the given information\n\n\n\n\n\n\n\n\n\n\nProblem 5. Make Strongly Connected\n\n\n\n\n\n[2 marks] In the graph below, what is the smallest number of edges you need to add to make the graph strongly connected? Recall that a strongly connected graph is one where there is a path from u to v for any pair of vertices u and v.\n\n\n\n\n\n\n\n\n\nProblem 6. Counting Gifts\n\n\n\n\n\n[2 marks] The following is true for n guests at a party:\n\nIn any group of three guests, there are two guests who do not know each other, and\nIn any groups of seven guests, there are two guests who do know each other.\n\nAt the end of the party, everyone gives a present to all the guests he or she knows.\nProve that the total number of gifts given is at most 6n.\nHint: what can you say about the maximum degree of this graph?"
  },
  {
    "objectID": "courses/2023/01-ES242/quizzes/q01.html",
    "href": "courses/2023/01-ES242/quizzes/q01.html",
    "title": "ES242. Data Structures and Algorithms I. Quiz 01",
    "section": "",
    "text": "Issued: 5 Jan, 2023\nBack to course page\n\n\n\n\n\n\nProblem 1. The 15-Puzzle\n\n\n\nSuppose you are implementing the 15 puzzle game:\n\nThis is a sliding puzzle having 15 square tiles numbered 1–15 in a frame that is 4 tiles high and 4 tiles wide, leaving one unoccupied tile position. Tiles in the same row or column of the open position can be moved by sliding them horizontally or vertically, respectively. The goal of the puzzle is to rearrange the tiles and place them in increasing numerical order.\n\nHere’s an example configuration:\n\n\n\nAn Example 15-Puzzle Instance\n\n\nYou decide to record the game state as a list of length 16, with elements between 0-15 (0 denotes the empty cell), using the following convention:\n\nthe first four elements contain the numbers in the first row of the board,\nthe fifth-eighth elements contain the numbers in the second row of the board,\nthe ninth-twelfth elements contain the numbers in the third row of the board, and\nthe thirteenth-sixteenth element csontain the numbers in the fourth row of the board.\n\nSuppose you generalise this to a game involving a N \\times N board, using a list of size N^2. The user indicates how they want to move at every step. Assume you can directly access and update any element in your list.\nHow much time do you need to update the configuration?\n\nproportional to N\nproportional to N^2\nconstant\n\n\n\n\n\n\n\n\n\nProblem 2. 2048\n\n\n\nSuppose you are implementing the 2048 game:\n\n2048 is played on a plain 4×4 grid, with numbered tiles that slide when a player moves them using the four arrow keys. Every turn, a new tile randomly appears in an empty spot on the board with a value of either 2 or 4. Tiles slide as far as possible in the chosen direction until they are stopped by either another tile or the edge of the grid. If two tiles of the same number collide while moving, they will merge into a tile with the total value of the two tiles that collided. The resulting tile cannot merge with another tile again in the same move.\n\nFeel free to play the game at the link above to get a feel for it.\nSuppose you are implementing a version of 2048 on a N \\times N board, using a list of size N^2. As in the previous question, the list carries information about the state of the board: the first N elements correspond to the numbers in the first row, and so on. The user indicates in which direction they want to move at every step. Assume you can directly access and update any element in your list.\nHow much time do you need to update the configuration?\n\nproportional to N\nproportional to N^2\nconstant\n\n\n\n\n\n\n\n\n\nProblem 3. Game of Trust\n\n\n\nDescribe how to define a set of marriage preferences among n men and n women such that there is exactly one stable marriage possible."
  },
  {
    "objectID": "courses/2023/01-ES242/quizzes/q02.html",
    "href": "courses/2023/01-ES242/quizzes/q02.html",
    "title": "ES242. Data Structures and Algorithms I. Quiz 02",
    "section": "",
    "text": "Issued: 12 Jan, 2023\nBack to course page\n\n\n\n\n\n\nProblem 1. Doubly Linked Lists\n\n\n\nIf p is the address of a node in a doubly linked list L, then:\n\nnext(p) is the address of the next node in the linked list\nprev(p) is the address of the previous node in the linked list\ndata(p) is the information contained in the the node at address p\n\nNote that:\n\nif p is the address of the first node in L then prev(p) is NULL.\nif p is the address of the last node in L then next(p) is NULL.\n\nAlso, data(p), next(p) and prev(p) returns a sensible value only if p is not NULL, otherwise they are UNDEFINED.\nIf L is a linked list with five elements and p is the address of the third element, then what does next(prev(next(next(p)))) represent?\n\nAddress of the 1st element\nAddress of the 2nd element\nAddress of the 3rd element\nAddress of the 4th element\nAddress of the 5th element\nUNDEFINED\n\nIf L is a linked list with five elements and p is the address of the third element, then what does data(prev(prev(next(p)))) represent?\n\nData of the 1st element\nData of the 2nd element\nData of the 3rd element\nData of the 4th element\nData of the 5th element\nUNDEFINED\n\n\n\n\n\n\n\n\n\nProblem 2. Adjacency Lists\n\n\n\nSuppose A is the adjacency matrix of a simple undirected graph G = (V,E) with n vertices given by \\{1,2,\\ldots,n\\}, that is,\n\n    A[i,j] =\n    \\begin{cases}\n      1 & \\text{if } (i,j) \\in E,\\\\\n      0 & \\text{if } (i,j) \\notin E.\n    \\end{cases}\n\nNote that A[i,i] = 0 for all i \\in \\{1,2,\\ldots,n\\} since G is simple.\nSuppose (i,j) \\in E for some i,j \\in \\{1,2,\\ldots,n\\}, i \\neq j. Let k denote the number of vertices that are adjacent to both i and j.\nWhat is the value of A^2[i,j]?\n\n0\n1\nk\nk+1\n\nSuppose (i,j) \\notin E for some i,j \\in \\{1,2,\\ldots,n\\}, i \\neq j. Let k denote the number of vertices that are adjacent to both i and j.\nWhat is the value of A^2[i,j]?\n\n0\n1\nk\nk+1\n\n\n\n\n\n\n\n\n\nProblem 3. Edge List\n\n\n\nSuppose every vertex of a graph G on n vertices has d neighbors.\nWhat is the size of the edge list?\n\nd \\cdot n\nd \\cdot n/2\n2d \\cdot n\n(d + n)\n\nIs it possible that both d and n are odd?\n\nYes\nNo"
  },
  {
    "objectID": "courses/2023/01-ES242/quizzes/a01.html",
    "href": "courses/2023/01-ES242/quizzes/a01.html",
    "title": "ES242. Data Structures and Algorithms I. Quiz 01 Solutions",
    "section": "",
    "text": "Released: 10 Jan, 2023\nBack to course page\n\n\n\n\n\n\nProblem 1. The 15-Puzzle\n\n\n\nSuppose you are implementing the 15 puzzle game:\n\nThis is a sliding puzzle having 15 square tiles numbered 1–15 in a frame that is 4 tiles high and 4 tiles wide, leaving one unoccupied tile position. Tiles in the same row or column of the open position can be moved by sliding them horizontally or vertically, respectively. The goal of the puzzle is to rearrange the tiles and place them in increasing numerical order.\n\nHere’s an example configuration:\n\n\n\nAn Example 15-Puzzle Instance\n\n\nYou decide to record the game state as a list of length 16, with elements between 0-15 (0 denotes the empty cell), using the following convention:\n\nthe first four elements contain the numbers in the first row of the board,\nthe fifth-eighth elements contain the numbers in the second row of the board,\nthe ninth-twelfth elements contain the numbers in the third row of the board, and\nthe thirteenth-sixteenth element csontain the numbers in the fourth row of the board.\n\nSuppose you generalise this to a game involving a N \\times N board, using a list of size N^2. The user indicates how they want to move at every step. Assume you can directly access and update any element in your list.\nHow much time do you need to update the configuration?\n\nproportional to N\nproportional to N^2\nconstant\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSuppose the empty cell is at row R (counting from the top; i.e, the top row is row 1) and column C (counting from the left; i.e, the left-most column is column 1). The user may chose one of the following four moves:\n\nmove the number at row R-1 and column C into the empty cell, provided R is not the top row.\nmove the number at row R and column C-1 into the empty cell, provided C is not the left-most column.\nmove the number at row R and column C+1 into the empty cell, provided C is not the right-most column.\nmove the number at row R+1 and column C into the empty cell, provided R is not the bottom row.\n\nThe procedure to update the configuration involves two things:\n\nidentify the number to be moved into the empty slot based on the move chosen by the user;\nupdate (swap) the values of the list at locations (R-1)*N + (C-1)1 and the location corresponding to the number to be moved.\n\nThese two steps require knowledge of R and C, i.e, the location of the empty slot. Since we are given the contents of all locations as a list, we may need to — in the worst case — go through the entire list to find where the 0-element lies.\nNote that to speed things up, we could store the integers R and C, representing the location of the 0-element, separately: and update it as moves are made. With this approach, the update can be achieved in constant time.\nFor this question, no such assumption is made, so the time required to update the configuration is proportional to N^2 in the worst-case.\n\n\n\n\n\n\n\n\n\nProblem 2. 2048\n\n\n\nSuppose you are implementing the 2048 game:\n\n2048 is played on a plain 4×4 grid, with numbered tiles that slide when a player moves them using the four arrow keys. Every turn, a new tile randomly appears in an empty spot on the board with a value of either 2 or 4. Tiles slide as far as possible in the chosen direction until they are stopped by either another tile or the edge of the grid. If two tiles of the same number collide while moving, they will merge into a tile with the total value of the two tiles that collided. The resulting tile cannot merge with another tile again in the same move.\n\nFeel free to play the game at the link above to get a feel for it.\nSuppose you are implementing a version of 2048 on a N \\times N board, using a list of size N^2. As in the previous question, the list carries information about the state of the board: the first N elements correspond to the numbers in the first row, and so on. The user indicates in which direction they want to move at every step. Assume you can directly access and update any element in your list.\nHow much time do you need to update the configuration?\n\nproportional to N\nproportional to N^2\nconstant\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNotice that there are moves that may require that you update the status of every cell in the board (as an extreme example, suppose all the odd-numbered rows have elements in them and all the even-numbered rows are empty; and the user choses to move downwards: then except for possibly the bottom row have to be updated in a single move).\nSo one would have to examine the impact of the move on each cell in board and update all the cells, which requires time proportional to N^2.\n\n\n\n\n\n\n\n\n\nProblem 3. Game of Trust\n\n\n\nDescribe how to define a set of marriage preferences among n men and n women such that there is exactly one stable marriage possible.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOne situation where there is exactly one matching that is stable is when all the men and women have identical preferences. In particular, if we denote the set of n men as V := \\{m_1,\\ldots,m_n\\} and the n women as W := \\{w_1,\\ldots,w_n\\}, and further:\n\nevery man has the preference w_1 \\succ w_2 \\succ \\cdots w_n and\nevery woman has the preference m_1 \\succ m_2 \\succ \\cdots m_n;\n\nthen then only stable matching is (w_1,m_1),\\cdots,(w_n,m_n).\nTo see this, suppose a stable matching M matches w_i to m_j where i \\neq j, and let i be the smallest index for which this happens (i.e, for all \\ell < i, M matches w_\\ell with m_\\ell). Then: it must be that j > i (since all men m_j with j < i are already matched to w_j). However, this implies that (w_i,m_i) will form a blocking pair (note that m_i is also matched to some w_t with t > i), contradicting our assumption that M is stable.\nFood for thought: are there other examples?\n\nEvaluation remark: for full credit, it suffices that the answer describes a valid example, even if there is no justification."
  },
  {
    "objectID": "courses/2023/01-ES242/quizzes/a02.html",
    "href": "courses/2023/01-ES242/quizzes/a02.html",
    "title": "ES242. Data Structures and Algorithms I. Quiz 02 Solutions",
    "section": "",
    "text": "Released: 12 Jan, 2023\nBack to course page\n\n\n\n\n\n\nProblem 1. Doubly Linked Lists\n\n\n\n\n\nIf p is the address of a node in a doubly linked list L, then:\n\nnext(p) is the address of the next node in the linked list\nprev(p) is the address of the previous node in the linked list\ndata(p) is the information contained in the the node at address p\n\nNote that:\n\nif p is the address of the first node in L then prev(p) is NULL.\nif p is the address of the last node in L then next(p) is NULL.\n\nAlso, data(p), next(p) and prev(p) returns a sensible value only if p is not NULL, otherwise they are UNDEFINED.\nIf L is a linked list with five elements and p is the address of the third element, then what does next(prev(next(next(p)))) represent?\n\nAddress of the 1st element\nAddress of the 2nd element\nAddress of the 3rd element\nAddress of the 4th element\nAddress of the 5th element\nUNDEFINED\n\nIf L is a linked list with five elements and p is the address of the third element, then what does data(prev(prev(next(p)))) represent?\n\nData of the 1st element\nData of the 2nd element\nData of the 3rd element\nData of the 4th element\nData of the 5th element\nUNDEFINED\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFor the first part:\nnext(prev(next(next(p)))) = next(prev(next(next(3)))) = next(prev(next(4))) = next(prev(5)) = next(4) = 5\nFor the second part:\ndata(prev(prev(next(p)))) = data(prev(prev(next(3)))) = data(prev(prev(4))) = data(prev(3)) = data(2)\n\n\n\n\n\n\n\n\n\nProblem 2. Adjacency Lists\n\n\n\n\n\nSuppose A is the adjacency matrix of a simple undirected graph G = (V,E) with n vertices given by \\{1,2,\\ldots,n\\}, that is,\n\n    A[i,j] =\n    \\begin{cases}\n      1 & \\text{if } (i,j) \\in E,\\\\\n      0 & \\text{if } (i,j) \\notin E.\n    \\end{cases}\n\nNote that A[i,i] = 0 for all i \\in \\{1,2,\\ldots,n\\} since G is simple.\nSuppose (i,j) \\in E for some i,j \\in \\{1,2,\\ldots,n\\}, i \\neq j. Let k denote the number of vertices that are adjacent to both i and j.\nWhat is the value of A^2[i,j]?\n\n0\n1\nk\nk+1\n\nSuppose (i,j) \\notin E for some i,j \\in \\{1,2,\\ldots,n\\}, i \\neq j. Let k denote the number of vertices that are adjacent to both i and j.\nWhat is the value of A^2[i,j]?\n\n0\n1\nk\nk+1\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nA^2[i,j] = k irrespective of whether (i,j) \\in E or not. Notice that the entry in the i-th row and j-th column of A^2 is the product of the i-th row of A and the j-th column of A, and the only terms that are not zeroed-out in this product are those that correspond to vertices adjacent to both i and j. Note that both i and j are not adjacent to themselves, which is why their adjacency (or lack of it) does not change the final answer.\n\n\n\n\n\n\n\n\n\nProblem 3. Edge List\n\n\n\n\n\nSuppose every vertex of a graph G on n vertices has d neighbors.\nWhat is the size of the edge list?\n\nd \\cdot n\nd \\cdot n/2\n2d \\cdot n\n(d + n)\n\nIs it possible that both d and n are odd?\n\nYes\nNo\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf every vertex has d neighbors then there are d edges incident to all the n vertices in the graph. Thus we have dn edges but with each edge counted exactly twice: in particular the edge (u,v) gets counted as being one of the edges incident on u and one of the edges incident on v. Therefore the total number of edges, and therefore the size of the edge list, is d \\cdot n/2.\nSince the total number of edges in any graph is a whole number, and is given by d \\cdot n/2, it is not possible that both d and n are odd."
  },
  {
    "objectID": "courses/index.html",
    "href": "courses/index.html",
    "title": "Courses",
    "section": "",
    "text": "Teaching\n\n \n\n\nIITGNNPTELOther\n\n\n\n\n\n    \n        \n            \n                    \n            \n            \n                            \n            \n            \n                ES242\n            \n            \n                Data Structures and Algorithms - I\n            \n            \n                2023\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                CS614\n            \n            \n                Advanced Algorithms\n            \n            \n                2023\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                ES242\n            \n            \n                Data Structures and Algorithms - I\n            \n            \n                2022\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                CS610\n            \n            \n                Advanced Algorithms\n            \n            \n                2021\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                ES301\n            \n            \n                Data Structures and Algorithms II\n            \n            \n                2021\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n            \n            \n                ES242\n            \n            \n                Data Structures and Algorithms - I\n            \n            \n                2020\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n            \n            \n                ES102\n            \n            \n                Computing\n            \n            \n                2020\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n            \n            \n                Special Topics\n            \n            \n                CS Theory Toolkit\n            \n            \n                2020\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                ES214\n            \n            \n                Discrete Mathematics\n            \n            \n                2020\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                ES242\n            \n            \n                Data Structures and Algorithms - I\n            \n            \n                2019\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                ST601\n            \n            \n                Social Networks\n            \n            \n                2019\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                ES214\n            \n            \n                Discrete Mathematics\n            \n            \n                2019\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                CS610\n            \n            \n                Advanced Algorithms\n            \n            \n                2019\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                MA607\n            \n            \n                Graph Theory and Applications\n            \n            \n                2018\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                ES112\n            \n            \n                Computing\n            \n            \n                2018\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n            \n            \n                ES102\n            \n            \n                Introduction to Computing\n            \n            \n                2018\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n            \n            \n                ES112\n            \n            \n                Computing\n            \n            \n                2017\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n            \n            \n                MA607\n            \n            \n                Graph Theory and Applications\n            \n            \n                2017\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n            \n            \n                FP601\n            \n            \n                Cultures of Communication\n            \n            \n                2017\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n            \n            \n                CS607\n            \n            \n                Combinatorics with Applications in Computer Science\n            \n            \n                2016\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n            \n            \n                FP601\n            \n            \n                Cultures of Communication\n            \n            \n                2016\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n            \n            \n                CS321\n            \n            \n                Analysis and Design of Algorithms\n            \n            \n                2016\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n            \n            \n                CS607\n            \n            \n                Combinatorics with Applications in Computer Science\n            \n            \n                2016\n            \n            \n                \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\nAt the moment, the only way of accessing the materials associated with these courses is to sign up for them through the NPTEL playform. You can access the videos via the playlists on YouTube.\nHowever, I have recieved requests for being able to access materials outside of the NPTEL LMS, along with downloadable slides and lecture notes. This is work in progress (really :) ), and I hope that eventually we will have most of the materials available from here.\n Watch this space!\n\n\n\n\n \n\n\n\n\n    \n        \n            \n                    \n            \n            \n            \n            \n                TBA\n            \n            \n                Getting Started with Competitive Programming  Co-instructor with Atul.\n            \n            \n                2023\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                TBA\n            \n            \n                Advanced Algorithms\n            \n            \n                2023\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                NOC23 CS30\n            \n            \n                Getting Started with Competitive Programming  Co-instructor with Atul.\n            \n            \n                2023\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                NOC22 CS82\n            \n            \n                Getting Started with Competitive Programming\n            \n            \n                2022\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                NOC22 CS81\n            \n            \n                Parameterized Algorithms  Co-instructor with Saket Saurabh\n            \n            \n                2022\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                NOC22 CS59\n            \n            \n                Getting Started with Competitive Programming\n            \n            \n                2022\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                NOC21 CS99\n            \n            \n                Getting Started with Competitive Programming  Co-instructor with Arjun Arul\n            \n            \n                2021\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                NOC21 CS92\n            \n            \n                Parameterized Algorithms  Co-instructor with Saket Saurabh\n            \n            \n                2021\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                NOC21 CS80\n            \n            \n                Discrete Mathematics  Facilitating co-instructor • Course by Sudarshan Iyengar\n            \n            \n                2021\n            \n            \n                \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\nThese are courses that I have been involved in coordinating and organizing. I am grateful to all the instructors here for sharing their time and expertise with us. If you would like to collaborate on a short course/workshop at IITGN — virtual/hybrid/in-person — please get in touch.\n\n\n\n\n \n\n\n\n\n    \n        \n            \n                    \n            \n            \n                            \n            \n            \n                191014K02\n            \n            \n                GIAN Course on Randomized Methods for Parameterized Algorithms  by Prof. Daniel Lokshtanov\n            \n            \n                2022\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                SC 310\n            \n            \n                Visual Science Communication  by Dr. Ipsa Jain\n            \n            \n                2022\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                Certification\n            \n            \n                Dynamic Programming Bootcamp  by Priyansh Agarwal\n            \n            \n                2022\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                SC 312\n            \n            \n                CS Research 101  by Shashank Srikant\n            \n            \n                2022\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                SC 302\n            \n            \n                Fundamentals of Science Communication  by Siddharth Kankaria\n            \n            \n                2022\n            \n            \n                \n            \n        \n        \n            \n                    \n            \n            \n                            \n            \n            \n                SC-235\n            \n            \n                Cards and Combinatorics  by Manish Jain (and team)\n            \n            \n                2019\n            \n            \n                \n            \n        \n\n\n\nNo matching items"
  },
  {
    "objectID": "courses/2019/cards.html",
    "href": "courses/2019/cards.html",
    "title": "Fundamentals of Science Communication | Siddharth Kankaria",
    "section": "",
    "text": "— Manish Jain\n\n\n\n\n\n\nAbout the Course\n\n\n\n\n\nIn this course, we will introduce many little-known theorems of advanced mathematics. We will go on a roller coaster ride from delightful self-working magic tricks to serious math, then back again to magic. The tricks don’t require any sleight of hand or trickery.\nA similar course is taught at Stanford University by a former professional magician named Persi Diaconis. At school, Diaconis supported himself by playing poker on ships between New York and South America. Martin Gardner, a writer at Scientific American, once saw him and recommended to a professor for Ph.D. at Harvard University.\nIn two days, we would learn about Hummer shuffles, Royal Hummer, de Bruijn Sequences, Universal Cycles, Mandelbrot Set, Neat Shuffles and many more card tricks. You would have about 10 cool card tricks up your sleeve and you would be comfortable exploring many more as you would know the terminology of math card tricks by the end of the course.\n\n\n\n\n\n\n\n\n\nAbout the Instructor\n\n\n\n\n\nManish Jain spends most of his time investigating the science behind simple toys, and is passionate about sharing his insights and excitement with people. He is Associate Teaching Professor at Center for Creative Learning (CCL), IIT Gandhinagar, whose goal is to create and foster makers who can take innovation to the next level. Towards this goal, CCL designs and offers deep and joyful learning experiences built around STEM toys and hands-on activities. The ultimate goal is to bring back the gleam in the eyes of students and teachers.\nBefore founding CCL, Manish worked at IUCAA’s Science Centre in Pune, with Padma Shri Arvind Gupta. In his previous avatar, he spent 19 years in the area of chip design at Synopsys (Bangalore & amp; Mountain View), serving as a Director of R&D and Scientist leading Low Power Simulation efforts, where he has 5 US patents.\nManish has a bachelor’s degree in Electrical Engineering from IIT Kanpur (1993) and has also finished a few courses at Stanford University.\n\n\n\n\n\n\n\n\n\nDates and Time\n\n\n\n\n\n6th and 7st April, 2019 • 10:00 AM to 1:00 PM, 3:00 PM to 5:00 PM"
  },
  {
    "objectID": "videos/index.html",
    "href": "videos/index.html",
    "title": "Videos",
    "section": "",
    "text": "Videos\n\n \n\nComing Soon :)"
  },
  {
    "objectID": "credits.html",
    "href": "credits.html",
    "title": "Credits",
    "section": "",
    "text": "Credits\n\n\n \n\n\nMade with Quarto (h/t Dr. Phil Chodrow).\nSVG backgrounds by Haikei.\nIcons by Bootstrap for the most part."
  },
  {
    "objectID": "bookmarks/index.html",
    "href": "bookmarks/index.html",
    "title": "Bookmarks",
    "section": "",
    "text": "Bookmarks\nA braindump of things I find — or at any rate, found at some point — interesting.\n\n\n\n\n\n\nDisclaimer\n\n\n\nI have not explored/read everything listed out here: if something is here, it just means that I am vaguely aware of said thing. Things I have some appreciation for are marked with a  and can be filtered by typing parsed in the search box on this page. Things I have passing or partial familiarity with are marked with a  and can be filtered by typing pseudo in the search box on this page.\n\n\n\n\n\n\n\n\n\nLegend for Estimated Effort\n\n\n\n Quick tips and the like: these will typically need between 2-15 minutes of your attention. Filter for these by typing short.\n Articles or resources that demand anywhere between an hour to an evening to process fully. Filter for these by typing moderate.\n Things to keep coming back to over time, like courses, books, youtube channels, and so on. Filter for these by typing long.\n\n\n\n\n\n\n\n\nLegend for Types (click to view)\n\n\n\n\n\n\n\n\n\n\n\nSymbol\nApproximate Category\n\n\n\n\n\nbook\n\n\n\ntweet\n\n\n\nwebsite\n\n\n\narticle\n\n\n\nchannel\n\n\n\nvideo\n\n\n\n\n\n\n\n\n\n\n\nSymbol\nApproximate Category\n\n\n\n\n\naudio\n\n\n\npodcast\n\n\n\nsong\n\n\n\nexplorable\n\n\n\nlist\n\n\n\nmeme\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n        \n        \n        \n    3Blue1Brown, by Grant Sanderson, is some combination of math and entertainment, depending on your disposition. The goal is for explanations to be driven by animations and for difficult problems to be made simple with changes in perspective.\n\n   \n        3blue1brown\n\n\n            \n\n\n        youtube   \n        math   \n        scicomm   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    The parsed status is a little tongue-in-cheek; I have not read the book cover to cover, but it is what I use for all my algorithms teaching, so I hope that counts! Absolute favorite ❤️\n\n   \n        Algorithms by Jeff Erickson\n\n\n            \n\n\n        computerscience   \n        book   \n\n   \n        \n        pseudo\n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    Valuable advice for apsiring academics by Shashank Srikant.\n\n   \n        Aspiring Academics\n\n\n            \n\n\n        advice   \n        article   \n        academics   \n\n   \n        \n        pseudo\n\n   \n        \n    moderate\n\n\n\n\n        \n        \n        \n    Subscribe to see tutorial-style videos about electronics, computer architecture, networking, and various other technical subjects.\n\n   \n        Ben Eater\n\n\n            \n\n\n        youtube   \n        scicomm   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    A regular series of seminars held via video meetings, open to anyone,  and targeted to the interests of attendees of the COMSOC workshop series.\n\n   \n        COMSOC Video Seminar\n\n\n            \n\n\n        list   \n        computerscience   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    CS Unplugged is a collection of free teaching material that teaches Computer Science through engaging games and puzzles that use cards, string, crayons and lots of running around.\n\n   \n        CS Unplugged\n\n\n            \n\n\n        scicomm   \n        computerscience   \n        list   \n\n   \n        \n        pseudo\n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    Led by Manish Jain at IIT Gandhinagar. STEM videos predominantly in Hindi and English.\n\n   \n        Center for Creative Learning\n\n\n            \n\n\n        youtube   \n        classroom   \n        scicomm   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    The next book from Ben Orlin, the popular math blogger and author of the underground bestseller Math With Bad Drawings.Change Is The Only Constant is an engaging and eloquent exploration of the intersection between calculus and daily life, complete with Orlin's sly humor and wonderfully bad drawings.\n\n   \n        Change Is the Only Constant\n\n\n            \n\n\n        scicomm   \n        math   \n        book   \n\n   \n        \n        pseudo\n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    A ridiculous (and fun!) way to solve Rubik’s cubes and (not) solve equations. Recording of a talk given by Ramprasad Saptharishi.\n\n   \n        Commutators\n\n\n            \n\n\n        scicomm   \n        video   \n        computerscience   \n\n   \n        \n        pseudo\n\n   \n        \n    moderate\n\n\n\n\n        \n        \n        \n    Opinions of Doron Zeilberger\n\n   \n        Dr. Z's Opinions\n\n\n            \n\n\n        opinions   \n        essays   \n        list   \n\n   \n        \n        pseudo\n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    These essays have been a heavy early influence on how think about a lot of things.\n\n   \n        Essays and Opinions by Oded Goldreich\n\n\n            \n\n\n        opinions   \n        essays   \n        list   \n\n   \n        \n        pseudo\n\n   \n        \n    long\n\n\n\n\n        \n    \n\n   \n        Essays by Matt Might\n\n\n            \n\n\n        list   \n        essays   \n        academia   \n\n   \n        \n        pseudo\n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    For your discrete math class.\n\n   \n        Flawed proof example\n\n\n            \n\n\n        math   \n        tweet   \n        classroom   \n\n   \n        \n        parsed\n\n   \n        \n    short\n\n\n\n\n        \n        \n        \n    Virtual lecture series in recent developments in parameterized complexity.\n\n   \n        Frontiers of Parameterized Complexity\n\n\n            \n\n\n        list   \n        computerscience   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n    \n\n   \n        List of ACM Turing Award Lectures\n\n\n            \n\n\n        list   \n        computerscience   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    Looking Glass Universe is a channel mostly about the strange world of quantum mechanics. It's created by Mithuna Yoganathan, who did her PhD in quantum computing at the University of Cambridge.\n\n   \n        Looking Glass Universe\n\n\n            \n\n\n        youtube   \n        scicomm   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    A live survey of known lower bounds in arithmetic circuits by Ramprasad Saptharishi\n\n   \n        Lowerbounds Survey\n\n\n            \n\n\n        survey   \n        article   \n        computerscience   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    Bestselling author and worst-drawing artist Ben Orlin expands his oeuvre with this interactive collection of mathematical games. With 70-plus games, each taking a minute to learn and a lifetime to master, this treasure trove will delight, educate, and entertain.\n\n   \n        Math Games with Bad Drawings\n\n\n            \n\n\n        scicomm   \n        math   \n        book   \n\n   \n        \n        pseudo\n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    A hilarious reeducation in mathematics-full of joy, jokes, and stick figures-that sheds light on the countless practical and wonderful ways that math structures and shapes our world. By Ben Orlin.\n\n   \n        Math with Bad Drawings\n\n\n            \n\n\n        scicomm   \n        math   \n        book   \n\n   \n        \n        parsed\n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    A book by Donald E. Knuth, Tracy L. Larrabee, and Paul M. Roberts\n\n   \n        Mathematical Writing\n\n\n            \n\n\n        advice   \n        writing   \n        book   \n\n   \n        \n        parsed\n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    Free tools, courses and manipulatives to make online learning more interactive and engaging than ever before.\n\n   \n        Mathigon\n\n\n            \n            \n\n\n        book   \n        math   \n        explorable   \n\n   \n        \n        pseudo\n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    Cool physics and other sweet science.\n\n   \n        Minute Physics\n\n\n            \n\n\n        youtube   \n        scicomm   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    Videos about numbers and mathematics. Videos by Brady Haran since 2011.\n\n   \n        Numberphile\n\n\n            \n\n\n        youtube   \n        scicomm   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    By Nicky Case and Vi Hart. \"... a story of how harmless choices can make a harmful world.\"\n\n   \n        Parable of the Polygons\n\n\n            \n\n\n        math   \n        explorable   \n        classroom   \n\n   \n        \n        parsed\n\n   \n        \n    moderate\n\n\n\n\n        \n        \n        \n    Thoughts from Shriram Krishnamurthi\n\n   \n        Parenthetically Speaking\n\n\n            \n\n\n        opinions   \n        essays   \n        list   \n\n   \n        \n        pseudo\n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    These are the lecture notes of the Aalto University course CS-E4580 Programming Parallel Computers. Very comprehensive!\n\n   \n        Programming Parallel Computers\n\n\n            \n\n\n        course   \n        computerscience   \n        website   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    A free introduction to quantum computing and quantum mechanics by Andy Matuschak and Michael Nielsen.\n\n   \n        Quantum Country\n\n\n            \n\n\n        physics   \n        book   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    Seeing Theory was created by Daniel Kunin while an undergraduate at Brown University. The goal of this website is to make statistics more accessible through interactive visualizations (designed using Mike Bostock’s JavaScript library D3.js).\n\n   \n        Seeing Theory\n\n\n            \n            \n\n\n        book   \n        computerscience   \n        explorable   \n\n   \n        \n        pseudo\n\n   \n        \n    long\n\n\n\n\n        \n    \n\n   \n        Standup Maths\n\n\n            \n\n\n        youtube   \n        maths   \n        scicomm   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    Videos about science.\n\n   \n        Steve Mould\n\n\n            \n\n\n        youtube   \n        math   \n        scicomm   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    Tessellate is the annual college festival of Chennai Mathematical Institute (CMI). The Youtube channel has a bunch of really nice talks!\n\n   \n        Tessellate CMI\n\n\n            \n\n\n        scicomm   \n        youtube   \n        math   \n\n   \n        \n        pseudo\n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    By Nicky Case. A remarkable explorable that demonstrates the iterated prisoners dilemma.\n\n   \n        The Evolution of Trust\n\n\n            \n\n\n        math   \n        explorable   \n        classroom   \n\n   \n        \n        parsed\n\n   \n        \n    moderate\n\n\n\n\n        \n        \n        \n    By Nicky Case. An interactive about how things spread in networks.\n\n   \n        The Wisdom and/or Madness of Crowds\n\n\n            \n\n\n        math   \n        explorable   \n        classroom   \n\n   \n        \n        parsed\n\n   \n        \n    moderate\n\n\n\n\n        \n        \n        \n    A lesson based on the windmill video. Neat problem and solution!\n\n   \n        The unexpectedly hard windmill question\n\n\n            \n\n\n        math   \n        explorable   \n        classroom   \n\n   \n        \n        parsed\n\n   \n        \n    moderate\n\n\n\n\n        \n        \n        \n    By Nicky Case. An interactive (and really well-done) guide to alternative voting systems.\n\n   \n        To Build a Better Ballot\n\n\n            \n\n\n        math   \n        explorable   \n        classroom   \n\n   \n        \n        parsed\n\n   \n        \n    moderate\n\n\n\n\n        \n        \n        \n    An element of truth - videos about science, education, and anything else I find interesting.\n\n   \n        Veritasium\n\n\n            \n\n\n        youtube   \n        scicomm   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    Visualising data structures and algorithms through animation. Conceptualised in 2011 by Dr Steven Halim as a tool to help his students better understand data structures and algorithms, by allowing them to learn the basics on their own and at their own pace.\n\n   \n        VisuAlgo\n\n\n            \n\n\n        course   \n        computerscience   \n        explorable   \n\n   \n        \n        pseudo\n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    An explorable video series by Grant Sanderson and Ben Eater. Pushing the limits of WebGL!\n\n   \n        Visualizing Quaternions\n\n\n            \n\n\n        math   \n        explorable   \n        classroom   \n\n   \n\n   \n        \n    moderate\n\n\n\n\n        \n    \n\n   \n        Welch Labs\n\n\n            \n\n\n        youtube   \n        maths   \n        scicomm   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n    \n\n   \n        Wendover Productions\n\n\n            \n\n\n        youtube   \n        scicomm   \n\n   \n\n   \n        \n    long\n\n\n\n\n        \n        \n        \n    Explorable from Minute Labs exploring the construct of a single day.\n\n   \n        What is a Day?\n\n\n            \n\n\n        physics   \n        explorable   \n        classroom   \n\n   \n\n   \n        \n    moderate\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "cp.html",
    "href": "cp.html",
    "title": "Notes on Competitive Programming",
    "section": "",
    "text": "This page collects editorial-style posts, and they will mostly be based off my NPTEL course on competitive programming. You can subscribe to a feed for this series by clicking here. If you’d like to guest author a post here, please drop me a line at: mail -AT- neeldhara.com\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nSam I Am\n\n\n\n\n\n\n\n\n\nOct 1, 2021\n\n\n9 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "exportober.html",
    "href": "exportober.html",
    "title": "Exportober",
    "section": "",
    "text": "This page is about a content-creation accountability challenge, which I plan to keep open around October every year (so it’s parallel to affairs like Inktober and possibly a warm-up for Nanowrimo the following month.) You can subscribe to a feed for this series by clicking here.\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nExportober 2022\n\n\n\n\n\n\n\n\n\nOct 7, 2022\n\n\n1 min\n\n\n\n\n\n\n\n\nExportober 2021\n\n\n\n\n\n\n\n\n\nSep 25, 2021\n\n\n1 min\n\n\n\n\n\n\n\n\nAbout Exportober\n\n\n\n\n\n\n\n\n\nSep 24, 2021\n\n\n6 min\n\n\n\n\n\n\n\n\nAn Invitation to Exportober 2021\n\n\n\n\n\n\n\n\n\nSep 19, 2021\n\n\n3 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "events/2022/index.html",
    "href": "events/2022/index.html",
    "title": "Events in 2022",
    "section": "",
    "text": "Events\n\n \n\nThese are events from 2022.\n\n\n \n\n\n\n\n\n\n    \n            \n        \n\n    ACM-India CSEd Workshop\n\n\n    2022\n\n\n    \n        \n        \n\n    \n        \n            \n        \n\n\n\n    \n            \n        \n\n    GIAN Course on Randomized Methods in Parameterized Algorithms  Professor Daniel Lokshtanov\n\n\n    2022\n\n\n    \n        \n        \n\n    \n        \n            \n        \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "events/2022/csed/index.html",
    "href": "events/2022/csed/index.html",
    "title": "ACM-India CS Education Workshop",
    "section": "",
    "text": "The discipline of Computer Science and Engineering at IIT Gandhinagar, in partnership with ACM India and NPTEL India, is organizing a one-day workshop on CS Education on the 23rd of December, 2022 (Friday).\nJoin us ahead of holiday season to prepare to your courses next term! \nVenue: AB 1/101\n\nOverviewScheduleFAQSpread the wordCertificates\n\n\n \n\n \n\n\n\n\n\n\n\n Target Audience. Anyone interested in matters of CS Education, with a focus on teaching programming and computational thinking, at either the school or undergraduate level, is welcome to attend.\n\n\n\n\n\n\n\n\n\n Logistics. This is a hybrid event.\nThe registration costs are as follows:\n\nRs. 1500 for in-person attendees (all-inclusive)\nRs. 350 (+GST) for online attendees (students)\nRs. 650 (+GST) for online attendees (non-students)\n\n\nRegistered participants are eligible for a certificate of participation subject to participation :)\n\n\n\n\n\n\n\n\n\n Registrations are now closed.\n\n\n\n\n\n\n\n\n\n Inquiries. Please direct any questions you have to neeldhara.m@iitgn.ac.in with CSEd Workshop Inquiry as the subject.\n\n\n\n\n\n9:30AM — 10AM. Registration\n\n10AM — 11AM. The CSPathshala Initiative: Computational Thinking in Schools • Sonia Garcha       \n The Bebras Challenge • CTiS • CSPathshala • The TACT Challenge\n\n11AM — 11:30AM.  Coffee Break\n\n11:30AM — 1PM. A hands-on introduction to Refute Questions • Viraj Kumar      \n Task 1 • Task 2 • Refute Code Template • Task 3\n\n\n\n\n\n\nTip\n\n\n\n\n\nq ## Abstract\nTo help students develop a critical eye for human and (increasingly) machine-generated code, this workshop proposes Refute questions. Students are given code created for a stated purpose and asked: Why does the code fail to serve that purpose? Students must provide evidence demonstrating this failure. After a hands-on introduction to Refute questions in their originally proposed context (an alternative to ‘Explain in Plain English’ questions), participants will receive and review a richer variety of Refute questions for autograded formative and summative assessments, targeting an introductory programming course in Python.\n\n\n\n\n1PM — 2PM.  Lunch\n\n2PM — 3:30PM. Algorithmic program development using Mapcode • Venkatesh Choppella      \n Colab Worksheet • Feedback Form • Introduction to Mathematical Computer Science\n\n\n\n\n\n\nAbstract\n\n\n\n\n\nMapcode (Viswanath, 2008) is a methodology for iterative algorithmic problem solving in which the requirements and the design of an algorithm are expressed as a collection of maps (total functions). Once the design is available, it can be easily coded as a program.\nThe workshop is an introduction to program development using the mapcode methodology. This will be done through a series of examples which illustrate the mapcode approach to the specification, design and coding of solutions as programs.\n\n\n\n\n3:30PM — 4PM.  Coffee Break\n\n4PM — 5PM. Teaching Data Structures • N S Kumar     \n Github Repository with Files\n\n5PM — 5:30PM.  High Tea\n\n\n\n\n\n\n\n\n\n Who is the target audience for this workshop?\n\n\n\n\n\nAnyone with an interest in CS Education at the school and/or college level will find this workshop interesting. We hope to bring together school and college teachers, CS Education researchers, industry professionals, and aspiring educators at any stage of their career — in particular, students with an interest pedagogy are also welcome.\n\n\n\n\n\n\n\n\n\n Are there any technical pre-requisites?\n\n\n\n\n\nThere are no explicit pre-requisites, although some experience with teaching introductory programming classes and/or data structures and algorithms would be relevant.\n\n\n\n\n\n\n\n\n\n Is accommodation available for outstation participants?\n\n\n\n\n\nIf you would like to join us in person and need accommodation, please send an email to neeldhara.m@iitgn.ac.in with the subject Accommodation Request for the CSEd Workshop. We expect most of the in-person attendance to be local, and encourage others to join us online. However, we are happy to explore accommodation options on request.\n\n\n\n\n\n\n\n\n\n Will the sessions be recorded?\n\n\n\n\n\nYes. The sessions will be recorded and made available in early January 2023.\n\n\n\n\n\n\n\n\n\n Why should I pay the registration fee for virtual attendance if the lectures will be recorded and available later?\n\n\n\n\n\nThe main difference is that you will be able to join the lectures over Zoom and have an opportunity interact with the speakers and other participants. You will also be eligible for a certificate subject to participation.\n\n\n\n\n\n\n\n\n\n Can I register in one mode now and switch later?\n\n\n\n\n\nYou can register for virtual participation and switch to onsite later by paying the difference in the registration fees. This will be a manual process, please send an email to neeldhara.m@iitgn.ac.in with the subject CSEd workshop registration upgrade if you are in this situation. However, if you decide to switch from onsite participation to virtual, please note that the difference will not be refunded.\n\n\n\n\n\n\n\n\n\n Is a refund is avalaible for any valid reason?\n\n\n\n\n\nThe registration fees are not refundable in general. We may be able to make exceptions in special cases: please send an email to neeldhara.m@iitgn.ac.in with the subject CSEd workshop registration cancelation if you have to cancel your participation due to exceptional circumstances.\n\n\n\n\n\n\n\n\n\n How do I get to IIT Gandhinagar?\n\n\n\n\n\nPlease see this page for more details about reaching IITGN and this page for general information about the IIT Gandhinagar campus.\n\nSardar Vallabhbhai Patel International Airport (AMD) is an international airport serving the cities of Ahmedabad and Gandhinagar in Gujarat, India and is nearer to our IIT campus.\nAhmedabad Junction Railway Station (ADI), locally known as Kalupur station is the main terminus which is very well connected with the other parts of the country.\nGeeta Mandir & Paldi are the bus terminals of Ahmedabad city.\n\n\n\n\n\n\n\n\n\n\n My question is not addressed above, where can I get an answer?\n\n\n\n\n\nPlease direct any questions you have to neeldhara.m@iitgn.ac.in with CSEd Workshop Inquiry as the subject.\n\n\n\n\n\n\nPlease share this on your social media!\n\n\n\n\nPoster\n\n\n\n\nTo obtain a certificate of participation, please fill out the form below no later than the 30th of December 2022. Digital certificates will be emailed on the 1st of January, 2023."
  },
  {
    "objectID": "events/index.html",
    "href": "events/index.html",
    "title": "Events",
    "section": "",
    "text": "Events\n\n \n\nThese events are made possible with extraordinary support from student volunteers, administrative staff, colleagues from the discipline, and funding agencies. The nature of my involvement in these events is revealed by hovering on  :)\n\n \n\n\n\n\n\n\n    \n            \n        \n\n    ACM-India CSEd Workshop\n\n\n    2022\n\n\n    \n        \n        \n\n    \n        \n            \n        \n\n\n\n    \n            \n        \n\n    GIAN Course on Randomized Methods in Parameterized Algorithms  Professor Daniel Lokshtanov\n\n\n    2022\n\n\n    \n        \n        \n\n    \n        \n            \n        \n\n\n\n    \n            \n        \n\n    Workshop on Parameterized Complexity 301 (Virtual)\n\n\n    2020\n\n\n    \n        \n        \n\n    \n        \n            \n        \n\n\n\n    \n            \n        \n\n    Workshop on Parameterized Complexity 201 (IISER Pune)\n\n\n    2020\n\n\n    \n        \n        \n\n    \n        \n            \n        \n\n\n\n    \n            \n        \n\n    ACM-India Inter-Research Institute Student Seminar in CS\n\n\n    2020\n\n\n    \n        \n        \n\n    \n        \n            \n        \n\n\n\n    \n            \n        \n\n    ACM-India Annual Event\n\n\n    2020\n\n\n    \n        \n        \n\n    \n        \n            \n        \n\n\n\n    \n            \n        \n\n    ACM-W India Workshop for Women in CS Research\n\n\n    2020\n\n\n    \n        \n        \n\n    \n        \n            \n        \n\n\n\n    \n            \n        \n\n    ACM-W Summer School on Algorithmic Game Theory\n\n\n    2019\n\n\n    \n        \n        \n\n    \n        \n            \n        \n\n\n\n    \n            \n        \n\n    GIAN Course on Computational Social Choice  Professor Edith Elkind\n\n\n    2017\n\n\n    \n        \n        \n\n    \n        \n            \n        \n\n\n\n    \n            \n        \n\n    GIAN Course on Pattern Matching Algorithms  Professor Amihood Amir\n\n\n    2017\n\n\n    \n        \n        \n\n    \n        \n            \n        \n\n\n\n    \n            \n        \n\n    ACM Summer School on Graph Theory and Graph Algorithms\n\n\n    2017\n\n\n    \n        \n        \n\n    \n        \n            \n        \n\n\n\n    \n            \n        \n\n    NMI Workshop on Complexity Theory\n\n\n    2016\n\n\n    \n        \n        \n\n    \n        \n            \n        \n\n\n\n    \n        \n\n    TEQIP Summer School on Design and Analysis of Algorithms\n\n\n    2016\n\n\n    \n        \n        \n\n    \n        \n            \n        \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Neeldhara",
    "section": "",
    "text": "Ernest Hemingway\n\n\n\nReal seriousness in regard to writing is one of two absolute necessities. The other, unfortunately, is talent.\n\n\nHeads up: I write with both prerequisites unfulfiled. Proceed with caution.\n\n \n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nNote Taking Resources\n\n\n\n\n\n\n\nlists\n\n\n \n\n\n\n\nJun 2, 2023\n\n\n0 min\n\n\n\n\n\n\n\n\nOn Career Choices\n\n\n\n\n\n\n\nfunda\n\n\n \n\n\n\n\nMay 26, 2023\n\n\n5 min\n\n\n\n\n\n\n\n\nLetting Go\n\n\n\n\n\n\n\npoem\n\n\n \n\n\n\n\nMay 11, 2023\n\n\n0 min\n\n\n\n\n\n\n\n\nCourse Plan Generator\n\n\n\n\n\n\n\nworkflow\n\n\n \n\n\n\n\nApr 25, 2023\n\n\n0 min\n\n\n\n\n\n\n\n\n13 Sheep\n\n\n\n\n\n\n\ngames\n\n\nexposition\n\n\n \n\n\n\n\nMar 26, 2023\n\n\n18 min\n\n\n\n\n\n\n\n\nLetters with Pandoc\n\n\n\n\n\n\n\npandoc\n\n\nworkflows\n\n\nlatex\n\n\n \n\n\n\n\nNov 27, 2022\n\n\n1 min\n\n\n\n\n\n\n\n\nThe Only Fair Ranking of IITs\n\n\n\n\n\n\n\nfunda\n\n\n \n\n\n\n\nNov 24, 2022\n\n\n1 min\n\n\n\n\n\n\n\n\nExportober 2022\n\n\n\n\n\n\n\nexportober\n\n\n \n\n\n\n\nOct 7, 2022\n\n\n1 min\n\n\n\n\n\n\n\n\nSKJ\n\n\n\n\n\n\n\niitgn\n\n\n \n\n\n\n\nSep 23, 2022\n\n\n3 min\n\n\n\n\n\n\n\n\nExternal Communications\n\n\n\n\n\n\n\niitgn\n\n\n \n\n\n\n\nSep 23, 2022\n\n\n12 min\n\n\n\n\n\n\n\n\nDog Bunny Puzzle\n\n\n\n\n\n\n\npuzzles\n\n\nexposition\n\n\n \n\n\n\n\nSep 19, 2022\n\n\n7 min\n\n\n\n\n\n\n\n\nOn Teaching\n\n\n\n\n\n\n\nfunda\n\n\n \n\n\n\n\nSep 5, 2022\n\n\n7 min\n\n\n\n\n\n\n\n\nSolo Chess\n\n\n\n\n\n\n\nexposition\n\n\ntwitterthread\n\n\n \n\n\n\n\nMar 24, 2022\n\n\n4 min\n\n\n\n\n\n\n\n\nEight Self-Sabotaging Behaviors\n\n\n\n\n\n\n\nfunda\n\n\ntwitterthread\n\n\n \n\n\n\n\nMar 15, 2022\n\n\n2 min\n\n\n\n\n\n\n\n\nKidney Exchanges\n\n\n\n\n\n\n\ntalk\n\n\nexposition\n\n\n \n\n\n\n\nFeb 25, 2022\n\n\n8 min\n\n\n\n\n\n\n\n\nWomen in Mathematics\n\n\n\n\n\n\n\nbooks\n\n\nlist\n\n\n \n\n\n\n\nFeb 21, 2022\n\n\n2 min\n\n\n\n\n\n\n\n\nOn the Communication Complexity of Equality\n\n\n\n\n\n\n\nsketchnotes\n\n\nlecturenotes\n\n\n \n\n\n\n\nOct 4, 2021\n\n\n0 min\n\n\n\n\n\n\n\n\nTwo approaches to the 15 puzzle\n\n\n\n\n\n\n\npuzzles\n\n\nexposition\n\n\n \n\n\n\n\nOct 3, 2021\n\n\n10 min\n\n\n\n\n\n\n\n\nSam I Am\n\n\n\n\n\n\n\ncp\n\n\nlecturenotes\n\n\n \n\n\n\n\nOct 1, 2021\n\n\n9 min\n\n\n\n\n\n\n\n\nNew Mac\n\n\n\n\n\n\n\napps\n\n\nlist\n\n\n \n\n\n\n\nSep 30, 2021\n\n\n11 min\n\n\n\n\n\n\n\n\nExportober 2021\n\n\n\n\n\n\n\nexportober\n\n\n \n\n\n\n\nSep 25, 2021\n\n\n1 min\n\n\n\n\n\n\n\n\nAbout Exportober\n\n\n\n\n\n\n\nexportober\n\n\n \n\n\n\n\nSep 24, 2021\n\n\n6 min\n\n\n\n\n\n\n\n\nMoving Blocks at CTIS 2021\n\n\n\n\n\n\n\npuzzles\n\n\nexposition\n\n\n \n\n\n\n\nSep 21, 2021\n\n\n3 min\n\n\n\n\n\n\n\n\nAn Invitation to Exportober 2021\n\n\n\n\n\n\n\nexportober\n\n\n \n\n\n\n\nSep 19, 2021\n\n\n3 min\n\n\n\n\n\n\n\n\nEnvelope Budgeting with Notion\n\n\n\n\n\n\n\nnotion\n\n\nworkflows\n\n\ntutorial\n\n\n \n\n\n\n\nSep 18, 2021\n\n\n19 min\n\n\n\n\n\n\n\n\nActually Building a Website with Notion\n\n\n\n\n\n\n\nnotion\n\n\nworkflows\n\n\nwebsites\n\n\n \n\n\n\n\nSep 12, 2021\n\n\n9 min\n\n\n\n\n\n\n\n\nNotion-powered websites\n\n\n\n\n\n\n\nnotion\n\n\nworkflows\n\n\nwebsites\n\n\n \n\n\n\n\nSep 11, 2021\n\n\n14 min\n\n\n\n\n\n\n\n\nMassren for fast file renaming\n\n\n\n\n\n\n\nworkflows\n\n\n \n\n\n\n\nSep 11, 2020\n\n\n0 min\n\n\n\n\n\n\n\n\nBuilding a first Django App\n\n\n\n\n\n\n\ntutorial\n\n\nwebsites\n\n\n \n\n\n\n\nJun 12, 2018\n\n\n12 min\n\n\n\n\n\n\n\n\nDad\n\n\n\n\n\n\n\npoem\n\n\n \n\n\n\n\nAug 27, 2012\n\n\n0 min\n\n\n\n\n\n\n\n\nOn the Fence\n\n\n\n\n\n\n\npoem\n\n\n \n\n\n\n\nApr 23, 2012\n\n\n0 min\n\n\n\n\n\n\n\n\nSprinkles of the Sky\n\n\n\n\n\n\n\npoem\n\n\n \n\n\n\n\nJan 5, 2011\n\n\n0 min\n\n\n\n\n\n\n\n\nHow Expensive Can Homework Help Be?\n\n\n\n\n\n\n\nexposition\n\n\nparameterized-algorithms\n\n\n \n\n\n\n\nMay 1, 2010\n\n\n5 min\n\n\n\n\n\n\n\n\nSeek\n\n\n\n\n\n\n\npoem\n\n\n \n\n\n\n\nApr 3, 2007\n\n\n0 min\n\n\n\n\n\n\n\n\nBloom\n\n\n\n\n\n\n\npoem\n\n\n \n\n\n\n\nFeb 3, 2005\n\n\n0 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L04.html",
    "href": "courses/2023/01-CS614/quizzes/L04.html",
    "title": "CS614. Advanced Algorithms. L04 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Matroid Intersection Example\n\n\n\nConsider a directed graph D=(V, E \\subseteq V \\times V). A set T \\subseteq E is an arborescence (oriented forest) if:\n\nT does not contain a cycle (ignoring directions of edges).\nEvery vertex in V has at most one incoming edge.\n\nAn arborescence T with |T|=n-1 will have one incoming edge incident on each node except one. If we denote this special node as root, this is an oriented spanning tree as shown in the figure.\n\n\n\nAn example arborescence.\n\n\nConsider the underlying undirected graph G_D = (V,E) associated with D (this is the graph obtained by “erasing the arrows” in D). Consider the universe given by E. Suggest two matroids {\\mathcal M}_1 and {\\mathcal M}_2 for which set of arborescences is given by the sets independent in both {\\mathcal M}_1 and {\\mathcal M}_2.\nHint: these are both matroids seen in class. Further, you might find it useful to partition E into |V| many parts as follows — the part P_v contains all edges that are incoming arcs for the vertex v in D. Can you define a matroid based on this partition?\nDescribe {\\mathcal M}_1 and {\\mathcal M}_2.\n\n\n\n\n\n\n\n\nProblem 2. Maker-Breaker Game\n\n\n\nTwo players take turns removing edges from an undirected graph until there are no edges left.\nPlayer 2 wins if the edges they remove contains a spanning tree, player 1 wins if the set of edges they remove would disconnect the original graph.\n\nIs it true that exactly one player wins this game? In other words, is the following statement true?\n\n“It is NOT the case that after the game has been played, both players can claim a win.”\n\nYes\nNo\n\n\nWhich player wins on a path?\n\n\nPlayer 1\nPlayer 2\n\n\nWhich player wins on a complete graph?\n\n\nPlayer 1\nPlayer 2\n\n\nComplete this sentence: player 2 has the winning strategy if and only if the graph contains BLANK.\n\n(No marks for answering this question, take your best guess :) )"
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/A04.html",
    "href": "courses/2023/01-CS614/quizzes/A04.html",
    "title": "CS614. Advanced Algorithms. L04 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Matroid Intersection Example\n\n\n\nConsider a directed graph D=(V, E \\subseteq V \\times V). A set T \\subseteq E is an arborescence (oriented forest) if:\n\nT does not contain a cycle (ignoring directions of edges).\nEvery vertex in V has at most one incoming edge.\n\nAn arborescence T with |T|=n-1 will have one incoming edge incident on each node except one. If we denote this special node as root, this is an oriented spanning tree as shown in the figure.\n\n\n\nAn example arborescence.\n\n\nConsider the underlying undirected graph G_D = (V,E) associated with D (this is the graph obtained by “erasing the arrows” in D). Consider the universe given by E. Suggest two matroids {\\mathcal M}_1 and {\\mathcal M}_2 for which set of arborescences is given by the sets independent in both {\\mathcal M}_1 and {\\mathcal M}_2.\nHint: these are both matroids seen in class. Further, you might find it useful to partition E into |V| many parts as follows — the part P_v contains all edges that are incoming arcs for the vertex v in D. Can you define a matroid based on this partition?\nDescribe {\\mathcal M}_1 and {\\mathcal M}_2.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTake {\\mathcal M}_1 to be the graphic matroid and {\\mathcal M}_2 to be the partition matroid with all budgets set to one. Membership in the first matroid ensures that there are no underlying undirected cycles and membership in the second matroid ensures that every vertex in V has at most one incoming edge.\n\n\n\n\n\n\n\n\n\nProblem 2. Maker-Breaker Game\n\n\n\nTwo players take turns removing edges from an undirected graph until there are no edges left.\nPlayer 2 wins if the edges they remove contains a spanning tree, player 1 wins if the set of edges they remove would disconnect the original graph.\n\nIs it true that exactly one player wins this game? In other words, is the following statement true?\n\n“It is NOT the case that after the game has been played, both players can claim a win.”\n\nYes\nNo\n\n\nWhich player wins on a path?\n\n\nPlayer 1\nPlayer 2\n\n\nWhich player wins on a complete graph?\n\n\nPlayer 1\nPlayer 2\n\n\nComplete this sentence: player 2 has the winning strategy if and only if the graph contains BLANK.\n\n(No marks for answering this question, take your best guess :) )\n\n\n\n\n\n\n\n\nHeads Up\n\n\n\nPart (3) was under-specified: the second player wins on complete graphs with at least four vertices but the first player has easy wins if the graph is an edge (a complete graph on two vertices) or a triangle (a complete graph on three vertices).\nGrading note: everyone recieves a full grade for this question.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSuppose both players indeed win. Let us delete the edges chosen by the first player. What is left is: (a) the set of edges chosen by the second player and (b) a disconnected graph. But the second player also won, so this set contains a spanning tree. A graph cannot simultaneously admit a spanning tree and be disconnected, this is a contradiction when applied on the graph induced by the leftover edges.\nPlayer 1 can choose any edge in the first step and he already wins.\nAssume that the graph has at least four vertices. Player 2 wins because notice that no matter how the first player plays the first (n-1) steps, it is not enough to disconnect the graph. By chosing edges carefully1, Player 2 can ensure that (s)he has booked a spanning tree already within the first (n-1) moves.\nNo spoilers on this one (yet)."
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w03.html",
    "href": "courses/2023/01-ES242/labs/lab-w03.html",
    "title": "ES242. Data Structures and Algorithms I. Week 03 Lab",
    "section": "",
    "text": "Back to course page\n\n\n\n\n\n\nTheme: Stacks\n\n\n\n\n\n\n\n\n\nProblem 1. Linked Lists\n\n\n\n\n\n#include<stdio.h>\n#include<stdlib.h>\n\nint main()\n{\n  //node structure\n  struct node\n  {\n      int data;\n      struct node *next;\n  };\n\n  //declaring nodes\n  struct node *head,*middle,*last;\n\n  //allocating memory for each node\n  head   = malloc(sizeof(struct node));\n  middle = malloc(sizeof(struct node));\n  last   = malloc(sizeof(struct node));\n\n  //assigning values to each node\n  head->data   = 10;\n  middle->data = 20;\n  last->data   = 30;\n\n  //connecting each nodes. head->middle->last\n  head->next   = middle;\n  middle->next = last;\n  last->next   = NULL;\n\n  //temp is a reference for head pointer.\n  struct node *temp = head;\n\n  //till the node becomes null, printing each nodes data\n  while(temp != NULL)\n  {\n      printf(\"%d->\",temp->data);\n      temp = temp->next;\n  }\n  printf(\"NULL\");\n\n  return 0;\n}\nExtend the code above to perform the following tasks:\n\nRead a sequence of n numbers from the input, p_1, \\ldots, p_n.\nInsert each of these number at a location where the linked list is still sorted when read from beginning to end.\nFor any given input i, output the number in the linked list that comes before the number i.\n\n\n\nThe first line contains a positive integer n. The second line contains n space-separated integers. The third line contains a positive integer m.\n\n\n\nOutput the number that comes before m in the linked list. It is guaranteed that m is one of the numbers from the second line. If the number happens to be the first element of the list, return -1.\n\n\n\n\n\n\n\n\n\n\nProblem 2. Parentheses\n\n\n\n\n\nYou are given a string consisting of parentheses ( and ). A string of this type is said to be correct:\n\nif it is the empty string\nif A and B are correct, AB is correct.\nif A is correct, (A) is correct.\n\nWrite a program that takes a sequence of strings of this of type and check their correctness.\nYour program can assume that the maximum string length is 128.\n\n\nThe first line of the input is a positive integer n, the number of tests. The next n lines consist of one test case each. Each test case is a string made of the parentheses ().\n\n\n\nThe output should consist of n lines, one for each test. The i-th line of the ouptut should be Yes if the the string in the i-th test case is correct, and No otherwise.\n\n\n\nSample Input\n5\n(\n(((\n()()\n)\n)))\nSample Output\nNo\nNo\nYes\nNo\nNo\n\n\n\n\n\n\n\n\n\n\nProblem 3. Challenge the Parentheses Solution\n\n\n\n\n\nConsider the following algorithm for the previous problem:\nIf the first character is not ( return FALSE\nIf the last character is not ) return FALSE\nInitialize i = 0\nFor j in s:\n    if j == \"(\":\n        i++\n    else:\n        i--\nif i != 0 return FALSE\nelse return TRUE\nProvide an input for which the algorithm above does not work. Your input should be a single line consisting of a string that has ( and ) characters only.\n\n\n\n\n\n\n\n\n\nProblem 4. Print Alternate Cards\n\n\n\n\n\nAdd a set of cards to a stack and print all the cards in odd-numbered positions of the stack.\n\n\nThe first line contains a number n, the number of cards in the stack. The next n lines contain two numbers. The first number b indicates if the card is to be added on the top (b=0) or at the bottom (b=1). The second number indicates the card’s value, an integer between 1 and 52.\nThe output should the list of alternating cards from bottom to top (i.e, starting at the card pointed to by the first pointer). If there are an even number of cards, note that the last card on the stack does not get printed.\nAdding a card on the top can be done by using pushBack, while adding it at the bottom pushFront.\n\n\n\nSample Input\n5\n0 1\n0 2\n1 3\n1 5\n0 4\nSample Output\n5\n1\n4\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct s_card {\n  int cardvalue;\n  struct s_card *next;\n  struct s_card *prev;\n} t_card;\n\ntypedef struct s_cardstack {\n  struct s_card *first;\n  struct s_card *last;\n} t_cardstack;\n\nt_cardstack *cardstackInit() {\n  t_cardstack *cardstack;\n  cardstack = malloc(sizeof(t_cardstack));\n  cardstack->first = NULL;\n  cardstack->last = NULL;\n  return cardstack;\n}\n\nint isEmpty(t_cardstack *cardstack) { return !cardstack->first; }\n\nvoid pushFront(t_cardstack *cardstack, int cardvalue) {\n  t_card *node = malloc(sizeof(t_card));\n  node->cardvalue = cardvalue;\n  node->prev = NULL;\n  node->next = cardstack->first;\n  if (isEmpty(cardstack))\n    cardstack->last = node;\n  else\n    cardstack->first->prev = node;\n  cardstack->first = node;\n}\n\nvoid pushBack(t_cardstack *cardstack, int cardvalue) {\n  t_card *node = malloc(sizeof(t_card));\n  node->cardvalue = cardvalue;\n  node->prev = cardstack->last;\n  node->next = NULL;\n  if (isEmpty(cardstack))\n    cardstack->first = node;\n  else\n    cardstack->last->next = node;\n  cardstack->last = node;\n}\n\nint popFront(t_cardstack *cardstack) {\n  t_card *node;\n  int cardvalue;\n  if (isEmpty(cardstack))\n    return -1;\n  node = cardstack->first;\n  cardstack->first = node->next;\n  if (!cardstack->first)\n    cardstack->last = NULL;\n  else\n    cardstack->first->prev = NULL;\n  cardvalue = node->cardvalue;\n  free(node);\n  return cardvalue;\n}\n\nint popBack(t_cardstack *cardstack) {\n  t_card *node;\n  int cardvalue;\n  if (isEmpty(cardstack))\n    return -1;\n  node = cardstack->last;\n  cardstack->last = node->prev;\n  if (!cardstack->last)\n    cardstack->first = NULL;\n  else\n    cardstack->last->next = NULL;\n  cardvalue = node->cardvalue;\n  free(node);\n  return cardvalue;\n}\n\nint peekFront(t_cardstack *cardstack) {\n  if (isEmpty(cardstack))\n    return -1;\n  return cardstack->first->cardvalue;\n}\n\nint peekBack(t_cardstack *cardstack) {\n  if (isEmpty(cardstack))\n    return -1;\n  return cardstack->last->cardvalue;\n}\n\nvoid *fronttoback(t_cardstack *cardstack) {\n  if (isEmpty(cardstack))\n    return NULL;\n  t_card *currpointer = cardstack->last;\n  while (currpointer) {\n    printf(\"%d\\n\", currpointer->cardvalue);\n    currpointer = currpointer->prev;\n  }\n}\n\nint main() { \n  t_cardstack *ms;\n  // Remember to initialize!\n  return 0; \n}\n\n\n\n\n\n\n\n\nCompilers - a slight adaptation of the second problem in this lab.\nAlternating Current - try to come up with a characterization of when the wires can be untangled in terms of the symbols.\nLargest Rectangle in a Histogram - a fun problem. See if you can make use of the cardstack!"
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w03.html#es242.-data-structures-and-algorithms-i.",
    "href": "courses/2023/01-ES242/labs/lab-w03.html#es242.-data-structures-and-algorithms-i.",
    "title": "ES242. Data Structures and Algorithms I. Week 01 Lab",
    "section": "ES242. Data Structures and Algorithms I.",
    "text": "ES242. Data Structures and Algorithms I.\n\nLab 02\nBack to course page\n\n\n\n\n\n\nTheme: Stacks\n\n\n\n\n\n\n\n\n\nProblem 1. Linked Lists\n\n\n\n\n\n#include<stdio.h>\n#include<stdlib.h>\n\nint main()\n{\n  //node structure\n  struct node\n  {\n      int data;\n      struct node *next;\n  };\n\n  //declaring nodes\n  struct node *head,*middle,*last;\n\n  //allocating memory for each node\n  head   = malloc(sizeof(struct node));\n  middle = malloc(sizeof(struct node));\n  last   = malloc(sizeof(struct node));\n\n  //assigning values to each node\n  head->data   = 10;\n  middle->data = 20;\n  last->data   = 30;\n\n  //connecting each nodes. head->middle->last\n  head->next   = middle;\n  middle->next = last;\n  last->next   = NULL;\n\n  //temp is a reference for head pointer.\n  struct node *temp = head;\n\n  //till the node becomes null, printing each nodes data\n  while(temp != NULL)\n  {\n      printf(\"%d->\",temp->data);\n      temp = temp->next;\n  }\n  printf(\"NULL\");\n\n  return 0;\n}\nExtend the code above to perform the following tasks:\n\nRead a sequence of n numbers from the input, p_1, \\ldots, p_n.\nInsert each of these number at a location where the linked list is still sorted when read from beginning to end.\nFor any given input i, output the number in the linked list that comes before the number i.\n\n\nInput\nThe first line contains a positive integer n. The second line contains n space-separated integers. The third line contains a positive integer m.\n\n\nOutput\nOutput the number that comes before m in the linked list. It is guaranteed that m is one of the numbers from the second line. If the number happens to be the first element of the list, return -1.\n\n\n\n\n\n\n\n\n\n\nProblem 2. Parentheses\n\n\n\n\n\nYou are given a string consisting of parentheses ( and ). A string of this type is said to be correct:\n\nif it is the empty string\nif A and B are correct, AB is correct.\nif A is correct, (A) is correct.\n\nWrite a program that takes a sequence of strings of this of type and check their correctness.\nYour program can assume that the maximum string length is 128.\n\nInput\nThe first line of the input is a positive integer n, the number of tests. The next n lines consist of one test case each. Each test case is a string made of the parentheses ().\n\n\nOutput\nThe output should consist of n lines, one for each test. The i-th line of the ouptut should be Yes if the the string in the i-th test case is correct, and No otherwise.\n\nSample Input\n5\n(\n(((\n()()\n)\n)))\nNo\nNo\nYes\nNo\nNo\n\n\n\n\n\n\n\n\n\n\n\nProblem 3. Challenge the Parentheses Solution\n\n\n\n\n\nConsider the following algorithm for the previous problem:\nIf the first character is not ( return FALSE\nIf the last character is not ) return FALSE\nInitialize i = 0\nFor j in s:\n    if j == \"(\":\n        i++\n    else:\n        i--\nif i != 0 return FALSE\nelse return TRUE\nProvide an input for which the algorithm above does not work. Your input should be a single line consisting of a string that has ( and ) characters only.\n\n\n\n\n\n\n\n\n\nProblem 4. Print Alternate Cards\n\n\n\n\n\nAdd a set of cards to a stack and print all the cards in odd-numbered positions of the stack.\n\nI/O Format\nThe first line contains a number n, the number of cards in the stack. The next n lines contain two numbers. The first number b indicates if the card is to be added on the top (b=0) or at the bottom (b=1). The second number indicates the card’s value, an integer between 1 and 52.\nThe output should the list of alternating cards from bottom to top (i.e, starting at the card pointed to by the first pointer). If there are an even number of cards, note that the last card on the stack does not get printed.\nAdding a card on the top can be done by using pushBack, while adding it at the bottom pushFront.\n\nSample input\n5\n0 1\n0 2\n1 3\n1 5\n0 4\n\n\nSample output\n5\n1\n4\n\n\n\n\n\n\n\nThe Cardstack Data Structure\n\n\n\n\n\n\nNote\n\n\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct s_card {\n  int cardvalue;\n  struct s_card *next;\n  struct s_card *prev;\n} t_card;\n\ntypedef struct s_cardstack {\n  struct s_card *first;\n  struct s_card *last;\n} t_cardstack;\n\nt_cardstack *cardstackInit() {\n  t_cardstack *cardstack;\n  cardstack = malloc(sizeof(t_cardstack));\n  cardstack->first = NULL;\n  cardstack->last = NULL;\n  return cardstack;\n}\n\nint isEmpty(t_cardstack *cardstack) { return !cardstack->first; }\n\nvoid pushFront(t_cardstack *cardstack, int cardvalue) {\n  t_card *node = malloc(sizeof(t_card));\n  node->cardvalue = cardvalue;\n  node->prev = NULL;\n  node->next = cardstack->first;\n  if (isEmpty(cardstack))\n    cardstack->last = node;\n  else\n    cardstack->first->prev = node;\n  cardstack->first = node;\n}\n\nvoid pushBack(t_cardstack *cardstack, int cardvalue) {\n  t_card *node = malloc(sizeof(t_card));\n  node->cardvalue = cardvalue;\n  node->prev = cardstack->last;\n  node->next = NULL;\n  if (isEmpty(cardstack))\n    cardstack->first = node;\n  else\n    cardstack->last->next = node;\n  cardstack->last = node;\n}\n\nint popFront(t_cardstack *cardstack) {\n  t_card *node;\n  int cardvalue;\n  if (isEmpty(cardstack))\n    return -1;\n  node = cardstack->first;\n  cardstack->first = node->next;\n  if (!cardstack->first)\n    cardstack->last = NULL;\n  else\n    cardstack->first->prev = NULL;\n  cardvalue = node->cardvalue;\n  free(node);\n  return cardvalue;\n}\n\nint popBack(t_cardstack *cardstack) {\n  t_card *node;\n  int cardvalue;\n  if (isEmpty(cardstack))\n    return -1;\n  node = cardstack->last;\n  cardstack->last = node->prev;\n  if (!cardstack->last)\n    cardstack->first = NULL;\n  else\n    cardstack->last->next = NULL;\n  cardvalue = node->cardvalue;\n  free(node);\n  return cardvalue;\n}\n\nint peekFront(t_cardstack *cardstack) {\n  if (isEmpty(cardstack))\n    return -1;\n  return cardstack->first->cardvalue;\n}\n\nint peekBack(t_cardstack *cardstack) {\n  if (isEmpty(cardstack))\n    return -1;\n  return cardstack->last->cardvalue;\n}\n\nvoid *fronttoback(t_cardstack *cardstack) {\n  if (isEmpty(cardstack))\n    return NULL;\n  t_card *currpointer = cardstack->last;\n  while (currpointer) {\n    printf(\"%d\\n\", currpointer->cardvalue);\n    currpointer = currpointer->prev;\n  }\n}\n\nint main() { \n  t_cardstack *ms;\n  // Remember to initialize!\n  return 0; \n}"
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w03.html#input-1",
    "href": "courses/2023/01-ES242/labs/lab-w03.html#input-1",
    "title": "ES242. Data Structures and Algorithms I. Week 01 Lab",
    "section": "Input",
    "text": "Input\nThe first line of the input is a positive integer n, the number of tests. The next n lines consist of one test case each. Each test case is a string made of the parentheses ()."
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w03.html#output-1",
    "href": "courses/2023/01-ES242/labs/lab-w03.html#output-1",
    "title": "ES242. Data Structures and Algorithms I. Week 01 Lab",
    "section": "Output",
    "text": "Output\nThe output should consist of n lines, one for each test. The i-th line of the ouptut should be Yes if the the string in the i-th test case is correct, and No otherwise.\n\nSample Input\n5\n(\n(((\n()()\n)\n)))\nNo\nNo\nYes\nNo\nNo"
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w03.html#io-format",
    "href": "courses/2023/01-ES242/labs/lab-w03.html#io-format",
    "title": "ES242. Data Structures and Algorithms I. Week 01 Lab",
    "section": "I/O Format",
    "text": "I/O Format\nThe first line contains a number n, the number of cards in the stack. The next n lines contain two numbers. The first number b indicates if the card is to be added on the top (b=0) or at the bottom (b=1). The second number indicates the card’s value, an integer between 1 and 52.\nThe output should the list of alternating cards from bottom to top (i.e, starting at the card pointed to by the first pointer). If there are an even number of cards, note that the last card on the stack does not get printed.\nAdding a card on the top can be done by using pushBack, while adding it at the bottom pushFront.\n\nSample input\n5\n0 1\n0 2\n1 3\n1 5\n0 4\n\n\nSample output\n5\n1\n4"
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L05.html",
    "href": "courses/2023/01-CS614/quizzes/L05.html",
    "title": "CS614. Advanced Algorithms. L05 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Approximate Vertex Cover\n\n\n\nGive an example of a graph where the 2-approximate solution (via maximal matchings) is worse than the optimal one. Even just slightly worse is enough :)\n\n\n\n\n\n\n\n\nProblem 2. Approximate Independent Set\n\n\n\nSince the complement of a vertex cover is an independent set, you might be tempted to think that the approximation discussed in class also approximates independent set. In particular, consider the following algorithm for independent set:\n\nRun the 2-approximation for vertex cover discussed in class, let the output be S.\nLet I := V(G) \\setminus S.\nIf I = \\emptyset, then let v \\in V(G) be an arbitrary vertex; set I := \\{v\\}.\n\nLet:\n\np denote the size of a largest independent set in G\nq denote the size of the set obtained by taking the complement of the output of the 2-approximation discussed in class.\nr denote \\max(q,1)\n\nNote that r is the size of the independent set output by the algorithm above.\nCome up with a graph where p can be a factor of cn larger than r for some constant c.\n\n\n\n\n\n\n\n\nProblem 3. Vertex Cover Matroid\n\n\n\nDo the set of vertex covers in a graph G form a matroid over the universe V(G)? If not, select the axiom that fails:\n\nExchange Axiom\nHereditary Axiom\nVertex covers do form a matroid"
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/A05.html",
    "href": "courses/2023/01-CS614/quizzes/A05.html",
    "title": "CS614. Advanced Algorithms. L05 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Approximate Vertex Cover\n\n\n\nGive an example of a graph where the 2-approximate solution (via maximal matchings) is worse than the optimal one. Even just slightly worse is enough :)\n\n\n\n\n\n\n\n\nFollow up question\n\n\n\n\n\nWhat are examples of graphs where the 2-approximate solution via maximal matchings is close to optimal? The empty and complete graphs come to mind, are there others?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nEven if the input graph is an edge, a star, or a matching, the 2-approximate solution is already worse by a factor of two.\n\n\n\n\n\n\n\n\n\nProblem 2. Approximate Independent Set\n\n\n\nSince the complement of a vertex cover is an independent set, you might be tempted to think that the approximation discussed in class also approximates independent set. In particular, consider the following algorithm for independent set:\n\nRun the 2-approximation for vertex cover discussed in class, let the output be S.\nLet I := V(G) \\setminus S.\nIf I = \\emptyset, then let v \\in V(G) be an arbitrary vertex; set I := \\{v\\}.\n\nLet:\n\np denote the size of a largest independent set in G\nq denote the size of the set obtained by taking the complement of the output of the 2-approximation discussed in class.\nr denote \\max(q,1)\n\nNote that r is the size of the independent set output by the algorithm above.\nCome up with a graph where p can be a factor of cn larger than r for some constant c.\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n\nIt was not explicit in the question: G denotes the input graph and n denotes the number of vertices in G.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet n = 2p and consider a complete bipartite graph K_{p,p}. The optimal independent set has size p but the algorithm above returns 1.\n\n\n\n\n\n\n\n\n\nProblem 3. Vertex Cover Matroid\n\n\n\nDo the set of vertex covers in a graph G form a matroid over the universe V(G)? If not, select the axiom that fails:\n\nExchange Axiom\nHereditary Axiom\nVertex covers do form a matroid\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nA subset of a vertex cover need not be a vertex cover; and in particular, the empty set is also not a vertex cover (although this axiom was not offered as an option)."
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L06.html",
    "href": "courses/2023/01-CS614/quizzes/L06.html",
    "title": "CS614. Advanced Algorithms. L06 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the Coursera course on Approximation Algorithms taught by Mark de Berg.\n\n\n\n\n\n\n\n\nProblem 1. Changing the threshold\n\n\n\nConsider the algorithm LPAPX-WVC from the class.\n\n\n\n\n\n\nProblem 1.1 Increasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 2/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 1/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. Changing the rounding scheme\n\n\n\nConsider a different rounding strategy for the LP relaxation of the vertex cover problem. Instead of rounding up every vertex whose value is at least 0.5 after running the LP, we do the following:\nWe look at every edge, and then we round up the variable of the endpoint with the highest value, where in case of ties we take the endpoint with the highest index.\nIn other words, if the vertex set is V=\\left\\{v_1, \\ldots, v_n\\right\\} and we denote the associated variable of v_i by x_i then the cover C is computed as follows:\nC:=\\left\\{v_i \\in V:\\right. there is an edge \\left(v_i, v_j\\right) such that \\left(x_i>x_j\\right) or \\left(x_i=x_j\\right. and \\left.\\left.i>j\\right)\\right\\}\nWhich statement is true?\n\nThis does not work, because we might report an invalid solution.\nThis gives a valid solution, but the approximation ratio becomes worse.\nThis gives a valid solution, and in fact the solution is always exactly the same as in the original rounding scheme.\nThis gives a valid solution. We sometimes report a better solution than in the original rounding scheme, but the approximation ratio of the algorithm is still more than 2 - \\epsilon for any \\epsilon > 0.\nThis gives a valid solution, and the approximation ratio of the algorithm becomes 3/2.\n\n\n\n\n\n\n\n\n\nProblem 3. Lower Bound\n\n\n\nSuppose you have created an algorithm for a certain problem using LP relaxation and you want to say something about its approximation ratio. Which lower bound on the optimal solution can you use?\n\nThe solution to the 0/1-LP.\nThe solution to the relaxed LP.\nDepends on the problem.\n\n\n\n\n\n\n\n\n\nProblem 4. Integrality Gap\n\n\n\nWhat is the integrality gap of the vertex-cover LP for the complete graph on n vertices, where all vertices have weight 1?"
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/A06.html",
    "href": "courses/2023/01-CS614/quizzes/A06.html",
    "title": "CS614. Advanced Algorithms. L06 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the Coursera course on Approximation Algorithms taught by Mark de Berg.\n\n\n\n\n\n\n\n\nProblem 1. Changing the threshold\n\n\n\nConsider the algorithm LPAPX-WVC from the class.\n\n\n\n\n\n\nProblem 1.1 Increasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 2/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 1/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf we increase the threshold t beyond 0.5, then the output may not even be a vertex cover: for example, consider the example of a complete graph where the LPOPT sets all variables to 0.5: in this case our output will be the empty set with any threshold higher than 0.5.\nIf we decrease the threshold t below 0.5, then the output will be a vertex cover — indeed, if any edge (u,v) is uncovered, then both u and v were set to values less than t, and in particular less than 0.5, so we will violate our edge constraint just as we do when working with a threshold of 0.5. However, by choosing a lower value, we worsen the approximation ratio: in particular, if t = 1/3 then the output is a 3-approximation.\n\n\n\n\n\n\n\n\n\nProblem 2. Changing the rounding scheme\n\n\n\nConsider a different rounding strategy for the LP relaxation of the vertex cover problem. Instead of rounding up every vertex whose value is at least 0.5 after running the LP, we do the following:\nWe look at every edge, and then we round up the variable of the endpoint with the highest value, where in case of ties we take the endpoint with the highest index.\nIn other words, if the vertex set is V=\\left\\{v_1, \\ldots, v_n\\right\\} and we denote the associated variable of v_i by x_i then the cover C is computed as follows:\nC:=\\left\\{v_i \\in V:\\right. there is an edge \\left(v_i, v_j\\right) such that \\left(x_i>x_j\\right) or \\left(x_i=x_j\\right. and \\left.\\left.i>j\\right)\\right\\}\nWhich statement is true?\n\nThis does not work, because we might report an invalid solution.\nThis gives a valid solution, but the approximation ratio becomes worse.\nThis gives a valid solution, and in fact the solution is always exactly the same as in the original rounding scheme.\nThis gives a valid solution. We sometimes report a better solution than in the original rounding scheme, but the approximation ratio of the algorithm is still more than 2 - \\epsilon for any \\epsilon > 0.\nThis gives a valid solution, and the approximation ratio of the algorithm becomes 3/2.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe solution is valid: indeed, let (u,v) be an edge, and recall that the algorithm worked as follows:\nWe look at every edge, \nand then we round up the variable of the endpoint with the highest value, \nwhere in case of ties we take the endpoint with the highest index. \nSince one of the endpoints was rounded up, the edge is covered; and this is evidently true of every edge.\nThe solution with respect to this rounding may be better than the threshold-based rounding: for example, consider again a complete graph where the LPOPT sets all variables to 1/2: the threshold-based rounding leads to a solution of cost n, while the cost here will be strictly less.\nHowever, to see that the approximation ratio of the algorithm is still more than 2 - \\epsilon for any \\epsilon > 0, consider, for example, a cycle on n vertices: one can choose a suitably large value of n to bring the approximation ratio arbitrarily close to 2.\n\n\n\n\n\n\n\n\n\nProblem 3. Lower Bound\n\n\n\nSuppose you have created an algorithm for a certain problem using LP relaxation and you want to say something about its approximation ratio. Which lower bound on the optimal solution can you use?\n\nThe solution to the 0/1-LP.\nThe solution to the relaxed LP.\nDepends on the problem.\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n\nAs was clarified in class, this question is in the context of minimization problems.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe solution to the relaxed LP is a useful lower bound for the OPT. The value of the OPT for the 0/1-LP is exactly equal to the OPT (in a presumed exact formulation of the problem) and does not, by itself, provide information about the behavior of the relaxed LP.\n\n\n\n\n\n\n\n\n\nProblem 4. Integrality Gap\n\n\n\nWhat is the integrality gap of the vertex-cover LP for the complete graph on n vertices, where all vertices have weight 1?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nILPOPT = n-1 and LPOPT = n/2; so the integrality gap is 2 \\cdot (n-1)/n = 2(1 - \\frac{1}{n})."
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L07.html",
    "href": "courses/2023/01-CS614/quizzes/L07.html",
    "title": "CS614. Advanced Algorithms. L07 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the textbook on Parameterized Algorithms by Marek Cygan, Fedor V. Fomin, Łukasz Kowalik, Daniel Lokshtanov, Dániel Marx, Marcin Pilipczuk, Michał Pilipczuk, and Saket Saurabh.\n\n\n\n\n\n\n\n\nProblem 1. Cluster Vertex Deletion\n\n\n\nIn the Cluster Vertex Deletion problem, we want to know if a simple undirected graph G has a subset S of at most k vertices such that G \\setminus S is a disjoint union of cliques.\n\n\n\n\n\n\nProblem 1.1 A Branching Algorithm\n\n\n\nDesign a 3^k \\cdot n^{\\mathcal{O}(1)} algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nDesign a 3-approximation algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\n\n\nProblem 2. Don’t Satisfy Too Much!\n\n\n\nIn the MIN-2-SAT problem, we are given a 2 -CNF formula \\phi and an integer k, and the objective is to decide whether there exists an assignment for \\phi that satisfies at most k clauses.\nShow that MIN-2-SAT can be solved in time 2^k n^{\\mathcal{O}(1)}."
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/A07.html",
    "href": "courses/2023/01-CS614/quizzes/A07.html",
    "title": "CS614. Advanced Algorithms. L07 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the textbook on Parameterized Algorithms by Marek Cygan, Fedor V. Fomin, Łukasz Kowalik, Daniel Lokshtanov, Dániel Marx, Marcin Pilipczuk, Michał Pilipczuk, and Saket Saurabh.\n\n\n\n\n\n\n\n\nProblem 1. Cluster Vertex Deletion\n\n\n\nIn the Cluster Vertex Deletion problem, we want to know if a simple undirected graph G has a subset S of at most k vertices such that G \\setminus S is a disjoint union of cliques.\n\n\n\n\n\n\nProblem 1.1 A Branching Algorithm\n\n\n\nDesign a 3^k \\cdot n^{\\mathcal{O}(1)} algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nDesign a 3-approximation algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAs discussed in class, the induced path on three vertices is a forbidden substructure for a cluster graph. We state and prove this fact here for completeness.\n\nClaim. A graph G is a disjoint union of cliques if and only if it does not contain a path on three vertices as an induced subgraph.\nProof (sketch). Suppose G is a disjoint union of cliques, and for the sake of contradiction, suppose it has an induced path on vertices x,y,z with the edges being between x and y, and y and z. Note that since this is an induced path, there is no edge between x and z. Since every component of G is a clique, we know that x and z must be in different components. However, there is a path from x to z via y, which is a contradiction.\nSuppose G does not contain a path on three vertices as an induced subgraph. Again, for the sake of contradiction, suppose G has a connected component that is not a clique. Let (u,v) be a non-edge in this component. Let P be a shortest path between u and v consisting of the vertices:\nP := \\{u, w_1, \\ldots, w_t, \\ldots v\\}.\nNotice that t \\geqslant 1, otherwise (u,v) is an edge. Further, notice that u, w_1, w_2 forms an induced path of length three1 (if (u,w_2) was an edge then we have a shorter path by omitting w_1, contradicting our assumption that P is a shortest path between u and v). This contradicts our assumption.\n\nBased on this, we have the following algorithm:\nCVD(G,k):\n    If k <= 0 and G has an induced P3 - RETURN NO\n    If k >= 0 and G is a cluster graph - RETURN YES\n\n    Let a,b,c be vertices such that ab and bc are edges and ac is not an edge.\n\n    Return (CVD(G-a,k-1) OR CVD(G-b,k-1) OR (G-c,k-1))\nOne can obtain a 3-approximation by enumerating a maximal collection of disjoint induced P_3’s and including all vertices from the collection in the solution. If the collection has size t, we know that any solution (and in particular, the optimal one) must contain at least t vertices and the output has at most 3t vertices. The algorithm is summarized below:\nCVD-3-Approx(G):\n    Init S = emptyset\n\n    While there is an induced P3 = (x,y,z) in G:\n        include (x,y,z) in S\n        G = G - (x,y,z)\n\n    return S\n\n\n\n\n\n\n\n\n\nProblem 2. Don’t Satisfy Too Much!\n\n\n\nIn the MIN-2-SAT problem, we are given a 2-CNF formula \\phi and an integer k, and the objective is to decide whether there exists an assignment for \\phi that satisfies at most k clauses.\nShow that MIN-2-SAT can be solved in time 2^k n^{\\mathcal{O}(1)}.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf there is a variable x that occurs only positively in \\phi, we claim that there exists an optimal assignment that sets it to 0. Indeed, let \\tau be an assignment that sets x to 1. Let \\tau_x be the assignment obtained from \\tau by flipping the value of x from 1 to 0. Note that the clauses that do not contain the variable x are either satisfied or falsified in both \\tau and \\tau_x. For clauses that contain x, it is possible that they are satisfied by \\tau but not by \\tau_x, but not vice versa. Therefore, \\tau_x falsifies at least as many clauses as \\tau, and we are done.\nBased on this, our algorithm proceeds as follows:\nif there is a variable x that occurs only as a positive literal:\n    set x to 0\nif there is a variable x that occurs only as a negated literal:\n    set x to 1\nThe argument for the negated occurrences is symmetric to the one we have for positive literals.\nOnce we perform this preprocessing, assuming that have clauses remaining, we have the following guarantee:\n\nEvery variable has at least one positive and one negated occurrence.\n\nNow we can branch exhuastively on the settings of variables; with the promise that either setting of the variable reduces our budget by at least one. The overall algorithm is summarized in the following pseudocode:\nMINSAT(phi,k):\n    if there is a variable x that occurs only as a positive literal:\n        set x to 0\n    if there is a variable x that occurs only as a negated literal:\n        set x to 1\n\n    if phi is empty:\n        return YES\n    if phi is not empty and k <= 0:\n        return NO\n\n    Let x be any variable that occurs in phi.\n    return MINSAT(phi|[x = TRUE],k-1) OR MINSAT(phi|[x = FALSE],k-1)"
  },
  {
    "objectID": "courses/2023/01-ES242/quizzes/q03.html",
    "href": "courses/2023/01-ES242/quizzes/q03.html",
    "title": "ES242. Data Structures and Algorithms I. Quiz 03",
    "section": "",
    "text": "Issued: 19 Jan, 2023\nBack to course page\n\n\n\n\n\n\nProblem 1. Party Puzzle I\n\n\n\nThe following is true for n guests at a party:\n\nIn any group of three guests, there are two guests who do not know each other, and\nIn any group of seven guests, there are two guests who do know each other.\n\nAt the end of the party, everyone gives a present to all the guests he or she knows.\nThe total number of gifts given is at most:\n\n6n\n4n\n3n\nNone of the above\n\n\n\n\n\n\n\n\n\nProblem 2. Party Puzzle II\n\n\n\nIs it possible that there is a group of six people where there is no group of three guests who are mutual friends and there is no group of three guests who are mutual strangers?\n\nYes\nNo\n\nAssume that every pair of people are either mutual friends or mutual strangers.\n\n\n\n\n\n\n\n\nProblem 3. Party Puzzle III\n\n\n\nIs it possible that there is a group of five people where there is no group of three guests who are mutual friends and there is no group of three guests who are mutual strangers?\n\nYes\nNo\n\nAssume that every pair of people are either mutual friends or mutual strangers."
  },
  {
    "objectID": "courses/2023/01-ES242/quizzes/q04.html",
    "href": "courses/2023/01-ES242/quizzes/q04.html",
    "title": "ES242. Data Structures and Algorithms I. Quiz 04",
    "section": "",
    "text": "Issued: 24 Jan, 2023\nBack to course page\n\n\n\n\n\n\nProblem 1. Divide by two\n\n\n\nLet n be a number given in decimal notation. Divide the number by two and push the remainder of each division onto to a cardstack until the number is reduced to 0. Then we pop all elements from the bottom. What is the output?\n\nThe representation of n in binary.\nThe reverse of the representation of n in binary.\nMeaningless and has nothing to do with n.\n\n\n\n\n\n\n\n\n\nProblem 2. Stacks I\n\n\n\nYou have a sequence \\ell of A’s and B’s. You initialize an empty stack S.\nYou read the sequence \\ell from left to right. Every time you see an A, you push 0 on to S. Every time you see a B, you pop from S. You never had to pop from an empty stack, and at the end, your stack is empty. Which of the following is true?\n\nThe sequence \\ell does NOT have an equal number of A’s and B’s.\nThe sequence \\ell started with ABBA.\nFor any 1 \\leq k \\leq \\ell, if you read first k entries of the sequence \\ell the number of A’s is at least the number of B’s.\nFor any 1 \\leq k \\leq \\ell, if you read first k entries of the sequence \\ell the number of B’s is at least the number of A’s.\n\n\n\n\n\n\n\n\n\nProblem 3. Stacks II\n\n\n\nYou have a sequence \\ell of A’s and B’s. You initialize an empty stack S.\nYou read the sequence \\ell from left to right. Every time you see an A, you push 0 on to S. Every time you see a B, you pop from S. At some point, you had to stop because you were trying to pop from an empty stack. Which of the following is definitely true?\n\nThe sequence \\ell has an equal number of A’s and B’s.\nThe sequence \\ell started with ABBA.\nFor some 1 \\leq k \\leq \\ell, if you read first k entries of the sequence \\ell the number of A’s is strictly more than the number of B’s.\nFor some 1 \\leq k \\leq \\ell, if you read first k entries of the sequence \\ell the number of B’s is strictly more than the number of A’s.\n\n\n\n\n\n\n\n\n\nProblem 3. Navigate this apartment\n\n\n\nConsider the floor plan shown below of a 5-room apartment.\nCan you find a continuous line that pass through each door exactly once? The line does not have to end where it started. Note that there is space to move around the big enclosing rectangle.\n\n\n\nA floor plan\n\n\n\nYes\nNo"
  },
  {
    "objectID": "courses/2023/01-ES242/quizzes/a03.html",
    "href": "courses/2023/01-ES242/quizzes/a03.html",
    "title": "ES242. Data Structures and Algorithms I. Quiz 03",
    "section": "",
    "text": "Issued: 19 Jan, 2023\nBack to course page\n\n\n\n\n\n\nProblem 1. Party Puzzle I\n\n\n\nThe following is true for n guests at a party:\n\nIn any group of three guests, there are two guests who do not know each other, and\nIn any group of seven guests, there are two guests who do know each other.\n\nAt the end of the party, everyone gives a present to all the guests he or she knows.\nThe total number of gifts given is at most:\n\n6n\n4n\n3n\nNone of the above\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nObserve that every guest knows at most six people: indeed, if some guest (say P) knows seven people, among the people s/he knows, there must be a pair (say A and B) that know each other; but then we would have a group of three guests, consisting of P, A, and B who all know each other, which contradicts the first condition. So the number of relationships leading to the giving of gifts in this party is at most 6n (summing up, for all guests, the people they know), so 6n is a valid upper bound for the total number of gifts given.\nThere can be parties where more than 4n gifts are given. For example, consider a party where there are two groups of six people each: call these groups X and Y. Suppose everyone in X knows everyone in Y and vice versa, but no pair of people in group X know each other and no pair of people in Y know each other either. Then there are 12 people, each of whom give six gifts each, amounting to a total of 72 gifts being given, which is more than 4n = 4 \\cdot 12 = 48.\n\n\n\n\n\n\n\n\n\nProblem 2. Party Puzzle II\n\n\n\nIs it possible that there is a group of six people where there is no group of three guests who are mutual friends and there is no group of three guests who are mutual strangers?\n\nYes\nNo\n\nAssume that every pair of people are either mutual friends or mutual strangers.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe answer is: NO.\nConsider any person P in a party of six people and note that they either:\n\nknow three people or more, or\ndo not know three people or more.\n\nIndeed, if neither of the above holds, then they:\n\nknow at most two people, and\ndo not know at most two people,\n\nbut this only accounts for four people among the remaining five.\nNow suppose P knows three people: call them A, B, C. If any pair of these three people know each other, then we have three guests who are mutual friends: P along with this pair. If not, then we have a group of three guests who are mutual strangers. So at least one of these two scenarios is always unavoidable.\n\n\n\n\n\n\n\n\n\nProblem 3. Party Puzzle III\n\n\n\nIs it possible that there is a group of five people where there is no group of three guests who are mutual friends and there is no group of three guests who are mutual strangers?\n\nYes\nNo\n\nAssume that every pair of people are either mutual friends or mutual strangers.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe answer is: YES.\nConsider five people A, B, C, D, and E; where:\n\nA knows B\nB knows C\nC knows D\nD knows E\nE knows A\n\nDrawn out as a graph (with undirected edges representing the “knowing each other” relationship, which was given to be mutual), this will look like a pentagon or a cycle on five vertices. Note that there is no triangle, and no subset of three vertices with no edges between them. This is equivalent to saying that there is no group of three guests who are mutual friends and there is no group of three guests who are mutual strangers, as asked."
  },
  {
    "objectID": "courses/2023/01-ES242/quizzes/a04.html",
    "href": "courses/2023/01-ES242/quizzes/a04.html",
    "title": "ES242. Data Structures and Algorithms I. Quiz 04",
    "section": "",
    "text": "Issued: 24 Jan, 2023\nBack to course page\n\n\n\n\n\n\nProblem 1. Divide by two\n\n\n\nLet n be a number given in decimal notation. Divide the number by two and push the remainder of each division onto to a cardstack until the number is reduced to 0. Then we pop all elements from the bottom. What is the output?\n\nThe representation of n in binary.\nThe reverse of the representation of n in binary.\nMeaningless and has nothing to do with n.\n\n\n\n\n\n\n\n\n\nClarification\n\n\n\nWhen we say “until the number is reduced to 0”, the successive divisions are meant to be applied on the quotient obtained from the previous divison operation. Also, note that we push to the top and pop from the bottom of the stack.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis is the standard algorithm for converting a number from decimal to binary notation. Let us look at an example execution with the number 19:\n\nthe first divison yields a remainder of 1 with a quotient of 9,\nthe second divison yields a remainder of 1 with a quotient of 4,\nthe third divison yields a remainder of 0 with a quotient of 2,\nthe fourth divison yields a remainder of 0 with a quotient of 1,\nthe fifth divison yields a remainder of 1 with a quotient of 0,\n\nWe push 1, 1, 0, 0, and 1 on to the stack in that order. We pop from the bottom, so the output we get is the numbers pushed on to the stack in the same order as they were pushed: 11001 — note that if we popped from the top, then the output would have reversed this order.\nThe correct answer is that the output is the reverse of the representation of n in binary. We omit here a formal justification of this fact, but you can convince yourself by combining your understanding of the standard conversion algorithm along with the behavior of the stack operations.\n\n\n\n\n\n\n\n\n\nProblem 2. Stacks I\n\n\n\nYou have a sequence \\ell of A’s and B’s. You initialize an empty stack S.\nYou read the sequence \\ell from left to right. Every time you see an A, you push 0 on to S. Every time you see a B, you pop from S. You never had to pop from an empty stack, and at the end, your stack is empty. Which of the following is true?\n\nThe sequence \\ell does NOT have an equal number of A’s and B’s.\nThe sequence \\ell started with ABBA.\nFor any 1 \\leq k \\leq \\ell, if you read first k entries of the sequence \\ell the number of A’s is at least the number of B’s.\nFor any 1 \\leq k \\leq \\ell, if you read first k entries of the sequence \\ell the number of B’s is at least the number of A’s.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSince the described behavior of the stack implicitly guarantees a bijection between the A’s and B’s in the string, the first option is not true. Also, consider the sequence \\ell given by AB. It matches the described behavior, and does not begin with ABBA, so the second and fourth options are also false (set k = 1 for option four).\nTo see that the third option is indeed true, notice that if it was not, then there exists some k \\in [\\ell] for which the first k entries of the sequence \\ell have strictly more B’s than A’s, but in this situation notice that we would have to attempt popping from an empty stack: but it is promised that this does happen.\n\n\n\n\n\n\n\n\n\nProblem 3. Stacks II\n\n\n\nYou have a sequence \\ell of A’s and B’s. You initialize an empty stack S.\nYou read the sequence \\ell from left to right. Every time you see an A, you push 0 on to S. Every time you see a B, you pop from S. At some point, you had to stop because you were trying to pop from an empty stack. Which of the following is definitely true?\n\nThe sequence \\ell has an equal number of A’s and B’s.\nThe sequence \\ell started with ABBA.\nFor some 1 \\leq k \\leq \\ell, if you read first k entries of the sequence \\ell the number of A’s is strictly more than the number of B’s.\nFor some 1 \\leq k \\leq \\ell, if you read first k entries of the sequence \\ell the number of B’s is strictly more than the number of A’s.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe first option is not definitely true: for example, the sequence ABB would match the described behavior and does not have an equal number of A’s and B’s. The second option is also not necessarily true for similar reasons. The example of the sequence B rules out the third option. Note that the fourth option must be true, because if it were not, then we would have the behavior described in the previous question instead of what is described here.\n\n\n\n\n\n\n\n\n\nProblem 3. Navigate this apartment\n\n\n\nConsider the floor plan shown below of a 5-room apartment.\nCan you find a continuous line that pass through each door exactly once? The line does not have to end where it started. Note that there is space to move around the big enclosing rectangle.\n\n\n\nA floor plan\n\n\n\nYes\nNo\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNote that three rooms have five doors, so such a path is not possible."
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w04.html",
    "href": "courses/2023/01-ES242/labs/lab-w04.html",
    "title": "ES242. Data Structures and Algorithms I. Week 04 Lab",
    "section": "",
    "text": "Back to course page\n\n\n\n\n\n\nTheme: Graph Representations and Euler Tours\n\n\n\n\n\n\n\n\n\nProblem 1. Adjacency Matrix\n\n\n\n\n\nThe goal of this exercise is to:\n\nRead a graph and store it as an adjacency matrix.\nReturn the largest degree, that is to say, return max(d(v)) over all vertices v in the graph G.\n\n\nYou can visualize the execution of a simplified version of the template code here.\n\n\nThe first line of input is two space-separated integers n and m, denoting the number of vertices and edges of G, respectively. Vertices are indexed from 0 to n-1.\nThe next m lines of code are two space separated integers u and v in the range 0 and n-1, indicating an (undirected) edge between vertices u and v.\n\n\n\nThe output is a single integer, corresponding to the maximum degree of the graph.\n\n\n\nSample Input\n5 4\n0 1\n0 2\n0 3\n0 4\nSample Output\n4\n\n\n\n// Adjacency Matrix representation in C\n#include <stdio.h>\n\nint main() {\n  int n;\n  scanf(\"%d\", &n);\n\n  int m;\n  scanf(\"%d\", &m);\n\n  int G[n][n];\n  for (int i = 0; i < n; i++)\n    for (int j = 0; j < n; j++)\n      G[i][j] = 0;\n\n  for (int i = 0; i < m; i++) {\n    // Write the logic to read the endpoints of the edge here.\n    // ...\n    \n    // Write the logic to add the edge just read next.\n    // ...\n  }\n\n  int maxdegree = 0;\n\n  // Write the logic to print the maxdegree of the graph here.\n  // ...\n\n  printf(\"%d\", maxdegree);\n  return 0;\n\n}\n\n\n\n\n\n\n\n\n\n\nProblem 2. Adjacency List\n\n\n\n\n\nIn this exercise your goal is to implement a graph as an adjacency list and determine, given a pair of vertices u and v, the number of common nieghbors that they have: that is, the number of vertices w such that w is adjacent to u AND w is adjacent to v (note that w is not equal to either u or v).\nYou can visualize the execution of a simplified version of the template code here.\n\n\nThe first line of input is two space-separated integers n and m, denoting the number of vertices and edges of G, respectively. Vertices are indexed from 0 to n-1.\nThe next m lines of code are two space separated integers u and v in the range 0 and n-1, indicating an (undirected) edge between vertices u and v.\nThe last line is a pair of space-separated integers x and y.\n\n\n\nThe output is a single integer, corresponding to the number of common neighbors of x and y.\n\n\n\nSample Input\n6 8\n0 1\n0 2\n0 3\n0 4\n5 1\n5 2\n5 3\n5 4\n0 5\nSample Output\n4\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n\n// A structure to represent an adjacency list node\nstruct AdjListNode {\n  int vertex;\n  struct AdjListNode *next;\n};\n\n// A structure to represent a graph. A graph is an array of adjacency lists.\n// Size of array will be V (number of vertices in graph)\nstruct Graph {\n  int n;\n  struct AdjListNode* vertices;\n};\n\n// A utility function to create a new adjacency list node\nstruct AdjListNode* newAdjListNode(int v) {\n  struct AdjListNode *newNode =\n      (struct AdjListNode *)malloc(sizeof(struct AdjListNode));\n  newNode->vertex = v;\n  newNode->next = NULL;\n  return newNode;\n}\n\n// A utility function that creates a graph of V vertices\nstruct Graph *createGraph(int V) {\n  struct Graph *graph = (struct Graph*)malloc(sizeof(struct Graph));\n  graph->n = V;\n  \n  graph->vertices = (struct AdjListNode*) malloc(V * sizeof(struct AdjListNode));\n  int i;\n  for (i = 0; i < V; ++i){\n    graph->vertices[i].next = NULL;\n    graph->vertices[i].vertex = -1;\n  }\n\n  return graph;\n}\n\n// Adds an edge to an undirected graph\nvoid addEdge(struct Graph *graph, int src, int dest) {\n  // Add an edge from src to dest.  A new node is added to the adjacency\n  // list of src.  The node is added at the begining\n  struct AdjListNode *newNode = newAdjListNode(dest);\n  newNode->next = graph->vertices[src].next;\n  graph->vertices[src].next = newNode;\n\n  // Since graph is undirected, add an edge from dest to src also. Write this part below.\n  // ...\n}\n\nint main() {\n\n  int n;\n  scanf(\"%d\", &n);\n\n  struct Graph *G = createGraph(n);\n\n  int m;\n  scanf(\"%d\", &m);\n\n  for (int i = 0; i < m; i++) {\n    int u, v;\n    scanf(\"%d\", &u);\n    scanf(\"%d\", &v);\n    addEdge(G, u, v);\n  }\n\n  int x, y;\n  \n  scanf(\"%d %d\", &x, &y);\n\n  // Write your solution here.\n  \n  return 0;\n}\n\n\n\n\n\n\n\n\n\n\nProblem 3. Edge List\n\n\n\n\n\nYou have to store the edges of a given graph as an edge list, and compute the degree of a given vertex.\nFor understanding how the template code works refer to this execution on a hard-coded example.\n\n\nThe first line contains a number m, which is the number of edges in the graph G.\nThe next m lines contain two space-separated integers represnting the endpoints of the edges.\nThe last line contains a single integer k.\n\n\n\nThe task is to report the degree of the vertex k, that is, the number of edges for which k is one of the endpoints.\n\n\n\nSample Input\n6\n1 3\n2 1\n5 3\n1 7\n1 8\n2 5\n1\nSample Output\n4\n\n\n\n#include <stdio.h>\n\n// Declare a datatype that stores a single edge.\n\nstruct SingleEdge {\n  int ep[2];\n  struct SingleEdge *nextedge;\n};\n\nint main(void) {\n\n  // To begin with, there was nothing.\n  struct SingleEdge *head = NULL;\n  head = (struct SingleEdge *)malloc(sizeof(struct SingleEdge));\n\n  struct SingleEdge *current = NULL;\n  current = (struct SingleEdge *)malloc(sizeof(struct SingleEdge));\n\n  // head simply points to the first element of the list.\n  // current will move forward as things get added.\n\n  head->ep[0] = -1;\n  head->ep[1] = -1;\n  head->nextedge = current;\n\n  // Read the number of edges.\n\n  int m;\n  scanf(\"%d\", &m);\n\n  for (int i = 0; i < m; i++) {\n\n    struct SingleEdge *newedge;\n\n    newedge = (struct SingleEdge *)malloc(sizeof(struct SingleEdge));\n\n    // Populate the newedge struct\n    // with information about the current edge.\n\n    current->nextedge = newedge;\n    current = newedge;\n  }\n\n  struct SingleEdge *navigator = head->nextedge;\n  int degree = 0;\n  int vertex;\n\n  scanf(\"%d\", &vertex);\n\n  while (navigator) {\n    // CHECK IF \"vertex\" is an endpoint\n    // of the current edge being explored.\n    if (...) {\n      degree = degree + 1;\n    }\n    navigator = navigator->nextedge;\n  }\n\n  printf(\"%d\", degree);\n\n  return 0;\n}\n\n\n\n\n\n\n\n\n\n\nProblem 4. Sanity Check\n\n\n\n\n\nGiven a simple (no selfloops or multiedges), connected (any two vertices are reachable from each other), and undirected (no edge orientations) graph as input, return YES if it has a Euler path OR circuit, and NO otherwise.\nYou may assume the following:\n\nAn undirected graph has an Eulerian cycle if and only if every vertex has even degree, and all of its vertices with nonzero degree belong to a single connected component.\nAn undirected graph has an Eulerian path if and only if exactly zero or two vertices have odd degree, and all of its vertices with nonzero degree belong to a single connected component.\n\n\n\nThe first line of input is two space-separated integers n and m, denoting the number of vertices and edges of G, respectively. Vertices are indexed from 0 to n-1.\nThe next m lines of code are two space separated integers u and v in the range 0 and n-1, indicating an (undirected) edge between vertices u and v.\n\n\n\nOutput YES if it has a Euler path or circuit, and NO otherwise.\n\n\n\nSample Input\n10 6\n1 3\n2 1\n5 3\n1 7\n1 8\n2 5\nSample Output\nYES\n\n\n\n\n\n\n\n\n\n\nProblem 5. [Optional] Which Way is the Highway?\n\n\n\n\n\nImagine a grid country with nm axis-parallel highways (no kidding: check out this video about the U.S. interstate highway numbering system! - watching the video is not required for understanding this problem).\nOf these highways, n are east-west and m are north-south. Note that the highways form an (n - 1) \\times (m - 1) grid. In order to control the traffic, a policy was enforced which involved making each highway one way.\nThis means in each east-west highway, the traffic moves from “left to right” or “right to left”. Also, traffic moves “top to bottom” or “bottom to top” in each highway that runs north-south. It is possible to enter a horizontal highway from a vertical highway, or vice versa, at their intersection.\nA proposed set of orientations is given to you. You have to figure out if it is possible, after making the highways one-way based on these suggested orientations, if it is possible to reach any intersection from any other (without breaking traffic rules!)\n\n\nThe first line of input contains two integers n and m, denoting the number of east-west highways and the number of north-south highways.\nThe second line contains a string of length n, made of characters ‘{’ and ‘}’, denoting direction of each horizontal highway. If the i-th character is equal to ‘{’, the highway is directed from right to left otherwise, the highway is directed from left to right. Highways are listed in order from top to bottom.\nThe third line contains a string of length m, made of characters ‘B’ and ‘T’, denoting direction of each vertical highway. If the i-th character is equal to ‘T’, the highway is directed from south to north (towards the top), and if it is ‘B’ the highway is directed from north to south (towards the bottom). Highways are listed in order from left to right.\n\n\n\nIf the given pattern meets the mayor’s criteria, print a single line containing “YES”, otherwise print a single line containing “NO”.\n\n\n\nSample Input\n3 3\n}{}\nBTB\nSample Output\nNO\nSample Input\n4 6\n{}{}\nBTBTBT\nSample Output\nYES\n\n\n\n\n\n\n\n\n\n\nProblem 6. [Optional] Edge Orientation Puzzle\n\n\n\n\n\nLet’s say that a vertex in a directed graph is balanced if its indegree is the same as its outdegree.\nYou are given a simple and undirected graph G. An orientation of G is an assigment of a direction to every edge in G.\nYou want to come up with an orientation that maximizes the number of balanced vertices.\nReturn the number of balanced vertices in a orientation that maximizes this number.\n\n\nThe first line contains a positive integer t~(1 \\leqslant t \\leqslant 200) — the number of testsets in the input.\nEach of the testsets is given in the following way.\nThe first line contains two integers n and m (1 \\leqslant n \\leqslant 200, 0 \\leqslant m \\leqslant n·(n - 1) / 2) — the number of vertices and the number of edges in G.\nThe next m lines contain the description of the edges. Each line contains two integers u and v (1 \\leqslant u, v \\leqslant n) — the endpoints of the edge. It’s guaranteed that there are no self-loops and multiedges. It is possible that the graph is not connected.\n\n\n\nFor each testset print the number of balanced vertices in an orientation that maximizes the number of balanced vertices.\n\n\n\nSample Input\n2\n5 5\n2 1\n4 5\n2 3\n1 3\n3 5\n7 2\n3 7\n4 2\nSample Output\n3\n3\nHere is an orientation of the first graph that has three balanced vertices:\n1 3\n3 5\n5 4\n3 2\n2 1\nIn the second graph, no matter how the two edges are oriented, there will be four imbalanced and three balanced vertices.\n\n\n\n\n\n\n\n\n\nWeird Journey - if you already know how to check if a graph is connected, go for this! Otherwise you could come back to it after learning BFS/DFS :)\nROOKPATH - can you figure out how to model this problem as finding an Euler Tour?\nMashtali: a Space Oddysey - at least one method of solving this question involves constructing an Euler tour (but it is less direct than the previous problem), revisit it once you have figured out how to."
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w05.html",
    "href": "courses/2023/01-ES242/labs/lab-w05.html",
    "title": "ES242. Data Structures and Algorithms I. Week 05 Lab",
    "section": "",
    "text": ":::{.column-body-outset}"
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w05.html#es242.-data-structures-and-algorithms-i.",
    "href": "courses/2023/01-ES242/labs/lab-w05.html#es242.-data-structures-and-algorithms-i.",
    "title": "ES242. Data Structures and Algorithms I. Week 05 Lab",
    "section": "ES242. Data Structures and Algorithms I.",
    "text": "ES242. Data Structures and Algorithms I.\n\nLab 05\nBack to course page\n\n\n\n\n\n\nBreadth First Search\n\n\n\n\n\n\n\n\n\nProblem 1. Implement BFS\n\n\n\n\n\nIn this exercise your goal is to output a BFS traversal of a given graph G starting from a given source s.\n\nInput Format\nThe first line of input is three space-separated integers n, m and s, denoting the number of vertices and edges of G, and the id of the source vertex, respectively. Vertices are indexed from 0 to n-1.\nThe next m lines of code are two space separated integers u and v in the range 0 and n-1, indicating an (undirected) edge between vertices u and v.\nThe last line is a pair of space-separated integers x and y.\n\n\nOutput Format\nThe output is formatted as follows: if the BFS lasts for t rounds, there are t lines of output. The i-th line consists of a space-separated list of the vertices visited by BFS in the i-th round of the traversal in increasing order of labels.\n\n\nSample I/O\nSample Input\n6 8 0\n0 1\n0 2\n0 3\n0 4\n5 1\n5 2\n5 3\n5 4\nSample Output\n0\n1 2 3 4\n5\n\n\n\n\n\n\n\n\n\n\nProblem 2. Unique Servers\n\n\n\n\n\nNetworking company Dagm is reponsible for extending internet services to town Xelo with n devices. To deploy such services, and guarantee their connection to the internet, Dagm has set up x services in its head office.\nYou are given a matrix same_server[n][n] which denotes if two devices are always connected to the same server. It implies, same_serve[i][j]=1 if device i and j are facilitated by the same server. Else, it is 0.\nYour task is compute the number x. That is, the number of unique servers set up by Dagm.\nYou are asked to complete the count_unique_servers() function in line 8\nConsider the illustration below:\n\n\n\nAn Example\n\n\nHere, number of unique servers is 2 (S1 and S2).\n\nInput Format\nThe first line contains an integer n, the number of devices in the city. The next n input line contains n space separated integers (0 or 1).\n\n\nOutput Format\nOutput a single number representing the answer.\nSample Input 1\n7\n1 1 1 0 1 0 0\n1 1 1 0 1 0 0\n1 1 1 0 1 0 0\n0 0 0 1 0 1 1\n1 1 1 0 1 0 0\n0 0 0 1 0 1 1\n0 0 0 1 0 1 1\nSample Output 1\n2\n\nSample Input 2\n10 \n1 0 0 0 0 0 0 0 0 0\n0 1 0 0 0 0 0 0 0 0\n0 0 1 0 0 0 0 0 0 0\n0 0 0 1 0 0 0 0 0 0\n0 0 0 0 1 0 0 0 0 0\n0 0 0 0 0 1 0 0 0 0\n0 0 0 0 0 0 1 0 0 0\n0 0 0 0 0 0 0 1 0 0\n0 0 0 0 0 0 0 0 1 0\n0 0 0 0 0 0 0 0 0 1\nSample Output 2\n10"
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w05.html#list-of-practice-problems",
    "href": "courses/2023/01-ES242/labs/lab-w05.html#list-of-practice-problems",
    "title": "ES242. Data Structures and Algorithms I. Week 05 Lab",
    "section": "List of Practice Problems",
    "text": "List of Practice Problems\n\nWonderland Chase This Google Code Jam Finals problem from 2022 has a small test case that can be solved by brute force but you’d need to apply BFS to solve the advanced test set.\nBlizzard Basin This Day 24 AoC question from 2022 involves a constantly changing graph. Can you make your way out? Give it a shot!"
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w06.html",
    "href": "courses/2023/01-ES242/labs/lab-w06.html",
    "title": "ES242. Data Structures and Algorithms I. Week 06 Lab",
    "section": "",
    "text": "Back to course page\n\n\n\n\n\n\nBreadth First Search\n\n\n\n\n\n\n\n\n\nProblem 1. Implement BFS\n\n\n\n\n\nIn this exercise your goal is to output a BFS traversal of a given graph G starting from a given source s.\n\n\nThe first line of input is three space-separated integers n, m and s, denoting the number of vertices and edges of G, and the id of the source vertex, respectively. Vertices are indexed from 0 to n-1.\nThe next m lines of code are two space separated integers u and v in the range 0 and n-1, indicating an (undirected) edge between vertices u and v.\nThe last line is a pair of space-separated integers x and y.\n\n\n\nThe output is formatted as follows: if the BFS lasts for t rounds, there are t lines of output. The i-th line consists of a space-separated list of the vertices visited by BFS in the i-th round of the traversal in increasing order of labels.\n\n\n\nSample Input\n6 8 0\n0 1\n0 2\n0 3\n0 4\n5 1\n5 2\n5 3\n5 4\nSample Output\n0\n1 2 3 4\n5\n\n\n\n\nNote. This was a worked out example and the code is here. Please note that there some very minor changes from the version discussed in class to account for proper printing of whitespace in the output.\n\n\n\n\n\n\nProblem 2. Unique Servers\n\n\n\n\n\nNetworking company Dagm is reponsible for extending internet services to town Xelo with n devices. To deploy such services, and guarantee their connection to the internet, Dagm has set up x services in its head office.\nYou are given a matrix same_server[n][n] which denotes if two devices are always connected to the same server. It implies, same_serve[i][j]=1 if device i and j are facilitated by the same server. Else, it is 0.\nYour task is compute the number x. That is, the number of unique servers set up by Dagm.\nYou are asked to complete the count_unique_servers() function in line 8\nConsider the illustration below:\n\n\n\nAn Example\n\n\nHere, number of unique servers is 2 (S1 and S2).\n\n\nThe first line contains an integer n, the number of devices in the city. The next n input line contains n space separated integers (0 or 1).\n\n\n\nOutput a single number representing the answer.\nSample Input 1\n7\n1 1 1 0 1 0 0\n1 1 1 0 1 0 0\n1 1 1 0 1 0 0\n0 0 0 1 0 1 1\n1 1 1 0 1 0 0\n0 0 0 1 0 1 1\n0 0 0 1 0 1 1\nSample Output 1\n2\n\nSample Input 2\n10 \n1 0 0 0 0 0 0 0 0 0\n0 1 0 0 0 0 0 0 0 0\n0 0 1 0 0 0 0 0 0 0\n0 0 0 1 0 0 0 0 0 0\n0 0 0 0 1 0 0 0 0 0\n0 0 0 0 0 1 0 0 0 0\n0 0 0 0 0 0 1 0 0 0\n0 0 0 0 0 0 0 1 0 0\n0 0 0 0 0 0 0 0 1 0\n0 0 0 0 0 0 0 0 0 1\nSample Output 2\n10\n\n\n\n\n\n\n\n\n\nWonderland Chase This Google Code Jam Finals problem from 2022 has a small test case that can be solved by brute force but you’d need to apply BFS to solve the advanced test set.\nBlizzard Basin This Day 24 AoC question from 2022 involves a constantly changing graph. Can you make your way out? Give it a shot!"
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w06.html#es242.-data-structures-and-algorithms-i.",
    "href": "courses/2023/01-ES242/labs/lab-w06.html#es242.-data-structures-and-algorithms-i.",
    "title": "ES242. Data Structures and Algorithms I. Week 06 Lab",
    "section": "ES242. Data Structures and Algorithms I.",
    "text": "ES242. Data Structures and Algorithms I.\n\nLab 06\nBack to course page\n\n\n\n\n\n\nBreadth First Search\n\n\n\n\n\n\n\n\n\nProblem 1. Implement BFS\n\n\n\n\n\nIn this exercise your goal is to output a BFS traversal of a given graph G starting from a given source s.\n\nInput Format\nThe first line of input is three space-separated integers n, m and s, denoting the number of vertices and edges of G, and the id of the source vertex, respectively. Vertices are indexed from 0 to n-1.\nThe next m lines of code are two space separated integers u and v in the range 0 and n-1, indicating an (undirected) edge between vertices u and v.\nThe last line is a pair of space-separated integers x and y.\n\n\nOutput Format\nThe output is formatted as follows: if the BFS lasts for t rounds, there are t lines of output. The i-th line consists of a space-separated list of the vertices visited by BFS in the i-th round of the traversal in increasing order of labels.\n\n\nSample I/O\nSample Input\n6 8 0\n0 1\n0 2\n0 3\n0 4\n5 1\n5 2\n5 3\n5 4\nSample Output\n0\n1 2 3 4\n5\n\n\n\n\n\n\n\n\n\n\nProblem 2. Unique Servers\n\n\n\n\n\nNetworking company Dagm is reponsible for extending internet services to town Xelo with n devices. To deploy such services, and guarantee their connection to the internet, Dagm has set up x services in its head office.\nYou are given a matrix same_server[n][n] which denotes if two devices are always connected to the same server. It implies, same_serve[i][j]=1 if device i and j are facilitated by the same server. Else, it is 0.\nYour task is compute the number x. That is, the number of unique servers set up by Dagm.\nYou are asked to complete the count_unique_servers() function in line 8\nConsider the illustration below:\n\n\n\nAn Example\n\n\nHere, number of unique servers is 2 (S1 and S2).\n\nInput Format\nThe first line contains an integer n, the number of devices in the city. The next n input line contains n space separated integers (0 or 1).\n\n\nOutput Format\nOutput a single number representing the answer.\nSample Input 1\n7\n1 1 1 0 1 0 0\n1 1 1 0 1 0 0\n1 1 1 0 1 0 0\n0 0 0 1 0 1 1\n1 1 1 0 1 0 0\n0 0 0 1 0 1 1\n0 0 0 1 0 1 1\nSample Output 1\n2\n\nSample Input 2\n10 \n1 0 0 0 0 0 0 0 0 0\n0 1 0 0 0 0 0 0 0 0\n0 0 1 0 0 0 0 0 0 0\n0 0 0 1 0 0 0 0 0 0\n0 0 0 0 1 0 0 0 0 0\n0 0 0 0 0 1 0 0 0 0\n0 0 0 0 0 0 1 0 0 0\n0 0 0 0 0 0 0 1 0 0\n0 0 0 0 0 0 0 0 1 0\n0 0 0 0 0 0 0 0 0 1\nSample Output 2\n10"
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w06.html#list-of-practice-problems",
    "href": "courses/2023/01-ES242/labs/lab-w06.html#list-of-practice-problems",
    "title": "ES242. Data Structures and Algorithms I. Week 06 Lab",
    "section": "List of Practice Problems",
    "text": "List of Practice Problems\n\nWonderland Chase This Google Code Jam Finals problem from 2022 has a small test case that can be solved by brute force but you’d need to apply BFS to solve the advanced test set.\nBlizzard Basin This Day 24 AoC question from 2022 involves a constantly changing graph. Can you make your way out? Give it a shot!"
  },
  {
    "objectID": "courses/2023/01-ES242/exams/exam01.html",
    "href": "courses/2023/01-ES242/exams/exam01.html",
    "title": "ES242. Data Structures and Algorithms I. Exam 01",
    "section": "",
    "text": "Issued: 16 Feb, 2023\nBack to course page\n\n\n\n\n\n\nInstructions\n\n\n\nWe will have Exam 1 at the usual classroom venue. The exam will be released on Gradescope by 9:05PM, and will be available until 10:30PM.\nAll questions are multiple choice or require a numeric answer. Do not enter any explanations for any questions. If required, we will follow up with individual vivas to understand any alternate explanations you had in mind.\nYou have been asked to rate your confidence for all answers that you give. Please see this slide for the grading scheme and instructions.\nAny violations of the honor code (in particular including, but not limited to, communicating during the quiz, or using the internet for anything other than looking up the official course materials) will be reported and will result in a F grade in the course.\n\n\n\n\n\n\n\n\nProblem 1. The Rubik’s Cube\n\n\n\nThe Rubik’s Cube is a 3-D combination puzzle involving a cube with a grid of nine squares on each face. In a solved state, each face of the cube has all the nine squares colored using one of six solid colours: white, red, blue, orange, green, and yellow.\n\n\n\nA Rubik Cube\n\n\nThe arrangement of colours is now standardised with white opposite yellow, blue opposite green, and orange opposite red, and the red, white, and blue arranged clockwise in that order.\nAn internal pivot mechanism enables each face to turn independently, thus mixing up the colours. For the puzzle to be solved, each face must be returned to have only one colour.\nSuppose you are implementing a Rubik Cube solver. To answer these questions, you do not need to know how to solve a Rubik’s cube. We assume that the cube is in a fixed orientation, so that that we can identify the front, back, top, bottom, left, and right faces in the natural way.\n\n\n\n\n\n\nProblem 1.1\n\n\n\n\n\nOne natural way to store the state of the cube is to use six 3x3 arrays of chars, with each character representing a color: cube-front[3][3], cube-back[3][3], cube-top[3][3], cube-bottom[3][3], cube-left[3][3], cube-right[3][3].\nIn this representation, to get the color of the sticker on the top-left corner of the front face, you would check the value of cube-front[0][0].\nIn general, for a face F, to get the color of the sticker on row R and column C, you will check the value of cube-F[R][C].\nSuppose we have a cube is in some state (not necessarily solved), and we want to transform the state to the one the cube would be in if the top face was rotated clockwise. Which array would remain unchanged?\n\ncube-front[3][3]\ncube-back[3][3]\ncube-top[3][3]\ncube-bottom[3][3]\ncube-left[3][3]\ncube-right[3][3]\n\n\n\n\n\n\n\n\n\n\nProblem 1.2\n\n\n\n\n\nConsider the following approach. Instead of storing six separate two-dimensional arrays, we store the state of the cube as a linked list with 54 entries as depicted below, by listing all the elements in the cube-front array first, followed by cube-back, cube-top, cube-bottom, cube-left, cube-right. The elements within a face are listed row-wise (i.e, all elements of the first row are listed first, second row second, and so on).\n\n\n\nTransforming the arrays to a linked list\n\n\nSuppose you want to determine the color of a sticker at a particular location, which is specified by the face, row number, and column number. Which approach will require more steps?\n\nThe array approach\nThe linked list approach\n\n\n\n\n\n\n\n\n\n\nProblem 1.3\n\n\n\n\n\nConsider the linked list approach from the previous question. What is the index of the element that stores the color of the center sticker (i.e, row 1 and column 1 with 0-based indexing) of the bottom face? Assume that the linked list is 1-indexed: for example the index of the element that stores the color of the center sticker for the front face is 5.\n\n\n\n\n\n\n\n\n\nProblem 1.4\n\n\n\n\n\nObserve that the central pieces of each face in a Rubik’s cube do not move with any of the rotations. We can think of the Rubik’s cube as being assembled from 8 corner pieces and 12 edge pieces as shown below. Each of these individual pieces is called a cubie.\n\n\n\nCubies\n\n\nObserve that the state of the cube can be fully specified by specifying the orientation of all the cubies. Fix a labeling of all the corner cubies from 0 to 7 and the edge cubies from 0 to 11.\nIn particular, let us say that we store the state by storing two orientation arrays and two location arrays.\nThe first array, C stores the orientation of the corner cubies and the second array E, stores the orientation of edge cubies. The elements of each array stores an orientation (0 or 1 for edges; 0, 1, or 2 for corners).\nThe third array, CC stores the location of the corner cubies and the fourth array EE, stores the location of edge cubies. The elements of CC are values between 0 and 7 and the elements of EE are values between 0 and 11.\nThe state can be recovered from the orientations of all the cubies: for example, we know that the edge cubie with label 3 is at the location EE[3], and oriented according to the value stored in E[3].\nWhich data structure for representing the state of a Rubik’s cube takes up the least space? Assume that we are measuring the space in terms of the total lengths of the sequences involved in each representation.\n\nthe first approach with six 2D arrays\nthe second approach using a linked list\nthe current approach using two cubie arrays\n\n\n\n\n\n\n\n\n\n\nProblem 1.5\n\n\n\n\n\nConsider the representation involving cubies described in the previous part.\nSuppose we have a cube is in some state (not necessarily solved), and we want to transform the state to the one the cube would be in if the top face was rotated clockwise. How many values would you have to update in the CC array?\n\n\n\n\n\n\n\n\n\nProblem 1.6\n\n\n\n\n\nConsider the representation involving cubies described in the previous part.\nSuppose we have a cube is in some state (not necessarily solved), and we want to transform the state to the one the cube would be in if the top face was rotated clockwise. How many values would you have to update in the EE array?\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. Stable Matchings\n\n\n\nRecall that the stable matching problem involves N men and N women. Each man has a ranking of all N women and each woman has a ranking of all N men. A matching M is a collection of N pairs where each pair consists of a man and a woman, and all the men and women appear in exactly one pair. A man a and a woman b are said to block M if a prefers b over his matched partner in M and b prefers a over her matched partner in M according to their respective rankings. A matching is stable if there are no blocking pairs with respect to it.\n\n\n\n\n\n\nProblem 2.1\n\n\n\n\n\nSuppose X and Y are two stable matchings. For a man a, let X[a] denote the matched partner of a in the matching X and let Y[a] denote the matched partner of a in the matching Y.\nConsider a matching Z formed as follows: pair up each man a with the woman he prefers more between X[a] and Y[a].\nNote: If X[a] and Y[a] happen to be the same woman b, then pair a with b.\nWhat can we say about Z?\n\nZ is not necessarily a matching.\nZ is a matching but not necessarily stable.\nZ is always a stable matching.\n\n\n\n\n\n\n\n\n\n\nProblem 2.2\n\n\n\n\n\nSuppose X and Y are two stable matchings. For a man a, let X[a] denote the matched partner of a in the matching X and let Y[a] denote the matched partner of a in the matching Y.\nConsider a matching Z formed as follows: pair up each man a with the woman he prefers less between X[a] and Y[a].\nNote: If X[a] and Y[a] happen to be the same woman b, then pair a with b.\nWhat can we say about Z?\n\nZ is not necessarily a matching.\nZ is a matching but not necessarily stable.\nZ is always a stable matching.\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 3. An Array and A Virus\n\n\n\nThe memory of Rubina’s computer contains two interesting things: an array of integers and a virus. Each midnight the virus becomes active. It takes each array in memory and replaces it with a bunch of new arrays: one for each contiguous subarray of the original array.\nFor example, if today the memory contains a single array (1,2,1,3), tomorrow it will contain the following arrays: (1), (2), (1), (3), (1,2), (2,1), (1,3), (1,2,1), (2,1,3), (1,2,1,3).\nAs another example, if today the memory contains a single array (7,7), tomorrow it will contain the following arrays: (7), (7), (7,7), and the day after tomorrow it will contain the following arrays: (7), (7), (7), (7), (7,7), and so on.\nYou are given Rubina’s original array A and the number of days D. Let f(A,D) be the sum of all elements of all arrays that will be in the memory of Rubina’s computer after D days. Our goal is to calculate f(A,D). You may assume that the memory of Rubina’s computer is sufficiently large to accommodate all the arrays.\nFor example, if A is the array (1,2,1,3) and D = 0 then the answer is 7.\n\n\n\n\n\n\nProblem 3.1\n\n\n\n\n\nIf A = (1,2,1,3) and D = 1, what is f(A,D)?\n\n\n\n\n\n\n\n\n\n\nProblem 3.2\n\n\n\n\n\nIf A = (500) and D = 120, what is f(A,D)?\n\n\n\n\n\n\n\n\n\n\nProblem 3.3\n\n\n\n\n\nIf A = (1,2) and D = 10, what is f(A,D)?\n\n\n\n\n\n\n\n\n\n\nProblem 3.4\n\n\n\n\n\nIf A has four elements, how many arrays of length one are there after two steps?\n\n\n\n\n\n\n::: Problem 4. A Bit of a Graph\nThe bit strings of length four are given by:\n0000, 0001, 0010, 0011, 0100, 0101, 0110, 0111, 1000, 1001, 1010, 1011, 1100, 1101, 1110, 1111.\nConsider a graph where we have:\n\na vertex for every bit string of length four, and let us say that the bit string associated with a vertex u is denoted by b_u; and\nan edge from u to v if the corresponding bit strings are such that the last three bits of b_u is the same as the first three bits of b_v.\n\nFor example, we will have an edge from the vertex representing 0010 to the vertex representing 0101. We will also have an edge from the vertex representing 0010 to the vertex representing 0100.\n\n\n\n\n\n\nProblem 4.1\n\n\n\n\n\nHow many vertices does this graph have?\n\n\n\n\n\n\n\n\n\nProblem 4.2\n\n\n\n\n\nHow many edges does this graph have?\n\n\n\n\n\n\n\n\n\nProblem 4.3\n\n\n\n\n\nHow many vertices in this graph have a self-loop?\n\n\n\n\n\n\n\n\n\nProblem 4.4\n\n\n\n\n\nDoes this graph have a closed Euler Tour?\n:::"
  },
  {
    "objectID": "courses/2023/01-ES242/exams/exam01.html#es242.-data-structures-and-algorithms-i.",
    "href": "courses/2023/01-ES242/exams/exam01.html#es242.-data-structures-and-algorithms-i.",
    "title": "ES242. Data Structures and Algorithms I. Quiz 01",
    "section": "ES242. Data Structures and Algorithms I.",
    "text": "ES242. Data Structures and Algorithms I.\n\nExam 01\nIssued: 16 Feb, 2023\nBack to course page\n\n\n\n\n\n\nProblem 1. The Rubik’s Cube\n\n\n\nThe Rubik’s Cube is a 3-D combination puzzle involving a cube with a grid of nine squares on each face. In a solved state, each face of the cube has all the nine squares colored using one of six solid colours: white, red, blue, orange, green, and yellow.\n\n\n\nA Rubik Cube\n\n\nThe arrangement of colours is now standardised with white opposite yellow, blue opposite green, and orange opposite red, and the red, white, and blue arranged clockwise in that order.\nAn internal pivot mechanism enables each face to turn independently, thus mixing up the colours. For the puzzle to be solved, each face must be returned to have only one colour.\nSuppose you are implementing a Rubik Cube solver. To answer these questions, you do not need to know how to solve a Rubik’s cube. We assume that the cube is in a fixed orientation, so that that we can identify the front, back, top, bottom, left, and right faces in the natural way.\n\n\n\n\n\n\nProblem 1.1\n\n\n\nOne natural way to store the state of the cube is to use six 3x3 arrays of chars: cube-front[3][3], cube-back[3][3], cube-top[3][3], cube-bottom[3][3], cube-left[3][3], cube-right[3][3].\nIn this representation, to get the color of the sticker on the top-left corner of the front face, you would check the value of cube-front[0][0].\nIn general, for a face F, to get the color of the sticker on row R and column C, you will check the value of cube-F[R][C].\nSuppose we have a cube is in some state (not necessarily solved), and we want to transform the state to the one the cube would be in if the top face was rotated clockwise. Which array would remain unchanged?\n\ncube-front[3][3]\ncube-back[3][3]\ncube-top[3][3]\ncube-bottom[3][3]\ncube-left[3][3]\ncube-right[3][3]\n\n\n\n\n\n\n\n\n\nProblem 1.2\n\n\n\nConsider the following approach. Instead of storing six separate two-dimensional arrays, we store the state of the cube as a linked list with 54 entries as depicted below, by listing all the elements in the cube-front array first, followed by cube-back, cube-top, cube-bottom, cube-left, cube-right. The elements within a face are listed row-wise (i.e, all elements of the first row are listed first, second row second, and so on).\n\n\n\nTransforming the arrays to a linked list\n\n\nSuppose you want to determine the color of a sticker at a particular location, which is specified by the face, row number, and column number. Which approach will require more steps?\n\nThe array approach\nThe linked list approach\n\n\n\n\n\n\n\n\n\nProblem 1.3\n\n\n\nConsider the linked list approach from the previous question. What is the index of the element that stores the color of the center sticker (i.e, row 1 and column 1 with 0-based indexing)? Assume that the linked list is 1-indexed: for example the index of the element that stores the color of the center sticker for the front face is 5.\n\n\n\n\n\n\n\n\n\nProblem 1.4\n\n\n\nObserve that the central pieces of each face in a Rubik’s cube do not move with any of the rotations. We can think of the Rubik’s cube as being assembled from 8 corner pieces and 12 edge pieces as shown below. Each of these individual pieces is called a cubie.\n\n\n\nCubies\n\n\nObserve that the state of the cube can be fully specified by specifying the orientation of all the cubies. Fix a labeling of all the corner cubies from 0 to 7 and the edge cubies from 0 to 11.\nIn particular, let us say that we store the state by storing two orientation arrays and two location arrays.\nThe first array, C stores the orientation of the corner cubies and the second array E, stores the orientation of edge cubies. The elements of each array stores an orientation (0 or 1 for edges; 0, 1, or 2 for corners).\nThe third array, CC stores the location of the corner cubies and the fourth array EE, stores the location of edge cubies. The elements of CC are values between 0 and 7 and the elements of EE are values between 0 and 11.\nThe state can be recovered from the orientations of all the cubies: for example, we know that the edge cubie with label 3 is at the location EE[3], and oriented according to the value stored in E[3].\nWhich data structure for representing the state of a Rubik’s cube takes up the least space? Assume that we are measuring the space in terms of the total lengths of the sequences involved in each representation.\n\nthe first approach with six 2D arrays\nthe second approach using a linked list\nthe current approach using two cubie arrays\n\n\n\n\n\n\n\n\n\nProblem 1.5\n\n\n\nConsider the representation involving cubies described in the previous part.\nSuppose we have a cube is in some state (not necessarily solved), and we want to transform the state to the one the cube would be in if the top face was rotated clockwise. How many values would you have to update in the CC array?\n\n\n\n\n\n\n\n\nProblem 1.6\n\n\n\nConsider the representation involving cubies described in the previous part.\nSuppose we have a cube is in some state (not necessarily solved), and we want to transform the state to the one the cube would be in if the top face was rotated clockwise. How many values would you have to update in the EE array?\n\n\n\n\n\n\n\n\n\n\nProblem 2. Stable Matchings\n\n\n\nRecall that the stable matching problem involves N men and N women. Each man has a ranking of all N women and each woman has a ranking of all N men. A matching M is a collection of N pairs where each pair consists of a man and a woman, and all the men and women appear in exactly one pair. A man a and a woman b are said to block M if a prefers b over his matched partner in M and b prefers a over her matched partner in M according to their respective rankings. A matching is stable if there are no blocking pairs with respect to it.\n\n\n\n\n\n\nProblem 2.1\n\n\n\nSuppose X and Y are two stable matchings. For a man a, let X[a] denote the matched partner of a in the matching X and let Y[a] denote the matched partner of a in the matching Y.\nConsider a matching Z formed as follows: pair up each man a with the woman he prefers more between X[a] and Y[a].\nNote: If X[a] and Y[a] happen to be the same woman b, then pair a with b.\nWhat can we say about Z?\n\nZ is not necessarily a matching.\nZ is a matching but not necessarily stable.\nZ is always a stable matching.\n\n\n\n\n\n\n\n\n\nProblem 2.2\n\n\n\nSuppose X and Y are two stable matchings. For a man a, let X[a] denote the matched partner of a in the matching X and let Y[a] denote the matched partner of a in the matching Y.\nConsider a matching Z formed as follows: pair up each man a with the woman he prefers less between X[a] and Y[a].\nNote: If X[a] and Y[a] happen to be the same woman b, then pair a with b.\nWhat can we say about Z?\n\nZ is not necessarily a matching.\nZ is a matching but not necessarily stable.\nZ is always a stable matching.\n\n\n\n\n\n\n\n\n\nProblem 3. An Array and A Virus\n\n\n\nThe memory of Rubina’s computer contains two interesting things: an array of integers and a virus. Each midnight the virus becomes active. It takes each array in memory and replaces it with a bunch of new arrays: one for each contiguous subarray of the original array.\nFor example, if today the memory contains a single array (1,2,1,3), tomorrow it will contain the following arrays: (1), (2), (1), (3), (1,2), (2, 1), (1, 3), (1,2, 1), (2, 1,3), (1,2, 1, 3).\nAs another example, if today the memory contains a single array (7,7), tomorrow it will contain the following arrays: (7), (7), (7,7), and the day after tomorrow it will contain the following arrays: (7), (7), (7), (7), (7,7), and so on.\nYou are given Rubina’s original array A and the number of days D. Let f(A,D) be the sum of all elements of all arrays that will be in the memory of Rubina’s computer after D days. Our goal is to calculate f(A,D). You may assume that the memory of Rubina’s computer is sufficiently large to accommodate all the arrays.\n\n\n\n\n\n\nProblem 3.1\n\n\n\nIf A = (1,2,1,3) and D = 1, what is f(A,D)?\n\n\n\n\n\n\n\n\n\nProblem 3.2\n\n\n\nIf A = (500) and D = 120, what is f(A,D)?\n\n\n\n\n\n\n\n\n\nProblem 3.3\n\n\n\nIf A = (1,2) and D = 10, what is f(A,D)?\n\n\n\n\n\n\n\n\n\nProblem 3.4\n\n\n\nIf A has four elements, how many arrays of length one are there after two steps?\n\n\n\n\n\n\n\n\nProblem 3.5\n\n\n\nSuppose you try to solve this problem by simulating the process. If you generate an array of length one at any step, you can:\n\nDiscard this array.\nAdd the value of the only element in the array to the answer and then discard this array.\nAdd D times the value of the only element in the array to the answer and then discard this array.\nIf the array was generated in the i-th step, we add D-i times the value of the only element in the array to the answer and then discard this array.\nIf the array was generated in the i-th step, we add (D-i+1) times the value of the only element in the array to the answer and then discard this array."
  },
  {
    "objectID": "courses/2023/01-ES242/exams/solutions-01.html",
    "href": "courses/2023/01-ES242/exams/solutions-01.html",
    "title": "ES242. Data Structures and Algorithms I. Exam 01 - Solutions",
    "section": "",
    "text": "Issued: 16 Feb, 2023\nBack to course page\n\n\n\n\n\n\nRemark\n\n\n\nThe question indices may be different from what you see on Gradescope because of the extra confidence rating questions. Multiply by two and subtract one from the question number to map it to Gradescope :)\n\n\n\n\n\n\n\n\nProblem 1. The Rubik’s Cube\n\n\n\nThe Rubik’s Cube is a 3-D combination puzzle involving a cube with a grid of nine squares on each face. In a solved state, each face of the cube has all the nine squares colored using one of six solid colours: white, red, blue, orange, green, and yellow.\n\n\n\nA Rubik Cube\n\n\nThe arrangement of colours is now standardised with white opposite yellow, blue opposite green, and orange opposite red, and the red, white, and blue arranged clockwise in that order.\nAn internal pivot mechanism enables each face to turn independently, thus mixing up the colours. For the puzzle to be solved, each face must be returned to have only one colour.\nSuppose you are implementing a Rubik Cube solver. To answer these questions, you do not need to know how to solve a Rubik’s cube. We assume that the cube is in a fixed orientation, so that that we can identify the front, back, top, bottom, left, and right faces in the natural way.\n\n\n\n\n\n\nProblem 1.1\n\n\n\n\n\nOne natural way to store the state of the cube is to use six 3x3 arrays of chars, with each character representing a color: cube-front[3][3], cube-back[3][3], cube-top[3][3], cube-bottom[3][3], cube-left[3][3], cube-right[3][3].\nIn this representation, to get the color of the sticker on the top-left corner of the front face, you would check the value of cube-front[0][0].\nIn general, for a face F, to get the color of the sticker on row R and column C, you will check the value of cube-F[R][C].\nSuppose we have a cube is in some state (not necessarily solved), and we want to transform the state to the one the cube would be in if the top face was rotated clockwise. Which array would remain unchanged?\n\ncube-front[3][3]\ncube-back[3][3]\ncube-top[3][3]\ncube-bottom[3][3]\ncube-left[3][3]\ncube-right[3][3]\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIf the top face is rotated then the bottom face is the only face that is certainly not affected. The top face itself may not be affected (for example, when all stickers on the top face have the same color), however, this is not guaranteed.\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 1.2\n\n\n\n\n\nConsider the following approach. Instead of storing six separate two-dimensional arrays, we store the state of the cube as a linked list with 54 entries as depicted below, by listing all the elements in the cube-front array first, followed by cube-back, cube-top, cube-bottom, cube-left, cube-right. The elements within a face are listed row-wise (i.e, all elements of the first row are listed first, second row second, and so on).\n\n\n\nTransforming the arrays to a linked list\n\n\nSuppose you want to determine the color of a sticker at a particular location, which is specified by the face, row number, and column number. Which approach will require more steps?\n\nThe array approach\nThe linked list approach\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWhile the index of the location in the linked list can be calculated in constant time, since we do not have direct access, the linked list approach will require more steps in the worst case.\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 1.3\n\n\n\n\n\nConsider the linked list approach from the previous question. What is the index of the element that stores the color of the center sticker (i.e, row 1 and column 1 with 0-based indexing) of the bottom face? Assume that the linked list is 1-indexed: for example the index of the element that stores the color of the center sticker for the front face is 5.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe answer is 32 by direct inspection.\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 1.4\n\n\n\n\n\nObserve that the central pieces of each face in a Rubik’s cube do not move with any of the rotations. We can think of the Rubik’s cube as being assembled from 8 corner pieces and 12 edge pieces as shown below. Each of these individual pieces is called a cubie.\n\n\n\nCubies\n\n\nObserve that the state of the cube can be fully specified by specifying the orientation of all the cubies. Fix a labeling of all the corner cubies from 0 to 7 and the edge cubies from 0 to 11.\nIn particular, let us say that we store the state by storing two orientation arrays and two location arrays.\nThe first array, C stores the orientation of the corner cubies and the second array E, stores the orientation of edge cubies. The elements of each array stores an orientation (0 or 1 for edges; 0, 1, or 2 for corners).\nThe third array, CC stores the location of the corner cubies and the fourth array EE, stores the location of edge cubies. The elements of CC are values between 0 and 7 and the elements of EE are values between 0 and 11.\nThe state can be recovered from the orientations of all the cubies: for example, we know that the edge cubie with label 3 is at the location EE[3], and oriented according to the value stored in E[3].\nWhich data structure for representing the state of a Rubik’s cube takes up the least space? Assume that we are measuring the space in terms of the total lengths of the sequences involved in each representation.\n\nthe first approach with six 2D arrays\nthe second approach using a linked list\nthe current approach using two cubie arrays\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe cubie approach requires employing a total of 40 units of memory, which is less than the 54 units we needed in the other two approaches.\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 1.5\n\n\n\n\n\nConsider the representation involving cubies described in the previous part.\nSuppose we have a cube is in some state (not necessarily solved), and we want to transform the state to the one the cube would be in if the top face was rotated clockwise. How many values would you have to update in the CC array?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSince only four corner cubes are involved in one rotation, the answer is 4. Note that the set of affected cubies is the same for 90 and 180 degree rotations of the top face.\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 1.6\n\n\n\n\n\nConsider the representation involving cubies described in the previous part.\nSuppose we have a cube is in some state (not necessarily solved), and we want to transform the state to the one the cube would be in if the top face was rotated clockwise. How many values would you have to update in the EE array?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSince only four edge cubes are involved in one rotation, the answer is 4. Note that the set of affected cubies is the same for 90 and 180 degree rotations of the top face.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. Stable Matchings\n\n\n\nRecall that the stable matching problem involves N men and N women. Each man has a ranking of all N women and each woman has a ranking of all N men. A matching M is a collection of N pairs where each pair consists of a man and a woman, and all the men and women appear in exactly one pair. A man a and a woman b are said to block M if a prefers b over his matched partner in M and b prefers a over her matched partner in M according to their respective rankings. A matching is stable if there are no blocking pairs with respect to it.\n\n\n\n\n\n\nProblem 2.1\n\n\n\n\n\nSuppose X and Y are two stable matchings. For a man a, let X[a] denote the matched partner of a in the matching X and let Y[a] denote the matched partner of a in the matching Y.\nConsider a matching Z formed as follows: pair up each man a with the woman he prefers more between X[a] and Y[a].\nNote: If X[a] and Y[a] happen to be the same woman b, then pair a with b.\nWhat can we say about Z?\n\nZ is not necessarily a matching.\nZ is a matching but not necessarily stable.\nZ is always a stable matching.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFirst, let us argue that Z is a matching. Suppose not: this means that some woman appears in more than one pair. Suppose there are two men p and q who are both matched to a woman b. Then p and q both prefer b over their matched partners in the matching where they are not matched to b. Now:\n\nIf b prefers p over q, and p was matched to b in the matching X, then observe that b must have been matched to q in Y and (p,b) is a blocking pair for Y.\nIf b prefers p over q, and p was matched to b in the matching Y, then observe that b must have been matched to q in X and (p,b) is a blocking pair for X.\nIf b prefers q over p, and q was matched to b in the matching X, then observe that b must have been matched to p in Y and (q,b) is a blocking pair for Y.\nIf b prefers q over p, and q was matched to b in the matching Y, then observe that b must have been matched to p in X and (q,b) is a blocking pair for X.\n\nIn all cases, we have a contradiction to the assumption that both X and Y are stable.\nSo Z is a matching. We now argue that Z is stable. Suppose not, and let (a,b) be a blocking pair in Z, with a being the man and b being the woman. Further, let the matched partner of a in Z be p and the matched partner of b in Z be q.\nNote that b was matched to q in either X or Y. Suppose b was matched to q in X. In X, a is matched either to p or someone that a prefers less to p. Since a prefers b over p (since (a,b) is a blocking pair), a prefers b over his matched partner in X. We already know that b prefers a over q for the same reason. So, (a,b) remains a blocking pair in the matching X, which contradicts our assumption that X was stable.\nA similar argument holds if b was matched to q in Y, where we contradict the stability of Y instead.\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 2.2\n\n\n\n\n\nSuppose X and Y are two stable matchings. For a man a, let X[a] denote the matched partner of a in the matching X and let Y[a] denote the matched partner of a in the matching Y.\nConsider a matching Z formed as follows: pair up each man a with the woman he prefers less between X[a] and Y[a].\nNote: If X[a] and Y[a] happen to be the same woman b, then pair a with b.\nWhat can we say about Z?\n\nZ is not necessarily a matching.\nZ is a matching but not necessarily stable.\nZ is always a stable matching.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIt turns out that Z is always a stable matching, the argument is analogous to the previous question.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 3. An Array and A Virus\n\n\n\nThe memory of Rubina’s computer contains two interesting things: an array of integers and a virus. Each midnight the virus becomes active. It takes each array in memory and replaces it with a bunch of new arrays: one for each contiguous subarray of the original array.\nFor example, if today the memory contains a single array (1,2,1,3), tomorrow it will contain the following arrays: (1), (2), (1), (3), (1,2), (2,1), (1,3), (1,2,1), (2,1,3), (1,2,1,3).\nAs another example, if today the memory contains a single array (7,7), tomorrow it will contain the following arrays: (7), (7), (7,7), and the day after tomorrow it will contain the following arrays: (7), (7), (7), (7), (7,7), and so on.\nYou are given Rubina’s original array A and the number of days D. Let f(A,D) be the sum of all elements of all arrays that will be in the memory of Rubina’s computer after D days. Our goal is to calculate f(A,D). You may assume that the memory of Rubina’s computer is sufficiently large to accommodate all the arrays.\nFor example, if A is the array (1,2,1,3) and D = 0 then the answer is 7.\n\n\n\n\n\n\nProblem 3.1\n\n\n\n\n\nIf A = (1,2,1,3) and D = 1, what is f(A,D)?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n34\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 3.2\n\n\n\n\n\nIf A = (500) and D = 120, what is f(A,D)?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n500\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 3.3\n\n\n\n\n\nIf A = (1,2) and D = 10, what is f(A,D)?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n33\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 3.4\n\n\n\n\n\nIf A has four elements, how many arrays of length one are there after two steps?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n20\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 4. A Bit of a Graph\n\n\n\nThe bit strings of length four are given by:\n0000, 0001, 0010, 0011, 0100, 0101, 0110, 0111, 1000, 1001, 1010, 1011, 1100, 1101, 1110, 1111.\nConsider a graph where we have:\n\na vertex for every bit string of length four, and let us say that the bit string associated with a vertex u is denoted by b_u; and\nan edge from u to v if the corresponding bit strings are such that the last three bits of b_u is the same as the first three bits of b_v.\n\nFor example, we will have an edge from the vertex representing 0010 to the vertex representing 0101. We will also have an edge from the vertex representing 0010 to the vertex representing 0100.\n\n\n\n\n\n\nProblem 4.1\n\n\n\n\n\nHow many vertices does this graph have?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n16\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 4.2\n\n\n\n\n\nHow many edges does this graph have?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n32\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 4.3\n\n\n\n\n\nHow many vertices in this graph have a self-loop?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTwo\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 4.4\n\n\n\n\n\nDoes this graph have a closed Euler Tour?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes"
  },
  {
    "objectID": "courses/2023/01-ES242/exams/solutions01.html",
    "href": "courses/2023/01-ES242/exams/solutions01.html",
    "title": "ES242. Data Structures and Algorithms I. Exam 01 - Solutions",
    "section": "",
    "text": "Issued: 16 Feb, 2023\nBack to course page\n\n\n\n\n\n\nRemark\n\n\n\nThe question indices may be different from what you see on Gradescope because of the extra confidence rating questions. Multiply by two and subtract one from the question number to map it to Gradescope :)\n\n\n\n\n\n\n\n\nProblem 1. The Rubik’s Cube\n\n\n\nThe Rubik’s Cube is a 3-D combination puzzle involving a cube with a grid of nine squares on each face. In a solved state, each face of the cube has all the nine squares colored using one of six solid colours: white, red, blue, orange, green, and yellow.\n\n\n\nA Rubik Cube\n\n\nThe arrangement of colours is now standardised with white opposite yellow, blue opposite green, and orange opposite red, and the red, white, and blue arranged clockwise in that order.\nAn internal pivot mechanism enables each face to turn independently, thus mixing up the colours. For the puzzle to be solved, each face must be returned to have only one colour.\nSuppose you are implementing a Rubik Cube solver. To answer these questions, you do not need to know how to solve a Rubik’s cube. We assume that the cube is in a fixed orientation, so that that we can identify the front, back, top, bottom, left, and right faces in the natural way.\n\n\n\n\n\n\nProblem 1.1\n\n\n\n\n\nOne natural way to store the state of the cube is to use six 3x3 arrays of chars, with each character representing a color: cube-front[3][3], cube-back[3][3], cube-top[3][3], cube-bottom[3][3], cube-left[3][3], cube-right[3][3].\nIn this representation, to get the color of the sticker on the top-left corner of the front face, you would check the value of cube-front[0][0].\nIn general, for a face F, to get the color of the sticker on row R and column C, you will check the value of cube-F[R][C].\nSuppose we have a cube is in some state (not necessarily solved), and we want to transform the state to the one the cube would be in if the top face was rotated clockwise. Which array would remain unchanged?\n\ncube-front[3][3]\ncube-back[3][3]\ncube-top[3][3]\ncube-bottom[3][3]\ncube-left[3][3]\ncube-right[3][3]\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIf the top face is rotated then the bottom face is the only face that is certainly not affected. The top face itself may not be affected (for example, when all stickers on the top face have the same color), however, this is not guaranteed.\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 1.2\n\n\n\n\n\nConsider the following approach. Instead of storing six separate two-dimensional arrays, we store the state of the cube as a linked list with 54 entries as depicted below, by listing all the elements in the cube-front array first, followed by cube-back, cube-top, cube-bottom, cube-left, cube-right. The elements within a face are listed row-wise (i.e, all elements of the first row are listed first, second row second, and so on).\n\n\n\nTransforming the arrays to a linked list\n\n\nSuppose you want to determine the color of a sticker at a particular location, which is specified by the face, row number, and column number. Which approach will require more steps?\n\nThe array approach\nThe linked list approach\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWhile the index of the location in the linked list can be calculated in constant time, since we do not have direct access, the linked list approach will require more steps in the worst case.\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 1.3\n\n\n\n\n\nConsider the linked list approach from the previous question. What is the index of the element that stores the color of the center sticker (i.e, row 1 and column 1 with 0-based indexing) of the bottom face? Assume that the linked list is 1-indexed: for example the index of the element that stores the color of the center sticker for the front face is 5.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe answer is 32 by direct inspection.\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 1.4\n\n\n\n\n\nObserve that the central pieces of each face in a Rubik’s cube do not move with any of the rotations. We can think of the Rubik’s cube as being assembled from 8 corner pieces and 12 edge pieces as shown below. Each of these individual pieces is called a cubie.\n\n\n\nCubies\n\n\nObserve that the state of the cube can be fully specified by specifying the orientation of all the cubies. Fix a labeling of all the corner cubies from 0 to 7 and the edge cubies from 0 to 11.\nIn particular, let us say that we store the state by storing two orientation arrays and two location arrays.\nThe first array, C stores the orientation of the corner cubies and the second array E, stores the orientation of edge cubies. The elements of each array stores an orientation (0 or 1 for edges; 0, 1, or 2 for corners).\nThe third array, CC stores the location of the corner cubies and the fourth array EE, stores the location of edge cubies. The elements of CC are values between 0 and 7 and the elements of EE are values between 0 and 11.\nThe state can be recovered from the orientations of all the cubies: for example, we know that the edge cubie with label 3 is at the location EE[3], and oriented according to the value stored in E[3].\nWhich data structure for representing the state of a Rubik’s cube takes up the least space? Assume that we are measuring the space in terms of the total lengths of the sequences involved in each representation.\n\nthe first approach with six 2D arrays\nthe second approach using a linked list\nthe current approach using two cubie arrays\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe cubie approach requires employing a total of 40 units of memory, which is less than the 54 units we needed in the other two approaches.\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 1.5\n\n\n\n\n\nConsider the representation involving cubies described in the previous part.\nSuppose we have a cube is in some state (not necessarily solved), and we want to transform the state to the one the cube would be in if the top face was rotated clockwise. How many values would you have to update in the CC array?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSince only four corner cubes are involved in one rotation, the answer is 4. Note that the set of affected cubies is the same for 90 and 180 degree rotations of the top face.\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 1.6\n\n\n\n\n\nConsider the representation involving cubies described in the previous part.\nSuppose we have a cube is in some state (not necessarily solved), and we want to transform the state to the one the cube would be in if the top face was rotated clockwise. How many values would you have to update in the EE array?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSince only four edge cubes are involved in one rotation, the answer is 4. Note that the set of affected cubies is the same for 90 and 180 degree rotations of the top face.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. Stable Matchings\n\n\n\nRecall that the stable matching problem involves N men and N women. Each man has a ranking of all N women and each woman has a ranking of all N men. A matching M is a collection of N pairs where each pair consists of a man and a woman, and all the men and women appear in exactly one pair. A man a and a woman b are said to block M if a prefers b over his matched partner in M and b prefers a over her matched partner in M according to their respective rankings. A matching is stable if there are no blocking pairs with respect to it.\n\n\n\n\n\n\nProblem 2.1\n\n\n\n\n\nSuppose X and Y are two stable matchings. For a man a, let X[a] denote the matched partner of a in the matching X and let Y[a] denote the matched partner of a in the matching Y.\nConsider a matching Z formed as follows: pair up each man a with the woman he prefers more between X[a] and Y[a].\nNote: If X[a] and Y[a] happen to be the same woman b, then pair a with b.\nWhat can we say about Z?\n\nZ is not necessarily a matching.\nZ is a matching but not necessarily stable.\nZ is always a stable matching.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFirst, let us argue that Z is a matching. Suppose not: this means that some woman appears in more than one pair. Suppose there are two men p and q who are both matched to a woman b. Then p and q both prefer b over their matched partners in the matching where they are not matched to b. Now:\n\nIf b prefers p over q, and p was matched to b in the matching X, then observe that b must have been matched to q in Y and (p,b) is a blocking pair for Y.\nIf b prefers p over q, and p was matched to b in the matching Y, then observe that b must have been matched to q in X and (p,b) is a blocking pair for X.\nIf b prefers q over p, and q was matched to b in the matching X, then observe that b must have been matched to p in Y and (q,b) is a blocking pair for Y.\nIf b prefers q over p, and q was matched to b in the matching Y, then observe that b must have been matched to p in X and (q,b) is a blocking pair for X.\n\nIn all cases, we have a contradiction to the assumption that both X and Y are stable.\nSo Z is a matching. We now argue that Z is stable. Suppose not, and let (a,b) be a blocking pair in Z, with a being the man and b being the woman. Further, let the matched partner of a in Z be p and the matched partner of b in Z be q.\nNote that b was matched to q in either X or Y. Suppose b was matched to q in X. In X, a is matched either to p or someone that a prefers less to p. Since a prefers b over p (since (a,b) is a blocking pair), a prefers b over his matched partner in X. We already know that b prefers a over q for the same reason. So, (a,b) remains a blocking pair in the matching X, which contradicts our assumption that X was stable.\nA similar argument holds if b was matched to q in Y, where we contradict the stability of Y instead.\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 2.2\n\n\n\n\n\nSuppose X and Y are two stable matchings. For a man a, let X[a] denote the matched partner of a in the matching X and let Y[a] denote the matched partner of a in the matching Y.\nConsider a matching Z formed as follows: pair up each man a with the woman he prefers less between X[a] and Y[a].\nNote: If X[a] and Y[a] happen to be the same woman b, then pair a with b.\nWhat can we say about Z?\n\nZ is not necessarily a matching.\nZ is a matching but not necessarily stable.\nZ is always a stable matching.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIt turns out that Z is always a stable matching, the argument is analogous to the previous question.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 3. An Array and A Virus\n\n\n\nThe memory of Rubina’s computer contains two interesting things: an array of integers and a virus. Each midnight the virus becomes active. It takes each array in memory and replaces it with a bunch of new arrays: one for each contiguous subarray of the original array.\nFor example, if today the memory contains a single array (1,2,1,3), tomorrow it will contain the following arrays: (1), (2), (1), (3), (1,2), (2,1), (1,3), (1,2,1), (2,1,3), (1,2,1,3).\nAs another example, if today the memory contains a single array (7,7), tomorrow it will contain the following arrays: (7), (7), (7,7), and the day after tomorrow it will contain the following arrays: (7), (7), (7), (7), (7,7), and so on.\nYou are given Rubina’s original array A and the number of days D. Let f(A,D) be the sum of all elements of all arrays that will be in the memory of Rubina’s computer after D days. Our goal is to calculate f(A,D). You may assume that the memory of Rubina’s computer is sufficiently large to accommodate all the arrays.\nFor example, if A is the array (1,2,1,3) and D = 0 then the answer is 7.\n\n\n\n\n\n\nProblem 3.1\n\n\n\n\n\nIf A = (1,2,1,3) and D = 1, what is f(A,D)?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n34\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 3.2\n\n\n\n\n\nIf A = (500) and D = 120, what is f(A,D)?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n500\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 3.3\n\n\n\n\n\nIf A = (1,2) and D = 10, what is f(A,D)?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n33\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 3.4\n\n\n\n\n\nIf A has four elements, how many arrays of length one are there after two steps?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n20\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 4. A Bit of a Graph\n\n\n\nThe bit strings of length four are given by:\n0000, 0001, 0010, 0011, 0100, 0101, 0110, 0111, 1000, 1001, 1010, 1011, 1100, 1101, 1110, 1111.\nConsider a graph where we have:\n\na vertex for every bit string of length four, and let us say that the bit string associated with a vertex u is denoted by b_u; and\nan edge from u to v if the corresponding bit strings are such that the last three bits of b_u is the same as the first three bits of b_v.\n\nFor example, we will have an edge from the vertex representing 0010 to the vertex representing 0101. We will also have an edge from the vertex representing 0010 to the vertex representing 0100.\n\n\n\n\n\n\nProblem 4.1\n\n\n\n\n\nHow many vertices does this graph have?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n16\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 4.2\n\n\n\n\n\nHow many edges does this graph have?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n32\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 4.3\n\n\n\n\n\nHow many vertices in this graph have a self-loop?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTwo\n\n\n\n\n\n\n\n\n\n\n\n\nProblem 4.4\n\n\n\n\n\nDoes this graph have a closed Euler Tour?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes"
  },
  {
    "objectID": "courses/2023/01-CS614/exams/E01.html",
    "href": "courses/2023/01-CS614/exams/E01.html",
    "title": "CS614. Advanced Algorithms. Exam 1.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nRemarks\n\n\n\nProblem indices on Gradescope for Problem 1 are off-by-one. Add one to the index here to match to Gradescope.\nErrata based on feedback from the class (thanks!) — these changes have been made in the questions below:\n\nQ5: it should have been v \\in S and not v \\in G.\nQ1.4: assume that the cycles C and D are edge-disjoint.\nQ1.6: the last return statement is G and not G-v (the vertex v is moved to F, not removed from the graph).\n\n\n\n\n\n\n\n\n\nProblem 1. The Constrained Cycle Hitting Set (CCHS) Problem.\n\n\n\n\n\n\n\n\n\nMarks Distribution.\n\n\n\nThis problem is worth 20 points overall. All subproblems carry two points each except 1.9 (which is zero marks).\n\n\nLet G = (V,E) be a simple and undirected graph. Let F \\subseteq V be a subset of vertices that we will call a forbidden subset. An instance of CCHS is given by (G,F,k), where k \\in \\mathbb{Z}^+ is a budget. Such an instance is a YES-instance if there exists a subset of S \\subseteq V \\setminus F such that:\n\n|S| \\leqslant k, and\nG \\setminus S is a forest, i.e, there are no cycles.\n\nSuch a subset is called a constrained cycle hitting set with respect to F. In this question, we will develop a c^k algorithm for solving a CCHS instance, combining reduction and branching rules in a spirit somewhat similar to what we have done for Vertex Cover in class.\nOur goal will be to return a solution, i.e, a subset of vertices that is a constrained cycle hitting set with respect to F. In particular, an informal overview of our approach, detailed further in the questions below, is the following:\n\nWe will eliminate low-degree (vertices of degree at most one) vertices, and branch on high-degree vertices.\nFor the base case, we will find ourselves “stuck” when the graph only has vertices of degree at most two, but this can be handled in polynomial time.\n\nOur algorithm will be denoted solve-CCHS(G,F,k). We begin the following straightforward rules:\n\nIf k < 0, return NO.\nIf V(G) = \\emptyset, return \\emptyset.\n\n\n\n\n\n\n\nProblem 1.0 No Hope Rule\n\n\n\n\n\nSuppose G[F] has a cycle C. Note that all vertices of C belong to F. Then return:\n\nNO\nsolve-CCHS(G-v,F-v,k-1) where v is a maximum degree vertex from C.\nsolve-CCHS(G-v,F-v,k-1) where v is a minimum degree vertex from C.\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.1 Low Degree Rule.\n\n\n\n\n\nIf a vertex v has degree zero or one, then return:\n\nsolve-CCHS(G-v,F-v,k).\nsolve-CCHS(G-v,F-v,k-1).\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Forced Vertex Rule.\n\n\n\n\n\nIf a vertex v \\in G \\setminus F has two neighbors in a single connected component of G[F], then return:\n\nsolve-CCHS(G-v,F,k).\nsolve-CCHS(G-v,F,k-1).\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.3 High Degree Vertex Has Low Degree - Structure I\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nLet C be a cycle in G. Which of the following scenarios are not feasible?\n\nC \\cap F \\neq \\emptyset and C \\cap (V \\setminus F) \\neq \\emptyset\nC \\cap F = \\emptyset and C \\cap (V \\setminus F) \\neq \\emptyset\nC \\cap F \\neq \\emptyset and C \\cap (V \\setminus F) = \\emptyset\n\nPick the correct option and justify your answer briefly.\n\n\n\n\n\n\n\n\n\nProblem 1.4 High Degree Vertex Has Low Degree - Structure II\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nLet C and D be two edge-disjoint cycles in G. Which of the following scenarios are not feasible?\n\nC \\cap D \\neq \\emptyset\n(C \\cap F) \\cap (D \\cap F) \\neq \\emptyset\n(C \\cap (V\\setminus F)) \\cap (D \\cap (V \\setminus F)) \\neq \\emptyset\n\nPick the correct option and justify your answer briefly.\n\n\n\n\n\n\n\n\n\nProblem 1.5 High Degree Vertex Has Low Degree - Rule\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nConsider the following algorithm to solve this instance:\ninit X = emptyset\nwhile G\\X has a cycle C:\n    let v be a vertex in C\\F:\n        add v to X\nif |X| > k:\n    return NO\nelse:\n    return X\nWhat can you say about the procedure above?\n\nIt correctly solves the kind of CCHS questions being considered in this problem.\nIt will not be correct if there are no vertices in C\\setminus F, as required in line 3.\nIt will not be correct if there are two overlapping cycles in the instance.\n\nPick the correct option and justify your answer briefly. If you believe this is not the right algorithm, please suggest an alternative that works. In further questions when we refer to the rule in problem 1.5, we are referring to either the algorithm above or the one in your justification.\n\n\n\n\n\n\n\n\n\nProblem 1.6 The Branching Step\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1, 1.2, and 1.5 do not apply. Let v be a vertex in G \\setminus F of maximum degree. Now we branch as follows:\nOption A.\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F U {v},k) // omit v\nOption B.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F U {v},k-1) // omit v\nOption C.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X\notherwise:\n    return solve-CCHS(G,F U {v},k) // omit v\nOption D.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F,k) // omit v\nPick the right branching strategy and justify your answer.\n\n\n\nWe summarize the overall algorithm below.\nIf k < 0, return NO.\nIf V(G) is empty, return the empty set.\n\nApply rules 1.0, 1.1, and 1.2.\n\nPick a vertex v in G\\F of maximum degree.\n\nIf d(v) = 2, apply rule 1.5.\nOtherwise branch according to 1.6.\nIn the next few questions, we will analyze the running time of this algorithm. Assume that the algorithm is called with F = \\emptyset, i.e, there are no forbidden vertices to begin with. Fix an execution path P in the branching tree1 of the algorithm that does not return NO. Now:\n\nWe use S(P) to denote the output: note that this would consist of the set of vertices that are removed from the instance for inclusion in the solution, i.e, vertices chosen by the first branch in Step 1.6.\nWe use F(P) to denote the set of vertices that are made forbidden along the path P, i.e, these are vertices chosen by the second branch in Step 1.6.\n\nNote that at the output node, the instance we have is (G,F(P),\\ell) for some \\ell \\leqslant k, where S(P) is a constrained cycle hitting set with respect to F(P) of size at most k - \\ell. Also the number of steps in the execution path P is given by |F(P)| + |S(P)|, since every time we branch, we either include a vertex in the solution or make it forbidden.\n\n\n\n\n\n\nProblem 1.7 Degree 3 vs Leaves in Trees\n\n\n\n\n\nLet T be a tree and let X be the set of leaves in T, and let Y be the set of vertices of degree three or more in T. Show that:\n\\sum_{v \\in Y} (d(v)-2) = |X| - 2,\nusing elementary facts about trees.\n\n\n\n\n\n\n\n\n\nProblem 1.8 Degree Evolution\n\n\n\n\n\nFix an execution path P on an instance (G,\\emptyset,k) (i.e, a path from root to leaf in the branching tree associated with the algorithm when the input is (G,\\emptyset,k)) and consider a vertex v that belongs to F(P), which is to say that the vertex v was included in the set of forbidden vertices at some point during the execution of the algorithm. Denote the instance at this stage of the algorithm by (H,F,k^\\prime). In particular, H is the graph obtained after v was included in F. Let d(v) denote the degree of the vertex v in the original instance G, and let d^\\star(v) denote its degree in the graph H. Which of the following is true?\n\n3 \\leqslant d^\\star(v) \\leqslant d(v)\n3 \\leqslant d^\\star(v) < d(v)\nd^\\star(v) \\geqslant \\min(d(v),3)\nd^\\star(v) > \\min(d(v),3)\n\n\n\n\n\n\n\n\n\n\nProblem 1.9 Successful Execution Paths are Short\n\n\n\n\n\nConsider an execution path P that does not return NO. Show that F(P) \\leqslant 3S(P).\nThis is an optional question that you can skip. It carries no points.\n\n\n\n\n\n\n\n\n\nProblem 1.10 The Final Running Time\n\n\n\n\n\nCan you use the fact from the previous question to come up with an algorithm for CCHS that runs in time O^\\star(16^k)? Note that the O^\\star(\\cdot) notation is used to hide factors that are polynomial in n and k.\nHint: Use the algorithm described previously in the question, but modify it slightly. In particular, if an execution path pushes more than 3S(P) vertices into the forbidden set F, can you terminate it prematurely? Also, what is the cost of the successful execution paths?\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. GreedyHS [2 points]\n\n\n\nLet U=\\left\\{x_1, \\ldots, x_n\\right\\} be an univere of n elements. Suppose we have a family \\mathcal{F} over U that consists of three-sized subsets of U, for example:\n\n\\mathcal{F} = \\left(x_1, x_3, x_4\\right),\\left(x_2, x_3, x_7\\right),\\left(x_1, x_5, x_6\\right)\n\nWe want to find a smallest subset X of U such that for all sets S \\in \\mathcal{F}, S \\cap X \\neq \\emptyset.\nConsider the following algorithm for this problem.\nGreedy(U,F)\n\nInit X = emptyset\nwhile F is non-empty do:\n    Take an arbitrary set S in F.\n    Let x be an element in S\n    X = X U {x}\n    Remove all sets from F that contain x\nend while\nWhat can you say about the worst-case approximation ratio of this algorithm?\n\n\n\n\n\n\n\n\nProblem 3. Knapsack [2 points]\n\n\n\nConsider the knapsack problem. Given a set X=\\left\\{x_1, \\ldots, x_n\\right\\} of n items with weights w\\left(x_i\\right) and values v\\left(x_i\\right), it asks for the highest total value of items we can put into our knapsack such that the total weight of all these items is at most W.\nDescribe a 0/1-LP that models the problem correctly.\n\n\n\n\n\n\n\n\nProblem 4. Rectangle Covering [4 Points]\n\n\n\n\n\n\nRectangle Cover Problem Example\n\n\nSuppose we have a set P=\\left\\{p_1, \\ldots, p_n\\right\\} of n points and a set R=\\left\\{r_1 \\ldots, r_m\\right\\} of m rectangles, as in the image above. Each rectangle r_i \\in R has a certain cost c_i>0 associated with it. We wish to find a subset S \\subseteq R of rectangles whose cost is minimized such that the rectangles in S together cover all points in P.\nWe wish to model this problem as a 0/1-LP. To this end we introduce a decision variable x_i for each rectangle r_i \\in R, where x_i=1 corresponds to putting rectangle r_i into S and x_i=0 corresponds to not putting r_i into S. otherwise. Furthermore, for a point p_j \\in P, define R\\left(p_j\\right)=\\left\\{r_i \\in R: p_j \\in r_i\\right\\}.\n\n\n\n\n\n\nLP for Rectangle Cover\n\n\n\n\n\nDescribe a 0/1-LP that models the problem correctly.\n\n\n\n\n\n\n\n\n\nLP-based Approximation for Rectangle Cover\n\n\n\n\n\nDescribe a 5-approximation assuming that each point is contained in at most 5 rectangles.\n\n\n\n\n\n\n\n\n\n\n\nProblem 5. Dominating Set Reduction Rule When The Graph has No Short Cycles [2 points]\n\n\n\nSuppose G is a simple, undirected graph that has no cycles of length three or four. Recall that a subset S of vertices of G is called a dominating set if every vertex v of G either belongs to S or has a neighbor in S, in other words, N[v] \\cap S \\neq \\emptyset.\nLet S be a dominating set of G of size at most k, where G is as given above (i.e, G has no triangles and no cycles of length four). Show that if the degree of v is more than k in G, then v \\in S."
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w08.html",
    "href": "courses/2023/01-ES242/labs/lab-w08.html",
    "title": "ES242. Data Structures and Algorithms I. Week 08 Lab",
    "section": "",
    "text": "Back to course page\n\n\n\n\n\n\nDepth First Search\n\n\n\n\n\n\n\n\n\nProblem 1. Implement DFS\n\n\n\n\n\nIn this exercise your goal is to output a DFS traversal of a given graph G starting from a given source s.\n\n\nThe first line of input is three space-separated integers n, m and s, denoting the number of vertices and edges of G, and the id of the source vertex, respectively. Vertices are indexed from 0 to n-1.\nThe next m lines of code are two space separated integers u and v in the range 0 and n-1, indicating an (undirected) edge between vertices u and v.\nThe last line is a pair of space-separated integers x and y.\n\n\n\nThe output is a sequence of vertices in the order in which they were pushed on to the stack. Assume that you always find your lexicographically smallest unvisited neighbor in your DFS implementation.\n\n\n\nSample Input\n6 8 0\n0 1\n0 2\n0 3\n0 4\n5 1\n5 2\n5 3\n5 4\nSample Output\n0 1 5 2 3 4 \nThere is a trailing whitespace at the end of the line in the output.\nNote. This was a worked out example and the code is here. Please note that there some very minor changes from the version discussed in class to account for proper ordering of vertices. In particular, in the stack implementation, to make sure that you are visiting the lowest-indexed neighbor, the vertices need to be added to the adjacency list in reverse sorted order.\n\n\n\n\n\n\n\n\n\n\nProblem 2. Is it a DAG?\n\n\n\n\n\nRecall that a path in a directed graph is a sequence of edges having the property that the ending vertex of each edge in the sequence is the same as the starting vertex of the next edge in the sequence; a path forms a cycle if the starting vertex of its first edge equals the ending vertex of its last edge. A directed acyclic graph (also known as a DAG) is a directed graph that has no cycles.\nYou are given a directed graph G. Your task is to determine whether the input graph is a DAG.\nNote that the vertices are 0-indexed. That is, the vertices are numbered as 0 \\ldots n-1.\nYour code should output YES if G is a DAG, else NO\n\n\nThe first line contains an integer n, the number of nodes in the graph.  The next line contains an integer m, denoting the number of edges in the graph.  The next m input lines contain two space-separated integers u,v denoting a directed edge from u to v (u->v).\n\n\n\nOutput YES if G is a DAG, else NO\nSample Input 1\n6\n6\n5 0\n5 2\n4 0\n4 1\n2 3\n3 1\nSample Output 1\nYES\nSample Input 2\n4\n4\n0 1\n1 2\n2 3\n3 0\nSample Output 2\nNO"
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L08.html",
    "href": "courses/2023/01-CS614/quizzes/L08.html",
    "title": "CS614. Advanced Algorithms. L08 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Better Approximation given a k-coloring\n\n\n\nGiven a k-coloring of a graph G, show that we can find a vertex cover which is a 2\\bigl(1−\\frac{1}{k}\\bigr) approximation.\nHint: use the k-coloring on the vertices of V_{1/2}.\n\n\n\n\n\n\n\n\nProblem 2. Point Line Cover\n\n\n\nIn the Point Line Cover problem, we are given a set of n points in the plane and an integer k, and the goal is to check if there exists a set of k lines on the plane that contain all the input points.\nShow a kernel for this problem with \\mathcal{O}\\left(k^2\\right) points."
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L09.html",
    "href": "courses/2023/01-CS614/quizzes/L09.html",
    "title": "CS614. Advanced Algorithms. L09 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Dominating Set\n\n\n\nA dominating set of a graph G is a subset of vertices S such that every vertex in G either belongs to S or has a neighbor in S.\nSuppose you have an instance of dominating set given by (G,k), which is a YES-instance if and only if G has a dominating set of size at most k.\nIs the following reduction rule safe?\nRR. If d(v) > k, then return (G-v,k-1).\n( ) Yes (X) No\nBriefly justify your answer:\n|____|\n\n\n\n\n\n\n\n\nProblem 2. Connected Vertex Cover\n\n\n\nA connected vertex cover of a graph G is a subset of vertices S such that: (a) S is a vertex cover of G, and (b) G[S] is a connected subgraph of G.\nSuppose you have an instance of connected vertex cover given by (G,k), which is a YES-instance if and only if G has a connected vertex cover of size at most k.\n\n\n\n\n\n\nProblem 2.1 Connected Vertex Cover I.\n\n\n\nDesign a \\mathcal{O}(2^k) vertex kernel for Connected Vertex Cover.\nHint: What can you say about high degree vertices? How many can G have?\nFollow up hint: What can you say about two vertices that have the same neighbourhood among the high-degree vertices?\n\n\n\n\n\n\n\n\nProblem 2.2 Connected Vertex Cover II.\n\n\n\nObserve that the kernelization argument that we made for Vertex Cover does not work as-is for connected vertex cover. Recall that the reduction rules were the following:\n\nR0. If k \\leqslant 0 and E is non-empty, return a trivial no-instance.\nR1. If k \\geqslant 0 and E is empty, return a trivial yes-instance.\nR2. If v is a degree zero vertex, return (G\\setminus \\{v\\},k), i.e, delete v from G and keep the budget the same.\nR3. If v is vertex whose degree is more than k, return (G\\setminus \\{v\\},k-1), i.e, delete v from G and reduce the budget by one.\n\nWhere does it fail? Justify, if possible, with an example."
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L10.html",
    "href": "courses/2023/01-CS614/quizzes/L10.html",
    "title": "CS614. Advanced Algorithms. L10 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Set Cover: The Greedy Bound is Tight\n\n\n\nWe argued in class that the greedy approach to solving the unweighted Set Cover problem achieves an approximation ratio of O(H_n). Argue that this bound is tight, i.e, come up with examples where the algorithm picks sets in a manner that the cost of the solution is roughly H_n worse than optimal.\n\n\n\n\n\n\n\n\nProblem 2. Set Cover and Related Problems\n\n\n\n\nShow that Vertex Cover is a special case of Set Cover.\nAlso show that Dominating Set and Set Cover are equivalent (i.e, Set Cover can be reduced to Dominating Set and vice versa)."
  },
  {
    "objectID": "materials/dsanotes/dfs/index.html",
    "href": "materials/dsanotes/dfs/index.html",
    "title": "Navigating Graphs",
    "section": "",
    "text": "So far, we have been exploring graphs with an emphasis on visiting all the edges: we want to cross all our bridges, draw every line that there is, and so on. Now we will switch gears and obsess over visiting vertices instead. While the language in our conversation will implicitly assume that the graphs in question are undirected, everything we say here can be easily adapted to directed graphs as well. The pseudocode presented here is for graphs on n vertices with vertex labels ranging between 0 and n-1 (inclusive).\nTo illustrate, let us go way back in time to when Facebook was a thing. You start off by making your Facebook account, and making friends with everyone you know. Now, as a part of your preparations for the apocalypse1, you want to make a list of everyone who you believe is accessible to you: these are people who are your friends, of course, but also friends of your friends, because you trust your friends to put you in touch with their friends if you need it; but now we can extend this confidence to friends of those who are friends of your friends, and so on. To make the “and so on” bit explicit, let us define the set of people you can access as follows:1 Who knows what — and who — may come in handy.\n\nyour friends on Facebook are accessible;\nif person A is accessible and person B is a Facebook friend of A, then A is also accessible.\n\nSo: how do you go about making this list? This is a good time to take a pause and work it out.\n\n\nWell, one natural way — at the risk of looking like a stalker — is the following. Let us call people on Facebook new if they are not yet on our list. To begin with, everyone is new and our list is empty. Also assume that all names are distinct2. Our list will spawn several notebooks, and we will build it up as follows.2 In practice, every profile has an unique ID, so the actual names do not matter: what is important is that we can easily verify, when we are exploring a profile, if it is new or not.\n\non day 1, make a list of all your friends on Facebook in a notebook called Volume 1.\non day 2, go to the profiles of everyone you have listed in Volume 1. For each person, go through their friends list, and make a list of everyone who is new to you in Volume 2.\non day 3, go to the profiles of everyone you have listed in Volume 2. For each person, go through their friends list, and make a list of everyone who is new to you in Volume 3.\n\non day t, go to the profiles of everyone you have listed in Volume t-1. For each person, go through their friends list, and make a list of everyone who is new to you to Volume t. Stop if the new volume is empty.\n\n\n\n\n\n\n\nNew People Only!\n\n\n\nNotice that it is crucial that you only list people who are new to you. Consider an example where all of Facebook is three people: you and your friends Akash and Babita, who are friends with each other as well. Now Akash and Babita make it to Volume 1, but on day 2, if you are not careful about listing only new people, you will:\n\nadd Babita to Volume 2 based on Akash’s list, and\nadd Akash to Volume 2 based on Babita’s list.\n\nNow, since Volume 2 is the same as Volume 1, it will spawn an identical Volume 3, and this will go on ad infinitum, which is not what we want!\n\n\n\n\n\n\n\n\nFood For Thought\n\n\n\nHow long does it take to build up the whole list of accessible people, if all of Facebook has N people and everyone has at most D friends? Assume that you can figure out — when looking at a profile — whether it is new or not. This is not terribly unrealistic: for example, your browser typically tells you if you have visited a page before or not by coloring the links purple instead of blue, at least in the early days of Facebook.\n\n\nYou should convince yourself that the process above indeed:\n\nlists everyone who is accessible,\ndoes not list anyone who is not accessible, and\nterminates pre-apocalypse assuming that Facebook is finite.\n\n\n\n\nNow, suppose that you are going to attend a hypothetical Facebook party: all the first 1729 users will be there, and in particular, you will get to meet your seven friends as well. Now you want to say hi to everyone who’s accessible, and maybe get them to sign your slam book too: but you haven’t finished building your list yet!\nSo how do you go about discovering all the accessible people? Well, you do what people do at networking events3 — you ask to be introduced to someone you have not met already. Start by approaching a friend, who will introduce you to one of their friends, who may or may not be a mutual: but you move on to said friend regardless, who will in turn introduce you to someone else, etc.3 Or at least what the author thinks people do at networking events.\nIn particular, let us proceed4 as follows:4 Don’t try this at an actual party.\nGo to an arbitrary friend `X`.\n\nRepeatedly do the following:\n    Declare under your breath that you have met `X`.\n    Ask X to introduce you to a friend of theirs \n    (whom you have not yet met).\n    \n    if X introduces you to Y:\n        Y is the new X.\n    \n    else X has nothing new to offer:\n        EXIT PARTY.\nClearly, everyone you meet this way is accessible, but do you get to meet everyone who is accessible?\n\n\n\n\n\n\nMisses\n\n\n\nSuppose you have a friend Ravi who knows both Seeta and Geeta, but Seeta and Geeta do not know each other. To begin with, you meet Ravi and say Ravi introduces you to Seeta. Seeta knows nobody whom you have not yet met, so you leave without meeting Geeta, but she was accessible! Had Ravi introduced you to Geeta instead, then you would have missed meeting Seeta with the approach above.\nPause and think about how you can fix your procedure so that you meet everyone who is accessible.\n\n\nOne way to expand the scope of people we meet at the party is by not giving up so early: specifically, if you meet someone who observes that you have already met all their friends, then you have a dead end, but for all you know you are just stuck in a local minima. You need to pull yourself up and keep looking — and there are a few different possibilities that you could experiment with here:\n\nfind another OG friend you have not met at the party and restart the process above\nfind a random person at the party to restart the process above\ngo back to the last person you were speaking with and continue the process above\n\nNote that with approach (1), you would still miss meeting either Seeta or Geeta in the example above, so while it’s a perfectly valid approach it may still fail to be comprehensive.\nThe issue with approach (2) — apart from the fact that it may not be well-suited to introverts — is that you might end up meeting and listing people who are not, in fact, accessible.\nSo let’s try approach (3), which you can think of as retracing your steps backward whenever you are stuck:\nGo to an arbitrary friend X.\nRepeatedly do the following:\n    Ask X to introduce you to a friend of theirs \n    (whom you have not yet met).\n\n    if X introduces you to Y:\n        Remember that X introduced you to Y.\n        Declare that you have met Y.\n        Y is the new X.\n\n    else X has nothing new to offer:\n        Who introduced you to X?\n            Nobody: EXIT PARTY.\n            It was Z: Z is the new X.\nAs before, you should convince yourself that the process above indeed:\n\nensures you meet everyone who is accessible,\ndoes not have you meet anyone who is not accessible.\n\nFurther, you can also show that you exit the party before the party exits you: in other words, the process above does not go on forever. Why is this?\nWell, notice that you never meet someone for the first time more than once, so the if block inside Repeatedly triggers at most 1728 times.\nNow lets talk about the else block inside Repeatedly. Let us say that you get “stuck at someone” if they have nothing new to offer. Now we claim that you never get stuck at someone more than once. To see this, lets put ourselves in the shoes of someone — say 💃 — attending this party and largely minding their own business. From their perspective, a novice networker — say 🕺 — keeps approaching them to meet new people. They meet this person some k times: perhaps they hope that k is zero, but if they are not so lucky, then the meetings pan out as follows.\n\nThe first meeting is when someone introduces 🕺 to 💃.\n\nNow 💃 introduces 🕺 to P_1, a new person.\n\nThe second meeting is when 🕺 backtracks from P_1 back to 💃.\n\nNow 💃 introduces 🕺 to P_2, a new person.\n\nThe second meeting is when 🕺 backtracks from P_2 back to 💃.\n\nNow 💃 introduces 🕺 to P_3, a new person. \\vdots\n\nThe k^{th} meeting is when 🕺 backtracks from P_{k-1} back to 💃.\n\nNow 💃 has nobody left to introduce 🕺 to.\n\n\nNote how all meetings but one are fruitful in that they lead to further progress, and it is only the last meeting where one gets stuck and backtracks from 💃. In other words, you never get stuck at the same person more than once, so the else block inside Repeatedly triggers at most 1728 times. So given a sufficiently long party, we will indeed build our lists in time.\n\n\n\nSo we have evidently figured out two ways of exploring the part of the graph accessible from a particular location. These belong to a family of graph traversal algorithms, dubbed Whatever-First-Search by Erickson, and can be generically described as follows:\nWhatever-First-Search(s):\n    put s into the bag\n    while the bag is not empty:\n        take v out of the bag\n        if v is unmarked\n            mark v\n                for each edge vw\n                    put w into the bag\nRecall that the notion of accessibility is recursively defined, so for many people it is most natural to think of the algorithms also as being recursive. In particular, it’s either:\n\nping all your friends, rinse, repeat, or\ngo to a friend, rinse, repeat;\n\nkeeping in mind that — in the spirit of recursion — when you are rinsing and repeating, you re-identify yourself as whoever you are working with currently, and also take care to ensure that you don’t end up going in circles forever by remembering what you have already seen and making good use of that intel.\n\n\n\nImagine that you open up Wikipedia’s featured article today, and it happens to be about Operation Flavius. Call this page P, and let’s say that another page Q on Wikipedia is reachable from P if you can arrive at Q by starting at P and following links that are visible on whatever the current page is. To make a list of all pages reachable from P, you can start with P as the current page and then either:\n\nopen up all blue links visible on the current page in background tabs, close the current page, and process the next tab similarly; or,\nopen the first blue link you see on the current page, and keep doing this, hitting the back button when you hit a page with no blue links.\n\nThe background tab hoarder is browsing breadth-first, while the distracted clicker is browsing depth-first :) With all this intuition collected, let us now describe professional-looking implementations for these algorithms and argue their correctness."
  },
  {
    "objectID": "materials/dsanotes/dfs/index.html#breadth-first",
    "href": "materials/dsanotes/dfs/index.html#breadth-first",
    "title": "Navigating Graphs",
    "section": "Breadth-First",
    "text": "Breadth-First\nWell, one natural way — at the risk of coming across as a stalker — is the following. Let us call people on Facebook new if they are not yet on our list. To begin with, everyone is new and our list is empty. Also assume that all names are distinct2. Our list will spawn several notebooks, and we will build it up as follows.2 In practice, every profile has an unique ID, so the actual names do not matter: what is important is that we can easily verify, when we are exploring a profile, if it is new or not.\n\non day 1, make a list of all your friends on Facebook in a notebook called Volume 1.\non day 2, go to the profiles of everyone you have listed in Volume 1. For each person, go through their friends list, and make a list of everyone who is new to you in Volume 2.\non day 3, go to the profiles of everyone you have listed in Volume 2. For each person, go through their friends list, and make a list of everyone who is new to you in Volume 3.\n\n\n\n…and go on\n\n\non day t, go to the profiles of everyone you have listed in Volume t-1. For each person, go through their friends list, and make a list of everyone who is new to you to Volume t. Stop if the new volume is empty.\n\n\n\n\n\n\n\nNew People Only!\n\n\n\nNotice that it is crucial that you only list people who are new to you. Consider an example where all of Facebook is three people: you and your friends Akash and Babita, who are friends with each other as well. Now Akash and Babita make it to Volume 1, but on day 2, if you are not careful about listing only new people, you will:\n\nadd Babita to Volume 2 based on Akash’s list, and\nadd Akash to Volume 2 based on Babita’s list.\n\nNow, since Volume 2 is the same as Volume 1, it will spawn an identical Volume 3, and this will go on ad infinitum, which is not what we want!\n\n\n\n\n\n\n\n\nFood For Thought\n\n\n\nHow long does it take to build up the whole list of accessible people, if all of Facebook has N people and everyone has at most D friends? Assume that you can figure out — when looking at a profile — whether it is new or not. This is not terribly unrealistic: for example, your browser typically tells you if you have visited a page before or not by coloring the links purple instead of blue, at least in the early days of Facebook.\n\n\nYou should convince yourself that the process above indeed:\n\nlists everyone who is accessible,\ndoes not list anyone who is not accessible, and\nterminates pre-apocalypse assuming that Facebook is finite."
  },
  {
    "objectID": "materials/dsanotes/dfs/index.html#depth-first",
    "href": "materials/dsanotes/dfs/index.html#depth-first",
    "title": "Navigating Graphs",
    "section": "Depth-First",
    "text": "Depth-First\nNow, suppose that you are going to attend a hypothetical Facebook party: all the first 1729 users will be there, and in particular, you will get to meet your seven friends as well. Now you want to say hi to everyone who’s accessible, and maybe get them to sign your slam book too: but you haven’t finished building your list yet!\nSo how do you go about discovering all the accessible people? Well, you do what people do at networking events3 — you ask to be introduced to someone you have not met already. Start by approaching a friend, who will introduce you to one of their friends, who may or may not be a mutual: but you move on to said friend regardless, who will in turn introduce you to someone else, etc.3 Or at least what the author thinks people do at networking events.\nIn particular, let us proceed4 as follows:4 Don’t try this at an actual party.\nGo to an arbitrary friend `X`.\n\nRepeatedly do the following:\n    Declare under your breath that you have met `X`.\n    Ask X to introduce you to a friend of theirs \n    (whom you have not yet met).\n    \n    if X introduces you to Y:\n        Y is the new X.\n    \n    else X has nothing new to offer:\n        EXIT PARTY.\nClearly, everyone you meet this way is accessible, but do you get to meet everyone who is accessible?\n\n\n\n\n\n\nMisses\n\n\n\nSuppose you have a friend Ravi who knows both Seeta and Geeta, but Seeta and Geeta do not know each other. To begin with, you meet Ravi and say Ravi introduces you to Seeta. Seeta knows nobody whom you have not yet met, so you leave without meeting Geeta, but she was accessible! Had Ravi introduced you to Geeta instead, then you would have missed meeting Seeta with the approach above.\nPause and think about how you can fix your procedure so that you meet everyone who is accessible.\n\n\nOne way to expand the scope of people we meet at the party is by not giving up so early: specifically, if you meet someone who observes that you have already met all their friends, then you have a dead end, but for all you know you are just stuck in a local minima. You need to pull yourself up and keep looking — and there are a few different possibilities that you could experiment with here:\n\nfind another OG friend you have not met at the party and restart the process above\nfind a random person at the party to restart the process above\ngo back to the last person you were speaking with and continue the process above\n\nNote that with approach (1), you would still miss meeting either Seeta or Geeta in the example above, so while it’s a perfectly valid approach it may still fail to be comprehensive.\nThe issue with approach (2) — apart from the fact that it may not be well-suited to introverts — is that you might end up meeting and listing people who are not, in fact, accessible.\nSo let’s try approach (3), which you can think of as retracing your steps backward whenever you are stuck:\nGo to an arbitrary friend X.\nRepeatedly do the following:\n    Ask X to introduce you to a friend of theirs \n    (whom you have not yet met).\n\n    if X introduces you to Y:\n        Remember that X introduced you to Y.\n        Declare that you have met Y.\n        Y is the new X.\n\n    else X has nothing new to offer:\n        Who introduced you to X?\n            Nobody: EXIT PARTY.\n            It was Z: Z is the new X.\nAs before, you should convince yourself that the process above indeed:\n\nensures you meet everyone who is accessible,\ndoes not have you meet anyone who is not accessible.\n\nFurther, you can also show that you exit the party before the party exits you: in other words, the process above does not go on forever. Why is this?\nWell, notice that you never meet someone for the first time more than once, so the if block inside Repeatedly triggers at most 1728 times.\nNow lets talk about the else block inside Repeatedly. Let us say that you get “stuck at someone” if they have nothing new to offer. Now we claim that you never get stuck at someone more than once. To see this, lets put ourselves in the shoes of someone — say 💃 — attending this party and largely minding their own business. From their perspective, a novice networker — say 🕺 — keeps approaching them to meet new people. They meet this person some k times: perhaps they hope that k is zero, but if they are not so lucky, then the meetings pan out as follows:\n\nthe first meeting when someone introduces 🕺 to 💃\n\nnow 💃 introduces 🕺 to a new person, say P_1.\n\nthe second meeting when 🕺 backtracks from P_1 back to 💃\n\nnow 💃 introduces 🕺 to a new person, say P_2.\n\nthe second meeting when 🕺 backtracks from P_2 back to 💃\n\nnow 💃 introduces 🕺 to a new person, say P_3.\n\nyada yada\nthe k^{th} meeting is when 🕺 backtracks from P_{k-1} back to 💃\n\nnow 💃 has nobody left to introduce 🕺 to.\n\n\nNote how all meetings but one are fruitful in that they lead to further progress, and it is only the last meeting where one gets stuck and backtracks from 💃. In other words, you never get stuck at the same person more than once, so the else block inside Repeatedly triggers at most 1728 times. So given a sufficiently long party, we will indeed build our lists in time."
  },
  {
    "objectID": "materials/dsanotes/dfs/index.html#paths-and-connectivity",
    "href": "materials/dsanotes/dfs/index.html#paths-and-connectivity",
    "title": "Navigating Graphs",
    "section": "Paths and Connectivity",
    "text": "Paths and Connectivity\nWe now turn to some definitions that are standard in graph theory. A path is a non-empty graph P=(V, E) of the form\n\nV=\\left\\{x_0, x_1, \\ldots, x_k\\right\\} \\quad E=\\left\\{x_0 x_1, x_1 x_2, \\ldots, x_{k-1} x_k\\right\\},\nwhere the x_i’s are all distinct.\nThe vertices x_0 and x_k are linked by P and are called its ends; the vertices x_1, \\ldots, x_{k-1} are the inner vertices of P.\nThe number of edges of a path is its length, and the path of length k is denoted by P^k.\nIf P=x_0 \\ldots x_{k-1} is a path and k \\geqslant 3, then the graph C:= P+x_{k-1} x_0 is called a cycle.\nThe distance d_G(x, y) in G of two vertices x, y is the length of a shortest x-y path in G; if no such path exists, we set d(x, y):=\\infty.\nThe greatest distance between any two vertices in G is the diameter of G, denoted by \\operatorname{d}(G).\nA non-empty graph G is called connected if any two of its vertices are linked by a path in G. If U \\subseteq V(G) and G[U] is connected, we also call U itself connected in G. A maximal connected subgraph of G is a connected component of G.\nGiven a vertex s in a graph G, we may want to know:\n\nthe size of the connected component that s belongs to;\nthe set of all vertices in the connected component that s belongs to;\nthe distance between s and t for some vertex t \\neq s;\nif s belongs to a cycle in G.\n\nIt turns out that navigation algorithms can help us address all these questions and then some."
  },
  {
    "objectID": "materials/dsanotes/dfs/index.html#breadth-first-search",
    "href": "materials/dsanotes/dfs/index.html#breadth-first-search",
    "title": "Navigating Graphs",
    "section": "Breadth-First Search",
    "text": "Breadth-First Search\nBreadth-first search maintains an evolving state of visited vertices. A vertex that is not yet upgrades itself to visited status if it is adjacent to a visited vertex. So we iteratively update the set of visited vertices — starting with just s as per tradition — by having the current set of visited vertices pull in their neighbors, and stop when there is nothing new to see.\nLetting visited denote a set of vertices in the global scope, one round of this process might look like this:\nexecute_one_round():\n    marked = {}\n    for all v in visited:\n        for all u in N(v):\n            if u is not in visited:\n                add u to marked\n    visited = visited U marked\nand now we keep going until we have nothing new to see:\nvisited = {s}\nwhile true:\n    prev = visited\n    execute_one_round()\n    if prev == visited:\n        exit\nNote that if working with a graph on n vertices as input, the while loop will run at most n times, and execute_one_round takes at most O(n^2) time, so overall we have an implementation that is straightforward but suffers a running time of O(n^3) overall.\n\nA Faster Implementation\nNotice that we are wasting time by pinging all visited vertices in every round: notice that only the new inductees are going to help with discovery — so we can save time by only focusing on them. This is what we did with the notebooks earlier: we only scanned volume t-1 in round t to develop volume t.\nThe most natural way of tracking the volumes efficiently is to use a queue: we begin by adding the starting point, and in general, pop elements off the queue. As we do that, we add any unvisited neighbors offered by the popped element back at the end:\nvisited[v] = -1 for all v\nvisited[s] = 0\nadd s to head of Q\nwhile Q is non-empty:\n    v = pop(Q) //remove the head of Q\n    for u in N(v):\n        if visited[u] is -1:\n            visited[u] = visited[v] + 1\n            push (Q,u)\nNow you might figure this to be an O(n^2) algorithm based on the fact that the while loop and the inner for loop run at most n times each, but you can in fact argue that the running time is bounded by O(n+m).\nTo see this, notice that the line u in N(v) is executed twice for every edge (p,q): once when p is at the head of the queue and once when q is at the head of the queue. Also notice that every vertex gets pushed on the queue at most once, so the line v = pop(Q) is executed at most n times. This gives us a tighter and neater upper bound of O(n+m). 🎉\nWe now argue that the procedure above sees exactly what it is supposed to see: nothing more and nothing less. Not only that: the visited array that we sneaked in tracks the “volume numbers” from the notebooks analogy, and in fact records distances from the starting point.\n\n\n\n\n\n\nLemma. For finite d, any vertex u is at a distance of d from s if and only if visited[u] = d.\n\n\n\nConsider the case of finite d. For both statements, we argue by induction on d. We omit the base cases because they are easy to verify.\nFirst, suppose visited[u] = d. Then:\n\nby the mechanics of the algorithm, there is a vertex v such that:\n\nu in N(v) and\nvisited[v] = d-1, and\n\nby the induction hypothesis, the distance of v from s is d-1.\n\nThe claim follows by adding u to the (d-1)-length path from s to v guaranteed by the induction hypothesis.\nNow, suppose u is at a distance of d from s. Then there is a path P of length d from s to u, and this is a shortest path. Let u’s neighbor on this path be v. Notice that the sub-path P that starts at s and ends at v is a shortest path between s and v — if not, then we could plug the edge (v,u) at the end of a hypothetical shorter path, say Q, to contradict the assumption that u is at a distance of d from s.\nApply the induction hypothesis on v to see that visited[v] = d-1. Notice that when v is popped from the queue, the visited array has values between -1 and d (inclusive). At this point, it must be the case that visited[u] = -1 or visited[u] = d: if not, then by previous claim, we again contradict our assumption about the distance of u from s. Now:\n\nif visited[u] = d, we are done, and\nif visited[u] = -1, then v pulls u into the queue and visited[u] = d after this step, so we are done again.\n\nNote that this implies that vertices unreachable from s are not visited.\n\n\n\n\n\n\nCorollary. We have that d(s,u) = \\infty if and only if visited[u] = -1."
  },
  {
    "objectID": "materials/dsanotes/dfs/index.html#depth-first-search",
    "href": "materials/dsanotes/dfs/index.html#depth-first-search",
    "title": "Navigating Graphs",
    "section": "Depth-First Search",
    "text": "Depth-First Search\nA Depth-First Search mainly involves:\n\na way of discovering new univisted neighbors so we can go forward\na way of remembering where we came from to be able to backtrack\n\nThe first is easily achieved by the use of a visited array again, and for the second, we introduce a prev array that can help us find our way back to where we came from. Here is an implementation that closely follows the description of the algorithm we discussed earlier. We throw in a clock variable and birth and death arrays for some extra bookkeeping that will help us remember the timing of our first and final encounters with the vertices that we meet as we go along.\nfor all v: prev[v] = -1 \n//prev[v] = -1 iff v is unvisited\n\ncurrent = s\nprev[s] = s\n\nclock = 0\n\nwhile true:\n    clock = clock + 1\n\n    X = unvisited_neighbor(current)\n    // this returns -1 if X has no univisited neighbors\n    // and an arbitrary unvisited neighbor otherwise\n\n    If X is not -1:\n    // we have discovered a new thing\n    \n        // lets remember where we came from:    \n        prev[X] = current\n        \n        // record the time of discovery:\n        birth[X] = clock\n        \n        // and then go to this new place:    \n        current = X\n    \n    \n\n    Else: \n    // i.e, X has no new neighbors to offer\n\n        If X == s:\n            // we are back where we started        \n            // and we are done:\n            break\n        \n        Else:\n            // we know where to go        \n            // step back to make progress:\n            set current to prev[current]\n            \n            // note that we are done with X:\n            set death[v] = clock\nTo analyze the running time here, we need to know how unvisited_neighbor() is implemented. Let us work with the adjacency list representation, and let’s say that for every vertex v, we have a pointer pv that initially points to the head of the adjacency list of v. Now consider the following implementation of unvisited_neighbor(), where we are using pv.vertex to denote the neighbor of v that pv is pointing to:\nunvisited_neighbor(v):\n    while prev[pv.vertex] != -1:\n        if pv->next is NULL:\n            return -1\n        else:\n            pv = pv->next\n    return pv.vertex\nNotice that the number of times the line:\nX = unvisited_neighbor(current)\nis executed is bounded by the total amount of “movement” experienced the pointers pv, where the totaling is being done over all vertices v. This is at most twice the number of edges.\nAlso observe that the if and else blocks can be triggered at most n times each since they correpsond to our first and last visits to a vertex, respectively.\nTherefore, the overall running time of the algorithm is O(m+n), just like it was with breadth-first search.\nAlso, as with breadth-first search, we can see that we visit exactly the vertices we are supposed to: the set of visited vertices coincides with the set of vertices reachable from s. First, we make note of the following invariant:\n\n\n\n\n\n\nLemma. For every vertex u, if prev[u] > -1 and v is a neighbor of u, then prev[v] > -1.\n\n\n\nThe intuition for this invariant is the following: once a vertex is “born”, we do not let it “die” until all its neighbors are visited. A visited vertex keeps feeding the algorithm its unvisited neighbors, thereby prolonging its own lifespan, until it runs out.\nSomewhat more formally, suppose prev[u] > -1 and, for the sake of contradiction, say prev[v] = -1 for some neighbor of u. Since prev[u] > -1, the line:\nX = unvisited_neighbor(current)\nis executed with current being u at least once.\nSince prev[v] = -1 at the end of the algorithm, note that prev[v] = -1 throughout the algorithm. However, none of the calls to unvisited_neighbor(u) could have possibly output v, since this would immediately lead to prev[v] being overwritten with u.\nFrom this we can only conclude that unvisited_neighbor(u) was dysfunctional: u had an unvisited neighbor v that was not returned by any of the calls to unvisited_neighbor(u), which is the desired contradiction.\n\n\n\n\n\n\nLemma. For every vertex u, d(s,u) = \\infty if and only if prev[u] = -1.\n\n\n\nWe first show that if prev[u] = -1 then d(s,u) = \\infty, the contrapositive of which is that everything reachable is visited.\nSuppose prev[u] = -1 but d(s,u) = d for some finite d. Then there is a path P from s to u of length d. Let v be the first vertex on this path for which prev[v] = -1, and let w be the previous vertex on the path; in other words, w is the nieghbor of v in P whose distance from s is the smallest.\nBy assumption, prev[w] is not -1, implying that w was in fact visited by the algorithm. However, if w is visited, then the mechanics of the algorithm ensures that all neighbors of w are visited as well (see above), and in particular, so is v. However, this contradicts our assumption that prev[v] = -1.\nWe now show that if d(s,u) = \\infty then prev[u] = -1, the contrapositive of which is that everything visited is reachable.\nLet us, in fact, establish the contrapositive: prev[u] > -1 implies that there exists a finite d for which d(s,u) \\leqslant d. The intuition here is that we can climb our way back to s from u following the previous pointers. We need to be sure that the previous pointers always exist and don’t send us around in cycles.\nIn particular, consider the following sequence of previous pointers:\nprev[u], prev[prev[u]], prev[prev[prev[u]]], …\nConsider the value of the clock when prev[u] is set: this coincides with birth[u]. Let us associate with prev[u] the time birth[u].\nNow, suppose prev[u] is v. Note that prev[u] = v implies that u is an unvsited neighbor of v, where v itself is a visited vertex. Therefore, prev[v] is also well-defined and associated with birth[v]. We can repeat this argument for every step of the sequence, noting that the clock value strictly decreases at every step: and hence the sequence must reach s, at which point we can truncate it.\nIt is also easy to check that the vertices in the sequence are distinct: if not, we will have to contend with time travel! For instance, say:\n\nprev[a] = b and birth[a] = p\nprev[b] = c and birth[b] = q\nprev[c] = a and birth[c] = r\n\nNote that p > q > r, so c was introduced by a at a time when a was not even visited, which is impossible. This argument is easily complicated completed with generic subscripts, an exercise we leave to the reader.\nFollowing the sequence backwards gives us the desired path, and its length is (loosely) upper bounded by birth[u], and we are done. 🎉\n\n\n\n\n\n\nFood For Thought\n\n\n\nShow that for any two vertices u and v, the intervals (birth[u],death[u]) and (birth[v],death[v]) are either such that one is strictly contained in another, or are fully disjoint.\n\n\n\n\n\n\n\n\nFood For Thought\n\n\n\nLet us say that a vertex v is alive when the clock value is T if:\n\nT > birth[v] and\nT < death[v].\n\nSuppose further that you were working with a directed graph. Show that if, when you visit a vertex u for the first time, there is an edge from u to some vertex v that is alive then, there is a cycle that contains u and v. Is it true that if a directed graph has a cycle, then you will have an edge of this form: one from a vertex newly visited to one that is alive?\nProtip: Google for backedges if you are trying to look this up!"
  },
  {
    "objectID": "materials/dsanotes/dfs/index.html#references",
    "href": "materials/dsanotes/dfs/index.html#references",
    "title": "Navigating Graphs",
    "section": "References",
    "text": "References\n\nHere are nice animated explanations, including actual implementations, for BFS and DFS.\nPlay around with examples of your own with visualgo implementations of graph traversals.\nThe following writeups emphasize recursive approaches to DFS:\n\nDFS on DAGs\nJeff Erickson on DFS"
  },
  {
    "objectID": "materials/dsanotes/traversals/index.html",
    "href": "materials/dsanotes/traversals/index.html",
    "title": "Navigating Graphs",
    "section": "",
    "text": "So far, we have been exploring graphs with an emphasis on visiting all the edges: we want to cross all our bridges, draw every line that there is, and so on. Now we will switch gears and obsess over visiting vertices instead. While the language in our conversation will implicitly assume that the graphs in question are undirected, everything we say here can be easily adapted to directed graphs as well. The pseudocode presented here is for graphs on n vertices with vertex labels ranging between 0 and n-1 (inclusive).\nTo illustrate, let us go way back in time to when Facebook was a thing. You start off by making your Facebook account, and making friends with everyone you know. Now, as a part of your preparations for the apocalypse1, you want to make a list of everyone who you believe is accessible to you: these are people who are your friends, of course, but also friends of your friends, because you trust your friends to put you in touch with their friends if you need it; but now we can extend this confidence to friends of those who are friends of your friends, and so on. To make the “and so on” bit explicit, let us define the set of people you can access as follows:\n\nyour friends on Facebook are accessible;\nif person A is accessible and person B is a Facebook friend of A, then A is also accessible.\n\nSo: how do you go about making this list? This is a good time to take a pause and work it out.\n\n\nWell, one natural way — at the risk of looking like a stalker — is the following. Let us call people on Facebook new if they are not yet on our list. To begin with, everyone is new and our list is empty. Also assume that all names are distinct2. Our list will spawn several notebooks, and we will build it up as follows.\n\non day 1, make a list of all your friends on Facebook in a notebook called Volume 1.\non day 2, go to the profiles of everyone you have listed in Volume 1. For each person, go through their friends list, and make a list of everyone who is new to you in Volume 2.\non day 3, go to the profiles of everyone you have listed in Volume 2. For each person, go through their friends list, and make a list of everyone who is new to you in Volume 3.\n\non day t, go to the profiles of everyone you have listed in Volume t-1. For each person, go through their friends list, and make a list of everyone who is new to you to Volume t. Stop if the new volume is empty.\n\n\n\n\n\n\n\nNew People Only!\n\n\n\nNotice that it is crucial that you only list people who are new to you. Consider an example where all of Facebook is three people: you and your friends Akash and Babita, who are friends with each other as well. Now Akash and Babita make it to Volume 1, but on day 2, if you are not careful about listing only new people, you will:\n\nadd Babita to Volume 2 based on Akash’s list, and\nadd Akash to Volume 2 based on Babita’s list.\n\nNow, since Volume 2 is the same as Volume 1, it will spawn an identical Volume 3, and this will go on ad infinitum, which is not what we want!\n\n\n\n\n\n\n\n\nFood For Thought\n\n\n\nHow long does it take to build up the whole list of accessible people, if all of Facebook has N people and everyone has at most D friends? Assume that you can figure out — when looking at a profile — whether it is new or not. This is not terribly unrealistic: for example, your browser typically tells you if you have visited a page before or not by coloring the links purple instead of blue, at least in the early days of Facebook.\n\n\nYou should convince yourself that the process above indeed:\n\nlists everyone who is accessible,\ndoes not list anyone who is not accessible, and\nterminates pre-apocalypse assuming that Facebook is finite.\n\n\n\n\nNow, suppose that you are going to attend a hypothetical Facebook party: all the first 1729 users will be there, and in particular, you will get to meet your seven friends as well. Now you want to say hi to everyone who’s accessible, and maybe get them to sign your slam book too: but you haven’t finished building your list yet!\nSo how do you go about discovering all the accessible people? Well, you do what people do at networking events3 — you ask to be introduced to someone you have not met already. Start by approaching a friend, who will introduce you to one of their friends, who may or may not be a mutual: but you move on to said friend regardless, who will in turn introduce you to someone else, etc.\nIn particular, let us proceed4 as follows:\nGo to an arbitrary friend `X`.\n\nRepeatedly do the following:\n    Declare under your breath that you have met `X`.\n    Ask X to introduce you to a friend of theirs \n    (whom you have not yet met).\n    \n    if X introduces you to Y:\n        Y is the new X.\n    \n    else X has nothing new to offer:\n        EXIT PARTY.\nClearly, everyone you meet this way is accessible, but do you get to meet everyone who is accessible?\n\n\n\n\n\n\nMisses\n\n\n\nSuppose you have a friend Ravi who knows both Seeta and Geeta, but Seeta and Geeta do not know each other. To begin with, you meet Ravi and say Ravi introduces you to Seeta. Seeta knows nobody whom you have not yet met, so you leave without meeting Geeta, but she was accessible! Had Ravi introduced you to Geeta instead, then you would have missed meeting Seeta with the approach above.\nPause and think about how you can fix your procedure so that you meet everyone who is accessible.\n\n\nOne way to expand the scope of people we meet at the party is by not giving up so early: specifically, if you meet someone who observes that you have already met all their friends, then you have a dead end, but for all you know you are just stuck in a local minima. You need to pull yourself up and keep looking — and there are a few different possibilities that you could experiment with here:\n\nfind another OG friend you have not met at the party and restart the process above\nfind a random person at the party to restart the process above\ngo back to the last person you were speaking with and continue the process above\n\nNote that with approach (1), you would still miss meeting either Seeta or Geeta in the example above, so while it’s a perfectly valid approach it may still fail to be comprehensive.\nThe issue with approach (2) — apart from the fact that it may not be well-suited to introverts — is that you might end up meeting and listing people who are not, in fact, accessible.\nSo let’s try approach (3), which you can think of as retracing your steps backward whenever you are stuck:\nGo to an arbitrary friend X.\nRepeatedly do the following:\n    Ask X to introduce you to a friend of theirs \n    (whom you have not yet met).\n\n    if X introduces you to Y:\n        Remember that X introduced you to Y.\n        Declare that you have met Y.\n        Y is the new X.\n\n    else X has nothing new to offer:\n        Who introduced you to X?\n            Nobody: EXIT PARTY.\n            It was Z: Z is the new X.\nAs before, you should convince yourself that the process above indeed:\n\nensures you meet everyone who is accessible,\ndoes not have you meet anyone who is not accessible.\n\nFurther, you can also show that you exit the party before the party exits you: in other words, the process above does not go on forever. Why is this?\nWell, notice that you never meet someone for the first time more than once, so the if block inside Repeatedly triggers at most 1728 times.\nNow lets talk about the else block inside Repeatedly. Let us say that you get “stuck at someone” if they have nothing new to offer. Now we claim that you never get stuck at someone more than once. To see this, lets put ourselves in the shoes of someone — say 💃 — attending this party and largely minding their own business. From their perspective, a novice networker — say 🕺 — keeps approaching them to meet new people. They meet this person some k times: perhaps they hope that k is zero, but if they are not so lucky, then the meetings pan out as follows.\n\nThe first meeting is when someone introduces 🕺 to 💃.\n\nNow 💃 introduces 🕺 to P_1, a new person.\n\nThe second meeting is when 🕺 backtracks from P_1 back to 💃.\n\nNow 💃 introduces 🕺 to P_2, a new person.\n\nThe third meeting is when 🕺 backtracks from P_2 back to 💃.\n\nNow 💃 introduces 🕺 to P_3, a new person. \\vdots\n\nThe k^{th} meeting is when 🕺 backtracks from P_{k-1} back to 💃.\n\nNow 💃 has nobody left to introduce 🕺 to.\n\n\nNote how all meetings but one are fruitful in that they lead to further progress, and it is only the last meeting where one gets stuck and backtracks from 💃. In other words, you never get stuck at the same person more than once, so the else block inside Repeatedly triggers at most 1728 times. So given a sufficiently long party, we will indeed build our lists in time.\n\n\n\nSo we have evidently figured out two ways of exploring the part of the graph accessible from a particular location. These belong to a family of graph traversal algorithms, dubbed Whatever-First-Search by Erickson, and can be generically described as follows:\nWhatever-First-Search(s):\n    put s into the bag\n    while the bag is not empty:\n        take v out of the bag\n        if v is unmarked\n            mark v\n                for each edge vw\n                    put w into the bag\n\n\n\nBread-first search, courtsey XKCD\n\n\nRecall that the notion of accessibility is recursively defined, so for many people it is most natural to think of the algorithms also as being recursive. In particular, it’s either:\n\nping all your friends, rinse, repeat, or\ngo to a friend, rinse, repeat;\n\nkeeping in mind that — in the spirit of recursion — when you are rinsing and repeating, you re-identify yourself as whoever you are working with currently, and also take care to ensure that you don’t end up going in circles forever by remembering what you have already seen and making good use of that intel.\n\n\n\nImagine that you open up Wikipedia’s featured article today, and it happens to be about Operation Flavius. Call this page P, and let’s say that another page Q on Wikipedia is reachable from P if you can arrive at Q by starting at P and following links that are visible on whatever the current page is. To make a list of all pages reachable from P, you can start with P as the current page and then either:\n\nopen up all blue links visible on the current page in background tabs, close the current page, and process the next tab similarly; or,\nopen the first blue link you see on the current page, and keep doing this, hitting the back button when you hit a page with no blue links.\n\nThe background tab hoarder is browsing breadth-first, while the distracted clicker is browsing depth-first :) With all this intuition collected, let us now describe professional-looking implementations for these algorithms and argue their correctness.\n\n\n\nThe problem with Wikipedia, as observed by XKCD"
  },
  {
    "objectID": "materials/dsanotes/traversals/index.html#paths-and-connectivity",
    "href": "materials/dsanotes/traversals/index.html#paths-and-connectivity",
    "title": "Navigating Graphs",
    "section": "Paths and Connectivity",
    "text": "Paths and Connectivity\nWe now turn to some definitions that are standard in graph theory. A path is a non-empty graph P=(V, E) of the form\n\nV=\\left\\{x_0, x_1, \\ldots, x_k\\right\\} \\quad E=\\left\\{x_0 x_1, x_1 x_2, \\ldots, x_{k-1} x_k\\right\\},\nwhere the x_i’s are all distinct.\nThe vertices x_0 and x_k are linked by P and are called its ends; the vertices x_1, \\ldots, x_{k-1} are the inner vertices of P.\nThe number of edges of a path is its length, and the path of length k is denoted by P^k.\nIf P=x_0 \\ldots x_{k-1} is a path and k \\geqslant 3, then the graph C:= P+x_{k-1} x_0 is called a cycle.\nThe distance d_G(x, y) in G of two vertices x, y is the length of a shortest x-y path in G; if no such path exists, we set d(x, y):=\\infty.\nThe greatest distance between any two vertices in G is the diameter of G, denoted by \\operatorname{d}(G).\nA non-empty graph G is called connected if any two of its vertices are linked by a path in G. If U \\subseteq V(G) and G[U] is connected, we also call U itself connected in G. A maximal connected subgraph of G is a connected component of G.\nGiven a vertex s in a graph G, we may want to know:\n\nthe size of the connected component that s belongs to;\nthe set of all vertices in the connected component that s belongs to;\nthe distance between s and t for some vertex t \\neq s;\nif s belongs to a cycle in G.\n\nIt turns out that navigation algorithms can help us address all these questions and then some."
  },
  {
    "objectID": "materials/dsanotes/traversals/index.html#breadth-first-search",
    "href": "materials/dsanotes/traversals/index.html#breadth-first-search",
    "title": "Navigating Graphs",
    "section": "Breadth-First Search",
    "text": "Breadth-First Search\nBreadth-first search maintains an evolving state of visited vertices. A vertex that is not yet upgrades itself to visited status if it is adjacent to a visited vertex. So we iteratively update the set of visited vertices — starting with just s as per tradition — by having the current set of visited vertices pull in their neighbors, and stop when there is nothing new to see.\nLetting visited denote a set of vertices in the global scope, one round of this process might look like this:\nexecute_one_round():\n    marked = {}\n    for all v in visited:\n        for all u in N(v):\n            if u is not in visited:\n                add u to marked\n    visited = visited U marked\nand now we keep going until we have nothing new to see:\nvisited = {s}\nwhile true:\n    prev = visited\n    execute_one_round()\n    if prev == visited:\n        exit\nNote that if working with a graph on n vertices as input, the while loop will run at most n times, and execute_one_round takes at most O(n^2) time, so overall we have an implementation that is straightforward but suffers a running time of O(n^3) overall.\n\nA Faster Implementation\nNotice that we are wasting time by pinging all visited vertices in every round: notice that only the new inductees are going to help with discovery — so we can save time by only focusing on them. This is what we did with the notebooks earlier: we only scanned volume t-1 in round t to develop volume t.\nThe most natural way of tracking the volumes efficiently is to use a queue: we begin by adding the starting point, and in general, pop elements off the queue. As we do that, we add any unvisited neighbors offered by the popped element back at the end:\nvisited[v] = -1 for all v\nvisited[s] = 0\nadd s to head of Q\nwhile Q is non-empty:\n    v = pop(Q) //remove the head of Q\n    for u in N(v):\n        if visited[u] is -1:\n            visited[u] = visited[v] + 1\n            push (Q,u)\nNow you might figure this to be an O(n^2) algorithm based on the fact that the while loop and the inner for loop run at most n times each, but you can in fact argue that the running time is bounded by O(n+m).\nTo see this, notice that the line u in N(v) is executed twice for every edge (p,q): once when p is at the head of the queue and once when q is at the head of the queue. Also notice that every vertex gets pushed on the queue at most once, so the line v = pop(Q) is executed at most n times. This gives us a tighter and neater upper bound of O(n+m). 🎉\nWe now argue that the procedure above sees exactly what it is supposed to see: nothing more and nothing less. Not only that: the visited array that we sneaked in tracks the “volume numbers” from the notebooks analogy, and in fact records distances from the starting point.\n\n\n\n\n\n\nLemma. For finite d, any vertex u is at a distance of d from s if and only if visited[u] = d.\n\n\n\nConsider the case of finite d. For both statements, we argue by induction on d. We omit the base cases because they are easy to verify.\nFirst, suppose visited[u] = d. Then:\n\nby the mechanics of the algorithm, there is a vertex v such that:\n\nu in N(v) and\nvisited[v] = d-1, and\n\nby the induction hypothesis, the distance of v from s is d-1.\n\nThe claim follows by adding u to the (d-1)-length path from s to v guaranteed by the induction hypothesis.\nNow, suppose u is at a distance of d from s. Then there is a path P of length d from s to u, and this is a shortest path. Let u’s neighbor on this path be v. Notice that the sub-path P that starts at s and ends at v is a shortest path between s and v — if not, then we could plug the edge (v,u) at the end of a hypothetical shorter path, say Q, to contradict the assumption that u is at a distance of d from s.\nApply the induction hypothesis on v to see that visited[v] = d-1. Notice that when v is popped from the queue, the visited array has values between -1 and d (inclusive). At this point, it must be the case that visited[u] = -1 or visited[u] = d: if not, then by previous claim, we again contradict our assumption about the distance of u from s. Now:\n\nif visited[u] = d, we are done, and\nif visited[u] = -1, then v pulls u into the queue and visited[u] = d after this step, so we are done again.\n\nNote that this implies that vertices unreachable from s are not visited.\n\n\n\n\n\n\nCorollary. We have that d(s,u) = \\infty if and only if visited[u] = -1."
  },
  {
    "objectID": "materials/dsanotes/traversals/index.html#depth-first-search",
    "href": "materials/dsanotes/traversals/index.html#depth-first-search",
    "title": "Navigating Graphs",
    "section": "Depth-First Search",
    "text": "Depth-First Search\nA Depth-First Search mainly involves:\n\na way of discovering new univisted neighbors so we can go forward\na way of remembering where we came from to be able to backtrack\n\nThe first is easily achieved by the use of a visited array again, and for the second, we introduce a prev array that can help us find our way back to where we came from. Here is an implementation that closely follows the description of the algorithm we discussed earlier. We throw in a clock variable and birth and death arrays for some extra bookkeeping that will help us remember the timing of our first and final encounters with the vertices that we meet as we go along.\nfor all v: prev[v] = -1 \n//prev[v] = -1 iff v is unvisited\n\ncurrent = s\nprev[s] = s\n\nclock = 0\n\nwhile true:\n    clock = clock + 1\n\n    X = unvisited_neighbor(current)\n    // this returns -1 if X has no univisited neighbors\n    // and an arbitrary unvisited neighbor otherwise\n\n    If X is not -1:\n    // we have discovered a new thing\n    \n        // lets remember where we came from:    \n        prev[X] = current\n        \n        // record the time of discovery:\n        birth[X] = clock\n        \n        // and then go to this new place:    \n        current = X\n    \n    \n\n    Else: \n    // i.e, X has no new neighbors to offer\n\n        If X == s:\n            // we are back where we started        \n            // and we are done:\n            break\n        \n        Else:\n            // we know where to go        \n            // step back to make progress:\n            set current to prev[current]\n            \n            // note that we are done with X:\n            set death[X] = clock\nTo analyze the running time here, we need to know how unvisited_neighbor() is implemented. Let us work with the adjacency list representation, and let’s say that for every vertex v, we have a pointer pv that initially points to the head of the adjacency list of v. Now consider the following implementation of unvisited_neighbor(), where we are using pv.vertex to denote the neighbor of v that pv is pointing to:\nunvisited_neighbor(v):\n    while prev[pv.vertex] != -1:\n        if pv->next is NULL:\n            return -1\n        else:\n            pv = pv->next\n    return pv.vertex\nConsider the number of times the line:\nX = unvisited_neighbor(current)\nis executed. Observe that this is bounded by the total amount of “movement” experienced the pointers pv, where the totaling is being done over all vertices v. Since the pointers always shift further along the adjacency lists, and the total length of all the adjacency lists put together is the sum of the degrees of all the vertices, we can bound the total amount of work by twice the number of edges.\nAlso observe that the if and else blocks can be triggered at most n times each since they correpsond to our first and last visits to a vertex, respectively.\nTherefore, the overall running time of the algorithm is O(m+n), just like it was with breadth-first search.\nAlso, as with breadth-first search, we can see that we visit exactly the vertices we are supposed to: the set of visited vertices coincides with the set of vertices reachable from s. First, we make note of the following invariant:\n\n\n\n\n\n\nLemma. For every vertex u, if prev[u] > -1 and v is a neighbor of u, then prev[v] > -1.\n\n\n\nThe intuition for this invariant is the following: once a vertex is “born”, we do not let it “die” until all its neighbors are visited. A visited vertex keeps feeding the algorithm its unvisited neighbors, thereby prolonging its own lifespan, until it runs out.\nSomewhat more formally, suppose prev[u] > -1 and, for the sake of contradiction, say prev[v] = -1 for some neighbor of u. Since prev[u] > -1, the line:\nX = unvisited_neighbor(current)\nis executed with current being u at least once.\nSince prev[v] = -1 at the end of the algorithm, note that prev[v] = -1 throughout the algorithm. However, none of the calls to unvisited_neighbor(u) could have possibly output v, since this would immediately lead to prev[v] being overwritten with u.\nFrom this we can only conclude that unvisited_neighbor(u) was dysfunctional: u had an unvisited neighbor v that was not returned by any of the calls to unvisited_neighbor(u), which is the desired contradiction.\n\n\n\n\n\n\nLemma. For every vertex u, d(s,u) = \\infty if and only if prev[u] = -1.\n\n\n\nWe first show that if prev[u] = -1 then d(s,u) = \\infty, the contrapositive of which is that everything reachable is visited.\nSuppose prev[u] = -1 but d(s,u) = d for some finite d. Then there is a path P from s to u of length d. Let v be the first vertex on this path for which prev[v] = -1, and let w be the previous vertex on the path; in other words, w is the nieghbor of v in P whose distance from s is the smallest.\nBy assumption, prev[w] is not -1, implying that w was in fact visited by the algorithm. However, if w is visited, then the mechanics of the algorithm ensures that all neighbors of w are visited as well (see above), and in particular, so is v. However, this contradicts our assumption that prev[v] = -1.\nWe now show that if d(s,u) = \\infty then prev[u] = -1, the contrapositive of which is that everything visited is reachable.\nLet us, in fact, establish the contrapositive: prev[u] > -1 implies that there exists a finite d for which d(s,u) \\leqslant d. The intuition here is that we can climb our way back to s from u following the previous pointers. We need to be sure that the previous pointers always exist and don’t send us around in cycles.\nIn particular, consider the following sequence of previous pointers:\nprev[u], prev[prev[u]], prev[prev[prev[u]]], …\nConsider the value of the clock when prev[u] is set: this coincides with birth[u]. Let us associate with prev[u] the time birth[u].\nNow, suppose prev[u] is v. Note that prev[u] = v implies that u is an unvsited neighbor of v, where v itself is a visited vertex. Therefore, prev[v] is also well-defined and associated with birth[v]. We can repeat this argument for every step of the sequence, noting that the clock value strictly decreases at every step: and hence the sequence must reach s, at which point we can truncate it.\nIt is also easy to check that the vertices in the sequence are distinct: if not, we will have to contend with time travel! For instance, say:\n\nprev[a] = b and birth[a] = p\nprev[b] = c and birth[b] = q\nprev[c] = a and birth[c] = r\n\nNote that p > q > r, so c was introduced by a at a time when a was not even visited, which is impossible. This argument is easily complicated completed with generic subscripts, an exercise we leave to the reader.\nFollowing the sequence backwards gives us the desired path, and its length is (loosely) upper bounded by birth[u], and we are done. 🎉\n\n\n\nCareful what you wish for with DFS (thanks again, XKCD)…\n\n\n\n\n\n\n\n\nFood For Thought\n\n\n\nShow that for any two vertices u and v, the intervals (birth[u],death[u]) and (birth[v],death[v]) are either such that one is strictly contained in another, or are fully disjoint.\n\n\n\n\n\n\n\n\nFood For Thought\n\n\n\nLet us say that a vertex v is alive when the clock value is T if:\n\nT > birth[v] and\nT < death[v].\n\nSuppose further that you were working with a directed graph. Show that if, when you visit a vertex u for the first time, there is an edge from u to some vertex v that is alive then, there is a cycle that contains u and v. Is it true that if a directed graph has a cycle, then you will have an edge of this form: one from a vertex newly visited to one that is alive?\nProtip: Google for backedges if you are trying to look this up!"
  },
  {
    "objectID": "materials/dsanotes/traversals/index.html#references",
    "href": "materials/dsanotes/traversals/index.html#references",
    "title": "Navigating Graphs",
    "section": "References",
    "text": "References\n\nHere are nice animated explanations, including actual implementations, for BFS and DFS.\nPlay around with examples of your own with visualgo implementations of graph traversals.\nThe following writeups emphasize recursive approaches to DFS:\n\nDFS on DAGs\nJeff Erickson on DFS"
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w10.html",
    "href": "courses/2023/01-ES242/labs/lab-w10.html",
    "title": "ES242. Data Structures and Algorithms I. Week 10 Lab",
    "section": "",
    "text": "Back to course page\n\n\n\n\n\n\nBFS and DFS Puzzles\n\n\n\n\n\n\n\n\n\nProblem 1. Make It Happen\n\n\n\n\n\nYou are playing a game on a coordinate grid that has n special locations that we call magical. If you are at a magical location L at (p,q), you can teleport to any other magical location that shares either the x-coordinate or the y-coordinate of L. These teleports are your only way of moving in the landscape of the game.\nYou want to ensure that if you start at any magical location, you should be able to reach any other magical location. This may not be possible with the original set of magical locations. You can open up new magical locations anywhere you like, but opening a new location is expensive. Therefore, you want to open as few new ones as possible.\nThe goal in this problem is to determine the smallest number of new magical locations that you have to open to achieve your goal of complete connectivity among magical locations.\n\n\nThe first line of input contains a single integer n (1 \\leqslant n \\leqslant 100) — the number of magical locations. Each of the following n lines contains two integers x_i and y_i (1 \\leqslant x_i, y_i \\leqslant 1000) — the coordinates of the i-th location.\nThe magical locations are all distinct.\n\n\n\nOutput the smallest number of new magical locations that you have to open to achieve your goal of complete connectivity among magical locations.\n\n\n\nSample Input\n2\n2 1\n1 2\nSample Output\n1\nSample Input\n2\n2 1\n4 1\nSample Output\n0\n\n\n\n\n\n\n\n\n\n\nProblem 2. Switching Lines\n\n\n\n\n\nYou are trying to navigate the Ahmedabad Metro, which consists of N stations and M railway lines.\nThe stations are numbered 1 through N.\nEach line is operated by a company. Each company has an identification number.\nThe i-th (1 \\leqslant i \\leqslant M) line connects station p_i and q_i bidirectionally. There is no intermediate station. This line is operated by company c_i.\nYou can change trains at a station where multiple lines are available.\nThe fare system used in this subway system works as follows.\n\nAs long as you only use lines that are operated by the same company, the fare remains 10 rupees.\nWhenever you change to a line that is operated by a different company from the current line, you will be charged an additional fare of 10 rupees.\nIn a case where you changed from some company A’s line to another company’s line, and then you change back to company A’s line, the additional fare is incurred again.\n\nYou begin at station 1 and you want to travel to station N using the metro. Find the minimum required fare.\n\n\nThe input is given in the following format. The first line consists of two space-separated integers, N and M. Then, M lines follow. The i-th line consists of three space-separated numbers p_i, q_i and c_i.\nN M\np1 q1 c1\n.\n.\n.\npM qM cM\n\n\n\nPrint the minimum required fare. If it is impossible to get to station N by subway, print -1 instead.\nSample Input 1\n3 3\n1 2 1\n2 3 1\n3 1 2\nSample Output 1\n10\nUse only company 1’s lines.\nSample Input 2\n8 11\n1 3 1\n1 4 2\n2 3 1\n2 5 1\n3 4 3\n3 6 3\n3 7 3\n4 8 4\n5 6 1\n6 7 5\n7 8 5\nSample Output 2\n20\nFirst, use company 1’s lines: 1 → 3 → 2 → 5 → 6. Then, use company 5’s lines: 6 → 7 → 8.\n\n\n\n\n\n\n\n\n\n\nProblem 3. Prolonged Vacation\n\n\n\n\n\nYou have won a contest, and the prize is a free flight trip that can consist of one or more flights through cities. Of course, you want to max out on the prize and make the trip as long as possible.\nIn particular, you want to fly from Ahmedabad to Mumbai while visiting the maximum number of cities. You are given the list of possible flights, and you are also given that there are no directed cycles in the flight network.\n\n\nThe first input line has two integers n and m: the number of cities and flights.\nThe cities are numbered 1,2,\\ldots,n.\nCity 1 is Ahmedabad, and City n is Mumbai.\nAfter this, there are m lines describing the flights. Each line has two integers a and b: there is a flight from city a to city b.\nNote that each flight is a one-way flight.\n\n\n\nFirst print the maximum number of cities on the route. If there are no solutions, print “IMPOSSIBLE”.\n(While this is not required for the lab submission, as a bonus problem, try to modify your code so that it also prints the cities in the order they will be visited.)\nSample Input\n5 5\n1 2\n2 5\n1 3\n3 4\n4 5\nSample Output\n4\nNote that 1 3 4 5 is a valid route."
  },
  {
    "objectID": "blog/13-sheep/index.html",
    "href": "blog/13-sheep/index.html",
    "title": "13 Sheep",
    "section": "",
    "text": "So 13 Sheep is cute roll-and-write game that involves protecting a bunch of sheep on a grid by placing small fences that have pre-defined shapes. The initial position of a certain number — typically 13, as the name suggests — of sheep over a 7x7 grid is given. Some grid edges are not available because there happen to be bushes: so you cannot fence them. The bushes do not protect the sheep either, the wolf can slide under them.\nYour goal is to enclose as many sheep as possible: the ones that are not fully protected by fences may, alas, be at considerable risk when the inevitable wolf attack happens.\nThere are three main constrianing factors in this game:\n\nThe shape of the fences that you can draw are determined by the roll of a die;\nYou cannot overwrite lines that are already drawn, you cannot also draw over bushes;\nYou have ~11 chances to place your randomly gifted fence shapes.\n\nYou can find out more about the game here, where you can generate board layouts to print and play as well.\nI found this game a lot of fun to play, and I thought it would be lovely to be able to play it on a computer, where the user can decide how many rounds, sheep, and bushes they want to play with. Given also that chatGPT has been apparently remarkably adept at coding games, I figured I’d give it a shot.\nMy first prompt was just a polite inquiry about whether chatGPT would be willing to participate in this exercise:\n\n\n\n\n\n\nWe want to code a game called 13 Sheep using HTML, CSS, and Javascript. Ready?\n\n\n\nAnd well, it immediately made this, based on the prompt above: a game where you get to count to 13 sheep. Huh. Promising.\nIn my next few prompts, I steered it away from the default game. The first few steps just involved setting up the UI:\n\n\n\n\n\n\nGreat start! Please make the main canvas a square and draw a 7 x 7 grid in it. I want all the corners of the cells to look like small + signs. Do not draw any grid borders yet.\n\n\n\n\n\n\n\n\n\nNice, how can I make the grid background mediumseagreen?\n\n\n\n\n\n\n\n\n\nOn load, I want 13 grid cells to be identified at random, and the image sheep.png to be placed at their centers, appropriately scaled to fit.\n\n\n\nAt this point I already had a nice-looking grid with 13 sheep on it (thanks to Flaticon for the cute sheep icon). The plus signs drawn on the boundary were oddly cropped out, so we fixed that next:\n\n\n\n\n\n\nOk this looks great. Can you update the drawcross function so that crosses are also drawn on the grid boundary? And make the canvas a little bigger if needed so the entire cross is visible?\n\n\n\nThis didn’t immediately work but some nudging fixed it:\n\n\n\n\n\n\nThe crosses at the bottom are getting cut off and now the sheep are off center. Please fix?\n\n\n\nNow we draw the bushes:\n\n\n\n\n\n\nVery nice. Can you randomly select 7 cells now and for each such cell make one of the cell boundaries colored indianred?\n\n\n\nNext we get the dice roll UI up:\n\n\n\n\n\n\nExcellent. Now please add six divs below the canvas, centered, evenly spaced, and with a light grey circular background, with the text 1, 2, 3, 4, 5, and 6 written inside them. Note that the first div should have the text 1, the second should have 2, and so on. Make sure the divs have at least 10px spacing between them.\nBelow these divs, please add a large button in the shape of a rounded rectangle, with the text “Roll Dice” written on it. The background color for this button should be indianred with a transparency of 0.42.\n\n\n\nThis actually worked out of the box, the next step was to make the roll dice functional:\n\n\n\n\n\n\nSuper nice!\nNow can you make it so that when the user clicks on the button labeled “Roll Dice”, we generate a number between 1 and 6 at random, and highlight the corresponding circular div by changing its background to Lavendar, while also resetting any previous highlight?\n\n\n\nSo far, so good. Now all that was left was to get the fences drawn depending on what dice was rolled out.\n\n\n\n\n\n\nFence Shapes Based on Dice Rolls\n\n\n\n\n\n\n\n\nDice Roll 1\n\n\n\n\n\n\nDice Roll 2\n\n\n\n\n\n\nDice Roll 3\n\n\n\n\n\n\nDice Roll 4\n\n\n\n\n\n\nDice Roll 5\n\n\n\n\n\n\nDice Roll 6\n\n\n\n\n\nThis was perhaps the trickiest bit. My first attempt was this prompt here:\n\n\n\n\n\n\nGreat! Now can you update it so that:\nif the outcome of the dice roll is a 1, the cursor should change to a shape that looks like a U, and nothing outside the grid should be clickable. If the user clicks on a grid cell, then the left, bottom, and right borders of the cell should change color and become a thick line colored in olivedrab. Once the user has clicked on a grid cell the cursor should change back to normal.\nif the outcome of the dice roll is a 2, the cursor should change to a shape that looks like a long line, and nothing outside the grid should be clickable, and none of the cells in the last column should be clickable either. If the user clicks on a grid cell, then the bottom border of the cell should change color and become a thick line colored in olivedrab, and the the bottom border of the horizontally adjacent cell should change color and become a thick line colored in olivedrab. Once the user has clicked on a grid cell the cursor should change back to normal.\n\n\n\nMy hope was that the change of cursor would be a good way for the player to register that they need to move on the grid now. At this point, I was not thinking about the different orientations of the fences, because I was not sure about how to incorporate that into the UI (my first thought was to have the fences rotate on subsequent clicks until the player clicks on a confirm button, but that seemed too messy). I also did not give all six scenarios in one go since — from recent experience — the interface dies out on longer requests. You can prod it to continue from where it left off, but it’s typically messy.\nIn any case, we could not get the change of cursor to work. At this point, note that the code is also not tracking what borders are colored, so even as we got things to mildly work, we were often overwriting fences and bushes. So anyway, at some point I gave up and it was back to square one, but smaller steps. First, instead of a change of cursor, I just requested a canvas background color change to subtly communicate a change of game state:\n\n\n\n\n\n\nOnce the dice roll button is clicked, can you change the background of the canvas to dodgerblue with transparency 0.42, and disable the roll dice button until the user clicks on a grid cell?\n\n\n\nThen we added a round tracker:\n\n\n\n\n\n\nAdd the following text just below the “Roll Dice” button: “Roll a dice now, 11 rounds left”. Every time the user clicks on “Roll Dice”, change the text to “Place a fence now.” Once the user clicks on a grid cell, change the text back to “Roll a dice now, 11 rounds left”, but decrease the number of rounds by one each time. Can you do this?\n\n\n\nThis took some back and forth to get working, since it was getting some details mixed up, but it was finally alright. I had to prompt more to take care of some edge cases and minor details, for instance:\n\n\n\n\n\n\nAnyway, can you make it so that when there are 0 rounds left, the text simply says “Game Over”?\nAlso when the roll dice button is not active, can it have a grey background? Only when it is not active.\n\n\n\nNow we are back to actually trying to get the fences to be drawn. With some nervousness, I go:\n\n\n\n\n\n\nVery nice. Now, if the dice roll is a 1 and the user clicks on a grid cell, can you do the following?\n\nlet us say that a cell is valid if the top, left, and bottom borders of the grid have no visible borders.\nif the cell is valid, then make its top, left, and bottom borders colored olivedrab.\n\n\n\n\nAt this point the code generated starts tracking what borders are visible: I had to prompt it explicitly to update the function that generated the bushes to feed into the visibility states, but this went off pretty smoothly. For quite some time the fences drawn were not the ones I wanted, but after a few nudges it got it about right.\nNow it occured to me that I could actually show the orientations after the dice is rolled and the user can select one of them, and we can draw the appropriate fence after this selection is made.\n\n\n\n\n\n\nGreat. This works. Now below the instruction-text element, please add another div with ID “orientation-select” that begins with the text: “Pick an orientation”. Below this, add four circular divs with a light grey backgorund with the content: “0”, “90”, “180”, “270”. This div should only be visible when the gamestate is “chooseFenceOrientation” or “placeFence”.\nOnce a dice is rolled, the game state should change to chooseFenceOrientation and the user should be allowed to click any of these four divs. Once the user clicks one of the four divs, highlight it with the color burntorange and change the gamestate to placeFence. Store the choice of which div the user clicked on in a variable called fenceorientation and change the game state to placeFence.\nOnce the user clicks on a grid cell, clear the burntorange highlight and hide the “orientation-select” div, as it should not be visible any more.\n\n\n\nOf course in the UI at the moment we just have these four numbers so it does not make a lot of sense to the player, so I whipped some images to show the user what fences would be drawn depending on what grid cell was clicked.\nNow we come back to the fence drawing thing to account for the orientations as well:\n\n\n\n\n\n\nIn the handleGridClick() function, we want to implement the following functionality.\nIf the outcome is 1 and the orientation is 0, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if the top, left, and bottom borders of the grid have no visible borders.\nif the cell is valid, then make its top, left, and bottom borders colored olivedrab.\n\nIf the outcome is 1 and the orientation is 90, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if the right, left, and bottom borders of the grid have no visible borders.\nif the cell is valid, then make its right, left, and bottom borders colored olivedrab.\n\nIf the outcome is 1 and the orientation is 180, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if the right, top, and bottom borders of the grid have no visible borders.\nif the cell is valid, then make its right, top, and bottom borders colored olivedrab.\n\nIf the outcome is 1 and the orientation is 270, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if the right, left, and top borders of the grid have no visible borders.\nif the cell is valid, then make its right, left, and top borders colored olivedrab.\n\nPlease remember to use the drawBorder function from before as you work out these cases. Also remember to update the grid visibility values, for the two relevant cells per border drawn. Thanks.\n\n\n\nGetting this going for all the 20 different cases was really the bulk of the back and forth. While it got the overall functionality right, there would be small and frequent bugs in the details. For instance, if a cell’s top border is being fenced, then the cell above it should have its bottom border’s visibility updated: it knows this, but frequently got combinations wrong, and so I did have to read the code generated carefully. I either fixed it manually when the bugs were minor, or went back to requesting corrections by explaining the issue when it was off by a whole lot.\nYou can see that some of the prompts are longer than the corresponding code :D\n\n\n\n\n\n\nLooks great! Lets continue with our updates. Please remember to account for all the cases when updating the grid visibility values.\nIf the outcome is 4 and the orientation is 0, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if its bottom and left borders are not visible and the horizontally adjacent cell (i.e, the cell to the right of it) also does not have a bottom border. if a cell is on the right-most column, it is automatically not valid.\nif the cell is valid, then make its bottom and left borders colored olivedrab. Also make the bottom border of the horizontally adjacent cell colored olivedrab. Update the grid visibility values as appropriate.\n\nIf the outcome is 4 and the orientation is 180, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if its top border is not visible and the horizontally adjacent cell (i.e, the cell to the right of it) also does not have a top border and the horizontally adjacent cell (i.e, the cell to the right of it) also does not have a right border. if a cell is on the right-most column, it is automatically not valid.\nif the cell is valid, then make its top border colored olivedrab. Also make the top border of the horizontally adjacent cell colored olivedrab. Also make the right border of the horizontally adjacent cell colored olivedrab. Update the grid visibility values as appropriate.\n\nIf the outcome is 4 and the orientation is 90, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if its top and left borders are not visible and the vertically adjacent cell (i.e, the cell below it) also does not have a left border. if a cell is on the right-most column, it is automatically not valid.\nif the cell is valid, then make its top and left borders colored olivedrab. Also make the left border of the vertically adjacent cell colored olivedrab. Update the grid visibility values as appropriate.\n\nIf the outcome is 4 and the orientation is 270, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if its bottom and right borders are not visible and the vertically adjacent cell (i.e, the cell to the top of it) also does not have a right border. if a cell is on the right-most column, it is automatically not valid.\nif the cell is valid, then make its bottom and right borders colored olivedrab. Also make the right border of the vertically adjacent cell colored olivedrab. Update the grid visibility values as appropriate.\n\n\n\n\nMaybe it’ll soon be possible to just upload a picture of the game instruction booklet and let chatGPT do the rest of the heavy lifting. Until then, this was the best I could think of: maybe there’s a shorter way? I did try using generic shape descriptions, but no luck on those.\nNow the basic game was done, and there were three main features I’d have really liked to add at this point:\n\nAllow the user undo the previous fence placement.\nCount the number of protected sheep at the end.\nMake a version of this game where instead of rolling a dice, we let the user pick the fences they want: this can be useful for a multiplayer setting where we want the random choices to be the same for all players: so one player can roll the dice and the others can follow along.\n\nI did try some of this: it’s impressive that chatGPT gets the main ideas right the first two requirements (the use of an action stack for implementing undo, and recognizing that we need some kind of flood fill algorithm for the score). However, all the implementations ended up being somewhat buggy and after some wrestling I decided to push these extras to the roadmap. The deterministic version of the game should not be hard to make, even manually at this point, so I hope to come back to it soon.\nAfter this I mainly asked for chatGPT to let the user customize the parameters of the game:\n\n\n\n\n\n\nCan you make it so that when the page loads we ask the user (via an alert) for a number between 7 and 32 and set the number of rounds to the number specified by the user?\n\n\n\nIt got this immediately right, and I wanted some styling:\n\n\n\n\n\n\nCan you add some css styling so that this prompt looks nice?\n\n\n\nand it’s response was:\n\n\n\n\n\n\nUnfortunately, you cannot directly style the default JavaScript prompt function. Instead, you can create a custom modal using HTML, CSS, and JavaScript to achieve a more visually appealing and flexible solution.\nHere’s an example of how you can create a custom modal to ask for the number of rounds:\n…\n\n\n\nGood to know! The modals worked out of the box, and it was easy to extend them so they asked for the number of sheep and bushes as well. The last thing I wanted to add was a sharing feature:\n\n\n\n\n\n\nCan you add code so that the user can share a screenshot of just the canvas once the game is over? So once the game is over, I want to show a link called “Share My Game!” The screenshot and options to share on social media should show up in a modal when the user clicks this link.\n\n\n\nNow this it did remarkably well, except that when it tried to pass the entire image as a URL parameter, that didn’t work out. When I conveyed this, the response was:\n\n\n\n\n\n\nI apologize for the inconvenience. The reason for this issue is that sharing an image directly using a URL is not possible due to security reasons. To share your game image on social media platforms like Facebook and Twitter, you’ll need to use their respective APIs.\nHere’s a modified approach for sharing the image on Facebook and Twitter. You’ll need to create Facebook and Twitter developer accounts and register your app to get the API keys.\n\n\n\nWhoa… so ok, I don’t have developer accounts and I was not going to follow through, but this was definitely interesting!\nI did interleave responses from chatGPT with help from Ghostwriter, which is the intelligence built into repl.it out of the box. Ghostwriter’s responses were usually not as sophisticated on comparable prompts, but on a couple of occassions chatGPT was completely lost on why something wasn’t working, but Ghostwriter would figure it out when asked pointed questions about an error.\nAnyway, I cleaned up a little further with some styling, and the game is here, while the source is here."
  },
  {
    "objectID": "blog/13sheep/index.html",
    "href": "blog/13sheep/index.html",
    "title": "13 Sheep",
    "section": "",
    "text": "13 Sheep happens to be a cute roll-and-write game designed by Moritz Dressler that involves protecting a bunch of sheep on a grid by placing small fences that have pre-defined shapes.\n\n\n\nThe Roll and Write Game\n\n\nThe initial position of a certain number — typically 13, as the name suggests — of sheep over a 7x7 grid is given. Some grid edges are not available because there happen to be bushes: so you cannot fence them. The bushes do not protect the sheep either, the wolf can slide under them.\nYour goal is to enclose as many sheep as possible: the ones that are not fully protected by fences may, alas, be at considerable risk when the inevitable wolf attack happens.\nThere are three main constrianing factors in this game:\n\nThe shape of the fences that you can draw are determined by the roll of a die;\nYou cannot overwrite lines that are already drawn, you cannot also draw over bushes;\nYou have ~11 chances to place your randomly gifted fence shapes.\n\nYou can find out more about the game here, where you can generate board layouts to print and play as well.\nI found this game a lot of fun to play, and I thought it would be lovely to be able to play it on a computer, where the user can decide how many rounds, sheep, and bushes they want to play with. Given also that chatGPT has been apparently remarkably adept at coding games, I figured I’d give it a shot1.\nI describe my conversation with chatGPT below, but if you just want to cut to the case and check the game out, you can find the playable version here and the source here.\nHere’s what we finally built:\n\n\n\nThe 13 Sheep UI\n\n\nAnd once you’ve finished playing you can share your accomplishment like so:\n\n\n\nOne of my completed games… where we protect five sheep, can you figure out how many rounds?\n\n\n\nSo, back to chatGPT. My first prompt was just a polite inquiry about willingness to participate in this exercise:\n\n\n\n\n\n\nWe want to code a game called 13 Sheep using HTML, CSS, and Javascript. Ready?\n\n\n\nAnd well, it immediately made this, based on the prompt above: a game where you get to count to 13 sheep. Huh. Promising.\nIn my next few prompts, I steered it away from the default game. The first few steps just involved setting up the UI:\n\n\n\n\n\n\nGreat start! Please make the main canvas a square and draw a 7 x 7 grid in it. I want all the corners of the cells to look like small + signs. Do not draw any grid borders yet.\n\n\n\n\n\n\n\n\n\nNice, how can I make the grid background mediumseagreen?\n\n\n\n\n\n\n\n\n\nOn load, I want 13 grid cells to be identified at random, and the image sheep.png to be placed at their centers, appropriately scaled to fit.\n\n\n\nAt this point I already had a nice-looking grid with 13 sheep on it (thanks to Flaticon for the cute sheep icon). The plus signs drawn on the boundary were oddly cropped out, so we fixed that next:\n\n\n\n\n\n\nOk this looks great. Can you update the drawcross function so that crosses are also drawn on the grid boundary? And make the canvas a little bigger if needed so the entire cross is visible?\n\n\n\nThis didn’t immediately work but some nudging fixed it:\n\n\n\n\n\n\nThe crosses at the bottom are getting cut off and now the sheep are off center. Please fix?\n\n\n\nThat worked — phew! Now we draw the bushes:\n\n\n\n\n\n\nVery nice. Can you randomly select 7 cells now and for each such cell make one of the cell boundaries colored indianred?\n\n\n\nNext we get the dice roll UI up:\n\n\n\n\n\n\nExcellent. Now please add six divs below the canvas, centered, evenly spaced, and with a light grey circular background, with the text 1, 2, 3, 4, 5, and 6 written inside them. Note that the first div should have the text 1, the second should have 2, and so on. Make sure the divs have at least 10px spacing between them.\nBelow these divs, please add a large button in the shape of a rounded rectangle, with the text “Roll Dice” written on it. The background color for this button should be indianred with a transparency of 0.42.\n\n\n\nThis actually worked out of the box, the next step was to make the roll dice functional:\n\n\n\n\n\n\nSuper nice!\nNow can you make it so that when the user clicks on the button labeled “Roll Dice”, we generate a number between 1 and 6 at random, and highlight the corresponding circular div by changing its background to Lavendar, while also resetting any previous highlight?\n\n\n\nSo far, so good. Now all that was left was to get the fences drawn depending on what dice was rolled out.\n\n\n\n\n\n\nFence Shapes Based on Dice Rolls\n\n\n\n\n\n\n\n\nDice Roll 1\n\n\n\n\n\n\nDice Roll 2\n\n\n\n\n\n\nDice Roll 3\n\n\n\n\n\n\nDice Roll 4\n\n\n\n\n\n\nDice Roll 5\n\n\n\n\n\n\nDice Roll 6\n\n\n\n\n\nThis was perhaps the trickiest bit. My first attempt was this prompt here:\n\n\n\n\n\n\nGreat! Now can you update it so that:\nif the outcome of the dice roll is a 1, the cursor should change to a shape that looks like a U, and nothing outside the grid should be clickable. If the user clicks on a grid cell, then the left, bottom, and right borders of the cell should change color and become a thick line colored in olivedrab. Once the user has clicked on a grid cell the cursor should change back to normal.\nif the outcome of the dice roll is a 2, the cursor should change to a shape that looks like a long line, and nothing outside the grid should be clickable, and none of the cells in the last column should be clickable either. If the user clicks on a grid cell, then the bottom border of the cell should change color and become a thick line colored in olivedrab, and the the bottom border of the horizontally adjacent cell should change color and become a thick line colored in olivedrab. Once the user has clicked on a grid cell the cursor should change back to normal.\n\n\n\nMy hope was that the change of cursor would be a good way for the player to register that they need to move on the grid now. At this point, I was not thinking about the different orientations of the fences, because I was not sure about how to incorporate that into the UI (my first thought was to have the fences rotate on subsequent clicks until the player clicks on a confirm button, but that seemed too messy). I also did not give all six scenarios in one go since — from recent experience — the interface dies out on longer requests. You can prod it to continue from where it left off, but it’s typically messy.\nIn any case, we could not get the change of cursor to work. At this point, note that the code is also not tracking what borders are colored, so even as we got things to mildly work, we were often overwriting fences and bushes. So anyway, at some point I gave up and it was back to square one, but smaller steps. First, instead of a change of cursor, I just requested a canvas background color change to subtly communicate a change of game state:\n\n\n\n\n\n\nOnce the dice roll button is clicked, can you change the background of the canvas to dodgerblue with transparency 0.42, and disable the roll dice button until the user clicks on a grid cell?\n\n\n\nThen we added a round tracker:\n\n\n\n\n\n\nAdd the following text just below the “Roll Dice” button: “Roll a dice now, 11 rounds left”. Every time the user clicks on “Roll Dice”, change the text to “Place a fence now.” Once the user clicks on a grid cell, change the text back to “Roll a dice now, 11 rounds left”, but decrease the number of rounds by one each time. Can you do this?\n\n\n\nThis took some back and forth to get working, since it was getting some details mixed up, but it was finally alright. I had to prompt more to take care of some edge cases and minor details, for instance:\n\n\n\n\n\n\nAnyway, can you make it so that when there are 0 rounds left, the text simply says “Game Over”?\nAlso when the roll dice button is not active, can it have a grey background? Only when it is not active.\n\n\n\nNow we are back to actually trying to get the fences to be drawn. With some nervousness, I go:\n\n\n\n\n\n\nVery nice. Now, if the dice roll is a 1 and the user clicks on a grid cell, can you do the following?\n\nlet us say that a cell is valid if the top, left, and bottom borders of the grid have no visible borders.\nif the cell is valid, then make its top, left, and bottom borders colored olivedrab.\n\n\n\n\nAt this point the code generated starts tracking what borders are visible. I did have to prompt it explicitly to update the earlier function that generated the bushes to feed into the visibility states. However, this went off pretty smoothly overall. For quite some time the fences drawn when the user clicked a grid cell were not the ones I wanted, but after a few nudges it got it about right.\nNow it occured to me that I could actually show the orientations after the dice is rolled and the user can select one of them, and we can draw the appropriate fence after this selection is made.\n\n\n\n\n\n\nGreat. This works. Now below the instruction-text element, please add another div with ID “orientation-select” that begins with the text: “Pick an orientation”. Below this, add four circular divs with a light grey backgorund with the content: “0”, “90”, “180”, “270”. This div should only be visible when the gamestate is “chooseFenceOrientation” or “placeFence”.\nOnce a dice is rolled, the game state should change to chooseFenceOrientation and the user should be allowed to click any of these four divs. Once the user clicks one of the four divs, highlight it with the color burntorange and change the gamestate to placeFence. Store the choice of which div the user clicked on in a variable called fenceorientation and change the game state to placeFence.\nOnce the user clicks on a grid cell, clear the burntorange highlight and hide the “orientation-select” div, as it should not be visible any more.\n\n\n\nOf course in the UI at the moment we just have these four numbers so it does not make a lot of sense to the player, so I whipped some images to show the user what fences would be drawn depending on what grid cell was clicked.\nNow we come back to the fence drawing thing to account for the orientations as well:\n\n\n\n\n\n\nIn the handleGridClick() function, we want to implement the following functionality.\nIf the outcome is 1 and the orientation is 0, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if the top, left, and bottom borders of the grid have no visible borders.\nif the cell is valid, then make its top, left, and bottom borders colored olivedrab.\n\nIf the outcome is 1 and the orientation is 90, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if the right, left, and bottom borders of the grid have no visible borders.\nif the cell is valid, then make its right, left, and bottom borders colored olivedrab.\n\nIf the outcome is 1 and the orientation is 180, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if the right, top, and bottom borders of the grid have no visible borders.\nif the cell is valid, then make its right, top, and bottom borders colored olivedrab.\n\nIf the outcome is 1 and the orientation is 270, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if the right, left, and top borders of the grid have no visible borders.\nif the cell is valid, then make its right, left, and top borders colored olivedrab.\n\nPlease remember to use the drawBorder function from before as you work out these cases. Also remember to update the grid visibility values, for the two relevant cells per border drawn. Thanks.\n\n\n\nGetting this going for all the 20 different cases was really the bulk of the back and forth. While it got the overall functionality right, there would be small and frequent bugs in the details. For instance, if a cell’s top border is being fenced, then the cell above it should have its bottom border’s visibility updated: it knows this, but frequently got combinations wrong, and so I did have to read the code generated carefully. I either fixed it manually when the bugs were minor, or went back to requesting corrections by explaining the issue when it was off by a whole lot.\nYou can see that some of the prompts are longer than the corresponding code :D\n\n\n\n\n\n\nLooks great! Lets continue with our updates. Please remember to account for all the cases when updating the grid visibility values.\nIf the outcome is 4 and the orientation is 0, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if its bottom and left borders are not visible and the horizontally adjacent cell (i.e, the cell to the right of it) also does not have a bottom border. if a cell is on the right-most column, it is automatically not valid.\nif the cell is valid, then make its bottom and left borders colored olivedrab. Also make the bottom border of the horizontally adjacent cell colored olivedrab. Update the grid visibility values as appropriate.\n\nIf the outcome is 4 and the orientation is 180, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if its top border is not visible and the horizontally adjacent cell (i.e, the cell to the right of it) also does not have a top border and the horizontally adjacent cell (i.e, the cell to the right of it) also does not have a right border. if a cell is on the right-most column, it is automatically not valid.\nif the cell is valid, then make its top border colored olivedrab. Also make the top border of the horizontally adjacent cell colored olivedrab. Also make the right border of the horizontally adjacent cell colored olivedrab. Update the grid visibility values as appropriate.\n\nIf the outcome is 4 and the orientation is 90, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if its top and left borders are not visible and the vertically adjacent cell (i.e, the cell below it) also does not have a left border. if a cell is on the right-most column, it is automatically not valid.\nif the cell is valid, then make its top and left borders colored olivedrab. Also make the left border of the vertically adjacent cell colored olivedrab. Update the grid visibility values as appropriate.\n\nIf the outcome is 4 and the orientation is 270, then do the following when the user clicks on a grid cell.\n\nlet us say that a cell is valid if its bottom and right borders are not visible and the vertically adjacent cell (i.e, the cell to the top of it) also does not have a right border. if a cell is on the right-most column, it is automatically not valid.\nif the cell is valid, then make its bottom and right borders colored olivedrab. Also make the right border of the vertically adjacent cell colored olivedrab. Update the grid visibility values as appropriate.\n\n\n\n\nMaybe it’ll soon be possible to just upload a picture of the game instruction booklet and let chatGPT do the rest of the heavy lifting. Until then, this was the best I could think of: maybe there’s a shorter way? I did try using generic shape descriptions, but no luck on those.\nNow the basic game was done, and there were three main features I’d have really liked to add at this point:\n\nAllow the user undo the previous fence placement.\nCount the number of protected sheep at the end.\nMake a version of this game where instead of rolling a dice, we let the user pick the fences they want: this can be useful for a multiplayer setting where we want the random choices to be the same for all players: so one player can roll the dice and the others can follow along.\n\nI did try some of this: it’s impressive that chatGPT gets the main ideas right the first two requirements (the use of an action stack for implementing undo, and recognizing that we need some kind of flood fill algorithm for the score). However, all the implementations ended up being somewhat buggy and after some wrestling I decided to push these extras to the roadmap. The deterministic version of the game should not be hard to make, even manually at this point, so I hope to come back to it soon.\nAfter this I mainly asked for chatGPT to let the user customize the parameters of the game:\n\n\n\n\n\n\nCan you make it so that when the page loads we ask the user (via an alert) for a number between 7 and 32 and set the number of rounds to the number specified by the user?\n\n\n\nIt got this immediately right, and I wanted some styling:\n\n\n\n\n\n\nCan you add some css styling so that this prompt looks nice?\n\n\n\nand it’s response was:\n\n\n\n\n\n\nUnfortunately, you cannot directly style the default JavaScript prompt function. Instead, you can create a custom modal using HTML, CSS, and JavaScript to achieve a more visually appealing and flexible solution.\nHere’s an example of how you can create a custom modal to ask for the number of rounds:\n…\n\n\n\nGood to know! The modals worked out of the box, and it was easy to extend them so they asked for the number of sheep and bushes as well. The last thing I wanted to add was a sharing feature:\n\n\n\n\n\n\nCan you add code so that the user can share a screenshot of just the canvas once the game is over? So once the game is over, I want to show a link called “Share My Game!” The screenshot and options to share on social media should show up in a modal when the user clicks this link.\n\n\n\nNow this it did remarkably well, except that when it tried to pass the entire image as a URL parameter, that didn’t work out. When I conveyed this, the response was:\n\n\n\n\n\n\nI apologize for the inconvenience. The reason for this issue is that sharing an image directly using a URL is not possible due to security reasons. To share your game image on social media platforms like Facebook and Twitter, you’ll need to use their respective APIs.\nHere’s a modified approach for sharing the image on Facebook and Twitter. You’ll need to create Facebook and Twitter developer accounts and register your app to get the API keys.\n\n\n\nWhoa… so ok, I don’t have developer accounts and I was not going to follow through, but this was definitely interesting!\nI did interleave responses from chatGPT with help from Ghostwriter, which is the intelligence built into repl.it out of the box. Ghostwriter’s responses were usually not as sophisticated on comparable prompts, but on a couple of occassions chatGPT was completely lost on why something wasn’t working, but Ghostwriter would figure it out when asked pointed questions about an error. There seems to be some potential that they will be a good team — possibly also alongside Copilot, which I did not use at all here.\n\n\n\n\n\n\nThe Final Product\n\n\n\nAnyway, long story short, I cleaned up a little further on my own, and finally: the game is here, the source is here.\n\n\nMy experience with chatGPT and Ghostwriter as pair programmers was — I daresay — rewarding overall. When I first thought of doing this, perhaps partially intoxicated by all the hype, I figured I could get this done in a couple of hours at the most: I estimated twenty minutes for functional code, and about a 100 minutes for making up my mind about colors and fonts. This was a vast underestimate: I think I spent close to a good twelve hours (including a couple of early throw-away prototypes, and all the failed attempts on the flood filling) altogether2… at some point it did get a little addictive, and perhaps there was a sunk cost argument for not letting go halfway through.\nAs someone who does not know javascript, I found this to be a part empowering, part learning, and mostly amusing experience. It felt like picking up a natural language by directly talking to mostly fluent speakers who made random and small mistakes. My overall sentiments were very similar to the process described in this thread, where Ammaar Reshi uses GPT-4, Replit, MidJourney, and Claude to create a 3D space runner from scratch with ZERO [sic] knowledge of Javascript or 3D game programming: you should check this out if you are interested in a much more sophisticated demonstration for deploying AI tools to make games!\nIn its current form I think this also has interesting implications for how programming is taught: I hesitate to elaborate any further on this given how likely it is that any commentary will be obsolete by tomorrow. But in the very near term, I can imagine that reading, analyzing, and even learning alongside chatGPT could make for interesting experiences in the classroom.\n\n\n\n\nFootnotes\n\n\nIncidentally, I couldn’t find a playable version like this one online. If you know of one please let me know and I’ll be sure to add a pointer!↩︎\nAt least I’m not the only one spending hours in the plural.↩︎"
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L14.html",
    "href": "courses/2023/01-CS614/quizzes/L14.html",
    "title": "CS614. Advanced Algorithms. L14 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 2. High-Degree Branching for FVS\n\n\n\nApply the same preprocessing steps as in the previous problem.\nLet \\left(v_1, v_2, \\ldots, v_n\\right) be a descending ordering of V(G) according to vertex degrees, i.e., d\\left(v_1\\right) \\geq d\\left(v_2\\right) \\geq \\ldots \\geq d\\left(v_n\\right). Let V_{3 k}=\\left\\{v_1, \\ldots, v_{3 k}\\right\\}.\nRecall that the minimum vertex degree of G is at least 3. Show that every feedback vertex set in G of size at most k contains at least one vertex of V_{3 k}."
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L13.html",
    "href": "courses/2023/01-CS614/quizzes/L13.html",
    "title": "CS614. Advanced Algorithms. L13 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. FVS: is this FPT?\n\n\n\nRecall the following branching algorithm for Feedback Vertex Set (FVS) discussed in class:\n\nPreprocess to eliminate vertices of degree at most two, resulting in an equivlaent multigraph.\nPreprocess to force vertices with self-loops in the solution and adjust the budget as appropriate.\nIf a pair of vertices have more than two edges between them, delete all but two of these edges.\nSTOP if the graph is a forest or if we are out of budget.\nFind a shortest cycle and branch on all its vertices.\n\nSince a graph of minimum degree three that is not acyclic always has a cycle of length O(\\lg n), this algorithm has a running time of O^\\star((\\lg n)^k). Argue that this running time in fact shows that FVS is FPT in k."
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L12.html",
    "href": "courses/2023/01-CS614/quizzes/L12.html",
    "title": "CS614. Advanced Algorithms. L12 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. List Coloring\n\n\n\nIn the List Coloring problem, we are given a graph G and for each vertex v \\in V(G) there is a set (also called a list) of admissible colors L(v) \\subseteq N. The goal is to verify whether it is possible to find a proper vertex coloring c: V(G) \\rightarrow \\mathbb{N} of G such that for ever y vertex v we have c(v) \\in L(v). In other words, L(v) is the set of colors allowed for v.\nShow a 2^n n^{\\mathcal{O}(1)}-time algorithm for List Coloring.\nHint. Read Theorem 10.8 from the Parameterized Algorithms text.\n\n\n\n\n\n\n\n\nProblem 2. Triangle Packing\n\n\n\nIn the Triangle Packing problem, we are given an undirected graph G and a positive integer k, and the objective is to test whether G has k-vertex disjoint triangles. Using color coding show that the problem admits an algorithm with running time 2^{O(k)} n^{O(1)}."
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L18.html",
    "href": "courses/2023/01-CS614/quizzes/L18.html",
    "title": "CS614. Advanced Algorithms. L18 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. 3-Hitting Set\n\n\n\nObtain an algorithm for 3-Hitting Set running in time 2.4656^k n^{\\mathcal{O}(1)} using iterative compression.\n\n\n\n\n\n\n\n\nProblem 2. d-Hitting Set\n\n\n\nGeneralize the algorithm from the previous problem to obtain an algorithm for d-Hitting Set running in time ((d-1)+0.4656)^k n^{\\mathcal{O}(1)}."
  },
  {
    "objectID": "courses/2023/01-CS614/exams/E02.html",
    "href": "courses/2023/01-CS614/exams/E02.html",
    "title": "CS614. Advanced Algorithms. Exam 2.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\nArturo I. Merino, Torsten Mütze, Aaron Williams: All Your bases Are Belong to Us: Listing All Bases of a Matroid by Greedy Exchanges. FUN 2022: 22:1-22:28 [PDF]\nDaniel Lokshtanov, Bernardo Subercaseaux: Wordle Is NP-Hard. FUN 2022: 19:1-19:8 [PDF]\nChristoph Brause, Ingo Schiermeyer: Kernelization of the 3-path vertex cover problem. Discret. Math. 339(7): 1935-1939 (2016) [PDF]\nRémy Belmonte, Tesshu Hanaka, Ioannis Katsikarelis, Michael Lampis, Hirotaka Ono, Yota Otachi: Parameterized Complexity of Safe Set. J. Graph Algorithms Appl. 24(3): 215-245 (2020) [PDF]\n\n\n\n\n\n\n\nNote for Paper #4\n\n\n\n\n\nFocus on Sections 5 and 7 for the presentation.\n\n\n\n\nRadovan Cervený, Ondrej Suchý: Faster FPT Algorithm for 5-Path Vertex Cover. MFCS 2019: 32:1-32:13 [PDF]\n\n\n\n\n\n\n\nNote for Paper #5\n\n\n\n\n\nSince there are several cases to the branching algorithm, there is no need to comprehensively cover them in the presentation\n\n\n\n\nFedor V. Fomin, Torstein J. F. Strømme: Vertex Cover Structural Parameterization Revisited. WG 2016: 171-182 [PDF]\n\n\n\n\n\n\n\nNote for Paper #6\n\n\n\n\n\nFocus on Section 3 for the presentation.\n\n\n\n\nA Note on Max k-Vertex Cover: Faster FPT-AS, Smaller Approximate Kernel and Improved Approximation. SOSA 2019: 15:1-15:21 [PDF]\n\n\n\n\n\n\n\nNote for Paper #7\n\n\n\n\n\nChoose an appropriate subset of results to present.\n\n\n\n\nDan Hefetz, Orna Kupferman, Amir Lellouche, Gal Vardi: Spanning-Tree Games. MFCS 2018: 35:1-35:16 [PDF]\nMichael Lampis, Valia Mitsou: The Computational Complexity of the Game of Set and Its Theoretical Applications. LATIN 2014: 24-34 [PDF]\n\n\n\n\n\n\n\nNote for Paper #7\n\n\n\n\n\nFocus on the NP-completeness and FPT results here.\n\n\n\n\nJulián Mestre: A Primal-Dual Approximation Algorithm for Partial Vertex Cover: Making Educated Guesses. APPROX-RANDOM 2005: 182-191 [PDF]"
  },
  {
    "objectID": "courses/2023/01-CS614/exams/E02.html#cs614.-advanced-algorithms.",
    "href": "courses/2023/01-CS614/exams/E02.html#cs614.-advanced-algorithms.",
    "title": "CS614. Advanced Algorithms. Exam 2.",
    "section": "CS614. Advanced Algorithms.",
    "text": "CS614. Advanced Algorithms.\n\nExam 2\nBack to the course page\n\n\n\n\n\n\nList of Papers\n\n\n\n\nArturo I. Merino, Torsten Mütze, Aaron Williams: All Your bases Are Belong to Us: Listing All Bases of a Matroid by Greedy Exchanges. FUN 2022: 22:1-22:28 a service of Schloss Dagstuhl - Leibniz Center for Informatics PDF\nDaniel Lokshtanov, Bernardo Subercaseaux: Wordle Is NP-Hard. FUN 2022: 19:1-19:8 PDF\nChristoph Brause, Ingo Schiermeyer: Kernelization of the 3-path vertex cover problem. Discret. Math. 339(7): 1935-1939 (2016) PDF\nRémy Belmonte, Tesshu Hanaka, Ioannis Katsikarelis, Michael Lampis, Hirotaka Ono, Yota Otachi: Parameterized Complexity of Safe Set. J. Graph Algorithms Appl. 24(3): 215-245 (2020)\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nFocus on Sections 5 and 7 for the presentation.\n\n\n\n\nRadovan Cervený, Ondrej Suchý: Faster FPT Algorithm for 5-Path Vertex Cover. MFCS 2019: 32:1-32:13 PDF\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nSince there are several cases to the branching algorithm, there is no need to comprehensively cover them in the presentation\n\n\n\n\nFedor V. Fomin, Torstein J. F. Strømme: Vertex Cover Structural Parameterization Revisited. WG 2016: 171-182 PDF\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nFocus on Section 3 for the presentation.\n\n\n\n\nA Note on Max k-Vertex Cover: Faster FPT-AS, Smaller Approximate Kernel and Improved Approximation. SOSA 2019: 15:1-15:21 PDF"
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L19.html",
    "href": "courses/2023/01-CS614/quizzes/L19.html",
    "title": "CS614. Advanced Algorithms. L19 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Bin Packing\n\n\n\nConsider the bin-packing problem:\nInput: n items with sizes a_1 \\cdots a_n respectively, a positive integer B (bin capacity) and a positive integer k (number of bins). Question: Is there a partition of the set \\{1 \\cdots n\\} into sets S_1, \\ldots, S_k such that for each i \\in\\{1 \\cdots k\\} we have that \\sum_{j \\in S_i} a_j \\leq B?\nShow that Bin Packing is NP-complete.\n\n\n\n\n\n\n\n\nProblem 2. BOX-DEPTH\n\n\n\nConsider the following problem, called BOX-DEPTH: Given a set of n axisaligned rectangles in the plane, how big is the largest subset of these rectangles that contain a common point?\n\nDescribe a polynomial-time reduction from BOX-DEPTH to MAXCLIQUE.\nDescribe and analyze a polynomial-time algorithm for BOX-DEPTH. [Hint: O\\left(n^3\\right) time should be easy, but O(n \\log n) time is possible.]\nWhy don’t these two results imply that \\mathrm{P}=\\mathrm{NP}?"
  },
  {
    "objectID": "courses/2023/01-ES242/exams/exam02.html",
    "href": "courses/2023/01-ES242/exams/exam02.html",
    "title": "ES242. Data Structures and Algorithms I. Exam 02",
    "section": "",
    "text": "Issued: 31 Mar, 2023\nBack to course page\n\n\n\n\n\n\nInstructions\n\n\n\nWe will have Exam 2 at the usual classroom venue. The exam will be released on Gradescope by 9PM, and will be available until 10:30PM.\nPart 1 consists of 5 multiple choice questions, worth 2 points each and is available directly on Gradescope.\nPart 2 consists of 3 programming assignments. Attempt one of problems 1 and 2; and attempt problem 3. The problems are worth 5 points each.\nTotal marks are capped at 20, there is no partial grading or negative marking.\nAny violations of the honor code (in particular including, but not limited to, communicating during the quiz, or using the internet for anything other than looking up the official course materials) will be reported and will result in a F grade in the course.\nUseful resources that you can access during the exam:\n\nBFS/DFS lecture notes\nBFS implementation with sorted neighbors\nDFS implementation with reverse sorted neighbors (so that they are visited in the sorted order)\n\n\n\n\n\n\n\n\n\nProblem 1. Shortest Distance\n\n\n\nGiven an undirected graph G = (V,E) and two specified vertices s and t, determine the length of the shortest path between s and t, where the length of a path is defined as the number of edges on the path.\nHint: start a BFS at s. The BFS layer number of t is the answer, where the layer number of vertex s is 0. If t does not appear in the BFS traversal starting from s, then there no path from s to t.\n\n\nThe first line of input is three space-separated integers n, m, s and t, denoting the number of vertices and edges of G, and the id of the source vertex and the target vertex, respectively. Vertices are indexed from 0 to n-1.\nThe next m lines of code are two space separated integers u and v in the range 0 and n-1, indicating an (undirected) edge between vertices u and v.\nThe last line is a pair of space-separated integers x and y.\n\n\n\nThe output is formatted as follows: print a single integer d, the length of the shortest path between s and t.\n\n\n\nSample Input\n6 8 0 5\n0 1\n0 2\n0 3\n0 4\n5 1\n5 2\n5 3\n5 4\nSample Output\n2\n\n\n\n\n\n\n\n\n\nProblem 2. Bags of Pebbles\n\n\n\nMahi and Brishti are playing with bags of pebbles. They have a row a of n bags of pebbles. The i-th bag has a_i pebbles. The bags are given to the players in the order from the first bag to the n-th bag.\nIf a bag has an even number of pebbles, Mahi grabs the bag. Otherwise, Brishti grabs the bag. Once a bag is grabbed, the number of pebbles in it gets added to the total number of pebbles of the player that took it.\nMahi wants to show off, so he wants to reorder the array so that at any moment (except at the start when they both have no pebbles), Mahi will have strictly more pebbles than Brishti. Help Mahi find out if such a reordering exists.\n\n\n\nThe first line of the input contains an integer t(1 \\leq t \\leq 1000)- the number of test cases.\nThe first line of each test case contains a single integer n(1 \\leq n \\leq 100) - the number of bags in the array.\nThe second line of each test case contains n space-separated integers a_i\\left(1 \\leq a_i \\leq 100\\right) - the number of pebbles in each bag.\n\n\n\n\nFor each test case, output “YES” (without quotes) if such a reordering exists, and “NO” (without quotes) otherwise.\n\n\n\nSample Input\n3\n4\n1 2 3 4\n4\n1 1 1 2\n3\n1 4 3\nSample Output\nYES\nNO\nNO\nNote In the first test case, Mahi can reorder the array as follows: [4,1,2,3]. Then the process proceeds as follows: - the first bag has 4 pebbles, which is even, so Mahi takes it - Mahi has 4 pebbles, and Brishti has 0 . - the second bag has 1 pebbles, which is odd, so Brishti takes it - Mahi has 4 pebbles, and Brishti has 1. - the third bag has 2 pebbles, which is even, so Mahi takes it - Mahi has 6 pebbles, and Brishti has 1 . - the fourth bag has 3 pebbles, which is odd, so Brishti takes it - Mahi has 6 pebbles, and Brishti has 4. Since Mahi always has more pebbles than Brishti, this reordering works.\n\n\n\n\n\n\n\n\n\nProblem 3. Learning Languages\n\n\n\nIITGN has n students. These students can use m languages for correspondence. The languages are numbered with integers from 1 to m. For each student we have the list of languages, which s/he knows. This list could be empty, i. e. a student may know no languages. But the students are willing to learn any number of languages, as long as the IITGN pays for their lessons. A study course in one language for one student costs 5000 rupees.\nFind the minimum sum of money the IITGN needs to spend so as any student could talk to any other one (their correspondence can be indirect, i. e. other students can help out translating).\nHint. Translate this into a graph where you have n vertices representing the students and m vertices representing languages. If this graph is fully connected then no money needs to be spent. Otherwise think of how much it costs to connect all the connected components of the graph. Which components do you need to worry about? Think about the special case when all students know no languages.\n\n\nThe first line contains two integers n and m (2 \\leqslant n, m \\leqslant 100) — the number of students and the number of languages.\nThen n lines follow — each student’s language list. At the beginning of the i-th line is integer ki (0 \\leqslant k_i \\leqslant m) — the number of languages the i-th student knows. Next, the i-th line contains k_i integers — a_{ij} (1 \\leqslant aij \\leqslant m) — the identifiers of languages the i-th student knows. It is guaranteed that all the identifiers in one list are distinct. Note that an student may know zero languages.\nThe numbers in the lines are separated by single spaces.\n\n\n\nPrint a single integer — the minimum amount of money to pay so that in the end every student could communicate with every other one (other students can help out translating).\n\n\n\nSample Input\n5 5\n1 2\n2 2 3\n2 3 4\n2 4 5\n1 5\nSample Output\n0\nSample Input\n8 7\n0\n3 1 2 3\n1 1\n2 5 4\n2 6 7\n1 3\n2 7 4\n1 1\nSample Output\n2\nSample Input\n2 2\n1 2\n0\nSample Output\n1\n\n\n\nIn the second sample the student 1 can learn language 2, and student 8 can learn language 4.\nIn the third sample student 2 must learn language 2."
  },
  {
    "objectID": "courses/2023/01-ES242/exams/exam02.html#es242.-data-structures-and-algorithms-i.",
    "href": "courses/2023/01-ES242/exams/exam02.html#es242.-data-structures-and-algorithms-i.",
    "title": "ES242. Data Structures and Algorithms I. Exam 02",
    "section": "ES242. Data Structures and Algorithms I.",
    "text": "ES242. Data Structures and Algorithms I.\n\nExam 02\nIssued: 31 Mar, 2023\nBack to course page\n\n\n\n\n\n\nInstructions\n\n\n\nWe will have Exam 2 at the usual classroom venue. The exam will be released on Gradescope by 9PM, and will be available until 10:30PM.\nPart 1 consists of 5 multiple choice questions, worth 2 points each.\nPart 2 consists of 3 programming assignments, worth 3, 3, and 4 points respectively.\nAny violations of the honor code (in particular including, but not limited to, communicating during the quiz, or using the internet for anything other than looking up the official course materials) will be reported and will result in a F grade in the course.\nUseful resources that you can access during the exam:\n\nBFS/DFS lecture notes\nBFS implementation with sorted neighbors\nDFS implementation with reverse sorted neighbors (so that they are visited in the sorted order)\n\n\n\n\n\n\n\n\n\nProblem 1. Shortest Distance\n\n\n\nGiven an undirected graph G = (V,E) and two specified vertices s and t, determine the length of the shortest path between s and t, where the length of a path is defined as the number of edges on the path.\nHint: start a BFS at s. The BFS layer number of t is the answer, where the layer number of vertex s is 0. If t does not appear in the BFS traversal starting from s, then there no path from s to t.\n\nInput Format\nThe first line of input is three space-separated integers n, m, s and t, denoting the number of vertices and edges of G, and the id of the source vertex and the target vertex, respectively. Vertices are indexed from 0 to n-1.\nThe next m lines of code are two space separated integers u and v in the range 0 and n-1, indicating an (undirected) edge between vertices u and v.\nThe last line is a pair of space-separated integers x and y.\n\n\nOutput Format\nThe output is formatted as follows: if the BFS lasts for t rounds, there are t lines of output. The i-th line consists of a space-separated list of the vertices visited by BFS in the i-th round of the traversal in increasing order of labels.\n\n\nSample I/O\nSample Input\n6 8 0 5\n0 1\n0 2\n0 3\n0 4\n5 1\n5 2\n5 3\n5 4\nSample Output\n2\n\n\n\n\n\n\n\n\n\nProblem 2. Learning Languages\n\n\n\nIITGN has n students. These students can use m languages for correspondence. The languages are numbered with integers from 1 to m. For each student we have the list of languages, which s/he knows. This list could be empty, i. e. an student may know no languages. But the students are willing to learn any number of languages, as long as the IITGN pays for their lessons. A study course in one language for one student costs 5000 rupees.\nFind the minimum sum of money the IITGN needs to spend so as any student could talk to any other one (their correspondence can be indirect, i. e. other students can help out translating).\n\nInput\nThe first line contains two integers n and m (2 \\leqslant n, m \\leqslant 100) — the number of students and the number of languages.\nThen n lines follow — each student’s language list. At the beginning of the i-th line is integer ki (0 \\leqslant k_i \\leqslant m) — the number of languages the i-th student knows. Next, the i-th line contains k_i integers — a_{ij} (1 \\leqslant aij \\leqslant m) — the identifiers of languages the i-th student knows. It is guaranteed that all the identifiers in one list are distinct. Note that an student may know zero languages.\nThe numbers in the lines are separated by single spaces.\n\n\nOutput\nPrint a single integer — the minimum amount of money to pay so that in the end every student could communicate with every other one (other students can help out translating).\n\n\nSample Input/Output\nSample Input\n5 5\n1 2\n2 2 3\n2 3 4\n2 4 5\n1 5\nSample Output\n0\nSample Input\n8 7\n0\n3 1 2 3\n1 1\n2 5 4\n2 6 7\n1 3\n2 7 4\n1 1\nSample Output\n2\nSample Input\n2 2\n1 2\n0\nSample Output\n1\n\n\nNote\nIn the second sample the student 1 can learn language 2, and student 8 can learn language 4.\nIn the third sample student 2 must learn language 2.\n\n\nHint\nThink about the case when all students know no languages. This may require an exception from your general approach (why?)."
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w14.html",
    "href": "courses/2023/01-ES242/labs/lab-w14.html",
    "title": "ES242. Data Structures and Algorithms I. Week 14 Lab",
    "section": "",
    "text": "Back to course page\n\n\n\n\n\n\nHeaps\n\n\n\n\n\n\n\n\n\nProblem 1. Build Heap by Insertions\n\n\n\n\n\nYou are given an array arr of length n. The array is represented in the form of a complete binary tree. A representation of an array as a binary tree is said to be heap compatible if it follows the following features:\nThe first element is made the root of the tree. Every subsequent element is made the left-child. If left pointer is non-empty, it is made the right-child. If both children exist, then the same procedure is followed for the left-child and then right child.\nConsider the array below:\narr[] = {5,6,89,9,45,7,1}\nThe heap compatible representation of arr[] is as follows:\n      5\n      /\\\n     6  89\n    /\\  /\\\n   9 45 7 1\n\n\nYou are given an array representation of a heap compatible binary tree. You have to construct a max-heap data structure using the given array. Return the BFS traversal of the data. Build the heap using iterated insertions.\n\nNote: You may want to use the given “queue.h” file to return the BFS traversal\n\n\n\nThe first line contains an integer n.  The next line contains n space-separated integers representing a heap compatible array.\n\n\n\nReturn n space-separated integers that represent the max-heap.\n\n\n\n\nSample Input 1\n5\n4 10 3 2 1\nSample Output 1\n10 4 3 2 1\n\n\n\n\n\n\n\n\n\n\nProblem 2. Heapify\n\n\n\n\n\nYou are given an array arr of length n. The array is represented in the form of a complete binary tree. A representation of an array as a binary tree is said to be heap compatible if it follows the following features:  The first element is made the root of the tree. Every subsequent element is made the left-child. If left pointer is non-empty, it is made the right-child. If both children exist, then the same procedure is followed for the left-child and then right child. In a way, it is a greedy level-wise filling\nConsider the array below:\narr[] = {5,6,89,9,45,7,1}\nThe heap compatible representation of arr[] is as follows:\n      5\n      /\\\n     6  89\n    /\\  /\\\n   9 45 7 1\n\n\nYou are given an array representation of a heap compatible binary tree. You have to construct a max-heap data structure using the given array. Return the BFS traversal of the data. Build the heap using the heapify method discussed in class.\n\nNote: You may want to use the given “queue.h” file to return the BFS traversal\n\n\n\nThe first line contains an integer n.  The next line contains n space-separated integers representing a heap compatible array.\n\n\n\nReturn n space-separated integers that represent the max-heap.\n\n\n\n\nSample Input 1\n5\n4 10 3 5 1\nSample Output 1\n10 5 3 4 1\nSample Input 2\n11\n1 3 5 4 6 13 10 9 8 15 17\nSample Output 2\n17 15 13 9 6 5 10 4 8 3 1"
  },
  {
    "objectID": "courses/2023/01-ES242/labs/lab-w14.html#es242.-data-structures-and-algorithms-i.",
    "href": "courses/2023/01-ES242/labs/lab-w14.html#es242.-data-structures-and-algorithms-i.",
    "title": "ES242. Data Structures and Algorithms I. Week 14 Lab",
    "section": "ES242. Data Structures and Algorithms I.",
    "text": "ES242. Data Structures and Algorithms I.\n\nLab 14\nBack to course page\n\n\n\n\n\n\nHeaps\n\n\n\n\n\n\n\n\n\nProblem 1. Build Heap by Insertions\n\n\n\n\n\nYou are given an array arr of length n. The array is represented in the form of a complete binary tree. A representation of an array as a binary tree is said to be heap compatible if it follows the following features:\nThe first element is made the root of the tree. Every subsequent element is made the left-child. If left pointer is non-empty, it is made the right-child. If both children exist, then the same procedure is followed for the left-child and then right child.\nConsider the array below:\narr[] = {5,6,89,9,45,7,1}\nThe heap compatible representation of arr[] is as follows:\n      5\n      /\\\n     6  89\n    /\\  /\\\n   9 45 7 1\n\nTask\nYou are given an array representation of a heap compatible binary tree. You have to construct a max-heap data structure using the given array. Return the BFS traversal of the data. Build the heap using iterated insertions.\n\nNote: You may want to use the given “queue.h” file to return the BFS traversal\n\n\nInput Format\nThe first line contains an integer n.  The next line contains n space-separated integers representing a heap compatible array.\n\n\nOutput Format\nReturn n space-separated integers that represent the max-heap.\n\n\n\nSample I/O\nSample Input 1\n5\n4 10 3 2 1\nSample Output 1\n10 4 3 2 1\n\n\n\n\n:::{.callout-note collapse=“true” icon=“false”}\n\n\nProblem 2. Heapify\nYou are given an array arr of length n. The array is represented in the form of a complete binary tree. A representation of an array as a binary tree is said to be heap compatible if it follows the following features:  The first element is made the root of the tree. Every subsequent element is made the left-child. If left pointer is non-empty, it is made the right-child. If both children exist, then the same procedure is followed for the left-child and then right child. In a way, it is a greedy level-wise filling\nConsider the array below:\narr[] = {5,6,89,9,45,7,1}\nThe heap compatible representation of arr[] is as follows:\n      5\n      /\\\n     6  89\n    /\\  /\\\n   9 45 7 1\n\n\nTask:\nYou are given an array representation of a heap compatible binary tree. You have to construct a max-heap data structure using the given array. Return the BFS traversal of the data. Build the heap using the heapify method discussed in class.\n\nNote: You may want to use the given “queue.h” file to return the BFS traversal\n\n\nInput Format\nThe first line contains an integer n.  The next line contains n space-separated integers representing a heap compatible array.\n\n\nOutput Format\nReturn n space-separated integers that represent the max-heap.\n\n\n\nSample I/O\nSample Input 1\n5\n4 10 3 5 1\nSample Output 1\n10 5 3 4 1\n\nSample Input 2\n11\n1 3 5 4 6 13 10 9 8 15 17\nSample Output 2\n17 15 13 9 6 5 10 4 8 3 1\n:::\n:::"
  },
  {
    "objectID": "courses/2023/02-ES214/index.html",
    "href": "courses/2023/02-ES214/index.html",
    "title": "ES 214 | Aug-Nov 2023",
    "section": "",
    "text": "(co-instructor with Prof. Anirban Dasgupta.)\n\n\n\n\n\n\nAbout the Course\n\n\n\n\n\nTBA\n\n\n\n\n\n\n\n\n\nTarget Audience\n\n\n\n\n\nYou will find this course interesting if:\n\nyou think counting the number of ways in which you can complete your graduation requirements is a fun problem to think about,\nyou enjoy logic puzzles like this one or probability puzzles like this one, or\nyou like box-stacking challenges, or\nyou are enrolled in a program for which this course is in the core.\n\n\n\n\n\n\n\n\n\n\nPrerequisites\n\n\n\n\n\nThis course is self-contained and involves no pre-requisites.\n\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\n\n\nDiscrete Mathematics and Its Applications by Kenneth Rosen\nOpen Textbook on Discrete Mathematics\nProofs: A Long-Form Mathematics Textbook by Jay Cummings\nPlaying with Discrete Math by Kyle Burke and Craig Tennenhouse\nOnline Course (with lecture videos): Math 4190, Summer I 2019\n\n\n\n\n\n\n\n\n\n\nTimings and Venue\n\n\n\n\n\nVenue: 1/101\nLectures:\n\nTuesdays 3:30PM — 5:00PM\nWednesdays 11:30 — 12:50\n\nTutorials\n\nThursdays 3:30PM — 5:00PM\n\n\n\n\n\n\n\n\n\n\nTAs and Office hours\n\n\n\n\n\nOffice Hours: By email.\nTAs: TBA\n\n\n\n\n\n\n\n\n\nEvaluation policy\n\n\n\n\n\n\nEach of the three exams account for 20% of the grade.\nEach of the eleven tutorials will have a quiz worth 5 points. The total number of points you can earn through quizzes is capped at 40, and accounts for 40% of the grade.\nThere will be weekly assignments that are not graded but are recommended for practice.\n\n\n\n\n\n\n\n\n\n\nRegister\n\n\n\n\n\n\nFor IITGN students, (pre-)register through IMS as usual.\nAll quizzes and exams will be on Gradescope.\nIf you are not from IITGN and are interested in taking up the course, then please send us an email.\n\n\n\n\n\nLecturesAssignmentsQuizzesExams\n\n\n\n\n\n    \n        Date\n        Lecture\n        Slides\n        Notes\n        Video\n    \n    \n                    \n            \n                02 Aug, 2023\n            \n            \n                1. Intro to Proofs - I\n                General Methods • Chessboard Tilings • Game of Chomp\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                03 Aug, 2023\n            \n            \n                2. Intro to Proofs - II\n                Pigeonhole Principle • Illustrative Examples\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                08 Aug, 2023\n            \n            \n                3. Sets\n                Definitions • Operations • Showing Containment • Showing Equality\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                09 Aug, 2023\n            \n            \n                4. Functions and Relations\n                Injections, Surjections, Bijections • Compositions • Equivalence Classes\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                16 Aug, 2023\n            \n            \n                5. Induction\n                Dominoes, Ladders, and Chips • Examples • Non-Examples • Strong Induction\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                22 Aug, 2023\n            \n            \n                6. Propositional and Predicate Logic\n                Syntax • Truth Tables • Quantifiers\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                23 Aug, 2023\n            \n            \n                7. Inference Systems\n                Inference Rules (e.g, Modus Ponens, Modus Tollens, Resolution, etc) • Paradoxes\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                29 Aug, 2023\n            \n            \n                8. Elementary Counting Methods\n                Permutations • Combinations • Binomial Coefficients\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                30 Aug, 2023\n            \n            \n                9. The Method of Double Counting\n                Examples of proofs by double-counting\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                12 Sep, 2023\n            \n            \n                10. Intro to Graphs: Euler Tours\n                Necessary and Sufficient Conditions for Euler Tours • Computing Euler Tours\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                13 Sep, 2023\n            \n            \n                11. Hall's Theorem\n                Matchings • Congestion in Bipartite Graphs • Hall's Theorem • Applications\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                19 Sep, 2023\n            \n            \n                12. Graph Coloring\n                Map Coloring • Greedy Algorithms • Bipartite Graphs • k-Degenerate Graphs\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                20 Sep, 2023\n            \n            \n                13. Planarity\n                Planar Graphs are Five-Colorable • Obstructions to Planarity\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                26 Sep, 2023\n            \n            \n                14. Graphs Recap\n                ~\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                27 Sep, 2023\n            \n            \n                15. Probability Intro\n                Basics of Discrete Probability • Monty Hall • Conditional Probability\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                03 Oct, 2023\n            \n            \n                16. The Probabilistic Method - I\n                An Introduction to the Method • Applications in Graph Theory\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                04 Oct, 2023\n            \n            \n                17. The Probabilistic Method - II\n                Ramsey Number • Sum-Free Sets\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                10 Oct, 2023\n            \n            \n                18. Recap\n                ~\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                17 Oct, 2023\n            \n            \n                19. The Linear Algebra Method - I\n                OddTown and EvenTown\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                18 Oct, 2023\n            \n            \n                20. The Linear Algebra Method - II\n                VC Dimension of a Set System • Sauer's Lemma\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                31 Oct, 2023\n            \n            \n                21. Intro to Groups: Rotations and Symmetries\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                01 Nov, 2023\n            \n            \n                22. Permutation and Cyclic Groups\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                07 Nov, 2023\n            \n            \n                23. Homomorphisms\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                08 Nov, 2023\n            \n            \n                24. Quotient Groups and First Isomorphism Theorem\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                14 Nov, 2023\n            \n            \n                25. Intro to Number Theory: Extended Euclid's Algorithm\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                15 Nov, 2023\n            \n            \n                26. Chinese Remainder Theorem\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                21 Nov, 2023\n            \n            \n                27. Applications I: RSA\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                22 Nov, 2023\n            \n            \n                28. Applications II: PageRank\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                23 Nov, 2023\n            \n            \n                29. Recap\n                ~\n            \n            \n            \n            \n            \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\nThese are the weekly practice problems. There is no need to submit these assignments, but please make sure to get feedback from your peers, instructors and TAs as you go along.\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                10 Aug, 2023\n            \n            \n                Sets and Functions\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                17 Aug, 2023\n            \n            \n                Induction\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                24 Aug, 2023\n            \n            \n                Logic\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                31 Aug, 2023\n            \n            \n                Counting\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                14 Sep, 2023\n            \n            \n                Graphs I\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                21 Sep, 2023\n            \n            \n                Graphs II\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                05 Oct, 2023\n            \n            \n                Probability\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                19 Oct, 2023\n            \n            \n                Dimensionality Arguments\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                02 Nov, 2023\n            \n            \n                Groups I\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                09 Nov, 2023\n            \n            \n                Groups II\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                16 Nov, 2023\n            \n            \n                Number Theory\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                10 Aug, 2023\n            \n            \n                Sets and Functions\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                17 Aug, 2023\n            \n            \n                Induction\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                24 Aug, 2023\n            \n            \n                Logic\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                31 Aug, 2023\n            \n            \n                Counting\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                14 Sep, 2023\n            \n            \n                Graphs I\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                21 Sep, 2023\n            \n            \n                Graphs II\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                05 Oct, 2023\n            \n            \n                Probability\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                19 Oct, 2023\n            \n            \n                Dimensionality Arguments\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                02 Nov, 2023\n            \n            \n                Groups I\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                09 Nov, 2023\n            \n            \n                Groups II\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                16 Nov, 2023\n            \n            \n                Number Theory\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                TBA\n            \n            \n                Exam 1\n                Syllabus: topics in lectures 1 to 9 (inclusive)\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n                    \n            \n                TBA\n            \n            \n                Exam 2\n                Syllabus: topics in lectures 10 to 18 (inclusive)\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n                    \n            \n                TBA\n            \n            \n                Exam 3\n                Syllabus: topics in lectures 21 to 26 (inclusive)\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n\n\n\nNo matching items"
  },
  {
    "objectID": "courses/2023/02-ES214/exams/E02.html",
    "href": "courses/2023/02-ES214/exams/E02.html",
    "title": "CS614. Advanced Algorithms. Exam 2.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\nArturo I. Merino, Torsten Mütze, Aaron Williams: All Your bases Are Belong to Us: Listing All Bases of a Matroid by Greedy Exchanges. FUN 2022: 22:1-22:28 [PDF]\nDaniel Lokshtanov, Bernardo Subercaseaux: Wordle Is NP-Hard. FUN 2022: 19:1-19:8 [PDF]\nChristoph Brause, Ingo Schiermeyer: Kernelization of the 3-path vertex cover problem. Discret. Math. 339(7): 1935-1939 (2016) [PDF]\nRémy Belmonte, Tesshu Hanaka, Ioannis Katsikarelis, Michael Lampis, Hirotaka Ono, Yota Otachi: Parameterized Complexity of Safe Set. J. Graph Algorithms Appl. 24(3): 215-245 (2020) [PDF]\n\n\n\n\n\n\n\nNote for Paper #4\n\n\n\n\n\nFocus on Sections 5 and 7 for the presentation.\n\n\n\n\nRadovan Cervený, Ondrej Suchý: Faster FPT Algorithm for 5-Path Vertex Cover. MFCS 2019: 32:1-32:13 [PDF]\n\n\n\n\n\n\n\nNote for Paper #5\n\n\n\n\n\nSince there are several cases to the branching algorithm, there is no need to comprehensively cover them in the presentation\n\n\n\n\nFedor V. Fomin, Torstein J. F. Strømme: Vertex Cover Structural Parameterization Revisited. WG 2016: 171-182 [PDF]\n\n\n\n\n\n\n\nNote for Paper #6\n\n\n\n\n\nFocus on Section 3 for the presentation.\n\n\n\n\nA Note on Max k-Vertex Cover: Faster FPT-AS, Smaller Approximate Kernel and Improved Approximation. SOSA 2019: 15:1-15:21 [PDF]\n\n\n\n\n\n\n\nNote for Paper #7\n\n\n\n\n\nChoose an appropriate subset of results to present.\n\n\n\n\nDan Hefetz, Orna Kupferman, Amir Lellouche, Gal Vardi: Spanning-Tree Games. MFCS 2018: 35:1-35:16 [PDF]\nMichael Lampis, Valia Mitsou: The Computational Complexity of the Game of Set and Its Theoretical Applications. LATIN 2014: 24-34 [PDF]\n\n\n\n\n\n\n\nNote for Paper #7\n\n\n\n\n\nFocus on the NP-completeness and FPT results here.\n\n\n\n\nJulián Mestre: A Primal-Dual Approximation Algorithm for Partial Vertex Cover: Making Educated Guesses. APPROX-RANDOM 2005: 182-191 [PDF]"
  },
  {
    "objectID": "courses/2023/02-ES214/exams/E01.html",
    "href": "courses/2023/02-ES214/exams/E01.html",
    "title": "ES214. Discrete Mathematics. Exam 1.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nRemarks\n\n\n\nProblem indices on Gradescope for Problem 1 are off-by-one. Add one to the index here to match to Gradescope.\nErrata based on feedback from the class (thanks!) — these changes have been made in the questions below:\n\nQ5: it should have been v \\in S and not v \\in G.\nQ1.4: assume that the cycles C and D are edge-disjoint.\nQ1.6: the last return statement is G and not G-v (the vertex v is moved to F, not removed from the graph).\n\n\n\n\n\n\n\n\n\nProblem 1. The Constrained Cycle Hitting Set (CCHS) Problem.\n\n\n\n\n\n\n\n\n\nMarks Distribution.\n\n\n\nThis problem is worth 20 points overall. All subproblems carry two points each except 1.9 (which is zero marks).\n\n\nLet G = (V,E) be a simple and undirected graph. Let F \\subseteq V be a subset of vertices that we will call a forbidden subset. An instance of CCHS is given by (G,F,k), where k \\in \\mathbb{Z}^+ is a budget. Such an instance is a YES-instance if there exists a subset of S \\subseteq V \\setminus F such that:\n\n|S| \\leqslant k, and\nG \\setminus S is a forest, i.e, there are no cycles.\n\nSuch a subset is called a constrained cycle hitting set with respect to F. In this question, we will develop a c^k algorithm for solving a CCHS instance, combining reduction and branching rules in a spirit somewhat similar to what we have done for Vertex Cover in class.\nOur goal will be to return a solution, i.e, a subset of vertices that is a constrained cycle hitting set with respect to F. In particular, an informal overview of our approach, detailed further in the questions below, is the following:\n\nWe will eliminate low-degree (vertices of degree at most one) vertices, and branch on high-degree vertices.\nFor the base case, we will find ourselves “stuck” when the graph only has vertices of degree at most two, but this can be handled in polynomial time.\n\nOur algorithm will be denoted solve-CCHS(G,F,k). We begin the following straightforward rules:\n\nIf k < 0, return NO.\nIf V(G) = \\emptyset, return \\emptyset.\n\n\n\n\n\n\n\nProblem 1.0 No Hope Rule\n\n\n\n\n\nSuppose G[F] has a cycle C. Note that all vertices of C belong to F. Then return:\n\nNO\nsolve-CCHS(G-v,F-v,k-1) where v is a maximum degree vertex from C.\nsolve-CCHS(G-v,F-v,k-1) where v is a minimum degree vertex from C.\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.1 Low Degree Rule.\n\n\n\n\n\nIf a vertex v has degree zero or one, then return:\n\nsolve-CCHS(G-v,F-v,k).\nsolve-CCHS(G-v,F-v,k-1).\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Forced Vertex Rule.\n\n\n\n\n\nIf a vertex v \\in G \\setminus F has two neighbors in a single connected component of G[F], then return:\n\nsolve-CCHS(G-v,F,k).\nsolve-CCHS(G-v,F,k-1).\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.3 High Degree Vertex Has Low Degree - Structure I\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nLet C be a cycle in G. Which of the following scenarios are not feasible?\n\nC \\cap F \\neq \\emptyset and C \\cap (V \\setminus F) \\neq \\emptyset\nC \\cap F = \\emptyset and C \\cap (V \\setminus F) \\neq \\emptyset\nC \\cap F \\neq \\emptyset and C \\cap (V \\setminus F) = \\emptyset\n\nPick the correct option and justify your answer briefly.\n\n\n\n\n\n\n\n\n\nProblem 1.4 High Degree Vertex Has Low Degree - Structure II\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nLet C and D be two edge-disjoint cycles in G. Which of the following scenarios are not feasible?\n\nC \\cap D \\neq \\emptyset\n(C \\cap F) \\cap (D \\cap F) \\neq \\emptyset\n(C \\cap (V\\setminus F)) \\cap (D \\cap (V \\setminus F)) \\neq \\emptyset\n\nPick the correct option and justify your answer briefly.\n\n\n\n\n\n\n\n\n\nProblem 1.5 High Degree Vertex Has Low Degree - Rule\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nConsider the following algorithm to solve this instance:\ninit X = emptyset\nwhile G\\X has a cycle C:\n    let v be a vertex in C\\F:\n        add v to X\nif |X| > k:\n    return NO\nelse:\n    return X\nWhat can you say about the procedure above?\n\nIt correctly solves the kind of CCHS questions being considered in this problem.\nIt will not be correct if there are no vertices in C\\setminus F, as required in line 3.\nIt will not be correct if there are two overlapping cycles in the instance.\n\nPick the correct option and justify your answer briefly. If you believe this is not the right algorithm, please suggest an alternative that works. In further questions when we refer to the rule in problem 1.5, we are referring to either the algorithm above or the one in your justification.\n\n\n\n\n\n\n\n\n\nProblem 1.6 The Branching Step\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1, 1.2, and 1.5 do not apply. Let v be a vertex in G \\setminus F of maximum degree. Now we branch as follows:\nOption A.\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F U {v},k) // omit v\nOption B.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F U {v},k-1) // omit v\nOption C.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X\notherwise:\n    return solve-CCHS(G,F U {v},k) // omit v\nOption D.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F,k) // omit v\nPick the right branching strategy and justify your answer.\n\n\n\nWe summarize the overall algorithm below.\nIf k < 0, return NO.\nIf V(G) is empty, return the empty set.\n\nApply rules 1.0, 1.1, and 1.2.\n\nPick a vertex v in G\\F of maximum degree.\n\nIf d(v) = 2, apply rule 1.5.\nOtherwise branch according to 1.6.\nIn the next few questions, we will analyze the running time of this algorithm. Assume that the algorithm is called with F = \\emptyset, i.e, there are no forbidden vertices to begin with. Fix an execution path P in the branching tree1 of the algorithm that does not return NO. Now:\n\nWe use S(P) to denote the output: note that this would consist of the set of vertices that are removed from the instance for inclusion in the solution, i.e, vertices chosen by the first branch in Step 1.6.\nWe use F(P) to denote the set of vertices that are made forbidden along the path P, i.e, these are vertices chosen by the second branch in Step 1.6.\n\nNote that at the output node, the instance we have is (G,F(P),\\ell) for some \\ell \\leqslant k, where S(P) is a constrained cycle hitting set with respect to F(P) of size at most k - \\ell. Also the number of steps in the execution path P is given by |F(P)| + |S(P)|, since every time we branch, we either include a vertex in the solution or make it forbidden.\n\n\n\n\n\n\nProblem 1.7 Degree 3 vs Leaves in Trees\n\n\n\n\n\nLet T be a tree and let X be the set of leaves in T, and let Y be the set of vertices of degree three or more in T. Show that:\n\\sum_{v \\in Y} (d(v)-2) = |X| - 2,\nusing elementary facts about trees.\n\n\n\n\n\n\n\n\n\nProblem 1.8 Degree Evolution\n\n\n\n\n\nFix an execution path P on an instance (G,\\emptyset,k) (i.e, a path from root to leaf in the branching tree associated with the algorithm when the input is (G,\\emptyset,k)) and consider a vertex v that belongs to F(P), which is to say that the vertex v was included in the set of forbidden vertices at some point during the execution of the algorithm. Denote the instance at this stage of the algorithm by (H,F,k^\\prime). In particular, H is the graph obtained after v was included in F. Let d(v) denote the degree of the vertex v in the original instance G, and let d^\\star(v) denote its degree in the graph H. Which of the following is true?\n\n3 \\leqslant d^\\star(v) \\leqslant d(v)\n3 \\leqslant d^\\star(v) < d(v)\nd^\\star(v) \\geqslant \\min(d(v),3)\nd^\\star(v) > \\min(d(v),3)\n\n\n\n\n\n\n\n\n\n\nProblem 1.9 Successful Execution Paths are Short\n\n\n\n\n\nConsider an execution path P that does not return NO. Show that F(P) \\leqslant 3S(P).\nThis is an optional question that you can skip. It carries no points.\n\n\n\n\n\n\n\n\n\nProblem 1.10 The Final Running Time\n\n\n\n\n\nCan you use the fact from the previous question to come up with an algorithm for CCHS that runs in time O^\\star(16^k)? Note that the O^\\star(\\cdot) notation is used to hide factors that are polynomial in n and k.\nHint: Use the algorithm described previously in the question, but modify it slightly. In particular, if an execution path pushes more than 3S(P) vertices into the forbidden set F, can you terminate it prematurely? Also, what is the cost of the successful execution paths?\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. GreedyHS [2 points]\n\n\n\nLet U=\\left\\{x_1, \\ldots, x_n\\right\\} be an univere of n elements. Suppose we have a family \\mathcal{F} over U that consists of three-sized subsets of U, for example:\n\n\\mathcal{F} = \\left(x_1, x_3, x_4\\right),\\left(x_2, x_3, x_7\\right),\\left(x_1, x_5, x_6\\right)\n\nWe want to find a smallest subset X of U such that for all sets S \\in \\mathcal{F}, S \\cap X \\neq \\emptyset.\nConsider the following algorithm for this problem.\nGreedy(U,F)\n\nInit X = emptyset\nwhile F is non-empty do:\n    Take an arbitrary set S in F.\n    Let x be an element in S\n    X = X U {x}\n    Remove all sets from F that contain x\nend while\nWhat can you say about the worst-case approximation ratio of this algorithm?\n\n\n\n\n\n\n\n\nProblem 3. Knapsack [2 points]\n\n\n\nConsider the knapsack problem. Given a set X=\\left\\{x_1, \\ldots, x_n\\right\\} of n items with weights w\\left(x_i\\right) and values v\\left(x_i\\right), it asks for the highest total value of items we can put into our knapsack such that the total weight of all these items is at most W.\nDescribe a 0/1-LP that models the problem correctly.\n\n\n\n\n\n\n\n\nProblem 4. Rectangle Covering [4 Points]\n\n\n\n\n\n\nRectangle Cover Problem Example\n\n\nSuppose we have a set P=\\left\\{p_1, \\ldots, p_n\\right\\} of n points and a set R=\\left\\{r_1 \\ldots, r_m\\right\\} of m rectangles, as in the image above. Each rectangle r_i \\in R has a certain cost c_i>0 associated with it. We wish to find a subset S \\subseteq R of rectangles whose cost is minimized such that the rectangles in S together cover all points in P.\nWe wish to model this problem as a 0/1-LP. To this end we introduce a decision variable x_i for each rectangle r_i \\in R, where x_i=1 corresponds to putting rectangle r_i into S and x_i=0 corresponds to not putting r_i into S. otherwise. Furthermore, for a point p_j \\in P, define R\\left(p_j\\right)=\\left\\{r_i \\in R: p_j \\in r_i\\right\\}.\n\n\n\n\n\n\nLP for Rectangle Cover\n\n\n\n\n\nDescribe a 0/1-LP that models the problem correctly.\n\n\n\n\n\n\n\n\n\nLP-based Approximation for Rectangle Cover\n\n\n\n\n\nDescribe a 5-approximation assuming that each point is contained in at most 5 rectangles.\n\n\n\n\n\n\n\n\n\n\n\nProblem 5. Dominating Set Reduction Rule When The Graph has No Short Cycles [2 points]\n\n\n\nSuppose G is a simple, undirected graph that has no cycles of length three or four. Recall that a subset S of vertices of G is called a dominating set if every vertex v of G either belongs to S or has a neighbor in S, in other words, N[v] \\cap S \\neq \\emptyset.\nLet S be a dominating set of G of size at most k, where G is as given above (i.e, G has no triangles and no cycles of length four). Show that if the degree of v is more than k in G, then v \\in S."
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/L14.html",
    "href": "courses/2023/02-ES214/quizzes/L14.html",
    "title": "CS614. Advanced Algorithms. L14 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 2. High-Degree Branching for FVS\n\n\n\nApply the same preprocessing steps as in the previous problem.\nLet \\left(v_1, v_2, \\ldots, v_n\\right) be a descending ordering of V(G) according to vertex degrees, i.e., d\\left(v_1\\right) \\geq d\\left(v_2\\right) \\geq \\ldots \\geq d\\left(v_n\\right). Let V_{3 k}=\\left\\{v_1, \\ldots, v_{3 k}\\right\\}.\nRecall that the minimum vertex degree of G is at least 3. Show that every feedback vertex set in G of size at most k contains at least one vertex of V_{3 k}."
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/L02.html",
    "href": "courses/2023/02-ES214/quizzes/L02.html",
    "title": "CS614. Advanced Algorithms. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer."
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/L03.html",
    "href": "courses/2023/02-ES214/quizzes/L03.html",
    "title": "CS614. Advanced Algorithms. L03 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Partition Matroid\n\n\n\nShow that the exchange axiom holds for the Partition Matroid defined in class.\n\n\n\n\n\n\n\n\nProblem 2. Representing the Graphic Matroid\n\n\n\nThe graphic matroid of a graph G can be represented by the following matrix: we have one row for each vertex, and one column for each edge. The column for edge e has +1 in the row for one endpoint, -1 in the row for the other endpoint, and 0 elsewhere; the choice of which endpoint to give which sign is arbitrary.\nArgue that this is a valid representation (i.e, that the forests correspond to linearly independent columns and the subsets of edges that have cycles in them correspond to dependent columns)."
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/L07.html",
    "href": "courses/2023/02-ES214/quizzes/L07.html",
    "title": "CS614. Advanced Algorithms. L07 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the textbook on Parameterized Algorithms by Marek Cygan, Fedor V. Fomin, Łukasz Kowalik, Daniel Lokshtanov, Dániel Marx, Marcin Pilipczuk, Michał Pilipczuk, and Saket Saurabh.\n\n\n\n\n\n\n\n\nProblem 1. Cluster Vertex Deletion\n\n\n\nIn the Cluster Vertex Deletion problem, we want to know if a simple undirected graph G has a subset S of at most k vertices such that G \\setminus S is a disjoint union of cliques.\n\n\n\n\n\n\nProblem 1.1 A Branching Algorithm\n\n\n\nDesign a 3^k \\cdot n^{\\mathcal{O}(1)} algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nDesign a 3-approximation algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\n\n\nProblem 2. Don’t Satisfy Too Much!\n\n\n\nIn the MIN-2-SAT problem, we are given a 2 -CNF formula \\phi and an integer k, and the objective is to decide whether there exists an assignment for \\phi that satisfies at most k clauses.\nShow that MIN-2-SAT can be solved in time 2^k n^{\\mathcal{O}(1)}."
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/L13.html",
    "href": "courses/2023/02-ES214/quizzes/L13.html",
    "title": "CS614. Advanced Algorithms. L13 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. FVS: is this FPT?\n\n\n\nRecall the following branching algorithm for Feedback Vertex Set (FVS) discussed in class:\n\nPreprocess to eliminate vertices of degree at most two, resulting in an equivlaent multigraph.\nPreprocess to force vertices with self-loops in the solution and adjust the budget as appropriate.\nIf a pair of vertices have more than two edges between them, delete all but two of these edges.\nSTOP if the graph is a forest or if we are out of budget.\nFind a shortest cycle and branch on all its vertices.\n\nSince a graph of minimum degree three that is not acyclic always has a cycle of length O(\\lg n), this algorithm has a running time of O^\\star((\\lg n)^k). Argue that this running time in fact shows that FVS is FPT in k."
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/L12.html",
    "href": "courses/2023/02-ES214/quizzes/L12.html",
    "title": "CS614. Advanced Algorithms. L12 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. List Coloring\n\n\n\nIn the List Coloring problem, we are given a graph G and for each vertex v \\in V(G) there is a set (also called a list) of admissible colors L(v) \\subseteq N. The goal is to verify whether it is possible to find a proper vertex coloring c: V(G) \\rightarrow \\mathbb{N} of G such that for ever y vertex v we have c(v) \\in L(v). In other words, L(v) is the set of colors allowed for v.\nShow a 2^n n^{\\mathcal{O}(1)}-time algorithm for List Coloring.\nHint. Read Theorem 10.8 from the Parameterized Algorithms text.\n\n\n\n\n\n\n\n\nProblem 2. Triangle Packing\n\n\n\nIn the Triangle Packing problem, we are given an undirected graph G and a positive integer k, and the objective is to test whether G has k-vertex disjoint triangles. Using color coding show that the problem admits an algorithm with running time 2^{O(k)} n^{O(1)}."
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/L06.html",
    "href": "courses/2023/02-ES214/quizzes/L06.html",
    "title": "CS614. Advanced Algorithms. L06 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the Coursera course on Approximation Algorithms taught by Mark de Berg.\n\n\n\n\n\n\n\n\nProblem 1. Changing the threshold\n\n\n\nConsider the algorithm LPAPX-WVC from the class.\n\n\n\n\n\n\nProblem 1.1 Increasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 2/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 1/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. Changing the rounding scheme\n\n\n\nConsider a different rounding strategy for the LP relaxation of the vertex cover problem. Instead of rounding up every vertex whose value is at least 0.5 after running the LP, we do the following:\nWe look at every edge, and then we round up the variable of the endpoint with the highest value, where in case of ties we take the endpoint with the highest index.\nIn other words, if the vertex set is V=\\left\\{v_1, \\ldots, v_n\\right\\} and we denote the associated variable of v_i by x_i then the cover C is computed as follows:\nC:=\\left\\{v_i \\in V:\\right. there is an edge \\left(v_i, v_j\\right) such that \\left(x_i>x_j\\right) or \\left(x_i=x_j\\right. and \\left.\\left.i>j\\right)\\right\\}\nWhich statement is true?\n\nThis does not work, because we might report an invalid solution.\nThis gives a valid solution, but the approximation ratio becomes worse.\nThis gives a valid solution, and in fact the solution is always exactly the same as in the original rounding scheme.\nThis gives a valid solution. We sometimes report a better solution than in the original rounding scheme, but the approximation ratio of the algorithm is still more than 2 - \\epsilon for any \\epsilon > 0.\nThis gives a valid solution, and the approximation ratio of the algorithm becomes 3/2.\n\n\n\n\n\n\n\n\n\nProblem 3. Lower Bound\n\n\n\nSuppose you have created an algorithm for a certain problem using LP relaxation and you want to say something about its approximation ratio. Which lower bound on the optimal solution can you use?\n\nThe solution to the 0/1-LP.\nThe solution to the relaxed LP.\nDepends on the problem.\n\n\n\n\n\n\n\n\n\nProblem 4. Integrality Gap\n\n\n\nWhat is the integrality gap of the vertex-cover LP for the complete graph on n vertices, where all vertices have weight 1?"
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/L10.html",
    "href": "courses/2023/02-ES214/quizzes/L10.html",
    "title": "CS614. Advanced Algorithms. L10 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Set Cover: The Greedy Bound is Tight\n\n\n\nWe argued in class that the greedy approach to solving the unweighted Set Cover problem achieves an approximation ratio of O(H_n). Argue that this bound is tight, i.e, come up with examples where the algorithm picks sets in a manner that the cost of the solution is roughly H_n worse than optimal.\n\n\n\n\n\n\n\n\nProblem 2. Set Cover and Related Problems\n\n\n\n\nShow that Vertex Cover is a special case of Set Cover.\nAlso show that Dominating Set and Set Cover are equivalent (i.e, Set Cover can be reduced to Dominating Set and vice versa)."
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/L04.html",
    "href": "courses/2023/02-ES214/quizzes/L04.html",
    "title": "CS614. Advanced Algorithms. L04 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Matroid Intersection Example\n\n\n\nConsider a directed graph D=(V, E \\subseteq V \\times V). A set T \\subseteq E is an arborescence (oriented forest) if:\n\nT does not contain a cycle (ignoring directions of edges).\nEvery vertex in V has at most one incoming edge.\n\nAn arborescence T with |T|=n-1 will have one incoming edge incident on each node except one. If we denote this special node as root, this is an oriented spanning tree as shown in the figure.\n\n\n\nAn example arborescence.\n\n\nConsider the underlying undirected graph G_D = (V,E) associated with D (this is the graph obtained by “erasing the arrows” in D). Consider the universe given by E. Suggest two matroids {\\mathcal M}_1 and {\\mathcal M}_2 for which set of arborescences is given by the sets independent in both {\\mathcal M}_1 and {\\mathcal M}_2.\nHint: these are both matroids seen in class. Further, you might find it useful to partition E into |V| many parts as follows — the part P_v contains all edges that are incoming arcs for the vertex v in D. Can you define a matroid based on this partition?\nDescribe {\\mathcal M}_1 and {\\mathcal M}_2.\n\n\n\n\n\n\n\n\nProblem 2. Maker-Breaker Game\n\n\n\nTwo players take turns removing edges from an undirected graph until there are no edges left.\nPlayer 2 wins if the edges they remove contains a spanning tree, player 1 wins if the set of edges they remove would disconnect the original graph.\n\nIs it true that exactly one player wins this game? In other words, is the following statement true?\n\n“It is NOT the case that after the game has been played, both players can claim a win.”\n\nYes\nNo\n\n\nWhich player wins on a path?\n\n\nPlayer 1\nPlayer 2\n\n\nWhich player wins on a complete graph?\n\n\nPlayer 1\nPlayer 2\n\n\nComplete this sentence: player 2 has the winning strategy if and only if the graph contains BLANK.\n\n(No marks for answering this question, take your best guess :) )"
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/L05.html",
    "href": "courses/2023/02-ES214/quizzes/L05.html",
    "title": "CS614. Advanced Algorithms. L05 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Approximate Vertex Cover\n\n\n\nGive an example of a graph where the 2-approximate solution (via maximal matchings) is worse than the optimal one. Even just slightly worse is enough :)\n\n\n\n\n\n\n\n\nProblem 2. Approximate Independent Set\n\n\n\nSince the complement of a vertex cover is an independent set, you might be tempted to think that the approximation discussed in class also approximates independent set. In particular, consider the following algorithm for independent set:\n\nRun the 2-approximation for vertex cover discussed in class, let the output be S.\nLet I := V(G) \\setminus S.\nIf I = \\emptyset, then let v \\in V(G) be an arbitrary vertex; set I := \\{v\\}.\n\nLet:\n\np denote the size of a largest independent set in G\nq denote the size of the set obtained by taking the complement of the output of the 2-approximation discussed in class.\nr denote \\max(q,1)\n\nNote that r is the size of the independent set output by the algorithm above.\nCome up with a graph where p can be a factor of cn larger than r for some constant c.\n\n\n\n\n\n\n\n\nProblem 3. Vertex Cover Matroid\n\n\n\nDo the set of vertex covers in a graph G form a matroid over the universe V(G)? If not, select the axiom that fails:\n\nExchange Axiom\nHereditary Axiom\nVertex covers do form a matroid"
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/A06.html",
    "href": "courses/2023/02-ES214/quizzes/A06.html",
    "title": "CS614. Advanced Algorithms. L06 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the Coursera course on Approximation Algorithms taught by Mark de Berg.\n\n\n\n\n\n\n\n\nProblem 1. Changing the threshold\n\n\n\nConsider the algorithm LPAPX-WVC from the class.\n\n\n\n\n\n\nProblem 1.1 Increasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 2/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 1/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf we increase the threshold t beyond 0.5, then the output may not even be a vertex cover: for example, consider the example of a complete graph where the LPOPT sets all variables to 0.5: in this case our output will be the empty set with any threshold higher than 0.5.\nIf we decrease the threshold t below 0.5, then the output will be a vertex cover — indeed, if any edge (u,v) is uncovered, then both u and v were set to values less than t, and in particular less than 0.5, so we will violate our edge constraint just as we do when working with a threshold of 0.5. However, by choosing a lower value, we worsen the approximation ratio: in particular, if t = 1/3 then the output is a 3-approximation.\n\n\n\n\n\n\n\n\n\nProblem 2. Changing the rounding scheme\n\n\n\nConsider a different rounding strategy for the LP relaxation of the vertex cover problem. Instead of rounding up every vertex whose value is at least 0.5 after running the LP, we do the following:\nWe look at every edge, and then we round up the variable of the endpoint with the highest value, where in case of ties we take the endpoint with the highest index.\nIn other words, if the vertex set is V=\\left\\{v_1, \\ldots, v_n\\right\\} and we denote the associated variable of v_i by x_i then the cover C is computed as follows:\nC:=\\left\\{v_i \\in V:\\right. there is an edge \\left(v_i, v_j\\right) such that \\left(x_i>x_j\\right) or \\left(x_i=x_j\\right. and \\left.\\left.i>j\\right)\\right\\}\nWhich statement is true?\n\nThis does not work, because we might report an invalid solution.\nThis gives a valid solution, but the approximation ratio becomes worse.\nThis gives a valid solution, and in fact the solution is always exactly the same as in the original rounding scheme.\nThis gives a valid solution. We sometimes report a better solution than in the original rounding scheme, but the approximation ratio of the algorithm is still more than 2 - \\epsilon for any \\epsilon > 0.\nThis gives a valid solution, and the approximation ratio of the algorithm becomes 3/2.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe solution is valid: indeed, let (u,v) be an edge, and recall that the algorithm worked as follows:\nWe look at every edge, \nand then we round up the variable of the endpoint with the highest value, \nwhere in case of ties we take the endpoint with the highest index. \nSince one of the endpoints was rounded up, the edge is covered; and this is evidently true of every edge.\nThe solution with respect to this rounding may be better than the threshold-based rounding: for example, consider again a complete graph where the LPOPT sets all variables to 1/2: the threshold-based rounding leads to a solution of cost n, while the cost here will be strictly less.\nHowever, to see that the approximation ratio of the algorithm is still more than 2 - \\epsilon for any \\epsilon > 0, consider, for example, a cycle on n vertices: one can choose a suitably large value of n to bring the approximation ratio arbitrarily close to 2.\n\n\n\n\n\n\n\n\n\nProblem 3. Lower Bound\n\n\n\nSuppose you have created an algorithm for a certain problem using LP relaxation and you want to say something about its approximation ratio. Which lower bound on the optimal solution can you use?\n\nThe solution to the 0/1-LP.\nThe solution to the relaxed LP.\nDepends on the problem.\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n\nAs was clarified in class, this question is in the context of minimization problems.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe solution to the relaxed LP is a useful lower bound for the OPT. The value of the OPT for the 0/1-LP is exactly equal to the OPT (in a presumed exact formulation of the problem) and does not, by itself, provide information about the behavior of the relaxed LP.\n\n\n\n\n\n\n\n\n\nProblem 4. Integrality Gap\n\n\n\nWhat is the integrality gap of the vertex-cover LP for the complete graph on n vertices, where all vertices have weight 1?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nILPOPT = n-1 and LPOPT = n/2; so the integrality gap is 2 \\cdot (n-1)/n = 2(1 - \\frac{1}{n})."
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/A07.html",
    "href": "courses/2023/02-ES214/quizzes/A07.html",
    "title": "CS614. Advanced Algorithms. L07 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the textbook on Parameterized Algorithms by Marek Cygan, Fedor V. Fomin, Łukasz Kowalik, Daniel Lokshtanov, Dániel Marx, Marcin Pilipczuk, Michał Pilipczuk, and Saket Saurabh.\n\n\n\n\n\n\n\n\nProblem 1. Cluster Vertex Deletion\n\n\n\nIn the Cluster Vertex Deletion problem, we want to know if a simple undirected graph G has a subset S of at most k vertices such that G \\setminus S is a disjoint union of cliques.\n\n\n\n\n\n\nProblem 1.1 A Branching Algorithm\n\n\n\nDesign a 3^k \\cdot n^{\\mathcal{O}(1)} algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nDesign a 3-approximation algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAs discussed in class, the induced path on three vertices is a forbidden substructure for a cluster graph. We state and prove this fact here for completeness.\n\nClaim. A graph G is a disjoint union of cliques if and only if it does not contain a path on three vertices as an induced subgraph.\nProof (sketch). Suppose G is a disjoint union of cliques, and for the sake of contradiction, suppose it has an induced path on vertices x,y,z with the edges being between x and y, and y and z. Note that since this is an induced path, there is no edge between x and z. Since every component of G is a clique, we know that x and z must be in different components. However, there is a path from x to z via y, which is a contradiction.\nSuppose G does not contain a path on three vertices as an induced subgraph. Again, for the sake of contradiction, suppose G has a connected component that is not a clique. Let (u,v) be a non-edge in this component. Let P be a shortest path between u and v consisting of the vertices:\nP := \\{u, w_1, \\ldots, w_t, \\ldots v\\}.\nNotice that t \\geqslant 1, otherwise (u,v) is an edge. Further, notice that u, w_1, w_2 forms an induced path of length three1 (if (u,w_2) was an edge then we have a shorter path by omitting w_1, contradicting our assumption that P is a shortest path between u and v). This contradicts our assumption.\n\nBased on this, we have the following algorithm:\nCVD(G,k):\n    If k <= 0 and G has an induced P3 - RETURN NO\n    If k >= 0 and G is a cluster graph - RETURN YES\n\n    Let a,b,c be vertices such that ab and bc are edges and ac is not an edge.\n\n    Return (CVD(G-a,k-1) OR CVD(G-b,k-1) OR (G-c,k-1))\nOne can obtain a 3-approximation by enumerating a maximal collection of disjoint induced P_3’s and including all vertices from the collection in the solution. If the collection has size t, we know that any solution (and in particular, the optimal one) must contain at least t vertices and the output has at most 3t vertices. The algorithm is summarized below:\nCVD-3-Approx(G):\n    Init S = emptyset\n\n    While there is an induced P3 = (x,y,z) in G:\n        include (x,y,z) in S\n        G = G - (x,y,z)\n\n    return S\n\n\n\n\n\n\n\n\n\nProblem 2. Don’t Satisfy Too Much!\n\n\n\nIn the MIN-2-SAT problem, we are given a 2-CNF formula \\phi and an integer k, and the objective is to decide whether there exists an assignment for \\phi that satisfies at most k clauses.\nShow that MIN-2-SAT can be solved in time 2^k n^{\\mathcal{O}(1)}.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf there is a variable x that occurs only positively in \\phi, we claim that there exists an optimal assignment that sets it to 0. Indeed, let \\tau be an assignment that sets x to 1. Let \\tau_x be the assignment obtained from \\tau by flipping the value of x from 1 to 0. Note that the clauses that do not contain the variable x are either satisfied or falsified in both \\tau and \\tau_x. For clauses that contain x, it is possible that they are satisfied by \\tau but not by \\tau_x, but not vice versa. Therefore, \\tau_x falsifies at least as many clauses as \\tau, and we are done.\nBased on this, our algorithm proceeds as follows:\nif there is a variable x that occurs only as a positive literal:\n    set x to 0\nif there is a variable x that occurs only as a negated literal:\n    set x to 1\nThe argument for the negated occurrences is symmetric to the one we have for positive literals.\nOnce we perform this preprocessing, assuming that have clauses remaining, we have the following guarantee:\n\nEvery variable has at least one positive and one negated occurrence.\n\nNow we can branch exhuastively on the settings of variables; with the promise that either setting of the variable reduces our budget by at least one. The overall algorithm is summarized in the following pseudocode:\nMINSAT(phi,k):\n    if there is a variable x that occurs only as a positive literal:\n        set x to 0\n    if there is a variable x that occurs only as a negated literal:\n        set x to 1\n\n    if phi is empty:\n        return YES\n    if phi is not empty and k <= 0:\n        return NO\n\n    Let x be any variable that occurs in phi.\n    return MINSAT(phi|[x = TRUE],k-1) OR MINSAT(phi|[x = FALSE],k-1)"
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/A05.html",
    "href": "courses/2023/02-ES214/quizzes/A05.html",
    "title": "CS614. Advanced Algorithms. L05 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Approximate Vertex Cover\n\n\n\nGive an example of a graph where the 2-approximate solution (via maximal matchings) is worse than the optimal one. Even just slightly worse is enough :)\n\n\n\n\n\n\n\n\nFollow up question\n\n\n\n\n\nWhat are examples of graphs where the 2-approximate solution via maximal matchings is close to optimal? The empty and complete graphs come to mind, are there others?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nEven if the input graph is an edge, a star, or a matching, the 2-approximate solution is already worse by a factor of two.\n\n\n\n\n\n\n\n\n\nProblem 2. Approximate Independent Set\n\n\n\nSince the complement of a vertex cover is an independent set, you might be tempted to think that the approximation discussed in class also approximates independent set. In particular, consider the following algorithm for independent set:\n\nRun the 2-approximation for vertex cover discussed in class, let the output be S.\nLet I := V(G) \\setminus S.\nIf I = \\emptyset, then let v \\in V(G) be an arbitrary vertex; set I := \\{v\\}.\n\nLet:\n\np denote the size of a largest independent set in G\nq denote the size of the set obtained by taking the complement of the output of the 2-approximation discussed in class.\nr denote \\max(q,1)\n\nNote that r is the size of the independent set output by the algorithm above.\nCome up with a graph where p can be a factor of cn larger than r for some constant c.\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n\nIt was not explicit in the question: G denotes the input graph and n denotes the number of vertices in G.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet n = 2p and consider a complete bipartite graph K_{p,p}. The optimal independent set has size p but the algorithm above returns 1.\n\n\n\n\n\n\n\n\n\nProblem 3. Vertex Cover Matroid\n\n\n\nDo the set of vertex covers in a graph G form a matroid over the universe V(G)? If not, select the axiom that fails:\n\nExchange Axiom\nHereditary Axiom\nVertex covers do form a matroid\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nA subset of a vertex cover need not be a vertex cover; and in particular, the empty set is also not a vertex cover (although this axiom was not offered as an option)."
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/A04.html",
    "href": "courses/2023/02-ES214/quizzes/A04.html",
    "title": "CS614. Advanced Algorithms. L04 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Matroid Intersection Example\n\n\n\nConsider a directed graph D=(V, E \\subseteq V \\times V). A set T \\subseteq E is an arborescence (oriented forest) if:\n\nT does not contain a cycle (ignoring directions of edges).\nEvery vertex in V has at most one incoming edge.\n\nAn arborescence T with |T|=n-1 will have one incoming edge incident on each node except one. If we denote this special node as root, this is an oriented spanning tree as shown in the figure.\n\n\n\nAn example arborescence.\n\n\nConsider the underlying undirected graph G_D = (V,E) associated with D (this is the graph obtained by “erasing the arrows” in D). Consider the universe given by E. Suggest two matroids {\\mathcal M}_1 and {\\mathcal M}_2 for which set of arborescences is given by the sets independent in both {\\mathcal M}_1 and {\\mathcal M}_2.\nHint: these are both matroids seen in class. Further, you might find it useful to partition E into |V| many parts as follows — the part P_v contains all edges that are incoming arcs for the vertex v in D. Can you define a matroid based on this partition?\nDescribe {\\mathcal M}_1 and {\\mathcal M}_2.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTake {\\mathcal M}_1 to be the graphic matroid and {\\mathcal M}_2 to be the partition matroid with all budgets set to one. Membership in the first matroid ensures that there are no underlying undirected cycles and membership in the second matroid ensures that every vertex in V has at most one incoming edge.\n\n\n\n\n\n\n\n\n\nProblem 2. Maker-Breaker Game\n\n\n\nTwo players take turns removing edges from an undirected graph until there are no edges left.\nPlayer 2 wins if the edges they remove contains a spanning tree, player 1 wins if the set of edges they remove would disconnect the original graph.\n\nIs it true that exactly one player wins this game? In other words, is the following statement true?\n\n“It is NOT the case that after the game has been played, both players can claim a win.”\n\nYes\nNo\n\n\nWhich player wins on a path?\n\n\nPlayer 1\nPlayer 2\n\n\nWhich player wins on a complete graph?\n\n\nPlayer 1\nPlayer 2\n\n\nComplete this sentence: player 2 has the winning strategy if and only if the graph contains BLANK.\n\n(No marks for answering this question, take your best guess :) )\n\n\n\n\n\n\n\n\nHeads Up\n\n\n\nPart (3) was under-specified: the second player wins on complete graphs with at least four vertices but the first player has easy wins if the graph is an edge (a complete graph on two vertices) or a triangle (a complete graph on three vertices).\nGrading note: everyone recieves a full grade for this question.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSuppose both players indeed win. Let us delete the edges chosen by the first player. What is left is: (a) the set of edges chosen by the second player and (b) a disconnected graph. But the second player also won, so this set contains a spanning tree. A graph cannot simultaneously admit a spanning tree and be disconnected, this is a contradiction when applied on the graph induced by the leftover edges.\nPlayer 1 can choose any edge in the first step and he already wins.\nAssume that the graph has at least four vertices. Player 2 wins because notice that no matter how the first player plays the first (n-1) steps, it is not enough to disconnect the graph. By chosing edges carefully1, Player 2 can ensure that (s)he has booked a spanning tree already within the first (n-1) moves.\nNo spoilers on this one (yet)."
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/A03.html",
    "href": "courses/2023/02-ES214/quizzes/A03.html",
    "title": "CS614. Advanced Algorithms. L03 Solutions.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Partition Matroid\n\n\n\nShow that the exchange axiom holds for the Partition Matroid defined in class.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet (U := U_1 \\cup \\cdots \\cup U_\\ell, \\mathcal{F}) be a partition matroid with budgets a_1,\\ldots,a_\\ell.\nSuppose S, T \\subseteq U_1 \\cup \\cdots \\cup U_\\ell such that S,T \\in \\mathcal{F}, and |T| > |S|.\nThen, there exists at least one part U_i where |T \\cap U_i| > |S \\cap U_i|. Now let x \\in (T \\setminus S) \\cap U_i. Note that S \\cup \\{x\\} \\in \\mathcal{F} since:\n\\begin{equation*}\n    |S \\cap U_j| =\n    \\begin{cases}\n      < a_j & \\text{if } j = i,\\\\\n      \\leqslant a_j & \\text{otherwise}.\n    \\end{cases}\n\\end{equation*}\nand therefore:\n\\begin{equation*}\n    |(S \\cup \\{x\\}) \\cap U_j| =\n    \\begin{cases}\n      |S \\cap U_i| + 1 \\leqslant a_j & \\text{if } j = i,\\\\\n      \\leqslant a_j & \\text{otherwise}.\n    \\end{cases}\n\\end{equation*}\n\n\n\n\n\n\n\n\n\nProblem 2. Representing the Graphic Matroid\n\n\n\nThe graphic matroid of a graph G can be represented by the following matrix: we have one row for each vertex, and one column for each edge. The column for edge e has +1 in the row for one endpoint, -1 in the row for the other endpoint, and 0 elsewhere; the choice of which endpoint to give which sign is arbitrary.\nArgue that this is a valid representation (i.e, that the forests correspond to linearly independent columns and the subsets of edges that have cycles in them correspond to dependent columns).\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSuppose we have a subset of edges that contains a cycle. For simplicity, suppose the cycle is given by:\n\\{pq, qr, rs, st\\}\nNow consider the column vectors c_p, c_q, c_r, c_s:\n\\begin{bmatrix}\nc_p & c_q & c_r & c_s\\\\\n1 & 0 & 0 & -1 \\\\\n-1 & 1 & 0 & 0 \\\\\n0 & -1 & -1 & 0 \\\\\n0 & 0 & 1 & 1\n\\end{bmatrix}\nNote that:\n1 \\cdot c_p + 1 \\cdot c_q + (-1) \\cdot c_r + 1 \\cdot c_s\nis a linear combination with constants (1,1,-1,1) that establish that these vectors are linearly dependent. In general, write down the columns in the order in which they appear on the cycle. If the first entry in the column is not +1, then multiply the column by -1 (except the last column, where we do the reverse: if the first entry is +1, then we multiply the column by -1). This way, we have a situation where every row contains exactly one +1 entry and one -1 entry, and the linear combination sums to 0.\nThis shows that dependent subsets of the matroid correspond to linearly dependent columns of M.\nTo see that independent subsets S \\subseteq E(G) correspond to linearly independent columns, consider the set of columns that correspond to S:\n\\{c_e ~|~ e \\in S\\    }\nSuppose, for the sake of contradiction, that there was some non-trivial linear combination of these columns that vanished, i.e, for non-empty subset T \\subseteq S, there exist constants \\{\\alpha_e\\}_{e \\in T} where:\n\\sum_{e \\in T} \\alpha_e c_e = 0\nBut now consider the subgraph consisting of the edges in T. Note that the minimum degree of T must be two (suppose u \\in T has degree one, and its unique neighbor is v: then consider the entry in the row corresponding to u in the column corresponding to the edge uv: this is non-zero and there is no cancelation possible in the sum above). However, a graph whose minimum degree is two cannot be acyclic, and this is a contradiction."
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/A02.html",
    "href": "courses/2023/02-ES214/quizzes/A02.html",
    "title": "CS614. Advanced Algorithms. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe circuits of the graphic matroid are the cycles of the graph G.\n\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c,d\\} with the edges \\{ab, cd, ad\\}.\nThere are two matchings in this instance:\n\nM_1 := \\{ab,cd\\}\nM_2: \\{ad\\}\n\nHowever, although |M_1| > |M_2|, neither of the edges from M_1 can be added to M_2.\n\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c\\} with the edges \\{ab, ac\\}. There are two independent sets: S_1 := \\{b,c\\} and M_2: \\{a\\}, but neither of the vertices from S_1 can be added to S_2.\n\nIf the independent sets formed a matroid the problem of finding a maximum independent set would not be NP-complete. \n— Comment in class"
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/L08.html",
    "href": "courses/2023/02-ES214/quizzes/L08.html",
    "title": "CS614. Advanced Algorithms. L08 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Better Approximation given a k-coloring\n\n\n\nGiven a k-coloring of a graph G, show that we can find a vertex cover which is a 2\\bigl(1−\\frac{1}{k}\\bigr) approximation.\nHint: use the k-coloring on the vertices of V_{1/2}.\n\n\n\n\n\n\n\n\nProblem 2. Point Line Cover\n\n\n\nIn the Point Line Cover problem, we are given a set of n points in the plane and an integer k, and the goal is to check if there exists a set of k lines on the plane that contain all the input points.\nShow a kernel for this problem with \\mathcal{O}\\left(k^2\\right) points."
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/L09.html",
    "href": "courses/2023/02-ES214/quizzes/L09.html",
    "title": "CS614. Advanced Algorithms. L09 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Dominating Set\n\n\n\nA dominating set of a graph G is a subset of vertices S such that every vertex in G either belongs to S or has a neighbor in S.\nSuppose you have an instance of dominating set given by (G,k), which is a YES-instance if and only if G has a dominating set of size at most k.\nIs the following reduction rule safe?\nRR. If d(v) > k, then return (G-v,k-1).\n( ) Yes (X) No\nBriefly justify your answer:\n|____|\n\n\n\n\n\n\n\n\nProblem 2. Connected Vertex Cover\n\n\n\nA connected vertex cover of a graph G is a subset of vertices S such that: (a) S is a vertex cover of G, and (b) G[S] is a connected subgraph of G.\nSuppose you have an instance of connected vertex cover given by (G,k), which is a YES-instance if and only if G has a connected vertex cover of size at most k.\n\n\n\n\n\n\nProblem 2.1 Connected Vertex Cover I.\n\n\n\nDesign a \\mathcal{O}(2^k) vertex kernel for Connected Vertex Cover.\nHint: What can you say about high degree vertices? How many can G have?\nFollow up hint: What can you say about two vertices that have the same neighbourhood among the high-degree vertices?\n\n\n\n\n\n\n\n\nProblem 2.2 Connected Vertex Cover II.\n\n\n\nObserve that the kernelization argument that we made for Vertex Cover does not work as-is for connected vertex cover. Recall that the reduction rules were the following:\n\nR0. If k \\leqslant 0 and E is non-empty, return a trivial no-instance.\nR1. If k \\geqslant 0 and E is empty, return a trivial yes-instance.\nR2. If v is a degree zero vertex, return (G\\setminus \\{v\\},k), i.e, delete v from G and keep the budget the same.\nR3. If v is vertex whose degree is more than k, return (G\\setminus \\{v\\},k-1), i.e, delete v from G and reduce the budget by one.\n\nWhere does it fail? Justify, if possible, with an example."
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/L19.html",
    "href": "courses/2023/02-ES214/quizzes/L19.html",
    "title": "CS614. Advanced Algorithms. L19 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Bin Packing\n\n\n\nConsider the bin-packing problem:\nInput: n items with sizes a_1 \\cdots a_n respectively, a positive integer B (bin capacity) and a positive integer k (number of bins). Question: Is there a partition of the set \\{1 \\cdots n\\} into sets S_1, \\ldots, S_k such that for each i \\in\\{1 \\cdots k\\} we have that \\sum_{j \\in S_i} a_j \\leq B?\nShow that Bin Packing is NP-complete.\n\n\n\n\n\n\n\n\nProblem 2. BOX-DEPTH\n\n\n\nConsider the following problem, called BOX-DEPTH: Given a set of n axisaligned rectangles in the plane, how big is the largest subset of these rectangles that contain a common point?\n\nDescribe a polynomial-time reduction from BOX-DEPTH to MAXCLIQUE.\nDescribe and analyze a polynomial-time algorithm for BOX-DEPTH. [Hint: O\\left(n^3\\right) time should be easy, but O(n \\log n) time is possible.]\nWhy don’t these two results imply that \\mathrm{P}=\\mathrm{NP}?"
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/L18.html",
    "href": "courses/2023/02-ES214/quizzes/L18.html",
    "title": "CS614. Advanced Algorithms. L18 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. 3-Hitting Set\n\n\n\nObtain an algorithm for 3-Hitting Set running in time 2.4656^k n^{\\mathcal{O}(1)} using iterative compression.\n\n\n\n\n\n\n\n\nProblem 2. d-Hitting Set\n\n\n\nGeneralize the algorithm from the previous problem to obtain an algorithm for d-Hitting Set running in time ((d-1)+0.4656)^k n^{\\mathcal{O}(1)}."
  },
  {
    "objectID": "courses/2023/02-ES214/tutorials/T01.html",
    "href": "courses/2023/02-ES214/tutorials/T01.html",
    "title": "ES214. Discrete Mathematics. Tutorial 01 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1A. How did they do it?\n\n\n\n\n\nImagine a friend gives you a deck of cards and lets you shuffle it a few times. They then ask vou to deal out the top 26 cards face down, which divides the deck into two.\nYou keep one half and they take the other. They ask you to count how many red cards you have. In the meantime, you notice that they are silently looking through their own half of the deck. But whatever they are doing they did it as quickly as you, because once you’re done they declare that they know how many red cards you counted, and correctly announce the answer!\nHow did they do it?\n\n\n\n\n\n\n\n\n\nProblem 1B. How did they do it? (Redux)\n\n\n\n\n\nDeduce how the following trick works.\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. Handshakes\n\n\n\n\n\nMr. and Mrs. Sharma invited four couples to their home. Some guests were friends of Mr. Sharma, and some others were friends of Mrs. Sharma. When the guests arrived, people who knew each other beforehand shook hands, those who did not know each other just greeted each other.\nAfter all this took place, the observant Mr. Sharma said “How interesting. If you disregard me, there are no two people present who shook hands the same number of times\nHow many times did Mrs. Sharma shake hands?\n\n\n\n\n\n\n\n\n\nProblem 3. Chessboard Game\n\n\n\n\n\nAlice begins by marking a corner square of an n × n chessboard; Bob marks an orthogonally adjacent square.\nThereafter, Alice and Bob continue alternating. each marking a square adjacent to the last one marked, until no unmarked adjacent square is available at which time the player whose turn it is to play loses.\nFor which n does Alice have a winning strategy? For which n does she win if the first square marked is instead a neighbor of a corner square?\nHint: dominoes.\n\n\n\n\n\n\n\n\n\nProblem 4. An Odd Party\n\n\n\n\n\nYou are at a party where any two people have an odd number of mutual friends at the party.\nShow that there are an odd number of attendees."
  },
  {
    "objectID": "courses/2023/02-ES214/tutorials/A01.html",
    "href": "courses/2023/02-ES214/tutorials/A01.html",
    "title": "ES214. Discrete Mathematics. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe circuits of the graphic matroid are the cycles of the graph G.\n\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c,d\\} with the edges \\{ab, cd, ad\\}.\nThere are two matchings in this instance:\n\nM_1 := \\{ab,cd\\}\nM_2: \\{ad\\}\n\nHowever, although |M_1| > |M_2|, neither of the edges from M_1 can be added to M_2.\n\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c\\} with the edges \\{ab, ac\\}. There are two independent sets: S_1 := \\{b,c\\} and M_2: \\{a\\}, but neither of the vertices from S_1 can be added to S_2.\n\nIf the independent sets formed a matroid the problem of finding a maximum independent set would not be NP-complete. \n— Comment in class"
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/Q01.html",
    "href": "courses/2023/02-ES214/quizzes/Q01.html",
    "title": "ES214. Discrete Mathematics. Tutorial 01 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer."
  },
  {
    "objectID": "courses/2023/02-ES214/quizzes/A01.html",
    "href": "courses/2023/02-ES214/quizzes/A01.html",
    "title": "ES214. Discrete Mathematics. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe circuits of the graphic matroid are the cycles of the graph G.\n\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c,d\\} with the edges \\{ab, cd, ad\\}.\nThere are two matchings in this instance:\n\nM_1 := \\{ab,cd\\}\nM_2: \\{ad\\}\n\nHowever, although |M_1| > |M_2|, neither of the edges from M_1 can be added to M_2.\n\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c\\} with the edges \\{ab, ac\\}. There are two independent sets: S_1 := \\{b,c\\} and M_2: \\{a\\}, but neither of the vertices from S_1 can be added to S_2.\n\nIf the independent sets formed a matroid the problem of finding a maximum independent set would not be NP-complete. \n— Comment in class"
  },
  {
    "objectID": "blog/course-plan/index.html",
    "href": "blog/course-plan/index.html",
    "title": "Course Plan Generator",
    "section": "",
    "text": "If you are\n\nteaching a course at IIT Gandhinagar next term (Aug-Dec 2023),\nworking on your course plan, and\nneed a list of dates on which you have classes,\n\nthen you can use the generator below to get a list, by checking your teaching days.\nDates during Exam I (Sep 02 – 06, 2023), Exam II (Oct 11 – 15, 2023), and the mid-sem recess (Oct 21 - 29, 2023) are excluded. Holidays are excluded too, but restricted holidays are not. If you need to view the holidays, you can indicate as much via the checkbox below.\nFor those outside IITGN: a standalone version is here and the source is here, in case you’d like to adapt this to your own context.\n\n\n Monday      Tuesday      Wednesday      Thursday      Friday\n\n\n  Include Holidays   Indicate Restricted Holidays    Generate Dates for Course Plan"
  },
  {
    "objectID": "courses/2023/02-AA/index.html",
    "href": "courses/2023/02-AA/index.html",
    "title": "CS 614 | Jan-Apr 2022",
    "section": "",
    "text": "About the Course\n\n\n\n\n\nThis course will explores the tradeoffs involved in coping with NP-completeness.\nWhen we think about designing algorithms, we are usually very demanding in how we go about it: we require our algorithms to be fast and accurate on all conceivable inputs. This is asking for quite a bit, and perhaps it is not surprising that we cannot afford this luxury all the time. The good news is that most of the time we can make meaningful progress by relaxing just one of these demands:\n\nGive up on accuracy, but not completely: look for solutions that are good enough (approximation) and/or work with algorithms that report the right solution most of the time (Las-Vegas style randomization).\nGive up on coverage, a little bit: let your algorithms work well on structured inputs. Hopefully the structure is such that it is not too limiting and is interesting enough for some application scenario, and is also enough to give you algorithmic leverage, i.e, there’s enough that you can exploit to make fast and accurate algorithms.\nGive up on speed, to some extent: going beyond the traditional allowance of polynomial time, which is the holy grail of what is considered efficient, takes you places. You could either allow for your algorithms have super-polynomial running times, and optimize as much as possible while being accurate on all inputs (exact algorithms), or allow for bad running times on a bounded subset of instances (Monte-Carlo style randomization).\n\nThis course is an introduction to techniques in achieving specific trade-offs, and understanding the theoretical foundations of frameworks that help us establish when certain tradeoffs are simply not feasible.\n\n\n\nFig. Exploring tradeoffs between the demands of accuracy, speed, and coverage.\n\n\n\n\n\n\n\n\n\n\n\nTarget Audience\n\n\n\n\n\nAnyone who is biting their nails from the NP-completeness cliffhanger at the end of their introduction to algorithms will probably enjoy this course.\n\n\n\n\n\n\n\n\n\nPrerequisites\n\n\n\n\n\nThis is a theoretical course that will require mathematical maturity (in particular, the ability to understand and write formal mathematical proofs), and some background in the design and analysis of algorithms. Programming experience is tangentially useful but not necessary. For students of IITGN, this course naturally follows up on DSA-II.\n\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\n\n\nThe Design of Approximation Algorithms • David P. Williamson and David B. Shmoys\nParameterized Algorithms • Marek Cygan, Fedor V. Fomin, Lukasz Kowalik, Daniel Lokshtanov, Daniel Marx, Marcin Pilipczuk, Michal Pilipczuk, and Saket Saurabh\nRandomized Algorithms • Motwani and Raghavan\nBeyond the Worst-Case Analysis of Algorithms • Tim Roughgarden\nAlgorithms • Jeff Erickson\n\n\n\n\n\n\n\n\n\n\nTimings and Venue\n\n\n\n\n\nOnline\n\n\n\n\n\n\n\n\n\nTAs and Office hours\n\n\n\n\n\nOffice Hours: Over Discord\nTAs TBA.\n\n\n\n\n\n\n\n\n\nEvaluation policy\n\n\n\n\n\nTBA\n\n\n\n\n\n\n\n\n\nRegister\n\n\n\n\n\nFor IITGN students, (pre-)register through IMS as usual.\nIf you are not from IITGN and are interested in taking up the course, then please send me an email.\n\n\n\n\nLecturesAssignmentsQuizzesExams\n\n\n\n\n\n    \n        Date\n        Lecture\n        Slides\n        Notes\n        Video\n    \n    \n                    \n            \n                04 Jan, 2023\n            \n            \n                1. Matroids and Greedy Algorithms - I\n                Matroids - definitions and examples • GreedyBasis Algorithm • Example: Scheduling with Deadlines\n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                09 Jan, 2023\n            \n            \n                2. Matroids and Greedy Algorithms - II\n                Proof of correctness of GreedyBasis\n            \n            \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                11 Jan, 2023\n            \n            \n                3. Matroid Intersection - I\n                Matroid Intersection and Matroid Parity (Section 12.2.1) • Connections with Matchings • 3-Matroid Intersection is NP-complete (Theorem 12.6)\n            \n            \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                16 Jan, 2023\n            \n            \n                4. Matroid Intersection - II\n                A polynomial time algorithm for Matroid Intersection\n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                18 Jan, 2023\n            \n            \n                5. Vertex Cover\n                Definition • Applications • Introduction to Approximation Algorithms • 2-approximation for Vertex Cover via maximal matchings\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                23 Jan, 2023\n            \n            \n                6. Vertex Cover\n                Introduction to Linear Programming • 2-approximation via rounding • A simple randomized algorithm for Vertex Cover\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                25 Jan, 2023\n            \n            \n                7. Vertex Cover\n                Introduction to Fixed-Parameter Tractability • An O(2^k) FPT algorithm by branching\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                01 Feb, 2023\n            \n            \n                8. Vertex Cover\n                Introduction to Kernelization • A Quadratic Kernel for Vertex Cover based on degree reductions\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                02 Feb, 2023\n            \n            \n                9. Vertex Cover\n                A Linear Kernel for Vertex Cover based on the LP formulation\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                13 Feb, 2023\n            \n            \n                10. Set Cover\n                A Greedy Approximation Algorithm • A LP formulation\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                15 Feb, 2023\n            \n            \n                11. Set Cover\n                Dual LP formulation • Weak Duality • Complementary Slackness Conditions • Rounding a Dual Solution\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                20 Feb, 2023\n            \n            \n                12. Detour: Long Path\n                Principle of Inclusion-Exclusion for a poly-space single-exponential algorithm for HAMPATH • Color Coding for Longest Path\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                22 Feb, 2023\n            \n            \n                13. Feedback Vertex Set\n                Dual LP Recap • Introduction to Feedback Vertex Set\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                27 Feb, 2023\n            \n            \n                14. Feedback Vertex Set\n                A first Primal-Dual-based O(log n)-approximation for FVS\n            \n            \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                01 Mar, 2023\n            \n            \n                15. No Class\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                13 Mar, 2023\n            \n            \n                16. Feedback Vertex Set\n                A 2-approximation algorithm for FVS: motivating the formulation\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                15 Mar, 2023\n            \n            \n                17. Feedback Vertex Set\n                A 2-approximation algorithm for FVS: the key combinatorial lemma\n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                20 Mar, 2023\n            \n            \n                18. Feedback Vertex Set\n                Iterative Compression • An O*(3.619^k) algorithm for FVS on general graphs\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                19. Lower Bounds\n                Introduction to NP-completeness • 3-Partition and friends • Multiprocessor Scheduling • Packing rectangles into a rectangle\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                29 Mar, 2023\n            \n            \n                20. Lower Bounds\n                Reductions from 3-Partition\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                03 Apr, 2023\n            \n            \n                21. Lower Bounds\n                SAT and Circuit SAT • CNF SAT • 3SAT • 3SAT-4 • Monotone 3SAT • Polynomial-time variants\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                05 Apr, 2023\n            \n            \n                22. Lower Bounds\n                Schaefer's Dichotomy Theorem • 2-colorable perfect matching\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                10 Apr, 2023\n            \n            \n                23. Lower Bounds\n                Parameterized Intractability • The W-hierarchy • Reductions from CLIQUE\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                12 Apr, 2023\n            \n            \n                24. Lower Bounds\n                Kernel Lower Bounds • Composition and Distillation • Examples of compositions • Parameter preserving transformations\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                17 Apr, 2023\n            \n            \n                25. Lower Bounds\n                The (Strong) Exponential Time Hypothesis • Sparsification Lemma • Implications for parameterized algorithms\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                19 Apr, 2023\n            \n            \n                26. Lower Bounds\n                Reductions based on the ETH\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                24 Apr, 2023\n            \n            \n                27. Lower Bounds\n                Inapproximability Introduction • NP optimization problems • PTAS, APX • Stronger notions of reductions that preserve approximability • APX-hardness of vertex cover\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                26 Apr, 2023\n            \n            \n                28. Lower Bounds\n                Gap Inapproximability • Gap Problems • Gap-producing and gap-preserving reductions • PCP theorem • Unique Games Conjecture\n            \n            \n            \n            \n            \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\nThese are some practice assignments: the due date is simply the recommended completion deadline. There is no need to submit these assignments.\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                11 Jan, 2023\n            \n            \n                Assignment 1\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    01 Feb, 2023\n            \n        \n                    \n            \n                20 Feb, 2023\n            \n            \n                Assignment 2\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    20 Mar, 2023\n            \n        \n                    \n            \n                03 Apr, 2023\n            \n            \n                Assignment 3\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    26 Apr, 2023\n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                09 Jan, 2023\n            \n            \n                Matroids and Greedy Algorithms - II\n                Proof of correctness of GreedyBasis\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    09 Jan, 2023\n            \n        \n                    \n            \n                11 Jan, 2023\n            \n            \n                Matroid Intersection - I\n                Matroid Intersection and Matroid Parity (Section 12.2.1) • Connections with Matchings • 3-Matroid Intersection is NP-complete (Theorem 12.6)\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    11 Jan, 2023\n            \n        \n                    \n            \n                16 Jan, 2023\n            \n            \n                Matroid Intersection - II\n                A polynomial time algorithm for Matroid Intersection\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    16 Jan, 2023\n            \n        \n                    \n            \n                18 Jan, 2023\n            \n            \n                Vertex Cover\n                Definition • Applications • Introduction to Approximation Algorithms • 2-approximation for Vertex Cover via maximal matchings\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    18 Jan, 2023\n            \n        \n                    \n            \n                23 Jan, 2023\n            \n            \n                Vertex Cover\n                Introduction to Linear Programming • 2-approximation via rounding • A simple randomized algorithm for Vertex Cover\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    23 Jan, 2023\n            \n        \n                    \n            \n                25 Jan, 2023\n            \n            \n                Vertex Cover\n                Introduction to Fixed-Parameter Tractability • An O(2^k) FPT algorithm by branching\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    25 Jan, 2023\n            \n        \n                    \n            \n                01 Feb, 2023\n            \n            \n                Vertex Cover\n                Introduction to Kernelization • A Quadratic Kernel for Vertex Cover based on degree reductions\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    01 Feb, 2023\n            \n        \n                    \n            \n                03 Feb, 2023\n            \n            \n                Vertex Cover\n                A Linear Kernel for Vertex Cover based on the LP formulation\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    03 Feb, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Set Cover\n                A Greedy Approximation Algorithm • A LP formulation\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Apr, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Detour: Long Path\n                Principle of Inclusion-Exclusion for a poly-space single-exponential algorithm for HAMPATH • Color Coding for Longest Path\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Apr, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Feedback Vertex Set\n                An O(log n)-approximation via primal dual\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Apr, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Feedback Vertex Set\n                A 2-approximation algorithm using a different LP formulation\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Apr, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Feedback Vertex Set\n                Iterative Compression • An O*(3.619^k) algorithm for FVS on general graphs • A polynomial-time algorithm on graphs of maximum degree 3\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Apr, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Lower Bounds\n                Introduction to NP-completeness • 3-Partition and friends • Multiprocessor Scheduling • Packing rectangles into a rectangle\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    27 Mar, 2023\n            \n        \n                    \n            \n                29 Mar, 2023\n            \n            \n                Lower Bounds\n                Reductions from 3-Partition\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    29 Mar, 2023\n            \n        \n                    \n            \n                03 Apr, 2023\n            \n            \n                Lower Bounds\n                SAT and Circuit SAT • CNF SAT • 3SAT • 3SAT-4 • Monotone 3SAT • Polynomial-time variants\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    03 Apr, 2023\n            \n        \n                    \n            \n                05 Apr, 2023\n            \n            \n                Lower Bounds\n                Schaefer's Dichotomy Theorem • 2-colorable perfect matching\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    05 Apr, 2023\n            \n        \n                    \n            \n                10 Apr, 2023\n            \n            \n                Lower Bounds\n                Parameterized Intractability • The W-hierarchy • Reductions from CLIQUE\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    10 Apr, 2023\n            \n        \n                    \n            \n                12 Apr, 2023\n            \n            \n                Lower Bounds\n                Kernel Lower Bounds • Composition and Distillation • Examples of compositions • Parameter preserving transformations\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    12 Apr, 2023\n            \n        \n                    \n            \n                17 Apr, 2023\n            \n            \n                Lower Bounds\n                The (Strong) Exponential Time Hypothesis • Sparsification Lemma • Implications for parameterized algorithms\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    17 Apr, 2023\n            \n        \n                    \n            \n                19 Apr, 2023\n            \n            \n                Lower Bounds\n                Reductions based on the ETH\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    19 Apr, 2023\n            \n        \n                    \n            \n                24 Apr, 2023\n            \n            \n                Lower Bounds\n                Inapproximability Introduction • NP optimization problems • PTAS, APX • Stronger notions of reductions that preserve approximability • APX-hardness of vertex cover\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    24 Apr, 2023\n            \n        \n                    \n            \n                26 Apr, 2023\n            \n            \n                Lower Bounds\n                Gap Inapproximability • Gap Problems • Gap-producing and gap-preserving reductions • PCP theorem • Unique Games Conjecture\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    26 Apr, 2023\n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                TBA\n            \n            \n                Exam 1\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n                    \n            \n                TBA\n            \n            \n                Exam 2\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n                    \n            \n                TBA\n            \n            \n                Exam 3\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n\n\n\nNo matching items"
  },
  {
    "objectID": "courses/2023/02-AA/exams/E02.html",
    "href": "courses/2023/02-AA/exams/E02.html",
    "title": "CS614. Advanced Algorithms. Exam 2.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\nArturo I. Merino, Torsten Mütze, Aaron Williams: All Your bases Are Belong to Us: Listing All Bases of a Matroid by Greedy Exchanges. FUN 2022: 22:1-22:28 [PDF]\nDaniel Lokshtanov, Bernardo Subercaseaux: Wordle Is NP-Hard. FUN 2022: 19:1-19:8 [PDF]\nChristoph Brause, Ingo Schiermeyer: Kernelization of the 3-path vertex cover problem. Discret. Math. 339(7): 1935-1939 (2016) [PDF]\nRémy Belmonte, Tesshu Hanaka, Ioannis Katsikarelis, Michael Lampis, Hirotaka Ono, Yota Otachi: Parameterized Complexity of Safe Set. J. Graph Algorithms Appl. 24(3): 215-245 (2020) [PDF]\n\n\n\n\n\n\n\nNote for Paper #4\n\n\n\n\n\nFocus on Sections 5 and 7 for the presentation.\n\n\n\n\nRadovan Cervený, Ondrej Suchý: Faster FPT Algorithm for 5-Path Vertex Cover. MFCS 2019: 32:1-32:13 [PDF]\n\n\n\n\n\n\n\nNote for Paper #5\n\n\n\n\n\nSince there are several cases to the branching algorithm, there is no need to comprehensively cover them in the presentation\n\n\n\n\nFedor V. Fomin, Torstein J. F. Strømme: Vertex Cover Structural Parameterization Revisited. WG 2016: 171-182 [PDF]\n\n\n\n\n\n\n\nNote for Paper #6\n\n\n\n\n\nFocus on Section 3 for the presentation.\n\n\n\n\nA Note on Max k-Vertex Cover: Faster FPT-AS, Smaller Approximate Kernel and Improved Approximation. SOSA 2019: 15:1-15:21 [PDF]\n\n\n\n\n\n\n\nNote for Paper #7\n\n\n\n\n\nChoose an appropriate subset of results to present.\n\n\n\n\nDan Hefetz, Orna Kupferman, Amir Lellouche, Gal Vardi: Spanning-Tree Games. MFCS 2018: 35:1-35:16 [PDF]\nMichael Lampis, Valia Mitsou: The Computational Complexity of the Game of Set and Its Theoretical Applications. LATIN 2014: 24-34 [PDF]\n\n\n\n\n\n\n\nNote for Paper #7\n\n\n\n\n\nFocus on the NP-completeness and FPT results here.\n\n\n\n\nJulián Mestre: A Primal-Dual Approximation Algorithm for Partial Vertex Cover: Making Educated Guesses. APPROX-RANDOM 2005: 182-191 [PDF]"
  },
  {
    "objectID": "courses/2023/02-AA/exams/E01.html",
    "href": "courses/2023/02-AA/exams/E01.html",
    "title": "CS614. Advanced Algorithms. Exam 1.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nRemarks\n\n\n\nProblem indices on Gradescope for Problem 1 are off-by-one. Add one to the index here to match to Gradescope.\nErrata based on feedback from the class (thanks!) — these changes have been made in the questions below:\n\nQ5: it should have been v \\in S and not v \\in G.\nQ1.4: assume that the cycles C and D are edge-disjoint.\nQ1.6: the last return statement is G and not G-v (the vertex v is moved to F, not removed from the graph).\n\n\n\n\n\n\n\n\n\nProblem 1. The Constrained Cycle Hitting Set (CCHS) Problem.\n\n\n\n\n\n\n\n\n\nMarks Distribution.\n\n\n\nThis problem is worth 20 points overall. All subproblems carry two points each except 1.9 (which is zero marks).\n\n\nLet G = (V,E) be a simple and undirected graph. Let F \\subseteq V be a subset of vertices that we will call a forbidden subset. An instance of CCHS is given by (G,F,k), where k \\in \\mathbb{Z}^+ is a budget. Such an instance is a YES-instance if there exists a subset of S \\subseteq V \\setminus F such that:\n\n|S| \\leqslant k, and\nG \\setminus S is a forest, i.e, there are no cycles.\n\nSuch a subset is called a constrained cycle hitting set with respect to F. In this question, we will develop a c^k algorithm for solving a CCHS instance, combining reduction and branching rules in a spirit somewhat similar to what we have done for Vertex Cover in class.\nOur goal will be to return a solution, i.e, a subset of vertices that is a constrained cycle hitting set with respect to F. In particular, an informal overview of our approach, detailed further in the questions below, is the following:\n\nWe will eliminate low-degree (vertices of degree at most one) vertices, and branch on high-degree vertices.\nFor the base case, we will find ourselves “stuck” when the graph only has vertices of degree at most two, but this can be handled in polynomial time.\n\nOur algorithm will be denoted solve-CCHS(G,F,k). We begin the following straightforward rules:\n\nIf k < 0, return NO.\nIf V(G) = \\emptyset, return \\emptyset.\n\n\n\n\n\n\n\nProblem 1.0 No Hope Rule\n\n\n\n\n\nSuppose G[F] has a cycle C. Note that all vertices of C belong to F. Then return:\n\nNO\nsolve-CCHS(G-v,F-v,k-1) where v is a maximum degree vertex from C.\nsolve-CCHS(G-v,F-v,k-1) where v is a minimum degree vertex from C.\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.1 Low Degree Rule.\n\n\n\n\n\nIf a vertex v has degree zero or one, then return:\n\nsolve-CCHS(G-v,F-v,k).\nsolve-CCHS(G-v,F-v,k-1).\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Forced Vertex Rule.\n\n\n\n\n\nIf a vertex v \\in G \\setminus F has two neighbors in a single connected component of G[F], then return:\n\nsolve-CCHS(G-v,F,k).\nsolve-CCHS(G-v,F,k-1).\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.3 High Degree Vertex Has Low Degree - Structure I\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nLet C be a cycle in G. Which of the following scenarios are not feasible?\n\nC \\cap F \\neq \\emptyset and C \\cap (V \\setminus F) \\neq \\emptyset\nC \\cap F = \\emptyset and C \\cap (V \\setminus F) \\neq \\emptyset\nC \\cap F \\neq \\emptyset and C \\cap (V \\setminus F) = \\emptyset\n\nPick the correct option and justify your answer briefly.\n\n\n\n\n\n\n\n\n\nProblem 1.4 High Degree Vertex Has Low Degree - Structure II\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nLet C and D be two edge-disjoint cycles in G. Which of the following scenarios are not feasible?\n\nC \\cap D \\neq \\emptyset\n(C \\cap F) \\cap (D \\cap F) \\neq \\emptyset\n(C \\cap (V\\setminus F)) \\cap (D \\cap (V \\setminus F)) \\neq \\emptyset\n\nPick the correct option and justify your answer briefly.\n\n\n\n\n\n\n\n\n\nProblem 1.5 High Degree Vertex Has Low Degree - Rule\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nConsider the following algorithm to solve this instance:\ninit X = emptyset\nwhile G\\X has a cycle C:\n    let v be a vertex in C\\F:\n        add v to X\nif |X| > k:\n    return NO\nelse:\n    return X\nWhat can you say about the procedure above?\n\nIt correctly solves the kind of CCHS questions being considered in this problem.\nIt will not be correct if there are no vertices in C\\setminus F, as required in line 3.\nIt will not be correct if there are two overlapping cycles in the instance.\n\nPick the correct option and justify your answer briefly. If you believe this is not the right algorithm, please suggest an alternative that works. In further questions when we refer to the rule in problem 1.5, we are referring to either the algorithm above or the one in your justification.\n\n\n\n\n\n\n\n\n\nProblem 1.6 The Branching Step\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1, 1.2, and 1.5 do not apply. Let v be a vertex in G \\setminus F of maximum degree. Now we branch as follows:\nOption A.\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F U {v},k) // omit v\nOption B.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F U {v},k-1) // omit v\nOption C.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X\notherwise:\n    return solve-CCHS(G,F U {v},k) // omit v\nOption D.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F,k) // omit v\nPick the right branching strategy and justify your answer.\n\n\n\nWe summarize the overall algorithm below.\nIf k < 0, return NO.\nIf V(G) is empty, return the empty set.\n\nApply rules 1.0, 1.1, and 1.2.\n\nPick a vertex v in G\\F of maximum degree.\n\nIf d(v) = 2, apply rule 1.5.\nOtherwise branch according to 1.6.\nIn the next few questions, we will analyze the running time of this algorithm. Assume that the algorithm is called with F = \\emptyset, i.e, there are no forbidden vertices to begin with. Fix an execution path P in the branching tree1 of the algorithm that does not return NO. Now:\n\nWe use S(P) to denote the output: note that this would consist of the set of vertices that are removed from the instance for inclusion in the solution, i.e, vertices chosen by the first branch in Step 1.6.\nWe use F(P) to denote the set of vertices that are made forbidden along the path P, i.e, these are vertices chosen by the second branch in Step 1.6.\n\nNote that at the output node, the instance we have is (G,F(P),\\ell) for some \\ell \\leqslant k, where S(P) is a constrained cycle hitting set with respect to F(P) of size at most k - \\ell. Also the number of steps in the execution path P is given by |F(P)| + |S(P)|, since every time we branch, we either include a vertex in the solution or make it forbidden.\n\n\n\n\n\n\nProblem 1.7 Degree 3 vs Leaves in Trees\n\n\n\n\n\nLet T be a tree and let X be the set of leaves in T, and let Y be the set of vertices of degree three or more in T. Show that:\n\\sum_{v \\in Y} (d(v)-2) = |X| - 2,\nusing elementary facts about trees.\n\n\n\n\n\n\n\n\n\nProblem 1.8 Degree Evolution\n\n\n\n\n\nFix an execution path P on an instance (G,\\emptyset,k) (i.e, a path from root to leaf in the branching tree associated with the algorithm when the input is (G,\\emptyset,k)) and consider a vertex v that belongs to F(P), which is to say that the vertex v was included in the set of forbidden vertices at some point during the execution of the algorithm. Denote the instance at this stage of the algorithm by (H,F,k^\\prime). In particular, H is the graph obtained after v was included in F. Let d(v) denote the degree of the vertex v in the original instance G, and let d^\\star(v) denote its degree in the graph H. Which of the following is true?\n\n3 \\leqslant d^\\star(v) \\leqslant d(v)\n3 \\leqslant d^\\star(v) < d(v)\nd^\\star(v) \\geqslant \\min(d(v),3)\nd^\\star(v) > \\min(d(v),3)\n\n\n\n\n\n\n\n\n\n\nProblem 1.9 Successful Execution Paths are Short\n\n\n\n\n\nConsider an execution path P that does not return NO. Show that F(P) \\leqslant 3S(P).\nThis is an optional question that you can skip. It carries no points.\n\n\n\n\n\n\n\n\n\nProblem 1.10 The Final Running Time\n\n\n\n\n\nCan you use the fact from the previous question to come up with an algorithm for CCHS that runs in time O^\\star(16^k)? Note that the O^\\star(\\cdot) notation is used to hide factors that are polynomial in n and k.\nHint: Use the algorithm described previously in the question, but modify it slightly. In particular, if an execution path pushes more than 3S(P) vertices into the forbidden set F, can you terminate it prematurely? Also, what is the cost of the successful execution paths?\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. GreedyHS [2 points]\n\n\n\nLet U=\\left\\{x_1, \\ldots, x_n\\right\\} be an univere of n elements. Suppose we have a family \\mathcal{F} over U that consists of three-sized subsets of U, for example:\n\n\\mathcal{F} = \\left(x_1, x_3, x_4\\right),\\left(x_2, x_3, x_7\\right),\\left(x_1, x_5, x_6\\right)\n\nWe want to find a smallest subset X of U such that for all sets S \\in \\mathcal{F}, S \\cap X \\neq \\emptyset.\nConsider the following algorithm for this problem.\nGreedy(U,F)\n\nInit X = emptyset\nwhile F is non-empty do:\n    Take an arbitrary set S in F.\n    Let x be an element in S\n    X = X U {x}\n    Remove all sets from F that contain x\nend while\nWhat can you say about the worst-case approximation ratio of this algorithm?\n\n\n\n\n\n\n\n\nProblem 3. Knapsack [2 points]\n\n\n\nConsider the knapsack problem. Given a set X=\\left\\{x_1, \\ldots, x_n\\right\\} of n items with weights w\\left(x_i\\right) and values v\\left(x_i\\right), it asks for the highest total value of items we can put into our knapsack such that the total weight of all these items is at most W.\nDescribe a 0/1-LP that models the problem correctly.\n\n\n\n\n\n\n\n\nProblem 4. Rectangle Covering [4 Points]\n\n\n\n\n\n\nRectangle Cover Problem Example\n\n\nSuppose we have a set P=\\left\\{p_1, \\ldots, p_n\\right\\} of n points and a set R=\\left\\{r_1 \\ldots, r_m\\right\\} of m rectangles, as in the image above. Each rectangle r_i \\in R has a certain cost c_i>0 associated with it. We wish to find a subset S \\subseteq R of rectangles whose cost is minimized such that the rectangles in S together cover all points in P.\nWe wish to model this problem as a 0/1-LP. To this end we introduce a decision variable x_i for each rectangle r_i \\in R, where x_i=1 corresponds to putting rectangle r_i into S and x_i=0 corresponds to not putting r_i into S. otherwise. Furthermore, for a point p_j \\in P, define R\\left(p_j\\right)=\\left\\{r_i \\in R: p_j \\in r_i\\right\\}.\n\n\n\n\n\n\nLP for Rectangle Cover\n\n\n\n\n\nDescribe a 0/1-LP that models the problem correctly.\n\n\n\n\n\n\n\n\n\nLP-based Approximation for Rectangle Cover\n\n\n\n\n\nDescribe a 5-approximation assuming that each point is contained in at most 5 rectangles.\n\n\n\n\n\n\n\n\n\n\n\nProblem 5. Dominating Set Reduction Rule When The Graph has No Short Cycles [2 points]\n\n\n\nSuppose G is a simple, undirected graph that has no cycles of length three or four. Recall that a subset S of vertices of G is called a dominating set if every vertex v of G either belongs to S or has a neighbor in S, in other words, N[v] \\cap S \\neq \\emptyset.\nLet S be a dominating set of G of size at most k, where G is as given above (i.e, G has no triangles and no cycles of length four). Show that if the degree of v is more than k in G, then v \\in S."
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/L14.html",
    "href": "courses/2023/02-AA/quizzes/L14.html",
    "title": "CS614. Advanced Algorithms. L14 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 2. High-Degree Branching for FVS\n\n\n\nApply the same preprocessing steps as in the previous problem.\nLet \\left(v_1, v_2, \\ldots, v_n\\right) be a descending ordering of V(G) according to vertex degrees, i.e., d\\left(v_1\\right) \\geq d\\left(v_2\\right) \\geq \\ldots \\geq d\\left(v_n\\right). Let V_{3 k}=\\left\\{v_1, \\ldots, v_{3 k}\\right\\}.\nRecall that the minimum vertex degree of G is at least 3. Show that every feedback vertex set in G of size at most k contains at least one vertex of V_{3 k}."
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/L02.html",
    "href": "courses/2023/02-AA/quizzes/L02.html",
    "title": "CS614. Advanced Algorithms. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer."
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/L03.html",
    "href": "courses/2023/02-AA/quizzes/L03.html",
    "title": "CS614. Advanced Algorithms. L03 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Partition Matroid\n\n\n\nShow that the exchange axiom holds for the Partition Matroid defined in class.\n\n\n\n\n\n\n\n\nProblem 2. Representing the Graphic Matroid\n\n\n\nThe graphic matroid of a graph G can be represented by the following matrix: we have one row for each vertex, and one column for each edge. The column for edge e has +1 in the row for one endpoint, -1 in the row for the other endpoint, and 0 elsewhere; the choice of which endpoint to give which sign is arbitrary.\nArgue that this is a valid representation (i.e, that the forests correspond to linearly independent columns and the subsets of edges that have cycles in them correspond to dependent columns)."
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/L07.html",
    "href": "courses/2023/02-AA/quizzes/L07.html",
    "title": "CS614. Advanced Algorithms. L07 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the textbook on Parameterized Algorithms by Marek Cygan, Fedor V. Fomin, Łukasz Kowalik, Daniel Lokshtanov, Dániel Marx, Marcin Pilipczuk, Michał Pilipczuk, and Saket Saurabh.\n\n\n\n\n\n\n\n\nProblem 1. Cluster Vertex Deletion\n\n\n\nIn the Cluster Vertex Deletion problem, we want to know if a simple undirected graph G has a subset S of at most k vertices such that G \\setminus S is a disjoint union of cliques.\n\n\n\n\n\n\nProblem 1.1 A Branching Algorithm\n\n\n\nDesign a 3^k \\cdot n^{\\mathcal{O}(1)} algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nDesign a 3-approximation algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\n\n\nProblem 2. Don’t Satisfy Too Much!\n\n\n\nIn the MIN-2-SAT problem, we are given a 2 -CNF formula \\phi and an integer k, and the objective is to decide whether there exists an assignment for \\phi that satisfies at most k clauses.\nShow that MIN-2-SAT can be solved in time 2^k n^{\\mathcal{O}(1)}."
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/L13.html",
    "href": "courses/2023/02-AA/quizzes/L13.html",
    "title": "CS614. Advanced Algorithms. L13 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. FVS: is this FPT?\n\n\n\nRecall the following branching algorithm for Feedback Vertex Set (FVS) discussed in class:\n\nPreprocess to eliminate vertices of degree at most two, resulting in an equivlaent multigraph.\nPreprocess to force vertices with self-loops in the solution and adjust the budget as appropriate.\nIf a pair of vertices have more than two edges between them, delete all but two of these edges.\nSTOP if the graph is a forest or if we are out of budget.\nFind a shortest cycle and branch on all its vertices.\n\nSince a graph of minimum degree three that is not acyclic always has a cycle of length O(\\lg n), this algorithm has a running time of O^\\star((\\lg n)^k). Argue that this running time in fact shows that FVS is FPT in k."
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/L12.html",
    "href": "courses/2023/02-AA/quizzes/L12.html",
    "title": "CS614. Advanced Algorithms. L12 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. List Coloring\n\n\n\nIn the List Coloring problem, we are given a graph G and for each vertex v \\in V(G) there is a set (also called a list) of admissible colors L(v) \\subseteq N. The goal is to verify whether it is possible to find a proper vertex coloring c: V(G) \\rightarrow \\mathbb{N} of G such that for ever y vertex v we have c(v) \\in L(v). In other words, L(v) is the set of colors allowed for v.\nShow a 2^n n^{\\mathcal{O}(1)}-time algorithm for List Coloring.\nHint. Read Theorem 10.8 from the Parameterized Algorithms text.\n\n\n\n\n\n\n\n\nProblem 2. Triangle Packing\n\n\n\nIn the Triangle Packing problem, we are given an undirected graph G and a positive integer k, and the objective is to test whether G has k-vertex disjoint triangles. Using color coding show that the problem admits an algorithm with running time 2^{O(k)} n^{O(1)}."
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/L06.html",
    "href": "courses/2023/02-AA/quizzes/L06.html",
    "title": "CS614. Advanced Algorithms. L06 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the Coursera course on Approximation Algorithms taught by Mark de Berg.\n\n\n\n\n\n\n\n\nProblem 1. Changing the threshold\n\n\n\nConsider the algorithm LPAPX-WVC from the class.\n\n\n\n\n\n\nProblem 1.1 Increasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 2/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 1/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. Changing the rounding scheme\n\n\n\nConsider a different rounding strategy for the LP relaxation of the vertex cover problem. Instead of rounding up every vertex whose value is at least 0.5 after running the LP, we do the following:\nWe look at every edge, and then we round up the variable of the endpoint with the highest value, where in case of ties we take the endpoint with the highest index.\nIn other words, if the vertex set is V=\\left\\{v_1, \\ldots, v_n\\right\\} and we denote the associated variable of v_i by x_i then the cover C is computed as follows:\nC:=\\left\\{v_i \\in V:\\right. there is an edge \\left(v_i, v_j\\right) such that \\left(x_i>x_j\\right) or \\left(x_i=x_j\\right. and \\left.\\left.i>j\\right)\\right\\}\nWhich statement is true?\n\nThis does not work, because we might report an invalid solution.\nThis gives a valid solution, but the approximation ratio becomes worse.\nThis gives a valid solution, and in fact the solution is always exactly the same as in the original rounding scheme.\nThis gives a valid solution. We sometimes report a better solution than in the original rounding scheme, but the approximation ratio of the algorithm is still more than 2 - \\epsilon for any \\epsilon > 0.\nThis gives a valid solution, and the approximation ratio of the algorithm becomes 3/2.\n\n\n\n\n\n\n\n\n\nProblem 3. Lower Bound\n\n\n\nSuppose you have created an algorithm for a certain problem using LP relaxation and you want to say something about its approximation ratio. Which lower bound on the optimal solution can you use?\n\nThe solution to the 0/1-LP.\nThe solution to the relaxed LP.\nDepends on the problem.\n\n\n\n\n\n\n\n\n\nProblem 4. Integrality Gap\n\n\n\nWhat is the integrality gap of the vertex-cover LP for the complete graph on n vertices, where all vertices have weight 1?"
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/L10.html",
    "href": "courses/2023/02-AA/quizzes/L10.html",
    "title": "CS614. Advanced Algorithms. L10 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Set Cover: The Greedy Bound is Tight\n\n\n\nWe argued in class that the greedy approach to solving the unweighted Set Cover problem achieves an approximation ratio of O(H_n). Argue that this bound is tight, i.e, come up with examples where the algorithm picks sets in a manner that the cost of the solution is roughly H_n worse than optimal.\n\n\n\n\n\n\n\n\nProblem 2. Set Cover and Related Problems\n\n\n\n\nShow that Vertex Cover is a special case of Set Cover.\nAlso show that Dominating Set and Set Cover are equivalent (i.e, Set Cover can be reduced to Dominating Set and vice versa)."
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/L04.html",
    "href": "courses/2023/02-AA/quizzes/L04.html",
    "title": "CS614. Advanced Algorithms. L04 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Matroid Intersection Example\n\n\n\nConsider a directed graph D=(V, E \\subseteq V \\times V). A set T \\subseteq E is an arborescence (oriented forest) if:\n\nT does not contain a cycle (ignoring directions of edges).\nEvery vertex in V has at most one incoming edge.\n\nAn arborescence T with |T|=n-1 will have one incoming edge incident on each node except one. If we denote this special node as root, this is an oriented spanning tree as shown in the figure.\n\n\n\nAn example arborescence.\n\n\nConsider the underlying undirected graph G_D = (V,E) associated with D (this is the graph obtained by “erasing the arrows” in D). Consider the universe given by E. Suggest two matroids {\\mathcal M}_1 and {\\mathcal M}_2 for which set of arborescences is given by the sets independent in both {\\mathcal M}_1 and {\\mathcal M}_2.\nHint: these are both matroids seen in class. Further, you might find it useful to partition E into |V| many parts as follows — the part P_v contains all edges that are incoming arcs for the vertex v in D. Can you define a matroid based on this partition?\nDescribe {\\mathcal M}_1 and {\\mathcal M}_2.\n\n\n\n\n\n\n\n\nProblem 2. Maker-Breaker Game\n\n\n\nTwo players take turns removing edges from an undirected graph until there are no edges left.\nPlayer 2 wins if the edges they remove contains a spanning tree, player 1 wins if the set of edges they remove would disconnect the original graph.\n\nIs it true that exactly one player wins this game? In other words, is the following statement true?\n\n“It is NOT the case that after the game has been played, both players can claim a win.”\n\nYes\nNo\n\n\nWhich player wins on a path?\n\n\nPlayer 1\nPlayer 2\n\n\nWhich player wins on a complete graph?\n\n\nPlayer 1\nPlayer 2\n\n\nComplete this sentence: player 2 has the winning strategy if and only if the graph contains BLANK.\n\n(No marks for answering this question, take your best guess :) )"
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/L05.html",
    "href": "courses/2023/02-AA/quizzes/L05.html",
    "title": "CS614. Advanced Algorithms. L05 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Approximate Vertex Cover\n\n\n\nGive an example of a graph where the 2-approximate solution (via maximal matchings) is worse than the optimal one. Even just slightly worse is enough :)\n\n\n\n\n\n\n\n\nProblem 2. Approximate Independent Set\n\n\n\nSince the complement of a vertex cover is an independent set, you might be tempted to think that the approximation discussed in class also approximates independent set. In particular, consider the following algorithm for independent set:\n\nRun the 2-approximation for vertex cover discussed in class, let the output be S.\nLet I := V(G) \\setminus S.\nIf I = \\emptyset, then let v \\in V(G) be an arbitrary vertex; set I := \\{v\\}.\n\nLet:\n\np denote the size of a largest independent set in G\nq denote the size of the set obtained by taking the complement of the output of the 2-approximation discussed in class.\nr denote \\max(q,1)\n\nNote that r is the size of the independent set output by the algorithm above.\nCome up with a graph where p can be a factor of cn larger than r for some constant c.\n\n\n\n\n\n\n\n\nProblem 3. Vertex Cover Matroid\n\n\n\nDo the set of vertex covers in a graph G form a matroid over the universe V(G)? If not, select the axiom that fails:\n\nExchange Axiom\nHereditary Axiom\nVertex covers do form a matroid"
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/A06.html",
    "href": "courses/2023/02-AA/quizzes/A06.html",
    "title": "CS614. Advanced Algorithms. L06 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the Coursera course on Approximation Algorithms taught by Mark de Berg.\n\n\n\n\n\n\n\n\nProblem 1. Changing the threshold\n\n\n\nConsider the algorithm LPAPX-WVC from the class.\n\n\n\n\n\n\nProblem 1.1 Increasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 2/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 1/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf we increase the threshold t beyond 0.5, then the output may not even be a vertex cover: for example, consider the example of a complete graph where the LPOPT sets all variables to 0.5: in this case our output will be the empty set with any threshold higher than 0.5.\nIf we decrease the threshold t below 0.5, then the output will be a vertex cover — indeed, if any edge (u,v) is uncovered, then both u and v were set to values less than t, and in particular less than 0.5, so we will violate our edge constraint just as we do when working with a threshold of 0.5. However, by choosing a lower value, we worsen the approximation ratio: in particular, if t = 1/3 then the output is a 3-approximation.\n\n\n\n\n\n\n\n\n\nProblem 2. Changing the rounding scheme\n\n\n\nConsider a different rounding strategy for the LP relaxation of the vertex cover problem. Instead of rounding up every vertex whose value is at least 0.5 after running the LP, we do the following:\nWe look at every edge, and then we round up the variable of the endpoint with the highest value, where in case of ties we take the endpoint with the highest index.\nIn other words, if the vertex set is V=\\left\\{v_1, \\ldots, v_n\\right\\} and we denote the associated variable of v_i by x_i then the cover C is computed as follows:\nC:=\\left\\{v_i \\in V:\\right. there is an edge \\left(v_i, v_j\\right) such that \\left(x_i>x_j\\right) or \\left(x_i=x_j\\right. and \\left.\\left.i>j\\right)\\right\\}\nWhich statement is true?\n\nThis does not work, because we might report an invalid solution.\nThis gives a valid solution, but the approximation ratio becomes worse.\nThis gives a valid solution, and in fact the solution is always exactly the same as in the original rounding scheme.\nThis gives a valid solution. We sometimes report a better solution than in the original rounding scheme, but the approximation ratio of the algorithm is still more than 2 - \\epsilon for any \\epsilon > 0.\nThis gives a valid solution, and the approximation ratio of the algorithm becomes 3/2.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe solution is valid: indeed, let (u,v) be an edge, and recall that the algorithm worked as follows:\nWe look at every edge, \nand then we round up the variable of the endpoint with the highest value, \nwhere in case of ties we take the endpoint with the highest index. \nSince one of the endpoints was rounded up, the edge is covered; and this is evidently true of every edge.\nThe solution with respect to this rounding may be better than the threshold-based rounding: for example, consider again a complete graph where the LPOPT sets all variables to 1/2: the threshold-based rounding leads to a solution of cost n, while the cost here will be strictly less.\nHowever, to see that the approximation ratio of the algorithm is still more than 2 - \\epsilon for any \\epsilon > 0, consider, for example, a cycle on n vertices: one can choose a suitably large value of n to bring the approximation ratio arbitrarily close to 2.\n\n\n\n\n\n\n\n\n\nProblem 3. Lower Bound\n\n\n\nSuppose you have created an algorithm for a certain problem using LP relaxation and you want to say something about its approximation ratio. Which lower bound on the optimal solution can you use?\n\nThe solution to the 0/1-LP.\nThe solution to the relaxed LP.\nDepends on the problem.\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n\nAs was clarified in class, this question is in the context of minimization problems.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe solution to the relaxed LP is a useful lower bound for the OPT. The value of the OPT for the 0/1-LP is exactly equal to the OPT (in a presumed exact formulation of the problem) and does not, by itself, provide information about the behavior of the relaxed LP.\n\n\n\n\n\n\n\n\n\nProblem 4. Integrality Gap\n\n\n\nWhat is the integrality gap of the vertex-cover LP for the complete graph on n vertices, where all vertices have weight 1?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nILPOPT = n-1 and LPOPT = n/2; so the integrality gap is 2 \\cdot (n-1)/n = 2(1 - \\frac{1}{n})."
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/A07.html",
    "href": "courses/2023/02-AA/quizzes/A07.html",
    "title": "CS614. Advanced Algorithms. L07 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the textbook on Parameterized Algorithms by Marek Cygan, Fedor V. Fomin, Łukasz Kowalik, Daniel Lokshtanov, Dániel Marx, Marcin Pilipczuk, Michał Pilipczuk, and Saket Saurabh.\n\n\n\n\n\n\n\n\nProblem 1. Cluster Vertex Deletion\n\n\n\nIn the Cluster Vertex Deletion problem, we want to know if a simple undirected graph G has a subset S of at most k vertices such that G \\setminus S is a disjoint union of cliques.\n\n\n\n\n\n\nProblem 1.1 A Branching Algorithm\n\n\n\nDesign a 3^k \\cdot n^{\\mathcal{O}(1)} algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nDesign a 3-approximation algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAs discussed in class, the induced path on three vertices is a forbidden substructure for a cluster graph. We state and prove this fact here for completeness.\n\nClaim. A graph G is a disjoint union of cliques if and only if it does not contain a path on three vertices as an induced subgraph.\nProof (sketch). Suppose G is a disjoint union of cliques, and for the sake of contradiction, suppose it has an induced path on vertices x,y,z with the edges being between x and y, and y and z. Note that since this is an induced path, there is no edge between x and z. Since every component of G is a clique, we know that x and z must be in different components. However, there is a path from x to z via y, which is a contradiction.\nSuppose G does not contain a path on three vertices as an induced subgraph. Again, for the sake of contradiction, suppose G has a connected component that is not a clique. Let (u,v) be a non-edge in this component. Let P be a shortest path between u and v consisting of the vertices:\nP := \\{u, w_1, \\ldots, w_t, \\ldots v\\}.\nNotice that t \\geqslant 1, otherwise (u,v) is an edge. Further, notice that u, w_1, w_2 forms an induced path of length three1 (if (u,w_2) was an edge then we have a shorter path by omitting w_1, contradicting our assumption that P is a shortest path between u and v). This contradicts our assumption.\n\nBased on this, we have the following algorithm:\nCVD(G,k):\n    If k <= 0 and G has an induced P3 - RETURN NO\n    If k >= 0 and G is a cluster graph - RETURN YES\n\n    Let a,b,c be vertices such that ab and bc are edges and ac is not an edge.\n\n    Return (CVD(G-a,k-1) OR CVD(G-b,k-1) OR (G-c,k-1))\nOne can obtain a 3-approximation by enumerating a maximal collection of disjoint induced P_3’s and including all vertices from the collection in the solution. If the collection has size t, we know that any solution (and in particular, the optimal one) must contain at least t vertices and the output has at most 3t vertices. The algorithm is summarized below:\nCVD-3-Approx(G):\n    Init S = emptyset\n\n    While there is an induced P3 = (x,y,z) in G:\n        include (x,y,z) in S\n        G = G - (x,y,z)\n\n    return S\n\n\n\n\n\n\n\n\n\nProblem 2. Don’t Satisfy Too Much!\n\n\n\nIn the MIN-2-SAT problem, we are given a 2-CNF formula \\phi and an integer k, and the objective is to decide whether there exists an assignment for \\phi that satisfies at most k clauses.\nShow that MIN-2-SAT can be solved in time 2^k n^{\\mathcal{O}(1)}.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf there is a variable x that occurs only positively in \\phi, we claim that there exists an optimal assignment that sets it to 0. Indeed, let \\tau be an assignment that sets x to 1. Let \\tau_x be the assignment obtained from \\tau by flipping the value of x from 1 to 0. Note that the clauses that do not contain the variable x are either satisfied or falsified in both \\tau and \\tau_x. For clauses that contain x, it is possible that they are satisfied by \\tau but not by \\tau_x, but not vice versa. Therefore, \\tau_x falsifies at least as many clauses as \\tau, and we are done.\nBased on this, our algorithm proceeds as follows:\nif there is a variable x that occurs only as a positive literal:\n    set x to 0\nif there is a variable x that occurs only as a negated literal:\n    set x to 1\nThe argument for the negated occurrences is symmetric to the one we have for positive literals.\nOnce we perform this preprocessing, assuming that have clauses remaining, we have the following guarantee:\n\nEvery variable has at least one positive and one negated occurrence.\n\nNow we can branch exhuastively on the settings of variables; with the promise that either setting of the variable reduces our budget by at least one. The overall algorithm is summarized in the following pseudocode:\nMINSAT(phi,k):\n    if there is a variable x that occurs only as a positive literal:\n        set x to 0\n    if there is a variable x that occurs only as a negated literal:\n        set x to 1\n\n    if phi is empty:\n        return YES\n    if phi is not empty and k <= 0:\n        return NO\n\n    Let x be any variable that occurs in phi.\n    return MINSAT(phi|[x = TRUE],k-1) OR MINSAT(phi|[x = FALSE],k-1)"
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/A05.html",
    "href": "courses/2023/02-AA/quizzes/A05.html",
    "title": "CS614. Advanced Algorithms. L05 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Approximate Vertex Cover\n\n\n\nGive an example of a graph where the 2-approximate solution (via maximal matchings) is worse than the optimal one. Even just slightly worse is enough :)\n\n\n\n\n\n\n\n\nFollow up question\n\n\n\n\n\nWhat are examples of graphs where the 2-approximate solution via maximal matchings is close to optimal? The empty and complete graphs come to mind, are there others?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nEven if the input graph is an edge, a star, or a matching, the 2-approximate solution is already worse by a factor of two.\n\n\n\n\n\n\n\n\n\nProblem 2. Approximate Independent Set\n\n\n\nSince the complement of a vertex cover is an independent set, you might be tempted to think that the approximation discussed in class also approximates independent set. In particular, consider the following algorithm for independent set:\n\nRun the 2-approximation for vertex cover discussed in class, let the output be S.\nLet I := V(G) \\setminus S.\nIf I = \\emptyset, then let v \\in V(G) be an arbitrary vertex; set I := \\{v\\}.\n\nLet:\n\np denote the size of a largest independent set in G\nq denote the size of the set obtained by taking the complement of the output of the 2-approximation discussed in class.\nr denote \\max(q,1)\n\nNote that r is the size of the independent set output by the algorithm above.\nCome up with a graph where p can be a factor of cn larger than r for some constant c.\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n\nIt was not explicit in the question: G denotes the input graph and n denotes the number of vertices in G.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet n = 2p and consider a complete bipartite graph K_{p,p}. The optimal independent set has size p but the algorithm above returns 1.\n\n\n\n\n\n\n\n\n\nProblem 3. Vertex Cover Matroid\n\n\n\nDo the set of vertex covers in a graph G form a matroid over the universe V(G)? If not, select the axiom that fails:\n\nExchange Axiom\nHereditary Axiom\nVertex covers do form a matroid\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nA subset of a vertex cover need not be a vertex cover; and in particular, the empty set is also not a vertex cover (although this axiom was not offered as an option)."
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/A04.html",
    "href": "courses/2023/02-AA/quizzes/A04.html",
    "title": "CS614. Advanced Algorithms. L04 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Matroid Intersection Example\n\n\n\nConsider a directed graph D=(V, E \\subseteq V \\times V). A set T \\subseteq E is an arborescence (oriented forest) if:\n\nT does not contain a cycle (ignoring directions of edges).\nEvery vertex in V has at most one incoming edge.\n\nAn arborescence T with |T|=n-1 will have one incoming edge incident on each node except one. If we denote this special node as root, this is an oriented spanning tree as shown in the figure.\n\n\n\nAn example arborescence.\n\n\nConsider the underlying undirected graph G_D = (V,E) associated with D (this is the graph obtained by “erasing the arrows” in D). Consider the universe given by E. Suggest two matroids {\\mathcal M}_1 and {\\mathcal M}_2 for which set of arborescences is given by the sets independent in both {\\mathcal M}_1 and {\\mathcal M}_2.\nHint: these are both matroids seen in class. Further, you might find it useful to partition E into |V| many parts as follows — the part P_v contains all edges that are incoming arcs for the vertex v in D. Can you define a matroid based on this partition?\nDescribe {\\mathcal M}_1 and {\\mathcal M}_2.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTake {\\mathcal M}_1 to be the graphic matroid and {\\mathcal M}_2 to be the partition matroid with all budgets set to one. Membership in the first matroid ensures that there are no underlying undirected cycles and membership in the second matroid ensures that every vertex in V has at most one incoming edge.\n\n\n\n\n\n\n\n\n\nProblem 2. Maker-Breaker Game\n\n\n\nTwo players take turns removing edges from an undirected graph until there are no edges left.\nPlayer 2 wins if the edges they remove contains a spanning tree, player 1 wins if the set of edges they remove would disconnect the original graph.\n\nIs it true that exactly one player wins this game? In other words, is the following statement true?\n\n“It is NOT the case that after the game has been played, both players can claim a win.”\n\nYes\nNo\n\n\nWhich player wins on a path?\n\n\nPlayer 1\nPlayer 2\n\n\nWhich player wins on a complete graph?\n\n\nPlayer 1\nPlayer 2\n\n\nComplete this sentence: player 2 has the winning strategy if and only if the graph contains BLANK.\n\n(No marks for answering this question, take your best guess :) )\n\n\n\n\n\n\n\n\nHeads Up\n\n\n\nPart (3) was under-specified: the second player wins on complete graphs with at least four vertices but the first player has easy wins if the graph is an edge (a complete graph on two vertices) or a triangle (a complete graph on three vertices).\nGrading note: everyone recieves a full grade for this question.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSuppose both players indeed win. Let us delete the edges chosen by the first player. What is left is: (a) the set of edges chosen by the second player and (b) a disconnected graph. But the second player also won, so this set contains a spanning tree. A graph cannot simultaneously admit a spanning tree and be disconnected, this is a contradiction when applied on the graph induced by the leftover edges.\nPlayer 1 can choose any edge in the first step and he already wins.\nAssume that the graph has at least four vertices. Player 2 wins because notice that no matter how the first player plays the first (n-1) steps, it is not enough to disconnect the graph. By chosing edges carefully1, Player 2 can ensure that (s)he has booked a spanning tree already within the first (n-1) moves.\nNo spoilers on this one (yet)."
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/A03.html",
    "href": "courses/2023/02-AA/quizzes/A03.html",
    "title": "CS614. Advanced Algorithms. L03 Solutions.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Partition Matroid\n\n\n\nShow that the exchange axiom holds for the Partition Matroid defined in class.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet (U := U_1 \\cup \\cdots \\cup U_\\ell, \\mathcal{F}) be a partition matroid with budgets a_1,\\ldots,a_\\ell.\nSuppose S, T \\subseteq U_1 \\cup \\cdots \\cup U_\\ell such that S,T \\in \\mathcal{F}, and |T| > |S|.\nThen, there exists at least one part U_i where |T \\cap U_i| > |S \\cap U_i|. Now let x \\in (T \\setminus S) \\cap U_i. Note that S \\cup \\{x\\} \\in \\mathcal{F} since:\n\\begin{equation*}\n    |S \\cap U_j| =\n    \\begin{cases}\n      < a_j & \\text{if } j = i,\\\\\n      \\leqslant a_j & \\text{otherwise}.\n    \\end{cases}\n\\end{equation*}\nand therefore:\n\\begin{equation*}\n    |(S \\cup \\{x\\}) \\cap U_j| =\n    \\begin{cases}\n      |S \\cap U_i| + 1 \\leqslant a_j & \\text{if } j = i,\\\\\n      \\leqslant a_j & \\text{otherwise}.\n    \\end{cases}\n\\end{equation*}\n\n\n\n\n\n\n\n\n\nProblem 2. Representing the Graphic Matroid\n\n\n\nThe graphic matroid of a graph G can be represented by the following matrix: we have one row for each vertex, and one column for each edge. The column for edge e has +1 in the row for one endpoint, -1 in the row for the other endpoint, and 0 elsewhere; the choice of which endpoint to give which sign is arbitrary.\nArgue that this is a valid representation (i.e, that the forests correspond to linearly independent columns and the subsets of edges that have cycles in them correspond to dependent columns).\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSuppose we have a subset of edges that contains a cycle. For simplicity, suppose the cycle is given by:\n\\{pq, qr, rs, st\\}\nNow consider the column vectors c_p, c_q, c_r, c_s:\n\\begin{bmatrix}\nc_p & c_q & c_r & c_s\\\\\n1 & 0 & 0 & -1 \\\\\n-1 & 1 & 0 & 0 \\\\\n0 & -1 & -1 & 0 \\\\\n0 & 0 & 1 & 1\n\\end{bmatrix}\nNote that:\n1 \\cdot c_p + 1 \\cdot c_q + (-1) \\cdot c_r + 1 \\cdot c_s\nis a linear combination with constants (1,1,-1,1) that establish that these vectors are linearly dependent. In general, write down the columns in the order in which they appear on the cycle. If the first entry in the column is not +1, then multiply the column by -1 (except the last column, where we do the reverse: if the first entry is +1, then we multiply the column by -1). This way, we have a situation where every row contains exactly one +1 entry and one -1 entry, and the linear combination sums to 0.\nThis shows that dependent subsets of the matroid correspond to linearly dependent columns of M.\nTo see that independent subsets S \\subseteq E(G) correspond to linearly independent columns, consider the set of columns that correspond to S:\n\\{c_e ~|~ e \\in S\\    }\nSuppose, for the sake of contradiction, that there was some non-trivial linear combination of these columns that vanished, i.e, for non-empty subset T \\subseteq S, there exist constants \\{\\alpha_e\\}_{e \\in T} where:\n\\sum_{e \\in T} \\alpha_e c_e = 0\nBut now consider the subgraph consisting of the edges in T. Note that the minimum degree of T must be two (suppose u \\in T has degree one, and its unique neighbor is v: then consider the entry in the row corresponding to u in the column corresponding to the edge uv: this is non-zero and there is no cancelation possible in the sum above). However, a graph whose minimum degree is two cannot be acyclic, and this is a contradiction."
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/A02.html",
    "href": "courses/2023/02-AA/quizzes/A02.html",
    "title": "CS614. Advanced Algorithms. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe circuits of the graphic matroid are the cycles of the graph G.\n\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c,d\\} with the edges \\{ab, cd, ad\\}.\nThere are two matchings in this instance:\n\nM_1 := \\{ab,cd\\}\nM_2: \\{ad\\}\n\nHowever, although |M_1| > |M_2|, neither of the edges from M_1 can be added to M_2.\n\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c\\} with the edges \\{ab, ac\\}. There are two independent sets: S_1 := \\{b,c\\} and M_2: \\{a\\}, but neither of the vertices from S_1 can be added to S_2.\n\nIf the independent sets formed a matroid the problem of finding a maximum independent set would not be NP-complete. \n— Comment in class"
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/L08.html",
    "href": "courses/2023/02-AA/quizzes/L08.html",
    "title": "CS614. Advanced Algorithms. L08 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Better Approximation given a k-coloring\n\n\n\nGiven a k-coloring of a graph G, show that we can find a vertex cover which is a 2\\bigl(1−\\frac{1}{k}\\bigr) approximation.\nHint: use the k-coloring on the vertices of V_{1/2}.\n\n\n\n\n\n\n\n\nProblem 2. Point Line Cover\n\n\n\nIn the Point Line Cover problem, we are given a set of n points in the plane and an integer k, and the goal is to check if there exists a set of k lines on the plane that contain all the input points.\nShow a kernel for this problem with \\mathcal{O}\\left(k^2\\right) points."
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/L09.html",
    "href": "courses/2023/02-AA/quizzes/L09.html",
    "title": "CS614. Advanced Algorithms. L09 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Dominating Set\n\n\n\nA dominating set of a graph G is a subset of vertices S such that every vertex in G either belongs to S or has a neighbor in S.\nSuppose you have an instance of dominating set given by (G,k), which is a YES-instance if and only if G has a dominating set of size at most k.\nIs the following reduction rule safe?\nRR. If d(v) > k, then return (G-v,k-1).\n( ) Yes (X) No\nBriefly justify your answer:\n|____|\n\n\n\n\n\n\n\n\nProblem 2. Connected Vertex Cover\n\n\n\nA connected vertex cover of a graph G is a subset of vertices S such that: (a) S is a vertex cover of G, and (b) G[S] is a connected subgraph of G.\nSuppose you have an instance of connected vertex cover given by (G,k), which is a YES-instance if and only if G has a connected vertex cover of size at most k.\n\n\n\n\n\n\nProblem 2.1 Connected Vertex Cover I.\n\n\n\nDesign a \\mathcal{O}(2^k) vertex kernel for Connected Vertex Cover.\nHint: What can you say about high degree vertices? How many can G have?\nFollow up hint: What can you say about two vertices that have the same neighbourhood among the high-degree vertices?\n\n\n\n\n\n\n\n\nProblem 2.2 Connected Vertex Cover II.\n\n\n\nObserve that the kernelization argument that we made for Vertex Cover does not work as-is for connected vertex cover. Recall that the reduction rules were the following:\n\nR0. If k \\leqslant 0 and E is non-empty, return a trivial no-instance.\nR1. If k \\geqslant 0 and E is empty, return a trivial yes-instance.\nR2. If v is a degree zero vertex, return (G\\setminus \\{v\\},k), i.e, delete v from G and keep the budget the same.\nR3. If v is vertex whose degree is more than k, return (G\\setminus \\{v\\},k-1), i.e, delete v from G and reduce the budget by one.\n\nWhere does it fail? Justify, if possible, with an example."
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/L19.html",
    "href": "courses/2023/02-AA/quizzes/L19.html",
    "title": "CS614. Advanced Algorithms. L19 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Bin Packing\n\n\n\nConsider the bin-packing problem:\nInput: n items with sizes a_1 \\cdots a_n respectively, a positive integer B (bin capacity) and a positive integer k (number of bins). Question: Is there a partition of the set \\{1 \\cdots n\\} into sets S_1, \\ldots, S_k such that for each i \\in\\{1 \\cdots k\\} we have that \\sum_{j \\in S_i} a_j \\leq B?\nShow that Bin Packing is NP-complete.\n\n\n\n\n\n\n\n\nProblem 2. BOX-DEPTH\n\n\n\nConsider the following problem, called BOX-DEPTH: Given a set of n axisaligned rectangles in the plane, how big is the largest subset of these rectangles that contain a common point?\n\nDescribe a polynomial-time reduction from BOX-DEPTH to MAXCLIQUE.\nDescribe and analyze a polynomial-time algorithm for BOX-DEPTH. [Hint: O\\left(n^3\\right) time should be easy, but O(n \\log n) time is possible.]\nWhy don’t these two results imply that \\mathrm{P}=\\mathrm{NP}?"
  },
  {
    "objectID": "courses/2023/02-AA/quizzes/L18.html",
    "href": "courses/2023/02-AA/quizzes/L18.html",
    "title": "CS614. Advanced Algorithms. L18 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. 3-Hitting Set\n\n\n\nObtain an algorithm for 3-Hitting Set running in time 2.4656^k n^{\\mathcal{O}(1)} using iterative compression.\n\n\n\n\n\n\n\n\nProblem 2. d-Hitting Set\n\n\n\nGeneralize the algorithm from the previous problem to obtain an algorithm for d-Hitting Set running in time ((d-1)+0.4656)^k n^{\\mathcal{O}(1)}."
  },
  {
    "objectID": "courses/2023/03-ES214/index.html",
    "href": "courses/2023/03-ES214/index.html",
    "title": "ES 214 | Aug-Nov 2023",
    "section": "",
    "text": "(co-instructor with Prof. Anirban Dasgupta.)\n\n\n\n\n\n\nAbout the Course\n\n\n\n\n\nTBA\n\n\n\n\n\n\n\n\n\nTarget Audience\n\n\n\n\n\nYou will find this course interesting if:\n\nyou think counting the number of ways in which you can complete your graduation requirements is a fun problem to think about,\nyou enjoy logic puzzles like this one or probability puzzles like this one, or\nyou like box-stacking challenges, or\nyou are enrolled in a program for which this course is in the core.\n\n\n\n\n\n\n\n\n\n\nPrerequisites\n\n\n\n\n\nThis course is self-contained and involves no pre-requisites.\n\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\n\n\nDiscrete Mathematics and Its Applications by Kenneth Rosen\nOpen Textbook on Discrete Mathematics\nProofs: A Long-Form Mathematics Textbook by Jay Cummings\nPlaying with Discrete Math by Kyle Burke and Craig Tennenhouse\nOnline Course (with lecture videos): Math 4190, Summer I 2019\n\n\n\n\n\n\n\n\n\n\nTimings and Venue\n\n\n\n\n\nVenue: 1/101\nLectures:\n\nTuesdays 3:30PM — 5:00PM\nWednesdays 11:30 — 12:50\n\nTutorials\n\nThursdays 3:30PM — 5:00PM\n\n\n\n\n\n\n\n\n\n\nTAs and Office hours\n\n\n\n\n\nOffice Hours: By email.\nTAs: TBA\n\n\n\n\n\n\n\n\n\nEvaluation policy\n\n\n\n\n\n\nEach of the three exams account for 20% of the grade.\nEach of the eleven tutorials will have a quiz worth 5 points. The total number of points you can earn through quizzes is capped at 40, and accounts for 40% of the grade.\nThere will be weekly assignments that are not graded but are recommended for practice.\n\n\n\n\n\n\n\n\n\n\nRegister\n\n\n\n\n\n\nFor IITGN students, (pre-)register through IMS as usual.\nAll quizzes and exams will be on Gradescope.\nIf you are not from IITGN and are interested in taking up the course, then please send us an email.\n\n\n\n\n\nLecturesAssignmentsQuizzesExams\n\n\n\n\n\n    \n        Date\n        Lecture\n        Slides\n        Notes\n        Video\n    \n    \n                    \n            \n                02 Aug, 2023\n            \n            \n                1. Intro to Proofs - I\n                General Methods • Chessboard Tilings • Game of Chomp\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                03 Aug, 2023\n            \n            \n                2. Intro to Proofs - II\n                Pigeonhole Principle • Illustrative Examples\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                08 Aug, 2023\n            \n            \n                3. Sets\n                Definitions • Operations • Showing Containment • Showing Equality\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                09 Aug, 2023\n            \n            \n                4. Functions and Relations\n                Injections, Surjections, Bijections • Compositions • Equivalence Classes\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                16 Aug, 2023\n            \n            \n                5. Induction\n                Dominoes, Ladders, and Chips • Examples • Non-Examples • Strong Induction\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                22 Aug, 2023\n            \n            \n                6. Propositional and Predicate Logic\n                Syntax • Truth Tables • Quantifiers\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                23 Aug, 2023\n            \n            \n                7. Inference Systems\n                Inference Rules (e.g, Modus Ponens, Modus Tollens, Resolution, etc) • Paradoxes\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                29 Aug, 2023\n            \n            \n                8. Elementary Counting Methods\n                Permutations • Combinations • Binomial Coefficients\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                30 Aug, 2023\n            \n            \n                9. The Method of Double Counting\n                Examples of proofs by double-counting\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                12 Sep, 2023\n            \n            \n                10. Intro to Graphs: Euler Tours\n                Necessary and Sufficient Conditions for Euler Tours • Computing Euler Tours\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                13 Sep, 2023\n            \n            \n                11. Hall's Theorem\n                Matchings • Congestion in Bipartite Graphs • Hall's Theorem • Applications\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                19 Sep, 2023\n            \n            \n                12. Graph Coloring\n                Map Coloring • Greedy Algorithms • Bipartite Graphs • k-Degenerate Graphs\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                20 Sep, 2023\n            \n            \n                13. Planarity\n                Planar Graphs are Five-Colorable • Obstructions to Planarity\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                26 Sep, 2023\n            \n            \n                14. Graphs Recap\n                ~\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                27 Sep, 2023\n            \n            \n                15. Probability Intro\n                Basics of Discrete Probability • Monty Hall • Conditional Probability\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                03 Oct, 2023\n            \n            \n                16. The Probabilistic Method - I\n                An Introduction to the Method • Applications in Graph Theory\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                04 Oct, 2023\n            \n            \n                17. The Probabilistic Method - II\n                Ramsey Number • Sum-Free Sets\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                10 Oct, 2023\n            \n            \n                18. Recap\n                ~\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                17 Oct, 2023\n            \n            \n                19. The Linear Algebra Method - I\n                OddTown and EvenTown\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                18 Oct, 2023\n            \n            \n                20. The Linear Algebra Method - II\n                VC Dimension of a Set System • Sauer's Lemma\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                31 Oct, 2023\n            \n            \n                21. Intro to Groups: Rotations and Symmetries\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                01 Nov, 2023\n            \n            \n                22. Permutation and Cyclic Groups\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                07 Nov, 2023\n            \n            \n                23. Homomorphisms\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                08 Nov, 2023\n            \n            \n                24. Quotient Groups and First Isomorphism Theorem\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                14 Nov, 2023\n            \n            \n                25. Intro to Number Theory: Extended Euclid's Algorithm\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                15 Nov, 2023\n            \n            \n                26. Chinese Remainder Theorem\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                21 Nov, 2023\n            \n            \n                27. Applications I: RSA\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                22 Nov, 2023\n            \n            \n                28. Applications II: PageRank\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                23 Nov, 2023\n            \n            \n                29. Recap\n                ~\n            \n            \n            \n            \n            \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\nThese are the weekly practice problems. There is no need to submit these assignments, but please make sure to get feedback from your peers, instructors and TAs as you go along.\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                10 Aug, 2023\n            \n            \n                Sets and Functions\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                17 Aug, 2023\n            \n            \n                Induction\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                24 Aug, 2023\n            \n            \n                Logic\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                31 Aug, 2023\n            \n            \n                Counting\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                14 Sep, 2023\n            \n            \n                Graphs I\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                21 Sep, 2023\n            \n            \n                Graphs II\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                05 Oct, 2023\n            \n            \n                Probability\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                19 Oct, 2023\n            \n            \n                Dimensionality Arguments\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                02 Nov, 2023\n            \n            \n                Groups I\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                09 Nov, 2023\n            \n            \n                Groups II\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                16 Nov, 2023\n            \n            \n                Number Theory\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                10 Aug, 2023\n            \n            \n                Sets and Functions\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                17 Aug, 2023\n            \n            \n                Induction\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                24 Aug, 2023\n            \n            \n                Logic\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                31 Aug, 2023\n            \n            \n                Counting\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                14 Sep, 2023\n            \n            \n                Graphs I\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                21 Sep, 2023\n            \n            \n                Graphs II\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                05 Oct, 2023\n            \n            \n                Probability\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                19 Oct, 2023\n            \n            \n                Dimensionality Arguments\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                02 Nov, 2023\n            \n            \n                Groups I\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                09 Nov, 2023\n            \n            \n                Groups II\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n                    \n            \n                16 Nov, 2023\n            \n            \n                Number Theory\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                TBA\n            \n            \n                Exam 1\n                Syllabus: topics in lectures 1 to 9 (inclusive)\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n                    \n            \n                TBA\n            \n            \n                Exam 2\n                Syllabus: topics in lectures 10 to 18 (inclusive)\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n                    \n            \n                TBA\n            \n            \n                Exam 3\n                Syllabus: topics in lectures 21 to 26 (inclusive)\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n\n\n\nNo matching items"
  },
  {
    "objectID": "courses/2023/03-ES214/tutorials/T01.html",
    "href": "courses/2023/03-ES214/tutorials/T01.html",
    "title": "ES214. Discrete Mathematics. Tutorial 01 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1A. How did they do it?\n\n\n\n\n\nImagine a friend gives you a deck of cards and lets you shuffle it a few times. They then ask vou to deal out the top 26 cards face down, which divides the deck into two.\nYou keep one half and they take the other. They ask you to count how many red cards you have. In the meantime, you notice that they are silently looking through their own half of the deck. But whatever they are doing they did it as quickly as you, because once you’re done they declare that they know how many red cards you counted, and correctly announce the answer!\nHow did they do it?\n\n\n\n\n\n\n\n\n\nProblem 1B. How did they do it? (Redux)\n\n\n\n\n\nDeduce how the following trick works.\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. Handshakes\n\n\n\n\n\nMr. and Mrs. Sharma invited four couples to their home. Some guests were friends of Mr. Sharma, and some others were friends of Mrs. Sharma. When the guests arrived, people who knew each other beforehand shook hands, those who did not know each other just greeted each other.\nAfter all this took place, the observant Mr. Sharma said “How interesting. If you disregard me, there are no two people present who shook hands the same number of times\nHow many times did Mrs. Sharma shake hands?\n\n\n\n\n\n\n\n\n\nProblem 3. Chessboard Game\n\n\n\n\n\nAlice begins by marking a corner square of an n × n chessboard; Bob marks an orthogonally adjacent square.\nThereafter, Alice and Bob continue alternating. each marking a square adjacent to the last one marked, until no unmarked adjacent square is available at which time the player whose turn it is to play loses.\nFor which n does Alice have a winning strategy? For which n does she win if the first square marked is instead a neighbor of a corner square?\nHint: dominoes.\n\n\n\n\n\n\n\n\n\nProblem 4. An Odd Party\n\n\n\n\n\nYou are at a party where any two people have an odd number of mutual friends at the party.\nShow that there are an odd number of attendees."
  },
  {
    "objectID": "courses/2023/03-ES214/tutorials/A01.html",
    "href": "courses/2023/03-ES214/tutorials/A01.html",
    "title": "ES214. Discrete Mathematics. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe circuits of the graphic matroid are the cycles of the graph G.\n\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c,d\\} with the edges \\{ab, cd, ad\\}.\nThere are two matchings in this instance:\n\nM_1 := \\{ab,cd\\}\nM_2: \\{ad\\}\n\nHowever, although |M_1| > |M_2|, neither of the edges from M_1 can be added to M_2.\n\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c\\} with the edges \\{ab, ac\\}. There are two independent sets: S_1 := \\{b,c\\} and M_2: \\{a\\}, but neither of the vertices from S_1 can be added to S_2.\n\nIf the independent sets formed a matroid the problem of finding a maximum independent set would not be NP-complete. \n— Comment in class"
  },
  {
    "objectID": "courses/2023/03-ES214/exams/E01.html",
    "href": "courses/2023/03-ES214/exams/E01.html",
    "title": "ES214. Discrete Mathematics. Exam 1.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nRemarks\n\n\n\nProblem indices on Gradescope for Problem 1 are off-by-one. Add one to the index here to match to Gradescope.\nErrata based on feedback from the class (thanks!) — these changes have been made in the questions below:\n\nQ5: it should have been v \\in S and not v \\in G.\nQ1.4: assume that the cycles C and D are edge-disjoint.\nQ1.6: the last return statement is G and not G-v (the vertex v is moved to F, not removed from the graph).\n\n\n\n\n\n\n\n\n\nProblem 1. The Constrained Cycle Hitting Set (CCHS) Problem.\n\n\n\n\n\n\n\n\n\nMarks Distribution.\n\n\n\nThis problem is worth 20 points overall. All subproblems carry two points each except 1.9 (which is zero marks).\n\n\nLet G = (V,E) be a simple and undirected graph. Let F \\subseteq V be a subset of vertices that we will call a forbidden subset. An instance of CCHS is given by (G,F,k), where k \\in \\mathbb{Z}^+ is a budget. Such an instance is a YES-instance if there exists a subset of S \\subseteq V \\setminus F such that:\n\n|S| \\leqslant k, and\nG \\setminus S is a forest, i.e, there are no cycles.\n\nSuch a subset is called a constrained cycle hitting set with respect to F. In this question, we will develop a c^k algorithm for solving a CCHS instance, combining reduction and branching rules in a spirit somewhat similar to what we have done for Vertex Cover in class.\nOur goal will be to return a solution, i.e, a subset of vertices that is a constrained cycle hitting set with respect to F. In particular, an informal overview of our approach, detailed further in the questions below, is the following:\n\nWe will eliminate low-degree (vertices of degree at most one) vertices, and branch on high-degree vertices.\nFor the base case, we will find ourselves “stuck” when the graph only has vertices of degree at most two, but this can be handled in polynomial time.\n\nOur algorithm will be denoted solve-CCHS(G,F,k). We begin the following straightforward rules:\n\nIf k < 0, return NO.\nIf V(G) = \\emptyset, return \\emptyset.\n\n\n\n\n\n\n\nProblem 1.0 No Hope Rule\n\n\n\n\n\nSuppose G[F] has a cycle C. Note that all vertices of C belong to F. Then return:\n\nNO\nsolve-CCHS(G-v,F-v,k-1) where v is a maximum degree vertex from C.\nsolve-CCHS(G-v,F-v,k-1) where v is a minimum degree vertex from C.\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.1 Low Degree Rule.\n\n\n\n\n\nIf a vertex v has degree zero or one, then return:\n\nsolve-CCHS(G-v,F-v,k).\nsolve-CCHS(G-v,F-v,k-1).\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Forced Vertex Rule.\n\n\n\n\n\nIf a vertex v \\in G \\setminus F has two neighbors in a single connected component of G[F], then return:\n\nsolve-CCHS(G-v,F,k).\nsolve-CCHS(G-v,F,k-1).\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.3 High Degree Vertex Has Low Degree - Structure I\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nLet C be a cycle in G. Which of the following scenarios are not feasible?\n\nC \\cap F \\neq \\emptyset and C \\cap (V \\setminus F) \\neq \\emptyset\nC \\cap F = \\emptyset and C \\cap (V \\setminus F) \\neq \\emptyset\nC \\cap F \\neq \\emptyset and C \\cap (V \\setminus F) = \\emptyset\n\nPick the correct option and justify your answer briefly.\n\n\n\n\n\n\n\n\n\nProblem 1.4 High Degree Vertex Has Low Degree - Structure II\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nLet C and D be two edge-disjoint cycles in G. Which of the following scenarios are not feasible?\n\nC \\cap D \\neq \\emptyset\n(C \\cap F) \\cap (D \\cap F) \\neq \\emptyset\n(C \\cap (V\\setminus F)) \\cap (D \\cap (V \\setminus F)) \\neq \\emptyset\n\nPick the correct option and justify your answer briefly.\n\n\n\n\n\n\n\n\n\nProblem 1.5 High Degree Vertex Has Low Degree - Rule\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nConsider the following algorithm to solve this instance:\ninit X = emptyset\nwhile G\\X has a cycle C:\n    let v be a vertex in C\\F:\n        add v to X\nif |X| > k:\n    return NO\nelse:\n    return X\nWhat can you say about the procedure above?\n\nIt correctly solves the kind of CCHS questions being considered in this problem.\nIt will not be correct if there are no vertices in C\\setminus F, as required in line 3.\nIt will not be correct if there are two overlapping cycles in the instance.\n\nPick the correct option and justify your answer briefly. If you believe this is not the right algorithm, please suggest an alternative that works. In further questions when we refer to the rule in problem 1.5, we are referring to either the algorithm above or the one in your justification.\n\n\n\n\n\n\n\n\n\nProblem 1.6 The Branching Step\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1, 1.2, and 1.5 do not apply. Let v be a vertex in G \\setminus F of maximum degree. Now we branch as follows:\nOption A.\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F U {v},k) // omit v\nOption B.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F U {v},k-1) // omit v\nOption C.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X\notherwise:\n    return solve-CCHS(G,F U {v},k) // omit v\nOption D.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F,k) // omit v\nPick the right branching strategy and justify your answer.\n\n\n\nWe summarize the overall algorithm below.\nIf k < 0, return NO.\nIf V(G) is empty, return the empty set.\n\nApply rules 1.0, 1.1, and 1.2.\n\nPick a vertex v in G\\F of maximum degree.\n\nIf d(v) = 2, apply rule 1.5.\nOtherwise branch according to 1.6.\nIn the next few questions, we will analyze the running time of this algorithm. Assume that the algorithm is called with F = \\emptyset, i.e, there are no forbidden vertices to begin with. Fix an execution path P in the branching tree1 of the algorithm that does not return NO. Now:\n\nWe use S(P) to denote the output: note that this would consist of the set of vertices that are removed from the instance for inclusion in the solution, i.e, vertices chosen by the first branch in Step 1.6.\nWe use F(P) to denote the set of vertices that are made forbidden along the path P, i.e, these are vertices chosen by the second branch in Step 1.6.\n\nNote that at the output node, the instance we have is (G,F(P),\\ell) for some \\ell \\leqslant k, where S(P) is a constrained cycle hitting set with respect to F(P) of size at most k - \\ell. Also the number of steps in the execution path P is given by |F(P)| + |S(P)|, since every time we branch, we either include a vertex in the solution or make it forbidden.\n\n\n\n\n\n\nProblem 1.7 Degree 3 vs Leaves in Trees\n\n\n\n\n\nLet T be a tree and let X be the set of leaves in T, and let Y be the set of vertices of degree three or more in T. Show that:\n\\sum_{v \\in Y} (d(v)-2) = |X| - 2,\nusing elementary facts about trees.\n\n\n\n\n\n\n\n\n\nProblem 1.8 Degree Evolution\n\n\n\n\n\nFix an execution path P on an instance (G,\\emptyset,k) (i.e, a path from root to leaf in the branching tree associated with the algorithm when the input is (G,\\emptyset,k)) and consider a vertex v that belongs to F(P), which is to say that the vertex v was included in the set of forbidden vertices at some point during the execution of the algorithm. Denote the instance at this stage of the algorithm by (H,F,k^\\prime). In particular, H is the graph obtained after v was included in F. Let d(v) denote the degree of the vertex v in the original instance G, and let d^\\star(v) denote its degree in the graph H. Which of the following is true?\n\n3 \\leqslant d^\\star(v) \\leqslant d(v)\n3 \\leqslant d^\\star(v) < d(v)\nd^\\star(v) \\geqslant \\min(d(v),3)\nd^\\star(v) > \\min(d(v),3)\n\n\n\n\n\n\n\n\n\n\nProblem 1.9 Successful Execution Paths are Short\n\n\n\n\n\nConsider an execution path P that does not return NO. Show that F(P) \\leqslant 3S(P).\nThis is an optional question that you can skip. It carries no points.\n\n\n\n\n\n\n\n\n\nProblem 1.10 The Final Running Time\n\n\n\n\n\nCan you use the fact from the previous question to come up with an algorithm for CCHS that runs in time O^\\star(16^k)? Note that the O^\\star(\\cdot) notation is used to hide factors that are polynomial in n and k.\nHint: Use the algorithm described previously in the question, but modify it slightly. In particular, if an execution path pushes more than 3S(P) vertices into the forbidden set F, can you terminate it prematurely? Also, what is the cost of the successful execution paths?\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. GreedyHS [2 points]\n\n\n\nLet U=\\left\\{x_1, \\ldots, x_n\\right\\} be an univere of n elements. Suppose we have a family \\mathcal{F} over U that consists of three-sized subsets of U, for example:\n\n\\mathcal{F} = \\left(x_1, x_3, x_4\\right),\\left(x_2, x_3, x_7\\right),\\left(x_1, x_5, x_6\\right)\n\nWe want to find a smallest subset X of U such that for all sets S \\in \\mathcal{F}, S \\cap X \\neq \\emptyset.\nConsider the following algorithm for this problem.\nGreedy(U,F)\n\nInit X = emptyset\nwhile F is non-empty do:\n    Take an arbitrary set S in F.\n    Let x be an element in S\n    X = X U {x}\n    Remove all sets from F that contain x\nend while\nWhat can you say about the worst-case approximation ratio of this algorithm?\n\n\n\n\n\n\n\n\nProblem 3. Knapsack [2 points]\n\n\n\nConsider the knapsack problem. Given a set X=\\left\\{x_1, \\ldots, x_n\\right\\} of n items with weights w\\left(x_i\\right) and values v\\left(x_i\\right), it asks for the highest total value of items we can put into our knapsack such that the total weight of all these items is at most W.\nDescribe a 0/1-LP that models the problem correctly.\n\n\n\n\n\n\n\n\nProblem 4. Rectangle Covering [4 Points]\n\n\n\n\n\n\nRectangle Cover Problem Example\n\n\nSuppose we have a set P=\\left\\{p_1, \\ldots, p_n\\right\\} of n points and a set R=\\left\\{r_1 \\ldots, r_m\\right\\} of m rectangles, as in the image above. Each rectangle r_i \\in R has a certain cost c_i>0 associated with it. We wish to find a subset S \\subseteq R of rectangles whose cost is minimized such that the rectangles in S together cover all points in P.\nWe wish to model this problem as a 0/1-LP. To this end we introduce a decision variable x_i for each rectangle r_i \\in R, where x_i=1 corresponds to putting rectangle r_i into S and x_i=0 corresponds to not putting r_i into S. otherwise. Furthermore, for a point p_j \\in P, define R\\left(p_j\\right)=\\left\\{r_i \\in R: p_j \\in r_i\\right\\}.\n\n\n\n\n\n\nLP for Rectangle Cover\n\n\n\n\n\nDescribe a 0/1-LP that models the problem correctly.\n\n\n\n\n\n\n\n\n\nLP-based Approximation for Rectangle Cover\n\n\n\n\n\nDescribe a 5-approximation assuming that each point is contained in at most 5 rectangles.\n\n\n\n\n\n\n\n\n\n\n\nProblem 5. Dominating Set Reduction Rule When The Graph has No Short Cycles [2 points]\n\n\n\nSuppose G is a simple, undirected graph that has no cycles of length three or four. Recall that a subset S of vertices of G is called a dominating set if every vertex v of G either belongs to S or has a neighbor in S, in other words, N[v] \\cap S \\neq \\emptyset.\nLet S be a dominating set of G of size at most k, where G is as given above (i.e, G has no triangles and no cycles of length four). Show that if the degree of v is more than k in G, then v \\in S."
  },
  {
    "objectID": "courses/2023/03-ES214/quizzes/Q01.html",
    "href": "courses/2023/03-ES214/quizzes/Q01.html",
    "title": "ES214. Discrete Mathematics. Tutorial 01 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer."
  },
  {
    "objectID": "courses/2023/03-ES214/quizzes/A01.html",
    "href": "courses/2023/03-ES214/quizzes/A01.html",
    "title": "ES214. Discrete Mathematics. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe circuits of the graphic matroid are the cycles of the graph G.\n\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c,d\\} with the edges \\{ab, cd, ad\\}.\nThere are two matchings in this instance:\n\nM_1 := \\{ab,cd\\}\nM_2: \\{ad\\}\n\nHowever, although |M_1| > |M_2|, neither of the edges from M_1 can be added to M_2.\n\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c\\} with the edges \\{ab, ac\\}. There are two independent sets: S_1 := \\{b,c\\} and M_2: \\{a\\}, but neither of the vertices from S_1 can be added to S_2.\n\nIf the independent sets formed a matroid the problem of finding a maximum independent set would not be NP-complete. \n— Comment in class"
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/index.html",
    "href": "courses/2023/02-NPTEL-AA/index.html",
    "title": "CS 614 | Jan-Apr 2022",
    "section": "",
    "text": "About the Course\n\n\n\n\n\nThis course will explores the tradeoffs involved in coping with NP-completeness.\nWhen we think about designing algorithms, we are usually very demanding in how we go about it: we require our algorithms to be fast and accurate on all conceivable inputs. This is asking for quite a bit, and perhaps it is not surprising that we cannot afford this luxury all the time. The good news is that most of the time we can make meaningful progress by relaxing just one of these demands:\n\nGive up on accuracy, but not completely: look for solutions that are good enough (approximation) and/or work with algorithms that report the right solution most of the time (Las-Vegas style randomization).\nGive up on coverage, a little bit: let your algorithms work well on structured inputs. Hopefully the structure is such that it is not too limiting and is interesting enough for some application scenario, and is also enough to give you algorithmic leverage, i.e, there’s enough that you can exploit to make fast and accurate algorithms.\nGive up on speed, to some extent: going beyond the traditional allowance of polynomial time, which is the holy grail of what is considered efficient, takes you places. You could either allow for your algorithms have super-polynomial running times, and optimize as much as possible while being accurate on all inputs (exact algorithms), or allow for bad running times on a bounded subset of instances (Monte-Carlo style randomization).\n\nThis course is an introduction to techniques in achieving specific trade-offs, and understanding the theoretical foundations of frameworks that help us establish when certain tradeoffs are simply not feasible.\n\n\n\nFig. Exploring tradeoffs between the demands of accuracy, speed, and coverage.\n\n\n\n\n\n\n\n\n\n\n\nTarget Audience\n\n\n\n\n\nAnyone who is biting their nails from the NP-completeness cliffhanger at the end of their introduction to algorithms will probably enjoy this course.\n\n\n\n\n\n\n\n\n\nPrerequisites\n\n\n\n\n\nThis is a theoretical course that will require mathematical maturity (in particular, the ability to understand and write formal mathematical proofs), and some background in the design and analysis of algorithms. Programming experience is tangentially useful but not necessary. For students of IITGN, this course naturally follows up on DSA-II.\n\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\n\n\nThe Design of Approximation Algorithms • David P. Williamson and David B. Shmoys\nParameterized Algorithms • Marek Cygan, Fedor V. Fomin, Lukasz Kowalik, Daniel Lokshtanov, Daniel Marx, Marcin Pilipczuk, Michal Pilipczuk, and Saket Saurabh\nRandomized Algorithms • Motwani and Raghavan\nBeyond the Worst-Case Analysis of Algorithms • Tim Roughgarden\nAlgorithms • Jeff Erickson\n\n\n\n\n\n\n\n\n\n\nTimings and Venue\n\n\n\n\n\nOnline\n\n\n\n\n\n\n\n\n\nTAs and Office hours\n\n\n\n\n\nOffice Hours: Over Discord\nTAs TBA.\n\n\n\n\n\n\n\n\n\nEvaluation policy\n\n\n\n\n\nTBA\n\n\n\n\n\n\n\n\n\nRegister\n\n\n\n\n\nFor IITGN students, (pre-)register through IMS as usual.\nIf you are not from IITGN and are interested in taking up the course, then please send me an email.\n\n\n\n\nLecturesAssignmentsQuizzesExams\n\n\n\n\n\n    \n        Date\n        Lecture\n        Slides\n        Notes\n        Video\n    \n    \n                    \n            \n                03 Jun, 2023\n            \n            \n                1. A Recap of Greedy Algorithms\n                Matroids - definitions and examples • GreedyBasis Algorithm • Example: Scheduling with Deadlines\n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\nThese are some practice assignments: the due date is simply the recommended completion deadline. There is no need to submit these assignments.\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                11 Jan, 2023\n            \n            \n                Assignment 1\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    01 Feb, 2023\n            \n        \n                    \n            \n                20 Feb, 2023\n            \n            \n                Assignment 2\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    20 Mar, 2023\n            \n        \n                    \n            \n                03 Apr, 2023\n            \n            \n                Assignment 3\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    26 Apr, 2023\n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                09 Jan, 2023\n            \n            \n                Matroids and Greedy Algorithms - II\n                Proof of correctness of GreedyBasis\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    09 Jan, 2023\n            \n        \n                    \n            \n                11 Jan, 2023\n            \n            \n                Matroid Intersection - I\n                Matroid Intersection and Matroid Parity (Section 12.2.1) • Connections with Matchings • 3-Matroid Intersection is NP-complete (Theorem 12.6)\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    11 Jan, 2023\n            \n        \n                    \n            \n                16 Jan, 2023\n            \n            \n                Matroid Intersection - II\n                A polynomial time algorithm for Matroid Intersection\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    16 Jan, 2023\n            \n        \n                    \n            \n                18 Jan, 2023\n            \n            \n                Vertex Cover\n                Definition • Applications • Introduction to Approximation Algorithms • 2-approximation for Vertex Cover via maximal matchings\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    18 Jan, 2023\n            \n        \n                    \n            \n                23 Jan, 2023\n            \n            \n                Vertex Cover\n                Introduction to Linear Programming • 2-approximation via rounding • A simple randomized algorithm for Vertex Cover\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    23 Jan, 2023\n            \n        \n                    \n            \n                25 Jan, 2023\n            \n            \n                Vertex Cover\n                Introduction to Fixed-Parameter Tractability • An O(2^k) FPT algorithm by branching\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    25 Jan, 2023\n            \n        \n                    \n            \n                01 Feb, 2023\n            \n            \n                Vertex Cover\n                Introduction to Kernelization • A Quadratic Kernel for Vertex Cover based on degree reductions\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    01 Feb, 2023\n            \n        \n                    \n            \n                03 Feb, 2023\n            \n            \n                Vertex Cover\n                A Linear Kernel for Vertex Cover based on the LP formulation\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    03 Feb, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Set Cover\n                A Greedy Approximation Algorithm • A LP formulation\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Apr, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Detour: Long Path\n                Principle of Inclusion-Exclusion for a poly-space single-exponential algorithm for HAMPATH • Color Coding for Longest Path\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Apr, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Feedback Vertex Set\n                An O(log n)-approximation via primal dual\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Apr, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Feedback Vertex Set\n                A 2-approximation algorithm using a different LP formulation\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Apr, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Feedback Vertex Set\n                Iterative Compression • An O*(3.619^k) algorithm for FVS on general graphs • A polynomial-time algorithm on graphs of maximum degree 3\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Apr, 2023\n            \n        \n                    \n            \n                27 Mar, 2023\n            \n            \n                Lower Bounds\n                Introduction to NP-completeness • 3-Partition and friends • Multiprocessor Scheduling • Packing rectangles into a rectangle\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    27 Mar, 2023\n            \n        \n                    \n            \n                29 Mar, 2023\n            \n            \n                Lower Bounds\n                Reductions from 3-Partition\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    29 Mar, 2023\n            \n        \n                    \n            \n                03 Apr, 2023\n            \n            \n                Lower Bounds\n                SAT and Circuit SAT • CNF SAT • 3SAT • 3SAT-4 • Monotone 3SAT • Polynomial-time variants\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    03 Apr, 2023\n            \n        \n                    \n            \n                05 Apr, 2023\n            \n            \n                Lower Bounds\n                Schaefer's Dichotomy Theorem • 2-colorable perfect matching\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    05 Apr, 2023\n            \n        \n                    \n            \n                10 Apr, 2023\n            \n            \n                Lower Bounds\n                Parameterized Intractability • The W-hierarchy • Reductions from CLIQUE\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    10 Apr, 2023\n            \n        \n                    \n            \n                12 Apr, 2023\n            \n            \n                Lower Bounds\n                Kernel Lower Bounds • Composition and Distillation • Examples of compositions • Parameter preserving transformations\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    12 Apr, 2023\n            \n        \n                    \n            \n                17 Apr, 2023\n            \n            \n                Lower Bounds\n                The (Strong) Exponential Time Hypothesis • Sparsification Lemma • Implications for parameterized algorithms\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    17 Apr, 2023\n            \n        \n                    \n            \n                19 Apr, 2023\n            \n            \n                Lower Bounds\n                Reductions based on the ETH\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    19 Apr, 2023\n            \n        \n                    \n            \n                24 Apr, 2023\n            \n            \n                Lower Bounds\n                Inapproximability Introduction • NP optimization problems • PTAS, APX • Stronger notions of reductions that preserve approximability • APX-hardness of vertex cover\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    24 Apr, 2023\n            \n        \n                    \n            \n                26 Apr, 2023\n            \n            \n                Lower Bounds\n                Gap Inapproximability • Gap Problems • Gap-producing and gap-preserving reductions • PCP theorem • Unique Games Conjecture\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    26 Apr, 2023\n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problem Set\n        Solutions\n        Due\n    \n    \n                    \n            \n                TBA\n            \n            \n                Exam 1\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n                    \n            \n                TBA\n            \n            \n                Exam 2\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n                    \n            \n                TBA\n            \n            \n                Exam 3\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n\n\n\nNo matching items"
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/exams/E02.html",
    "href": "courses/2023/02-NPTEL-AA/exams/E02.html",
    "title": "CS614. Advanced Algorithms. Exam 2.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\nArturo I. Merino, Torsten Mütze, Aaron Williams: All Your bases Are Belong to Us: Listing All Bases of a Matroid by Greedy Exchanges. FUN 2022: 22:1-22:28 [PDF]\nDaniel Lokshtanov, Bernardo Subercaseaux: Wordle Is NP-Hard. FUN 2022: 19:1-19:8 [PDF]\nChristoph Brause, Ingo Schiermeyer: Kernelization of the 3-path vertex cover problem. Discret. Math. 339(7): 1935-1939 (2016) [PDF]\nRémy Belmonte, Tesshu Hanaka, Ioannis Katsikarelis, Michael Lampis, Hirotaka Ono, Yota Otachi: Parameterized Complexity of Safe Set. J. Graph Algorithms Appl. 24(3): 215-245 (2020) [PDF]\n\n\n\n\n\n\n\nNote for Paper #4\n\n\n\n\n\nFocus on Sections 5 and 7 for the presentation.\n\n\n\n\nRadovan Cervený, Ondrej Suchý: Faster FPT Algorithm for 5-Path Vertex Cover. MFCS 2019: 32:1-32:13 [PDF]\n\n\n\n\n\n\n\nNote for Paper #5\n\n\n\n\n\nSince there are several cases to the branching algorithm, there is no need to comprehensively cover them in the presentation\n\n\n\n\nFedor V. Fomin, Torstein J. F. Strømme: Vertex Cover Structural Parameterization Revisited. WG 2016: 171-182 [PDF]\n\n\n\n\n\n\n\nNote for Paper #6\n\n\n\n\n\nFocus on Section 3 for the presentation.\n\n\n\n\nA Note on Max k-Vertex Cover: Faster FPT-AS, Smaller Approximate Kernel and Improved Approximation. SOSA 2019: 15:1-15:21 [PDF]\n\n\n\n\n\n\n\nNote for Paper #7\n\n\n\n\n\nChoose an appropriate subset of results to present.\n\n\n\n\nDan Hefetz, Orna Kupferman, Amir Lellouche, Gal Vardi: Spanning-Tree Games. MFCS 2018: 35:1-35:16 [PDF]\nMichael Lampis, Valia Mitsou: The Computational Complexity of the Game of Set and Its Theoretical Applications. LATIN 2014: 24-34 [PDF]\n\n\n\n\n\n\n\nNote for Paper #7\n\n\n\n\n\nFocus on the NP-completeness and FPT results here.\n\n\n\n\nJulián Mestre: A Primal-Dual Approximation Algorithm for Partial Vertex Cover: Making Educated Guesses. APPROX-RANDOM 2005: 182-191 [PDF]"
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/exams/E01.html",
    "href": "courses/2023/02-NPTEL-AA/exams/E01.html",
    "title": "CS614. Advanced Algorithms. Exam 1.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nRemarks\n\n\n\nProblem indices on Gradescope for Problem 1 are off-by-one. Add one to the index here to match to Gradescope.\nErrata based on feedback from the class (thanks!) — these changes have been made in the questions below:\n\nQ5: it should have been v \\in S and not v \\in G.\nQ1.4: assume that the cycles C and D are edge-disjoint.\nQ1.6: the last return statement is G and not G-v (the vertex v is moved to F, not removed from the graph).\n\n\n\n\n\n\n\n\n\nProblem 1. The Constrained Cycle Hitting Set (CCHS) Problem.\n\n\n\n\n\n\n\n\n\nMarks Distribution.\n\n\n\nThis problem is worth 20 points overall. All subproblems carry two points each except 1.9 (which is zero marks).\n\n\nLet G = (V,E) be a simple and undirected graph. Let F \\subseteq V be a subset of vertices that we will call a forbidden subset. An instance of CCHS is given by (G,F,k), where k \\in \\mathbb{Z}^+ is a budget. Such an instance is a YES-instance if there exists a subset of S \\subseteq V \\setminus F such that:\n\n|S| \\leqslant k, and\nG \\setminus S is a forest, i.e, there are no cycles.\n\nSuch a subset is called a constrained cycle hitting set with respect to F. In this question, we will develop a c^k algorithm for solving a CCHS instance, combining reduction and branching rules in a spirit somewhat similar to what we have done for Vertex Cover in class.\nOur goal will be to return a solution, i.e, a subset of vertices that is a constrained cycle hitting set with respect to F. In particular, an informal overview of our approach, detailed further in the questions below, is the following:\n\nWe will eliminate low-degree (vertices of degree at most one) vertices, and branch on high-degree vertices.\nFor the base case, we will find ourselves “stuck” when the graph only has vertices of degree at most two, but this can be handled in polynomial time.\n\nOur algorithm will be denoted solve-CCHS(G,F,k). We begin the following straightforward rules:\n\nIf k < 0, return NO.\nIf V(G) = \\emptyset, return \\emptyset.\n\n\n\n\n\n\n\nProblem 1.0 No Hope Rule\n\n\n\n\n\nSuppose G[F] has a cycle C. Note that all vertices of C belong to F. Then return:\n\nNO\nsolve-CCHS(G-v,F-v,k-1) where v is a maximum degree vertex from C.\nsolve-CCHS(G-v,F-v,k-1) where v is a minimum degree vertex from C.\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.1 Low Degree Rule.\n\n\n\n\n\nIf a vertex v has degree zero or one, then return:\n\nsolve-CCHS(G-v,F-v,k).\nsolve-CCHS(G-v,F-v,k-1).\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Forced Vertex Rule.\n\n\n\n\n\nIf a vertex v \\in G \\setminus F has two neighbors in a single connected component of G[F], then return:\n\nsolve-CCHS(G-v,F,k).\nsolve-CCHS(G-v,F,k-1).\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.3 High Degree Vertex Has Low Degree - Structure I\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nLet C be a cycle in G. Which of the following scenarios are not feasible?\n\nC \\cap F \\neq \\emptyset and C \\cap (V \\setminus F) \\neq \\emptyset\nC \\cap F = \\emptyset and C \\cap (V \\setminus F) \\neq \\emptyset\nC \\cap F \\neq \\emptyset and C \\cap (V \\setminus F) = \\emptyset\n\nPick the correct option and justify your answer briefly.\n\n\n\n\n\n\n\n\n\nProblem 1.4 High Degree Vertex Has Low Degree - Structure II\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nLet C and D be two edge-disjoint cycles in G. Which of the following scenarios are not feasible?\n\nC \\cap D \\neq \\emptyset\n(C \\cap F) \\cap (D \\cap F) \\neq \\emptyset\n(C \\cap (V\\setminus F)) \\cap (D \\cap (V \\setminus F)) \\neq \\emptyset\n\nPick the correct option and justify your answer briefly.\n\n\n\n\n\n\n\n\n\nProblem 1.5 High Degree Vertex Has Low Degree - Rule\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nConsider the following algorithm to solve this instance:\ninit X = emptyset\nwhile G\\X has a cycle C:\n    let v be a vertex in C\\F:\n        add v to X\nif |X| > k:\n    return NO\nelse:\n    return X\nWhat can you say about the procedure above?\n\nIt correctly solves the kind of CCHS questions being considered in this problem.\nIt will not be correct if there are no vertices in C\\setminus F, as required in line 3.\nIt will not be correct if there are two overlapping cycles in the instance.\n\nPick the correct option and justify your answer briefly. If you believe this is not the right algorithm, please suggest an alternative that works. In further questions when we refer to the rule in problem 1.5, we are referring to either the algorithm above or the one in your justification.\n\n\n\n\n\n\n\n\n\nProblem 1.6 The Branching Step\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1, 1.2, and 1.5 do not apply. Let v be a vertex in G \\setminus F of maximum degree. Now we branch as follows:\nOption A.\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F U {v},k) // omit v\nOption B.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F U {v},k-1) // omit v\nOption C.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X\notherwise:\n    return solve-CCHS(G,F U {v},k) // omit v\nOption D.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F,k) // omit v\nPick the right branching strategy and justify your answer.\n\n\n\nWe summarize the overall algorithm below.\nIf k < 0, return NO.\nIf V(G) is empty, return the empty set.\n\nApply rules 1.0, 1.1, and 1.2.\n\nPick a vertex v in G\\F of maximum degree.\n\nIf d(v) = 2, apply rule 1.5.\nOtherwise branch according to 1.6.\nIn the next few questions, we will analyze the running time of this algorithm. Assume that the algorithm is called with F = \\emptyset, i.e, there are no forbidden vertices to begin with. Fix an execution path P in the branching tree1 of the algorithm that does not return NO. Now:\n\nWe use S(P) to denote the output: note that this would consist of the set of vertices that are removed from the instance for inclusion in the solution, i.e, vertices chosen by the first branch in Step 1.6.\nWe use F(P) to denote the set of vertices that are made forbidden along the path P, i.e, these are vertices chosen by the second branch in Step 1.6.\n\nNote that at the output node, the instance we have is (G,F(P),\\ell) for some \\ell \\leqslant k, where S(P) is a constrained cycle hitting set with respect to F(P) of size at most k - \\ell. Also the number of steps in the execution path P is given by |F(P)| + |S(P)|, since every time we branch, we either include a vertex in the solution or make it forbidden.\n\n\n\n\n\n\nProblem 1.7 Degree 3 vs Leaves in Trees\n\n\n\n\n\nLet T be a tree and let X be the set of leaves in T, and let Y be the set of vertices of degree three or more in T. Show that:\n\\sum_{v \\in Y} (d(v)-2) = |X| - 2,\nusing elementary facts about trees.\n\n\n\n\n\n\n\n\n\nProblem 1.8 Degree Evolution\n\n\n\n\n\nFix an execution path P on an instance (G,\\emptyset,k) (i.e, a path from root to leaf in the branching tree associated with the algorithm when the input is (G,\\emptyset,k)) and consider a vertex v that belongs to F(P), which is to say that the vertex v was included in the set of forbidden vertices at some point during the execution of the algorithm. Denote the instance at this stage of the algorithm by (H,F,k^\\prime). In particular, H is the graph obtained after v was included in F. Let d(v) denote the degree of the vertex v in the original instance G, and let d^\\star(v) denote its degree in the graph H. Which of the following is true?\n\n3 \\leqslant d^\\star(v) \\leqslant d(v)\n3 \\leqslant d^\\star(v) < d(v)\nd^\\star(v) \\geqslant \\min(d(v),3)\nd^\\star(v) > \\min(d(v),3)\n\n\n\n\n\n\n\n\n\n\nProblem 1.9 Successful Execution Paths are Short\n\n\n\n\n\nConsider an execution path P that does not return NO. Show that F(P) \\leqslant 3S(P).\nThis is an optional question that you can skip. It carries no points.\n\n\n\n\n\n\n\n\n\nProblem 1.10 The Final Running Time\n\n\n\n\n\nCan you use the fact from the previous question to come up with an algorithm for CCHS that runs in time O^\\star(16^k)? Note that the O^\\star(\\cdot) notation is used to hide factors that are polynomial in n and k.\nHint: Use the algorithm described previously in the question, but modify it slightly. In particular, if an execution path pushes more than 3S(P) vertices into the forbidden set F, can you terminate it prematurely? Also, what is the cost of the successful execution paths?\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. GreedyHS [2 points]\n\n\n\nLet U=\\left\\{x_1, \\ldots, x_n\\right\\} be an univere of n elements. Suppose we have a family \\mathcal{F} over U that consists of three-sized subsets of U, for example:\n\n\\mathcal{F} = \\left(x_1, x_3, x_4\\right),\\left(x_2, x_3, x_7\\right),\\left(x_1, x_5, x_6\\right)\n\nWe want to find a smallest subset X of U such that for all sets S \\in \\mathcal{F}, S \\cap X \\neq \\emptyset.\nConsider the following algorithm for this problem.\nGreedy(U,F)\n\nInit X = emptyset\nwhile F is non-empty do:\n    Take an arbitrary set S in F.\n    Let x be an element in S\n    X = X U {x}\n    Remove all sets from F that contain x\nend while\nWhat can you say about the worst-case approximation ratio of this algorithm?\n\n\n\n\n\n\n\n\nProblem 3. Knapsack [2 points]\n\n\n\nConsider the knapsack problem. Given a set X=\\left\\{x_1, \\ldots, x_n\\right\\} of n items with weights w\\left(x_i\\right) and values v\\left(x_i\\right), it asks for the highest total value of items we can put into our knapsack such that the total weight of all these items is at most W.\nDescribe a 0/1-LP that models the problem correctly.\n\n\n\n\n\n\n\n\nProblem 4. Rectangle Covering [4 Points]\n\n\n\n\n\n\nRectangle Cover Problem Example\n\n\nSuppose we have a set P=\\left\\{p_1, \\ldots, p_n\\right\\} of n points and a set R=\\left\\{r_1 \\ldots, r_m\\right\\} of m rectangles, as in the image above. Each rectangle r_i \\in R has a certain cost c_i>0 associated with it. We wish to find a subset S \\subseteq R of rectangles whose cost is minimized such that the rectangles in S together cover all points in P.\nWe wish to model this problem as a 0/1-LP. To this end we introduce a decision variable x_i for each rectangle r_i \\in R, where x_i=1 corresponds to putting rectangle r_i into S and x_i=0 corresponds to not putting r_i into S. otherwise. Furthermore, for a point p_j \\in P, define R\\left(p_j\\right)=\\left\\{r_i \\in R: p_j \\in r_i\\right\\}.\n\n\n\n\n\n\nLP for Rectangle Cover\n\n\n\n\n\nDescribe a 0/1-LP that models the problem correctly.\n\n\n\n\n\n\n\n\n\nLP-based Approximation for Rectangle Cover\n\n\n\n\n\nDescribe a 5-approximation assuming that each point is contained in at most 5 rectangles.\n\n\n\n\n\n\n\n\n\n\n\nProblem 5. Dominating Set Reduction Rule When The Graph has No Short Cycles [2 points]\n\n\n\nSuppose G is a simple, undirected graph that has no cycles of length three or four. Recall that a subset S of vertices of G is called a dominating set if every vertex v of G either belongs to S or has a neighbor in S, in other words, N[v] \\cap S \\neq \\emptyset.\nLet S be a dominating set of G of size at most k, where G is as given above (i.e, G has no triangles and no cycles of length four). Show that if the degree of v is more than k in G, then v \\in S."
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/L14.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/L14.html",
    "title": "CS614. Advanced Algorithms. L14 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 2. High-Degree Branching for FVS\n\n\n\nApply the same preprocessing steps as in the previous problem.\nLet \\left(v_1, v_2, \\ldots, v_n\\right) be a descending ordering of V(G) according to vertex degrees, i.e., d\\left(v_1\\right) \\geq d\\left(v_2\\right) \\geq \\ldots \\geq d\\left(v_n\\right). Let V_{3 k}=\\left\\{v_1, \\ldots, v_{3 k}\\right\\}.\nRecall that the minimum vertex degree of G is at least 3. Show that every feedback vertex set in G of size at most k contains at least one vertex of V_{3 k}."
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/L02.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/L02.html",
    "title": "CS614. Advanced Algorithms. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer."
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/L03.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/L03.html",
    "title": "CS614. Advanced Algorithms. L03 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Partition Matroid\n\n\n\nShow that the exchange axiom holds for the Partition Matroid defined in class.\n\n\n\n\n\n\n\n\nProblem 2. Representing the Graphic Matroid\n\n\n\nThe graphic matroid of a graph G can be represented by the following matrix: we have one row for each vertex, and one column for each edge. The column for edge e has +1 in the row for one endpoint, -1 in the row for the other endpoint, and 0 elsewhere; the choice of which endpoint to give which sign is arbitrary.\nArgue that this is a valid representation (i.e, that the forests correspond to linearly independent columns and the subsets of edges that have cycles in them correspond to dependent columns)."
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/L07.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/L07.html",
    "title": "CS614. Advanced Algorithms. L07 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the textbook on Parameterized Algorithms by Marek Cygan, Fedor V. Fomin, Łukasz Kowalik, Daniel Lokshtanov, Dániel Marx, Marcin Pilipczuk, Michał Pilipczuk, and Saket Saurabh.\n\n\n\n\n\n\n\n\nProblem 1. Cluster Vertex Deletion\n\n\n\nIn the Cluster Vertex Deletion problem, we want to know if a simple undirected graph G has a subset S of at most k vertices such that G \\setminus S is a disjoint union of cliques.\n\n\n\n\n\n\nProblem 1.1 A Branching Algorithm\n\n\n\nDesign a 3^k \\cdot n^{\\mathcal{O}(1)} algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nDesign a 3-approximation algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\n\n\nProblem 2. Don’t Satisfy Too Much!\n\n\n\nIn the MIN-2-SAT problem, we are given a 2 -CNF formula \\phi and an integer k, and the objective is to decide whether there exists an assignment for \\phi that satisfies at most k clauses.\nShow that MIN-2-SAT can be solved in time 2^k n^{\\mathcal{O}(1)}."
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/L13.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/L13.html",
    "title": "CS614. Advanced Algorithms. L13 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. FVS: is this FPT?\n\n\n\nRecall the following branching algorithm for Feedback Vertex Set (FVS) discussed in class:\n\nPreprocess to eliminate vertices of degree at most two, resulting in an equivlaent multigraph.\nPreprocess to force vertices with self-loops in the solution and adjust the budget as appropriate.\nIf a pair of vertices have more than two edges between them, delete all but two of these edges.\nSTOP if the graph is a forest or if we are out of budget.\nFind a shortest cycle and branch on all its vertices.\n\nSince a graph of minimum degree three that is not acyclic always has a cycle of length O(\\lg n), this algorithm has a running time of O^\\star((\\lg n)^k). Argue that this running time in fact shows that FVS is FPT in k."
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/L12.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/L12.html",
    "title": "CS614. Advanced Algorithms. L12 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. List Coloring\n\n\n\nIn the List Coloring problem, we are given a graph G and for each vertex v \\in V(G) there is a set (also called a list) of admissible colors L(v) \\subseteq N. The goal is to verify whether it is possible to find a proper vertex coloring c: V(G) \\rightarrow \\mathbb{N} of G such that for ever y vertex v we have c(v) \\in L(v). In other words, L(v) is the set of colors allowed for v.\nShow a 2^n n^{\\mathcal{O}(1)}-time algorithm for List Coloring.\nHint. Read Theorem 10.8 from the Parameterized Algorithms text.\n\n\n\n\n\n\n\n\nProblem 2. Triangle Packing\n\n\n\nIn the Triangle Packing problem, we are given an undirected graph G and a positive integer k, and the objective is to test whether G has k-vertex disjoint triangles. Using color coding show that the problem admits an algorithm with running time 2^{O(k)} n^{O(1)}."
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/L06.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/L06.html",
    "title": "CS614. Advanced Algorithms. L06 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the Coursera course on Approximation Algorithms taught by Mark de Berg.\n\n\n\n\n\n\n\n\nProblem 1. Changing the threshold\n\n\n\nConsider the algorithm LPAPX-WVC from the class.\n\n\n\n\n\n\nProblem 1.1 Increasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 2/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 1/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. Changing the rounding scheme\n\n\n\nConsider a different rounding strategy for the LP relaxation of the vertex cover problem. Instead of rounding up every vertex whose value is at least 0.5 after running the LP, we do the following:\nWe look at every edge, and then we round up the variable of the endpoint with the highest value, where in case of ties we take the endpoint with the highest index.\nIn other words, if the vertex set is V=\\left\\{v_1, \\ldots, v_n\\right\\} and we denote the associated variable of v_i by x_i then the cover C is computed as follows:\nC:=\\left\\{v_i \\in V:\\right. there is an edge \\left(v_i, v_j\\right) such that \\left(x_i>x_j\\right) or \\left(x_i=x_j\\right. and \\left.\\left.i>j\\right)\\right\\}\nWhich statement is true?\n\nThis does not work, because we might report an invalid solution.\nThis gives a valid solution, but the approximation ratio becomes worse.\nThis gives a valid solution, and in fact the solution is always exactly the same as in the original rounding scheme.\nThis gives a valid solution. We sometimes report a better solution than in the original rounding scheme, but the approximation ratio of the algorithm is still more than 2 - \\epsilon for any \\epsilon > 0.\nThis gives a valid solution, and the approximation ratio of the algorithm becomes 3/2.\n\n\n\n\n\n\n\n\n\nProblem 3. Lower Bound\n\n\n\nSuppose you have created an algorithm for a certain problem using LP relaxation and you want to say something about its approximation ratio. Which lower bound on the optimal solution can you use?\n\nThe solution to the 0/1-LP.\nThe solution to the relaxed LP.\nDepends on the problem.\n\n\n\n\n\n\n\n\n\nProblem 4. Integrality Gap\n\n\n\nWhat is the integrality gap of the vertex-cover LP for the complete graph on n vertices, where all vertices have weight 1?"
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/L10.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/L10.html",
    "title": "CS614. Advanced Algorithms. L10 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Set Cover: The Greedy Bound is Tight\n\n\n\nWe argued in class that the greedy approach to solving the unweighted Set Cover problem achieves an approximation ratio of O(H_n). Argue that this bound is tight, i.e, come up with examples where the algorithm picks sets in a manner that the cost of the solution is roughly H_n worse than optimal.\n\n\n\n\n\n\n\n\nProblem 2. Set Cover and Related Problems\n\n\n\n\nShow that Vertex Cover is a special case of Set Cover.\nAlso show that Dominating Set and Set Cover are equivalent (i.e, Set Cover can be reduced to Dominating Set and vice versa)."
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/L04.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/L04.html",
    "title": "CS614. Advanced Algorithms. L04 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Matroid Intersection Example\n\n\n\nConsider a directed graph D=(V, E \\subseteq V \\times V). A set T \\subseteq E is an arborescence (oriented forest) if:\n\nT does not contain a cycle (ignoring directions of edges).\nEvery vertex in V has at most one incoming edge.\n\nAn arborescence T with |T|=n-1 will have one incoming edge incident on each node except one. If we denote this special node as root, this is an oriented spanning tree as shown in the figure.\n\n\n\nAn example arborescence.\n\n\nConsider the underlying undirected graph G_D = (V,E) associated with D (this is the graph obtained by “erasing the arrows” in D). Consider the universe given by E. Suggest two matroids {\\mathcal M}_1 and {\\mathcal M}_2 for which set of arborescences is given by the sets independent in both {\\mathcal M}_1 and {\\mathcal M}_2.\nHint: these are both matroids seen in class. Further, you might find it useful to partition E into |V| many parts as follows — the part P_v contains all edges that are incoming arcs for the vertex v in D. Can you define a matroid based on this partition?\nDescribe {\\mathcal M}_1 and {\\mathcal M}_2.\n\n\n\n\n\n\n\n\nProblem 2. Maker-Breaker Game\n\n\n\nTwo players take turns removing edges from an undirected graph until there are no edges left.\nPlayer 2 wins if the edges they remove contains a spanning tree, player 1 wins if the set of edges they remove would disconnect the original graph.\n\nIs it true that exactly one player wins this game? In other words, is the following statement true?\n\n“It is NOT the case that after the game has been played, both players can claim a win.”\n\nYes\nNo\n\n\nWhich player wins on a path?\n\n\nPlayer 1\nPlayer 2\n\n\nWhich player wins on a complete graph?\n\n\nPlayer 1\nPlayer 2\n\n\nComplete this sentence: player 2 has the winning strategy if and only if the graph contains BLANK.\n\n(No marks for answering this question, take your best guess :) )"
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/L05.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/L05.html",
    "title": "CS614. Advanced Algorithms. L05 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Approximate Vertex Cover\n\n\n\nGive an example of a graph where the 2-approximate solution (via maximal matchings) is worse than the optimal one. Even just slightly worse is enough :)\n\n\n\n\n\n\n\n\nProblem 2. Approximate Independent Set\n\n\n\nSince the complement of a vertex cover is an independent set, you might be tempted to think that the approximation discussed in class also approximates independent set. In particular, consider the following algorithm for independent set:\n\nRun the 2-approximation for vertex cover discussed in class, let the output be S.\nLet I := V(G) \\setminus S.\nIf I = \\emptyset, then let v \\in V(G) be an arbitrary vertex; set I := \\{v\\}.\n\nLet:\n\np denote the size of a largest independent set in G\nq denote the size of the set obtained by taking the complement of the output of the 2-approximation discussed in class.\nr denote \\max(q,1)\n\nNote that r is the size of the independent set output by the algorithm above.\nCome up with a graph where p can be a factor of cn larger than r for some constant c.\n\n\n\n\n\n\n\n\nProblem 3. Vertex Cover Matroid\n\n\n\nDo the set of vertex covers in a graph G form a matroid over the universe V(G)? If not, select the axiom that fails:\n\nExchange Axiom\nHereditary Axiom\nVertex covers do form a matroid"
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/A06.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/A06.html",
    "title": "CS614. Advanced Algorithms. L06 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the Coursera course on Approximation Algorithms taught by Mark de Berg.\n\n\n\n\n\n\n\n\nProblem 1. Changing the threshold\n\n\n\nConsider the algorithm LPAPX-WVC from the class.\n\n\n\n\n\n\nProblem 1.1 Increasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 2/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 1/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf we increase the threshold t beyond 0.5, then the output may not even be a vertex cover: for example, consider the example of a complete graph where the LPOPT sets all variables to 0.5: in this case our output will be the empty set with any threshold higher than 0.5.\nIf we decrease the threshold t below 0.5, then the output will be a vertex cover — indeed, if any edge (u,v) is uncovered, then both u and v were set to values less than t, and in particular less than 0.5, so we will violate our edge constraint just as we do when working with a threshold of 0.5. However, by choosing a lower value, we worsen the approximation ratio: in particular, if t = 1/3 then the output is a 3-approximation.\n\n\n\n\n\n\n\n\n\nProblem 2. Changing the rounding scheme\n\n\n\nConsider a different rounding strategy for the LP relaxation of the vertex cover problem. Instead of rounding up every vertex whose value is at least 0.5 after running the LP, we do the following:\nWe look at every edge, and then we round up the variable of the endpoint with the highest value, where in case of ties we take the endpoint with the highest index.\nIn other words, if the vertex set is V=\\left\\{v_1, \\ldots, v_n\\right\\} and we denote the associated variable of v_i by x_i then the cover C is computed as follows:\nC:=\\left\\{v_i \\in V:\\right. there is an edge \\left(v_i, v_j\\right) such that \\left(x_i>x_j\\right) or \\left(x_i=x_j\\right. and \\left.\\left.i>j\\right)\\right\\}\nWhich statement is true?\n\nThis does not work, because we might report an invalid solution.\nThis gives a valid solution, but the approximation ratio becomes worse.\nThis gives a valid solution, and in fact the solution is always exactly the same as in the original rounding scheme.\nThis gives a valid solution. We sometimes report a better solution than in the original rounding scheme, but the approximation ratio of the algorithm is still more than 2 - \\epsilon for any \\epsilon > 0.\nThis gives a valid solution, and the approximation ratio of the algorithm becomes 3/2.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe solution is valid: indeed, let (u,v) be an edge, and recall that the algorithm worked as follows:\nWe look at every edge, \nand then we round up the variable of the endpoint with the highest value, \nwhere in case of ties we take the endpoint with the highest index. \nSince one of the endpoints was rounded up, the edge is covered; and this is evidently true of every edge.\nThe solution with respect to this rounding may be better than the threshold-based rounding: for example, consider again a complete graph where the LPOPT sets all variables to 1/2: the threshold-based rounding leads to a solution of cost n, while the cost here will be strictly less.\nHowever, to see that the approximation ratio of the algorithm is still more than 2 - \\epsilon for any \\epsilon > 0, consider, for example, a cycle on n vertices: one can choose a suitably large value of n to bring the approximation ratio arbitrarily close to 2.\n\n\n\n\n\n\n\n\n\nProblem 3. Lower Bound\n\n\n\nSuppose you have created an algorithm for a certain problem using LP relaxation and you want to say something about its approximation ratio. Which lower bound on the optimal solution can you use?\n\nThe solution to the 0/1-LP.\nThe solution to the relaxed LP.\nDepends on the problem.\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n\nAs was clarified in class, this question is in the context of minimization problems.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe solution to the relaxed LP is a useful lower bound for the OPT. The value of the OPT for the 0/1-LP is exactly equal to the OPT (in a presumed exact formulation of the problem) and does not, by itself, provide information about the behavior of the relaxed LP.\n\n\n\n\n\n\n\n\n\nProblem 4. Integrality Gap\n\n\n\nWhat is the integrality gap of the vertex-cover LP for the complete graph on n vertices, where all vertices have weight 1?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nILPOPT = n-1 and LPOPT = n/2; so the integrality gap is 2 \\cdot (n-1)/n = 2(1 - \\frac{1}{n})."
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/A07.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/A07.html",
    "title": "CS614. Advanced Algorithms. L07 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the textbook on Parameterized Algorithms by Marek Cygan, Fedor V. Fomin, Łukasz Kowalik, Daniel Lokshtanov, Dániel Marx, Marcin Pilipczuk, Michał Pilipczuk, and Saket Saurabh.\n\n\n\n\n\n\n\n\nProblem 1. Cluster Vertex Deletion\n\n\n\nIn the Cluster Vertex Deletion problem, we want to know if a simple undirected graph G has a subset S of at most k vertices such that G \\setminus S is a disjoint union of cliques.\n\n\n\n\n\n\nProblem 1.1 A Branching Algorithm\n\n\n\nDesign a 3^k \\cdot n^{\\mathcal{O}(1)} algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nDesign a 3-approximation algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAs discussed in class, the induced path on three vertices is a forbidden substructure for a cluster graph. We state and prove this fact here for completeness.\n\nClaim. A graph G is a disjoint union of cliques if and only if it does not contain a path on three vertices as an induced subgraph.\nProof (sketch). Suppose G is a disjoint union of cliques, and for the sake of contradiction, suppose it has an induced path on vertices x,y,z with the edges being between x and y, and y and z. Note that since this is an induced path, there is no edge between x and z. Since every component of G is a clique, we know that x and z must be in different components. However, there is a path from x to z via y, which is a contradiction.\nSuppose G does not contain a path on three vertices as an induced subgraph. Again, for the sake of contradiction, suppose G has a connected component that is not a clique. Let (u,v) be a non-edge in this component. Let P be a shortest path between u and v consisting of the vertices:\nP := \\{u, w_1, \\ldots, w_t, \\ldots v\\}.\nNotice that t \\geqslant 1, otherwise (u,v) is an edge. Further, notice that u, w_1, w_2 forms an induced path of length three1 (if (u,w_2) was an edge then we have a shorter path by omitting w_1, contradicting our assumption that P is a shortest path between u and v). This contradicts our assumption.\n\nBased on this, we have the following algorithm:\nCVD(G,k):\n    If k <= 0 and G has an induced P3 - RETURN NO\n    If k >= 0 and G is a cluster graph - RETURN YES\n\n    Let a,b,c be vertices such that ab and bc are edges and ac is not an edge.\n\n    Return (CVD(G-a,k-1) OR CVD(G-b,k-1) OR (G-c,k-1))\nOne can obtain a 3-approximation by enumerating a maximal collection of disjoint induced P_3’s and including all vertices from the collection in the solution. If the collection has size t, we know that any solution (and in particular, the optimal one) must contain at least t vertices and the output has at most 3t vertices. The algorithm is summarized below:\nCVD-3-Approx(G):\n    Init S = emptyset\n\n    While there is an induced P3 = (x,y,z) in G:\n        include (x,y,z) in S\n        G = G - (x,y,z)\n\n    return S\n\n\n\n\n\n\n\n\n\nProblem 2. Don’t Satisfy Too Much!\n\n\n\nIn the MIN-2-SAT problem, we are given a 2-CNF formula \\phi and an integer k, and the objective is to decide whether there exists an assignment for \\phi that satisfies at most k clauses.\nShow that MIN-2-SAT can be solved in time 2^k n^{\\mathcal{O}(1)}.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf there is a variable x that occurs only positively in \\phi, we claim that there exists an optimal assignment that sets it to 0. Indeed, let \\tau be an assignment that sets x to 1. Let \\tau_x be the assignment obtained from \\tau by flipping the value of x from 1 to 0. Note that the clauses that do not contain the variable x are either satisfied or falsified in both \\tau and \\tau_x. For clauses that contain x, it is possible that they are satisfied by \\tau but not by \\tau_x, but not vice versa. Therefore, \\tau_x falsifies at least as many clauses as \\tau, and we are done.\nBased on this, our algorithm proceeds as follows:\nif there is a variable x that occurs only as a positive literal:\n    set x to 0\nif there is a variable x that occurs only as a negated literal:\n    set x to 1\nThe argument for the negated occurrences is symmetric to the one we have for positive literals.\nOnce we perform this preprocessing, assuming that have clauses remaining, we have the following guarantee:\n\nEvery variable has at least one positive and one negated occurrence.\n\nNow we can branch exhuastively on the settings of variables; with the promise that either setting of the variable reduces our budget by at least one. The overall algorithm is summarized in the following pseudocode:\nMINSAT(phi,k):\n    if there is a variable x that occurs only as a positive literal:\n        set x to 0\n    if there is a variable x that occurs only as a negated literal:\n        set x to 1\n\n    if phi is empty:\n        return YES\n    if phi is not empty and k <= 0:\n        return NO\n\n    Let x be any variable that occurs in phi.\n    return MINSAT(phi|[x = TRUE],k-1) OR MINSAT(phi|[x = FALSE],k-1)"
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/A05.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/A05.html",
    "title": "CS614. Advanced Algorithms. L05 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Approximate Vertex Cover\n\n\n\nGive an example of a graph where the 2-approximate solution (via maximal matchings) is worse than the optimal one. Even just slightly worse is enough :)\n\n\n\n\n\n\n\n\nFollow up question\n\n\n\n\n\nWhat are examples of graphs where the 2-approximate solution via maximal matchings is close to optimal? The empty and complete graphs come to mind, are there others?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nEven if the input graph is an edge, a star, or a matching, the 2-approximate solution is already worse by a factor of two.\n\n\n\n\n\n\n\n\n\nProblem 2. Approximate Independent Set\n\n\n\nSince the complement of a vertex cover is an independent set, you might be tempted to think that the approximation discussed in class also approximates independent set. In particular, consider the following algorithm for independent set:\n\nRun the 2-approximation for vertex cover discussed in class, let the output be S.\nLet I := V(G) \\setminus S.\nIf I = \\emptyset, then let v \\in V(G) be an arbitrary vertex; set I := \\{v\\}.\n\nLet:\n\np denote the size of a largest independent set in G\nq denote the size of the set obtained by taking the complement of the output of the 2-approximation discussed in class.\nr denote \\max(q,1)\n\nNote that r is the size of the independent set output by the algorithm above.\nCome up with a graph where p can be a factor of cn larger than r for some constant c.\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n\nIt was not explicit in the question: G denotes the input graph and n denotes the number of vertices in G.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet n = 2p and consider a complete bipartite graph K_{p,p}. The optimal independent set has size p but the algorithm above returns 1.\n\n\n\n\n\n\n\n\n\nProblem 3. Vertex Cover Matroid\n\n\n\nDo the set of vertex covers in a graph G form a matroid over the universe V(G)? If not, select the axiom that fails:\n\nExchange Axiom\nHereditary Axiom\nVertex covers do form a matroid\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nA subset of a vertex cover need not be a vertex cover; and in particular, the empty set is also not a vertex cover (although this axiom was not offered as an option)."
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/A04.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/A04.html",
    "title": "CS614. Advanced Algorithms. L04 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Matroid Intersection Example\n\n\n\nConsider a directed graph D=(V, E \\subseteq V \\times V). A set T \\subseteq E is an arborescence (oriented forest) if:\n\nT does not contain a cycle (ignoring directions of edges).\nEvery vertex in V has at most one incoming edge.\n\nAn arborescence T with |T|=n-1 will have one incoming edge incident on each node except one. If we denote this special node as root, this is an oriented spanning tree as shown in the figure.\n\n\n\nAn example arborescence.\n\n\nConsider the underlying undirected graph G_D = (V,E) associated with D (this is the graph obtained by “erasing the arrows” in D). Consider the universe given by E. Suggest two matroids {\\mathcal M}_1 and {\\mathcal M}_2 for which set of arborescences is given by the sets independent in both {\\mathcal M}_1 and {\\mathcal M}_2.\nHint: these are both matroids seen in class. Further, you might find it useful to partition E into |V| many parts as follows — the part P_v contains all edges that are incoming arcs for the vertex v in D. Can you define a matroid based on this partition?\nDescribe {\\mathcal M}_1 and {\\mathcal M}_2.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTake {\\mathcal M}_1 to be the graphic matroid and {\\mathcal M}_2 to be the partition matroid with all budgets set to one. Membership in the first matroid ensures that there are no underlying undirected cycles and membership in the second matroid ensures that every vertex in V has at most one incoming edge.\n\n\n\n\n\n\n\n\n\nProblem 2. Maker-Breaker Game\n\n\n\nTwo players take turns removing edges from an undirected graph until there are no edges left.\nPlayer 2 wins if the edges they remove contains a spanning tree, player 1 wins if the set of edges they remove would disconnect the original graph.\n\nIs it true that exactly one player wins this game? In other words, is the following statement true?\n\n“It is NOT the case that after the game has been played, both players can claim a win.”\n\nYes\nNo\n\n\nWhich player wins on a path?\n\n\nPlayer 1\nPlayer 2\n\n\nWhich player wins on a complete graph?\n\n\nPlayer 1\nPlayer 2\n\n\nComplete this sentence: player 2 has the winning strategy if and only if the graph contains BLANK.\n\n(No marks for answering this question, take your best guess :) )\n\n\n\n\n\n\n\n\nHeads Up\n\n\n\nPart (3) was under-specified: the second player wins on complete graphs with at least four vertices but the first player has easy wins if the graph is an edge (a complete graph on two vertices) or a triangle (a complete graph on three vertices).\nGrading note: everyone recieves a full grade for this question.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSuppose both players indeed win. Let us delete the edges chosen by the first player. What is left is: (a) the set of edges chosen by the second player and (b) a disconnected graph. But the second player also won, so this set contains a spanning tree. A graph cannot simultaneously admit a spanning tree and be disconnected, this is a contradiction when applied on the graph induced by the leftover edges.\nPlayer 1 can choose any edge in the first step and he already wins.\nAssume that the graph has at least four vertices. Player 2 wins because notice that no matter how the first player plays the first (n-1) steps, it is not enough to disconnect the graph. By chosing edges carefully1, Player 2 can ensure that (s)he has booked a spanning tree already within the first (n-1) moves.\nNo spoilers on this one (yet)."
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/A03.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/A03.html",
    "title": "CS614. Advanced Algorithms. L03 Solutions.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Partition Matroid\n\n\n\nShow that the exchange axiom holds for the Partition Matroid defined in class.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet (U := U_1 \\cup \\cdots \\cup U_\\ell, \\mathcal{F}) be a partition matroid with budgets a_1,\\ldots,a_\\ell.\nSuppose S, T \\subseteq U_1 \\cup \\cdots \\cup U_\\ell such that S,T \\in \\mathcal{F}, and |T| > |S|.\nThen, there exists at least one part U_i where |T \\cap U_i| > |S \\cap U_i|. Now let x \\in (T \\setminus S) \\cap U_i. Note that S \\cup \\{x\\} \\in \\mathcal{F} since:\n\\begin{equation*}\n    |S \\cap U_j| =\n    \\begin{cases}\n      < a_j & \\text{if } j = i,\\\\\n      \\leqslant a_j & \\text{otherwise}.\n    \\end{cases}\n\\end{equation*}\nand therefore:\n\\begin{equation*}\n    |(S \\cup \\{x\\}) \\cap U_j| =\n    \\begin{cases}\n      |S \\cap U_i| + 1 \\leqslant a_j & \\text{if } j = i,\\\\\n      \\leqslant a_j & \\text{otherwise}.\n    \\end{cases}\n\\end{equation*}\n\n\n\n\n\n\n\n\n\nProblem 2. Representing the Graphic Matroid\n\n\n\nThe graphic matroid of a graph G can be represented by the following matrix: we have one row for each vertex, and one column for each edge. The column for edge e has +1 in the row for one endpoint, -1 in the row for the other endpoint, and 0 elsewhere; the choice of which endpoint to give which sign is arbitrary.\nArgue that this is a valid representation (i.e, that the forests correspond to linearly independent columns and the subsets of edges that have cycles in them correspond to dependent columns).\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSuppose we have a subset of edges that contains a cycle. For simplicity, suppose the cycle is given by:\n\\{pq, qr, rs, st\\}\nNow consider the column vectors c_p, c_q, c_r, c_s:\n\\begin{bmatrix}\nc_p & c_q & c_r & c_s\\\\\n1 & 0 & 0 & -1 \\\\\n-1 & 1 & 0 & 0 \\\\\n0 & -1 & -1 & 0 \\\\\n0 & 0 & 1 & 1\n\\end{bmatrix}\nNote that:\n1 \\cdot c_p + 1 \\cdot c_q + (-1) \\cdot c_r + 1 \\cdot c_s\nis a linear combination with constants (1,1,-1,1) that establish that these vectors are linearly dependent. In general, write down the columns in the order in which they appear on the cycle. If the first entry in the column is not +1, then multiply the column by -1 (except the last column, where we do the reverse: if the first entry is +1, then we multiply the column by -1). This way, we have a situation where every row contains exactly one +1 entry and one -1 entry, and the linear combination sums to 0.\nThis shows that dependent subsets of the matroid correspond to linearly dependent columns of M.\nTo see that independent subsets S \\subseteq E(G) correspond to linearly independent columns, consider the set of columns that correspond to S:\n\\{c_e ~|~ e \\in S\\    }\nSuppose, for the sake of contradiction, that there was some non-trivial linear combination of these columns that vanished, i.e, for non-empty subset T \\subseteq S, there exist constants \\{\\alpha_e\\}_{e \\in T} where:\n\\sum_{e \\in T} \\alpha_e c_e = 0\nBut now consider the subgraph consisting of the edges in T. Note that the minimum degree of T must be two (suppose u \\in T has degree one, and its unique neighbor is v: then consider the entry in the row corresponding to u in the column corresponding to the edge uv: this is non-zero and there is no cancelation possible in the sum above). However, a graph whose minimum degree is two cannot be acyclic, and this is a contradiction."
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/A02.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/A02.html",
    "title": "CS614. Advanced Algorithms. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe circuits of the graphic matroid are the cycles of the graph G.\n\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c,d\\} with the edges \\{ab, cd, ad\\}.\nThere are two matchings in this instance:\n\nM_1 := \\{ab,cd\\}\nM_2: \\{ad\\}\n\nHowever, although |M_1| > |M_2|, neither of the edges from M_1 can be added to M_2.\n\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c\\} with the edges \\{ab, ac\\}. There are two independent sets: S_1 := \\{b,c\\} and M_2: \\{a\\}, but neither of the vertices from S_1 can be added to S_2.\n\nIf the independent sets formed a matroid the problem of finding a maximum independent set would not be NP-complete. \n— Comment in class"
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/L08.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/L08.html",
    "title": "CS614. Advanced Algorithms. L08 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Better Approximation given a k-coloring\n\n\n\nGiven a k-coloring of a graph G, show that we can find a vertex cover which is a 2\\bigl(1−\\frac{1}{k}\\bigr) approximation.\nHint: use the k-coloring on the vertices of V_{1/2}.\n\n\n\n\n\n\n\n\nProblem 2. Point Line Cover\n\n\n\nIn the Point Line Cover problem, we are given a set of n points in the plane and an integer k, and the goal is to check if there exists a set of k lines on the plane that contain all the input points.\nShow a kernel for this problem with \\mathcal{O}\\left(k^2\\right) points."
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/L09.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/L09.html",
    "title": "CS614. Advanced Algorithms. L09 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Dominating Set\n\n\n\nA dominating set of a graph G is a subset of vertices S such that every vertex in G either belongs to S or has a neighbor in S.\nSuppose you have an instance of dominating set given by (G,k), which is a YES-instance if and only if G has a dominating set of size at most k.\nIs the following reduction rule safe?\nRR. If d(v) > k, then return (G-v,k-1).\n( ) Yes (X) No\nBriefly justify your answer:\n|____|\n\n\n\n\n\n\n\n\nProblem 2. Connected Vertex Cover\n\n\n\nA connected vertex cover of a graph G is a subset of vertices S such that: (a) S is a vertex cover of G, and (b) G[S] is a connected subgraph of G.\nSuppose you have an instance of connected vertex cover given by (G,k), which is a YES-instance if and only if G has a connected vertex cover of size at most k.\n\n\n\n\n\n\nProblem 2.1 Connected Vertex Cover I.\n\n\n\nDesign a \\mathcal{O}(2^k) vertex kernel for Connected Vertex Cover.\nHint: What can you say about high degree vertices? How many can G have?\nFollow up hint: What can you say about two vertices that have the same neighbourhood among the high-degree vertices?\n\n\n\n\n\n\n\n\nProblem 2.2 Connected Vertex Cover II.\n\n\n\nObserve that the kernelization argument that we made for Vertex Cover does not work as-is for connected vertex cover. Recall that the reduction rules were the following:\n\nR0. If k \\leqslant 0 and E is non-empty, return a trivial no-instance.\nR1. If k \\geqslant 0 and E is empty, return a trivial yes-instance.\nR2. If v is a degree zero vertex, return (G\\setminus \\{v\\},k), i.e, delete v from G and keep the budget the same.\nR3. If v is vertex whose degree is more than k, return (G\\setminus \\{v\\},k-1), i.e, delete v from G and reduce the budget by one.\n\nWhere does it fail? Justify, if possible, with an example."
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/L19.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/L19.html",
    "title": "CS614. Advanced Algorithms. L19 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Bin Packing\n\n\n\nConsider the bin-packing problem:\nInput: n items with sizes a_1 \\cdots a_n respectively, a positive integer B (bin capacity) and a positive integer k (number of bins). Question: Is there a partition of the set \\{1 \\cdots n\\} into sets S_1, \\ldots, S_k such that for each i \\in\\{1 \\cdots k\\} we have that \\sum_{j \\in S_i} a_j \\leq B?\nShow that Bin Packing is NP-complete.\n\n\n\n\n\n\n\n\nProblem 2. BOX-DEPTH\n\n\n\nConsider the following problem, called BOX-DEPTH: Given a set of n axisaligned rectangles in the plane, how big is the largest subset of these rectangles that contain a common point?\n\nDescribe a polynomial-time reduction from BOX-DEPTH to MAXCLIQUE.\nDescribe and analyze a polynomial-time algorithm for BOX-DEPTH. [Hint: O\\left(n^3\\right) time should be easy, but O(n \\log n) time is possible.]\nWhy don’t these two results imply that \\mathrm{P}=\\mathrm{NP}?"
  },
  {
    "objectID": "courses/2023/02-NPTEL-AA/quizzes/L18.html",
    "href": "courses/2023/02-NPTEL-AA/quizzes/L18.html",
    "title": "CS614. Advanced Algorithms. L18 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. 3-Hitting Set\n\n\n\nObtain an algorithm for 3-Hitting Set running in time 2.4656^k n^{\\mathcal{O}(1)} using iterative compression.\n\n\n\n\n\n\n\n\nProblem 2. d-Hitting Set\n\n\n\nGeneralize the algorithm from the previous problem to obtain an algorithm for d-Hitting Set running in time ((d-1)+0.4656)^k n^{\\mathcal{O}(1)}."
  },
  {
    "objectID": "courses/2023/01-CS614/exams/E03.html",
    "href": "courses/2023/01-CS614/exams/E03.html",
    "title": "CS614. Advanced Algorithms. Exam 1.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nEXACT MATCH (3 points)\n\n\n\nGiven a graph G and an integer k, the EXACT MATCH problem asks for an induced matching of size k, that is, k edges x_1 y_1, \\ldots, x_k y_k such that the 2k endpoints are all distinct and there is no edge between \\left\\{x_i, y_i\\right\\} and \\left\\{x_j, y_j\\right\\} for any i \\neq j.\nProve that EXACT MATCH parameterized by k is as hard as INDEPENDENT SET parameterized by k.\n\n\n\n\n\n\n\n\nDominating Set on Restricted Classes\n\n\n\nConsider the Dominating Set problem.\n\n\n\n\n\n\nProblem 2.1 Understanding graph classes (1 point)\n\n\n\n\n\nLet \\mathcal{A} be the graphs excluding the star K_{1,4} as an induced subgraph. That is, a graph G belongs to \\mathcal{A} if and only if there is no copy of a star on four leaves as an induced subgraph (but you may still have vertices of degree four or more).\nSimilarly, let \\mathcal{B} be the graphs excluding the star K_{1,2} as an induced subgraph.\nWhich of the following is true?\n\n\\mathcal{A} \\subseteq \\mathcal{B}\n\\mathcal{B} \\subseteq \\mathcal{A}\nneither of the above\n\n\n\n\n\n\n\n\n\n\nProblem 2.2 An Easy Case (2 points)\n\n\n\n\n\nCan you solve Dominating Set in polynomial time if your input graph does not contain the star K_{1,2} as an induced subgraph?\n\n\n\n\n\n\n\n\n\nProblem 2.3 A Hard Case (4 points)\n\n\n\n\n\nProve that Dominating Set restricted to graphs excluding the star K_{1,4} as an induced subgraph is as hard as Dominating Set on general graphs.\nHint: look up the textbook (Theorem 13.15) reduction for Connected Dominating Set and adapt it.\n\n\n\n\n\n\n\n\n\n\n\nPERMUTATION COMPOSITION (3 points)\n\n\n\nThe EXACT UNIQUE HITTING SET problem is the following:\nInput: A universe U, a set A of subsets of U, and an integer k. Question: Does there exist a set X \\subseteq U of size exactly k such that |A \\cap X|=1 for every A \\in A?\nIn the PERMUTATION COMPOSITION problem, the input consists of a family \\mathcal{P} of permutations of a finite universe U, additional permutation \\pi of U, and an integer k, and the question is whether one can find a sequence \\pi_1, \\pi_2, \\ldots, \\pi_k \\in \\mathcal{P} such that:\n\\pi=\\pi_1 \\circ \\pi_2 \\circ \\ldots \\circ \\pi_k.\nShow a reduction from EXACT UNIQUE HITTING SET to PERMUTATION COMPOSITION.\n\n\n\n\n\n\n\n\nNICE SUBSET (3 points)\n\n\n\nLet G=\\left(X, Y, E\\right) be an undirected bipartite graph, that is, a graph whose nodes are divided into two sets, X and Y, such that every edge in E connects a node in X to a node in Y. The nodes in X are all labeled with non-negative integers.\nSome of the nodes in Y can be removed to leave a subset W \\subseteq Y. A subset W is called nice with G if every node in X which has been assigned a number m is connected to exactly m nodes in W. An example of a nice set is in the image below.\nThe problem is to determine whether a nice W exists. Demonstrate a reduction from 3SAT to this problem.\n\n\n\nImage showing an example\n\n\n\n\n\n\n\n\n\n\nNP-completeness Examples (4 points)\n\n\n\nPick any two problems below and show that they are NP-complete.\n\n\n\n\n\n\nProblem 5.1\n\n\n\n\n\nGiven an undirected graph G, does G contain a simple path that visits all but 9 vertices?\n\n\n\n\n\n\n\n\n\nProblem 5.2\n\n\n\n\n\nGiven an undirected graph G, does G have a spanning tree in which every node has degree at most 32?\n\n\n\n\n\n\n\n\n\nProblem 5.3\n\n\n\n\n\nGiven an undirected graph G, does G have a spanning tree with at most 5 leaves?\n\n\n\n\n\n\n\n\n\nProblem 5.4\n\n\n\n\n\nGiven an undirected graph G=(V, E), what is the size of the largest subset of vertices S \\subseteq V such that at most 50 edges in E have both endpoints in S?"
  },
  {
    "objectID": "courses/2023/01-CS614/exams/E03.html#cs614.-advanced-algorithms.",
    "href": "courses/2023/01-CS614/exams/E03.html#cs614.-advanced-algorithms.",
    "title": "CS614. Advanced Algorithms. Exam 1.",
    "section": "CS614. Advanced Algorithms.",
    "text": "CS614. Advanced Algorithms.\n\nExam 3\nBack to the course page\n\n\n\n\n\n\nDanger\n\n\n\n\n\n\n\n\n\nEXACT MATCH (3 points)\n\n\n\nGiven a graph G and an integer k, the EXACT MATCH problem asks for an induced matching of size k, that is, k edges x_1 y_1, \\ldots, x_k y_k such that the 2k endpoints are all distinct and there is no edge between \\left\\{x_i, y_i\\right\\} and \\left\\{x_j, y_j\\right\\} for any i \\neq j.\nProve that EXACT MATCH parameterized by k is as hard as INDEPENDENT SET parameterized by k.\n\n\n\n\n\n\n\n\nDominating Set on Restricted Classes\n\n\n\nConsider the Dominating Set problem.\n\n\n\n\n\n\nProblem 2.1 Understanding graph classes (1 point)\n\n\n\n\n\nLet \\mathcal{A} be the graphs excluding the star K_{1,4} as an induced subgraph. That is, a graph G belongs to \\mathcal{A} if and only if there is no copy of a star on four leaves as an induced subgraph (but you may still have vertices of degree four or more).\nSimilarly, let \\mathcal{B} be the graphs excluding the star K_{1,2} as an induced subgraph.\nWhich of the following is true?\n\n\\mathcal{A} \\subseteq \\mathcal{B}\n\\mathcal{B} \\subseteq \\mathcal{A}\nneither of the above\n\n\n\n\n\n\n\n\n\n\nProblem 2.2 An Easy Case (2 points)\n\n\n\n\n\nCan you solve Dominating Set in polynomial time if your input graph does not contain the star K_{1,2} as an induced subgraph?\n\n\n\n\n\n\n\n\n\nProblem 2.3 A Hard Case (4 points)\n\n\n\n\n\nProve that Dominating Set restricted to graphs excluding the star K_{1,4} as an induced subgraph is as hard as Dominating Set on general graphs.\nHint: look up the textbook (Theorem 13.15) reduction for Connected Dominating Set and adapt it.\n\n\n\n\n\n\n\n\n\n\n\nPERMUTATION COMPOSITION (3 points)\n\n\n\nThe EXACT UNIQUE HITTING SET problem is the following:\nInput: A universe U, a set A of subsets of U, and an integer k. Question: Does there exist a set X \\subseteq U of size exactly k such that |A \\cap X|=1 for every A \\in A?\nIn the PERMUTATION COMPOSITION problem, the input consists of a family \\mathcal{P} of permutations of a finite universe U, additional permutation \\pi of U, and an integer k, and the question is whether one can find a sequence \\pi_1, \\pi_2, \\ldots, \\pi_k \\in \\mathcal{P} such that:\n\\pi=\\pi_1 \\circ \\pi_2 \\circ \\ldots \\circ \\pi_k.\nShow a reduction from EXACT UNIQUE HITTING SET to PERMUTATION COMPOSITION.\n\n\n\n\n\n\n\n\nNICE SUBSET (3 points)\n\n\n\nLet G=\\left(X, Y, E\\right) be an undirected bipartite graph, that is, a graph whose nodes are divided into two sets, X and Y, such that every edge in E connects a node in X to a node in Y. The nodes in X are all labeled with non-negative integers.\nSome of the nodes in Y can be removed to leave a subset W \\subseteq Y. A subset W is called nice with G if every node in X which has been assigned a number m is connected to exactly m nodes in W. An example of a nice set is in the image below.\nThe problem is to determine whether a nice W exists. Demonstrate a reduction from 3SAT to this problem.\n\n\n\nImage showing an example\n\n\n\n\n\n\n\n\n\n\nNP-completeness Examples (4 points)\n\n\n\nPick any two problems below and show that they are NP-complete.\n\n\n\n\n\n\nProblem 5.1\n\n\n\n\n\nGiven an undirected graph G, does G contain a simple path that visits all but 9 vertices?\n\n\n\n\n\n\n\n\n\nProblem 5.2\n\n\n\n\n\nGiven an undirected graph G, does G have a spanning tree in which every node has degree at most 32?\n\n\n\n\n\n\n\n\n\nProblem 5.3\n\n\n\n\n\nGiven an undirected graph G, does G have a spanning tree with at most 5 leaves?\n\n\n\n\n\n\n\n\n\nProblem 5.4\n\n\n\n\n\nGiven an undirected graph G=(V, E), what is the size of the largest subset of vertices S \\subseteq V such that at most 50 edges in E have both endpoints in S?"
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L20.html",
    "href": "courses/2023/01-CS614/quizzes/L20.html",
    "title": "CS614. Advanced Algorithms. L20 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Monotone Satisfiability with Few True Variables\n\n\n\nConsider an instance of the Satisfiability Problem, specified by clauses C_1, \\ldots, C_k over a set of Boolean variables x_1, \\ldots, x_n. We say that the instance is monotone if each term in each clause consists of a nonnegated variable; that is, each term is equal to x_i, for some i, rather than \\bar{x}_i. Monotone instances of Satisfiability are very easy to solve: They are always satisfiable, by setting each variable equal to 1 . For example, suppose we have the three clauses \n\\left(x_1 \\vee x_2\\right),\\left(x_1 \\vee x_3\\right),\\left(x_2 \\vee x_3\\right) .\n This is monotone, and indeed the assignment that sets all three variables to 1 satisfies all the clauses. But we can observe that this is not the only satisfying assignment; we could also have set x_1 and x_2 to 1 , and x_3 to 0 . Indeed, for any monotone instance, it is natural to ask how few variables we need to set to 1 in order to satisfy it.\nGiven a monotone instance of Satisfiability, together with a number k, the problem of Monotone Satisfiability with Few True Variables asks: Is there a satisfying assignment for the instance in which at most k variables are set to 1?\nProve this problem is NP-complete. Hint: reduce from vertex cover.\n\n\n\n\n\n\n\n\nProblem 2. ALL-or-NOTHING-3SAT\n\n\n\nThe problem ALL-or-NOTHING-3SAT asks, given a 3CNF boolean formula, whether there is an assignment to the variables such that each clause either has three TRUE literals or has three FALSE literals.\n\nDescribe a polynomial-time algorithm to solve ALL-or-NOTHING-3SAT.\nBut 3SAT is NP-hard! Why doesn’t the existence of this algorithm prove that P=NP?"
  },
  {
    "objectID": "courses/2023/01-CS614/quizzes/L22.html",
    "href": "courses/2023/01-CS614/quizzes/L22.html",
    "title": "CS614. Advanced Algorithms. L22 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Hall Set\n\n\n\nGiven a bipartite graph G with bipartite classes A, B \\subseteq V(G) and an integer k, the Hall SET problem asks for a Hall set of size at most k, that is, a set S \\subseteq A of size at most k such that |N(S)|<|S|. Show that HalL SET is W[1]-hard.\n\nHint: Reduce from Clique. Given a graph G, we construct a bipartite graph where class A corresponds to the edges of G and class B corresponds to the vertices of B; the vertex of A corresponding to edge u v of G is adjacent to the two vertices u, v \\in B. Additionally, we introduce a set of {k \\choose 2}-k-1 vertices into B and make them adjacent to every vertex of A.\nShow that every Hall set of size at most {k \\choose 2} has size exactly {k \\choose 2} and corresponds to the edges of a k-clique in G."
  },
  {
    "objectID": "blog/poems/letting-go/index.html",
    "href": "blog/poems/letting-go/index.html",
    "title": "Letting Go",
    "section": "",
    "text": "ख्वाब हे वो माशूका जो तुझे मिलने से रहा, हकीकत हे वो हमसफर जिसे तुने है ठुकरा दिया\nसपनों का घर है नींदो मे उन्हे वहीं तू छोड दे जो हकीकत सम्झोता लगे वहीं सुकून है जान ले\n\nA dream is an elusive enchantment; while that that is to be treasured is what has been for real and is easily ignored.\nBut a mere figment of imagination, a dream is captive and binding: let it go to be free from your quest never-ending.\n\nInspired by Pallavi Mahajan’s brilliant poetry."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/index.html",
    "href": "courses/2023/02-IITM-AA/index.html",
    "title": "CS 614 | Jan-Apr 2022",
    "section": "",
    "text": "About the Course\n\n\n\n\n\nThis course will explores the tradeoffs involved in coping with NP-completeness.\nWhen we think about designing algorithms, we are usually very demanding in how we go about it: we require our algorithms to be fast and accurate on all conceivable inputs. This is asking for quite a bit, and perhaps it is not surprising that we cannot afford this luxury all the time. The good news is that most of the time we can make meaningful progress by relaxing just one of these demands:\n\nGive up on accuracy, but not completely: look for solutions that are good enough (approximation) and/or work with algorithms that report the right solution most of the time (Las-Vegas style randomization).\nGive up on coverage, a little bit: let your algorithms work well on structured inputs. Hopefully the structure is such that it is not too limiting and is interesting enough for some application scenario, and is also enough to give you algorithmic leverage, i.e, there’s enough that you can exploit to make fast and accurate algorithms.\nGive up on speed, to some extent: going beyond the traditional allowance of polynomial time, which is the holy grail of what is considered efficient, takes you places. You could either allow for your algorithms have super-polynomial running times, and optimize as much as possible while being accurate on all inputs (exact algorithms), or allow for bad running times on a bounded subset of instances (Monte-Carlo style randomization).\n\nThis course is an introduction to techniques in achieving specific trade-offs, and understanding the theoretical foundations of frameworks that help us establish when certain tradeoffs are simply not feasible.\n\n\n\nFig. Exploring tradeoffs between the demands of accuracy, speed, and coverage.\n\n\n\n\n\n\n\n\n\n\n\nTarget Audience\n\n\n\n\n\nAnyone who is biting their nails from the NP-completeness cliffhanger at the end of their introduction to algorithms will probably enjoy this course.\n\n\n\n\n\n\n\n\n\nPrerequisites\n\n\n\n\n\nThis is a theoretical course that will require mathematical maturity (in particular, the ability to understand and write formal mathematical proofs), and some background in the design and analysis of algorithms. Programming experience is tangentially useful but not necessary.\n\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\n\n\nThe Design of Approximation Algorithms • David P. Williamson and David B. Shmoys\nParameterized Algorithms • Marek Cygan, Fedor V. Fomin, Lukasz Kowalik, Daniel Lokshtanov, Daniel Marx, Marcin Pilipczuk, Michal Pilipczuk, and Saket Saurabh\nRandomized Algorithms • Motwani and Raghavan\nBeyond the Worst-Case Analysis of Algorithms • Tim Roughgarden\nAlgorithms • Jeff Erickson\n\n\n\n\n\n\n\n\n\n\nTimings and Venue\n\n\n\n\n\nOnline\n\n\n\n\n\n\n\n\n\nRegister\n\n\n\n\n\nThis course is meant for students of the IITM online BS program. If you are not enrolled in this program, but are interested in following along, please feel free to do so by going through the materials here. Send me an email if you would like to have access to the assignment problems.\n\n\n\n\nLecturesWeekly PracticeExams\n\n\n\n\n\n    \n        Date\n        Lecture\n        Slides\n        Notes\n        Video\n    \n    \n                    \n            \n                03 Jun, 2023\n            \n            \n                1. Greedy Algorithms\n                • Storing Files on Tape I  • Storing Files on Tape II  • Scheduling Classes I  • Scheduling Classes II  • Stable Matchings I  • Stable Matchings II  • Stable Matchings III\n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                10 Jun, 2023\n            \n            \n                2. Matroids\n                • A Generic Optimization Problem  • Motivating the Definition  • Greedy Works!  • Examples of Matroids I  • Examples of Matroids II  • Scheduling with Deadlines I  • Scheduling with Deadlines II\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                17 Jun, 2023\n            \n            \n                3. Dynamic Programming\n                • Longest Increasing Subsequence  • Edit Distance I  • Edit Distance II  • Subset Sum  • Optimal BSTs I  • Optimal BSTs II  • Optimal BSTs III\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                24 Jun, 2023\n            \n            \n                4. Maximum Flows\n                • Flows  • Cuts  • Maxflow-Mincut I  • Maxflow-Mincut II  • Augmenting Paths  • Bipartite Matchings  • Other Settings\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                01 Jul, 2023\n            \n            \n                5. Applications of Flows\n                • Exam Scheduling I  • Exam Scheduling II  • Baseball Elimination I  • Baseball Elimination II  • Baseball Elimination III  • Project Selection I  • Project Selection II\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                08 Jul, 2023\n            \n            \n                6. NP-hardness\n                • P, NP, NP-hardness, NP-completeness I  • P, NP, NP-hardness, NP-completeness II  • Reductions and SAT  • 3SAT  • Maximum Independent Set  • Graph Coloring  • Subset Sum\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                15 Jul, 2023\n            \n            \n                7. Approximation Algorithms\n                • Introduction to Approximation Frameworks  • Vertex Cover via Maximal Matchings  • Vertex Cover via LP rounding  • TSP  • Metric TSP  • Set Cover I  • Set Cover II\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                22 Jul, 2023\n            \n            \n                8. Randomized Algorithms\n                • Monte Carlo v. Las Vegas  • Min-Cut Algorithm  • MAX SAT via the Probabilistic Method I  • MAX SAT via the Probabilistic Method II  • 2SAT via Markov Chains I  • 2SAT via Markov Chains II • Primality Testing\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                29 Jul, 2023\n            \n            \n                9. Exact Algorithms\n                • Branch and Bound  • An Inclusion-Exclusion approach to Hamiltonian Path I  • An Inclusion-Exclusion approach to Hamiltonian Path II  • Dynamic Programming for TSP I  • Dynamic Programming for TSP II  • Local Search I  • Local Search II\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                05 Aug, 2023\n            \n            \n                10. Parameterized Algorithms\n                • Closest String I  • Closest String II  • Iterative Compression for FVS I  • Iterative Compression for FVS II  • Randomized Algorithm for k-Path I  • Randomized Algorithm for k-Path II  • DP over subsets - Set Cover\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                12 Aug, 2023\n            \n            \n                11. Kernelization\n                • Vertex Cover I (High-degree rule) • Vertex Cover II (LP-based Reduction) • Matrix Rigidity  • Feedback Arc Set on Tournaments I  • Feedback Arc Set on Tournaments II • Max Sat • Edge Clique Cover\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                19 Aug, 2023\n            \n            \n                12. Practical Approaches to Coping with Hardness\n                • SAT Sovlers  • SAT reductions I  • SAT reductions II  • LP solvers  • LP reductions I  • LP reductions II\n            \n            \n            \n            \n            \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problems\n        Solutions\n        Due\n    \n    \n                    \n            \n                03 Jun, 2023\n            \n            \n                Greedy Algorithms\n                • Storing Files on Tape  • Scheduling Classes  • Stable Matchings \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    10 Jun, 2023\n            \n        \n                    \n            \n                10 Jun, 2023\n            \n            \n                Matroids\n                • A Generic Optimization Problem • Motivating the Definition • Greedy Works! • Examples of Matroids  • Scheduling with Deadlines \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    17 Jun, 2023\n            \n        \n                    \n            \n                17 Jun, 2023\n            \n            \n                Dynamic Programming\n                • Longest Increasing Subsequence • Edit Distance  • Subset Sum • Optimal BSTs \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    24 Jun, 2023\n            \n        \n                    \n            \n                24 Jun, 2023\n            \n            \n                Maximum Flows\n                • Flows • Cuts • Maxflow-Mincut  • Augmenting Paths • Bipartite Matchings • Other Settings\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    01 Jul, 2023\n            \n        \n                    \n            \n                01 Jul, 2023\n            \n            \n                Applications of Flows\n                • Exam Scheduling  • Baseball Elimination  • Project Selection \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    08 Jul, 2023\n            \n        \n                    \n            \n                08 Jul, 2023\n            \n            \n                NP-hardness\n                • P, NP, NP-hardness, NP-completeness  • Reductions and SAT • 3SAT • Maximum Independent Set • Graph Coloring • Subset Sum\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    15 Jul, 2023\n            \n        \n                    \n            \n                15 Jul, 2023\n            \n            \n                Approximation Algorithms\n                • Introduction to Approximation Frameworks • Vertex Cover via Maximal Matchings • Vertex Cover via LP rounding • TSP • Metric TSP • Set Cover \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    22 Jul, 2023\n            \n        \n                    \n            \n                22 Jul, 2023\n            \n            \n                Randomized Algorithms\n                • Monte Carlo v. Las Vegas • Min-Cut Algorithm • MAX SAT via the Probabilistic Method  • 2SAT via Markov Chains \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    29 Jul, 2023\n            \n        \n                    \n            \n                29 Jul, 2023\n            \n            \n                Exact Algorithms\n                • Branch and Bound • An Inclusion-Exclusion approach to Hamiltonian Path  • Dynamic Programming for TSP  • Local Search \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    05 Aug, 2023\n            \n        \n                    \n            \n                05 Aug, 2023\n            \n            \n                Parameterized Algorithms\n                • Closest String  • Iterative Compression for FVS  • Randomized Algorithm for k-Path  • DP over subsets - Set Cover\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    12 Aug, 2023\n            \n        \n                    \n            \n                12 Aug, 2023\n            \n            \n                Kernelization\n                • Vertex Cover • Matrix Rigidity • Feedback Arc Set on Tournaments  • MaxSat  • Edge Clique Cover\n            \n            \n                    \n                \n            \n                    \n                \n            \n                    19 Aug, 2023\n            \n        \n                    \n            \n                19 Aug, 2023\n            \n            \n                Practical Approaches to Coping with Hardness\n                • SAT Sovlers • SAT reductions  • LP solvers • LP reductions \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    26 Aug, 2023\n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Issued\n        Assessment\n        Problems\n        Solutions\n        Due\n    \n    \n                    \n            \n                TBA\n            \n            \n                Mid-Term Quiz\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n                    \n            \n                TBA\n            \n            \n                Final Exam\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n                    \n            \n                TBA\n            \n            \n                Practice Exam\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n                    -\n            \n        \n\n\n\nNo matching items"
  },
  {
    "objectID": "courses/2023/02-IITM-AA/exams/E02.html",
    "href": "courses/2023/02-IITM-AA/exams/E02.html",
    "title": "CS614. Advanced Algorithms. Exam 2.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\nArturo I. Merino, Torsten Mütze, Aaron Williams: All Your bases Are Belong to Us: Listing All Bases of a Matroid by Greedy Exchanges. FUN 2022: 22:1-22:28 [PDF]\nDaniel Lokshtanov, Bernardo Subercaseaux: Wordle Is NP-Hard. FUN 2022: 19:1-19:8 [PDF]\nChristoph Brause, Ingo Schiermeyer: Kernelization of the 3-path vertex cover problem. Discret. Math. 339(7): 1935-1939 (2016) [PDF]\nRémy Belmonte, Tesshu Hanaka, Ioannis Katsikarelis, Michael Lampis, Hirotaka Ono, Yota Otachi: Parameterized Complexity of Safe Set. J. Graph Algorithms Appl. 24(3): 215-245 (2020) [PDF]\n\n\n\n\n\n\n\nNote for Paper #4\n\n\n\n\n\nFocus on Sections 5 and 7 for the presentation.\n\n\n\n\nRadovan Cervený, Ondrej Suchý: Faster FPT Algorithm for 5-Path Vertex Cover. MFCS 2019: 32:1-32:13 [PDF]\n\n\n\n\n\n\n\nNote for Paper #5\n\n\n\n\n\nSince there are several cases to the branching algorithm, there is no need to comprehensively cover them in the presentation\n\n\n\n\nFedor V. Fomin, Torstein J. F. Strømme: Vertex Cover Structural Parameterization Revisited. WG 2016: 171-182 [PDF]\n\n\n\n\n\n\n\nNote for Paper #6\n\n\n\n\n\nFocus on Section 3 for the presentation.\n\n\n\n\nA Note on Max k-Vertex Cover: Faster FPT-AS, Smaller Approximate Kernel and Improved Approximation. SOSA 2019: 15:1-15:21 [PDF]\n\n\n\n\n\n\n\nNote for Paper #7\n\n\n\n\n\nChoose an appropriate subset of results to present.\n\n\n\n\nDan Hefetz, Orna Kupferman, Amir Lellouche, Gal Vardi: Spanning-Tree Games. MFCS 2018: 35:1-35:16 [PDF]\nMichael Lampis, Valia Mitsou: The Computational Complexity of the Game of Set and Its Theoretical Applications. LATIN 2014: 24-34 [PDF]\n\n\n\n\n\n\n\nNote for Paper #7\n\n\n\n\n\nFocus on the NP-completeness and FPT results here.\n\n\n\n\nJulián Mestre: A Primal-Dual Approximation Algorithm for Partial Vertex Cover: Making Educated Guesses. APPROX-RANDOM 2005: 182-191 [PDF]"
  },
  {
    "objectID": "courses/2023/02-IITM-AA/exams/E01.html",
    "href": "courses/2023/02-IITM-AA/exams/E01.html",
    "title": "CS614. Advanced Algorithms. Exam 1.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nRemarks\n\n\n\nProblem indices on Gradescope for Problem 1 are off-by-one. Add one to the index here to match to Gradescope.\nErrata based on feedback from the class (thanks!) — these changes have been made in the questions below:\n\nQ5: it should have been v \\in S and not v \\in G.\nQ1.4: assume that the cycles C and D are edge-disjoint.\nQ1.6: the last return statement is G and not G-v (the vertex v is moved to F, not removed from the graph).\n\n\n\n\n\n\n\n\n\nProblem 1. The Constrained Cycle Hitting Set (CCHS) Problem.\n\n\n\n\n\n\n\n\n\nMarks Distribution.\n\n\n\nThis problem is worth 20 points overall. All subproblems carry two points each except 1.9 (which is zero marks).\n\n\nLet G = (V,E) be a simple and undirected graph. Let F \\subseteq V be a subset of vertices that we will call a forbidden subset. An instance of CCHS is given by (G,F,k), where k \\in \\mathbb{Z}^+ is a budget. Such an instance is a YES-instance if there exists a subset of S \\subseteq V \\setminus F such that:\n\n|S| \\leqslant k, and\nG \\setminus S is a forest, i.e, there are no cycles.\n\nSuch a subset is called a constrained cycle hitting set with respect to F. In this question, we will develop a c^k algorithm for solving a CCHS instance, combining reduction and branching rules in a spirit somewhat similar to what we have done for Vertex Cover in class.\nOur goal will be to return a solution, i.e, a subset of vertices that is a constrained cycle hitting set with respect to F. In particular, an informal overview of our approach, detailed further in the questions below, is the following:\n\nWe will eliminate low-degree (vertices of degree at most one) vertices, and branch on high-degree vertices.\nFor the base case, we will find ourselves “stuck” when the graph only has vertices of degree at most two, but this can be handled in polynomial time.\n\nOur algorithm will be denoted solve-CCHS(G,F,k). We begin the following straightforward rules:\n\nIf k < 0, return NO.\nIf V(G) = \\emptyset, return \\emptyset.\n\n\n\n\n\n\n\nProblem 1.0 No Hope Rule\n\n\n\n\n\nSuppose G[F] has a cycle C. Note that all vertices of C belong to F. Then return:\n\nNO\nsolve-CCHS(G-v,F-v,k-1) where v is a maximum degree vertex from C.\nsolve-CCHS(G-v,F-v,k-1) where v is a minimum degree vertex from C.\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.1 Low Degree Rule.\n\n\n\n\n\nIf a vertex v has degree zero or one, then return:\n\nsolve-CCHS(G-v,F-v,k).\nsolve-CCHS(G-v,F-v,k-1).\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Forced Vertex Rule.\n\n\n\n\n\nIf a vertex v \\in G \\setminus F has two neighbors in a single connected component of G[F], then return:\n\nsolve-CCHS(G-v,F,k).\nsolve-CCHS(G-v,F,k-1).\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.3 High Degree Vertex Has Low Degree - Structure I\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nLet C be a cycle in G. Which of the following scenarios are not feasible?\n\nC \\cap F \\neq \\emptyset and C \\cap (V \\setminus F) \\neq \\emptyset\nC \\cap F = \\emptyset and C \\cap (V \\setminus F) \\neq \\emptyset\nC \\cap F \\neq \\emptyset and C \\cap (V \\setminus F) = \\emptyset\n\nPick the correct option and justify your answer briefly.\n\n\n\n\n\n\n\n\n\nProblem 1.4 High Degree Vertex Has Low Degree - Structure II\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nLet C and D be two edge-disjoint cycles in G. Which of the following scenarios are not feasible?\n\nC \\cap D \\neq \\emptyset\n(C \\cap F) \\cap (D \\cap F) \\neq \\emptyset\n(C \\cap (V\\setminus F)) \\cap (D \\cap (V \\setminus F)) \\neq \\emptyset\n\nPick the correct option and justify your answer briefly.\n\n\n\n\n\n\n\n\n\nProblem 1.5 High Degree Vertex Has Low Degree - Rule\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nConsider the following algorithm to solve this instance:\ninit X = emptyset\nwhile G\\X has a cycle C:\n    let v be a vertex in C\\F:\n        add v to X\nif |X| > k:\n    return NO\nelse:\n    return X\nWhat can you say about the procedure above?\n\nIt correctly solves the kind of CCHS questions being considered in this problem.\nIt will not be correct if there are no vertices in C\\setminus F, as required in line 3.\nIt will not be correct if there are two overlapping cycles in the instance.\n\nPick the correct option and justify your answer briefly. If you believe this is not the right algorithm, please suggest an alternative that works. In further questions when we refer to the rule in problem 1.5, we are referring to either the algorithm above or the one in your justification.\n\n\n\n\n\n\n\n\n\nProblem 1.6 The Branching Step\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1, 1.2, and 1.5 do not apply. Let v be a vertex in G \\setminus F of maximum degree. Now we branch as follows:\nOption A.\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F U {v},k) // omit v\nOption B.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F U {v},k-1) // omit v\nOption C.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X\notherwise:\n    return solve-CCHS(G,F U {v},k) // omit v\nOption D.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F,k) // omit v\nPick the right branching strategy and justify your answer.\n\n\n\nWe summarize the overall algorithm below.\nIf k < 0, return NO.\nIf V(G) is empty, return the empty set.\n\nApply rules 1.0, 1.1, and 1.2.\n\nPick a vertex v in G\\F of maximum degree.\n\nIf d(v) = 2, apply rule 1.5.\nOtherwise branch according to 1.6.\nIn the next few questions, we will analyze the running time of this algorithm. Assume that the algorithm is called with F = \\emptyset, i.e, there are no forbidden vertices to begin with. Fix an execution path P in the branching tree1 of the algorithm that does not return NO. Now:\n\nWe use S(P) to denote the output: note that this would consist of the set of vertices that are removed from the instance for inclusion in the solution, i.e, vertices chosen by the first branch in Step 1.6.\nWe use F(P) to denote the set of vertices that are made forbidden along the path P, i.e, these are vertices chosen by the second branch in Step 1.6.\n\nNote that at the output node, the instance we have is (G,F(P),\\ell) for some \\ell \\leqslant k, where S(P) is a constrained cycle hitting set with respect to F(P) of size at most k - \\ell. Also the number of steps in the execution path P is given by |F(P)| + |S(P)|, since every time we branch, we either include a vertex in the solution or make it forbidden.\n\n\n\n\n\n\nProblem 1.7 Degree 3 vs Leaves in Trees\n\n\n\n\n\nLet T be a tree and let X be the set of leaves in T, and let Y be the set of vertices of degree three or more in T. Show that:\n\\sum_{v \\in Y} (d(v)-2) = |X| - 2,\nusing elementary facts about trees.\n\n\n\n\n\n\n\n\n\nProblem 1.8 Degree Evolution\n\n\n\n\n\nFix an execution path P on an instance (G,\\emptyset,k) (i.e, a path from root to leaf in the branching tree associated with the algorithm when the input is (G,\\emptyset,k)) and consider a vertex v that belongs to F(P), which is to say that the vertex v was included in the set of forbidden vertices at some point during the execution of the algorithm. Denote the instance at this stage of the algorithm by (H,F,k^\\prime). In particular, H is the graph obtained after v was included in F. Let d(v) denote the degree of the vertex v in the original instance G, and let d^\\star(v) denote its degree in the graph H. Which of the following is true?\n\n3 \\leqslant d^\\star(v) \\leqslant d(v)\n3 \\leqslant d^\\star(v) < d(v)\nd^\\star(v) \\geqslant \\min(d(v),3)\nd^\\star(v) > \\min(d(v),3)\n\n\n\n\n\n\n\n\n\n\nProblem 1.9 Successful Execution Paths are Short\n\n\n\n\n\nConsider an execution path P that does not return NO. Show that F(P) \\leqslant 3S(P).\nThis is an optional question that you can skip. It carries no points.\n\n\n\n\n\n\n\n\n\nProblem 1.10 The Final Running Time\n\n\n\n\n\nCan you use the fact from the previous question to come up with an algorithm for CCHS that runs in time O^\\star(16^k)? Note that the O^\\star(\\cdot) notation is used to hide factors that are polynomial in n and k.\nHint: Use the algorithm described previously in the question, but modify it slightly. In particular, if an execution path pushes more than 3S(P) vertices into the forbidden set F, can you terminate it prematurely? Also, what is the cost of the successful execution paths?\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. GreedyHS [2 points]\n\n\n\nLet U=\\left\\{x_1, \\ldots, x_n\\right\\} be an univere of n elements. Suppose we have a family \\mathcal{F} over U that consists of three-sized subsets of U, for example:\n\n\\mathcal{F} = \\left(x_1, x_3, x_4\\right),\\left(x_2, x_3, x_7\\right),\\left(x_1, x_5, x_6\\right)\n\nWe want to find a smallest subset X of U such that for all sets S \\in \\mathcal{F}, S \\cap X \\neq \\emptyset.\nConsider the following algorithm for this problem.\nGreedy(U,F)\n\nInit X = emptyset\nwhile F is non-empty do:\n    Take an arbitrary set S in F.\n    Let x be an element in S\n    X = X U {x}\n    Remove all sets from F that contain x\nend while\nWhat can you say about the worst-case approximation ratio of this algorithm?\n\n\n\n\n\n\n\n\nProblem 3. Knapsack [2 points]\n\n\n\nConsider the knapsack problem. Given a set X=\\left\\{x_1, \\ldots, x_n\\right\\} of n items with weights w\\left(x_i\\right) and values v\\left(x_i\\right), it asks for the highest total value of items we can put into our knapsack such that the total weight of all these items is at most W.\nDescribe a 0/1-LP that models the problem correctly.\n\n\n\n\n\n\n\n\nProblem 4. Rectangle Covering [4 Points]\n\n\n\n\n\n\nRectangle Cover Problem Example\n\n\nSuppose we have a set P=\\left\\{p_1, \\ldots, p_n\\right\\} of n points and a set R=\\left\\{r_1 \\ldots, r_m\\right\\} of m rectangles, as in the image above. Each rectangle r_i \\in R has a certain cost c_i>0 associated with it. We wish to find a subset S \\subseteq R of rectangles whose cost is minimized such that the rectangles in S together cover all points in P.\nWe wish to model this problem as a 0/1-LP. To this end we introduce a decision variable x_i for each rectangle r_i \\in R, where x_i=1 corresponds to putting rectangle r_i into S and x_i=0 corresponds to not putting r_i into S. otherwise. Furthermore, for a point p_j \\in P, define R\\left(p_j\\right)=\\left\\{r_i \\in R: p_j \\in r_i\\right\\}.\n\n\n\n\n\n\nLP for Rectangle Cover\n\n\n\n\n\nDescribe a 0/1-LP that models the problem correctly.\n\n\n\n\n\n\n\n\n\nLP-based Approximation for Rectangle Cover\n\n\n\n\n\nDescribe a 5-approximation assuming that each point is contained in at most 5 rectangles.\n\n\n\n\n\n\n\n\n\n\n\nProblem 5. Dominating Set Reduction Rule When The Graph has No Short Cycles [2 points]\n\n\n\nSuppose G is a simple, undirected graph that has no cycles of length three or four. Recall that a subset S of vertices of G is called a dominating set if every vertex v of G either belongs to S or has a neighbor in S, in other words, N[v] \\cap S \\neq \\emptyset.\nLet S be a dominating set of G of size at most k, where G is as given above (i.e, G has no triangles and no cycles of length four). Show that if the degree of v is more than k in G, then v \\in S."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/L14.html",
    "href": "courses/2023/02-IITM-AA/quizzes/L14.html",
    "title": "CS614. Advanced Algorithms. L14 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 2. High-Degree Branching for FVS\n\n\n\nApply the same preprocessing steps as in the previous problem.\nLet \\left(v_1, v_2, \\ldots, v_n\\right) be a descending ordering of V(G) according to vertex degrees, i.e., d\\left(v_1\\right) \\geq d\\left(v_2\\right) \\geq \\ldots \\geq d\\left(v_n\\right). Let V_{3 k}=\\left\\{v_1, \\ldots, v_{3 k}\\right\\}.\nRecall that the minimum vertex degree of G is at least 3. Show that every feedback vertex set in G of size at most k contains at least one vertex of V_{3 k}."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/L02.html",
    "href": "courses/2023/02-IITM-AA/quizzes/L02.html",
    "title": "CS614. Advanced Algorithms. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/L03.html",
    "href": "courses/2023/02-IITM-AA/quizzes/L03.html",
    "title": "CS614. Advanced Algorithms. L03 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Partition Matroid\n\n\n\nShow that the exchange axiom holds for the Partition Matroid defined in class.\n\n\n\n\n\n\n\n\nProblem 2. Representing the Graphic Matroid\n\n\n\nThe graphic matroid of a graph G can be represented by the following matrix: we have one row for each vertex, and one column for each edge. The column for edge e has +1 in the row for one endpoint, -1 in the row for the other endpoint, and 0 elsewhere; the choice of which endpoint to give which sign is arbitrary.\nArgue that this is a valid representation (i.e, that the forests correspond to linearly independent columns and the subsets of edges that have cycles in them correspond to dependent columns)."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/L07.html",
    "href": "courses/2023/02-IITM-AA/quizzes/L07.html",
    "title": "CS614. Advanced Algorithms. L07 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the textbook on Parameterized Algorithms by Marek Cygan, Fedor V. Fomin, Łukasz Kowalik, Daniel Lokshtanov, Dániel Marx, Marcin Pilipczuk, Michał Pilipczuk, and Saket Saurabh.\n\n\n\n\n\n\n\n\nProblem 1. Cluster Vertex Deletion\n\n\n\nIn the Cluster Vertex Deletion problem, we want to know if a simple undirected graph G has a subset S of at most k vertices such that G \\setminus S is a disjoint union of cliques.\n\n\n\n\n\n\nProblem 1.1 A Branching Algorithm\n\n\n\nDesign a 3^k \\cdot n^{\\mathcal{O}(1)} algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nDesign a 3-approximation algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\n\n\nProblem 2. Don’t Satisfy Too Much!\n\n\n\nIn the MIN-2-SAT problem, we are given a 2 -CNF formula \\phi and an integer k, and the objective is to decide whether there exists an assignment for \\phi that satisfies at most k clauses.\nShow that MIN-2-SAT can be solved in time 2^k n^{\\mathcal{O}(1)}."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/L13.html",
    "href": "courses/2023/02-IITM-AA/quizzes/L13.html",
    "title": "CS614. Advanced Algorithms. L13 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. FVS: is this FPT?\n\n\n\nRecall the following branching algorithm for Feedback Vertex Set (FVS) discussed in class:\n\nPreprocess to eliminate vertices of degree at most two, resulting in an equivlaent multigraph.\nPreprocess to force vertices with self-loops in the solution and adjust the budget as appropriate.\nIf a pair of vertices have more than two edges between them, delete all but two of these edges.\nSTOP if the graph is a forest or if we are out of budget.\nFind a shortest cycle and branch on all its vertices.\n\nSince a graph of minimum degree three that is not acyclic always has a cycle of length O(\\lg n), this algorithm has a running time of O^\\star((\\lg n)^k). Argue that this running time in fact shows that FVS is FPT in k."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/L12.html",
    "href": "courses/2023/02-IITM-AA/quizzes/L12.html",
    "title": "CS614. Advanced Algorithms. L12 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. List Coloring\n\n\n\nIn the List Coloring problem, we are given a graph G and for each vertex v \\in V(G) there is a set (also called a list) of admissible colors L(v) \\subseteq N. The goal is to verify whether it is possible to find a proper vertex coloring c: V(G) \\rightarrow \\mathbb{N} of G such that for ever y vertex v we have c(v) \\in L(v). In other words, L(v) is the set of colors allowed for v.\nShow a 2^n n^{\\mathcal{O}(1)}-time algorithm for List Coloring.\nHint. Read Theorem 10.8 from the Parameterized Algorithms text.\n\n\n\n\n\n\n\n\nProblem 2. Triangle Packing\n\n\n\nIn the Triangle Packing problem, we are given an undirected graph G and a positive integer k, and the objective is to test whether G has k-vertex disjoint triangles. Using color coding show that the problem admits an algorithm with running time 2^{O(k)} n^{O(1)}."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/L06.html",
    "href": "courses/2023/02-IITM-AA/quizzes/L06.html",
    "title": "CS614. Advanced Algorithms. L06 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the Coursera course on Approximation Algorithms taught by Mark de Berg.\n\n\n\n\n\n\n\n\nProblem 1. Changing the threshold\n\n\n\nConsider the algorithm LPAPX-WVC from the class.\n\n\n\n\n\n\nProblem 1.1 Increasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 2/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 1/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. Changing the rounding scheme\n\n\n\nConsider a different rounding strategy for the LP relaxation of the vertex cover problem. Instead of rounding up every vertex whose value is at least 0.5 after running the LP, we do the following:\nWe look at every edge, and then we round up the variable of the endpoint with the highest value, where in case of ties we take the endpoint with the highest index.\nIn other words, if the vertex set is V=\\left\\{v_1, \\ldots, v_n\\right\\} and we denote the associated variable of v_i by x_i then the cover C is computed as follows:\nC:=\\left\\{v_i \\in V:\\right. there is an edge \\left(v_i, v_j\\right) such that \\left(x_i>x_j\\right) or \\left(x_i=x_j\\right. and \\left.\\left.i>j\\right)\\right\\}\nWhich statement is true?\n\nThis does not work, because we might report an invalid solution.\nThis gives a valid solution, but the approximation ratio becomes worse.\nThis gives a valid solution, and in fact the solution is always exactly the same as in the original rounding scheme.\nThis gives a valid solution. We sometimes report a better solution than in the original rounding scheme, but the approximation ratio of the algorithm is still more than 2 - \\epsilon for any \\epsilon > 0.\nThis gives a valid solution, and the approximation ratio of the algorithm becomes 3/2.\n\n\n\n\n\n\n\n\n\nProblem 3. Lower Bound\n\n\n\nSuppose you have created an algorithm for a certain problem using LP relaxation and you want to say something about its approximation ratio. Which lower bound on the optimal solution can you use?\n\nThe solution to the 0/1-LP.\nThe solution to the relaxed LP.\nDepends on the problem.\n\n\n\n\n\n\n\n\n\nProblem 4. Integrality Gap\n\n\n\nWhat is the integrality gap of the vertex-cover LP for the complete graph on n vertices, where all vertices have weight 1?"
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/L10.html",
    "href": "courses/2023/02-IITM-AA/quizzes/L10.html",
    "title": "CS614. Advanced Algorithms. L10 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Set Cover: The Greedy Bound is Tight\n\n\n\nWe argued in class that the greedy approach to solving the unweighted Set Cover problem achieves an approximation ratio of O(H_n). Argue that this bound is tight, i.e, come up with examples where the algorithm picks sets in a manner that the cost of the solution is roughly H_n worse than optimal.\n\n\n\n\n\n\n\n\nProblem 2. Set Cover and Related Problems\n\n\n\n\nShow that Vertex Cover is a special case of Set Cover.\nAlso show that Dominating Set and Set Cover are equivalent (i.e, Set Cover can be reduced to Dominating Set and vice versa)."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/L04.html",
    "href": "courses/2023/02-IITM-AA/quizzes/L04.html",
    "title": "CS614. Advanced Algorithms. L04 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Matroid Intersection Example\n\n\n\nConsider a directed graph D=(V, E \\subseteq V \\times V). A set T \\subseteq E is an arborescence (oriented forest) if:\n\nT does not contain a cycle (ignoring directions of edges).\nEvery vertex in V has at most one incoming edge.\n\nAn arborescence T with |T|=n-1 will have one incoming edge incident on each node except one. If we denote this special node as root, this is an oriented spanning tree as shown in the figure.\n\n\n\nAn example arborescence.\n\n\nConsider the underlying undirected graph G_D = (V,E) associated with D (this is the graph obtained by “erasing the arrows” in D). Consider the universe given by E. Suggest two matroids {\\mathcal M}_1 and {\\mathcal M}_2 for which set of arborescences is given by the sets independent in both {\\mathcal M}_1 and {\\mathcal M}_2.\nHint: these are both matroids seen in class. Further, you might find it useful to partition E into |V| many parts as follows — the part P_v contains all edges that are incoming arcs for the vertex v in D. Can you define a matroid based on this partition?\nDescribe {\\mathcal M}_1 and {\\mathcal M}_2.\n\n\n\n\n\n\n\n\nProblem 2. Maker-Breaker Game\n\n\n\nTwo players take turns removing edges from an undirected graph until there are no edges left.\nPlayer 2 wins if the edges they remove contains a spanning tree, player 1 wins if the set of edges they remove would disconnect the original graph.\n\nIs it true that exactly one player wins this game? In other words, is the following statement true?\n\n“It is NOT the case that after the game has been played, both players can claim a win.”\n\nYes\nNo\n\n\nWhich player wins on a path?\n\n\nPlayer 1\nPlayer 2\n\n\nWhich player wins on a complete graph?\n\n\nPlayer 1\nPlayer 2\n\n\nComplete this sentence: player 2 has the winning strategy if and only if the graph contains BLANK.\n\n(No marks for answering this question, take your best guess :) )"
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/L05.html",
    "href": "courses/2023/02-IITM-AA/quizzes/L05.html",
    "title": "CS614. Advanced Algorithms. L05 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Approximate Vertex Cover\n\n\n\nGive an example of a graph where the 2-approximate solution (via maximal matchings) is worse than the optimal one. Even just slightly worse is enough :)\n\n\n\n\n\n\n\n\nProblem 2. Approximate Independent Set\n\n\n\nSince the complement of a vertex cover is an independent set, you might be tempted to think that the approximation discussed in class also approximates independent set. In particular, consider the following algorithm for independent set:\n\nRun the 2-approximation for vertex cover discussed in class, let the output be S.\nLet I := V(G) \\setminus S.\nIf I = \\emptyset, then let v \\in V(G) be an arbitrary vertex; set I := \\{v\\}.\n\nLet:\n\np denote the size of a largest independent set in G\nq denote the size of the set obtained by taking the complement of the output of the 2-approximation discussed in class.\nr denote \\max(q,1)\n\nNote that r is the size of the independent set output by the algorithm above.\nCome up with a graph where p can be a factor of cn larger than r for some constant c.\n\n\n\n\n\n\n\n\nProblem 3. Vertex Cover Matroid\n\n\n\nDo the set of vertex covers in a graph G form a matroid over the universe V(G)? If not, select the axiom that fails:\n\nExchange Axiom\nHereditary Axiom\nVertex covers do form a matroid"
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/A06.html",
    "href": "courses/2023/02-IITM-AA/quizzes/A06.html",
    "title": "CS614. Advanced Algorithms. L06 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the Coursera course on Approximation Algorithms taught by Mark de Berg.\n\n\n\n\n\n\n\n\nProblem 1. Changing the threshold\n\n\n\nConsider the algorithm LPAPX-WVC from the class.\n\n\n\n\n\n\nProblem 1.1 Increasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 2/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nSuppose that instead of putting a vertex v_i into the cover when x_i \\geqslant 1/2, we put v_i into the cover when x_i \\geqslant 1/3. What happens?\n\nWe still get a valid solution, and the algorithm remains a 2-approximation.\nWe still get a valid solution, and the algorithm becomes a (3/2)-approximation.\nWe still get a valid solution, and the algorithm becomes a 3-approximation.\nWe may no longer get a valid solution.\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf we increase the threshold t beyond 0.5, then the output may not even be a vertex cover: for example, consider the example of a complete graph where the LPOPT sets all variables to 0.5: in this case our output will be the empty set with any threshold higher than 0.5.\nIf we decrease the threshold t below 0.5, then the output will be a vertex cover — indeed, if any edge (u,v) is uncovered, then both u and v were set to values less than t, and in particular less than 0.5, so we will violate our edge constraint just as we do when working with a threshold of 0.5. However, by choosing a lower value, we worsen the approximation ratio: in particular, if t = 1/3 then the output is a 3-approximation.\n\n\n\n\n\n\n\n\n\nProblem 2. Changing the rounding scheme\n\n\n\nConsider a different rounding strategy for the LP relaxation of the vertex cover problem. Instead of rounding up every vertex whose value is at least 0.5 after running the LP, we do the following:\nWe look at every edge, and then we round up the variable of the endpoint with the highest value, where in case of ties we take the endpoint with the highest index.\nIn other words, if the vertex set is V=\\left\\{v_1, \\ldots, v_n\\right\\} and we denote the associated variable of v_i by x_i then the cover C is computed as follows:\nC:=\\left\\{v_i \\in V:\\right. there is an edge \\left(v_i, v_j\\right) such that \\left(x_i>x_j\\right) or \\left(x_i=x_j\\right. and \\left.\\left.i>j\\right)\\right\\}\nWhich statement is true?\n\nThis does not work, because we might report an invalid solution.\nThis gives a valid solution, but the approximation ratio becomes worse.\nThis gives a valid solution, and in fact the solution is always exactly the same as in the original rounding scheme.\nThis gives a valid solution. We sometimes report a better solution than in the original rounding scheme, but the approximation ratio of the algorithm is still more than 2 - \\epsilon for any \\epsilon > 0.\nThis gives a valid solution, and the approximation ratio of the algorithm becomes 3/2.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe solution is valid: indeed, let (u,v) be an edge, and recall that the algorithm worked as follows:\nWe look at every edge, \nand then we round up the variable of the endpoint with the highest value, \nwhere in case of ties we take the endpoint with the highest index. \nSince one of the endpoints was rounded up, the edge is covered; and this is evidently true of every edge.\nThe solution with respect to this rounding may be better than the threshold-based rounding: for example, consider again a complete graph where the LPOPT sets all variables to 1/2: the threshold-based rounding leads to a solution of cost n, while the cost here will be strictly less.\nHowever, to see that the approximation ratio of the algorithm is still more than 2 - \\epsilon for any \\epsilon > 0, consider, for example, a cycle on n vertices: one can choose a suitably large value of n to bring the approximation ratio arbitrarily close to 2.\n\n\n\n\n\n\n\n\n\nProblem 3. Lower Bound\n\n\n\nSuppose you have created an algorithm for a certain problem using LP relaxation and you want to say something about its approximation ratio. Which lower bound on the optimal solution can you use?\n\nThe solution to the 0/1-LP.\nThe solution to the relaxed LP.\nDepends on the problem.\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n\nAs was clarified in class, this question is in the context of minimization problems.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe solution to the relaxed LP is a useful lower bound for the OPT. The value of the OPT for the 0/1-LP is exactly equal to the OPT (in a presumed exact formulation of the problem) and does not, by itself, provide information about the behavior of the relaxed LP.\n\n\n\n\n\n\n\n\n\nProblem 4. Integrality Gap\n\n\n\nWhat is the integrality gap of the vertex-cover LP for the complete graph on n vertices, where all vertices have weight 1?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nILPOPT = n-1 and LPOPT = n/2; so the integrality gap is 2 \\cdot (n-1)/n = 2(1 - \\frac{1}{n})."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/A07.html",
    "href": "courses/2023/02-IITM-AA/quizzes/A07.html",
    "title": "CS614. Advanced Algorithms. L07 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgement\n\n\n\nThe questions in this problem set are adapted from the textbook on Parameterized Algorithms by Marek Cygan, Fedor V. Fomin, Łukasz Kowalik, Daniel Lokshtanov, Dániel Marx, Marcin Pilipczuk, Michał Pilipczuk, and Saket Saurabh.\n\n\n\n\n\n\n\n\nProblem 1. Cluster Vertex Deletion\n\n\n\nIn the Cluster Vertex Deletion problem, we want to know if a simple undirected graph G has a subset S of at most k vertices such that G \\setminus S is a disjoint union of cliques.\n\n\n\n\n\n\nProblem 1.1 A Branching Algorithm\n\n\n\nDesign a 3^k \\cdot n^{\\mathcal{O}(1)} algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\nProblem 1.2 Decreasing the threshold\n\n\n\nDesign a 3-approximation algorithm for Cluster Vertex Deletion.\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAs discussed in class, the induced path on three vertices is a forbidden substructure for a cluster graph. We state and prove this fact here for completeness.\n\nClaim. A graph G is a disjoint union of cliques if and only if it does not contain a path on three vertices as an induced subgraph.\nProof (sketch). Suppose G is a disjoint union of cliques, and for the sake of contradiction, suppose it has an induced path on vertices x,y,z with the edges being between x and y, and y and z. Note that since this is an induced path, there is no edge between x and z. Since every component of G is a clique, we know that x and z must be in different components. However, there is a path from x to z via y, which is a contradiction.\nSuppose G does not contain a path on three vertices as an induced subgraph. Again, for the sake of contradiction, suppose G has a connected component that is not a clique. Let (u,v) be a non-edge in this component. Let P be a shortest path between u and v consisting of the vertices:\nP := \\{u, w_1, \\ldots, w_t, \\ldots v\\}.\nNotice that t \\geqslant 1, otherwise (u,v) is an edge. Further, notice that u, w_1, w_2 forms an induced path of length three1 (if (u,w_2) was an edge then we have a shorter path by omitting w_1, contradicting our assumption that P is a shortest path between u and v). This contradicts our assumption.\n\nBased on this, we have the following algorithm:\nCVD(G,k):\n    If k <= 0 and G has an induced P3 - RETURN NO\n    If k >= 0 and G is a cluster graph - RETURN YES\n\n    Let a,b,c be vertices such that ab and bc are edges and ac is not an edge.\n\n    Return (CVD(G-a,k-1) OR CVD(G-b,k-1) OR (G-c,k-1))\nOne can obtain a 3-approximation by enumerating a maximal collection of disjoint induced P_3’s and including all vertices from the collection in the solution. If the collection has size t, we know that any solution (and in particular, the optimal one) must contain at least t vertices and the output has at most 3t vertices. The algorithm is summarized below:\nCVD-3-Approx(G):\n    Init S = emptyset\n\n    While there is an induced P3 = (x,y,z) in G:\n        include (x,y,z) in S\n        G = G - (x,y,z)\n\n    return S\n\n\n\n\n\n\n\n\n\nProblem 2. Don’t Satisfy Too Much!\n\n\n\nIn the MIN-2-SAT problem, we are given a 2-CNF formula \\phi and an integer k, and the objective is to decide whether there exists an assignment for \\phi that satisfies at most k clauses.\nShow that MIN-2-SAT can be solved in time 2^k n^{\\mathcal{O}(1)}.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf there is a variable x that occurs only positively in \\phi, we claim that there exists an optimal assignment that sets it to 0. Indeed, let \\tau be an assignment that sets x to 1. Let \\tau_x be the assignment obtained from \\tau by flipping the value of x from 1 to 0. Note that the clauses that do not contain the variable x are either satisfied or falsified in both \\tau and \\tau_x. For clauses that contain x, it is possible that they are satisfied by \\tau but not by \\tau_x, but not vice versa. Therefore, \\tau_x falsifies at least as many clauses as \\tau, and we are done.\nBased on this, our algorithm proceeds as follows:\nif there is a variable x that occurs only as a positive literal:\n    set x to 0\nif there is a variable x that occurs only as a negated literal:\n    set x to 1\nThe argument for the negated occurrences is symmetric to the one we have for positive literals.\nOnce we perform this preprocessing, assuming that have clauses remaining, we have the following guarantee:\n\nEvery variable has at least one positive and one negated occurrence.\n\nNow we can branch exhuastively on the settings of variables; with the promise that either setting of the variable reduces our budget by at least one. The overall algorithm is summarized in the following pseudocode:\nMINSAT(phi,k):\n    if there is a variable x that occurs only as a positive literal:\n        set x to 0\n    if there is a variable x that occurs only as a negated literal:\n        set x to 1\n\n    if phi is empty:\n        return YES\n    if phi is not empty and k <= 0:\n        return NO\n\n    Let x be any variable that occurs in phi.\n    return MINSAT(phi|[x = TRUE],k-1) OR MINSAT(phi|[x = FALSE],k-1)"
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/A05.html",
    "href": "courses/2023/02-IITM-AA/quizzes/A05.html",
    "title": "CS614. Advanced Algorithms. L05 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Approximate Vertex Cover\n\n\n\nGive an example of a graph where the 2-approximate solution (via maximal matchings) is worse than the optimal one. Even just slightly worse is enough :)\n\n\n\n\n\n\n\n\nFollow up question\n\n\n\n\n\nWhat are examples of graphs where the 2-approximate solution via maximal matchings is close to optimal? The empty and complete graphs come to mind, are there others?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nEven if the input graph is an edge, a star, or a matching, the 2-approximate solution is already worse by a factor of two.\n\n\n\n\n\n\n\n\n\nProblem 2. Approximate Independent Set\n\n\n\nSince the complement of a vertex cover is an independent set, you might be tempted to think that the approximation discussed in class also approximates independent set. In particular, consider the following algorithm for independent set:\n\nRun the 2-approximation for vertex cover discussed in class, let the output be S.\nLet I := V(G) \\setminus S.\nIf I = \\emptyset, then let v \\in V(G) be an arbitrary vertex; set I := \\{v\\}.\n\nLet:\n\np denote the size of a largest independent set in G\nq denote the size of the set obtained by taking the complement of the output of the 2-approximation discussed in class.\nr denote \\max(q,1)\n\nNote that r is the size of the independent set output by the algorithm above.\nCome up with a graph where p can be a factor of cn larger than r for some constant c.\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n\nIt was not explicit in the question: G denotes the input graph and n denotes the number of vertices in G.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet n = 2p and consider a complete bipartite graph K_{p,p}. The optimal independent set has size p but the algorithm above returns 1.\n\n\n\n\n\n\n\n\n\nProblem 3. Vertex Cover Matroid\n\n\n\nDo the set of vertex covers in a graph G form a matroid over the universe V(G)? If not, select the axiom that fails:\n\nExchange Axiom\nHereditary Axiom\nVertex covers do form a matroid\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nA subset of a vertex cover need not be a vertex cover; and in particular, the empty set is also not a vertex cover (although this axiom was not offered as an option)."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/A04.html",
    "href": "courses/2023/02-IITM-AA/quizzes/A04.html",
    "title": "CS614. Advanced Algorithms. L04 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Matroid Intersection Example\n\n\n\nConsider a directed graph D=(V, E \\subseteq V \\times V). A set T \\subseteq E is an arborescence (oriented forest) if:\n\nT does not contain a cycle (ignoring directions of edges).\nEvery vertex in V has at most one incoming edge.\n\nAn arborescence T with |T|=n-1 will have one incoming edge incident on each node except one. If we denote this special node as root, this is an oriented spanning tree as shown in the figure.\n\n\n\nAn example arborescence.\n\n\nConsider the underlying undirected graph G_D = (V,E) associated with D (this is the graph obtained by “erasing the arrows” in D). Consider the universe given by E. Suggest two matroids {\\mathcal M}_1 and {\\mathcal M}_2 for which set of arborescences is given by the sets independent in both {\\mathcal M}_1 and {\\mathcal M}_2.\nHint: these are both matroids seen in class. Further, you might find it useful to partition E into |V| many parts as follows — the part P_v contains all edges that are incoming arcs for the vertex v in D. Can you define a matroid based on this partition?\nDescribe {\\mathcal M}_1 and {\\mathcal M}_2.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTake {\\mathcal M}_1 to be the graphic matroid and {\\mathcal M}_2 to be the partition matroid with all budgets set to one. Membership in the first matroid ensures that there are no underlying undirected cycles and membership in the second matroid ensures that every vertex in V has at most one incoming edge.\n\n\n\n\n\n\n\n\n\nProblem 2. Maker-Breaker Game\n\n\n\nTwo players take turns removing edges from an undirected graph until there are no edges left.\nPlayer 2 wins if the edges they remove contains a spanning tree, player 1 wins if the set of edges they remove would disconnect the original graph.\n\nIs it true that exactly one player wins this game? In other words, is the following statement true?\n\n“It is NOT the case that after the game has been played, both players can claim a win.”\n\nYes\nNo\n\n\nWhich player wins on a path?\n\n\nPlayer 1\nPlayer 2\n\n\nWhich player wins on a complete graph?\n\n\nPlayer 1\nPlayer 2\n\n\nComplete this sentence: player 2 has the winning strategy if and only if the graph contains BLANK.\n\n(No marks for answering this question, take your best guess :) )\n\n\n\n\n\n\n\n\nHeads Up\n\n\n\nPart (3) was under-specified: the second player wins on complete graphs with at least four vertices but the first player has easy wins if the graph is an edge (a complete graph on two vertices) or a triangle (a complete graph on three vertices).\nGrading note: everyone recieves a full grade for this question.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSuppose both players indeed win. Let us delete the edges chosen by the first player. What is left is: (a) the set of edges chosen by the second player and (b) a disconnected graph. But the second player also won, so this set contains a spanning tree. A graph cannot simultaneously admit a spanning tree and be disconnected, this is a contradiction when applied on the graph induced by the leftover edges.\nPlayer 1 can choose any edge in the first step and he already wins.\nAssume that the graph has at least four vertices. Player 2 wins because notice that no matter how the first player plays the first (n-1) steps, it is not enough to disconnect the graph. By chosing edges carefully1, Player 2 can ensure that (s)he has booked a spanning tree already within the first (n-1) moves.\nNo spoilers on this one (yet)."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/A03.html",
    "href": "courses/2023/02-IITM-AA/quizzes/A03.html",
    "title": "CS614. Advanced Algorithms. L03 Solutions.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Partition Matroid\n\n\n\nShow that the exchange axiom holds for the Partition Matroid defined in class.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet (U := U_1 \\cup \\cdots \\cup U_\\ell, \\mathcal{F}) be a partition matroid with budgets a_1,\\ldots,a_\\ell.\nSuppose S, T \\subseteq U_1 \\cup \\cdots \\cup U_\\ell such that S,T \\in \\mathcal{F}, and |T| > |S|.\nThen, there exists at least one part U_i where |T \\cap U_i| > |S \\cap U_i|. Now let x \\in (T \\setminus S) \\cap U_i. Note that S \\cup \\{x\\} \\in \\mathcal{F} since:\n\\begin{equation*}\n    |S \\cap U_j| =\n    \\begin{cases}\n      < a_j & \\text{if } j = i,\\\\\n      \\leqslant a_j & \\text{otherwise}.\n    \\end{cases}\n\\end{equation*}\nand therefore:\n\\begin{equation*}\n    |(S \\cup \\{x\\}) \\cap U_j| =\n    \\begin{cases}\n      |S \\cap U_i| + 1 \\leqslant a_j & \\text{if } j = i,\\\\\n      \\leqslant a_j & \\text{otherwise}.\n    \\end{cases}\n\\end{equation*}\n\n\n\n\n\n\n\n\n\nProblem 2. Representing the Graphic Matroid\n\n\n\nThe graphic matroid of a graph G can be represented by the following matrix: we have one row for each vertex, and one column for each edge. The column for edge e has +1 in the row for one endpoint, -1 in the row for the other endpoint, and 0 elsewhere; the choice of which endpoint to give which sign is arbitrary.\nArgue that this is a valid representation (i.e, that the forests correspond to linearly independent columns and the subsets of edges that have cycles in them correspond to dependent columns).\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSuppose we have a subset of edges that contains a cycle. For simplicity, suppose the cycle is given by:\n\\{pq, qr, rs, st\\}\nNow consider the column vectors c_p, c_q, c_r, c_s:\n\\begin{bmatrix}\nc_p & c_q & c_r & c_s\\\\\n1 & 0 & 0 & -1 \\\\\n-1 & 1 & 0 & 0 \\\\\n0 & -1 & -1 & 0 \\\\\n0 & 0 & 1 & 1\n\\end{bmatrix}\nNote that:\n1 \\cdot c_p + 1 \\cdot c_q + (-1) \\cdot c_r + 1 \\cdot c_s\nis a linear combination with constants (1,1,-1,1) that establish that these vectors are linearly dependent. In general, write down the columns in the order in which they appear on the cycle. If the first entry in the column is not +1, then multiply the column by -1 (except the last column, where we do the reverse: if the first entry is +1, then we multiply the column by -1). This way, we have a situation where every row contains exactly one +1 entry and one -1 entry, and the linear combination sums to 0.\nThis shows that dependent subsets of the matroid correspond to linearly dependent columns of M.\nTo see that independent subsets S \\subseteq E(G) correspond to linearly independent columns, consider the set of columns that correspond to S:\n\\{c_e ~|~ e \\in S\\    }\nSuppose, for the sake of contradiction, that there was some non-trivial linear combination of these columns that vanished, i.e, for non-empty subset T \\subseteq S, there exist constants \\{\\alpha_e\\}_{e \\in T} where:\n\\sum_{e \\in T} \\alpha_e c_e = 0\nBut now consider the subgraph consisting of the edges in T. Note that the minimum degree of T must be two (suppose u \\in T has degree one, and its unique neighbor is v: then consider the entry in the row corresponding to u in the column corresponding to the edge uv: this is non-zero and there is no cancelation possible in the sum above). However, a graph whose minimum degree is two cannot be acyclic, and this is a contradiction."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/A02.html",
    "href": "courses/2023/02-IITM-AA/quizzes/A02.html",
    "title": "CS614. Advanced Algorithms. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe circuits of the graphic matroid are the cycles of the graph G.\n\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c,d\\} with the edges \\{ab, cd, ad\\}.\nThere are two matchings in this instance:\n\nM_1 := \\{ab,cd\\}\nM_2: \\{ad\\}\n\nHowever, although |M_1| > |M_2|, neither of the edges from M_1 can be added to M_2.\n\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c\\} with the edges \\{ab, ac\\}. There are two independent sets: S_1 := \\{b,c\\} and M_2: \\{a\\}, but neither of the vertices from S_1 can be added to S_2.\n\nIf the independent sets formed a matroid the problem of finding a maximum independent set would not be NP-complete. \n— Comment in class"
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/L08.html",
    "href": "courses/2023/02-IITM-AA/quizzes/L08.html",
    "title": "CS614. Advanced Algorithms. L08 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Better Approximation given a k-coloring\n\n\n\nGiven a k-coloring of a graph G, show that we can find a vertex cover which is a 2\\bigl(1−\\frac{1}{k}\\bigr) approximation.\nHint: use the k-coloring on the vertices of V_{1/2}.\n\n\n\n\n\n\n\n\nProblem 2. Point Line Cover\n\n\n\nIn the Point Line Cover problem, we are given a set of n points in the plane and an integer k, and the goal is to check if there exists a set of k lines on the plane that contain all the input points.\nShow a kernel for this problem with \\mathcal{O}\\left(k^2\\right) points."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/L09.html",
    "href": "courses/2023/02-IITM-AA/quizzes/L09.html",
    "title": "CS614. Advanced Algorithms. L09 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Dominating Set\n\n\n\nA dominating set of a graph G is a subset of vertices S such that every vertex in G either belongs to S or has a neighbor in S.\nSuppose you have an instance of dominating set given by (G,k), which is a YES-instance if and only if G has a dominating set of size at most k.\nIs the following reduction rule safe?\nRR. If d(v) > k, then return (G-v,k-1).\n( ) Yes (X) No\nBriefly justify your answer:\n|____|\n\n\n\n\n\n\n\n\nProblem 2. Connected Vertex Cover\n\n\n\nA connected vertex cover of a graph G is a subset of vertices S such that: (a) S is a vertex cover of G, and (b) G[S] is a connected subgraph of G.\nSuppose you have an instance of connected vertex cover given by (G,k), which is a YES-instance if and only if G has a connected vertex cover of size at most k.\n\n\n\n\n\n\nProblem 2.1 Connected Vertex Cover I.\n\n\n\nDesign a \\mathcal{O}(2^k) vertex kernel for Connected Vertex Cover.\nHint: What can you say about high degree vertices? How many can G have?\nFollow up hint: What can you say about two vertices that have the same neighbourhood among the high-degree vertices?\n\n\n\n\n\n\n\n\nProblem 2.2 Connected Vertex Cover II.\n\n\n\nObserve that the kernelization argument that we made for Vertex Cover does not work as-is for connected vertex cover. Recall that the reduction rules were the following:\n\nR0. If k \\leqslant 0 and E is non-empty, return a trivial no-instance.\nR1. If k \\geqslant 0 and E is empty, return a trivial yes-instance.\nR2. If v is a degree zero vertex, return (G\\setminus \\{v\\},k), i.e, delete v from G and keep the budget the same.\nR3. If v is vertex whose degree is more than k, return (G\\setminus \\{v\\},k-1), i.e, delete v from G and reduce the budget by one.\n\nWhere does it fail? Justify, if possible, with an example."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/L19.html",
    "href": "courses/2023/02-IITM-AA/quizzes/L19.html",
    "title": "CS614. Advanced Algorithms. L19 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Bin Packing\n\n\n\nConsider the bin-packing problem:\nInput: n items with sizes a_1 \\cdots a_n respectively, a positive integer B (bin capacity) and a positive integer k (number of bins). Question: Is there a partition of the set \\{1 \\cdots n\\} into sets S_1, \\ldots, S_k such that for each i \\in\\{1 \\cdots k\\} we have that \\sum_{j \\in S_i} a_j \\leq B?\nShow that Bin Packing is NP-complete.\n\n\n\n\n\n\n\n\nProblem 2. BOX-DEPTH\n\n\n\nConsider the following problem, called BOX-DEPTH: Given a set of n axisaligned rectangles in the plane, how big is the largest subset of these rectangles that contain a common point?\n\nDescribe a polynomial-time reduction from BOX-DEPTH to MAXCLIQUE.\nDescribe and analyze a polynomial-time algorithm for BOX-DEPTH. [Hint: O\\left(n^3\\right) time should be easy, but O(n \\log n) time is possible.]\nWhy don’t these two results imply that \\mathrm{P}=\\mathrm{NP}?"
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/L18.html",
    "href": "courses/2023/02-IITM-AA/quizzes/L18.html",
    "title": "CS614. Advanced Algorithms. L18 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. 3-Hitting Set\n\n\n\nObtain an algorithm for 3-Hitting Set running in time 2.4656^k n^{\\mathcal{O}(1)} using iterative compression.\n\n\n\n\n\n\n\n\nProblem 2. d-Hitting Set\n\n\n\nGeneralize the algorithm from the previous problem to obtain an algorithm for d-Hitting Set running in time ((d-1)+0.4656)^k n^{\\mathcal{O}(1)}."
  },
  {
    "objectID": "materials/algorithms/index.html",
    "href": "materials/algorithms/index.html",
    "title": "Advanced Algorithms",
    "section": "",
    "text": "Lecture Notes\n\n\non Advanced Algorithms\n\n\n \n\nThese are running notes on selected topics in Advanced Algorithms.\nI have been developing these as a part of my course on Advanced Algorithms that I teach at both IIT Gandhinagar and also as a part of the IIT Madras online BS program. Please see the course websites for additional materials (e.g, problem sets).\nAt the time of this writing these notes are largely raw and informal. They certainly do not substitute — but hopefully do supplement — an actual textbook :) I do borrow heavily from Algorithms by Erickson.\nIf you have any general comments or questions, please leave them below. Thanks!"
  },
  {
    "objectID": "materials/algorithms/greedy/index.html",
    "href": "materials/algorithms/greedy/index.html",
    "title": "Greedy Algorithms",
    "section": "",
    "text": "It is perhaps not often that greed is good, but in the context of the problems that we encounter in this chapter, we are going to make greedy look good! Read on to find out more about:\n\nFiles on a Tape\nDance Classes\nStable Marriages"
  },
  {
    "objectID": "materials/algorithms/greedy/scheduling/index.html",
    "href": "materials/algorithms/greedy/scheduling/index.html",
    "title": "2. A Scheduling Problem",
    "section": "",
    "text": "Acknowledgements\n\n\n\nThis write up is borrowed (with minor adaptations) from Chapter 4 of Jeff Erickson’s textbook on Algorithms.\n\n\n\nThe Problem\nSuppose you decide to sign up for dance classes, and a dance academy next door offers a bunch of classes, but only on Saturdays. You cannot take two classes whose timings overlap: for example, in the example shown in the figure below, the Bollywood and Ballet classes are clashing, so you would have to pick one between the two.\n\nMore formally:\n\nSuppose you are given two arrays S[1 .. n] and F[1 .. n] listing the start and finish times of each class; to be concrete, we can assume that 0 \\leq S[i]<F[i] \\leq M for each i, for some value M.\nYour task is to choose the largest possible subset X \\in\\{1,2, \\ldots, n\\} so that for any pair i, j \\in X, either S[i]>F[j] or S[j]>F[i].\n\nWe can illustrate the problem by drawing each class as a rectangle whose left and right x-coordinates show the start and finish times. The goal is to find a largest subset of rectangles that do not overlap vertically, as shown below1.\n\nNotice that there are several natural greedy approaches to this problem. A template for a greedy algorithm would look like this:\nrepeat while there is at least one class left:\n- pick a class, say C, that is <<GREEDY CHOICE>>\n- eliminate C and all classes that clash with C from the collection\nHere are some “natural” greedy choices:\n\npick a class that has the shortest duration\npick a class that has the fewest clashes with other classes\npick a class that starts as early as possible\npick a class that finishes as early as possible\n\n\n\n\n\n\n\nGreedy Does Not Work!\n\n\n\nIt turns out that the first three greedy approaches are actually wrong, in the sense that there are examples on which they will fail to produce an optimal schedule. Can you construct these examples?\n\n\nThe intuition for the last option above is that we would like the first class to finish as early as possible, because that leaves us with the largest number of remaining classes. This intuition suggests the following simple greedy algorithm. Scan through the classes in order of finish time; whenever you encounter a class that doesn’t conflict with your latest class so far, take it! Here is some pseudocode that captures this process:\nGreedySchedule(S,F)\n\nsort F and permute S to match \ncount = 1\nX[count] = 1\n\nfor i from 2...n:\n    if S[i]>F[X[count]]\n        count = count +1\n        X[count] = i\nreturn X[1...count]\nA greedy algorithm for finding a maximum set of non-overlapping classes\n\n\nGreedy Works Out\nTo prove that GreedySchedule actually computes the largest conflict-free schedule, we use an exchange argument, similar to the one we used for tape sorting. We are not claiming that the greedy schedule is the only maximal schedule; there could be others. (Can you come with examples to justify this comment?)\nAll we can claim is that at least one of the optimal schedules is the one produced by the greedy algorithm.\n\n\n\n\n\n\nAt least one maximal conflict-free schedule includes the class that finishes first.\n\n\n\nProof: Let f be the class that finishes first. Suppose we have a maximal conflict-free schedule X that does not include f. Let g be the first class in X to finish. Since f finishes before g does, f cannot conflict with any class in the set X \\backslash\\{g\\}. Thus, the schedule X^{\\prime}=X \\cup\\{f\\} \\backslash\\{g\\} is also conflict-free. Since X^{\\prime} has the same size as X, it is also maximal.\n\n\nTo finish the proof, we call on our old friend induction.\n\n\n\n\n\n\nTheorem. The greedy schedule is an optimal schedule.\n\n\n\nProof: Let f be the class that finishes first, and let A be the subset of classes that start after f finishes. The previous lemma implies that some optimal schedule contains f, so the best schedule that contains f is an optimal schedule. The best schedule that includes f must contain an optimal schedule for the classes that do not conflict with f, that is, an optimal schedule for A. The greedy algorithm chooses f and then, by the inductive hypothesis, computes an optimal schedule of classes from A.\n\n\nAnother way to see why greedy works is the following. Consider the finish times of all the greedy choices. Note that every other class contains at least one of these finish times: if not, then there is a class that starts after the i^{th} earliest class to start (among the greedy choices) and finishes before the (i+1)^{th} earliest class to start (among the greedy choices). This means that the choice made by the greedy algorithm in the (i+1)^{th} step was not on brand: a contradiction.\n\nWhy is this observation useful? Well, suppose the greedy algorithm outputs a collection of k classes. Then define the following groups of classes: — the j-th group consists of all classes that are active during the finish time of the j^{th} earliest class to start among the greedy chocies. These groups form a cover, i.e, every class belongs to at least one of these groups because of our observation earlier. Now notice that all classes within any group are mutually clashing, because they are all active at a common time. Therefore, any valid solution cannot pick more than one class from a given group, implying therefore that any solution must have at most k classes. But the greedy outcome has exactly k classes, so this is indeed the best we can hope for.\n\n\nGeneral Patterns\nThe basic structure of this correctness proof is exactly the same as for the tape-sorting problem: an inductive exchange argument.\n\nAssume that there is an optimal solution that is different from the greedy solution.\nFind the “first” difference between the two solutions. - Argue that we can exchange the optimal choice for the greedy choice without making the solution worse (although the exchange might not make it better).\n\nThis argument implies by induction that some optimal solution contains the entire greedy solution, and therefore equals the greedy solution. Sometimes, as in the scheduling problem, an additional step is required to show no optimal solution strictly improves the greedy solution.\n\n\n\n\n\nFootnotes\n\n\nWhy is this optimal?↩︎"
  },
  {
    "objectID": "materials/algorithms/greedy/file-storage/index.html",
    "href": "materials/algorithms/greedy/file-storage/index.html",
    "title": "1. Storing Files on a Tape",
    "section": "",
    "text": "Acknowledgements\n\n\n\nThis write up is borrowed (with minor adaptations) from Chapter 4 of Jeff Erickson’s textbook on Algorithms. The interactive illustrations were generated with assistance from ChatGPT (the May 12 version).\n\n\n\nThe Problem\nSuppose we have a set of n files that we want to store on magnetic tape1. In the future, users will want to read those files from the tape. Reading a file from tape isn’t like reading a file from disk; first we have to fast-forward past all the other files, and that takes a significant amount of time. Let L[1 .. n] be an array listing the lengths of each file; specifically, file i has length L[i]. If the files are stored in order from 1 to n, then the cost of accessing the k th file is\n\n\\operatorname{cost}(k)=\\sum_{i=1}^{k} L[i] .\n\nThe cost reflects the fact that before we read file k we must first scan past all the earlier files on the tape. If we assume for the moment that each file is equally likely to be accessed, then the expected cost of searching for a random file is\n\n\\mathrm{E}[\\operatorname{cost}]=\\sum_{k=1}^{n} \\frac{\\operatorname{cost}(k)}{n}=\\frac{1}{n} \\sum_{k=1}^{n} \\sum_{i=1}^{k} L[i] \\text {. }\n\nIf we change the order of the files on the tape, we change the cost of accessing the files; some files become more expensive to read, but others become cheaper. Different file orders are likely to result in different expected costs. Specifically, let \\pi(i) denote the index of the file stored at position i on the tape. Then the expected cost of the permutation \\pi is\n\n\\mathrm{E}[\\operatorname{cost}(\\pi)]=\\frac{1}{n} \\sum_{k=1}^{n} \\sum_{i=1}^{k} L[\\pi(i)]\n\nWhich order should we use if we want this expected cost to be as small as possible? Try this yourself in the demonstration below. The tape is the grey rectangle, and the files are the colored boxes below it. The widths of the boxes are proportional to the file lengths. Double-click to get a file outside the tape to push it on the tape, and double-click a file on the tape to remove it. Can you match the optimal cost?\n\n\n\n\n\n\n\n\n\nAverage: 0\n\n\nTarget:\n\n\nKeep going until all pieces are on the tape…\n\n\n\nAfter some playing around, you may have come to the conclusion that you should sort the files by increasing length. Indeed, the length of the first file shows up the most frequently in the expression we are trying to optimize, while the length of the last file shows up just once: so it seems clear that the larger files should be pushed to the end.\nHowever — and especially so with greedy approaches — intuition is a tricky beast. The only way to be sure that this order works is to actually prove that it works!\n\n\nGreedy Works Out\n\n\n\n\n\n\nCorrectness of Greedy - I\n\n\n\nLemma. \\mathrm{E}[\\operatorname{cost}(\\pi)] is minimized when L[\\pi(i)] \\leq L[\\pi(i+1)] for all i.\nSuppose L[\\pi(i)]>L[\\pi(i+1)] for some index i. To simplify notation, let a=\\pi(i) and b=\\pi(i+1). If we swap files a and b, then the cost of accessing a increases by L[b], and the cost of accessing b decreases by L[a]. Overall, the swap changes the expected cost by (L[b]-L[a]) / n. But this change is an improvement, because L[b]<L[a]. Thus, if the files are out of order, we can decrease the expected cost by swapping some mis-ordered pair of files.\n\n\nTry dragging the borders below to see how changes in file sizes impacts the average cost.\n\n\n\n105\n\n\n\n\n\n105\n\n\n\n\n\n105\n\n\n\n\n\n105\n\n\n\n\nCurrent Cost: 262.5\n\n\nOptimal Cost: 262.5\n\n\n\nThis is our first example of a correct greedy algorithm. To minimize the total expected cost of accessing the files, we put the file that is cheapest to access first, and then recursively write everything else; no backtracking, no dynamic programming, just make the best local choice and blindly plow ahead. If we use an efficient sorting algorithm, the running time is clearly O(n \\log n), plus the time required to actually write the files. To show that the greedy algorithm is actually correct, we proved that the output of any other algorithm can be improved by some sort of exchange.\n\n\nFrequencies\nLet’s generalize this idea further. Suppose we are also given an array F[1 .. n] of access frequencies for each file; file i will be accessed exactly F[i] times over the lifetime of the tape. Now the total cost of accessing all the files on the tape is\n\n\\Sigma \\cos t(\\pi)=\\sum_{k=1}^{n}\\left(F[\\pi(k)] \\cdot \\sum_{i=1}^{k} L[\\pi(i)]\\right)=\\sum_{k=1}^{n} \\sum_{i=1}^{k}(F[\\pi(k)] \\cdot L[\\pi(i)]) .\n\nAs before, reordering the files can change this total cost. So what order should we use if we want the total cost to be as small as possible? (This question is similar in spirit to the optimal binary search tree problem, but the target data structure and the cost function are both different, so the algorithm must be different, too.)\nWe already proved that if all the frequencies are equal, we should sort the files by increasing size. If the frequencies are all different but the file lengths L[i] are all equal, then intuitively, we should sort the files by decreasing access frequency, with the most-accessed file first.\n\n\n\n\n\n\nFood For Thought\n\n\n\nProve this formally by adapting the proof from the previous discussion.\n\n\nBut what if the sizes and the frequencies both vary? In this case, we should sort the files by the ratio L / F.\n\n\n\n\n\n\nCorrectness of Greedy - II\n\n\n\nLemma. \\Sigma \\operatorname{cost}(\\pi) is minimized when \\frac{L[\\pi(i)]}{F[\\pi(i)]} \\leq \\frac{L[\\pi(i+1)]}{F[\\pi(i+1)]} for all i.\nProof: Suppose L[\\pi(i)] / F[\\pi(i)]>L[\\pi(i+1)] / F[\\pi(i+i)] for some index i. To simplify notation, let a=\\pi(i) and b=\\pi(i+1). If we swap files a and b, then the cost of accessing a increases by L[b], and the cost of accessing b decreases by L[a]. Overall, the swap changes the total cost by L[b] F[a]-L[a] F[b]. But this change is an improvement, because\n\n\\frac{L[a]}{F[a]}>\\frac{L[b]}{F[b]} \\Longleftrightarrow L[b] F[a]-L[a] F[b]<0 .\n\nThus, if any two adjacent files are out of order, we can improve the total cost by swapping them.\n\n\n\n\n\n\n\nFootnotes\n\n\nJust in case you have not heard of them, here’s Wikipedia on magnetic tapes :)↩︎"
  },
  {
    "objectID": "materials/algorithms/greedy/stable-matchings/index.html",
    "href": "materials/algorithms/greedy/stable-matchings/index.html",
    "title": "3. Stable Matchings",
    "section": "",
    "text": "The Problem\nThe problem of pairing up people and/or resources shows up a lot:\n\nMatching students who graduate high school to seats in various colleges.\nMatching students who graduate college to employers for jobs, internships, residencies, and so on.\nGetting actors and actresses to commit to work together for films amidst various constraints.\nMatching organ donors to patients accounting for constraints of compatibility and timing.\nMatching men and women in a dating/marriage market.\n\nWe are going to look at one particular abstraction that captures many of the scenarios above (among others). Suppose we have a set V = \\{m_1, \\ldots, m_n\\} of n men and W = \\{w_1, \\ldots, w_n\\} of n women, where each man (respectively, woman) has a strict and complete ranking over the women (respectively, men). Our goal is to find a matching between the men and the women, which is to say, a bijection between V and W.\nNow, a natural question at this point is: what kind of matchings do we want to find? Unconstrained, there are plenty of matchings that we can choose from. Which one is the “best”?\nUpon a moment’s reflection you might come up with several ideas. We are going to focus on a fundamental game-theoretic approach to identifying what we desire from the matchings we seek. What we will demand of the matching M that we seek is that there is no man and woman who are unmatched in M who prefer each other over their matched partners. To this end, we first define the notion of a blocking pair with respect to M:\n\n\n\n\n\n\nBlocking Pair\n\n\n\nGiven a matching M between n men and n women, if a \\in V and b \\in W, then (a,b) forms a blocking pair if ALL of the following hold:\n\na and b are not matched to each other in M,\na prefers b over M(a),\nb prefers a over M(b)\n\n\n\nThe presence of a blocking pair (a,b) implies that the matching M is unlikely to “sustain”: a and b both have an incentive to break off the alliances suggested by the matching M and “elope” with each other instead. Thus, matchings that have blocking pairs are called unstable.\n\n\n\n\n\n\nUnstable Matching\n\n\n\nA matching M is said to be unstable if there is a blocking pair with respect to M.\n\n\n\n\n\n\n\n\nAn Example of a Matching with no blocking pairs.\n\n\n\n\n\nConsider the preferences given below (where the first column in each row is the ID of the men and the women, and the remaining columns indicate the rank):\n\n\n\nMen\n1\n2\n3\n4\n\n\n\n\n1\n2\n4\n1\n3\n\n\n2\n3\n1\n4\n2\n\n\n3\n2\n3\n1\n4\n\n\n4\n4\n1\n3\n2\n\n\n\n\n\n\nWomen\n1\n2\n3\n4\n\n\n\n\n1\n2\n1\n4\n3\n\n\n2\n4\n3\n1\n2\n\n\n3\n1\n4\n3\n2\n\n\n4\n2\n1\n4\n3\n\n\n\nand the matching given by: M = (1,4), (2,3), (3,2), (4,1). Notice that this matching has, in fact, no blocking pairs.\n\n\n\n\n\n\n\n\n\nHow many blocking pairs can we have?\n\n\n\nCome up with a stable matching instance that has \\Omega(n^2) blocking pairs. What’s the maximum number possible?\n\n\nA matching without blocking pairs is called stable.\n\n\n\n\n\n\nStable Matching\n\n\n\nA matching M is said to be stable if there are no blocking pairs with respect to M.\n\n\nIt’s easy to verify if a given matching M is stable: for all men m we look up all women w that m ranks higher than M(m), and check if w also ranks m higher than M(w): if yes, then we can declare M unstable since (m,w) is a blocking pair. If we find no blocking pairs after having checked all men m, then we can declare that M is stable.\nThis takes at most O(n^2) time, assuming that ranks can be retrieved in constant time. Thus we have the following.\n\n\n\n\n\n\nVerifying that a matching is stable.\n\n\n\nGiven a matching M between n men and n women and their preferences over each other, it is possible to verify if M is stable in O(n^2) time.\n\n\nThe next natural questions are:\n\nDo stable matchings always exist?\n\nIf yes: can we always find them efficiently?\nIf not: can we efficiently find matchings that minimize the number of blocking pairs?\n\n\nThis is a good place to pause and ponder!\n\n\nDeveloping a Solution\nIt turns out that (somewhat surprisingly!) stable matchings indeed always exist!\nThe algorithm for finding a stable matching works as follows. To begin with, we say that all men and women are single, i.e, unmatched to anyone so far.\nAnticipating our need for stability, we take a greedy approach: the men attempt to match up to their best option by proposing to them. But notice that this may not be immediately workable: possibly multiple men have the same choice for their top option. This puts the ball in the woman’s court, so to speak, and again in the interest of being eventually stable, it’s intuitive that the woman will choose to align with the best offer she has among the proposals she’s recieved.\nAlso, since we finally want everyone to be matched, we will also ensure that proposals are not rejected simply because they seem unattractive in absolute terms: if a woman who’s single recieves one or more proposals, she will accept the best among them, no matter how good or bad they are.\nAfter one round of proposals, the situation is as follows:\n\nsome women (say W_\\star \\subseteq W) recieved one or more proposals and picked the best offer, and are no longer single;\nsome women (say W_0 = W \\setminus W_\\star) recieved no proposals and are still single;\nsome men (say V_\\star \\subseteq V) had their proposals accepted and they are no longer single ;\nsome men (say V_0 = V \\setminus V_\\star) were turned down and are still single.\n\nIf W_0 = \\emptyset, that’s… well, that’s awesome, because what that means is all men had distinct choices for their top preference, and so V_0 = \\emptyset as well and we already have a matching where everyone has their best possible match: so this is clearly very stable and we are done.\nOn the other hand, it’s possible that W_0 \\neq \\emptyset, which is to say that some women are still single, and therefore there are some single men as well. Now, to make progress, single men go back to the drawing board and propose again. Now, a natural question at this point is the following:\n\nShould the currently single men try their luck again with women who’ve rejected them?\n\nWell, since they were rejected for good reason (said women had better offers), and the reason has not gone away, it is clearly a waste of time for men to go back to women who’ve rejected them. So what they do instead is to propose to the next best option. Now: what if their next best option is not a single woman? Well, suppose m decides to not approach w because w is matched to some m^\\star in the first round. Then m will eventually be matched to someone who’s worse than w, and if w happened to prefer m over m^\\star, then (m,w) will eventually be a blocking pair.\nHowever, recall that this is exactly the situation we want to avoid. So we’re going to have m propose to their next best option irrespective of whether they are single or not. From the woman’s perspective, they are going to recieve proposals again, and we’ll let them pick the best offer, even if it means breaking off their current engagement.\nAfter this second round of proposals we again have some single men and women, and some engagements. Note that the following invariant is true:\n\nAny woman who was not single at the end of the first round remains engaged at the end of the second round as well.\n\nMen, on the other hand, may become single again. At this point, we simply continue as before: at the end of every round, the single men continue to propose to their current best option, and the women continue to accept the best offer that they have. We continue this until there are no single men left.\n\n\nThe Algorithm and its Properties\nHere’s pseudocode (borrowed from Wikipedia) summarizing the algorithm, which is due to Gale and Shapley. The version below is morally equivalent to our description above, except that all proposals happen one by one, and it turns out that this way of looking at it simplifies the analysis.\nalgorithm stable_matching is\n    Initialize m ∈ M and w ∈ W to free\n    while ∃ free man m who has a woman w to propose to do\n        w := first woman on m's list to whom m has not yet proposed\n        if ∃ some pair (m', w) then\n            if w prefers m to m' then\n                m' becomes free\n                (m, w) become engaged\n            end if\n        else\n            (m, w) become engaged\n        end if\n    repeat\nIt turns out that this procedure:\n\nterminates in finite time (in fact, after O(n^2) proposals have been made)\noutputs a perfect matching M between the men and the women that has no blocking pairs.\n\nThe first property follows from the fact that men never propose twice to the same woman, so the number of proposals made is \\leqslant n^2 . Also note that no man m is rejected by all women: this can only happen if all the women have found better engagements (which are necessarily distinct — notice that the set of engagments at any stage of the algorithm always forms a valid matching), but there are only n-1 men other than w: so this is not feasible.\nSo we know that the while loop terminates, and that once it does we have a matching M.\nIt remains to show that M is stable. But if M has a blocking pair (m,w), then w was proposed to by m before m proposed to M(w), and since (m,w) are not matched in M, it must be the case that w prefers M(w) over m, so (m,w) cannot be a blocking pair after all.\nThis brings us to the following claim:\n\n\n\n\n\n\nFinding a stable matching\n\n\n\nGiven a matching M between n men and n women and their preferences over each other, it is possible to find a stable matching M in O(n^3) time.\n\n\nThe output of the Gale-Shapley algorithm has a couple of interesting properties. First off, it turns out that the output is not just stable, but also qualitatively very good. Let us define, for a man m, their optimal match as the best woman that m can be matched to in any stable matching. It turns out that M matches all men to their optimal matches!\n\n\n\n\n\n\nThe Men Are Lucky\n\n\n\nLet M be the output of the GS algorithm. For all men m, there is no stable matching M^\\star where m prefers M^\\star(m) over M(m).\n\n\nAlso, the output of GS is weakly Pareto optimal, which is to say that there is no matching (stable or otherwise), where all the men are better off.\n\n\n\n\n\n\nThe GS matching is weakly PO\n\n\n\nLet M be the output of the GS algorithm. There is no matching M^\\star for which it is true that all men m prefer M^\\star(m) over M(m).\n\n\nWe state these claims above without proof. The interested reader should look them up!\n\n\nReferences\nNumberphile video about the algorithm\nNumberphile video about the proof\nNotes on implementation details"
  },
  {
    "objectID": "materials/algorithms/greedy/stable-matchings/index.html#references",
    "href": "materials/algorithms/greedy/stable-matchings/index.html#references",
    "title": "3. Stable Matchings",
    "section": "References",
    "text": "References\nNumberphile video about the algorithm\nNumberphile video about the proof\nNotes on implementation details"
  },
  {
    "objectID": "materials/algorithms/greedy/file-storage/index.html#the-problem.",
    "href": "materials/algorithms/greedy/file-storage/index.html#the-problem.",
    "title": "1. Storing Files on a Tape",
    "section": "The Problem.=",
    "text": "The Problem.=\nSuppose we have a set of n files that we want to store on magnetic tape1. In the future, users will want to read those files from the tape. Reading a file from tape isn’t like reading a file from disk; first we have to fast-forward past all the other files, and that takes a significant amount of time. Let L[1 \\ldots n] be an array listing the lengths of each file; specifically, file i has length L[i]. If the files are stored in order from 1 to n, then the cost of accessing the k th file is\n\n\\operatorname{cost}(k)=\\sum_{i=1}^{k} L[i] .\n\nThe cost reflects the fact that before we read file k we must first scan past all the earlier files on the tape. If we assume for the moment that each file is equally likely to be accessed, then the expected cost of searching for a random file is\n\n\\mathrm{E}[\\cos t]=\\sum_{k=1}^{n} \\frac{\\cos t(k)}{n}=\\frac{1}{n} \\sum_{k=1}^{n} \\sum_{i=1}^{k} L[i] \\text {. }\n\nIf we change the order of the files on the tape, we change the cost of accessing the files; some files become more expensive to read, but others become cheaper. Different file orders are likely to result in different expected costs. Specifically, let \\pi(i) denote the index of the file stored at position i on the tape. Then the expected cost of the permutation \\pi is\n\n\\mathrm{E}[\\operatorname{cost}(\\pi)]=\\frac{1}{n} \\sum_{k=1}^{n} \\sum_{i=1}^{k} L[\\pi(i)]\n\nWhich order should we use if we want this expected cost to be as small as possible? Try this yourself in the demonstration below. The tape is the grey rectangle, and the files are the colored boxes below it. The widths of the boxes are proportional to the file lengths. Double-click to get a file outside the tape to push it on the tape, and double-click a file on the tape to remove it. Can you match the optimal cost?\n\n\n\n\n\n\n\n\n\nAverage: 0\n\n\nTarget:\n\n\nKeep going until all pieces are on the tape…\n\n\n\nAfter some playing around, you may have come to the conclusion that you should sort the files by increasing length. Indeed, the length of the first file shows up the most frequently in the expression we are trying to optimize, while the length of the last file shows up just once: so it seems clear that the larger files should be pushed to the end.\nHowever — and especially so with greedy approaches — intuition is a tricky beast. The only way to be sure that this order works is to actually prove that it works!\n\n\n\n\n\n\nCorrectness of the Greedy Algorithm\n\n\n\nLemma. \\mathrm{E}[\\operatorname{cost}(\\pi)] is minimized when L[\\pi(i)] \\leq L[\\pi(i+1)] for all i.\nSuppose L[\\pi(i)]>L[\\pi(i+1)] for some index i. To simplify notation, let a=\\pi(i) and b=\\pi(i+1). If we swap files a and b, then the cost of accessing a increases by L[b], and the cost of accessing b decreases by L[a]. Overall, the swap changes the expected cost by (L[b]-L[a]) / n. But this change is an improvement, because L[b]<L[a]. Thus, if the files are out of order, we can decrease the expected cost by swapping some mis-ordered pair of files.\n\n\nThis is our first example of a correct greedy algorithm. To minimize the total expected cost of accessing the files, we put the file that is cheapest to access first, and then recursively write everything else; no backtracking, no dynamic programming, just make the best local choice and blindly plow ahead. If we use an efficient sorting algorithm, the running time is clearly O(n \\log n), plus the time required to actually write the files. To show that the greedy algorithm is actually correct, we proved that the output of any other algorithm can be improved by some sort of exchange.\nLet’s generalize this idea further. Suppose we are also given an array F[1 \\ldots n] of access frequencies for each file; file i will be accessed exactly F[i] times over the lifetime of the tape. Now the total cost of accessing all the files on the tape is\n\n\\Sigma \\cos t(\\pi)=\\sum_{k=1}^{n}\\left(F[\\pi(k)] \\cdot \\sum_{i=1}^{k} L[\\pi(i)]\\right)=\\sum_{k=1}^{n} \\sum_{i=1}^{k}(F[\\pi(k)] \\cdot L[\\pi(i)]) .\n\nAs before, reordering the files can change this total cost. So what order should we use if we want the total cost to be as small as possible? (This question is similar in spirit to the optimal binary search tree problem, but the target data structure and the cost function are both different, so the algorithm must be different, too.)\nWe already proved that if all the frequencies are equal, we should sort the files by increasing size. If the frequencies are all different but the file lengths L[i] are all equal, then intuitively, we should sort the files by decreasing access frequency, with the most-accessed file first. In fact, this is not hard to prove (hint, hint) by modifying the proof of Lemma 4.1. But what if the sizes and the frequencies both vary? In this case, we should sort the files by the ratio L / F.\nLemma 4.2. \\Sigma \\operatorname{cost}(\\pi) is minimized when \\frac{L[\\pi(i)]}{F[\\pi(i)]} \\leq \\frac{L[\\pi(i+1)]}{F[\\pi(i+1)]} for all i.\nProof: Suppose L[\\pi(i)] / F[\\pi(i)]>L[\\pi(i+1)] / F[\\pi(i+i)] for some index i. To simplify notation, let a=\\pi(i) and b=\\pi(i+1). If we swap files a and b, then the cost of accessing a increases by L[b], and the cost of accessing b decreases by L[a]. Overall, the swap changes the total cost by L[b] F[a]-L[a] F[b]. But this change is an improvement, because\n\n\\frac{L[a]}{F[a]}>\\frac{L[b]}{F[b]} \\Longleftrightarrow L[b] F[a]-L[a] F[b]<0 .\n\nThus, if any two adjacent files are out of order, we can improve the total cost by swapping them."
  },
  {
    "objectID": "materials/algorithms/greedy/file-storage/index.html#the-problem",
    "href": "materials/algorithms/greedy/file-storage/index.html#the-problem",
    "title": "1. Storing Files on a Tape",
    "section": "The Problem",
    "text": "The Problem\nSuppose we have a set of n files that we want to store on magnetic tape1. In the future, users will want to read those files from the tape. Reading a file from tape isn’t like reading a file from disk; first we have to fast-forward past all the other files, and that takes a significant amount of time. Let L[1 \\ldots n] be an array listing the lengths of each file; specifically, file i has length L[i]. If the files are stored in order from 1 to n, then the cost of accessing the k th file is\n\n\\operatorname{cost}(k)=\\sum_{i=1}^{k} L[i] .\n\nThe cost reflects the fact that before we read file k we must first scan past all the earlier files on the tape. If we assume for the moment that each file is equally likely to be accessed, then the expected cost of searching for a random file is\n\n\\mathrm{E}[\\cos t]=\\sum_{k=1}^{n} \\frac{\\cos t(k)}{n}=\\frac{1}{n} \\sum_{k=1}^{n} \\sum_{i=1}^{k} L[i] \\text {. }\n\nIf we change the order of the files on the tape, we change the cost of accessing the files; some files become more expensive to read, but others become cheaper. Different file orders are likely to result in different expected costs. Specifically, let \\pi(i) denote the index of the file stored at position i on the tape. Then the expected cost of the permutation \\pi is\n\n\\mathrm{E}[\\operatorname{cost}(\\pi)]=\\frac{1}{n} \\sum_{k=1}^{n} \\sum_{i=1}^{k} L[\\pi(i)]\n\nWhich order should we use if we want this expected cost to be as small as possible? Try this yourself in the demonstration below. The tape is the grey rectangle, and the files are the colored boxes below it. The widths of the boxes are proportional to the file lengths. Double-click to get a file outside the tape to push it on the tape, and double-click a file on the tape to remove it. Can you match the optimal cost?\n\n\n\n\n\n\n\n\n\nAverage: 0\n\n\nTarget:\n\n\nKeep going until all pieces are on the tape…\n\n\n\nAfter some playing around, you may have come to the conclusion that you should sort the files by increasing length. Indeed, the length of the first file shows up the most frequently in the expression we are trying to optimize, while the length of the last file shows up just once: so it seems clear that the larger files should be pushed to the end.\nHowever — and especially so with greedy approaches — intuition is a tricky beast. The only way to be sure that this order works is to actually prove that it works!"
  },
  {
    "objectID": "materials/algorithms/greedy/file-storage/index.html#greedy-works-out",
    "href": "materials/algorithms/greedy/file-storage/index.html#greedy-works-out",
    "title": "1. Storing Files on a Tape",
    "section": "Greedy Works Out",
    "text": "Greedy Works Out\n\n\n\n\n\n\nCorrectness of the Greedy Algorithm\n\n\n\nLemma. \\mathrm{E}[\\operatorname{cost}(\\pi)] is minimized when L[\\pi(i)] \\leq L[\\pi(i+1)] for all i.\nSuppose L[\\pi(i)]>L[\\pi(i+1)] for some index i. To simplify notation, let a=\\pi(i) and b=\\pi(i+1). If we swap files a and b, then the cost of accessing a increases by L[b], and the cost of accessing b decreases by L[a]. Overall, the swap changes the expected cost by (L[b]-L[a]) / n. But this change is an improvement, because L[b]<L[a]. Thus, if the files are out of order, we can decrease the expected cost by swapping some mis-ordered pair of files.\n\n\nThis is our first example of a correct greedy algorithm. To minimize the total expected cost of accessing the files, we put the file that is cheapest to access first, and then recursively write everything else; no backtracking, no dynamic programming, just make the best local choice and blindly plow ahead. If we use an efficient sorting algorithm, the running time is clearly O(n \\log n), plus the time required to actually write the files. To show that the greedy algorithm is actually correct, we proved that the output of any other algorithm can be improved by some sort of exchange."
  },
  {
    "objectID": "materials/algorithms/greedy/file-storage/index.html#frequencies",
    "href": "materials/algorithms/greedy/file-storage/index.html#frequencies",
    "title": "1. Storing Files on a Tape",
    "section": "Frequencies",
    "text": "Frequencies\nLet’s generalize this idea further. Suppose we are also given an array F[1 \\ldots n] of access frequencies for each file; file i will be accessed exactly F[i] times over the lifetime of the tape. Now the total cost of accessing all the files on the tape is\n\n\\Sigma \\cos t(\\pi)=\\sum_{k=1}^{n}\\left(F[\\pi(k)] \\cdot \\sum_{i=1}^{k} L[\\pi(i)]\\right)=\\sum_{k=1}^{n} \\sum_{i=1}^{k}(F[\\pi(k)] \\cdot L[\\pi(i)]) .\n\nAs before, reordering the files can change this total cost. So what order should we use if we want the total cost to be as small as possible? (This question is similar in spirit to the optimal binary search tree problem, but the target data structure and the cost function are both different, so the algorithm must be different, too.)\nWe already proved that if all the frequencies are equal, we should sort the files by increasing size. If the frequencies are all different but the file lengths L[i] are all equal, then intuitively, we should sort the files by decreasing access frequency, with the most-accessed file first. In fact, this is not hard to prove (hint, hint) by modifying the proof of Lemma 4.1. But what if the sizes and the frequencies both vary? In this case, we should sort the files by the ratio L / F.\nLemma 4.2. \\Sigma \\operatorname{cost}(\\pi) is minimized when \\frac{L[\\pi(i)]}{F[\\pi(i)]} \\leq \\frac{L[\\pi(i+1)]}{F[\\pi(i+1)]} for all i.\nProof: Suppose L[\\pi(i)] / F[\\pi(i)]>L[\\pi(i+1)] / F[\\pi(i+i)] for some index i. To simplify notation, let a=\\pi(i) and b=\\pi(i+1). If we swap files a and b, then the cost of accessing a increases by L[b], and the cost of accessing b decreases by L[a]. Overall, the swap changes the total cost by L[b] F[a]-L[a] F[b]. But this change is an improvement, because\n\n\\frac{L[a]}{F[a]}>\\frac{L[b]}{F[b]} \\Longleftrightarrow L[b] F[a]-L[a] F[b]<0 .\n\nThus, if any two adjacent files are out of order, we can improve the total cost by swapping them."
  },
  {
    "objectID": "courses/2023/02-IITM-AA/quizzes/P01.html",
    "href": "courses/2023/02-IITM-AA/quizzes/P01.html",
    "title": "Advanced Algorithms. Week 1 Practice Problems",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nAcknowledgements\n\n\n\nThese questions are from Chapter 4 of Jeff Erickson’s textbook on Algorithms.\n\n\n\n\n\n\n\n\nProblem 1. Alternate Greedy Schedules\n\n\n\n\n\nThe GreedySchedule algorithm we described for the class scheduling problem is not the only greedy strategy we could have tried. For each of the following alternative greedy strategies, either prove that the resulting algorithm always constructs an optimal schedule, or describe a small input example for which the algorithm does not produce an optimal schedule.\nAssume that all algorithms break ties arbitrarily (that is, in a manner that is completely out of your control).\n[Hint: Three of these algorithms are actually correct.]\n\nChoose the course x that ends last, discard classes that conflict with x, and recurse.\nChoose the course x that starts first, discard all classes that conflict with x, and recurse.\nChoose the course x that starts last, discard all classes that conflict with x, and recurse.\nChoose the course x with shortest duration, discard all classes that conflict with x, and recurse.\nChoose a course x that conflicts with the fewest other courses, discard all classes that conflict with x, and recurse.\nIf no classes conflict, choose them all. Otherwise, discard the course with longest duration and recurse.\nIf no classes conflict, choose them all. Otherwise, discard a course that conflicts with the most other courses and recurse.\nLet x be the class with the earliest start time, and let y be the class with the second earliest start time.\n\n\nIf x and y are disjoint, choose x and recurse on everything but x.\nIf x completely contains y, discard x and recurse.\nOtherwise, discard y and recurse.\n\n\nIf any course x completely contains another course, discard x and recurse. Otherwise, choose the course y that ends last, discard all classes that conflict with y, and recurse.\n\n\n\n\n\n\n\n\n\n\nProblem 2. Weighted Scheduling\n\n\n\n\n\nNow consider a weighted version of the class scheduling problem, where different classes offer different number of credit hours (totally unrelated to the duration of the class lectures). Your goal is now to choose a set of non-conflicting classes that give you the largest possible number of credit hours, given arrays of start times, end times, and credit hours as input.\n\nProve that the greedy algorithm described at the beginning of this chapter-Choose the class that ends first and recurse-does not always return an optimal schedule.\nProve that none of the greedy algorithms described in Exercise 1 always return an optimal schedule. [Hint: Solve Exercise 1 first; the algorithms that don’t work there don’t work here, either.]\nBONUS QUESTION Describe and analyze an algorithm that always computes an optimal schedule. [Hint: Your algorithm will not be greedy.]\n\n\n\n\n\n\n\n\n\n\nProblem 3. Finding a Cover\n\n\n\n\n\nLet X be a set of n intervals on the real line. We say that a subset of intervals Y \\subseteq X covers X if the union of all intervals in Y is equal to the union of all intervals in X. The size of a cover is just the number of intervals.\nDescribe and analyze an efficient algorithm to compute the smallest cover of X. Assume that your input consists of two arrays L[1 \\ldots n] and R[1 . . n], representing the left and right endpoints of the intervals in X. If you use a greedy algorithm, you must prove that it is correct.\n\n\n\nA set of intervals, with a cover (shaded) of size 7.\n\n\n\n\n\n\n\n\n\n\n\nProblem 4. Finding a Stabbing Set\n\n\n\n\n\nLet X be a set of n intervals on the real line. We say that a set P of points stabs X if every interval in X contains at least one point in P. Describe and analyze an efficient algorithm to compute the smallest set of points that stabs X. Assume that your input consists of two arrays L[1 . . n] and R[1 . . n], representing the left and right endpoints of the intervals in X. As usual, If you use a greedy algorithm, you must prove that it is correct.\n\n\n\nA set of intervals stabbed by four points (shown here as vertical segments).\n\n\n\n\n\n\n\n\n\n\n\nProblem 5. Proper Coloring\n\n\n\n\n\nLet X be a set of n intervals on the real line. A proper coloring of X assigns a color to each interval, so that any two overlapping intervals are assigned different colors. Describe and analyze an efficient algorithm to compute the minimum number of colors needed to properly color X. Assume that your input consists of two arrays L[1 . . n] and R[1 . . n], representing the left and right endpoints of the intervals in X. As usual, if you use a greedy algorithm, you must prove that it is correct.\n\n\n\nA proper coloring of a set of intervals using five colors.\n\n\n\n\n\n\n\n\n\n\n\nProblem 6. Stable Matchings\n\n\n\n\n\n\nProve that it is possible for the Gale-Shapley algorithm to perform \\Omega\\left(n^{2}\\right) offers before termination.\n(You need to describe both a suitable input and a sequence of \\Omega\\left(n^{2}\\right) valid offers.)\nDescribe for any integer n a set of preferences for n men and n women that forces the Gale-Shapley algorithm to execute \\Omega\\left(n^{2}\\right) rounds, no matter which valid proposal is made in each round.\n[Hint: Part (b) implies part (a).]\n\n\n\n\n\n\n\n\n\n\nProblem 7. A Unique Stable Matching\n\n\n\n\n\nDescribe and analyze an efficient algorithm to determine whether a given set of men and women preferences has to have a unique stable matching."
  },
  {
    "objectID": "courses/2023/03-CS699/index.html",
    "href": "courses/2023/03-CS699/index.html",
    "title": "CS 699 | Aug-Nov 2023",
    "section": "",
    "text": "About the Course\n\n\n\n\n\nWe are going to play some games! Here are some typical questions we will explore:\n\nWho is going to win assuming optimal play?\nWhat is the complexity of determining the winner (or a winning strategy) given the rules of a game?\n\nIf you are curious about how this typically goes, start with the excellent talks here and here.\nIf you want to play: here’s Subtraction, and here’s Sim.\n\n\n\n\n\n\n\n\n\nTarget Audience\n\n\n\n\n\nYou will find this course interesting if:\n\nyou enjoy playing games,\nyou enjoy logic puzzles like this one or probability puzzles like this one, or\nyou like box-stacking challenges.\n\n\n\n\n\n\n\n\n\n\nPrerequisites\n\n\n\n\n\nThis course is self-contained and involves no pre-requisites.\n\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\n\n\nWinning Ways for your Mathematical Plays, the classic book that is an amazing ride through all parts of CGT.\nLessons in Play, an excellent text for upper level undergrads and grad students in math.\nCombinatorial Game Theory, a great text for advanced mathematicians.\nPlaying with Discrete Math. This text is appropriate for undergrads who may or may not be math majors.\nGames, puzzles and computation. This text, based on the thesis of Robert A. Hearn, explores computational aspects of games.\nIs NP-hard, a compendium of games with a lot of information about their complexity status.\nMath Games with Bad Drawings, another compendium of games, with — as the title suggestions — bad drawings and lots of trivia.\n\nNote. The descriptions for the first four books are borrowed from the Sprouts 2023 website.\n\n\n\n\n\n\n\n\n\nTimings and Venue\n\n\n\n\n\n\nVenue: TBA\nLectures: Mondays and Fridays 3:30PM — 5:00PM\n\n\n\n\n\n\n\n\n\n\nTAs and Office hours\n\n\n\n\n\nOffice Hours: By email.\nTAs: TBA\n\n\n\n\n\n\n\n\n\nEvaluation policy\n\n\n\n\n\n\nDevelop your own game and demonstrate a non-trivial analysis X 1 = 15 points\nDevelop new results about the complexity of an existing game = 15 points\nImplement a known game in as an interactive JS application X 3 = 30 points\nThree take-home exams = 45 points\nTotal capped at 100.\n\nThe use of assistance from tools like chatGPT or similar is permitted for the development of the interactive experiences.\n\n\n\n\n\n\n\n\n\nRegister\n\n\n\n\n\n\nFor IITGN students, (pre-)register through IMS as usual.\nOtherwise, please send me an email.\n\n\n\n\n\nRecordingsLecturesAssignments\n\n\n\n\n\n    \n        Date\n        Lecture\n        Slides\n        Notes\n        Video\n        Recap\n    \n    \n                    \n            \n                22 May, 2023\n            \n            \n                1. Impartial Game Trees\n                (0.1, 0.2, 0.3 in PWDM)\n            \n            \n                    \n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                23 May, 2023\n            \n            \n                2. Game Sums\n                (0.4, 0.5 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                24 May, 2023\n            \n            \n                3. Game Equivalences\n                (0.4, 0.5 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                25 May, 2023\n            \n            \n                4. Nimbers\n                (0.6, 0.7 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n                    \n            \n            \n            \n        \n                    \n            \n                05 Jun, 2023\n            \n            \n                5. Nim Sums\n                (0.6, 0.7 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                06 Jun, 2023\n            \n            \n                6. Other Impartial Games\n                (0.8 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                07 Jun, 2023\n            \n            \n                7. Sequences of impartial game values\n                (0.9 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                08 Jun, 2023\n            \n            \n                08. Geography\n                (1.1 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                09 Jun, 2023\n            \n            \n                09. Undirected Edge Geography\n                (1.2 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                10 Jun, 2023\n            \n            \n                10. Directed Geography\n                (1.3 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                11 Jun, 2023\n            \n            \n                11. Partisan Game Notation\n                (2.1 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                12 Jun, 2023\n            \n            \n                12. Game Trees and Outcome Classes\n                (2.2 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                13 Jun, 2023\n            \n            \n                13. Partisan Game Sums\n                (2.3 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                14 Jun, 2023\n            \n            \n                14. Negatives and Equality\n                (2.4 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                15 Jun, 2023\n            \n            \n                15. Inequalities\n                (2.5 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                16 Jun, 2023\n            \n            \n                16. Dominated Options\n                (2.6 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                17 Jun, 2023\n            \n            \n                17. Integers\n                (3.1 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                18 Jun, 2023\n            \n            \n                18. Simplest Numbers\n                (3.2 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                19 Jun, 2023\n            \n            \n                19. Switches\n                (3.3 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                20 Jun, 2023\n            \n            \n                20. Other rational game value\n                (3.4 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                21 Jun, 2023\n            \n            \n                21. Infinitesimals\n                (3.5 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                22 Jun, 2023\n            \n            \n                22. They-Love-Me-They-Love-Me-Nc\n                (4.1 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                23 Jun, 2023\n            \n            \n                23. Determining Winnability\n                (4.2 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                24 Jun, 2023\n            \n            \n                24. Which Move Should we Make?\n                (4.3 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                25 Jun, 2023\n            \n            \n                25. More strategy stealing.\n                (4.4 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                26 Jun, 2023\n            \n            \n                26. Card games\n                (5.1 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                27 Jun, 2023\n            \n            \n                27. Dice and role-playing games\n                (5.2 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                28 Jun, 2023\n            \n            \n                28. Birthdays\n                (6.1 in PWDM)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                29 Jun, 2023\n            \n            \n                29. SUMMARY OF PART I\n                \n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                30 Jun, 2023\n            \n            \n                30. Introducing Complexity Classes and Constraint\n                Logic  (1 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                01 Jul, 2023\n            \n            \n                31. Constraint Graphs\n                (2.1 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                02 Jul, 2023\n            \n            \n                32. Planar Constraint Graphs\n                (2.2 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                03 Jul, 2023\n            \n            \n                33. Constraint-Graph Conversion Techniques\n                (2.3 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                04 Jul, 2023\n            \n            \n                34. Zero-Player Games (Simulations)\n                (3.1 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                05 Jul, 2023\n            \n            \n                35. One-Player Games (Puzzles)\n                (3.2 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                06 Jul, 2023\n            \n            \n                36. Two-Player Games\n                (3.3 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                07 Jul, 2023\n            \n            \n                37. Team Games\n                (3.4 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                08 Jul, 2023\n            \n            \n                38. Bounded Games (Zero-Player)\n                (4.1 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                09 Jul, 2023\n            \n            \n                39. Unbounded Games (Zero-Player)\n                (4.2 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                10 Jul, 2023\n            \n            \n                40. Bounded Games (One-Player)\n                (5.1 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                11 Jul, 2023\n            \n            \n                41. Unbounded Games (One-Player)\n                (5.2 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                12 Jul, 2023\n            \n            \n                42. Bounded Games (Two-Player)\n                (6.1 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                13 Jul, 2023\n            \n            \n                43. Unbounded Games (Two-Player)\n                (6.2 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                14 Jul, 2023\n            \n            \n                44. No-Repeat Games (Two-Player)\n                (6.3 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                15 Jul, 2023\n            \n            \n                45. Bounded Games (Team)\n                (7.1 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                16 Jul, 2023\n            \n            \n                46. Unbounded Games (Team)\n                (7.2 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                17 Jul, 2023\n            \n            \n                47. TipOver\n                (9.1 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                18 Jul, 2023\n            \n            \n                48. Hitori\n                (9.2 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                19 Jul, 2023\n            \n            \n                49. Sliding-Block Puzzles\n                (9.3 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                20 Jul, 2023\n            \n            \n                50. The Warehouseman’s Problem\n                (9.4 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                21 Jul, 2023\n            \n            \n                51. Sliding-Coin Puzzles\n                (9.5 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                22 Jul, 2023\n            \n            \n                52. Plank Puzzles\n                (9.6 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                23 Jul, 2023\n            \n            \n                53. Sokoban\n                (9.7 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                24 Jul, 2023\n            \n            \n                54. Push-2-F\n                (9.8 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                25 Jul, 2023\n            \n            \n                55. Rush Hour\n                (9.9 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                26 Jul, 2023\n            \n            \n                56. Triangular Rush Hour\n                (9.10 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                27 Jul, 2023\n            \n            \n                57. Hinged Polygon Dissections\n                (9.11 in GPC)\n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n                    \n            \n                28 Jul, 2023\n            \n            \n                58. SUMMARY OF PART II\n                \n            \n            \n            \n            \n                    \n            \n            \n            \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\n\n\n    \n        Date\n        Lecture\n        Slides\n        Notes\n        Video\n    \n    \n                    \n            \n                04 Aug, 2023\n            \n            \n                1. Introduction\n                Basic Setup, Terminology, and Examples.\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                07 Aug, 2023\n            \n            \n                2. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                11 Aug, 2023\n            \n            \n                3. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                14 Aug, 2023\n            \n            \n                4. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                18 Aug, 2023\n            \n            \n                5. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                21 Aug, 2023\n            \n            \n                6. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                25 Aug, 2023\n            \n            \n                7. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                28 Aug, 2023\n            \n            \n                08. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                01 Sep, 2023\n            \n            \n                09. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                08 Sep, 2023\n            \n            \n                10. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                11 Sep, 2023\n            \n            \n                11. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                15 Sep, 2023\n            \n            \n                12. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                18 Sep, 2023\n            \n            \n                13. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                22 Sep, 2023\n            \n            \n                14. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                25 Sep, 2023\n            \n            \n                15. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                29 Sep, 2023\n            \n            \n                16. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                06 Oct, 2023\n            \n            \n                17. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                09 Oct, 2023\n            \n            \n                18. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                16 Oct, 2023\n            \n            \n                19. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                20 Oct, 2023\n            \n            \n                20. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                30 Oct, 2023\n            \n            \n                21. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                03 Nov, 2023\n            \n            \n                22. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                06 Nov, 2023\n            \n            \n                23. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                10 Nov, 2023\n            \n            \n                24. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                13 Nov, 2023\n            \n            \n                25. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                17 Nov, 2023\n            \n            \n                26. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                20 Nov, 2023\n            \n            \n                27. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                24 Nov, 2023\n            \n            \n                28. TBA\n                \n            \n            \n            \n            \n            \n            \n            \n        \n\n\n\nNo matching items\n\n\n\n\n\nWe will share user-developed content here.\n\n\n\n\n    \n        Issued\n        Assessment\n        Problems\n        Solutions\n        Due\n    \n    \n                    \n            \n                01 Aug, 2023\n            \n            \n                Coming Soon\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n\n\n\nNo matching items"
  },
  {
    "objectID": "courses/2023/03-CS699/tutorials/T01.html",
    "href": "courses/2023/03-CS699/tutorials/T01.html",
    "title": "ES214. Discrete Mathematics. Tutorial 01 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1A. How did they do it?\n\n\n\n\n\nImagine a friend gives you a deck of cards and lets you shuffle it a few times. They then ask vou to deal out the top 26 cards face down, which divides the deck into two.\nYou keep one half and they take the other. They ask you to count how many red cards you have. In the meantime, you notice that they are silently looking through their own half of the deck. But whatever they are doing they did it as quickly as you, because once you’re done they declare that they know how many red cards you counted, and correctly announce the answer!\nHow did they do it?\n\n\n\n\n\n\n\n\n\nProblem 1B. How did they do it? (Redux)\n\n\n\n\n\nDeduce how the following trick works.\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. Handshakes\n\n\n\n\n\nMr. and Mrs. Sharma invited four couples to their home. Some guests were friends of Mr. Sharma, and some others were friends of Mrs. Sharma. When the guests arrived, people who knew each other beforehand shook hands, those who did not know each other just greeted each other.\nAfter all this took place, the observant Mr. Sharma said “How interesting. If you disregard me, there are no two people present who shook hands the same number of times\nHow many times did Mrs. Sharma shake hands?\n\n\n\n\n\n\n\n\n\nProblem 3. Chessboard Game\n\n\n\n\n\nAlice begins by marking a corner square of an n × n chessboard; Bob marks an orthogonally adjacent square.\nThereafter, Alice and Bob continue alternating. each marking a square adjacent to the last one marked, until no unmarked adjacent square is available at which time the player whose turn it is to play loses.\nFor which n does Alice have a winning strategy? For which n does she win if the first square marked is instead a neighbor of a corner square?\nHint: dominoes.\n\n\n\n\n\n\n\n\n\nProblem 4. An Odd Party\n\n\n\n\n\nYou are at a party where any two people have an odd number of mutual friends at the party.\nShow that there are an odd number of attendees."
  },
  {
    "objectID": "courses/2023/03-CS699/tutorials/A01.html",
    "href": "courses/2023/03-CS699/tutorials/A01.html",
    "title": "ES214. Discrete Mathematics. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe circuits of the graphic matroid are the cycles of the graph G.\n\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c,d\\} with the edges \\{ab, cd, ad\\}.\nThere are two matchings in this instance:\n\nM_1 := \\{ab,cd\\}\nM_2: \\{ad\\}\n\nHowever, although |M_1| > |M_2|, neither of the edges from M_1 can be added to M_2.\n\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c\\} with the edges \\{ab, ac\\}. There are two independent sets: S_1 := \\{b,c\\} and M_2: \\{a\\}, but neither of the vertices from S_1 can be added to S_2.\n\nIf the independent sets formed a matroid the problem of finding a maximum independent set would not be NP-complete. \n— Comment in class"
  },
  {
    "objectID": "courses/2023/03-CS699/exams/E01.html",
    "href": "courses/2023/03-CS699/exams/E01.html",
    "title": "ES214. Discrete Mathematics. Exam 1.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nRemarks\n\n\n\nProblem indices on Gradescope for Problem 1 are off-by-one. Add one to the index here to match to Gradescope.\nErrata based on feedback from the class (thanks!) — these changes have been made in the questions below:\n\nQ5: it should have been v \\in S and not v \\in G.\nQ1.4: assume that the cycles C and D are edge-disjoint.\nQ1.6: the last return statement is G and not G-v (the vertex v is moved to F, not removed from the graph).\n\n\n\n\n\n\n\n\n\nProblem 1. The Constrained Cycle Hitting Set (CCHS) Problem.\n\n\n\n\n\n\n\n\n\nMarks Distribution.\n\n\n\nThis problem is worth 20 points overall. All subproblems carry two points each except 1.9 (which is zero marks).\n\n\nLet G = (V,E) be a simple and undirected graph. Let F \\subseteq V be a subset of vertices that we will call a forbidden subset. An instance of CCHS is given by (G,F,k), where k \\in \\mathbb{Z}^+ is a budget. Such an instance is a YES-instance if there exists a subset of S \\subseteq V \\setminus F such that:\n\n|S| \\leqslant k, and\nG \\setminus S is a forest, i.e, there are no cycles.\n\nSuch a subset is called a constrained cycle hitting set with respect to F. In this question, we will develop a c^k algorithm for solving a CCHS instance, combining reduction and branching rules in a spirit somewhat similar to what we have done for Vertex Cover in class.\nOur goal will be to return a solution, i.e, a subset of vertices that is a constrained cycle hitting set with respect to F. In particular, an informal overview of our approach, detailed further in the questions below, is the following:\n\nWe will eliminate low-degree (vertices of degree at most one) vertices, and branch on high-degree vertices.\nFor the base case, we will find ourselves “stuck” when the graph only has vertices of degree at most two, but this can be handled in polynomial time.\n\nOur algorithm will be denoted solve-CCHS(G,F,k). We begin the following straightforward rules:\n\nIf k < 0, return NO.\nIf V(G) = \\emptyset, return \\emptyset.\n\n\n\n\n\n\n\nProblem 1.0 No Hope Rule\n\n\n\n\n\nSuppose G[F] has a cycle C. Note that all vertices of C belong to F. Then return:\n\nNO\nsolve-CCHS(G-v,F-v,k-1) where v is a maximum degree vertex from C.\nsolve-CCHS(G-v,F-v,k-1) where v is a minimum degree vertex from C.\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.1 Low Degree Rule.\n\n\n\n\n\nIf a vertex v has degree zero or one, then return:\n\nsolve-CCHS(G-v,F-v,k).\nsolve-CCHS(G-v,F-v,k-1).\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.2 Forced Vertex Rule.\n\n\n\n\n\nIf a vertex v \\in G \\setminus F has two neighbors in a single connected component of G[F], then return:\n\nsolve-CCHS(G-v,F,k).\nsolve-CCHS(G-v,F,k-1).\n\nChoose the correct option and justify the correctness of the reduction rule.\n\n\n\n\n\n\n\n\n\nProblem 1.3 High Degree Vertex Has Low Degree - Structure I\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nLet C be a cycle in G. Which of the following scenarios are not feasible?\n\nC \\cap F \\neq \\emptyset and C \\cap (V \\setminus F) \\neq \\emptyset\nC \\cap F = \\emptyset and C \\cap (V \\setminus F) \\neq \\emptyset\nC \\cap F \\neq \\emptyset and C \\cap (V \\setminus F) = \\emptyset\n\nPick the correct option and justify your answer briefly.\n\n\n\n\n\n\n\n\n\nProblem 1.4 High Degree Vertex Has Low Degree - Structure II\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nLet C and D be two edge-disjoint cycles in G. Which of the following scenarios are not feasible?\n\nC \\cap D \\neq \\emptyset\n(C \\cap F) \\cap (D \\cap F) \\neq \\emptyset\n(C \\cap (V\\setminus F)) \\cap (D \\cap (V \\setminus F)) \\neq \\emptyset\n\nPick the correct option and justify your answer briefly.\n\n\n\n\n\n\n\n\n\nProblem 1.5 High Degree Vertex Has Low Degree - Rule\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1 and 1.2 do not apply. Suppose further that d(v) = 2.\nConsider the following algorithm to solve this instance:\ninit X = emptyset\nwhile G\\X has a cycle C:\n    let v be a vertex in C\\F:\n        add v to X\nif |X| > k:\n    return NO\nelse:\n    return X\nWhat can you say about the procedure above?\n\nIt correctly solves the kind of CCHS questions being considered in this problem.\nIt will not be correct if there are no vertices in C\\setminus F, as required in line 3.\nIt will not be correct if there are two overlapping cycles in the instance.\n\nPick the correct option and justify your answer briefly. If you believe this is not the right algorithm, please suggest an alternative that works. In further questions when we refer to the rule in problem 1.5, we are referring to either the algorithm above or the one in your justification.\n\n\n\n\n\n\n\n\n\nProblem 1.6 The Branching Step\n\n\n\n\n\nLet v be a vertex of maximum degree in G \\setminus F, and suppose G is an instance where the rules from Problem 1.0, 1.1, 1.2, and 1.5 do not apply. Let v be a vertex in G \\setminus F of maximum degree. Now we branch as follows:\nOption A.\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F U {v},k) // omit v\nOption B.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F U {v},k-1) // omit v\nOption C.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X\notherwise:\n    return solve-CCHS(G,F U {v},k) // omit v\nOption D.\n\nX = solve-CCHS(G-v,F,k-1) // pick v\nif X is not NO:\n    return X U {v}\notherwise:\n    return solve-CCHS(G,F,k) // omit v\nPick the right branching strategy and justify your answer.\n\n\n\nWe summarize the overall algorithm below.\nIf k < 0, return NO.\nIf V(G) is empty, return the empty set.\n\nApply rules 1.0, 1.1, and 1.2.\n\nPick a vertex v in G\\F of maximum degree.\n\nIf d(v) = 2, apply rule 1.5.\nOtherwise branch according to 1.6.\nIn the next few questions, we will analyze the running time of this algorithm. Assume that the algorithm is called with F = \\emptyset, i.e, there are no forbidden vertices to begin with. Fix an execution path P in the branching tree1 of the algorithm that does not return NO. Now:\n\nWe use S(P) to denote the output: note that this would consist of the set of vertices that are removed from the instance for inclusion in the solution, i.e, vertices chosen by the first branch in Step 1.6.\nWe use F(P) to denote the set of vertices that are made forbidden along the path P, i.e, these are vertices chosen by the second branch in Step 1.6.\n\nNote that at the output node, the instance we have is (G,F(P),\\ell) for some \\ell \\leqslant k, where S(P) is a constrained cycle hitting set with respect to F(P) of size at most k - \\ell. Also the number of steps in the execution path P is given by |F(P)| + |S(P)|, since every time we branch, we either include a vertex in the solution or make it forbidden.\n\n\n\n\n\n\nProblem 1.7 Degree 3 vs Leaves in Trees\n\n\n\n\n\nLet T be a tree and let X be the set of leaves in T, and let Y be the set of vertices of degree three or more in T. Show that:\n\\sum_{v \\in Y} (d(v)-2) = |X| - 2,\nusing elementary facts about trees.\n\n\n\n\n\n\n\n\n\nProblem 1.8 Degree Evolution\n\n\n\n\n\nFix an execution path P on an instance (G,\\emptyset,k) (i.e, a path from root to leaf in the branching tree associated with the algorithm when the input is (G,\\emptyset,k)) and consider a vertex v that belongs to F(P), which is to say that the vertex v was included in the set of forbidden vertices at some point during the execution of the algorithm. Denote the instance at this stage of the algorithm by (H,F,k^\\prime). In particular, H is the graph obtained after v was included in F. Let d(v) denote the degree of the vertex v in the original instance G, and let d^\\star(v) denote its degree in the graph H. Which of the following is true?\n\n3 \\leqslant d^\\star(v) \\leqslant d(v)\n3 \\leqslant d^\\star(v) < d(v)\nd^\\star(v) \\geqslant \\min(d(v),3)\nd^\\star(v) > \\min(d(v),3)\n\n\n\n\n\n\n\n\n\n\nProblem 1.9 Successful Execution Paths are Short\n\n\n\n\n\nConsider an execution path P that does not return NO. Show that F(P) \\leqslant 3S(P).\nThis is an optional question that you can skip. It carries no points.\n\n\n\n\n\n\n\n\n\nProblem 1.10 The Final Running Time\n\n\n\n\n\nCan you use the fact from the previous question to come up with an algorithm for CCHS that runs in time O^\\star(16^k)? Note that the O^\\star(\\cdot) notation is used to hide factors that are polynomial in n and k.\nHint: Use the algorithm described previously in the question, but modify it slightly. In particular, if an execution path pushes more than 3S(P) vertices into the forbidden set F, can you terminate it prematurely? Also, what is the cost of the successful execution paths?\n\n\n\n\n\n\n\n\n\n\n\nProblem 2. GreedyHS [2 points]\n\n\n\nLet U=\\left\\{x_1, \\ldots, x_n\\right\\} be an univere of n elements. Suppose we have a family \\mathcal{F} over U that consists of three-sized subsets of U, for example:\n\n\\mathcal{F} = \\left(x_1, x_3, x_4\\right),\\left(x_2, x_3, x_7\\right),\\left(x_1, x_5, x_6\\right)\n\nWe want to find a smallest subset X of U such that for all sets S \\in \\mathcal{F}, S \\cap X \\neq \\emptyset.\nConsider the following algorithm for this problem.\nGreedy(U,F)\n\nInit X = emptyset\nwhile F is non-empty do:\n    Take an arbitrary set S in F.\n    Let x be an element in S\n    X = X U {x}\n    Remove all sets from F that contain x\nend while\nWhat can you say about the worst-case approximation ratio of this algorithm?\n\n\n\n\n\n\n\n\nProblem 3. Knapsack [2 points]\n\n\n\nConsider the knapsack problem. Given a set X=\\left\\{x_1, \\ldots, x_n\\right\\} of n items with weights w\\left(x_i\\right) and values v\\left(x_i\\right), it asks for the highest total value of items we can put into our knapsack such that the total weight of all these items is at most W.\nDescribe a 0/1-LP that models the problem correctly.\n\n\n\n\n\n\n\n\nProblem 4. Rectangle Covering [4 Points]\n\n\n\n\n\n\nRectangle Cover Problem Example\n\n\nSuppose we have a set P=\\left\\{p_1, \\ldots, p_n\\right\\} of n points and a set R=\\left\\{r_1 \\ldots, r_m\\right\\} of m rectangles, as in the image above. Each rectangle r_i \\in R has a certain cost c_i>0 associated with it. We wish to find a subset S \\subseteq R of rectangles whose cost is minimized such that the rectangles in S together cover all points in P.\nWe wish to model this problem as a 0/1-LP. To this end we introduce a decision variable x_i for each rectangle r_i \\in R, where x_i=1 corresponds to putting rectangle r_i into S and x_i=0 corresponds to not putting r_i into S. otherwise. Furthermore, for a point p_j \\in P, define R\\left(p_j\\right)=\\left\\{r_i \\in R: p_j \\in r_i\\right\\}.\n\n\n\n\n\n\nLP for Rectangle Cover\n\n\n\n\n\nDescribe a 0/1-LP that models the problem correctly.\n\n\n\n\n\n\n\n\n\nLP-based Approximation for Rectangle Cover\n\n\n\n\n\nDescribe a 5-approximation assuming that each point is contained in at most 5 rectangles.\n\n\n\n\n\n\n\n\n\n\n\nProblem 5. Dominating Set Reduction Rule When The Graph has No Short Cycles [2 points]\n\n\n\nSuppose G is a simple, undirected graph that has no cycles of length three or four. Recall that a subset S of vertices of G is called a dominating set if every vertex v of G either belongs to S or has a neighbor in S, in other words, N[v] \\cap S \\neq \\emptyset.\nLet S be a dominating set of G of size at most k, where G is as given above (i.e, G has no triangles and no cycles of length four). Show that if the degree of v is more than k in G, then v \\in S."
  },
  {
    "objectID": "courses/2023/03-CS699/quizzes/Q01.html",
    "href": "courses/2023/03-CS699/quizzes/Q01.html",
    "title": "ES214. Discrete Mathematics. Tutorial 01 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nProblem 1. Identify the Circuits\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer."
  },
  {
    "objectID": "courses/2023/03-CS699/quizzes/A01.html",
    "href": "courses/2023/03-CS699/quizzes/A01.html",
    "title": "ES214. Discrete Mathematics. L02 Quiz.",
    "section": "",
    "text": "Back to the course page\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the graphic matroid discussed in class, i.e, where:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are acyclic.\n\nA maximal independent set in a matroid is called a basis, and for this example, the maximal independent sets correspond to spanning trees.\nA minimal dependent set in a matroid is called a circuit. In this example, what are the circuits?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe circuits of the graphic matroid are the cycles of the graph G.\n\n\n\n\n\n\n\n\n\nProblem 2. Matchings\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of edges of G, i.e, E(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets of edges that are matchings.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c,d\\} with the edges \\{ab, cd, ad\\}.\nThere are two matchings in this instance:\n\nM_1 := \\{ab,cd\\}\nM_2: \\{ad\\}\n\nHowever, although |M_1| > |M_2|, neither of the edges from M_1 can be added to M_2.\n\n\n\n\n\n\n\n\n\nProblem 3. Independent Sets\n\n\n\nLet G be a simple, undirected, and connected graph. Consider the following set system:\n\nthe universe U is the set of vertices of G, i.e, V(G);\nthe family \\mathcal{F} of independent sets is the collection of all subsets S of that are independent in G, i.e, the subgraph G[S] has no edges.\n\nIs this a matroid? Why or why not? Justify your answer.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNot a matroid: consider the graph on the vertex set \\{a,b,c\\} with the edges \\{ab, ac\\}. There are two independent sets: S_1 := \\{b,c\\} and M_2: \\{a\\}, but neither of the vertices from S_1 can be added to S_2.\n\nIf the independent sets formed a matroid the problem of finding a maximum independent set would not be NP-complete. \n— Comment in class"
  },
  {
    "objectID": "courses/2023/03-CS699/index.html#cs699.-combinatorial-and-computational-aspects-of-games",
    "href": "courses/2023/03-CS699/index.html#cs699.-combinatorial-and-computational-aspects-of-games",
    "title": "CS 699 | Aug-Nov 2023",
    "section": "CS699. Combinatorial and Computational Aspects of Games",
    "text": "CS699. Combinatorial and Computational Aspects of Games\n\nAugust — November 2023\n\n\n\n\n\n\nAbout the Course\n\n\n\n\n\nWe are going to play some games! Here are some typical questions we will explore:\n\nWho is going to win assuming optimal play?\nWhat is the complexity of determining the winner (or a winning strategy) given the rules of a game?\n\nIf you are curious about how this typically goes, start with the excellent talks here and here.\nIf you want to play: here’s Subtraction, and here’s Sim.\n\n\n\n\n\n\n\n\n\nTarget Audience\n\n\n\n\n\nYou will find this course interesting if:\n\nyou enjoy playing games,\nyou enjoy logic puzzles like this one or probability puzzles like this one, or\nyou like box-stacking challenges.\n\n\n\n\n\n\n\n\n\n\nPrerequisites\n\n\n\n\n\nThis course is self-contained and involves no pre-requisites.\n\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\n\n\nWinning Ways for your Mathematical Plays, the classic book that is an amazing ride through all parts of CGT.\nLessons in Play, an excellent text for upper level undergrads and grad students in math.\nCombinatorial Game Theory, a great text for advanced mathematicians.\nPlaying with Discrete Math. This text is appropriate for undergrads who may or may not be math majors.\nGames, puzzles and computation. This text, based on the thesis of Robert A. Hearn, explores computational aspects of games.\nIs NP-hard, a compendium of games with a lot of information about their complexity status.\nMath Games with Bad Drawings, another compendium of games, with — as the title suggestions — bad drawings and lots of trivia.\n\nNote. The descriptions for the first four books are borrowed from the Sprouts 2023 website.\n\n\n\n\n\n\n\n\n\nTimings and Venue\n\n\n\n\n\n\nVenue: TBA\nLectures: Mondays and Fridays 3:30PM — 5:00PM\n\n\n\n\n\n\n\n\n\n\nTAs and Office hours\n\n\n\n\n\nOffice Hours: By email.\nTAs: TBA\n\n\n\n\n\n\n\n\n\nEvaluation policy\n\n\n\n\n\n\nDevelop your own game and demonstrate a non-trivial analysis X 1 = 20 points\nDevelop new results about the complexity of an existing game = 20 points\nImplement a known game in as an interactive JS application X 3 = 60 points\n\nThe use of assistance from tools like chatGPT or similar is permitted for the development of the interactive experiences.\n\n\n\n\n\n\n\n\n\nRegister\n\n\n\n\n\n\nFor IITGN students, (pre-)register through IMS as usual.\nOtherwise, please send me an email.\n\n\n\n\n::: {.panel-tabset} ## Lectures\n\n\n\n    \n        Date\n        Lecture\n        Slides\n        Notes\n        Video\n    \n    \n                    \n            \n                02 Aug, 2023\n            \n            \n                1. Intro to Proofs - I\n                General Methods • Chessboard Tilings • Game of Chomp\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                03 Aug, 2023\n            \n            \n                2. Intro to Proofs - II\n                Pigeonhole Principle • Illustrative Examples\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                08 Aug, 2023\n            \n            \n                3. Sets\n                Definitions • Operations • Showing Containment • Showing Equality\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                09 Aug, 2023\n            \n            \n                4. Functions and Relations\n                Injections, Surjections, Bijections • Compositions • Equivalence Classes\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                16 Aug, 2023\n            \n            \n                5. Induction\n                Dominoes, Ladders, and Chips • Examples • Non-Examples • Strong Induction\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                22 Aug, 2023\n            \n            \n                6. Propositional and Predicate Logic\n                Syntax • Truth Tables • Quantifiers\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                23 Aug, 2023\n            \n            \n                7. Inference Systems\n                Inference Rules (e.g, Modus Ponens, Modus Tollens, Resolution, etc) • Paradoxes\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                29 Aug, 2023\n            \n            \n                8. Elementary Counting Methods\n                Permutations • Combinations • Binomial Coefficients\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                30 Aug, 2023\n            \n            \n                9. The Method of Double Counting\n                Examples of proofs by double-counting\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                12 Sep, 2023\n            \n            \n                10. Intro to Graphs: Euler Tours\n                Necessary and Sufficient Conditions for Euler Tours • Computing Euler Tours\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                13 Sep, 2023\n            \n            \n                11. Hall's Theorem\n                Matchings • Congestion in Bipartite Graphs • Hall's Theorem • Applications\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                19 Sep, 2023\n            \n            \n                12. Graph Coloring\n                Map Coloring • Greedy Algorithms • Bipartite Graphs • k-Degenerate Graphs\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                20 Sep, 2023\n            \n            \n                13. Planarity\n                Planar Graphs are Five-Colorable • Obstructions to Planarity\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                26 Sep, 2023\n            \n            \n                14. Graphs Recap\n                ~\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                27 Sep, 2023\n            \n            \n                15. Probability Intro\n                Basics of Discrete Probability • Monty Hall • Conditional Probability\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                03 Oct, 2023\n            \n            \n                16. The Probabilistic Method - I\n                An Introduction to the Method • Applications in Graph Theory\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                04 Oct, 2023\n            \n            \n                17. The Probabilistic Method - II\n                Ramsey Number • Sum-Free Sets\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                10 Oct, 2023\n            \n            \n                18. Recap\n                ~\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                17 Oct, 2023\n            \n            \n                19. The Linear Algebra Method - I\n                OddTown and EvenTown\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                18 Oct, 2023\n            \n            \n                20. The Linear Algebra Method - II\n                VC Dimension of a Set System • Sauer's Lemma\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                31 Oct, 2023\n            \n            \n                21. Intro to Groups: Rotations and Symmetries\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                01 Nov, 2023\n            \n            \n                22. Permutation and Cyclic Groups\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                07 Nov, 2023\n            \n            \n                23. Homomorphisms\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                08 Nov, 2023\n            \n            \n                24. Quotient Groups and First Isomorphism Theorem\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                14 Nov, 2023\n            \n            \n                25. Intro to Number Theory: Extended Euclid's Algorithm\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                15 Nov, 2023\n            \n            \n                26. Chinese Remainder Theorem\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                21 Nov, 2023\n            \n            \n                27. Applications I: RSA\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                22 Nov, 2023\n            \n            \n                28. Applications II: PageRank\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                23 Nov, 2023\n            \n            \n                29. Recap\n                ~\n            \n            \n            \n            \n            \n            \n            \n        \n\n\n\nNo matching items\n\n\n\nLive Streams\n\n\n\n\n\n    \n        Date\n        Lecture\n        Slides\n        Notes\n        Video\n    \n    \n                    \n            \n                02 Aug, 2023\n            \n            \n                1. Intro to Proofs - I\n                General Methods • Chessboard Tilings • Game of Chomp\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                03 Aug, 2023\n            \n            \n                2. Intro to Proofs - II\n                Pigeonhole Principle • Illustrative Examples\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                08 Aug, 2023\n            \n            \n                3. Sets\n                Definitions • Operations • Showing Containment • Showing Equality\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                09 Aug, 2023\n            \n            \n                4. Functions and Relations\n                Injections, Surjections, Bijections • Compositions • Equivalence Classes\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                16 Aug, 2023\n            \n            \n                5. Induction\n                Dominoes, Ladders, and Chips • Examples • Non-Examples • Strong Induction\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                22 Aug, 2023\n            \n            \n                6. Propositional and Predicate Logic\n                Syntax • Truth Tables • Quantifiers\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                23 Aug, 2023\n            \n            \n                7. Inference Systems\n                Inference Rules (e.g, Modus Ponens, Modus Tollens, Resolution, etc) • Paradoxes\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                29 Aug, 2023\n            \n            \n                8. Elementary Counting Methods\n                Permutations • Combinations • Binomial Coefficients\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                30 Aug, 2023\n            \n            \n                9. The Method of Double Counting\n                Examples of proofs by double-counting\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                12 Sep, 2023\n            \n            \n                10. Intro to Graphs: Euler Tours\n                Necessary and Sufficient Conditions for Euler Tours • Computing Euler Tours\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                13 Sep, 2023\n            \n            \n                11. Hall's Theorem\n                Matchings • Congestion in Bipartite Graphs • Hall's Theorem • Applications\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                19 Sep, 2023\n            \n            \n                12. Graph Coloring\n                Map Coloring • Greedy Algorithms • Bipartite Graphs • k-Degenerate Graphs\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                20 Sep, 2023\n            \n            \n                13. Planarity\n                Planar Graphs are Five-Colorable • Obstructions to Planarity\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                26 Sep, 2023\n            \n            \n                14. Graphs Recap\n                ~\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                27 Sep, 2023\n            \n            \n                15. Probability Intro\n                Basics of Discrete Probability • Monty Hall • Conditional Probability\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                03 Oct, 2023\n            \n            \n                16. The Probabilistic Method - I\n                An Introduction to the Method • Applications in Graph Theory\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                04 Oct, 2023\n            \n            \n                17. The Probabilistic Method - II\n                Ramsey Number • Sum-Free Sets\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                10 Oct, 2023\n            \n            \n                18. Recap\n                ~\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                17 Oct, 2023\n            \n            \n                19. The Linear Algebra Method - I\n                OddTown and EvenTown\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                18 Oct, 2023\n            \n            \n                20. The Linear Algebra Method - II\n                VC Dimension of a Set System • Sauer's Lemma\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                31 Oct, 2023\n            \n            \n                21. Intro to Groups: Rotations and Symmetries\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                01 Nov, 2023\n            \n            \n                22. Permutation and Cyclic Groups\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                07 Nov, 2023\n            \n            \n                23. Homomorphisms\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                08 Nov, 2023\n            \n            \n                24. Quotient Groups and First Isomorphism Theorem\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                14 Nov, 2023\n            \n            \n                25. Intro to Number Theory: Extended Euclid's Algorithm\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                15 Nov, 2023\n            \n            \n                26. Chinese Remainder Theorem\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                21 Nov, 2023\n            \n            \n                27. Applications I: RSA\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                22 Nov, 2023\n            \n            \n                28. Applications II: PageRank\n                TBA\n            \n            \n            \n            \n            \n            \n            \n        \n                    \n            \n                23 Nov, 2023\n            \n            \n                29. Recap\n                ~\n            \n            \n            \n            \n            \n            \n            \n        \n\n\n\nNo matching items\n\n\n\nAssignments\n\n\n\nWe will share user-developed content here.\n\n\n\n\n    \n        Issued\n        Assessment\n        Problems\n        Solutions\n        Due\n    \n    \n                    \n            \n                01 Aug, 2023\n            \n            \n                Coming Soon\n                \n            \n            \n                    \n                \n            \n                    \n                \n            \n            \n        \n\n\n\nNo matching items"
  },
  {
    "objectID": "materials/games/index.html",
    "href": "materials/games/index.html",
    "title": "Combinatorial Games",
    "section": "",
    "text": "Lecture Notes\n\n\non Computational and Combinatorial Aspects of Games\n\n\n \n\nThese are running notes on selected topics in combinatorial games.\nI have been developing these as a part of my course on Computational and Combinatorial Aspects of Games IIT Gandhinagar. Please see the course websites for additional materials (e.g, problem sets).\nAt the time of this writing these notes are largely raw and informal, with an emphasis on quick recaps and providing for interactive experiences. They certainly do not substitute — but hopefully do supplement — an actual textbook :) I borrow heavily from the following books:\n\nPlaying with Discrete Math. This text is appropriate for undergrads who may or may not be math majors.\nGames, puzzles and computation. This text, based on the thesis of Robert A. Hearn, explores computational aspects of games.\n\nIf you have any general comments or questions, please leave them below. Thanks!"
  },
  {
    "objectID": "materials/games/greedy/file-storage/index.html",
    "href": "materials/games/greedy/file-storage/index.html",
    "title": "1. Storing Files on a Tape",
    "section": "",
    "text": "Acknowledgements\n\n\n\nThis write up is borrowed (with minor adaptations) from Chapter 4 of Jeff Erickson’s textbook on Algorithms. The interactive illustrations were generated with assistance from ChatGPT (the May 12 version).\n\n\n\nThe Problem\nSuppose we have a set of n files that we want to store on magnetic tape1. In the future, users will want to read those files from the tape. Reading a file from tape isn’t like reading a file from disk; first we have to fast-forward past all the other files, and that takes a significant amount of time. Let L[1 \\ldots n] be an array listing the lengths of each file; specifically, file i has length L[i]. If the files are stored in order from 1 to n, then the cost of accessing the k th file is\n\n\\operatorname{cost}(k)=\\sum_{i=1}^{k} L[i] .\n\nThe cost reflects the fact that before we read file k we must first scan past all the earlier files on the tape. If we assume for the moment that each file is equally likely to be accessed, then the expected cost of searching for a random file is\n\n\\mathrm{E}[\\operatorname{cost}]=\\sum_{k=1}^{n} \\frac{\\operatorname{cost}(k)}{n}=\\frac{1}{n} \\sum_{k=1}^{n} \\sum_{i=1}^{k} L[i] \\text {. }\n\nIf we change the order of the files on the tape, we change the cost of accessing the files; some files become more expensive to read, but others become cheaper. Different file orders are likely to result in different expected costs. Specifically, let \\pi(i) denote the index of the file stored at position i on the tape. Then the expected cost of the permutation \\pi is\n\n\\mathrm{E}[\\operatorname{cost}(\\pi)]=\\frac{1}{n} \\sum_{k=1}^{n} \\sum_{i=1}^{k} L[\\pi(i)]\n\nWhich order should we use if we want this expected cost to be as small as possible? Try this yourself in the demonstration below. The tape is the grey rectangle, and the files are the colored boxes below it. The widths of the boxes are proportional to the file lengths. Double-click to get a file outside the tape to push it on the tape, and double-click a file on the tape to remove it. Can you match the optimal cost?\n\n\n\n\n\n\n\n\n\nAverage: 0\n\n\nTarget:\n\n\nKeep going until all pieces are on the tape…\n\n\n\nAfter some playing around, you may have come to the conclusion that you should sort the files by increasing length. Indeed, the length of the first file shows up the most frequently in the expression we are trying to optimize, while the length of the last file shows up just once: so it seems clear that the larger files should be pushed to the end.\nHowever — and especially so with greedy approaches — intuition is a tricky beast. The only way to be sure that this order works is to actually prove that it works!\n\n\nGreedy Works Out\n\n\n\n\n\n\nCorrectness of Greedy - I\n\n\n\nLemma. \\mathrm{E}[\\operatorname{cost}(\\pi)] is minimized when L[\\pi(i)] \\leq L[\\pi(i+1)] for all i.\nSuppose L[\\pi(i)]>L[\\pi(i+1)] for some index i. To simplify notation, let a=\\pi(i) and b=\\pi(i+1). If we swap files a and b, then the cost of accessing a increases by L[b], and the cost of accessing b decreases by L[a]. Overall, the swap changes the expected cost by (L[b]-L[a]) / n. But this change is an improvement, because L[b]<L[a]. Thus, if the files are out of order, we can decrease the expected cost by swapping some mis-ordered pair of files.\n\n\nTry dragging the borders below to see how changes in file sizes impacts the average cost.\n\n\n\n105\n\n\n\n\n\n105\n\n\n\n\n\n105\n\n\n\n\n\n105\n\n\n\n\nCurrent Cost: 262.5\n\n\nOptimal Cost: 262.5\n\n\n\nThis is our first example of a correct greedy algorithm. To minimize the total expected cost of accessing the files, we put the file that is cheapest to access first, and then recursively write everything else; no backtracking, no dynamic programming, just make the best local choice and blindly plow ahead. If we use an efficient sorting algorithm, the running time is clearly O(n \\log n), plus the time required to actually write the files. To show that the greedy algorithm is actually correct, we proved that the output of any other algorithm can be improved by some sort of exchange.\n\n\nFrequencies\nLet’s generalize this idea further. Suppose we are also given an array F[1 \\ldots n] of access frequencies for each file; file i will be accessed exactly F[i] times over the lifetime of the tape. Now the total cost of accessing all the files on the tape is\n\n\\Sigma \\cos t(\\pi)=\\sum_{k=1}^{n}\\left(F[\\pi(k)] \\cdot \\sum_{i=1}^{k} L[\\pi(i)]\\right)=\\sum_{k=1}^{n} \\sum_{i=1}^{k}(F[\\pi(k)] \\cdot L[\\pi(i)]) .\n\nAs before, reordering the files can change this total cost. So what order should we use if we want the total cost to be as small as possible? (This question is similar in spirit to the optimal binary search tree problem, but the target data structure and the cost function are both different, so the algorithm must be different, too.)\nWe already proved that if all the frequencies are equal, we should sort the files by increasing size. If the frequencies are all different but the file lengths L[i] are all equal, then intuitively, we should sort the files by decreasing access frequency, with the most-accessed file first.\n\n\n\n\n\n\nFood For Thought\n\n\n\nProve this formally by adapting the proof from the previous discussion.\n\n\nBut what if the sizes and the frequencies both vary? In this case, we should sort the files by the ratio L / F.\n\n\n\n\n\n\nCorrectness of Greedy - II\n\n\n\nLemma. \\Sigma \\operatorname{cost}(\\pi) is minimized when \\frac{L[\\pi(i)]}{F[\\pi(i)]} \\leq \\frac{L[\\pi(i+1)]}{F[\\pi(i+1)]} for all i.\nProof: Suppose L[\\pi(i)] / F[\\pi(i)]>L[\\pi(i+1)] / F[\\pi(i+i)] for some index i. To simplify notation, let a=\\pi(i) and b=\\pi(i+1). If we swap files a and b, then the cost of accessing a increases by L[b], and the cost of accessing b decreases by L[a]. Overall, the swap changes the total cost by L[b] F[a]-L[a] F[b]. But this change is an improvement, because\n\n\\frac{L[a]}{F[a]}>\\frac{L[b]}{F[b]} \\Longleftrightarrow L[b] F[a]-L[a] F[b]<0 .\n\nThus, if any two adjacent files are out of order, we can improve the total cost by swapping them.\n\n\n\n\n\n\n\nFootnotes\n\n\nJust in case you have not heard of them, here’s Wikipedia on magnetic tapes :)↩︎"
  },
  {
    "objectID": "materials/games/greedy/scheduling/index.html",
    "href": "materials/games/greedy/scheduling/index.html",
    "title": "2. A Scheduling Problem",
    "section": "",
    "text": "Acknowledgements\n\n\n\nThis write up is borrowed (with minor adaptations) from Chapter 4 of Jeff Erickson’s textbook on Algorithms.\n\n\n\nThe Problem\nSuppose you decide to sign up for dance classes, and a dance academy next door offers a bunch of classes, but only on Saturdays. You cannot take two classes whose timings overlap: for example, in the example shown in the figure below, the Bollywood and Ballet classes are clashing, so you would have to pick one between the two.\n\nMore formally:\n\nSuppose you are given two arrays S[1 \\ldots n] and F[1 \\ldots n] listing the start and finish times of each class; to be concrete, we can assume that 0 \\leq S[i]<F[i] \\leq M for each i, for some value M.\nYour task is to choose the largest possible subset X \\in\\{1,2, \\ldots, n\\} so that for any pair i, j \\in X, either S[i]>F[j] or S[j]>F[i].\n\nWe can illustrate the problem by drawing each class as a rectangle whose left and right x-coordinates show the start and finish times. The goal is to find a largest subset of rectangles that do not overlap vertically, as shown below1.\n\nNotice that there are several natural greedy approaches to this problem. A template for a greedy algorithm would look like this:\nrepeat while there is at least one class left:\n- pick a class, say C, that is <<GREEDY CHOICE>>\n- eliminate C and all classes that clash with C from the collection\nHere are some “natural” greedy choices:\n\npick a class that has the shortest duration\npick a class that has the fewest clashes with other classes\npick a class that starts as early as possible\npick a class that finishes as early as possible\n\n\n\n\n\n\n\nGreedy Does Not Work!\n\n\n\nIt turns out that the first three greedy approaches are actually wrong, in the sense that there are examples on which they will fail to produce an optimal schedule. Can you construct these examples?\n\n\nThe intuition for the last option above is that we would like the first class to finish as early as possible, because that leaves us with the largest number of remaining classes. This intuition suggests the following simple greedy algorithm. Scan through the classes in order of finish time; whenever you encounter a class that doesn’t conflict with your latest class so far, take it! Here is some pseudocode that captures this process:\nGreedySchedule(S,F)\n\nsort F and permute S to match \ncount = 1\nX[count] = 1\n\nfor i from 2...n:\n    if S[i]>F[X[count]]\n        count = count +1\n        X[count] = i\nreturn X[1...count]\nA greedy algorithm for finding a maximum set of non-overlapping classes\n\n\nGreedy Works Out\nTo prove that GreedySchedule actually computes the largest conflict-free schedule, we use an exchange argument, similar to the one we used for tape sorting. We are not claiming that the greedy schedule is the only maximal schedule; there could be others. (Can you come with examples to justify this comment?)\nAll we can claim is that at least one of the optimal schedules is the one produced by the greedy algorithm.\n\n\n\n\n\n\nAt least one maximal conflict-free schedule includes the class that finishes first.\n\n\n\nProof: Let f be the class that finishes first. Suppose we have a maximal conflict-free schedule X that does not include f. Let g be the first class in X to finish. Since f finishes before g does, f cannot conflict with any class in the set X \\backslash\\{g\\}. Thus, the schedule X^{\\prime}=X \\cup\\{f\\} \\backslash\\{g\\} is also conflict-free. Since X^{\\prime} has the same size as X, it is also maximal.\n\n\nTo finish the proof, we call on our old friend induction.\n\n\n\n\n\n\nTheorem. The greedy schedule is an optimal schedule.\n\n\n\nProof: Let f be the class that finishes first, and let A be the subset of classes that start after f finishes. The previous lemma implies that some optimal schedule contains f, so the best schedule that contains f is an optimal schedule. The best schedule that includes f must contain an optimal schedule for the classes that do not conflict with f, that is, an optimal schedule for A. The greedy algorithm chooses f and then, by the inductive hypothesis, computes an optimal schedule of classes from A.\n\n\nAnother way to see why greedy works is the following. Consider the finish times of all the greedy choices. Note that every other class contains at least one of these finish times: if not, then there is a class that starts after the i^{th} earliest class to start (among the greedy choices) and finishes before the (i+1)^{th} earliest class to start (among the greedy choices). This means that the choice made by the greedy algorithm in the (i+1)^{th} step was not on brand: a contradiction.\n\nWhy is this observation useful? Well, suppose the greedy algorithm outputs a collection of k classes. Then define the following groups of classes: — the j-th group consists of all classes that are active during the finish time of the j^{th} earliest class to start among the greedy chocies. These groups form a cover, i.e, every class belongs to at least one of these groups because of our observation earlier. Now notice that all classes within any group are mutually clashing, because they are all active at a common time. Therefore, any valid solution cannot pick more than one class from a given group, implying therefore that any solution must have at most k classes. But the greedy outcome has exactly k classes, so this is indeed the best we can hope for.\n\n\nGeneral Patterns\nThe basic structure of this correctness proof is exactly the same as for the tape-sorting problem: an inductive exchange argument.\n\nAssume that there is an optimal solution that is different from the greedy solution.\nFind the “first” difference between the two solutions. - Argue that we can exchange the optimal choice for the greedy choice without making the solution worse (although the exchange might not make it better).\n\nThis argument implies by induction that some optimal solution contains the entire greedy solution, and therefore equals the greedy solution. Sometimes, as in the scheduling problem, an additional step is required to show no optimal solution strictly improves the greedy solution.\n\n\n\n\n\nFootnotes\n\n\nWhy is this optimal?↩︎"
  },
  {
    "objectID": "materials/games/greedy/stable-matchings/index.html",
    "href": "materials/games/greedy/stable-matchings/index.html",
    "title": "3. Stable Matchings",
    "section": "",
    "text": "The Problem\nThe problem of pairing up people and/or resources shows up a lot:\n\nMatching students who graduate high school to seats in various colleges.\nMatching students who graduate college to employers for jobs, internships, residencies, and so on.\nGetting actors and actresses to commit to work together for films amidst various constraints.\nMatching organ donors to patients accounting for constraints of compatibility and timing.\nMatching men and women in a dating/marriage market.\n\nWe are going to look at one particular abstraction that captures many of the scenarios above (among others). Suppose we have a set V = \\{m_1, \\ldots, m_n\\} of n men and W = \\{w_1, \\ldots, w_n\\} of n women, where each man (respectively, woman) has a strict and complete ranking over the women (respectively, men). Our goal is to find a matching between the men and the women, which is to say, a bijection between V and W.\nNow, a natural question at this point is: what kind of matchings do we want to find? Unconstrained, there are plenty of matchings that we can choose from. Which one is the “best”?\nUpon a moment’s reflection you might come up with several ideas. We are going to focus on a fundamental game-theoretic approach to identifying what we desire from the matchings we seek. What we will demand of the matching M that we seek is that there is no man and woman who are unmatched in M who prefer each other over their matched partners. To this end, we first define the notion of a blocking pair with respect to M:\n\n\n\n\n\n\nBlocking Pair\n\n\n\nGiven a matching M between n men and n women, if a \\in V and b \\in W, then (a,b) forms a blocking pair if ALL of the following hold:\n\na and b are not matched to each other in M,\na prefers b over M(a),\nb prefers a over M(b)\n\n\n\nThe presence of a blocking pair (a,b) implies that the matching M is unlikely to “sustain”: a and b both have an incentive to break off the alliances suggested by the matching M and “elope” with each other instead. Thus, matchings that have blocking pairs are called unstable.\n\n\n\n\n\n\nUnstable Matching\n\n\n\nA matching M is said to be unstable if there is a blocking pair with respect to M.\n\n\n\n\n\n\n\n\nAn Example of a Matching with no blocking pairs.\n\n\n\n\n\nConsider the preferences given below (where the first column in each row is the ID of the men and the women, and the remaining columns indicate the rank):\n\n\n\nMen\n1\n2\n3\n4\n\n\n\n\n1\n2\n4\n1\n3\n\n\n2\n3\n1\n4\n2\n\n\n3\n2\n3\n1\n4\n\n\n4\n4\n1\n3\n2\n\n\n\n\n\n\nWomen\n1\n2\n3\n4\n\n\n\n\n1\n2\n1\n4\n3\n\n\n2\n4\n3\n1\n2\n\n\n3\n1\n4\n3\n2\n\n\n4\n2\n1\n4\n3\n\n\n\nand the matching given by: M = (1,4), (2,3), (3,2), (4,1). Notice that this matching has, in fact, no blocking pairs.\n\n\n\n\n\n\n\n\n\nHow many blocking pairs can we have?\n\n\n\nCome up with a stable matching instance that has \\Omega(n^2) blocking pairs. What’s the maximum number possible?\n\n\nA matching without blocking pairs is called stable.\n\n\n\n\n\n\nStable Matching\n\n\n\nA matching M is said to be stable if there are no blocking pairs with respect to M.\n\n\nIt’s easy to verify if a given matching M is stable: for all men m we look up all women w that m ranks higher than M(m), and check if w also ranks m higher than M(w): if yes, then we can declare M unstable since (m,w) is a blocking pair. If we find no blocking pairs after having checked all men m, then we can declare that M is stable.\nThis takes at most O(n^2) time, assuming that ranks can be retrieved in constant time. Thus we have the following.\n\n\n\n\n\n\nVerifying that a matching is stable.\n\n\n\nGiven a matching M between n men and n women and their preferences over each other, it is possible to verify if M is stable in O(n^2) time.\n\n\nThe next natural questions are:\n\nDo stable matchings always exist?\n\nIf yes: can we always find them efficiently?\nIf not: can we efficiently find matchings that minimize the number of blocking pairs?\n\n\nThis is a good place to pause and ponder!\n\n\nDeveloping a Solution\nIt turns out that (somewhat surprisingly!) stable matchings indeed always exist!\nThe algorithm for finding a stable matching works as follows. To begin with, we say that all men and women are single, i.e, unmatched to anyone so far.\nAnticipating our need for stability, we take a greedy approach: the men attempt to match up to their best option by proposing to them. But notice that this may not be immediately workable: possibly multiple men have the same choice for their top option. This puts the ball in the woman’s court, so to speak, and again in the interest of being eventually stable, it’s intuitive that the woman will choose to align with the best offer she has among the proposals she’s recieved.\nAlso, since we finally want everyone to be matched, we will also ensure that proposals are not rejected simply because they seem unattractive in absolute terms: if a woman who’s single recieves one or more proposals, she will accept the best among them, no matter how good or bad they are.\nAfter one round of proposals, the situation is as follows:\n\nsome women (say W_\\star \\subseteq W) recieved one or more proposals and picked the best offer, and are no longer single;\nsome women (say W_0 = W \\setminus W_\\star) recieved no proposals and are still single;\nsome men (say V_\\star \\subseteq V) had their proposals accepted and they are no longer single ;\nsome men (say V_0 = V \\setminus V_\\star) were turned down and are still single.\n\nIf W_0 = \\emptyset, that’s… well, that’s awesome, because what that means is all men had distinct choices for their top preference, and so V_0 = \\emptyset as well and we already have a matching where everyone has their best possible match: so this is clearly very stable and we are done.\nOn the other hand, it’s possible that W_0 \\neq \\emptyset, which is to say that some women are still single, and therefore there are some single men as well. Now, to make progress, single men go back to the drawing board and propose again. Now, a natural question at this point is the following:\n\nShould the currently single men try their luck again with women who’ve rejected them?\n\nWell, since they were rejected for good reason (said women had better offers), and the reason has not gone away, it is clearly a waste of time for men to go back to women who’ve rejected them. So what they do instead is to propose to the next best option. Now: what if their next best option is not a single woman? Well, suppose m decides to not approach w because w is matched to some m^\\star in the first round. Then m will eventually be matched to someone who’s worse than w, and if w happened to prefer m over m^\\star, then (m,w) will eventually be a blocking pair.\nHowever, recall that this is exactly the situation we want to avoid. So we’re going to have m propose to their next best option irrespective of whether they are single or not. From the woman’s perspective, they are going to recieve proposals again, and we’ll let them pick the best offer, even if it means breaking off their current engagement.\nAfter this second round of proposals we again have some single men and women, and some engagements. Note that the following invariant is true:\n\nAny woman who was not single at the end of the first round remains engaged at the end of the second round as well.\n\nMen, on the other hand, may become single again. At this point, we simply continue as before: at the end of every round, the single men continue to propose to their current best option, and the women continue to accept the best offer that they have. We continue this until there are no single men left.\n\n\nThe Algorithm and its Properties\nHere’s pseudocode (borrowed from Wikipedia) summarizing the algorithm, which is due to Gale and Shapley. The version below is morally equivalent to our description above, except that all proposals happen one by one, and it turns out that this way of looking at it simplifies the analysis.\nalgorithm stable_matching is\n    Initialize m ∈ M and w ∈ W to free\n    while ∃ free man m who has a woman w to propose to do\n        w := first woman on m's list to whom m has not yet proposed\n        if ∃ some pair (m', w) then\n            if w prefers m to m' then\n                m' becomes free\n                (m, w) become engaged\n            end if\n        else\n            (m, w) become engaged\n        end if\n    repeat\nIt turns out that this procedure:\n\nterminates in finite time (in fact, after O(n^2) proposals have been made)\noutputs a perfect matching M between the men and the women that has no blocking pairs.\n\nThe first property follows from the fact that men never propose twice to the same woman, so the number of proposals made is \\leqslant n^2 . Also note that no man m is rejected by all women: this can only happen if all the women have found better engagements (which are necessarily distinct — notice that the set of engagments at any stage of the algorithm always forms a valid matching), but there are only n-1 men other than w: so this is not feasible.\nSo we know that the while loop terminates, and that once it does we have a matching M.\nIt remains to show that M is stable. But if M has a blocking pair (m,w), then w was proposed to by m before m proposed to M(w), and since (m,w) are not matched in M, it must be the case that w prefers M(w) over m, so (m,w) cannot be a blocking pair after all.\nThis brings us to the following claim:\n\n\n\n\n\n\nFinding a stable matching\n\n\n\nGiven a matching M between n men and n women and their preferences over each other, it is possible to find a stable matching M in O(n^3) time.\n\n\nThe output of the Gale-Shapley algorithm has a couple of interesting properties. First off, it turns out that the output is not just stable, but also qualitatively very good. Let us define, for a man m, their optimal match as the best woman that m can be matched to in any stable matching. It turns out that M matches all men to their optimal matches!\n\n\n\n\n\n\nThe Men Are Lucky\n\n\n\nLet M be the output of the GS algorithm. For all men m, there is no stable matching M^\\star where m prefers M^\\star(m) over M(m).\n\n\nAlso, the output of GS is weakly Pareto optimal, which is to say that there is no matching (stable or otherwise), where all the men are better off.\n\n\n\n\n\n\nThe GS matching is weakly PO\n\n\n\nLet M be the output of the GS algorithm. There is no matching M^\\star for which it is true that all men m prefer M^\\star(m) over M(m).\n\n\nWe state these claims above without proof. The interested reader should look them up!\n\n\nReferences\nNumberphile video about the algorithm\nNumberphile video about the proof\nNotes on implementation details"
  },
  {
    "objectID": "materials/games/greedy/index.html",
    "href": "materials/games/greedy/index.html",
    "title": "Greedy Algorithms",
    "section": "",
    "text": "It is perhaps not often that greed is good, but in the context of the problems that we encounter in this chapter, we are going to make greedy look good! Read on to find out more about:\n\nFiles on a Tape\nDance Classes\nStable Marriages"
  },
  {
    "objectID": "materials/games/game-trees/subtraction/index.html",
    "href": "materials/games/game-trees/subtraction/index.html",
    "title": "1. Game Trees",
    "section": "",
    "text": "1. Game Trees\n  \n    algonotes\n    lecturenotes\n  \n  \n\n\n\n\n\n    \n    \n    Published\n    \n      May 16, 2023\n    \n  \n  \n    \n  \n  \n\n\n\n\n\n\n\n\n\nAcknowledgements\n\n\n\nThis write up is based on material from Sections 0.1 — 0.3 of Kyle Burke and Craig Tennenhouse’s textbook on Playing wiht Discrete Mathematics. The interactive games were generated with assistance from ChatGPT (the May 12 version).\n\n\n\nMain Ideas\nWe are going to play some games, and analyze them! Informally speaking, our games consist of:\n\ntwo players who take turns to play\na setup that describes the state of the game at the beginning\na ruleset that describe the moves that are available to the players, and a description of how these rules affect the state of the game\na winning condition: typically, the player who has no valid moves loses\n\nFor now, there will be no probabilities involved (so Poker does not fit the bill above), and no skills required to execute the moves (so Cricket is not our kind of game here).\nThe two players have several names by which we may refer to them:\n\nfirst player, second player\nleft player, right player\nAlice, Bob\nLata, Raj\n\nA winning strategy for any player is a powerful thing: it’s a way for the player to respond to every move of the opponent in a manner that guarantees a win. You can think of a strategy as a function that maps game states to valid moves, and a winning strategy is a strategy which, if followed, always ends in a win for the player employing it. Instead of saying “Player X has a winning strategy”, we will just say “Player X wins”, or in question form, “Does player X win?” — even though it may be technically possible for a player to “throw a game”, we will assume optimal play.\n\n\n\n\n\n\nSubtraction\n\n\n\nSUBTRACTION is a game played on a heap of tokens. Each turn, the current player can remove either 1,2, or 3 tokens from the pile, provided enough tokens exist. When the pile is empty there are no available moves. The player with no valid moves left loses.\n\n\n\nYou can play the game below.\n\n\n\n\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n\nLata’s turn to move.\n\n\n\n\n\n\n\n\n\nCorrectness of Greedy - II\n\n\n\n\n\n\n\nCollapsible Tree\n\n\na:  b:  n:"
  },
  {
    "objectID": "materials/games/game-trees/index.html",
    "href": "materials/games/game-trees/index.html",
    "title": "Impartial Games",
    "section": "",
    "text": "It is perhaps not often that greed is good, but in the context of the problems that we encounter in this chapter, we are going to make greedy look good! Read on to find out more about:\n\nGame Trees\nDance Classes\nStable Marriages"
  },
  {
    "objectID": "materials/games/impartial-games/game-trees/index.html",
    "href": "materials/games/impartial-games/game-trees/index.html",
    "title": "1. Game Trees",
    "section": "",
    "text": "1. Game Trees\n  \n    algonotes\n    lecturenotes\n  \n  \n\n\n\n\n\n    \n    \n    Published\n    \n      May 16, 2023\n    \n  \n  \n    \n  \n  \n\n\n\n\n\n\n\n\n\nAcknowledgements\n\n\n\nThis write up is based on material from Sections 0.1 — 0.3 of Kyle Burke and Craig Tennenhouse’s textbook on Playing wiht Discrete Mathematics. The interactive games were generated with assistance from ChatGPT (the May 12 version).\n\n\n\nMain Ideas\nWe are going to play some games, and analyze them! Informally speaking, our games consist of:\n\ntwo players who take turns to play\na setup that describes the state of the game at the beginning\na ruleset that describe the moves that are available to the players, and a description of how these rules affect the state of the game\na winning condition: typically, the player who has no valid moves loses\n\nFor now, there will be no probabilities involved (so Poker does not fit the bill above), and no skills required to execute the moves (so Cricket is not our kind of game here).\nThe two players have several names by which we may refer to them:\n\nfirst player, second player\nleft player, right player\nAlice, Bob\nLata, Raj\n\nA winning strategy for any player is a powerful thing: it’s a way for the player to respond to every move of the opponent in a manner that guarantees a win. You can think of a strategy as a function that maps game states to valid moves, and a winning strategy is a strategy which, if followed, always ends in a win for the player employing it. Instead of saying “Player X has a winning strategy”, we will just say “Player X wins”, or in question form, “Does player X win?” — even though it may be technically possible for a player to throw a game, we will always assume optimal play unless mentioned otherwise.\n\n\nSubtraction\nHere’s our first game:\n\n\n\n\n\n\nSubtraction\n\n\n\nSubtraction is a game played on a heap of tokens. The game begins with N tokens on a pile.\n\nEach turn, the current player can remove either 1,2, or 3 tokens from the pile, provided enough tokens exist.\nWhen the pile is empty there are no available moves.\nThe player with no valid moves left loses.\n\n\n\nYou can play this game below: the number of tokens that we start with is chosen randomly, so you should have a new game every time you referesh this page :)\n\n\n\n\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n\n\n\nLata’s turn to move.\n\n\n\n\n\nHere’s a more general version of the game where the number of tokens you are allowed to remove is not 1,2,3; but 1, a and b, where a and b are distinct numbers chosen randomly between 2 and 10. As before, it is a new game every time you referesh this page.\n\n\n\n\n\n\n\n\n\n1\n\n\n\n\n\n\n\n\n\nLata’s turn to move.\n\n\n\n\n\nLet us refer to the player whose turn it is as the current player, and the player who is up next as the other player. Coming back to the 1,2,3 Subtraction game, note that:\n\nIf there are no tokens, the position is losing for the current player.\nIf the number of tokens is 1, 2, or 3, the position is winning for the current player.\nIf the number of tokens is 4, the position is losing for the current player. (Why?)\n\nCan you generalize the reasoning above?\n\n\nGame Trees\nA game tree is a useful representation of game states over all possible progressions of game play from the start. In particular:\n\nThe root represents the starting state of the game.\nIf the state of the game represented by a node x has t valid moves — say m_1, \\ldots, m_t for the current player, then:\n\nx has t children y_1, \\ldots, y_t\nthe node y_i represents the state of the game that is obtained from x if the move m_i is made by the current player\n\n\nNote the the leaf nodes are terminal states of the game, this is where there are no moves remaining to be made. Observe that:\n\nEvery leaf node is a losing position for the current player\nAn internal node is winning for the current player if and only if it has a child node that is losing for the current player (Why?)\n\nYou can build out the game tree for Subtraction with 1, a, and b tokens, starting with n tokens, by supplying the values of a, b, and n below. The red nodes represent positions that are losing for the current player (equivalently, winning for the other player), while the green nodes represent positions that are winning for the current player (equivalently, losing for the other player).\n\n\n\n\n\n\nHeads up!\n\n\n\nNote that the nodes collapse on click, but unfortunately do not retain the correct color state on collapse.\nThis is a caveat that should be fixed soon!\n\n\n\na:            b:            n:"
  },
  {
    "objectID": "materials/games/impartial-games/index.html",
    "href": "materials/games/impartial-games/index.html",
    "title": "Impartial Games",
    "section": "",
    "text": "We are going to setup the terminology that we will use for the rest of our discussions, and play some games while at it! Read on to find out more about:\n\nGame Trees\nGame Sums [TBA]\nNim and Nimbers [TBA]\nOther Impartial Games [TBA]"
  },
  {
    "objectID": "materials/games/impartial-games/game-trees/index.html#game-trees",
    "href": "materials/games/impartial-games/game-trees/index.html#game-trees",
    "title": "1. Game Trees",
    "section": "Game Trees",
    "text": "Game Trees\nA game tree is a useful representation of game states over all possible progressions of game play from the start. In particular:\n\nThe root represents the starting state of the game.\nIf the state of the game represented by a node x has t valid moves — say m_1, \\ldots, m_t for the current player, then:\n\nx has t children y_1, \\ldots, y_t\nthe node y_i represents the state of the game that is obtained from x if the move m_i is made by the current player\n\n\nNote the the leaf nodes are terminal states of the game, this is where there are no moves remaining to be made. Observe that:\n\nEvery leaf node is a losing position for the current player\nAn internal node is winning for the current player if and only if it has a child node that is losing for the current player (Why?)\n\nYou can build out the game tree for (1,a,b)-Subtraction starting with n tokens, by supplying the values of a, b, and n below. The red nodes represent positions that are losing for the current player (equivalently, winning for the other player), while the green nodes represent positions that are winning for the current player (equivalently, losing for the other player).\n\n\n\n\n\n\nHeads up!\n\n\n\nNote that the nodes collapse on click, but unfortunately do not retain the correct color state on collapse.  This is a caveat that should be fixed soon!\n\n\n\na:            b:            n:"
  },
  {
    "objectID": "materials/games/impartial-games/game-trees/index.html#main-ideas",
    "href": "materials/games/impartial-games/game-trees/index.html#main-ideas",
    "title": "1. Game Trees",
    "section": "Main Ideas",
    "text": "Main Ideas\nWe are going to play some games, and analyze them! Informally speaking, our games consist of:\n\ntwo players who take turns to play\na setup that describes the state of the game at the beginning\na ruleset that describe the moves that are available to the players, and a description of how these rules affect the state of the game\na winning condition: typically, the player who has no valid moves loses\n\nFor now, there will be no probabilities involved (so Poker does not fit the bill above), and no skills required to execute the moves (so Cricket is not our kind of game here).\nThe two players have several names by which we may refer to them:\n\nfirst player, second player\nleft player, right player\nAlice, Bob\nLata, Raj\n\nA winning strategy for any player is a powerful thing: it’s a way for the player to respond to every move of the opponent in a manner that guarantees a win. You can think of a strategy as a function that maps game states to valid moves, and a winning strategy is a strategy which, if followed, always ends in a win for the player employing it. Instead of saying “Player X has a winning strategy”, we will just say “Player X wins”, or in question form, “Does player X win?” — even though it may be technically possible for a player to throw a game, we will always assume optimal play unless mentioned otherwise."
  },
  {
    "objectID": "materials/games/impartial-games/game-trees/index.html#subtraction",
    "href": "materials/games/impartial-games/game-trees/index.html#subtraction",
    "title": "1. Game Trees",
    "section": "Subtraction",
    "text": "Subtraction\nHere’s our first game:\n\n\n\n\n\n\nSubtraction\n\n\n\nSubtraction is a game played on a heap of tokens. The game begins with N tokens on a pile.\n\nEach turn, the current player can remove either 1,2, or 3 tokens from the pile, provided enough tokens exist.\nWhen the pile is empty there are no available moves.\nThe player with no valid moves left loses.\n\n\n\nYou can play this game below: the number of tokens that we start with is chosen randomly, so you should have a new game every time you referesh this page :)\n\n\n\n\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n\n\n\nLata’s turn to move.\n\n\n\n\n\nHere’s a more general version of the game where the number of tokens you are allowed to remove is not 1,2,3; but 1, a and b, where a and b are distinct numbers chosen randomly between 2 and 10. As before, it is a new game every time you referesh this page.\n\n\n\n\n\n\n\n\n\n1\n\n\n\n\n\n\n\n\n\nLata’s turn to move.\n\n\n\n\n\nLet us refer to the player whose turn it is as the current player, and the player who is up next as the other player. Coming back to the (1,2,3)-Subtraction game, note that:\n\nIf there are no tokens, the position is losing for the current player.\nIf the number of tokens is 1, 2, or 3, the position is winning for the current player.\nIf the number of tokens is 4, the position is losing for the current player. (Why?)\n\nCan you generalize the reasoning above?"
  },
  {
    "objectID": "materials/games/impartial-games/game-trees/index.html#takeaways-and-next-up",
    "href": "materials/games/impartial-games/game-trees/index.html#takeaways-and-next-up",
    "title": "1. Game Trees",
    "section": "Takeaways and Next Up",
    "text": "Takeaways and Next Up\nWhat we saw here:\n\nThe concept of a turn-based, two-player game with perfect information.\nThe notion of winning strategies and positions.\nThe idea of a game tree.\n\nNext time, we will discuss decomposing games into “disjoint unions” of smaller games."
  },
  {
    "objectID": "materials/games/impartial-games/game-trees/index.html#summary",
    "href": "materials/games/impartial-games/game-trees/index.html#summary",
    "title": "1. Game Trees",
    "section": "Summary",
    "text": "Summary\nWhat we saw here:\n\nThe concept of a turn-based, two-player game with perfect information.\nThe notion of winning strategies and positions.\nThe idea of a game tree.\n\nNext time, we will discuss decomposing games into “disjoint unions” of smaller games."
  },
  {
    "objectID": "blog/on-career-choices/index.html",
    "href": "blog/on-career-choices/index.html",
    "title": "On Career Choices",
    "section": "",
    "text": "A version of this article was featured in A Lesson from IIT, a column on the Indian Express. The link to the column is here, and this is the link to the present article. Many thanks to Ritika Chopra for prompting me to write this, and for not giving up on me as I took my time :)\nThanks are also due to friends Manasa, Jyothi, and Sharmistha for going over early versions of this writeup and sharing their thoughts!\n\n\n\nDuring school, my earliest exposure to the notion of being an engineer was an at-the-time popular audio clip called The Knack, in which a doctor is diagnosing a kid with a condition involving extreme intuition for all things mechanical and electrical. It is implied that having “the knack” is not compatible with a normal life, since the kid is now destined to… be an engineer. This causes his mother to experience much concern and grief. The episode inspired me to keep a polite but firm distance from all things engineering, conveniently including the entrance exams meant to unlock the gates of the IITs.\nCollege admissions are rife with two types of scenarios that are less than ideal: students ending up in programs that are not their cup of tea, and students missing out on experiences that would have been right up their alley. These mismatches are cumulatively expensive: there is the price paid in misallocated resources, and then there’s the personal cost of training for programs that eventually turn out to be a poor fit, which is typically very substantial.\nSome of this can be mitigated with an appreciation of what these programs entail, and what the campuses have to offer. The IITs are known predominantly for their undergraduate programs in the traditional engineering disciplines. However, several of them also host excellent programs in the sciences. Further, there are an increasing number of undergraduate programs that have interdisciplinary themes (such as the Btech program in Civil and Infrastructure Engineering with specialization in Smart Infrastructure at IIT Jodhpur) and a focus on emerging technologies and areas (for instance, the BTech program in Artificial Intelligence at IIT Hyderabad or the undergraduate program in Design at IIT Delhi).\nCurrently, awareness about these opportunities is mostly a heady mix of word of mouth, Quora answers, vibes from coffee-table conversations at coaching centers, and placement statistics on popular media. Impressions of what campus life entails is also largely a combination of imagination fueled by things seen on, say, Netflix and the like. However, if you are a prospective student or a parent of one, you would do well to go beyond these secondary sources of intelligence and get some first-hand experience.\nMost IITs host open days every so often: these are special days when the campuses are open to anyone to walk in, and professors and students from the organization delight in sharing what they are up to with accessible demonstrations or lab tours. A recent example is the G20-Ignite Sci-Tech fair which hosted hundreds of school students at the IIT Gandhinagar campus. Often, even one such experience can trigger an inner calling, helping you identify the thing you want to do for life – or at least for a substantial duration. \nYou could also go beyond the glimpses offered by open days. Watch out for opportunities to collaborate over small projects. For example, the Center for Creative Learning at IIT Gandhinagar welcomes high school students for short term projects over summer, and students who do well in courses on the NPTEL platform have a shot at internships with the instructors of those courses. Many professors delight in talking to students: check out the various seasons of Talk to a Scientist, for example. You can also ask your school to reach out to professors at nearby institutions for an interactive session, or approach organizations like INYAS that focus deeply on outreach activities at the school level. Finally, several IITs also host bootcamps, hackathons, and so on: they are usually announced on their websites and social media channels, so keep an eye out for these!\nHaving said all this, a choice of career – or more immediately, a branch or stream – does not have to be prompted necessarily by an intense love at first sight. The routes leading to your final pursuit(s) can be potentially meandering, and not having an inner voice abundant in clarity should be no cause for alarm. Examples of this abound, and I’ll share a representative one. Ronald Graham is arguably best-known as an American mathematician who made fundamental contributions to combinatorics. Because his father worked in various jobs related to oil fields and shipbuilding, he moved schools often. He did not study in any school for more than eighteen months and often studied in grades higher than what would have been normal for his age.\nAt the age of 15, Graham won a Ford Foundation scholarship to the University of Chicago, where he spent three years learning gymnastics. Because of his outstanding performance in math on the scholarship examinations, he did not (have to) take any mathematics courses. After the duration of the scholarship, he moved to the University of California at Berkeley, where he majored in electrical engineering. During this time, a one-off number theory course with D H Lehmer “fired his imagination for the subject”. After four subsequent years in the Air Force, during which he also earned a B.S. in physics, he returned to UC Berkeley where he completed his Ph.D. in mathematics with D H Lehmer as his thesis advisor. \nAll this is to say that life can be — and typically is — highly non-linear. I would argue that as much as we like to imagine being in control, planning one’s future down to summer-vacation-wise bucket lists is perhaps somewhat excessive. Your first branch and your first job does not have to be your last: for more evidence, I recommend reading Tim Ferriss’ book, Tribe of Mentors. Now, you might be prone to making your choices after optimizing for a dozen variables or more, or you might prefer leaving your destiny to the gods of randomness. I believe somewhere in between, there is an approach more reasonable than either extreme: make an informed choice after investing a finite amount of your own time and energy into understanding what actually lies in store.\nThe IITs are now far from being the only ticket to the good life and a powerful alumni network: if these are your main motivators, you might consider exploring less painful pathways to the same outcomes. If not, allow yourself the space to let your instincts come to the fore, and follow them to make your choices. This will maximize the chances that you will end up in a meaningful journey that involves truly enjoying what the programs have to offer, instead of being in a situation where you have simply transitioned from one rat race into another."
  },
  {
    "objectID": "materials/cpnotes/Lec40.html",
    "href": "materials/cpnotes/Lec40.html",
    "title": "Minimum Spanning Trees - Module 2 (Cherries Mesh)",
    "section": "",
    "text": "Lecture - 40\nMinimum Spanning Trees - Module 2 (Cherries Mesh)\n(Refer Slide Time: 00:14)\n\nWelcome back to the second module of the seventh week and Getting Started with Competitive Programming. As you know, we are talking about minimum spanning trees this week. And the first problem I want to discuss is this really short and sweet problem called ‘cherries mesh.’ It is literally sweet in the sense that it is based on a ‘dessert preparation.’ And this problem showed up in Google Kick Start 2019 round E.\nAnd if you read the problem, I think you will see quite quickly that it calls for an MST-based solution. However, if you just rush into building up the graph and running your favorite MST algorithm, you might run into a little bit of trouble with the constraints, especially in the large data set. So, you have to do just a little optimization to make sure that your algorithm runs within the given limits. So, let us get started by looking at the problem statement.\n(Refer Slide Time: 01:11)\n \nSo, your friend is recently done with a cooking class. And now he wants to boast in front of his school friends by making a nice dessert. He has come up with an amazing dessert called cherries mesh.\nAnd to make the dish he has already collected N cherries, which are numbered 1 to N. And he has also decided to connect each distinct unordered pair of cherries with a sweet strand made of sugar. So, you can probably already see where the graph modeling comes in. You could quite naturally, I think, think of the cherries as being vertices. And when you see this business about unordered pair of cherries being connected, you obviously think of undirected edges corresponding to these vertices. So, these strands correspond to edges in your graph.\n(Refer Slide Time: 02:05)\n \nWhat we are told is that the sweet strands are either red or black, depending on the sugar content in them. Each black strand contains one unit of sugar, and each red strand contains two units of sugar. So, this, again, quite naturally corresponds to edge weights.\nIf you wanted to visualize this, you know, you could look at an example like this. Notice that all the edges are present. This comes from, again, the problem description, where you are told that every pair of cherries is connected by a strand. So, the only information that makes these strands distinctive is whether they are a black-strand or a red-strand, reflecting the amount of sugar content in them. So, this is the setup. Now let us talk about the task.\n(Refer Slide Time: 02:51)\n \nIt turns out that the desert is too sweet because there are too many edges or too many strands in them. And these days, school friends are dieting, and they usually like dishes with less sugar. So, that is our task now.\nYou want to find out which strands you should remove so that the dessert still hangs together. Okay. So, you want each pair of cherries to still be connected to each other somehow, either by a direct strand or by a sequence of strands. And you want the remaining strands to add up to having the minimum possible sugar content. Now if you read this, this is what I meant when I said that it is reasonably clear that this calls for an MST application.\nBecause if you look at these two conditions, they are exactly like the conditions we spoke about in the first module when we were talking about paving a muddy city. Remember, we said the first condition was that you should be able to go from anywhere to anywhere. The second condition was that the cost of the roads that you build has to be as small as possible. So, these conditions have a very similar flavor.\nThe first condition says that every pair of cherries should be connected directly or indirectly. And the second condition says that you want to minimize the sugar content in the strands that you do decide to keep. So, clearly, what you are looking for, here, is a minimum spanning tree. Although the question in the problem statement is framed as figuring out what you should remove. If you look at the input-output description, you will see that what you are expected to output is the minimum amount of sugar content that will be left behind.\nSo, you are really looking for the cost of a minimum spanning tree in this graph. Now once you recognize this, at least one solution is quite immediate. We just build up the graph and then run our MST algorithm on it. Now for this problem, how do you build up the graph? What are you given? You are given a list of all the black strands. In other words, you are given the list of all the edges that have weight 1.\nAnd it is implicit that every edge that has not been listed is a weight 2 edge or it is a pair that corresponds to a red strand. To make this more explicit, let us just look at the data in the second sample input, or the second test case in the sample input.\n(Refer Slide Time: 05:21)\n\nSo, what you are given is that there are three cherries, and there is one black strand connecting the cherries labeled 2 and 3. So, that is all the information that you have from the sample input. So, when you look at the black edge, you read it in and added to your adjacency lists or your edge lists, as usual, remembering to record also that the weight of these edges is just 1. But now you also have to add all the remaining edges.\nAnd one way of doing that would be, for instance, if you were storing things in an adjacency list, then you could go to every vertex and simply loop through the whole list of vertices and check if these vertices are already present in the list. If yes, then you can ignore them. But if they are missing, then you will add them in with a weight of 2 as we just did here. This will generate your complete graph.\nBut notice that already the complexity of generating this graph is going to be at least n square, which is understandable, because there are n squared edges to be put on the record, given that this is in fact a complete graph that you are working on. In fact, if you just follow the process that I am describing here, using adjacency lists, as I have been suggesting, then you might even need a little more than ‘n’ square time.\nBecause when you are trying to populate the red edges in the adjacency list of some vertex, you have to go through every other vertex, and check if they are already on your adjacency list or not. So, that bit of searching is going to cost you a little bit extra. Now, there are probably ways that you can optimize this. But an easy way of doing this in order n squared time, given that you are committed to spending that n squared time anyway is to simply use an adjacency matrix instead.\nThis is a good point actually to pause the video and try and see if you want to implement this solution, it is a good warm-up to what we are going to see next. And if you actually do this, what you will likely experience is that your solution will work well for the first test set, which has smaller test cases.\n(Refer Slide Time: 07:38)\n\nBut for the second test set, which has the larger tests, you might run into some trouble with these constraints. Notice that the number of vertices can be as large as 105, which means that n square running time will land you in some trouble. Notice also that the number of edges of weight 1 is also guaranteed to be at most 105. So, in some sense, if you look at the subgraph comprised of the black edges – it is sort of a sparse subgraph.\nSo, one question to consider in terms of improving our approach is if we can come up with an algorithm whose running time really depends on the black edges, rather than building up this whole big, dense structure. So, take a moment here and think about this a little bit. Think about, for instance, what would Kruskal’s algorithm do when it is building out the spanning tree. Does it have some special structure, especially in terms of thinking about the black edges first and then the red edges? Come back once you have had a chance to spend a moment reflecting on the whole situation.\nOkay. So, if you think about how Kruskal’s algorithm would work, notice that it will process all the black strands or the edges of weight 1 first before getting to any of the red strands, or the edges of weight 2.\n(Refer Slide Time: 09:03)\n   \nSo, for instance, in this example here, if you were to run Kruskal’s algorithm, you will find that at some point, once you are done processing all the edges of weight 1, you are going to have a spanning forest for the subgraph on the black edges alone. Now the exact structure of the spanning forest on this black subgraph will depend on the nature of the order in which the edges are being processed.\nSo, different runs of Kruskal’s algorithm if ties are being broken differently, might lead you to different spanning forest structures. But the key thing is that the total cost of the spanning forest is going to be the same, no matter how ties were broken, no matter which particular spanning forest you end up on.\nAnd this cost is simply going to be the sum of the sizes of the components in this black subgraph. Of course, you need to subtract 1 from each of those sizes, to get to the actual cost of the spanning forest that you get at the end of this first phase of Kruskal’s algorithm. So, in this example, for instance, we have two components, which have 3 and 2 vertices respectively. So, the cost of any spanning forest on this sub-graph is going to be 3, which is the size of the first component - 1, 3 - 1, 2. And the size of the second component - 1 should be 2 - 1, 1.\nSo, 2 + 1 = 3. And here is what a spanning forest for this graph could look like, for instance. Now, what happens in the second phase of Kruskal’s algorithm, when it is starting to process all of the red edges? Well, all that it would have to do is essentially connect the trees that are there in the spanning forest. And again, there is going to be many different ways that you can do this.\nBut the crucial thing, once again, is that all of them have the same cost. Take a moment to pause the video here and think about what this cost is going to be. And come back once you are ready. Okay. So, if you have ‘k’ components in the spanning forest on the black subgraph, then you are going to need k - 1 edges to connect all of them. And now, since the only edges that remain – that is safe to add – are edges that have a weight of 2, the total cost of extending the spanning forest to a spanning tree, no matter how you do it, is going to be 2 * k - 1.\nIn this example, we have two components. So, we need one edge to tie them together. And this edge will have to be one of the red edges. You can pick your favorite one. And that is it, that would be your final solution. By the way, I said, you can pick your favorite one, which is as long as it is a safe edge, so it has to be an edge that actually connects two components.\nThe key thing is that because you are only being asked for the cost of the minimum spanning tree, you only want to know the amount of sugar that will be left behind after all the strands that can be deleted are deleted. You do not have to actually build up a spanning tree, you just have to compute its cost. Therefore, we do not have to really go through the process of running Kruskal’s algorithm on the whole graph.\nIn particular, we do not even need to build up the whole graph, we can simply work with this sparse black subgraph to just identify how many components are there in the black subgraph and what their sizes are. And this is something that can be done in a fairly natural way using disjoint set union. And we will come to the implementation in just a moment. But I just want you to think about what will the final computation be?\nAnd what is the answer that you are going to output? If you have a piece of pen and paper handy, just see if you could write it out. And then you could come back and tally your solution with mine. Alright. So, the final answer that you want outward is simply the following.\n(Refer Slide Time: 13:18 & 14:22)\n \nSo, it is the number of edges in any spanning forest on the black strands. This is something that you could calculate or just keep track of as you run, you simulate classical Kruskal’s algorithm on the black subgraph. And to this, you want to add the expression 2 * the number of components in this spanning forest - 1, which is to say, the number of red edges is going to be the number of components - 1, but each of them has a cost of 2 units. So, you have a multiplier of 2.\nSo, this is the expression that you want to return. So, you want to make sure that you can compute both of these quantities here, the first being the number of edges in any spanning forest on the black subgraph. The second is the number of components in the spanning forest. Fortunately, we already know how a disjoint set union as a data structure can help us keep track of both of these things. So, let us actually go ahead and take a look at the key part of the implementation.\nSo, by this time, we have actually read in the inputs – n is the number of vertices in the graph. And EL is the list of edges with the weights being the first component of the tuple here. Actually, the weights are not going to matter because we are only working with the black edges. So, this is as good as an un-weighted graph – the path that we are focused on. But nonetheless, just using the traditional edge list format. So I have recorded the edge weights as 1.\nAs always you can find the full code in the official repository. So, there is a link in the description, which you can follow. If you want to look up the part which does the tasks of reading the input in and building up the edge list and so on. But now the first thing we do is create an instance of the UnionFind data structure. This is the same data structure that we used back in week 4. So, we are going to use the exact same code from there.\nAnd we have one-based indexing for the vertices. So, just to keep things simple, I am going to initialize UnionFind with n plus 1 elements, so that I do not have to worry about adjusting the indices as we go along. So, now what we do is we just go through the edge list, and whatever order it does not really matter. Notice that I am not bothering to sort the edge list here. Because once again, there is no sorting that needs to be done. All the edges have the same weight, which is a weight of 1.\nAnd so what is happening here is that you are building a simple spanning forest. You are just seeing if an edge is safe or not. If it is not safe in the sense that it has both of its endpoints, the same component, thereby creating a cycle, then that is an edge that gets ignored. But whenever you have an edge that actually meaningfully connects to components in your current spanning forest, we added and (we) increase the number of edges that go into the spanning tree.\nSo, this is being kept track of in the variable that I am calling ‘answer.’ We just keep incrementing ‘answer’ every time you add an edge to your spanning forest. So, when we come out of the ‘for’ loop, we know exactly how many edges are there in an optimal spanning forest for the black subgraph.\nSo, that is the first quantity in this expression here. And now, once you are done, you need to figure out how many components are there in this spanning forest. And that is something that the UnionFind data structure actually can keep track of for you. And in our implementation of this data structure, we did have a helper function that returns how many disjoint sets there are. And notice that every disjoint set actually corresponds to a tree in the spanning forest.\nSo, the number of components that you are interested in is actually given by the number of disjoint sets in this data structure. Now, the expression that you want here subtracts one from the number of components. But in this code, you might see that we have subtracted two instead. And the reason for this is the silly thing that we did, of initializing UnionFind with ‘n + 1’ elements. So, there is a dummy element there corresponding to vertex 0, which does not really exist in our graph.\nSo, vertex 0 is going to contribute one extra to the count of the number of sets in the disjoint set union data structure. So, this extra -1 is simply to correct for that. So hopefully, that is clear. And this expression is exactly what do you want. And it turns out that this completely solves the problem, even for the larger data sets. So, I hope that this made sense. As always, if you have any questions, please leave them in the comments on this video.\nOr if you are watching this, during an active run of the course you can join us in the Discord community or share your comments over at the mailing list. We will look forward to hearing from you. Next up, is a problem called hierarchy, which is another nice application of minimum spanning trees and that is coming up in the third module. So, I will see you then. Thanks for watching!"
  },
  {
    "objectID": "materials/cpnotes/Lec06.html",
    "href": "materials/cpnotes/Lec06.html",
    "title": "Searching and Sorting - Module 2 (The Meeting Place Cannot be",
    "section": "",
    "text": "Lecture - 06\nSearching and Sorting - Module 2 (The Meeting Place Cannot be Changed)\n(Refer Slide Time: 00:11)\n\nWelcome back to the second module of the second week of Getting Started with Competitive Programming. We continue our journey through problems that require some application of either sorting or searching. In this video, it is going to be searching. We will be talking about the Codeforces problem from round number 403. The problem name is, The Meeting Place Cannot Be Changed.\nIt turns out this is also the title of a 1979 soviet five-part television miniseries. That is information that you probably did not need to know. But that is what shows up when you do a Google search for this phrase. So, if you want to get to the Codeforces problem statement make sure to add Codeforces to your search query or just use the link in the description of this lecture video. This problem has a pretty short story. But I will say that the binary search aspect of the solution was not very obvious to me from the outset.\nThere are some problems wherefrom the statement you can quite easily guess that there must be some kind of a binary search involved here. But I will say that in this one, at least to me, it felt a bit hidden. It seemed like the statement was suggesting more of a greedy sort of an approach or something like that. But, of course, once you start thinking about it and you look at the problem limits, it becomes clearer and clearer that you have to do some sort of a binary search. So, let us get started by looking at the problem statement as usual.\n(Refer Slide Time: 01:36)\n\n\nIt all starts with this road in Bytecity, which can be thought of as a straight line that goes from west to east. I should point out that this is not verbatim from the problem statement, where it is a north-south road instead. But I wanted to give myself some horizontal space on these slides. I did not also want to disorient you by calling this horizontal line a north-south road. But this detail is really not relevant to the main mechanics of the problem. So, I just wanted to flag that it is different but it does not matter. This road is demarked by integer coordinates.\nWhat we are told is that there are ‘n’ friends who are standing on this road. In fact, we are given their exact locations as input, as we will see later. We are also told that these people can move around on the road in either direction, and each individual has a maximum speed that they can travel with. So, you have ‘n’ people standing at these ‘n’ locations, which may or may not be distinct. Each one of these people has a speed with which they can travel. They can travel either towards the east or towards the west. So, what do we want to do?\nRemember the name of the problem is ‘The Meeting Place Cannot Be Changed.’ You might guess that the problem itself has something to do with getting these people to meet? Indeed, it turns out that the question we want to address is: What is the minimum time that we need for getting all of these people to meet? By asking them to move of course, if necessary. We can direct the first person, for example, to go eastward, the second person to go westward. Whatever we want them to do, we can just ask them to do it.\nWe want to know, what is the most optimal set of directions that we can give these people so that they come to a common point after a certain amount of time has elapsed. We want this to happen as quickly as possible. So, that is the question. Also, one thing to note is that the place where they meet is not constrained to be an integer coordinate. So they can meet anywhere on this line, as long as they get to meet. That is what is important.\n(Refer Slide Time: 03:54)\n\nLet us, maybe, work through an example. As usual, we will pick up one of these sample inputs and go over it. These distances or these coordinates are measured from the east-most building. We just think of this building as the origin. We have coordinates being given as distances from this origin. What we have is three people who are standing at locations 7, 1, and 3, and their respective speeds are 1, 2, and 1.\nYou can see that the speeds are color-coded according to the people who have those maximum possible speeds. At this point, maybe you want to work through this yourself. What is the smallest amount of time that you will need to get these people to meet up at a common point? Please take a pause here and try to figure this out without, hopefully, looking at the problem statement. This is a nice example to work through. It will give you some intuition for what is going on.\n(Refer Slide Time: 05:11)\n\n\n\nHopefully, you had a chance to think through that. So, let us ask ourselves if, for example, one second is enough. So here is the scope of how much people can travel within one second based on their speeds. You can see that the green and the blue intervals are disjoint. Even if the green guy comes as much to the right as possible and the left chap moves as much to the left as possible (both of them are stretching as much as they can), it will still not be possible for them to meet.\nSo, we know that one second is not enough. Maybe we want to ramp this up and try to work with two seconds. Would that work? Again, if you have not completely worked through the example already, this is another chance to pause and try to figure this out.\n(Refer Slide Time: 06:00)\n\nWith 2 seconds at your disposal, notice that people can move around more and you indeed have a valid meeting point at the fifth coordinate. In particular, you could ask the green point to move 2 steps to the right and the blue point to move 2 steps to the left. The pink point also moves four steps to the left, which it can in 2 seconds because this point has a maximum velocity of 2. This also tells you that anything less than two seconds will not suffice.\nEven if you have 0.9999 seconds at your disposal, the green and the blue points will still fall slightly short of the meeting. This is also a good opportunity for me to point out that the answer in terms of the number of seconds also need not be an integer. We are really looking at 10-6 level of precision here.\nThis will become clear when we start getting to the implementation later. But for now, just keep that at the back of your mind: The number of seconds that you report need not be an integer. So, with this example fully worked out and behind us, let us now address the more general question of whether it is possible to meet within ‘k’ seconds.\n(Refer slide Time: 07:09)\n\n\nIf I tell you that you have a budget of ‘k’ seconds and you have all this information about the starting points of all the ‘n’ friends and their respective maximum velocities, can you figure out if it is possible to get them to meet within ‘k’ seconds? Based on the way we tackled the example, you might already have some thoughts about this.\nBecause we know the initial locations, the maximum velocities, and how much people can move within ‘k’ seconds. We could draw these intervals around each of these points realizing that anything outside of this is not attainable within ‘k’ seconds. Based on this, can you come up with criteria for whether people can meet within ‘k’ seconds or not?\nTake a moment here to think through this because this is one of the key pieces of the puzzle. There is one more coming up that has to do with the theme of this lecture which is binary searching. But we will get to that in just a few minutes. For now, just think about how will you figure out if ‘k’ seconds are enough for people to meet? I guess it is reasonably clear, at least, visually that it is possible for everybody to meet within ‘k’ seconds, if and only if there is a point that belongs to all of these intervals that we have drawn here.\nIn particular for this example, notice that it is not possible for everybody to meet because, for instance, the pink point and the orange point are always going to be divorced from each other. They are never going to come to a commonplace, at least within this time, assuming that these intervals are an accurate representation of how much they can move based on their velocities.\n(Refer Slide Time: 08:58)\n\n\n\n\nOn the other hand, let us look at an example where things do work out. Notice that there is at least one point, in fact, there is an entire range, which could be used as a meeting place because the points on that range are accessible to all people involved here. That brings up the natural question of how can we figure out if a collection of intervals has a common point or not?\nThis is again, a cute question. If you have a collection of intervals given by the left and right endpoints, what would be an algorithm to figure out if there is a point on the line, which is contained in all of these intervals? Again, just take a moment here to think through this and see if you can work it out. Come back once you are ready. Hopefully, you had a chance to think about this. Let us go back to the example from before.\nHere, let me highlight all the left endpoints of all the intervals. One of these is special, the one that is special is encircled in red. Among all the left-end points, it is the rightmost one. Let us also highlight all the right endpoints. The one that I am interested in is the left most of them. The two encircled points are the left most of the right endpoints and the right most of the left endpoints.\nThe criteria for all the intervals to overlap is simply the following. What we want is for the right most of the left endpoints to come before the left most of the right endpoints. If this happens, then you know that essentially everybody meets within this range that is defined by these two points. But if these two points are separated then things do not quite work out. Let us also see an example of when things do work out.\nFor instance, you can see that the rightmost of the left endpoints come first and the leftmost of the right endpoints comes afterward. This works out nicely. You can see that there is a substantial range of potential meeting points in this example. Now, this is a statement that you can actually prove formally.\n(Refer Slide Time: 11:19)\n\nLet me write out the criteria here. So, if the maximum of the Li is at most the minimum of the Ri, then you do have a meeting point. In fact, every point in this range, max Li, min Ri will actually give you a valid meeting point. The reason for this is: Well, suppose that there was one interval that was outside of this range. It did not intersect this range. Then depending on whether the interval was to the right of this range or entirely to the left of this range, you can argue that either its right or left endpoint will contradict our definition of the choices of min and max.\nThis is a really simple two-line proof. I would encourage you to write it out if you are not completely convinced. The other side of the argument is that if this does not work out. In particular, if the max of Li is greater than the min of Ri. Then if you just look at those two intervals, the ones that witness this max and min, you will see that those two intervals themselves are disjoint. There is no hope for these two intervals to intersect.\nTherefore, it is certainly true that all of the intervals do not have a common point on which they overlap. So, these are the criteria that help us determine if ‘k’ seconds are enough or not for everybody to meet. But notice that our actual task is to find the smallest ‘k’ for which a meeting is feasible. How do we go about that? This is where the binary search comes in.\n(Refer slide Time: 13:02)\n\nOnce again, let us go back to this question here. We know how to address this question, given k, and all the xi‘s and the Vi’s. We know how to figure out whether ’k’ is enough or not. Hopefully, it is clear by now that the xi’s are the locations and the Vi’s are the max velocities. So, we know how to figure this out. But notice the following two things.\nFirst of all, if the answer to this question turns out to be ‘no.’ So ‘k’ seconds are not enough, then certainly anything less than ‘k’ is also not enough because already with ‘k’ you are not able to meet. If you have even less than ‘k’ seconds at your hands, then you are even more constrained. Of course, it is not going to work out because if it worked out with less than ‘k,’ then it is going to work out with ‘k’ as well. Hopefully, it is clear that if the answer to this question is ‘no’ for some ‘k,’ then it is also no for every value that is less than ‘k.’\nSimilarly, if the answer to this question is ‘yes,’ then the answer is yes for all values that are bigger than ‘k.’ So, that means that if, let us say, five seconds was enough then, six seconds are also enough and seven seconds are enough and so on. Once you have a ‘k’ that is feasible, the interesting question is, can we do it with a smaller ‘k?’\nThat is what we want to figure out. And if you have a ‘k’ that is infeasible, then the question you ask yourself is, ‘k’ was not enough so we probably need to give ourselves a little more budget, a little more wiggle room. That motivates a very natural binary search over the range of all possible ‘k.’\n(Refer Slide Time: 14:43)\n\n  \nBased on the limits of the problem statement, let us work with the range 0 to some large number. I think something like 109 or so should suffice. With this range we are binary searching. We start in the middle, and we ask ourselves is 50 how many ever seconds enough? Suppose the answer turns out to be ‘yes,’ that this is enough. Then what should we do? We want to throw away half of this range, which half should we throw away?\nJust think about that for a second. Pause the video and take a moment here to think through this because this is the crux of the binary search part of the algorithm. Hopefully, you had a chance to commit to an answer. So, if these many seconds are enough, then we need to challenge ourselves to see if we can do it with even fewer seconds.\n(Refer slide Time: 16:03)\n \nWe do not need to worry about the right half of the range. It is only the left half that is relevant. We bring the right endpoint of our search space down to the midpoint. On the other hand, if the answer is that it was not feasible, then perhaps you can anticipate that the interesting range is the right half because if it is not feasible, we know that anything smaller is also not going to be feasible. So, there is no point in checking for those numbers.\nSo, we search in the right half. In other words, the way we truncate our search space is by bringing the left endpoint to the middle. That is kind of how you would do it in the program. That completes the overall description of the algorithm. You binary search over all possible values that the number of seconds could take, which is the answer. Every time you pose a question ‘is so many seconds enough?’, you use the interval intersecting business that we discussed a few minutes ago to figure out whether the answer to the question is ‘yes’ or ‘no.’\nEvery time you have an answer, you know which way to proceed. Hopefully, by now you have enough information to try and implement this algorithm yourself. Please go ahead and give it a shot. Do keep in mind that the numbers can be big. And the answer is required to be within a 1 over 106 error bound. It is possible that the judge has a particular answer and you have a slightly different one because you are dealing with floating points. Some calculations may not be exact. But you want the absolute difference between the answer of the judge and your answer to be within 10 to the minus 6. So, just make sure that you are using enough precision as you go along. In particular, we are binary searching. So, one way to think of the binary search criteria is when have you narrowed in enough to say that you know the answer?\nRemember, back when we were talking about the problem definition. We said that the output, which is the number of seconds, need not be an integer. You certainly cannot just stop when you have a pair of consecutive integers, one of which reports ‘yes’ and the other reports ‘no.’ Then you just report the one that said ‘yes.’ That is not enough. You have to dig deeper into the gap between these two consecutive integers. For instance, suppose you say that one second is not enough, but two seconds is enough, you still have to probe the possibility that maybe 1.5 seconds are enough.\nIf the answer to that is ‘yes,’ then you have to continue your search between 1 and 1.5. When do you decide to give up because these are not integers? What are the stopping criteria going to be? You have to decide when you have two numbers that are close enough for you to take a call.\nYou keep the search going for as long as the two numbers that you are working with are sufficiently far apart. Since you are looking at a 10-6 kind of precision, you can say that if the numbers are closer than that then this is a good enough approximation of the final answer. That is how we will be implementing it.\nI think that is the spirit in which most of the implementations would be for this problem. Please go ahead, give it a shot and come back to exchange notes. As usual, I will spend a few minutes going through my implementation for this. For this problem, the implementation that I will show you is in Python. By now, we also have an announcement, which is on the mailing list as well as in Discord, where we have shared with you a link to a Google Form, requesting translations of the sample answers in other languages.\nFor instance, for this problem, the GitHub repository will already have the Python code. But it will be great if you have C++, C, or Java versions of the same code, as long as you follow a similar format and document your code well.\nIf your code passes all the test cases, then please do share it with us so that we can add it to the repository with full credit. Make sure you add your name and anything else that you want to add about yourself in the comments. We will be very happy to share this with the rest of the class. Thank you in advance for your contribution to making this course better.\n(Refer Slide Time: 20:32)\n\n\nLet us move on to the implementation here. The first few lines here are, again, accepting the input. The input is always just three lines. The first line is the number of people. The next line is a space-separated list of integers, which talks about the locations. The last line is a space-separated list of integers, which talks about the velocities. You read them in and I have used very short variable names here. But they are still descriptive. So, x for the x[i]s, and v for the v[i]s.\nLet us move along. Here are the criteria for determining if ‘k’ seconds are enough. We have three very short functions. The first one identifies the right-most left endpoint. Remember, the left-hand points are given by the offset from the original location towards the left for how much you can travel in ‘t’ seconds. You say x[i]-v[i]*t. I think that is reasonably natural and easy to understand. On the other hand, we have how much can you move to the right.\nThat is x[i]+v[i]*t. That is an array that collects the right endpoints. The second function is simply returning the leftmost of the right endpoints. Remember, this was the max of Li, min of Ri expression that we had seen a couple of minutes ago. The ‘is feasible’ function takes a number ‘k,’ which represents the number of seconds that you have on your budget. It tries to figure it out by comparing the left-most right endpoint and the right-most left endpoint, whether this is workable or not.\nNotice that the two functions above take ‘t’ as a parameter, which is the number of seconds that you have and that is what we are passing to them when we are writing the ‘is feasible’ function. This, hopefully, is quite closely representative of what we had discussed a few minutes ago.\n(Refer Slide Time: 22:47)\n\nThe only thing left to do now is the actual binary search. We initialize our range. Remember, you could need as little as 0 seconds in case everyone is already in the same position, to begin with. I think if you study the limits, you will see that you will never need more than 109. So, that is what we have here for left and right. As we discussed, we are going to keep searching for as long as the search range has not become tiny. As long as R-L is bigger than a really small number, we are going to continue our search.\nI think we always maintain the invariant that R is at least L. The absolute value here is not really necessary. But it is there anyway, so, it does not hurt, but I think it is not required. That is the criteria for whether you want to keep searching or not. As long as R and L are sufficiently separated, you keep going. What do you do when you are binary searching?\nOf course, the first step is to find the midpoint of your current search range (the value of mid). Based on whether the current mid is feasible or not, you decide to truncate your search interval one way or the other. Remember, we said that if the answer is ‘yes’ (feasible), then we ignore everything, every number that is larger. We want to challenge ourselves to find a smaller number. So, we bring R down to mid.\nOn the other hand, if it is ‘no’ (not feasible), we know that what we have is not enough, so we need to go higher. So, we ignore everything that is smaller. The way to do that is to bring the left-hand point all the way up to the midpoint. That is how we reset the values of L and R. You just keep going until you have a search range that is sufficiently tiny. At that point, you can exit the loop and print the answer. This is, I think, fairly clean and in some sense, also a little bit clever.\nAt least this solution was not completely obvious to me. I think the part about the intervals is pretty natural to do but from there, you start thinking about whether you want to do something that is greedy or something else. But the final solution that does happen to work, I think is really cute. I hope you enjoyed this as much as I did. So, we call it a wrap here and we will see another problem in the next video as usual. So, I will see you there. In the meantime, thanks for watching!"
  },
  {
    "objectID": "materials/cpnotes/Lec12.html",
    "href": "materials/cpnotes/Lec12.html",
    "title": "Greedy Algorithms - Module 3 (Stable Marriage-II)",
    "section": "",
    "text": "Lecture - 12\nGreedy Algorithms - Module 3 (Stable Marriage-II)\n(Refer Slide Time: 00:11)\n\nHello, and welcome to this short follow-up video where we discuss the implementation for the ‘Stable Marriage’ problem that we discussed in the previous video. As I mentioned there, this problem is available both in the ICBC Regional Archives as well as the CodeChef problem archive. The code that I am going to share with you right now is tested on the CodeChef platform.\nIf you want to run it on the ICPC platform instead, just make sure that you have appropriately adjusted for proper input-output. Make sure to double-check all the details at least once. With that said, let us get started. Our code for this problem is going to be in C++.\n(Refer Slide Time: 00:49)\n\nAs usual, to begin with, we have the usual reading of input. We want to have 2N vectors to store the 2N rankings that have been given to us. The rankings are given as space-separated integers. The ‘men’ and the ‘women’ are represented as integers between 1 and N. The only little annoying detail to keep in mind is that the lines that give you the preferences begin with a number denoting whose preference it is.\nThe first line is the first women’s preference, and it starts with a ‘1’ and is then followed by N integers between 1 to N in some order, which gives you the actual ranking. You have to remember to ignore this leading number. If you forget to do that, your algorithm is going to be all messed up. It is a very tiny detail, but just useful to note. That is why you have the stand-alone ‘cin’ person outside of the ‘for’ loop, which takes this input and does not really do anything with it. Then you read the rest of it into a vector.\nWe have a collection of N vectors for the N women and a different collection of N vectors for the N men. You will notice that I am also reversing these rankings so that I have the top preferences at the end of the array. This just makes it easy for me to access the top choice that these people have because that is something that we will need to do frequently. But you can absolutely do this also without reversing the list. It would really be the same thing. It is a matter of minor details.\nAll the heavy lifting is done in this ‘solve’ function. Let us go and try to understand what is happening in solve. It is going to use a few helper functions whose objectives will be self-explanatory. I will show you the helper functions at the very end, but I will show you the main function, the main solve function, to begin with.\n(Refer Slide Time: 02:44)\n\nHere, we are going to maintain a list of engagements in the arrays or the vectors WE and ME. So, WE[i] is going to store the current partner of the (i+1)th woman, and ME[i] stores the current partner of the (i+1)th man. The reason this is off by 1 is because the men and the women in the problem statement are denoted as numbers between 1 and N whereas these arrays are indexed from 0 to N minus 1. That is why the offset. Just keep in mind that this is what is happening.\nTo begin with, if you remember also from the pseudocode, everybody is free. There are no engagements. Nobody is matched to anybody. We will use -1 to denote that somebody is currently single. The initialization is clearly that everybody is single. That is what is happening here.\n(Refer Slide Time: 03:39)\n\nNow, we turn to the main logic of actually creating the matching. The first thing we said was that as long as there is a single man left, who still has to propose to somebody, we are going to go ahead and actually execute that proposal. We have this helper function, which tells us if there are any single people remaining, and you could examine either of the arrays because WE and ME are symmetric in reflecting the matched state of all the people involved.\nWe could pass either of them to the ‘singlesRemaining’ helper function. This helper function will return true if there is at least 1 person who is still single at this point and will return false otherwise. Hopefully, this ‘while’ statement makes sense. If there is at least 1 person remaining, who is single, we enter the loop. Then we go over the list of all men. In particular, we focus on those men who are currently single. That is the ‘for’ loop under ‘if’ block here.\nIf we have a man who is single, so if ME[i] is -1, which is to say that the (i+1)th man is currently single, then we want this man to propose to the woman who is currently at the top of his list. That just essentially amounts to pulling back the last element of the array. Because remember, we said that we have reversed the preference list. The top element is really at the bottom of the array, or it is the last element of the array.\nThat is what I am pulling in here and we have a -1 to adjust for the indexing. This is the correct index to refer to in the arrays that we are storing. Of course, what is being stored, is the number or the identity of the woman that this person likes the most currently. We remove this element from M[i]’s vector as well because we will have no need for it later. Remember that you always go further down in your preference list, and you never look back.\nThis is just all about identifying the person that the (i+1)th man will propose to now. Once we are done with this, we actually try and look at what happens when the proposal is made. Here, we have to look at what is going on with the woman that we are now calling ‘top.’ For this woman, we have to distinguish between the cases of whether she is currently single or engaged. Let us do the easy case first.\nIf this woman is currently single, then we go ahead and make the match. There is nothing else that needs to be done. The match can be immediately made. On the other hand, if the woman is currently engaged, then we have to compare the person that she is engaged to with the person who is making the proposal. Let us store in the variable ‘competitor,’ the current match of this woman, and now what we have to do is compare the competitor with the man ‘i+1.’\nWe have another helper function ‘getRank,’ which tells us how the competitor is ranked, and how the current man is ranked. Remember all of these +1s and -1s are just adjusting for the indexing. If you read it carefully, you will see that all of it is consistent. We use the getRank function to retrieve the ranks of these two candidates in the preference list of the woman who is denoted by the variable top and we compare these two ranks.\nRemember that smaller ranks are going to be better. That is how the helper function is set up. If the man ‘i+1’ has a lower rank, then that means that the current engagement needs to be broken, and the previous person that ‘top’ was engaged to, we need to signify that he is back in the single spool of men. We make sure to set the competitors index in the ME array to -1 and we also make sure that man ‘i+1’ is matched with top. That is going to happen with this match helper function. So, that is essentially the heart of the algorithm.\nThat is all the business that we need to do. We check if the woman who is at the top of the (i+1)th man’s preference list is single or not. If she is single, we make the match immediately. If she is not single, then we compare the new match with the old one. If the new match is better then we break off the old engagement and make the new match. Otherwise, we do nothing, and the man who was making the proposal continues to remain single. We just walk out of the ‘else’ block without any work being done in that case. That is the entire algorithm more or less. The only thing left is to show you how the helper functions work.\n(Refer Slide Time: 08:26)\n\nAll of these helper functions are fairly standard. What getRank will do is, it will try to return the rank of the person in a given list. The reason we have N minus here is that we had reversed the list, to begin with. If you did not reverse the list, then you do not need to do this N minus calculation here. You can just directly return the location of the person in the list.\nNow, the way the ‘find’ function works is that it actually gives you an index and memory. You need to adjust that to get the actual rank. You could also use something like distance to figure out the rank. You can have your own version of the getRank function, depending on which built-in functions you use, and whether you reversed the list in the beginning or not. Your version may vary a little bit from what we have here.\nJust make sure that the way you index things — the way you number of things — is consistent between all the functions that you write. The singlesRemaining function is also really simple. It just boils down to identifying if the input array has a -1 or not. All we are doing here is just checking if there is an occurrence of -1 or not. If there is no occurrence of -1, we return false, otherwise, we return true.\nThe exact conditional and this ‘if’ statement here is basically based on the documentation for the find functions. If the ‘find’ function returns an index, which is just after the last location of the array, that is the signal, that the thing that you were looking for was not found. That is what we have here. I am sure there are many other ways of writing this as well. Take your pick. Essentially, the logic that you need to implement is to return false if -1 was not found in the array. Any way you have of doing that should be just fine.\nThe match function essentially updates the ‘engagements’ array to reflect that a particular man got matched with a particular woman. This is really simple. You need to go to the wth index in the women’s engagement array, and make sure that it is updated to ‘m.’ You need to go to the mth index in the men’s engagement array and make sure that it is updated to ‘w.’\nAgain, you could make a choice here about whether you want to reflect the true identity of the person, or do you want to use the index that you are going to be using, which is going to be essentially the identity -1. Whatever you do is fine, as long as you are consistent in your code and how you use it. I have tried to be careful here, and I think everything here is reasonably robust. As usual, you can find the entire code here in the GitHub repository.\nIf you have any feedback, then that would be absolutely very welcome. Also, if you manage to write this in a different language, please do submit a pull request so that we can add it to the official repository. With that, we come to the conclusion of the ‘Stable Marriage’ problem. I think I should quickly mention that the one thing I have not shown you on the slides is the output statement.\nIf you are just working from the video, and you try to imitate all of this code, please do not forget to write your final output statement where you output the stable matching that you found. I think we are done here. Let us call this a wrap. We have one more module left, which is going to be an interesting one because we will not really discuss any more problems.\nWe will, in fact, look at problems for which greedy strategies actually fail. Hopefully, that will serve as a useful warning for us to keep in mind when we are applying this very powerful but also very slippery sort of paradigm in contest programming. So, I will see you there. Thanks for watching and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec13.html",
    "href": "materials/cpnotes/Lec13.html",
    "title": "Greedy Algorithms - Module 4 (When Greedy Does Not Work - Coin",
    "section": "",
    "text": "Lecture - 13\nGreedy Algorithms - Module 4 (When Greedy Does Not Work - Coin Change)\n(Refer Slide Time: 00:11)\n \nHello, and welcome to the final module in the third week of ‘Getting Started with Competitive Programming.’ This video is going to be slightly unusual in the sense that we will not be solving any specific contest problems as we normally do. Instead, we will just take a look at a few examples of situations where the natural greedy strategies that you might come up with for those situations actually end up not working.\nThis is just to really emphasize the point that a ‘Greedy Algorithm’ might look like a very tempting proposition, but it may in fact be wrong. Let us go through a few of these scenarios. There will be no real coding involved in any of these. Hopefully, in due course, we will be able to discover more sophisticated strategies, which would actually help you tackle the sort of problems that we will be talking about in this particular lecture.\nIn terms of logistics, this module is broken up into three shorter videos — each one featuring one example of a problem or a situation where there is a natural greedy strategy, and we will see that it does not work. In some sense, there is no suspense, you already know that the strategy is bound to fail. But I hope that you will still take your time to pause the video, and think about coming up with a counter-example yourself before it is revealed in the lecture.\nWith that said, let us get started here with our very first example, which is a pretty popular one. You may have seen it before. This is called the ‘Coin Change’ problem.\nHere, essentially, imagine that you are trying to get some change for, say, 100 rupees, and you are at a cash counter. The cashier is trying to figure out how to generate 100 rupees from the notes that he or she has at his or her disposal at that time. It could be that you get two 50s, or you get three 20s and four 10s, or you get ten 10s or some such combination.\nThe optimization objective here is usually that you want to minimize the number of notes that are generated. You usually assume that you have an unlimited supply of notes in each specific denomination. A specific version of this problem did show up once on ‘Codeforces.’\n(Refer Slide Time: 02:29)\n\nThis was problem A in Round number 492 in the Second Division. Let us just go over this problem statement here. You want to generate n dollars using bills of denominations 1, 5, 10, 20, and 100. The optimization objective is to minimize the number of bills that you use. It turns out that, here, the natural greedy strategy that you can think of actually does work. You might be thinking that there was a whole lot of false advertising at the start when I said, we would not be solving any contest problems and we will be looking at examples where ‘greedy’ does not work.\nBut it turns out that the reason ‘greedy’ works in this setting is because of a very special property of the denominations. In fact, we will see that once you do not have this special property, ‘greedy’ will no longer work. The reason I picked this as the opening example, is to show you how close you can come to a situation where ‘greedy’ does work for some specific variant if you have some extra special properties. But the moment you drop those structural assumptions, then ‘greedy’ ceases to work. All the more reason to be super careful.\nI just wanted to draw up that contrast, which is why we are starting with this warm-up variant, where greedy does, in fact, work. Just to give you a sense of how to convince yourself that the greedy algorithm is correct, we will go over at least some hints for the proof of the correctness of the greedy algorithm in this setting. We will also try to tease out what is the important property that these denominations have that ensures that the greedy algorithm does work. Before we get to all that: What is the natural greedy algorithm?\nIf it is not clear already, then please take a minute here to pause the video and think about how you would come up with a greedy strategy to solve this problem. The natural greedy thing to do would probably be to use the largest bill that you can possibly use to knock out as much of your remaining task as possible. Remember, you are trying to generate ‘n’ dollars.\nFor instance, if ‘n’ is greater than 100, then I will probably reach out to 100 dollar bill first because that gives me the maximum leverage. It is only when the remaining amount that I have to generate falls below 100 that I will stop using the 100 dollar bills and turn to the next largest denomination that I can use, and so on and so forth.\n(Refer Slide Time: 05:03)\n\nLet us write out the overall strategy. You want to pick the largest denomination of coin, which is not greater than the remaining amount to be made at every stage of this algorithm. You stop once you have generated the entire amount that you were supposed to generate. Let us see how this plays out in a few examples.\n(Refer Slide Time: 05:21)\n\nRemember that the denominations are 1, 5, 10, 20, and 100. Suppose we want to generate 125. Then the first bill I would pick is a 100 dollar bill because 125 is greater than 100. Now since I have accounted for 100, I am left with 25. I can no longer use 100 dollar bill; I would have to use a 20 dollar bill. Once we have done that, we still have to generate 5 dollars more, and there is a 5 dollar bill so we will use that. You could confirm that there is no way of generating 125 using only two distinct bills of the given denominations. Suppose you want to generate 43, then the largest bill that you can use is 20 because 43 is less than 100. Let us throw in a 20 dollar bill to the mix. Now you are left with 23.\nAgain, you can pack in a 20 dollar bill. Now you are left with 3. You cannot use a 20 dollar bill or a 10 dollar bill or even a 5 dollar bill to generate 3 dollars. The only thing to do here is to use 3 one-dollar bills. That is the only valid thing to do at this point. Once again, take a moment here, just play around and see if you can do this with less than 5 bills for the amount: 43. The last example is, let us say, 10,000 dollars.\nNotice that you can just keep using 100 dollar bills. You will have to use 100 of them to generate 10,000 and it should be visibly the best possible. That is what is going on with the greedy algorithm. Hopefully, the mechanics of ‘greedy’ are clear. But to see that this actually does always generate the smallest number of bills for this combination of denominations does require a bit of an argument.\nNow, I will not go through a complete and formal proof. But I will just try to convey some intuition for what is going on. Sometimes these coin systems for which the greedy algorithm does produce the right answer are called Canonical Systems. A property that these canonical systems have is that if you look at the larger denominations, they are always divisible by all of the smaller ones. For instance, here, 100 is divisible by 20, 10, 5, and 1. 20 is divisible by 10, and 5 and 1, and so on. Let us see why this property might be useful to us.\n(Refer Slide Time: 07:48)\n \nSuppose that in some instance, your greedy algorithm produces a solution, and it looks like this. The specific numbers are not important here. Let us just imagine that this is some solution to some instance. Suppose somebody comes up with a competing optimal solution, which uses fewer bills, and let us say it is different from the greedy output. The point is that we want to get to a contradiction because we have assumed that there is a better optimal solution than what is produced by the greedy algorithm.\nIn particular, let us take a look at this optimal solution. Let us take a look at their first denomination for which the optimal solution has a different behavior from the greedy solution. Just to keep things simple, I am assuming here that the optimal solution uses fewer 100 dollar bills than the greedy solution does. This could have also been, say, 20 dollar bills. Maybe the optimal solution uses the same number of 100 dollar bills as the greedy solution but uses fewer 20 dollar bills, or it could be that it uses the same number of 100 and 20 dollar bills as the greedy solution, but fewer 5 dollar bills and so on.\nIn each case, the spirit of the argument will remain the same. Let us just work with this situation. Notice here, in this example, greedy uses five 100 dollar bills, and some optimal solution comes along, claiming to do better than the greedy solution. It is distinct from the greedy solution. Let us say that this was the first point of difference — it uses fewer 100 dollar bills.\nWhat does the optimal solution do in terms of the composition of the other bills? We do not have any details here and for the most part, it will not really matter. What is important to know is the fact that the remaining amount in the optimal solution must add up to at least 100 plus whatever amount remains when you take away all the 100 dollar bills from the greedy solution. So the optimal solution which is competing with the greedy solution also has to generate a total amount of ‘n’ but now it is doing this with 100 dollar bill less. That is what we are assuming.\nThis remaining amount has to be whatever remains in the greedy solution after all 100 dollar bills have been removed that amount for sure but also plus another 100. Because this missing one 100 dollar bill has to be compensated for by the bills that come in from the remaining denominations. What we do know about this is, even though the exact composition of bills may be opaque and unknown to us, we know the total amount sitting here at least is 173 — that is the specific figure for this example here.\nBecause 100 is divisible by all of these smaller denominations. It is divisible by 1, 5, and 20. I know that if there is an amount of at least one 100 sitting here, then I can, in fact, find a subset of coins from here, which adds up to exactly 100.\nJust take a moment to confirm that this makes sense. Once you see that you can do this, then what you could do is just eliminate this subset of coins, which add up to 100. Notice that you do not have to pick the subset in any special way. You can just pick any subset of coins that adds up to 100. You know that you will be picking at least two coins because the denominations here are smaller than 100. In fact, because the next largest denomination happens to be 20, you know that you will be picking at least 5 coins but that detail is not so relevant here.\n(Refer Slide Time: 11:48)\n\nWhat is important is that you are going to be discarding at least 2 coins and let us say you bring in one 100 dollar bill in exchange to compensate for what you have thrown away. Now notice that this is a solution, which manages exactly what the so-called optimal solution was managing, but with fewer bills. The claimed optimal solution was not optimal after all, which is a contradiction.\nNow, of course, we have done this with some specific numbers and in a slightly specific way, assuming that the optimal differs from the greedy in the number of 100 dollar bills that it uses and it differs by exactly 1. Hopefully, even this specialized limited argument gives you a sense of why the greedy algorithm may be expected to be correct. Now you could take pen and paper and try to write out this argument in its full generality.\nTry and appreciate where the divisibility property comes into play when you argue the correctness. All of this is leading up to the idea that for more general non-canonical coin systems, the greedy algorithm may not work. You could take a moment here again to try and come up with your own coin system where you do not have this divisibility property and try and figure out why it does not work.\n(Refer Slide Time: 13:02)\n\nAs a hint, let me give you a coin system. Here is a coin system with 3 denominations, 1, 3, and 4. Can you come up with a choice of ‘n’ for which the greedy strategy will fail? Feel free to pause here for a moment and try to work through this. Here is a value of ‘n’ for which greedy will fail. Suppose you try to generate 6, the greedy algorithm will try to do its maximum leverage backing.\nIt will use one 4 dollar coin or bill and after this, you are still left with an amount of 2 to be generated. You cannot use 4. You also cannot use 3. The only choice you have is to use two 1 dollar bills. On the other hand, you can probably tell that this is not optimal because 6 can instead be generated with just two 3 dollar bills and that would be the optimal solution in this case. So, you can see that the greedy algorithm can land you in trouble in these more general settings.\nIt is a useful exercise to go back and see where the proof ideas that we had for the canonical systems, in fact, break down. Just try and pretend to be prove the greedy algorithm in the setting where you already know in advance that it does not work. Try to go through the experience of the step at which the proof in fact breaks down. So with that, we come to the end of the description of our first greedy failure. Now we are going to do a couple of more examples in the upcoming videos. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec07.html",
    "href": "materials/cpnotes/Lec07.html",
    "title": "Searching and Sorting - Module 3 (Magic Ship)",
    "section": "",
    "text": "Lecture - 07\nSearching and Sorting - Module 3 (Magic Ship)\n(Refer Slide Time: 00:11)\n\nWelcome back to the third module of the second week on searching and sorting algorithms. This time, we are going to be looking at a really cute problem called Magic Ship. This is from the educational Codeforces round number 60, I believe. It is one of those problems where I think at some point, it does become clear that you have to do some kind of a binary search, just looking at the limits in the input.\nBut it turns out that it is not completely obvious what the upper limit for the binary search range should be, at the outset. Of course, you can make an educated guess. But just thinking through proper argument is a really fun experience as well. So, we are going to see that and a lot more. As usual, let us get started by taking a look at the problem statement.\n(Refer Slide Time: 01:02)\n \n \nThe problem statement begins by proposing that you are the captain of a ship. This picture here is quite appropriate because our task is to figure out if we can steer the ship to a particular destination in the presence of very windy weather. Let us take a closer look at what we are supposed to do. The very poetic concept of an ocean is modeled by simple cartesian coordinates in this problem. To begin with, your ship is at the location x1, y1, and your destination is at the location x2, y2.\nIn one step, you can move one unit to the left or to the right or up or down. You cannot make a diagonal move in a single step. That is how your ship is constrained to move. These are the instructions that you can give your ship if you had to go from where you are currently to where you want to go. It is quite straightforward.\nNotice that it is the best you can hope for in terms of the number of steps that you need to expend. But if this was the entire story, this would probably be an implementation problem that we will have discussed last week. So, the twist is that, as I mentioned earlier, you are navigating the ocean in windy weather and the winds are pushing the ship around in different ways. You have to try and figure out whether you can get to the destination in the presence of these winds. How are the winds modeled? How are we given information about what the winds are doing?\n(Refer Slide Time: 02:50)\n\nThis is through a weather forecast. And the weather forecast is essentially coded in this language. It is a string, which has ‘n’ letters and each of these letters is one of these alphabets here. It is either ‘U, D, L, or R,’ signifying whether the wind is going to blow the ship in the east direction, or west or north or south. The winds also, in one day, will push the ship one unit in one of these directions. That is the behavior of the wind. Let us try to understand this through an example.\n(Refer Slide Time: 03:35)\n\nWe have here the initial state of the ship. We also have the weather forecast for the next 7 days. I was talking about one step so far. But in the language of the problem statement, these steps are codified as days. So, I will talk about days and steps interchangeably. With this one-week weather forecast, let us see what the ship will do if it has no other forces acting on it. Right now the captain is sleeping peacefully and is not steering the ship in any way. So, the winds alone will have the following effect on the ship.\n(Refer Slide Time: 04:02)\n \nOn the first day, the ship will move north one unit. On the second day, it will simply come back down to its original position. On the third day, it will move one unit to the right. On the fourth day, it will again move one unit further to the right. On the fifth day, it will go up. On the sixth day, it will come back down. Finally, on the seventh day, it will move one unit to the left. You can see that the net effect of all of these movements is that the ship moved one unit to the right of where it was originally.\n(Refer Slide Time: 04:11)\n \n \n\nLet us see how these instructions from the weather interleave with actual steering attempts from the captain. While the winds are doing their thing, let us say that the captain has now woken up and decided to steer the ship in some meaningful way. On the first day, the winds are blowing towards the north. Let us say the captain tries to leverage this and also pushes the ship in the northern direction. This will have a compounding effect. These moves are going to add up, and the ship overall will end up moving two steps to the north.\n(Refer Slide Time: 04:45)\n \n \nOn the second day when the wind is trying to push the ship back down, the captain tries to apply an opposing force where the instruction from the captain is to go up. This up and down will have sort of a canceling effect. The final outcome is that the ship will stay put at its location at the start of the day. It does not have any net movement.\nOn the third day, both the captain and the winds are pushing the ship rightwards. So, the overall effect is that the ship moves two units to the right. On the fourth day, the wind is pushing the ship one unit to the right, and the captain observes that this is exactly what he wants. So, there is no instruction from the captain on this day. He chooses to stay put, and the ship just stays in place. Notice that by now the ship has actually arrived at its destination.\nWhat you do from here will turn out to be not so relevant to the mechanics of our problem. One option is to just go back to sleep and be at the mercy of the winds again. This will just mean that the ship will drift around based on the instructions from the weather forecast.\nOn the other hand, if you really wanted to stay put at the destination for longer, then you could simply issue instructions that negate the impact of the wind, and you can stay at the destination for as long as you want. Both possibilities are definitely feasible. But as I said, they will not be as important as getting to the destination in the first place, which will be the main focus of our problem.\nThe next thing I want to talk about is the weather forecast. Here, for instance, we have the forecast for the next 7 days. But if you wanted to know what happens in the next month or the next year, then how do you get that information? This may be important because perhaps it is not possible to get to the destination within 7 days. So, you might need to have an understanding of how the weather will behave beyond these seven days.\n(Refer Slide Time: 07:27)\n \nWhat we are given in the problem statement is that the weather forecast is periodic, which means the same behavior will keep playing out again and again. In some sense, you have a weather forecast, which is indefinite. You know exactly what is going to happen any number of days from now, just by maintaining this information cleverly in your code. We will come to that later in a little more detail. But for now, know that in principle, you have all the information that you could possibly want about how the winds are going to behave over the coming days.\n(Refer Slide Time: 08:07)\n\nOur task is going to be to figure out how quickly can we get from our current position to our ultimate destination? Specifically, we want to find out what is the minimum number of days that we need to reach the destination in the presence of these winds, as they have been described by the weather forecast.\n(Refer Slide Time: 08:27)\n \nIf you look at the actual output format, and this is a screenshot from the problem statement, it says exactly what you would expect. The output has only one line and it prints the minimum number of days that are required for the ship to reach x2, y2. But then it has this interesting follow-up line which says ‘if it is impossible, then print -1.’ This line right here suggests the possibility that our task may, in fact, be impossible in some situations.\nIt is perhaps conceivable that there are choices of starting points and destinations, and weather forecasts, which are such that the forces of nature are so strong that no matter how clever or how hard working a captain you are, you simply cannot get the ship to where it should be.\nThis is a good time to pause and think about whether you can come up with such a concrete example or is it just a trick statement here. Maybe, the problem setters thought that this would be a cute thing to add just to throw you off a bit. Take a pause and try and play around with some examples and see if you can come up with one that is, in fact, impossible. Come back when you are ready.\nHopefully, you had a chance to think about this. One possibility is that you are in the ‘what is impossible camp.’ Maybe, you believe that no matter how adversarial the situation is, if you are determined to get the ship to where it should be then you will manage to do it. However, it turns out that this is not a trick sentence. There could be scenarios, which are, in fact, impossible.\n(Refer Slide Time: 10:09)\n \nHere is one which is very similar to one of the sample input-outputs that are given in the problem statement. Here is a situation where the ship looks temptingly close to its destination. It is just one unit off to the left, or to the right, depending on how you are looking at it. The weather forecast is also very simple. It says that the winds are always blowing northwards. Since the forecast is periodic, we know that we are forever stuck with a wind that is pushing the ship up north.\nLet us think about why the ship under this circumstance will never reach the destination. For this, let us try and analyze what are the possible things that the captain can do. The first possibility, for instance, is that the captain can choose to abstain and say that, ‘okay, we will not do anything.’ In this case, the wind is going to take the ship one unit north, and what happens is that you are truly doomed from here.\nThe reason for that is in all future steps, your ship is only going to gain, I guess, altitude is not the word, but it is either longitude or latitude, one of these things. Basically, the ship will either stay where it is, that will happen when you issue a negating force to what the wind is doing, you try to move downwards, or you just move either North or Northeast or Northwest. But you are never coming back. You will never come back to thinking of this as rows and columns, you will never come back to the ith row if that is where you started out. So, if you decide to do nothing, then it is very clear that there is no looking back.\n(Refer Slide Time: 11:56)\n \nThe other thing that you could do is that perhaps you could try to go North. It seems even more silly, to be honest, than what we did in the previous case. If you choose to move north, then you are only helping the wind in taking you further away from your destination. You just drifting away even faster. It will clearly not work for very similar reasons once again.\nThe other thing you can do is try to move left, which again, intuitively is moving away from where you need to go. This time, you will move northwest. Again, it is the same argument as before. You are going to continue to either stay in the (i+1)th row or actually move even further up and further away, in particular.\n(Refer Slide Time: 12:53)\n\nThe two remaining possibilities are that you either move down or you move to the right. If you move downwards, then all that happens is that you stay where you are because you have negated the wind. If you move to the right, which seems to be the most natural thing to do because that is where you are supposed to go, in the absence of the wind, you would have reached at your destination, but in the presence of the wind, you just miss it.\nSo, you end up going upwards instead of going to the right. All in all, no matter what you try to do, you are not reaching your destination. Here again, with the last case, the same argument applies with regards to once you have shifted one row upwards, it is just going to be downhill from there, or maybe uphill.\nWhat I am saying is that it is, basically, a lost cause. Either you stay where you are permanently, or if you have any movement at all, it is going to be damaging. It is just going to make you drift further away from your destination. The closest you can be is to stay put. But that is not what we are analyzing here. We want to reach the destination. Overall, this tells us that these impossible scenarios do exist, and whatever strategy we come up with should have the ability to recognize them.\nHow do we go about something like this? If you remember the last problem that we discussed, The Meeting Place Cannot Be Changed. One question that we asked ourselves was: Are ‘k’ seconds enough to get everybody to meet at some common point? This turned out to be an insightful question to ask, which eventually led us to our solution.\n(Refer Slide Time: 14:45)\n\nHere we will ask an analogous question, which is essentially going to be: Are ‘k’ days enough for us to reach the destination? If there is a solution at all, it is going to require some number of days. We will show that if there is a solution, then there is also a solution, which is at most something. This will be an upper bound that we identify so that we have a well-defined search space. We say that either it is an impossible situation, or the possibilities are really limited to this range for the value of an optimal solution.\nOnce we do that, notice that we can again binary search on this range. Because if you can get to the destination in at most ‘k’ days, then you can get to the destination in at most ‘k’ prime days for any ‘k’ prime that is larger than ‘k.’ That gives us the sort of a binary searching strategy, just like before.\nIf the answer to this question: ‘Can we reach the destination in k days?’ is yes, then we need to challenge ourselves with smaller values of ‘k.’ But if the answer is no, then we know that we need more time because we certainly cannot do it with fewer than ‘k’ days if we cannot do it in ‘k’ days already. In that case, we will search for values larger than ‘k.’ The overall template is the same as last time.\nBut we do need to fill in a couple of very specific blanks. The first one is identifying the scope of the search space. So, we will have to think about what is an upper bound on the size of any optimal solution, if one exists. The other thing is, how do we answer this question? When we are probing the midpoint of whatever our current search space is, we need to ask ourselves, are so many days enough?\nBased on whether the answer to that question is yes or no, we will prune our search space appropriately. These are the two things that we need to figure out. Let us address the second question first. Let us talk about how to figure out if we can reach our destination in ‘k’ days.\n(Refer Slide Time: 16:58)\n  \nTo address this question, let us just draw up an abstract scenario. Here you can see the ship in its initial location. You have the destination, and you have the weather forecast as usual. To consider the possibilities of what can happen over a period of ‘k’ days, it is useful to just split up the impact of the weather conditions, and the impact of the captain’s instructions. You know that the weather forecast is an inevitable factor in what happens over the next ‘k’ days. Let us consider that first.\nWe let the wind do its thing and just keep track of how the coordinates are going to change as the weather forecast plays out. You can do this by simply looking at the code of the forecast and figuring out how much you have to adjust the ‘x’ and ‘y’ coordinates of the ship in aggregate.\nIn some sense, you know where the ship will end up. If the captain was sleeping throughout these ‘k’ days, if there were no instructions from the captain at all, then you would be at this location that we are for now calling x3, y3. The question is, can we come up with criteria of when the destination is accessible? Given we know that we are going to take a hit of at least so much in our x and y coordinates. Of course, what we are still left with, we have some role to place yet. We have to figure out if we can do some course correction by exploiting the fact that the captain can do some work.\nBut how much course correction is going to be possible? Is it going to be enough for us to reach the destination? Please pause the video here and think about if you can come up with some criteria for whether the destination is reachable or not. Given that the unavoidable impact of the wind takes you to x3, y3 if you do nothing. Hopefully, you had a chance to think about this.\nNote that the thing we need to make precise is the following. We want some kind of clean criteria that will help us identify exactly which points are accessible, given that we start at the starting point and the wind brings us to x3, y3, if considered stand-alone. Also, given the fact that we still have the opportunity of ‘k’ days worth of course correction across both coordinates combined.\nWhen you put all this together, you realize that the points that are ultimately accessible to the ship, starting where it started and given all of these other facts are precisely those points, which have a Manhattan distance of at most ‘k’ from x3, y3. By Manhattan distance, we just mean all points that can be reached by a perturbation of, let us say, ε1 across the ‘x’ coordinate and a perturbation of ε2 on the ‘y’ coordinate, such that the ε1+ε2 is at most ‘k.’\nYou are allowed to move along the x and y coordinates in such a way that the total movement does not exceed ‘k.’ That is, sort of, exactly what we can afford to do. As we were saying earlier, whether you do the compounding of the instructions from the wind and the instructions from the captain on a day-to-day basis, or whether you separate them out and consider the effect of the wind first, and then the effect of the captain’s instructions, the ultimate point where you land up is going to be the same.\nThis reordering of the instructions is useful because you can first focus on x3, y3. You know that that is where you are going to reach by virtue of the weather forecast. Now you can consider what can possibly happen based on the remaining ‘k’ instructions. What can possibly happen is that you can only move around in this sort of ‘k’ neighborhood of x3, y3, but this is not the standard ball around x3, y3. As I said, everything that is accessible through a total movement of ‘k’ units across both coordinates.\nHopefully, that is clear. Of course, in this particular example, you can see that our destination actually does fall in this region that we have identified and is, therefore, accessible. This is only an abstract example. I have not even put in a specific weather forecast or specific numbers. But that is not important. I think what is crucial is just being able to identify this condition. To recap the actual condition, what we are saying is the following.\n(Refer Slide Time: 21:58)\n \nSo, ‘k’ days are enough if and only if the Manhattan distance between x3, y3, and x2, y2 is at most ‘k,’ where x3, y3 is the point that you land up at if you were to start at x1, y1, and just obediently follow the weather forecast for ‘k’ days. Once again, we will have to figure out how to write this in code. Because ‘k’ could very well be more than ‘n,’ which is the number of days for which you have the weather forecast.\nYou have to do a bit of a circus to do the periodic exercise to figure out exactly how much movement is there. Fortunately, it is not hard at all. It is just a matter of being careful about keeping this aspect in mind. Let us recap what we have learned so far.\nRemember, we were trying to address the question of whether we can reach our destination in at most ‘k’ days. In particular, we wanted to come up with a procedure that will help us identify whether the answer to this question is yes or no. We said at a high level that it is useful to separate the impact of the weather forecast from the captain’s instructions. So, as a first step, what we did was we calculated the net effect of the weather forecast up to ‘k’ days on the coordinate x1, y1, and this brought us to the coordinates x3, y3.\nIn the second step, we just had to check if the Manhattan distance between x3, y3, which is where we land up under the influence of the wind, is at most ‘k’ from x2, y2, which is our destination. If it is, then the answer to the question is yes. If it is not, then the answer is no. By now we have a subroutine, which can tell us if ‘k’ days are enough or not.\n(Refer Slide Time: 23:52)\n\nThe only piece of the puzzle that remains is to figure out the scope of the search space. You know the rest of the template. You know you are going to do a binary search. You just have to figure out a valid upper bound for the search. It can be dangerous to work with an ad hoc upper bound, because if it is not good enough, maybe there was a solution that was bigger than the upper bound you were experimenting with, but you just missed out on it.\nTo address this, what we are going to do now is to come up with a guaranteed upper bound, which assures us that if there was a solution at all, there would have been one with cost, at most, this much. It is safe for us to restrict our search space to be 0 to that quantity, whatever that quantity is. I will also say that when you are solving a problem like this in a contest, then coming up with a provable argument of the sort that we are just going to see in the next few minutes may not be completely necessary.\nIf you have some intuition based on the limits of the problem, you could just try to give it a shot with that. Or you could simply try and shoot for the largest upper bound that the time constraints will allow. At this point of solving the problem, we are probably reasonably confident that our overall binary search template is correct. We also know how to handle the probing questions of whether ‘k’ days are enough.\nThe only issue left is, what upper bound should we use? We can do a quick back-of-the-envelope calculation to estimate the amount of time that we need to answer the probes. Then we can actually reverse engineer what is the largest limit that we can afford to have for our code to not timeout. Then we can simply use that limit. So, if we are short on time, you can use tricks like this. But it turns out that there is a very nice argument, which says that you can work with a particular limit. Let us try to understand that a little bit.\n(Refer Slide Time: 26:03)\n\nHere is our abstract picture. Let us use ‘n’ to denote the length of one full forecast cycle, the number of days for which we have the weather forecast. Let us also use ‘d’ to denote the Manhattan distance between the original source and destination points. That is what we have. The claim is going to be that if this is not one of those impossible scenarios, then there is a solution whose cost in terms of the number of days is at most d*n, and d and n are as we just defined.\nLet us try to argue this a little bit. The intuition here is that with every cycle of the movements of the wind according to the forecast, you must somehow reduce the Manhattan distance by at least one. If you do not have a strategy to do that, then you are basically never going to get to the destination in the first place. If you think about it a bit that is what was happening when we were discussing the one impossible scenario example earlier.\nIn one cycle of the weather forecast, which was just essentially one day, we were not able to reduce the Manhattan distance between the source and the destination. Remember that they were one unit apart. We saw that no matter what we did, they remained one unit apart, or they drifted even further apart. That is the kind of spirit of the argument that we are going to make right now as well. Let us get to it.\n(Refer Slide Time: 27:47)\n\nSuppose we do have a solution. The explicit claim we are making is that there is some sequence of ‘n’ instructions that the captain can give, which, if given along with this weather forecast that has been given to us in the first place, when is combined, then the Manhattan distance between the source and destination strictly decreases. That is the claim. So, again, just to recap, because this was quite a handful. What we are saying is that if there was a solution, that means there is a way of getting closer to the destination in one cycle of ‘n’ days.\nTo see that this is true, let us say that suppose this was not the case. That no matter what sequence of instructions the captain comes up with, and there is going to be 4n possible such sequences, for each one of them if we try to run that sequence of instructions in one cycle, then we would be left either where we were, or we would be left further away in terms of Manhattan distance from the destination.\nSuppose this is the case. No matter what you do, you either stay where you were, or you stay within the same Manhattan distance of the destination, or your distance from the destination in fact increases. One of these two things happens. If this is the case, then I want to argue that you cannot have a solution. No matter what solution somebody attempts, you are either going to not make any progress or if at all, you end up moving, then you keep drifting further and further away from the destination. Let us try to just get some intuition for why this is true.\n(Refer Slide Time: 29:41)\n\nSppose, somebody did try to come up with a solution. Even though we know that no matter what set of instructions you use in each cycle, the total amount of movement that you experience, at least in the first cycle, we know by assumption that our Manhattan distance from the solution has not reduced. In particular, it is either stayed the same or it is increased. Tthat is what is going to happen when the ship has finished executing all of these instructions from the first cycle.\n(Refer Slide Time: 30:14)\n \n \nSuppose it gets to the end of the second cycle. I want to claim that, once again, this is true. That the distance between the source and the destination has either stayed the same or it is increased, but it could not have possibly decreased, and so on and so forth. Bcause this just keeps happening, you never actually get to the destination. To understand this a little bit better, let us make the arguments somewhat more explicit by working with actual coordinates.\n(Refer Slide Time: 30:41)\n \nTo make our life a little bit simpler though, instead of working with x1, y1, and x2, y2, let us just say that we are trying to reach the origin from some point x, y. This is without loss of generality because you can always slide your coordinate system so that the origin coincides with the point x2, y2, which is your destination. And I am just relabelling x1, y1 as x, y.\nHopefully, this part is okay, just makes the notation a little bit cleaner. Notice that the Manhattan distance of any point from the origin is just the sum of its x and y coordinates. That comes in useful as well. Notice that in the first cycle of ‘n’ days, let us say we get from x, y to x’, y’, what we know is that x’ + y’ is at least x + y. Right. Because by assumption, we have said that no matter which of the 4n sequences you deploy, you are not going to reduce the Manhattan distance from the destination.\nWe know that we are at least as far away as before. Let me just try to write x’, y’ as ε offsets from the original point x, y. So, we can say that x’ is x + εx, and y’ is y + εy. Note that our information about x’ + y’ being at least x + y simply translates to εx + εy being at least 0. That is what we have in the first step. What is interesting to observe is what happens in the first and the second cycles combined. Let us say we go from x, y to x’‘, y’’.\nLet us say we get there by deploying the first sequence of instructions, the orange ones, and then these green ones. This picture of just being a bit miserly with space may be a bit misleading. What is going on is that to get from x, y to x’‘, y’‘, you essentially go to x’, y’ first, and then from there, you deploy a fresh set of instructions, which are these green ones. We know that if we had deployed the green instructions on just x, y directly and nothing else, we would still be left no closer to the destination.\nLet us see if we can use that to say that even x’‘, y’‘, which is the orange and the green instructions combined, are also no closer to the destination compared to when we started out. So, let us write out x’‘, y’’, and let us say that the effect of the green instructions was ε offsets once again, but this time it is the green epsilon. Let us say that if you had applied the green sequence of instructions on x, y, then you would have landed up at x + εx and y + εy, with these epsilons being the green ones.\nThen if you apply the green instructions to x’‘, y’‘, then what you get is this point here, which is x’ + εx and y’ + εy. Now let us substitute for x’ and y’, in terms of x + εx and y + εy. But this time, it is the orange epsilons from before.\nNotice that we essentially have offsets. We have understood x’’ and y’’ in terms of offsets from x, y, but we also know that the net effect of these offsets is non-negative. What we really want is the total offset to be negative to be able to come closer to the destination.\nNotice that even after two cycles, that is not happening. It is the exact same argument to say that it is not going to happen after three cycles or four cycles, or after any number of cycles. If it was really the case that no matter which set of instructions you apply, you come no closer to your destination.\n(Refer Slide Time: 35:06)\n \nWe know that if there is a solution, then there must be a sequence of instructions, which is such that if you combine it with the weather forecast, then it strictly reduces the Manhattan distance between the source and the destination. Now just keep repeating this argument to see that you must have a sequence that brings you to the destination in, at most, d*n steps. Because in every cycle, you are able to reduce the Manhattan distance by at least 1 by applying the appropriate set of instructions. So, you will never need more than d*n many steps to actually get to the destination.\nIf you look up the actual limits in the problem for ‘n’ and so on, I think it turns out that your upper limit is some 2*1014 or something like this. In any case, at some fixed upper bound, as I said, you do not have to have either a bound that is so precise, nor do you need an argument that is this detailed. You just need to have some either overall intuition for what is going on. So, that you arrive at this d*n as sort of a bound, roughly speaking, or you can, as I said, employ a trick to just let the bound be as large as it can possibly be. Just work with that. That should be perfectly fine.\n(Refer Slide Time: 36:35)\n \n \nLet us just recap how the binary search will work. As usual, you get to the midpoint. If the current midpoint is, let us say, some ‘k,’ we ask ourselves: Are ‘k’ days going to be enough to reach the destination? If ‘k’ days are indeed enough, then we need to challenge ourselves to find smaller values of ‘k’ that are probably better, but we can definitely, confidently eliminate the top half of the search space.\nSimilarly, if ‘k’ days are not enough, then we know for sure that all values of ‘k’ that are smaller are useless for us because we know for sure that none of those are feasible. So, we can just focus on the top half of the search space. With that, notice that we are pretty much done. You might be wondering about when this algorithm returns a verdict of impossible for the task at hand. Notice that it will happen when each of your probes individually returns an output of infeasible.\nYou try with the first midpoint: it says, well, these many days are not enough. You try with a larger value, and it is still not enough and you try with a larger value, and it is still not enough, and so on and so forth. You keep doing this till the very end. If every output is ‘this is not enough,’ then at that point, you know that you have exited the binary search with some sort of a failure to discover a ‘k’ in the range that we had stipulated, which would work for you.\nBut since, we have argued already that if there is an answer at all, then there is an answer in this range. This is sufficient evidence to conclude that your task was indeed impossible. Of course, if any one of the probes says feasible, then you certainly have at least one valid answer. Because of the nature of the binary search, by the time you exit your ‘while’ loop that is controlling the binary search, the value that you have is, in fact, the optimal number of days. That, I think, brings us to the end of our discussion of the overall approach.\nIt is now time to roll up our sleeves and write some code. I think the implementation of this is fairly straightforward, and structurally, very similar to what we saw last time. But one detail to keep in mind is implementing the periodicity so that you can do these little operations in terms of figuring out if ‘k’ is feasible or not, and things like that, comfortably. We will get to that in just a moment. But this is your standard reminder that if you wanted to try this yourself, then please give it a shot and come back when you are ready. In the meantime, let us just go ahead and talk about the implementation.\nSo, we will be looking at some Python code here. The reason is that, first of all, the official editorial for this problem has some nice C++ code already. I recall thinking that it was quite readable. I think you could follow that if you primarily work in C++. The approach is exactly the same as what we have here. There may, of course, be a few very minor implementation details that vary but the algorithm is essentially what we have discussed, so far.\nThe other thing is, this is a problem involving some fairly big numbers. I just wanted to demonstrate that you can do pretty well with a Python-based implementation as well. I think if you look at the problem history, you will see that there have been a number of Python-based solutions that have passed and we are going to look at one such.\n(Refer Slide Time: 40:17)\n \nTo begin with, what we have here is just taking the input in. This is pretty standard. There is nothing unusual here. We take in the coordinates of the origin and the destination and store them with variable names that are consistent with our discussion, so far. We have x1, y1, and x2, y2. Then we have the length of the weather forecast that is an integer, and we have the weather forecast itself, which is a string with that many characters. We take that in as a string and call it ‘S.’\nNow, let us just compute an array. This was essentially the analog of the prefix sums approach for keeping track of the periodicity of the weather forecast. What we want to do here is, essentially, pretend that we are starting at the origin and let the wind drag us around wherever it needs to, based on the weather forecast. This code here is exactly like the code version of the slide where we were explaining what the forecast means, what the different letters mean.\nBased on whether you are going up, down, left or right, you update the ‘y’ or the ‘x’ coordinates respectively. This will kind of be your memory of how you travel, based on the weather forecast alone. We are going to store in walk list your evolution as you go along. For instance, let us say the forecast was R, R, R, then the walk list would be 0, 0, to begin with, then you would append a 1, 0 because you have moved one step to the right and nothing on the y-direction, that is going to be the same.\nThe next element in the walk list will be 2, 0, and the element after that will be 3, 0. You could write down this piece of code here and run some print statements just to sanity check that everything works out the way you expect it to. This is the sort of place where there may be small typos like a + may become a - or something like that. It is always a good idea to sort of sanity check these things as you are writing the code so that once you have moved on from here, you are reasonably sure that there were no typos or bugs here. So this is some auxiliary thing, which will help us later.\n(Refer Slide Time: 42:46)\n\nThe main drama, of course, happens with the binary search. That is what we want to talk about next. Here we have the initial limits. We worked very hard to come up with an upper bound on the search space. We said it is two times 1014. I am just being lazy here, 1015 is my upper bound, that should work just as well, of course. It is even more liberal.\nNow, we have the usual binary search templates. As long as the left and the right endpoints of the search space have not converged to a single conclusive point, we have to keep going. That is the ‘while’ statement that declares the start of the binary search process. We compute the midpoint in the standard way as well, nothing fancy there.\nNow we have to figure out: so, what is mid? Mid is our current guess for the number of days that we want to spend. The question we are asking ourselves now is: Are mid-many days enough to reach the destination?\nRemember, the criteria for figuring out the answer to this question, we had to compute the Manhattan distance between the destination and the place that we will end up at if we were only at the mercy of the weather. We have to, first of all, compute x3, y3. Where do we end up if we just followed the weather forecast?\nFirst, let us figure out how many cycles of the weather forecast are there inside mid and what is the remainder. So, you can use this built-in ‘divmod’ function to quickly figure out the quotient and the remainder. That is exactly how it works. If you give ‘divmod’ two numbers, let us say a and b, it is going to compute ‘a’/‘b.’ It is going to give you the quotient and the remainder. That is what we have done here.\n(Refer Slide Time: 44:29)\n  \nNow that we know this, let us compute the x and the y offsets from the origin point. We start at x1 and y1 respectively. And we know that we have to go through Q cycles of the weather forecast. We have an offset of Q*x and Q*y. If you go back, remember that x and y are essentially storing the total amount of offset that you experienced if you go through one cycle of the weather forecast.\nThat is what we are doing here. We are going through Q cycles. We are adding Q*x and Q*y. But now we also have ‘remainder-many’ days of the weather forecast that we experience. It is not a full cycle; it is a partial cycle. The offsets for all possible partial cycles are stored in the walk list. If you go to the ith element of the walk list, you will know where you would be ‘i’ days after experiencing the weather forecast starting from the origin, so that is essentially the offset. We add that offset to whatever coordinates we have computed, so far.\nThe expression that you see after the negative sign is essentially the values of x3 and y3, and the absolute difference between x2 and y2 with x3 and y3 respectively is essentially giving you the two components of the Manhattan distance between the destination and x3, y3, which is where you land up only under the impact of the event.\nLet us recall what was the defining criteria for whether mid-many days are going to be enough. What we needed was for this distance that we have just calculated between the destination and x3, y3. We needed that distance to be at most mid. If that distance is at most mid, then we know that we can issue appropriate instructions to get to the destination, otherwise, mid-many days are not enough. That is what is happening in the next four lines of this program.\nWe are saying that if the total distance, which is given by the sum of the x and the y offsets, if that distance is at most made, then great. Then mid-many days are enough, and we should be more ambitious. We should aim to work with smaller values of mid and see if that would also work out. What we do is we take the right endpoint of the search space and bring it down to mid because larger values of mid are of no interest to us. We have already managed what we need with mid and now we are going to explore the lower half of the search space.\nOf course, in the ‘else’ block, the exact opposite logic takes over, that mid many days are in fact, not enough. Because of exactly what we said, your distance is too much. Your distance from x3, y3 to destination exceeds mid. Whatever you can do within mid-days, you are not going to arrive at the destination. In this case, you know that mid is not enough. Your search base reduces to ‘mid+1’ all the way up to the end. You can bring the left endpoint all the way up to ‘mid+1.’ Okay. So, these are the two possibilities that play out here.\nNotice that when the answer is impossible, you will never get into the first ‘if’ block. So, R will remain at 1015 or whatever. The left endpoint will just keep getting closer and closer to the R endpoint.\nAt some point, it will just collapse and become 1015 itself. That is in fact, what we have next, what we are saying is that if L becomes 1015 at some point. Then you could have also done this outside of the ‘while loop,’ it does not make a difference. If you have hit the upper limit, if L is equal to R is equal to 1015 then we know that it is impossible to reach the destination.\nWe also flag that for ourselves. So, if it is not impossible, then whatever the value of mid was, which is also the value of L and R when you have exited the loop, that is going to be the answer that you need to print. That is what is happening here. That actually is essentially the entire program. This was the binary search over the number of potential days that you need to get to your destination.\nI hope you have a chance to try this out. If you have your own versions in either C++ or Java with similar documentation, then please remember to submit a pull request on the official repository. Other languages are also equally welcome, of course. Remember to attribute yourself and share your Discord username if you are in the community so that we can give you a shout-out.\nSo, we have one problem left for this week. That is going to be more about numbers. There is not so much of a story there. But it is also really fun. I hope you will join us back for the next and the last lecture of this series this week. Thanks so much for watching, and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec39.html",
    "href": "materials/cpnotes/Lec39.html",
    "title": "Minimum Spanning Trees - Module 1 (Kruskal’s Algorithm)",
    "section": "",
    "text": "Lecture - 39\nMinimum Spanning Trees - Module 1 (Kruskal’s Algorithm)\n(Refer Slide Time: 00:11)\n\nWelcome back to the final segment of the first module of Minimum Spanning Trees. So, here I want to tell you about Kruskal’s algorithm, which is a contrasting way of building up a minimum spanning tree and, certainly, a different approach from Prim’s algorithm. While you can visualize Prim’s algorithm as slowly growing out a large component starting from just a single vertex, Kruskal’s algorithm takes a more global view and is closer in spirit to the first algorithm that we discussed, where we said, let us just keep picking safe edges as long as we can. So, that is what is going to more or less happen here. Let us take a look at how we can think of Kruskal’s algorithm in terms of iteratively building up a spanning forest using safe edges.\n(Refer Slide Time: 00:58, 01:11 & 01:18)\n  \nSo, as a standard by now, we are going to initialize the algorithm by thinking of the spanning forest that is just the empty graph on the vertex set of G. And after this, what we are going to do is just consider edges in increasing order of weight. And if an edge is safe to add to the graph, if it is safe in the current graph, then we simply add it.\nThat is all that the algorithm does. It just processes the edges in increasing order of weight and adds the ones that are safe to add. So, you can imagine why something like a disjoint set union would be a useful data structure for implementing this algorithm. I will let you think about that in the back of your mind. While let us just go over a simulation, once again, just to be sure that we have a common understanding of the mechanics of the algorithm.\n(Refer Slide Time: 01:49)\n   \nSo, we are going to use the same example as before. This will also give us an opportunity to check if, you know, we get a different spanning tree. And hopefully, it has the same cost because while you can have multiple ‘minimum spanning trees,’ they should all, of course, by definition, have the same total cost. So, let us see what happens with Kruskal’s algorithm. To begin with, all the vertices that you see here are a part of the forest; none of the edges belong to the forest just yet.\nWhat we are going to do is start processing the edges in increasing order of weight. So, as an example, you might choose to pick this edge. It is one of the ones that has minimum weight. And the question that we want to ask ourselves is, is this edge safe? Well, notice that this edge certainly does not create any cycles. We are just getting started. And notice that at any step, that is actually enough to confirm that the edge is safe.\nIn particular, because this is the globally minimum weight edge, you can be sure that it is also the cheapest edge coming out of whatever components that the edge is incident on. So, to answer the question ‘Is this edge safe?’ in the current iteration, all we have to do is make sure that it is not a part of a cycle. Alright. So, this edge certainly looks safe. So, we go ahead and add it to our spanning tree. And then we look for another edge, which is of minimum weight.\nLet us say we look at this one, once again, looks safe. So, we add it. The next edge we pick is, say this one, again, a safe edge. So, it gets added. The next edge is also safe and also gets added to the structure that we are building up. Now the next edge that has minimum weight again, you have a few choices here. Let us say we pick this one. This again, looks safe – does not really create any cycles – so, we go ahead and add it.\n(Refer Slide Time: 03:56)\n   \nWhat about the next stage we want to pick? Let us say it is this one. Again, does not create any cycle so, we go ahead and add it. Even the next stage that we pick looks pretty safe – does not create any cycles. So, let us go ahead and add it. The next edge that we pick that has minimum weight could be, in fact, has to be this one here. Notice that this is an interesting edge. It actually does create a cycle. So, it is, in fact, what we would call a useless edge.\nAnd in particular, it is not a safe edge. So, we do not add this to the structure that we are building up. Moving on, the next edge of minimum weight has to be one of the edges that have weight 4. So let us try this one here.\n(Refer Slide Time: 04:38)\n   \nNotice that this edge, again, is actually not a safe edge because it creates a cycle. So, we are going to ignore this one as well. And pick one of the other ones. Say, here. This looks pretty safe, so, we go ahead and add it.\nThis one is also safe so we add this as well. And at this point, you could continue drilling down your set of edges but you might also observe that from here on any edge that you try to add is going to actually be a useless edge.\nAnd it will, in fact, create a cycle with what you already have. One of the reasons for this is that at this point, we have actually collected 9 edges. And since we are working with a graph of 10 vertices, we are actually done. So, once again, even in your implementation, it would be useful to just keep track of how many edges you have added so far and exit early.\nOnce you know that you are done, there is no need to analyze edges any further. You can check that the cost of this spanning tree is also 25 tallying with the cost that we got from the outcome of Prim’s algorithm. And once again, you could play around with breaking ties differently to get to different structures.\nSo, you can observe here that both of these algorithms may lead to different spanning trees, and in fact, two different iterations of the same algorithm if ties are broken arbitrarily can lead you to the minimum spanning trees that look different as well. So, at this point, hopefully, we understand what Kruskal’s algorithm is doing. So this is a good place to switch to a discussion of its implementation.\nSo, for Kruskal’s algorithm, we will try to maintain the graph as an edge list because that is convenient. Remember that the main algorithm is really a loop through a sorted list of edges. So, that is what we are going to use to store the graph.\n(Refer Slide Time: 06:20)\n\nSo, to begin with, we are going to actually just sort the edge list after taking input in whatever form. So, once again, please look at the full code on the official repository to look up the initializations and how the data is being incorporated into the edge list EL. At the moment, the way the edge list is structured is that every element of the edge list is a collection of three numbers: The weight of the edge, and the pair of vertices that are involved in the edge itself.\nSo, the way this works (because the weight is the first component of this triplet), when you do the sort of a sort, it is going to sort according to the first component. So, that is nice and convenient from our point of view. So, the next thing is again, the standard initializations. We have these even for Prim’s algorithm. So, mst_cost is initialized to 0. It is the variable that will help us track the cost of the MST that we are building, and num_taken again keeps track of how many edges we have included in our spanning forests so far.\nAnd this will help us with the optimization that I have mentioned before. This is when we just check if num_taken is n minus 1, and we exit the main loop whenever that condition is true. Now the data structure that we want to use to implement Kruskal’s algorithm is the disjoint set union data structure that we have already discussed in week four.\nSo, if you need to recap, you might want to just go back and look at our discussions about UnionFind from back then. For now, let me just say that the elements of our universe will correspond to the vertices and as we go along, the sets will correspond to the components of our spanning forest. So, to begin with, we have sets, which are singletons, which naturally correspond to the spanning forest that we initialize our algorithm with, where every component is just an isolated vertex.\nSo, this initialization that is ‘default’ to a UnionFind works out pretty well for us. Now the main body of the algorithm is going to be this ‘for’ loop, which just goes through the list of edges. And what we want to do is, well, of course, the list of edges has been sorted already according to weight, so you are approaching them in the correct order already. And now let us just look at the current edge. And what we want to know is if this edge is safe to add.\nAs we mentioned earlier, it is enough to check if the addition of this edge creates a cycle or not. So, given the setup that we have here, an edge is safe, if and only if it is not useless. This is not true in general, but because we are attacking the edges in increasing order of weight, we do have this luxury. So all we have to do is check for a cycle. And that is exactly what is happening in this line of code. You have a cycle exactly when the edge has both of its endpoints in the same component. But that is exactly what the same set operation from UnionFind helps you check.\nSo, if both u and v, which is the edge that is under consideration currently belong to the same set, that means that that is in fact a sign of a useless edge. So, we are going to ignore this edge and continue along the main ‘for’ loop. On the other hand, if this edge is not useless, then it is a safe bet to actually add this edge. So, we are going to go through the process of adding this edge by just making sure that we add the cost of this edge to the mst_cost variable.\nWe actually merged the components that the edge has its endpoints in – this is the key step in terms of structurally accounting for the fact that this edge has been added to your spanning tree. And after this, of course, we could also update the num_taken variable to indicate that we have added one more edge to our collection here. And then finally, we add the sanity check, which says that if you have enough edges, you can get out of this loop – if you like, just leave the party early.\nAt this point, we are pretty much done we could come out of this loop and print the cost of the spanning tree that we have built so far. And once again, (it would) be an interesting little bit of extra bookkeeping to keep track of the actual edges that go into your spanning tree. So, see if you can keep track of that and actually output the spanning tree when you are done. So, notice that at the end, you must have exactly one set in your UnionFind data structure for you to have actually found a spanning tree. This will happen as long as your graph is connected, to begin with.\nIf it is not connected, what you will end up with is a spanning forest with as many components as there are sets in your UnionFind data structure. So, that is it, that is pretty much the entire implementation for Kruskal’s Algorithm.\n(Refer Slide Time: 11:14)\n\nLet us just talk a little bit about how long this is going to take in terms of its running time. Well, the first step, of course, is when you sort the edges. That already costs you m log n. And after that, you have this for loop over the edges. So, that is going to run m times. And inside the loop, you do have operations like checking for whether u and v belong to the same set or not. And actually, taking the union of these two sets whenever they do not belong to the same set.\nSo, those are operations from the UnionFind data structure, and their expense will depend a little bit on the implementation. You know that if you do something like path-compression-based implementations with union-by-depth heuristics, then you could get as good as near-constant amortized complexity. But even if you do a fairly simple union by rank implementation, even the worst-case complexity of each of these steps can be bounded by log n.\nSo, it is just easy to think of the complexity of Kruskal’s algorithm as being m log n in the worst case, given that m is at most n squared. So, notice that this is very, very similar to the running time that we already have for Prim’s algorithm. Once again, I will repeat that if you have to make a choice, you could probably use either algorithm for most MST problems that come up in contests.\nPerformance-wise, it should not make a difference. But often, you are not being asked directly for MST. I mean, there are probably two kinds of problems that you will encounter. One is where most of the work is in just recognizing that it is an MST problem in the first place. And being able to come up with a clever graph abstraction where the task can be translated to the MST problem. In this case, either algorithm should work out fine.\nAnd your main work is really in being able to see the graph and, you know, being able to model the problem as a graph. And after that, it is just plug-and-play. On the other hand, there are other kinds of problems where these are basically rip-offs of MST. So you are looking at MST variants. And then you may need to actually use one of these algorithms, but with minor tweaks. So, in that case, it may turn out that one of these approaches is better suited to the problem at hand compared to the other.\nSo, that is a situation in which you might want to be equally comfortable implementing either of these approaches. So, as always, you can find the code that we have discussed in the official repository. And if you are watching this video during the live run of the course, then the Discord forum is going to remain active. So, please share your comments or your questions there.\nAnd if you are not watching this during a live run of the course, please leave your feedback in the comments on this YouTube video, and we look forward to getting back to you. Thanks so much for watching. In the next videos, we will solve some actual problems based on MST, and I will see you in the upcoming modules!"
  },
  {
    "objectID": "materials/cpnotes/Lec11.html",
    "href": "materials/cpnotes/Lec11.html",
    "title": "Greedy Algorithms - Module 3 (Stable Marriage-I)",
    "section": "",
    "text": "Lecture - 11\nGreedy Algorithms - Module 3 (Stable Marriage-I)\n(Refer Slide Time: 00:11)\n\nWelcome to the third module in the third week of ‘Getting Started with Competitive Programming.’ This week we have been looking at ‘Greedy Algorithms’ and I hope that the couple of examples that you have seen so far are already giving you a feel for how these things work. This time we are going to look at an example, which is actually a computer science classic, and it is called the ‘Stable Marriage’ problem.\nThis problem has enormous applications and really interesting history. If you are curious about some of the trivia that is associated with this problem, please check out some of the links in the description, which include a pointer to a very cool number file video on the topic and a couple of other really interesting articles. I will be presenting this as a stand-alone puzzle because of limitations of time and will really be doing no justice to the amazing history of this problem.\nPlease do learn more about it after you are done with this video, if you feel so inclined. Back to the context of contests, this problem did make an appearance in one of the ICPC Regionals. It is also available on the CodeChef problem archive. You can find links to both versions in the description of this video and you can use either one for practice, whatever is more convenient. The tasks are exactly the same and if I remember correctly, the limits are also kind of similar. So, it should really make no difference. With all that said, let us get to the problem statement and figure out what our task is going to be.\n(Refer Slide Time: 01:47)\n  \nThe setting is the following. We are given two groups of people, which we will refer to as ‘men’ and ‘women’ and there is always going to be the same number of them. Let us say that there are N men and N women for a total of 2N people. By the way, let me just mention that this terminology, using the word ‘marriage’ to refer to the problem itself and to refer to these groups of people as men and women, is traditional even in the computer science research literature around this problem.\nSo, it is not just from the contest problem statement. Do not be fooled into thinking that this is just a puzzle about matching men and women and getting them into happy marriages. It just turns out that this terminology is a convenient abstraction for modeling a wide array of application scenarios, some of which may even occur to you as we go through the problem statement together.\nFor a more comprehensive view of the many scenarios that can be thought of as instances of this stable marriage problem, I will point you to some of the links in the description. Let us now get back to the problem statement and consider what else we are given. We have these two groups of people: N men and N women, and it turns out that this is a rather judgmental group of people.\nEvery individual here has feelings for the people in the opposite group, and the way these feelings are modeled or given to us is by way of rankings. In particular, every man will have a ranking over the set of all women. You can think of a ranking as simply a permutation of the opposite set. In this case, the set of all women. Similarly, all the women also have rankings over the set of men. These rankings are really individual preferences and there need not be any relationship between the rankings of two different people.\nYou can think of the input as just being N permutations of the set of women corresponding to the N men and N permutations of the set of men corresponding to the N women. Often we will think of these permutations literally as ranked preferences and we will talk about the top preference or the second favorite and things like that. In this example, for instance, the ‘king of spades’ seems to like the ‘queen of diamonds’ the most and that is his top preference. The second-best preference is going to be the ‘queen of spades’ and so on and so forth.\nWe will use that kind of positional terminology to refer to people on a certain rank list. Hopefully, the input is clear. As I said, it is going to be 2N people and correspondingly N permutations of the men and N permutations of the women. What is the output?\n(Refer Slide Time: 04:44)\n \nWhat we want to output is essentially a bijection between the men and the women, which is to say that we want to match every man with exactly one woman. There are many different ways to match men with women. In fact, if you think about it, you will realize that there are N factorial possible matchings. Every matching can be thought of as a permutation of one of these sets and there is going to be N factorial of them.\nWe are not interested in just any arbitrary matching. Since we are given these preferences, we want a matching, which in some sense makes everyone happy. We do have to be careful about what we mean by a matching that makes everyone happy though. A natural definition may be to say, well, why do not we just match everyone with their favorite person from the other side. An immediate issue with this is that it is possible that multiple men, for example, have the same choice of favorite woman or multiple women have the same choice of their favorite man.\nIn this case, coming up with a well-defined matching that gives everybody their favorite person from the other side is going to be impossible. You could say that in these cases, we just say that there is no matching possible. But it turns out that we are going to have a more interesting definition for what we want from our matching.\nTo be able to understand what we mean by a so-called stable matching, which you might have guessed is what we are going to be looking for from the name of the problem, we first have to define an intermediate notion called a ‘blocking pair.’ The notion of a blocking pair only makes sense in the context of a matching. As with most things, let us try to learn about this definition through a concrete example.\n(Refer Slide Time: 06:28)\n \nHere, I have a fragment of a larger matching. I just wanted to focus on these four people here. That is why I am only showing you a part of the matching. We have a situation where the ‘king of spades’ has been matched to the ‘queen of spades,’ and the ‘king of hearts’ has been matched to the ‘queen of hearts.’\nSsuppose that in terms of preferences, we had the following situation. Let us say that the king of spades happens to prefer the queen of hearts over the queen of spades. He likes the queen of hearts more according to his ranking. On the other hand, if you consider the queen of spades, she also likes the king of spades more than the king of hearts.\nShe also prefers the king of spades over the king of hearts in her ranking over the men. With a little imagination, you can probably already guess what happens next. Because the king of spades and the queen of hearts prefer each other over their currently matched partners, they might find it an interesting option to just break off their current alliances and elope with each other.\nThis is why they are called a blocking pair because they put the current matching in some kind of jeopardy because of this mutual incentive to run away with each other. Remember that it is very important for this admiration to be mutual.\nIf only one of these people prefers a different person over their matched partner but said person does not return this admiration, then you do not have a blocking pair. It is not going to be a problem.\nBut as of now, these folks are left stranded and this is not a good situation. By now you have probably developed this intuition that blocking pairs are troublemakers for matchings and that is why you might find this definition of stable matching very natural now.\n(Refer Slide Time: 08:22)\n \nA matching is set to be stable if it simply does not have any blocking pairs and our task with this problem is to find a stable matching if one exists. Now I am saying ‘if one exists’ just to sound fancy.\nIf you actually look at the CodeChef problem statement, the last sentence of this paragraph guarantees that this problem always has a solution, which you might find surprising at first. When we come up with the algorithm, you will see that the algorithm itself doubles up as proof for why these stable matchings always exist.\n(Refer Slide Time: 08:55)\n \nLet us try to think about how we will go about this goal of finding a ‘stable-matching.’ What is the natural greedy choice here?\nA first cut observation to make is that if somebody is matched with their top choice, then they are never going to be involved in a blocking pair. Because they are absolutely happy with what they have and they are not going to really be interested in forming a blocking pair with any other person. A natural greedy choice may be to match as many people with their top choices as is possible. Let us try to pursue this strategy with an example.\n(Refer Slide Time: 09:34)\n \nHere we have again, the four men and four women in our running example, and let me bring up the top choices for the men. You can see that both the king of spades and the king of hearts like the queen of hearts as their favorite option, and both the king of spades and the king of diamonds like the queen of diamonds as their favorite.\nIn the spirit of doing the greedy thing, let us try to see what happens if we try to match all of these gentlemen with their favorite options. As you can see, this is not going to be straightforward because there is clearly some competition. For instance, both the king of hearts as well as the king of spades will reach out and try to get matched with the queen of hearts, while both the king of diamonds and the king of clubs will try to reach out and get matched to the queen of diamonds.\nNotice that both the queen of hearts and the queen of diamonds have a bit of a choice to make here, while the queen of spades and the queen of clubs are left stranded, at least for the moment. From the perspective of the queens that do have a choice, what choice do you think they should make? They can only pick one option because remember that the thing we want to finally output is a proper bijection. It is a matching.\nThese queens have to pick one choice. It may not be a permanent choice. It may be something that they could revisit later for reasons that we will see in a bit. But for now, they have to at least make a temporary choice disregarding one of the offers that they seem to be getting. The natural choice here would be, again in the spirit of ‘greedy,’ to pick the better option.\nNotice that it is possible that these options are not very good for the queens in absolute terms. For instance, it is conceivable that these two options that they have are their bottom-most choices. But still, because there is a choice to be made, you just pick the relatively better one. In this example, let us say that the queen of hearts prefers the king of hearts over the king of spades and the queen of diamonds prefers the king of diamonds over the king of clubs.\nThey go ahead and make those choices, and you are left with this sort of tentative arrangement at this stage. What we have achieved so far is that these two kings have been matched to their favorite options and at least as long as this matching persists, these kings will never participate in blocking pairs. Of course, it is possible that we may have to modify this matching as we go along.\nFor example, especially if these queens receive better options in the future. Remember, we said that we are only looking at the top options from the perspective of the kings. These options that the queens have received may be some of their worst. It is conceivable that the queens receive better offers later on, and they may have to give up on their current alliances to forge new ones.\nNotice that if that happens, the kings will still not participate in a blocking pair because the only people that they would care about forming a blocking pair with were taken away from them because they found better matches for themselves. Any of this admiration that the kings may have will not be reciprocated. This, of course, is getting a little ahead of ourselves.\nIf some of this does not make sense, do not worry about it. We will have more explicit examples and we will go over the overall algorithm once again. Do not worry if some of this sounded a little bit vague. Let us continue with our story here.\nThese kings have already been matched. The other two kings, who did not have any luck in the first round, are now going to move on to the second favorite options on their list. This time, the king of spades has the queen of spades as his second favorite option, and similarly, the king of clubs has the queen of clubs as his second favorite option.\nThese proposals are made to the respective queens and from the perspective of queens — well, it does not even matter where these gentlemen rank on their lists because we are intuitively in a situation where being matched is better than not being matched. Remember, we want to output a matching eventually.\nThe queens are simply going to accept this offer because it is better than nothing. They do not have to make any further comparisons because they do not have a choice, at least at this stage, and therefore these offers are accepted. Notice that all the men have been matched, and we have, in fact, a matching.\nYou can think about why would this matching, in fact, be a stable matching in this case because it was a simple example. We already know that the king of hearts and the king of diamonds have been matched to their top options so they do not participate in any blocking pairs.\nThe king of clubs and the king of spades could have potentially participated in blocking pairs with, say, the queen of hearts or the queen of diamonds. These are queens that they prefer more than their currently matched partners.\nBut notice that these two queens, just by construction, are currently matched to people that they like better than the king of spades and the king of clubs. So, they are not going to reciprocate the love and therefore these blocking pairs will remain incomplete.\nYou can hopefully convince yourself that the matching that we obtained for this particular example is a stable one. Let us go through another example, which is just a little more non-trivial, to really get a feel for what is happening.\n(Refer Slide Time: 15:12)\n \nWe are back to the original situation with four kings and four queens and this time, let us say that the top options look like this. As you can probably tell, we are once again in a situation where the top options are concentrated on two of the queens. In particular, both the king of spades and the king of clubs have the queen of diamonds as their top choice and both the king of hearts and the king of diamonds have the queen of hearts as their top option.\nLet us ask the queens what they make of the proposals that they have received. For the queen of hearts, let us say that the king of hearts happens to be her top choice. If this is the case, then the queen of hearts is going to reject the application from the king of diamonds and the alliance between the king of hearts and the queen of hearts is going to be forged at this stage.\nNotice that this is a really good match because these are two people who have been matched to their mutually top options. This is a match that will never be revisited. In some sense, we will never need to change this because it really does not get any better than this, to put it intuitively.\nLet us turn our attention to the queen of diamonds who has to make a choice between the king of clubs and the king of spades. Let us say that she likes the king of diamonds the best. But she does not have a proposal from him. So, let us ignore that for now.\nBetween the king of spades and the king of clubs, she likes the king of spades better. So, she is going to reject the proposal from the king of clubs and instead settle with the king of spades. This is the tentative arrangement that we have at this stage and we are still left with two kings that do not have a match yet. Let us turn to them and ask them about their next best options.\n(Refer Slide Time: 16:56)\n\nThe king of clubs has the queen of spades as his next best option and the king of diamonds is the queen of diamonds as his next best option. Let us say that these kings go ahead and make these proposals. Notice that now we have an interesting situation. The queen of diamonds already is engaged, in some sense, to the king of spades from the previous round.\nBut now she has a more interesting proposal to consider. If you remember her preferences, she prefers the king of diamonds over the king of spades who is her current partner. Given that this new proposal looks tempting, should the queen of diamonds deflect and basically go with this new proposal breaking her old arrangement? Or should she just be loyal to her current partner and ditch the king of diamonds even though she likes him more?\nJust think about what would be the appropriate thing to do given that we eventually want a stable matching, which is one without any blocking pairs. Hopefully, you had a chance to think about this because it is a really interesting question at this point. There is a tension between doing the seemingly right thing in terms of being loyal to somebody you have been matched with before and doing the thing that seems like the correct greedy choice in terms of optimality to the point where it almost sounds selfish.\nWhat should the queen of diamonds do? Let us consider what happens if she decides to stay true to her current partner who is the king of spades. If she does that, then at the very end, she is matched with the king of spades and on the other hand, the king of diamonds is matched to somebody that he certainly likes less than the queen of diamonds.\nEverybody that he liked more than the queen of diamonds, he has already been rejected by from previous rounds. In the current round, the queen of diamonds decided to reject his proposal as well. In the final matching, the king of diamonds is going to be matched with somebody that he likes less than the queen of diamonds. Notice that the queen of diamonds and the king of diamonds will end up forming a blocking pair because they mutually prefer each other over their ultimate matched partners.\nSince this is precisely the situation that we want to avoid at the end, it would actually make a lot of sense for the queen of diamonds to actually break off her current relationship with the king of spades and accept this new alliance with the king of diamonds. It may seem like a painful thing to do, at the moment, but it will be for the best in the long run.\nNotice that no actual rejections are happening. No actual breakages of engagements are happening. This is all background work that is being done by the algorithm and it is only the final matching at the end that will matter even in the context of a more real-world application.\nDo not worry about any actual heartbreak. This is really all in the analysis. Now, it is much easier to think about the queen of spades who has only one proposal in this round. So, there are no choices to be made, and she just goes ahead and accepts the alliance with the king of clubs.\nNow we still have one unmatched king, that is the king of spades who was matched before, but has now gone back to being single. Let us now consider the next best option for the king of spades.\n(Refer Slide Time: 20:24)\n \nLet us say that this happens to be the queen of spades. The king of spades will go ahead and make that proposal. Now, the queen of spades is in a situation similar to the one that the queen of diamonds was in previously. She has to consider making a choice between accepting this new proposal and breaking off the old one versus rejecting the new proposal and keeping the old one.\nWhat the queen does depends on how she compares her current partner with the potential new partner. Let us bring back her preference lists and observe that she actually prefers the king of spades over the king of clubs, and because of this she would want to actually accept this new proposal and break off her current alliance with the king of spades, much like the queen of diamonds of did before.\nNotice that this may not always happen. If the preference was listed the other way, then the queen of spades would have maintained her current alliance and the king of spades would have to go back and try his luck with the next person on his list. But in this example, that is not how it plays out.\nThis is the current matching that we have at this stage. Now the king of clubs goes back to being single and makes a proposal to the queen of clubs, who is the next person on his list. This proposal gets accepted because the queen of clubs is single at the moment and because something is better than nothing. This is an immediate acceptance and we finally have a ‘matching.’\nYou can try to convince yourself that this matching is stable. That should be intuitive given that we had that at the back of our minds all along. Nonetheless, it is useful to actually prove this formally and instead of working in the context of this example, let us actually turn to the algorithm in full generality and try to argue the correctness also in slightly more general terms.\n(Refer Slide Time: 22:25)\n\nJust to recap what the algorithm is doing. We start off with the list of men and women and initially, nobody is matched to anybody, to begin with. This piece of pseudocode is borrowed from the book ‘Algorithm Design’ by Kleinberg and Tardos and you can find a pointer to the book website in the description of this video.\nWhat we are going to do is basically run a ‘while’ loop for as long as there is a free man. A man who is still single and has not been matched to anybody. As long as there is such a man, what we are going to do is basically look at the highest-ranked woman for this man to whom he has not yet proposed or in other words, the highest-ranked woman who has not yet rejected him.\nWe have this man approach this woman, and what plays out from here will depend on the situation of the woman. If the woman is unmatched herself, if she is single because we have been saying that it is better to be matched than to not be matched, this proposal will have immediate acceptance. So, this match is made and we are done.\nOn the other hand, if ‘w’ is currently engaged, then she would have a choice to make between her current matched partner and this new proposal. We have seen this play out a couple of times in the last example that we discussed, so you should probably be able to predict what the algorithm does here.\nLet us say that the currently matched partner is m’ and the new proposal is coming from “m.” Suppose ‘w’ prefers m’ over “m,” which is to say that she likes her current situation better than the new proposal, then she is just going to reject this new proposal, and “m” remains single and will have to go back and revisit his preferences and propose to the next woman on his list, which will happen naturally as you go back to the start of this ‘while’ loop.\nOn the other hand, if ‘w’ finds this new proposal more exciting than her current alliance, then she is going to break off her current alliance, and m’ now becomes a free man (gets added to the pool of single men) and the engagement between ‘m’ and ‘w’ is established – ‘m’ being the new person who is proposing to ‘w.’\nThat is pretty much it. That is how this progresses and once you stop, that happens when all men have been matched, and at that point, you have a set of engagements that you can finalize and claim to be a stable matching. There are a few useful observations to make about this algorithm.\nFirst of all, let us argue termination. Because there is a ‘while’ loop involved and there are engagements being broken and men going back to being single, you might even suspect if there is a possibility that this algorithm keeps going around in circles and possibly never stops on some cleverly designed input.\nIf this thought is in fact bothering you, then I would encourage you to pause here and take a closer look at the pseudocode and see if you can find an argument for termination. One hint would be to think about the number of proposals that are being made and observe that the running time of this algorithm is really proportional to the number of proposals being made and see if you can bound that in some way. Come back when you are ready. Hopefully, you have had a chance to think about this. As we were just saying, the most basic question here would be one of termination.\n(Refer Slide Time: 25:56)\n \nNotice that the number of proposals that are made over any run of this algorithm is at most n2 because a man never proposes to the same woman twice. He is always walking down his preference list and there are ‘n’ men and every man has ‘n’ women to propose to. The number of proposals may never exceed n2 and this essentially drives the conclusion for termination.\nWe also want to say that the algorithm terminates with a complete matching. Nobody is left free at the very end. One of the reasons for this is that if somebody is single, then there is still some work to be done. There is still somebody that he can propose to. Notice that at every intermediate stage of the algorithm, the set of engagements form a valid partial matching, which is to say that you never have a situation where one man is matched with multiple women or multiple men are matched to the same woman.\nWhat you have is a valid partial matching. It is enough to argue that at the very end, you do not have any single men. But as long as you have a single man, he still has some woman left on his list that he can propose to, so the algorithm has not yet terminated. Notice that the reason for this is that if he really proposed to every woman on his list, and he is still single that means that he was rejected one way or the other by every woman that he proposed to, either outright or by getting into an engagement and then being kicked out of it.\nThis only happens when the women are already engaged to somebody. But you cannot have ‘n’ women being engaged to ‘n-1’ men if what you are maintaining is a valid partial matching at every stage. Therefore, it is not possible for a man to be single, once the algorithm has terminated. But since every man is matched, and you have a valid partial matching at every stage, at the final stage you indeed have a complete matching.\n(Refer Slide Time: 27:53)\n \nThe last thing we want to claim is that this complete matching is, in fact, stable. The intuition for stability was probably already established when we were making some of these greedy choices with respect to the proposals and the rejections. Let us once again recap the reason why the output matching is, in fact, stable. One way to argue this is by contradiction. Let us say that the output matching was not stable.\nThe algorithm output something with a blocking pair and let us say that the blocking pair looks like this. The output matching matches the king of spades to the queen of spades and the king of hearts to the queen of hearts. But the queen of hearts prefers the king of spades over the king of hearts and this love is reciprocated in that the king of spades also prefers the queen of hearts over the queen of spades.\nIf the situation were to really arise, can you think of a contradiction in terms of the behavior of the algorithm? In particular, think about the proposals that the king of spades would have made during the run of the algorithm and think about how the queen of hearts should have reacted at a certain point.\nPlease feel free to pause the video here and really think through the proof yourself before continuing. Consider the king of spades and the proposals that he makes. Before he proposed to the queen of spades which he must have done to be finally engaged with her, he must have first proposed the queen of hearts. Because the assumption here is that the king of spades prefers the queen of hearts over the queen of spades. So, she would have come first in his list and would have been approached before the king of spades approached the queen of spades.\nThe real question now is: What did the queen of hearts do when she was proposed by the king of spades? Given that they are not matched in the output, it must have been the case that the queen of hearts rejected this proposal in one way or the other. Either it was rejected immediately or it was accepted and rejected in a future iteration in favor of a better proposal. But notice that if the queen of hearts did indeed reject the king of spades, either immediately or later on, it must have been because she was in a better situation than the king of spades.\nIt could not be possibly the case that she likes her current matched partner less than the king of spades as stipulated by this blocking pair scenario. Hopefully, it is at least intuitively clear why we are not going to have blocking pairs because really the greedy choices were geared towards avoiding them in the first place.\nPlease feel free to take your time to work through this yourself and hopefully convince yourself that everything does work out in terms of both termination and obtaining a complete matching and also ensuring that this matching was a stable one. This brings us to the end of the description of the algorithm. You probably have enough, especially if you go back to the place where we discussed the pseudocode, you probably have enough to actually code this algorithm yourself now.\nPlease feel free to take a break and do that and come back to the rest of the content once you have given it a shot yourself. For this particular module, we are going to split up the implementation into a separate video and I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec05.html",
    "href": "materials/cpnotes/Lec05.html",
    "title": "Searching and Sorting - Module 1 (Trouble Sort)",
    "section": "",
    "text": "Lecture - 05\nSearching and Sorting - Module 1 (Trouble Sort)\n(Refer Slide Time: 00:11)\n\nHello, and welcome to the second week of Getting Started with Competitive Programming on NPTEL. I hope you have been having a great time in the course so far. So, this week, we will be focusing on searching and sorting-based problems. These are really fundamental techniques. It turns out that they are extremely useful in competitive programming as well.\nThey show up in all kinds of complex problems, either as pre-processing routines or as useful things to do here and there or as the thing that helps you get to the final answer at the very end. So, it is a good idea to develop some degree of competence in using these techniques. For the most part in this week, we will be focusing on identifying the fact that these techniques come into play.\nIn particular, we will not really be worrying about implementing classic, sorting algorithms, like say, insertion sort, or merge sort, or quick sort, or whatever. If that is something that you feel like doing just to brush up a little bit, then there is a great sequence of exercises on HackerRank. You can go and try that out. If you just want to brush up on the concepts, then there are some really nice articles on Khan Academy. I would recommend those as well.\nYou can find the links either in the description of this lecture video or you can find them on the prerequisites page for week two on the course homepage. Please go ahead and take a look in case your background in sorting algorithms and binary search is a little bit rusty because that will be helpful as you come back here. Another thing that is worth doing in preparation is to look up the documentation for the built-in sorting functions in your language of choice.\nMake sure what parameters they take in, and whether they have any extra superpowers. Also, just double-check that you know how to do simple related tasks like, let us say, sorting an array in reverse order, sorting a subarray, and things like that. With all that said, we can now begin our discussion of the first problem for this week, which is Trouble Sort. It is, once again, a Google Code Jam qualification problem from back in 2018. It might remind you of Reversort because there are some reversals happening. But of course, it is quite a different problem. So, let us get started.\n(Refer Slide Time: 02:34)\n\n\n\nLet us begin as usual by going over the problem statement. We are introduced to trouble sort with some background on bubble sort, to begin with. Remember that in bubble sort, what happens is that we do repeated passes over the array. In each pass, whenever we encounter a consecutive pair of integers, which are out of their natural order, then we swap them to fix it.\nAuthors claim to have come up with a better or an enhanced version of bubble sort, where instead of considering a pair of numbers at a time, they are going to consider triplets of numbers at a time. If a triplet is out of order, by which they mean that the last number in the triplet is smaller than the first number in the triplet, then they are going to reverse this entire triplet. As opposed to swapping adjacent numbers, this entire triplet gets reversed.\nNotice that when you reverse three consecutive numbers, the middle number actually stays in place. It does not shift in any way. That is essentially trouble sort. The claimed reason behind its name is that it is short for a triplet version of bubble sort. So, there is always a cheeky remark in the Code Jam problem statements. This is the one for this example here.\n(Refer Slide Time: 04:04)\n\nLet us take a look at the pseudo-code for trouble sort just to make sure that we are on the same page about what it does. There is going to be a flag variable done, which keeps track of whether we have managed to sort the whole array or not. If done is true, then that means that we can stop doing any further passes on the array.\nWe initialize done to true and then we start our pass. Because we are looking at triplets, we do not have to go all the way up to the (n-1)th element, we only go up to the (n-2)th element because otherwise, you will just fall off the cliff, so to speak. By n I just mean the length of the array.\nSo, I am using n to denote Len of L. What happens in the ith iteration is that you compare the elements in L[i] and L[i+2]. These are the extreme points of the triplet that starts at the ith location. If it turns out that these elements are out of order, so the element that appears earlier is larger than the element that appears later, then we reset the done flag to false. We say: Okay, we did encounter a problem, this array was not sorted in its present form.\nTo fix this particular aberration, we will reverse the sub-list from L[i] to L[i+2]. Once again, notice that this amounts to swapping the elements at L[i] and L[i+2] because the middle element, which is at L[i+1] stays in place during this so-called reversal. That is pretty much the entire algorithm. You keep fixing triplets for as long as you need to.\nWhen you finally are able to make one full pass, without having encountered any broken triplets, then you stop. To understand what is going on, it is useful to walk through an example. Let us just go over the workout example that is given in the problem statement. We have an array here with 5 elements 5, 6, 6, 4, 3, in that order. The numbers written just below these elements are the corresponding array indices for our reference. Let us go over a run of trouble sort on this array.\n(Refer Slide Time: 06:32)\n\n\n\n\nTo begin with, the variable done is initialized to false, and i is not initialized yet. But we will get to that in a minute. We, of course, enter the while loop and reset done to true. Then we initialize ‘i’ to 0. Notice that in the first iteration of the for loop, we are comparing the elements at L[0] and L[2].\nThose elements happen to be 5 and 6. Notice that the conditional does not really trigger because 5 is not greater than 6. So, we move on. We go back to the for loop, we increment ’i’ to 1. Now we are comparing the elements L[1] and L[3]. However, this time, the conditional will trigger because 6 is greater than 4. So, we enter this if block, and we reset done to false.\nThis is a note to say that this pass did have a problem. We want to flag that for ourselves. In the next step, we will try to fix this aberration by swapping these two elements. The language here is that you reverse the sub-list. But as we have mentioned earlier, that is the same as swapping the endpoints. So, this is now done. We can go back to the next iteration of for loop. At this point, ’i’ gets incremented to 2 and we are comparing the elements at L[2] and L[4].\nOnce again, notice that 6 is greater than 3. The conditional will trigger. Done is already false. So, we do not have to do anything there. But we do have to execute the swap. At this point, the array looks like 5, 4, 3, 6, 6. Now, if we go back to the start of for loop, ‘i’ is incremented to 3. But notice that there is no triplet that starts from L[3]. In particular, we have just run out of room.\nSo, this iteration is done. We now go back to the while loop. Are we done? Well, the value of ‘done’ is false. Remember, we had a warning that this pass had some issues, not all the triplets were properly placed. So, we need to do another round of checking. In fact, if you look at the array right now, it is not yet quite sorted. It is a good sign that we are giving this another sort.\n(Refer Slide Time: 09:03)\n\n\n\n\nOnce again, we will begin by resetting the done variable to true and then initialize the ‘for’ loop. So ‘i’ get reset once again to 0. This time, notice that when we compare the elements at L[0] and L[2], this is no longer a valid triplet. Since 5 is greater than 3, we do need to execute a swap before which we should also remember to reset the done variable as before. So, ‘done’ is now false. We have the swap between 5 and 3.\nWe go back to the start of the for loop, and we increment ‘i’ to 1. At this point, we are comparing the elements L[1] and L[3]. Notice that this pair of elements is already in the right order. So, we do not have to do anything. The conditional does not trigger and we go back to incrementing ‘i’ to 2. When i=2, we are comparing the elements by 5 and 6. Once again, these guys are doing fine.\nWe do not need to do anything here. We go back to the ‘for’ loop. But once ‘i’ is incremented to 3, we have essentially run out. So, we go back to the start of the while loop now. Once again, notice that we are not done yet. We will have to do this one more time. We reset done to true. But this time around, notice that every time we compare these triplets, everything is going to work out. You can see this by just observing that the whole array is sorted.\nIn particular, you will never encounter a triplet, which has its elements being in the wrong order. Everything works out here and we are, in fact, this time done. The algorithm stops with the array state being 3, 4, 5, 6, 6, which looks pretty good. Everything is sorted. You might be tempted to think that trouble sort is a real sorting algorithm after going through this example. But it turns out that that would be quite misleading.\n(Refer Slide Time: 11:12)\n\n\nWhy don’t you take a moment here to try ‘trouble sort’ yourself on this small example? Think about what trouble sort would do. See if you can come up with your own examples where trouble sort has suspicious behavior. Hopefully, you had a chance to take a look at this. And if you did, you would have realized that trouble sort is not going to successfully sort this array.\nThe only elements that it has a chance to compare are the elements that are at indices 0 and 2. Those, of course, seem to be perfectly in order. But you can see that the overall array is certainly not sorted. So, trouble sort does fail at this point. In fact, that turns out to be the problem statement.\n(Refer Slide Time: 11:56)\n\n\n\nIt is our task to figure out if a given array gets sorted by trouble sort or not. Further, if trouble sort fails, we also have to identify the first point of failure, which is defined as the smallest index with the property that the value at that index is larger than the value that immediately follows it in the array after trouble sort has finished processing the array. Of course, you might be thinking that trouble sort looks like a reasonably straightforward algorithm.\nWhy not just simulate trouble sort on the input array, and check if the resulting array is sorted or not? That is a perfectly valid approach. But to figure out if that is going to be feasible, we will have to think about the complexity of running trouble sort on a given array. Then we have to take a look at the problem limits. Let us address the first question first. Once again, take a pause here, go back in the lecture if you need to, to look at what trouble sort is doing more closely. Think about what would be a valid upper bound for the complexity of trouble sort, when it is run on an array with ‘n’ elements. Come back when you are ready. Hopefully, you have had a chance to think about this.\n(Refer Slide Time: 13:16)\n\n\nLet us take a look at the trouble sort pseudo-code again. You will see that there is this for loop that clearly runs for ‘n’ iterations, again being the length of the array that we are working with. The real question: How many times do you run this for loop? That is going to be as many times as you need to run the outer while loop. You can probably come up with examples of arrays where the outer while loop actually runs for ‘n’ many iterations.\nSince that can happen, we know that there are certainly instances where the running time can be as bad as ‘n-squared.’ It turns out that the running time can, in fact, also be bounded by ‘n-squared,’ it is never worse. You can show that the outer while loop will never execute more than n times. The reason for this will become clearer as we go along.\nBut hopefully, you had some intuition for why the answer to this question was order n-squared. The question: Is this going to be a reasonable strategy for us? For this, we need to look at the limits of the problem.\n(Refer Slide Time: 14:30)\n\n\n\n\nIt turns out that our arrays can have as many as 109 elements. So, the order n-squared algorithm is not really going to work out. We need a slightly different approach. Let us go back to the drawing board and look more deeply into what trouble sort is doing. Here we have an array with six elements, and I have pulled out the most crucial part of the trouble sort pseudo-code, which emphasizes what is happening during the passes.\nLet us take a look at what happens when we do a one-pass over this array. In the first iteration, the first and the third elements get compared. In the second iteration, the second and the fourth elements get compared. In the third iteration, the third and the fifth elements get compared. In the fourth iteration, which is the final iteration, the fourth and the sixth elements get compared.\nNotice that the green elements get compared to the green elements, and the pink elements get compared to the pink elements in every single iteration. In particular, a green element never gets compared with a pink element, just by design. In some sense, because you are skipping over the middle element of the triplet, whenever you are considering a triplet, you never have a chance to compare an element, which is sitting at an odd index with an element that is sitting at an even index. It means that there are going to be a lot of lost opportunities.\nIf you remember the array 1, 3, 2, this is exactly what was happening. Trouble sort can be thought of as two independent runs of an algorithm that you are already familiar with. Take a moment to pause here and think about if you can fill in the blank in this sentence: So, trouble sort is just two parallel runs of which algorithm? Do not take the word “parallel” too seriously.\nWhat I mean is that it is essentially running a familiar algorithm on some sub-array and it is running the same algorithm on another sub-array. Can you think of ‘trouble sort’ this way? If you have had a chance to think about this, you might have come to the conclusion that trouble sort is essentially just a bubble sort being run separately on the sub-array that consists of the odd indices, and separately on the sub-array that consists of the even indices.\n(Refer Slide Time: 17:00)\n  \nYou can think of trouble sort as sorting the even indices separately from the odd ones, and then putting them back together. This is a really useful perspective on trouble sort because it allows us to implement trouble sort without really implementing it. In particular, what we want to do is take an array and figure out what is the array that trouble sort would output if it was working with this given array as input.\nWe want to get to this information without actually literally implementing trouble sort. Now knowing what trouble sort what is effectively doing, we can do this in our own way. I think by now you have enough hints to piece together the final algorithm. If you want to take a pause here, this would be a good time to try and figure out the rest of the details yourself, and then come back to exchange notes once you have given it a shot. So here is what you could do with the information that you have at hand.\n(Refer Slide Time: 18:09)\n\nTo begin with, you could split the given array into odd and even sub-arrays. Collect all the numbers that are sitting at odd indices, and declare that to be your first array. Then separately, collect all the numbers that are sitting at even indices, and this becomes your second sub-array. Now, you could sort these two sub-arrays independently.\nHere crucially, remember to use an efficient sorting algorithm. Do not use something like bubble sort to stay true to the spirit of trouble sort or something like that. That would just bring you back to square one, in terms of an inefficient implementation that will definitely timeout. At this point, use a built-in sorting function, or even if you are using a sorting function that you have written. Make sure that it is based on an order ‘n log n’ kind of algorithm.\nSort these two sub-arrays independently, and then splice them back together. Put them back to one big array, with the odd elements being in the odd positions and the even elements being in the even positions. If this array is sorted, then that is what you have to output (if trouble sort works). Otherwise, you can do one-pass over the array to figure out the first inversion that you encounter.\nWhat you want is the first pair of adjacent elements that are out of their natural order, and that is fairly straightforward to do. At this point, I think, we have come to the end of discussing how we implement the solution. So we can now move on to the implementation. But let me just make a quick point before that, which is about the running time of trouble sort.\nRemember, I said that the running time can be as bad as n-squared. But how do you show that it is never worse than n-squared? Now that trouble sort is essentially performing two independent runs of bubble sort, you can use what you know about the analysis of bubble sort to argue an upper bound on the running time of trouble sort. In particular, you can observe the behavior of the even and the odd sub-arrays independently, and conclude that the outer while loop will never run for more than ‘n’ iterations.\nOf course, the inner ‘for’ loop by design will run for exactly n-2 iterations every time. The overall complexity is going to be ‘order n-squared.’ That is a claim that we had made earlier. I just wanted to make sure that we have some sense of why it is true.\n(Refer Slide Time: 20:50)\n\n\nLet us take a look at the implementation. I am just going to share the code snippets from the sample solution. You can find the sample solution from the official GitHub repository for these lectures. There is a link in the description of this video, as well as the course website. So, there is nothing special about the input formatting. It is pretty standard stuff. There are ‘T’ test cases. Every test case is a number followed by the elements of the array given as space-separated integers, so you just read them all in.\nThe first thing we want to do is split the input array into these odd and even sub-arrays. We just declare two integer arrays, and we run a loop that goes over the original array. Depending on whether the current index is odd or even, you pull out that element and push it to the correct sub-array.\n(Refer Slide Time: 22:02)\n\nThe next thing we want to do is to sort these sub-arrays that we have generated. This is the part where we need to be careful about using an efficient sorting algorithm. Here, I am just using the built-in sort function in C++. As I said, your language of choice should have an appropriate sorting method that you can use.\nYou could write your own sorting function as well. Just make sure that it is not bubble sort and that you are using or implementing an efficient sorting algorithm here. This is crucial to ensuring that you do not get a timeout. After this, you still need to put these arrays back. That is what is happening in the second half of this code.\nWe declare a new array called ‘sorted,’ which we are going to build out. This array that is named sorted may not be sorted. That is what we have to figure out. Maybe I should have used a variable name like ‘trouble sort output’ or something like that. But anyway, we will live with this. So, what is going on with ‘sorted?’ How are we building it?\nEssentially, it is the opposite of what we were doing previously. We were splitting the array and putting things back trying to ensure that the sorted version of the odd sub-array falls in place in the odd indices. The sorted version of the even array gets into the even indices of this array that we are calling ‘vsorted.’ Once again, you just run a loop. You do different things based on the parity of the current index.\nIf you are at an even index, then you pull an element from the even sub-array. If you are at an odd index, then you pull an element from the odd sub-array that you have sorted. The way I am doing this is that I am always pulling what is at the head of the array and I am able to do that. That is working because notice that I am erasing that element from the array that I am working with.\nThis is just one convenient way of doing it. But there are many other ways. You could instead also have an additional index, for instance, that advances through these arrays instead of deleting them as you go along. Whatever way you decide to do it should be perfectly fine.\n(Refer Slide Time: 24:22)\n\n\nNow that we have put everything back together, all we need to do is check if this array that we are calling sorted is actually sorted or not. Remember that if it is not sorted, we have to report the first inversion that we find, the first pair of adjacent elements that are out of order. This is fairly intuitive. You just go through the array step by step.\nEvery time you are at the ith location in the array, just compare the ith element with the (i+1)th element. If you have a problem, which is to say that the ith element is larger than the (i+1)th element, then you can trigger a flag to say that this is not sorted. The flag can also double up to remember the location so that you can just output the value of the flag as the answer.\nRemember, I am initializing the flag to -1, just so that there is no confusion. Because the first problem could even happen at the 0th index. For instance, in 1, 3, 2, the answer would have been 0. So, initialize your flag to -1. When you come out of this loop, just check if the flag is -1. If it is that means that the flag was never triggered - you never had a problem as you went along. The array is, in fact, sorted.\nBut if the flag is a value that is different from -1, then the value flag is actually the answer that you are looking for. It is the smallest index at which you encounter an adjacent inversion. You output the value of the flag in this case. The other details are pretty routine in terms of the formatting of the output and so forth.\nIn Code Jam, it is pretty standard that they also want the case number and the literal word case spelled out and so forth. Make sure that you get those details right. Then I think you should do well, in terms of getting your code to pass. Please do try this out and let us know how it went over at the Discord community or on the mailing list. We will, as always, look forward to hearing from you. In the next lecture, we will talk about a different problem and I look forward to seeing you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec04.html",
    "href": "materials/cpnotes/Lec04.html",
    "title": "Ad hoc and Implementation - Module 4 (Will It Stop?)",
    "section": "",
    "text": "Lecture - 04\nAd hoc and Implementation - Module 4 (Will It Stop?)\nWelcome to the final module of the first week on AdHoc and Implementation-based problems. I do hope that you have had a good time solving the problems that we have showcased so far in this week. And, as usual, this is a friendly reminder that if you are stuck anywhere at all, then please do join us in the Discord community that has been set up exclusively for this course. Now, in this module, we will be talking about a fun problem called, Will It Stop?\n(Refer Slide Time: 00:43)\n\nThis problem features in a really nice compendium of contest problems called looking for a challenge, Volume 2. And at the time of this recording, this book is freely available from the book’s website. So, you can find the link in the description below, as well as on the course homepage. I should, perhaps, mention that this book consists of model solutions to problems that featured in the Polish College at programming contests, the ones that took place between 2011 and 2014.\nAnd while this is an excellent collection of problems, if you are just starting out on your competitive programming journey, you might find that they are a little more advanced than what you are prepared for right now. Do not worry about it, and definitely come back to them later, when you do have the background to appreciate some of the other problems. The problem that we are featuring in this video is problem C, and it, fortunately, requires no specific background. And it is a really cute problem. So, let us get right to it.\n(Refer Slide Time: 01:43)\nLet us begin by taking a look at the problem statement without the story for now. So, here is the task at hand. We are given the following program.\n\nYou can see that it is a snippet of code that involves a while loop and a number n. And it seems to be doing something different based on whether the number n is even or odd, to begin with. Specifically, if the number n is even then it seems to be getting halved. And if the number is odd, then it is roughly getting tripled. Specifically, it is transforming as 3 * n + 3.\nSo, at a high level, what is happening is that the number is either becoming smaller or bigger based on whether it was even or odd, to begin with. You can probably already imagine that there might be values of n for which this while loop just goes on forever and the program never terminates. It turns out that this is precisely our task.\nWe are given a number n as input. This number can range anywhere between 2 and 1014, which is just to say that this can be a pretty big number. And we have to identify whether this code that you are seeing on your screen right now terminates when n is given to it as input.\nWhat would be the most natural way of trying to solve this problem? Well, it might occur to you that we should just try to simulate this code snippet here on the given value of n and see if it terminates or not. That is fairly natural, but you can probably already see why it is going to be problematic. Of course, if your code actually terminates on n within a small number of steps, then you can confidently conclude that the program indeed terminates.\nHowever, suppose your code runs for, maybe, 1000 steps, 10,000 steps, or even 100,000 steps, and it is still not terminated. Now, can you still confidently conclude that the program will never terminate? Well, these early steps may not be a good indicator of what happens ultimately. It is possible that if you had waited for another 3 steps, the program would have terminated.\nIt is also possible that you needed to wait for another 10 billion steps before the program actually did terminate. So, you can see why this is going to be dicey. Fundamentally, the issue is that just because your program did not terminate in the first so many steps that is not enough evidence to conclude that it is never going to terminate. So, it seems like the real task for us is to identify some pattern on the numbers n for which this code does not terminate, and then use that pattern to answer the question.\nHow do we discover this pattern? Maybe, we can go back to the simulation approach we were discussing. Yes, I know I just said that it is not going to work. But it is not going to hurt for a bit of a trial-and-error approach. Let us replicate this code in Python or whatever programming language you are using right now. And just run it for some small values of n.\nPick a threshold that you like, say 100,000 steps, and let us just identify those values of n for which this program does not terminate even within 100,000 steps. We can flag those values as potentially being those for which the program never terminates. At this point, this is just going to be an educated guess. But it is going to be a good starting point to investigate further. I would really encourage you to try this yourself, and join me to discuss what we observed.\n(Refer Slide Time: 05:19)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEventually,\n\nI ran the program for values of n between 2 and 10. For n = 2, the program terminated in just 1 step. But for 3, it seems like the program is getting into the cycle of values between 3, 6, and 12. It is seemingly going on forever. For 4, the program terminates in just 2 steps. But for 5, again, the program eventually gets into the same cycle that we observed for the number 3.\nNow 6 was interesting because so far, the program seems to be terminating on even numbers and non-terminating on odd numbers. So, we may be tempted to conjecture that that is the pattern. But for 6, the program is again getting into this ‘3, 6, 12’ kind of cycle. For 7, the program again gets into the sort of a loop that shows no sign of stopping.\nBut for the next number, which is 8, the program again terminates in just 3 steps. For 9 and 10, you see that the program again gets into a cycle and shows no signs of stopping. So, at this point, can you identify a pattern to, at least, the 3 numbers that we have seen so far on which the program seems to terminate? If you run this program for even more values of n, then you may have a larger stash of numbers on which to guess a pattern.\nFrom what we have seen so far, it looks like all the numbers on which the program did terminate happened to be powers of 2. So that seems like a very tempting conjecture to make. Perhaps the program only terminates on powers of 2.\n(Refer Slide Time: 07:02)\n\nIt is reasonably easy to see that if you have a power of 2, then the program does terminate. It is because the program is successively shaving off powers of 2 from n, till the number becomes 1. For instance, if to begin with n was the rth power of 2, then after the first iteration, it will become the r-1th power of 2. After the second iteration, it will become the r-2th power of 2 and so on. And after r iterations, the number becomes 2 to the 0, which is 1, at which point the program terminates.\nTo summarize, if n was the rth power of 2, then the program terminates in r iterations. We also saw this with the examples. When n was equal to 2, then we terminated after 1 iteration. When n was 4, we terminated and 2, and when n was 8, we terminated in 3 iterations. So, this case is abundantly clear. Now let us consider the other possibility, which is that n is not a power of 2. When n is not a power of 2, let us split things up into 2 further scenarios.\n(Refer Slide Time: 08:04)\n\nWhat if n is not a power of 2, and is odd? In this case, notice that n is always going to be a multiple of 3. Indeed, in the very first step, n gets transformed into 3*n+3. At this point, it is clearly a multiple of 3. Since in future iterations, we never divide by 3, it should be clear that n is always going to be a multiple of 3. For this reason, it is never going to reach a value of 1, and the program is going to run forever.\nWhat happens if n is not a power of 2 but it is even, to begin with? Then well, let us just consider the prime factorization of n. It is going to have some powers of 2, and then some other factors as well, because we explicitly said that n is not just a power of 2. So, as long as n is divisible by 2, the program is going to enter the first branch of the if statement. It is going to, again, successively shave off the powers of 2. But when it has no factors of 2 left, you are left with a number that, by definition, is odd. You are back to the previous case, where n is not a power of 2, and it is odd. From here on out, it is going to go on forever.\nWhat we have argued after making an educated guess is that, indeed, the program does not stop if and only if n is not a power of 2. So, the program that you have to write at this point is really simple. You just have to check if n is a power of 2 or not. And one way to do that is to just try and successively divide by n and see where you get stuck.\nIf you go all the way to one then n was a power of 2, but if you stop short of something that is different from 1 then n is not a power of 2. If you are used to bit manipulation tricks, then there is a faster way of checking if n is a power of 2 or not. We will mention this when we get to the summary at the end. Before we go further though, let me just show you the original problem statement so that you can take a look at the story there.\nI know that normally we are in a big rush to just somehow get rid of this story and quickly identify the abstractions involved. But in this case, I think the story has a little bit of interesting trivia. So, I want to tell you about it, especially now that we have more or less solved the problem.\n(Refer Slide Time: 10:31)\n\nSo, here is how the problem statement goes. Byteasar was wandering around the library of the University of Warsaw. At one of its facades, he noticed a piece of a program with an inscription: Will it stop? The question seemed interesting, so Byteasar tried to tackle it after returning home. Unfortunately, when he was writing down the piece of code, he made a mistake. The rest of it is what we have discussed so far. But this might make you curious about a couple of things. First of all, is there such an inscription at the facades of the library of the University of Warsaw? It turns out that there is indeed such an inscription. Did Byteasar actually make a mistake while noting it down? It turns out that, yes, the original inscription, on the facade of the library is a slightly different code snippet. It is a really small mistake that Byteasar made while noting down this piece of code.\n(Refer Slide Time: 11:27)\n\nSo instead of a +3 in the else statement, we have a +1. That is the only difference, but it turns out that it massively changes the nature of the problem. The mathematician Lothar Collatz believes that this code stops for any value of n. It turns out that as of now, nobody really knows if this is true. Of course, people have tried this computationally, apart from in other ways.\nIt has been verified that the program does terminate for some fairly large values of n. But we do not know if this is the case for every n or not. This is a fascinating conjecture with a lot of history. If you are interested in this, then do look up the Collatz conjecture. I am sure it will be a very interesting rabbit hole for you to explore. But let us now recap what we have learned.\n(Refer Slide Time: 12:12)\n\n\nFor the version of the code that we saw in the problem statement, we can say yes, if n is a power of 2, and we can say no if n is not. I promised you a bit manipulation trick that would help you identify if n is a power of 2 or not. And here it is. You can test if n is a power of 2 or not by just taking the XOR of n and n-1, and doing an AND with n and check if that is n.\nSo, you can probably see right away that if n is a power of 2, then this equation is satisfied. When you do n XOR n-1, you get essentially all ones. When you add that with n, then only the first, the most significant bit is the only one that survives, and you get back n. However, it is a little more work to check that this equation actually fails for any value of n, which is not a power of 2.\nIt is a fun little exercise so I will not spoil it for you. But for now, if you just want to record it as a trick that you can use, then by all means, please do make a note of it. So, all that remains is to actually code this up. As you can imagine, for this problem, the coding bed is really simple, but let us just go through it.\n(Refer Slide Time: 13:33)\n\n\nSo, here is the page, which has the problem statement. This is a new platform compared to the ones that you have seen so far. If you are here for the first time, on the top right, you will see a link, which says login, as opposed to your username. If you do not have an account yet, then when you click on login, you will get a drop-down menu, which will also give you the opportunity to register.\nIt is a very simple registration form. So, you should have your account set up in a couple of minutes. It is completely automatic. Once you have done all that, please make sure to log in. The only reason I am recommending that you set up an account of your own is because you do need that to be able to actually make a submission. If you are not logged in, you will not be able to submit your code.\nLet us just quickly recap the problem statement. The contents of the problem itself are exactly as we have discussed. Let us take a note of the input. There is only one line of input and that is the integer n. And the output well is yes or no, but notice that it is in Polish. So let us just take a note of the words: It is going to be TAK or NIE. Let us just make sure that that is what we output in our program. Otherwise, the tests are not going to pass.\nLet us head over to the submission pane. Notice that you cannot, right away, select the programming language. But once you start typing in here, the drop-down does get activated. I am just going to pick Python because it is a simple program. It should not really make a difference, what programming language we use here. We take in the number n. Now we just have to test if it is a power of 2 or not. So let us use the bit manipulation trick that we just talked about. We want to do n XOR n-1. So, the bitwise XOR is the ^ symbol in Python, and the bitwise AND is a single & sign. We want to ask ourselves if this is true, and if it is, then we print TAK.\nIf it is not, then we print NIE. That should be the entire program. Notice that the editor interface here does not really have support for tabs. That is why, I am kind of typing out for spaces. You can, of course, also just code this in your favorite IDE and upload the file instead.\n(Refer Slide Time: 16:33)\n\nLet us just go ahead and make the submission to be sure. At this point, the status is pending. I have made a similar submission before. My current submission has run its course. It seems like it has a full score, which means all the tests passed, which is not surprising given that it was a really simple check that needed to be done.\nSo, there is not a whole lot of margin for error here. But do try this out, and see if you managed to also pass all the tests. You could try doing this the other way where you actually successively divide n by 2 and see if that is within the time limit. I believe that that approach also works just as well. Do give it a shot and let us know how it went for you. This was the final problem that we discussed in this week. We are looking forward to seeing you next week, and also over at Discord and the Google Groups. Thanks so much and talk soon. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec10.html",
    "href": "materials/cpnotes/Lec10.html",
    "title": "Greedy Algorithms - Module 2 (Islands War)",
    "section": "",
    "text": "Lecture - 10\nGreedy Algorithms - Module 2 (Islands War)\n(Refer Slide Time: 00:11)\n\nWelcome back to the second module of the third week. We continue our exploration of ‘Greedy Algorithms.’ As I mentioned, this time, we will be talking about a problem called the ‘Islands War.’ It was the fourth problem of an ABC contest on ‘AtCoder.’ It was contest number 103. You can find a link to the problem statement in the description of this video, and this one turns out to be a problem with a really fun story about warring islands, as you can guess from the name of the problem.\nSo, there will be a lot of conflict and drama, and your task will be to figure out how you can resolve all of these conflicts with minimum damage. So, we are going to have a lot of fun. Let us get started.\n(Refer Slide Time: 00:56)\n \n Eventually \nWe have ‘n’ islands lining up from west to east connected by ‘n-1’ bridges. These bridges are not completely arbitrary. The ith bridge is given to connect the ith island from the west with the (i+1)th island from the west. So, it is a really clean visual. Here is an example with ten islands and the bridges. There are nine bridges, which just connect them from left to right.\nWest to east has been, sort of, modeled as left to right on your screen. So, the westmost island is the first island here and so on. The real story begins when we are told that some disputes have broken out between some islands, and we want to make traveling between those islands using these bridges impossible. How do we do this? We must have something to work with to be able to meet this goal. The thing that we are allowed to do is we can remove some of these bridges.\nBut as you can imagine, removing bridges is a fairly destructive thing to do. What we are also asked to do is to minimize the number of bridges that need to be removed. So, you want to pacify everybody involved in a dispute. In the language of the problem statement, these disputes are called ‘requests.’\nSo we are given ‘m’ requests. Each request is a pair ‘ai bi,’ indicating which pair of islands are involved in the corresponding dispute. What you want to do is you want to remove bridges in such a way that every request is satisfied. That is the entire problem statement.\nThat is the goal. What we are going to do is just try and think about this first with the help of a few scenarios. Before we get to actually thinking about specific examples, let us go through this one right here. As you probably have noticed already, we have five requests here and a useful way to visualize these requests. Because we want to be thinking about which bridges to remove to satisfy all of these requests.\n(Refer Slide Time: 3:31)\n \n \nWe are going to visualize these requests as lines that have their endpoints at the two islands that are involved in the request. Let us just draw these out here. Maybe you can just try to figure out what is the optimal solution for this example. Just to get a feel for the question to make sure that we are on the same page with respect to the task at hand.\nFeel free to pause here because I am just going to give it away after I finish this sentence. For this example, you may have noticed that it is impossible to meet all requests by destroying just one bridge because, for instance, we have a pair of disjoint requests. So, we have two requests that do not have any bridge that is common to them. There is no single bridge that will handle both of these requests. You need at least two, and the interesting thing is that you can do it with just two bridges.\nYou could, for example, remove these two bridges here, and you would be done. How do we go about thinking about this problem in a greedy fashion? What is a natural greedy strategy? Remember that we have to meet all requests and minimize the number of bridges we use to satisfy these requests.\nWhat sort of bridges should we prioritize? What sorts of bridges are likely to appear in an optimal solution? A natural thing to do is to probably just go over every bridge and count how many requests are such that they would be satisfied if we were to remove that bridge. You could call this the ‘power of a bridge’ or something like that. You could use whatever term seems natural to you. I am just going to go with power.\nLet us say that the power of a bridge is just the number of requests, which would be handled if we were to destroy that bridge hypothetically. Now, it seems to make sense to target the bridges that have the highest power because the more powerful a bridge, in some sense, the more requests you handle in one shot.\n(Refer Slide Time: 05:51)\n\nThis motivates our first greedy approach to this problem. What we could do is compute the power of every bridge. Sort the bridges by their powers, and then pick the most powerful bridges first. In particular, to begin with, we include the most powerful bridge in our solution, breaking ties arbitrarily. Then we delete all of those requests that got handled due to deleting this bridge. Then we keep repeating this as long as we have at least one request left.\nRemember that you may have to re-compute the powers of the bridges because after you delete some requests, some bridges may become less powerful than they were before. You could do all of this and what you would have as a result is a perfectly valid approach. But this is a good time to pause and think about whether it actually works. It will certainly produce a subset of bridges whose removal will handle all the requests just by definition.\nThe real question is whether this is the best that we can do? In other words, are we really getting to the minimum number of bridges that we need to destroy to handle all requests? This is a great time to pause the video and actually think about this. Play with some examples and see if you can come up with either an argument for the correctness or if you can come up with a counter-example showing that this may not actually be the best possible strategy.\nPlease go ahead and take that pause and come back to this video once you are ready. Hopefully, you have had a chance to think about this. It turns out that while extremely tempting, this strategy does not, in fact, work.\n(Refer Slide Time: 07:32)\n \nWe are going to show you an example where the strategy of choosing the most powerful bridges can actually lead you to a solution that is not the optimal solution. Here we have a collection of four disjoint requests, which tells you straight away that the optimal answer has to be at least 4. Then we have a bunch of other requests, which are going to play out over the next couple of seconds.\nLet us try and think about what the greedy strategy will do here. You can check that, to begin with, three bridges have a power of 4, and ‘4, 5’ is one among these most powerful bridges. The greedy algorithm could start by picking ‘4, 5’ followed by ‘8, 9,’ which is one of the most powerful bridges left in the second iteration.\nAfter deleting ‘4, 5,’ and ‘8, 9,’ you are still left with three disjoint requests, which means that the greedy algorithm will have to output a solution involving five bridges. However, notice that four bridges are actually enough for this instance. Remember, earlier, we said that we need at least four, but it turns out that four bridges are even enough.\nNow you might be thinking that was pretty close. It was off by just one. Do I really need to worry about this? So, once again, let me remind you that in contest programming, you have to get it exactly right. There is no partial credit for coming close to the right answer. Sometimes there are problem statements, which will allow for solutions close to the optimal.\nBut these are rare and certainly out of the scope of this course. So, always work with the mindset of shooting for the exact optimum solution. Besides, although this particular example was off by one, you can probably think about coming up with ways of modifying this example so that you can really amplify the gap between the output of a greedy algorithm that follows the strategy of destroying the most powerful bridges first and the true optimal solution.\nI leave that to you as food for thought while we should probably move on, get back to the drawing board, and think about other alternate strategies. To get a feel for what is going on, let us actually begin by looking at two really simple scenarios. These are probably the simplest scenarios that we can come up with, but they will still give us some intuition for what is going on.\n(Refer Slide Time: 10:04)\n  \nFirst, let us think about what if all the requests were disjoint? In this case, you know that there is no bridge that can handle more than one request. You know that the optimal solution must involve at least as many bridges as there are requests. So, ‘opt’ is actually equal to ‘m,’ in this case. In terms of actually coming up with a solution, if you had to, you could simply pick one bridge per request, and it could really be any bridge that kills that request. It would not matter.\n(Refer Slide Time: 10:41)\n  \nOn the other end of the spectrum: What if every request went over some common bridge? In other words, what if there was one bridge that was involved in every single request? Here is one example where this plays out, and you can probably, as we go along, identify the bridge that is common to each request. It is the one that is right in the middle. When you have a situation like this, ‘what should the optimum solution be?’, you can probably guess that the optimum solution is just that one bridge that every request is involved in. A typical instance is going to be some combination of these two very extreme scenarios. So, let us think about a more generic situation.\n(Refer Slide Time: 11:31)\n\nOften it helps to think about what an optimal solution looks like, especially at the extremes. If there is some notion of beginning or end in a problem, it is worth thinking about what is going on the edge. Let us do that here and think about a situation that has no special structure.\nImagine that somebody has given you an optimal solution to look at and one question that I would like you to think about now is: Where is the leftmost bridge on this optimal solution? Where does it lie? Which request is driving the choice of the leftmost bridge? Please take a pause here and think about this because this is going to lead us to the main insight for the final solution. I hope you had a chance to think about that. We are going to work through this with an example.\n(Refer Slide Time: 12:24)\n\nLet us drop some requests right here and, as we said earlier, you really want to be thinking about: Which is that critical request that drives the choice of the leftmost bridge? There are some natural candidates. Is that the one that finishes first? Is it the one that starts first? Is it the one that finishes last? The one that starts the last? If you think about it, you will realize that it is probably the request that finishes first.\nBecause if you choose a bridge that came after this request finished, then you are in deep trouble. We know that we have to, at least, pick the bridge ‘3, 4,’ or one of the ones before it, to make sure that the first request is satisfied. In this example, we know that we have to pick at least one of these three bridges ‘1, 2,’ ‘2, 3,’ and ‘3, 4,’ to satisfy the first request.\nThe thing to think about here is: Between these three bridges, is there a natural greedy choice to be made? Is there a bridge that seems to be at least as powerful as the other ones, so that we can sort of pick it at this stage without having to worry about exploring all the choices that we have?\nA natural thing to target is the last bridge, which is the bridge ‘3, 4’ in this case. Because notice that every request that can be handled by ‘1, 2,’ or ‘2, 3’ can also be handled by ‘3, 4.’ If this was not the case, then we have a request that is being handled by the previous bridges but is not being handled by ‘3, 4,’ and that would contradict our choice of the bridge that finishes first.\nIn case that was not completely clear, please take a moment to work through it. It is a simple argument, but it lies at the crux of why the strategy that we are going to propose is, in fact, correct. The idea here is to simply prioritize the bridge that is on the brink of the request that finishes first. Because, again, the overall intuition is that we know that we do have to pick either this bridge or one of the ones that come before it, and it seems like this bridge is at least as powerful as the ones that come before it. So, we might as well just pick this one. Let us convert this idea into an algorithm.\n(Refer Slide Time: 14:51)\n\n \nThe natural thing to do here is to sort the requests by their right endpoints, which is to say that the requests that finish the earliest will come first in the sorted order. Just to be sure, let us look at this sorted order for one of the examples that we saw just a little bit earlier. Now from here, what does the algorithm do? It is going to look at the first request, pick the last bridge on it, and then eliminate all the requests that are handled by this bridge.\n(Refer Slide Time: 15:11)\n \nThen we simply continue. For as long as we have a request left, we are going to be picking the last bridge on the first request. Notice that the sorted order of the requests remains unchanged, even as bridges get deleted. We just have to make sure that we track which requests are being handled by the bridges that we are including in our solution.\nLet us just play this out on a couple of examples to get a feel for what is going on. At this stage of our discussion, you are actually exposed to the entire algorithm that finds the solution. Hopefully, you have some intuition for why it works. We are going to have more to say about that and the running time in just a minute. But if you cannot wait to implement this yourself, this would be a good time to take a pause and do it.\n(Refer Slide Time: 16:19)\n \nIn the meantime, let us play out the algorithm once again on one of the examples that actually appeared in the problem statement. Speaking of the problem statement, let me also remind you about the constraints that we are given on the inputs. Notice that the number of islands and the number of requests can be as large as 105, which means that an algorithm that is either quadratic in ‘N’ or ‘M’ would not be feasible.\nIn fact, even a solution that has a worst-case complexity of ‘N*M’ might get you into trouble. Let us analyze the running time of the approach that we have just proposed. Recall that in the first step, we sort the requests according to their right endpoints. That is just a standard sorting procedure and it will take you time ‘M log M,’ which is still pretty safe within the given limits.\nThe second phase is where we actually build up the solution. The way we did this was by performing one pass over the sorted list of requests. Every time we encountered a request, we would include the last bridge on that request in our solution. We would also eliminate all the other requests that were handled by this bridge.\nBut if you implemented exactly according to this description, then you have to be a little bit careful because you might end up getting an order ‘M2’ kind of a running time. Because every time you include a bridge, you do one more pass over the list of requests to identify those that need to be eliminated.\nI will leave it to you to think a little bit about how you can implement this in a slightly different way to ensure that all your work is being done in just this one pass over the requests. One hint is that instead of actually explicitly eliminating requests as you go along, can you simply track the last bridge that you have included in your solution and for every request that you are going over, simply check as you go along, if it was handled by that last bridge or not and think about why this approach would also work?\nThat is all that I will have to say about the implementation for now. I would like to go back a little bit to our discussion about the correctness of this algorithm. One of the really neat things about this algorithm is that the solution that it produces carries proof of correctness. If you think about the bridges that we chose finally, each of them corresponds very naturally to a request.\nThat is that request, which triggered the choice of this bridge and the solution. If you think about it, you will realize that all of these requests are, in fact, disjoint. Because if they were not disjoint, then at least one of the overlapping requests would have been eliminated in a previous iteration. You get a really simple contradiction. Now you have a collection of disjoint requests that is exactly the same size as the solution, which means that our solution has to be optimal.\n(Refer Slide Time: 19:31)\n  \nGoing back to one of the first observations that we made, it was this really simple idea that you need at least as many bridges as there are disjoint requests in your instance. What this algorithm is telling you right now is that it is actually enough. You do not need anymore. It is this really nice duality telling you that the largest number of mutually disjoint requests actually determines the number of bridges that you need to destroy. That concludes our discussion about the algorithm and its correctness.\n(Refer Slide Time: 20:07)\n\n\nLet us move on to the implementation. This is your regular spoiler alert at this stage of the discussion. If you want to try this yourself, you should probably come back after you have given it a shot. In the meantime, let us get started here. Let us recall that the first line of the input is just the number of islands and the number of requests given as two space-separated integers.\nLet us just read those in and the next ‘M’ lines give you the ‘M’ requests. Let us declare a list of requests and let us read these in. I am going to store each request as a tuple, you could also store it as a list - does not really make a difference. This is the current request, which we are going to append to the list of requests.\nThe first thing that we have to do is to sort this list of requests according to the right endpoint. What we are going to do is use the built-in sort function on the list of requests. But we also have to tell the ‘sort’ function to sort according to the second coordinate. There are many ways that we can do this.\nFor brevity, I will just use a lambda function here. If you are not familiar with this sort of notation, you can look it up. But intuitively, you can imagine that it is instructing the sort function to sort according to the second coordinate of the tuples. Now that the requests are sorted the way we want them, let us actually get to the bit where we build up the solution.\nLet us declare an answer variable, which we initialize to 0. We will start looking at these requests and figure out if a request really demands that a bridge needs to be added to the solution. Let us start by going over the requests one by one. What do we need to know about this current request?\nWhat we need to know is: Is it being handled already by the solution that we have built up so far or not? If it is not, then we need to add the last bridge on this request to our solution. If it is, then there is nothing to be done and we can move on. How do we check this? How do we check if the current request is being handled by the solution that we have built up so far?\nNotice that if it is being handled by the solution, then certainly the last bridge in our solution covers this request. Because if the last bridge does not cover this request, then none of the previous bridges would either. If it covers the request, then we are done. It is enough to keep track of the last bridge in the solution that we have built up so far.\nIn some sense, what we are going to have is something like this: If the last bridge is at least request of 0. What does this mean? Look at where the request starts, and make sure that the last bridge is after the starting of this request. If this is the case, then the last bridge covers this request. If this is the situation, then we can just keep going.\nBut if it is not, then notice that we do need to add a bridge to our solution to handle this particular request. What is the bridge that we are going to add to the solution? As we have discussed when we were going over the greedy approach, we said that it is enough to pick the last bridge that covers this request.\nThat is given by request of 1. What we want to do is, we want to add this bridge to our solution. When I am talking about the request of one, it is really the bridge that connects the islands’ request of 1-1 with request of 1. So, that is the bridge that I want to add to my solution.\nRemember that we are really just tracking the number of bridges in our solution and as we go through this one pass over the requests, what I need to remember is: What was the last bridge? In other words, what was the rightmost bridge in my solution? At this point, what do you want to update is just the value of last bridge to reflect that the last bridge is now the bridge that ends at request of 1.\nBy the way, I am just thinking of representing the bridges by their right endpoints here. You could also represent a bridge by its left endpoint but then you would have to adapt the ‘if’ condition in the previous block. The other thing that we have to update is the answer variable. We need to increment that by 1, and we need to print this answer.\nOne thing that we have not done is initialization. What happens to the first request? When you start this ‘for’ loop, you are going to run into a problem when you try to execute this ‘if’ statement because there is no last bridge. We have not even started building our solution so far.\nTo make sure that the last bridge of the first request is actually chosen in the solution, what I initialize last bridge is -1 because that way even if the request started at island number 1, it is still not going to be covered by this last bridge. Notice that this is an artificial last bridge, it does not really exist.\nIt is just so that the code that we have written picks up the last bridge of the first request, to begin with. Then it does its thing after that. You could also initialize this as requests of 1 of 0 and then you could start your ‘for’ loop from the second request onwards. That is just going to be a matter of preference.\nBut I believe this should work. I think we have gotten all of the moving parts right here. So, I am going to try and run this. Notice that the output here turns out to be 2. I think this was one of the examples or at least close to one of the examples that we have discussed. We see that the expected output is also 2. In general, as a matter of practice, you just want to make sure that your output tallies exactly with what is expected.\nWe could run this on one of the other examples as well. As usual, you probably also want to run this on examples that you come up with just to have an extra level of sanity check. Let us try running this on the last sample output where the expected answer is 4 and this is also an example that we have actually seen.\nLet us go back and run our program and we will see that the output actually matches and everything seems fine. I think we should have some confidence from the fact that we have discussed our approach by now, in quite some detail. At this point, I would encourage you to actually check this code or a version of it that you might have put together on the full set of test cases and let us know how it went.\nAs usual, if you are stuck anywhere or if you are running into trouble with the logistics of submitting your solution, please give us a heads up on either the Discord channel or drop a message in the Google Forums for this course and one of us will be sure to get back to you. All the best and we will see you in the next problem. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec38.html",
    "href": "materials/cpnotes/Lec38.html",
    "title": "Minimum Spanning Trees - Module 1 (Prim’s Algorithm)",
    "section": "",
    "text": "Lecture - 38\nMinimum Spanning Trees - Module 1 (Prim’s Algorithm)\nWelcome back to the second segment of the first module on Minimum Spanning Trees. In this segment, I want to talk about Prim’s algorithm. And remember, from the previous segment, we talked about how most MST algorithms can be thought of as algorithms that build out a spanning forest step by step while making careful use of safe and useless edges. So, let us see how Prim’s algorithm realizes this framework.\n(Refer Slide Time: 00:40, 00:59 & 01:19)\n  \nTo begin with, we are going to start with the empty spanning forest, which is to say that the vertex set is simply the vertex set of G, and every vertex at the moment is isolated. What Prim’s algorithm is going to do is essentially try and build out one component starting from some specific vertex.\nSo, you can pick any vertex you like for this purpose. Let us just fixate on a vertex called ‘v.’ And let us call this vertex ‘T.’ That is to say, that is the spanning tree that we want to build out. So, this is a component that we want to continue focusing on, and (all of) Prim’s algorithm, the mechanics basically boils down to this.\nSo, we look at the safe edge incident on T, which is to say, let us look at the cheapest edge among all edges that have one endpoint inside T and the other outside. So, to begin with, once again, this is just going to be the cheapest edge that is incident on the vertex v. And that is what is going to get pulled into T. The other endpoint of this edge is going to now become a part of T. And, in a general step, you have built out some ‘component’ starting from this vertex v.\nAnd you are going to look at all the edges that go out of this component, pick the one that has the least cost, and then add the vertex that is at the other end of this edge in component T. So, we continue doing this until T is fully fleshed out into a spanning tree, which is something that you get to know once T has ‘n minus 1’ edges. By this time, it would have automatically visited or accounted for all vertices being reachable from the vertex that you started with. Now, just to make sure that we are on the same page as to how this algorithm works, let us actually run it on an example.\n(Refer Slide Time: 02:30)\n \n \nLet us just pick up the example that we looked at in the first segment. So, here is the graph. And I have highlighted in yellow the vertex that is the vertex that we are going to start with. So, this is our vertex v. So, the vertices do not have labels here just to keep the slide a bit clutter-free. So, let me just explain how color coding works. So, the edges that have been marked red are going to represent edges that are under consideration in the current iteration, which is to say these are edges that have one endpoint inside T and the other endpoint outside of T.\nTypically, what we will do is we will then highlight in green, the cheapest edge among all of these edges that are under consideration. And then, once we have identified this edge, we are going to bring in the vertex, which is at the other endpoint into the fold of T. These are vertices that you can think of as the visited vertices, the seen vertices. So, such witnesses will also be marked yellow. So, as and when we see more and more vertices as the component T bells out, all the vertices that belong to T will be marked yellow.\nSo, hopefully, that makes sense. Let us get started with the first step here. Notice that the edges under consideration are simply all the edges that go out of the vertex v. So, these are the highlighted edges here. And if you just read off the weights, you will see that the cheapest edge is the one that has weight 2. So, we bring in this neighbor into the fold. And now we see if we need to expand our set of edges that have one endpoint in the visited set and the other endpoint outside. And indeed, there are three such edges that need to be added.\nSo, these have been highlighted for you. Now once again, let us go over the edge weights of the red edges. And we see that there are two edges that have a weight of 3, and both of these are in competition for being the current cheapest edge. At this point, I am going to break the tie by picking the edge at the bottom and incorporating this vertex into the fold. Now notice that one of these red edges became yellow because this red edge is now no longer an edge that has one endpoint inside T and the other outside.\nIt has both of its endpoints inside T. So, we are going to mark it yellow as well. Now let us look at all the edges that are crossing T. So, there is one more that needs to be added. And once again, if you evaluate all the edge weights, you will see that now we have this other edge with a weight of 3 being the winner here. So, that brings in this vertex. And once again, we have more edges that cross now, at least one more. And this new edge is, in fact, the edge which has the smallest cost that is currently crossing. So, we use that to bring (in) this vertex into T. And now we have a few more edges that cross the cut.\n(Refer Slide Time: 05:43)\n  \n \nAnd among these edges, among all the red edges right now, you can see that the next cheapest edge that gets chosen is the edge with a weight of 2. There is no contention here. It is the cheapest edge, and it brings in this vertex. And now you have all of these edges crossing the cut. And now, in fact, we have two edges that are both the cheapest from component T.\nAnd we pick one of them. This one that is closer to the center – this brings in the vertex that is the center of your screen into the component T, and it also adds one edge to the cut. Now if you look at all the crossing edges, you see that there is an edge still of weight 2. So, that is the next cheapest edge to go with. It brings (in) the corner vertex into the fold and adds this edge to the cut. And now, among all the crossing edges, you again have a tie between the two edges that have a weight of 4.\nSo, let us break it by picking the vertex that is, once again, in the middle of this path at the bottom – this brings (in) this vertex into T. And at this point, you are going to have this edge crossing the cut, which would be in fact also the minimum edge for the current cut. And that is how the last vertex gets incorporated into your spanning tree. Now, you could try to rerun this simulation here by breaking ties differently, and you will see that you will end up with a different structure for the set of edges that witnessed the incorporation of vertices.\nSo, by the way, all of these edges that are marked green, which were the edges that triggered the incorporation of the next vertex, these trees very naturally form a spanning tree. And this is in fact the minimum spanning tree that is returned by Prim’s algorithm. And as I said, if you had broken the ties differently, you would end up with different tree structures. But notice that all of them will in fact have the same cost. It should be easy for you to believe that the set of edges that you get at the end is spanning and it is a tree. I think these are fairly intuitive properties of the set of edges that you finally get your hands on. But what is quite a bit more non-trivial is the fact that this is in fact the best you can do. So, for example, if you add up the costs here, I think it will amount to 25. But it is not trivial, even for this example, to convince yourself that this is the best that you can hope for, you can do a little bit of trial and error. And, you know, just try and see if you can improve on this.\nBut assuming that I have not made any mistakes in the simulation, this is going to be guaranteed to be the best that you can hope for because of the proof of correctness of Prim’s algorithm. So, this is a good point to remind you once again that in case you have not seen this proof before, although we will not be discussing it here, there are a number of pointers where you can find out more if you are so inclined. So, please do check either the course website or the description of this video for more. Now in the meantime, let us move on to the implementation of the ideas that we have discussed here.\nNotice that we are repeatedly finding the minimum cost edge incident to some ‘component.’ So, it is intuitive that priority queues come in somewhere in the picture. And notice that in spirit, this does seem to follow a very Dijkstra-like pattern, where we are constantly evolving some collection of visited vertices. But unlike Dijkstra, we do not really have to relax any edges or update the weights. So, we do not have to worry about the fact that, in particular, the C++ priority queue interface does not offer us a way to update the values of the keys. It does not matter here because we will never need to. So, we are going to use a priority queue to store the edge weights. And we are just going to carefully try and understand what are the edges that are incident on the component T as we go along. So, let us take a look at the code here.\n(Refer Slide Time: 09:46)\n\nSo, this is just an initialization of a taken array or a visited array. This just keeps track of which vertices have been visited so far by the algorithm. So, this array is basically the information about the yellow vertices from the previous simulation. So, initially, you could say that nothing is visited. And you could start things off by saying that the first vertex is visited. So, in this case, the first vertex is indexed by 0.\nAnd we just said, taken[0] = 1 to indicate that the story has, in fact, started. Now I just want to initialize also the priority queue with the values of the edges that are incident to this first or source vertex. So, let me just go over all the neighbors of the vertex 0 that is what is happening in AL[0]. By the way, I should mention that we are just storing all the information about the graph as an adjacency list because that is just something that happens to be convenient for this.\nSo, we are just going to do the standard thing of visiting all the neighbors of the vertex 0 and loading up the weights of the corresponding edges into a priority queue, which has been initialized. Just before this code snippet, just make sure to initialize the priority queue so that it acts as a min-heap and not as a max-heap, which is the C++ default. Do make sure to take a look at the whole code in the official repository to look at the surrounding details of the initializations, and so on, especially if you are not sure about how to set it up so that it is a min-heap instead of a max-heap.\nAlright. So, now that we are done with the first element in the priority queue let us do a little more initialization. So, we have the variables mst_cost, and then the variable num_taken both initialized to 0: mst_cost is pretty self-explanatory, it is going to store the cost of the solution; the variable num_taken is going to keep track of how many edges are in the spanning tree so far. This allows us to exit as soon as we have seen that we have picked up n-1 edges because that is a signal that your spanning-tree build-up is complete.\nSo, that gives us a way to exit the algorithm potentially earlier than waiting for the whole priority queue to be emptied out. So, that is why we have this extra variable here. You have to be careful about problems where you are handling multiple test cases. So, if you do this early exit, just make sure that you clean up the priority queue before you go to the next case. This is a very common source of bugs to have your adjacency lists or priority queues being corrupted with information from the previous test case.\nSo, do make sure to clear them out or re-declared them, especially when you are using this sort of optimization that does not automatically empty out the priority queue for you. Now let us get to the main loop that is at the heart of this algorithm. So, the way we are going to do this is to actually process the priority queue for as long as it has an edge on it with our check for, you know, getting out of this loop early, if we have actually built out the tree, as just described.\nSo, this is going to be our main outer loop. And what we are going to do is just repeatedly pull out the cheapest edges that we have in stock. Notice that one property of all the edges that get into the priority queue is that at least one of their endpoints is already in the set of the same vertices. That is how these edges got into the priority queue in the first place. This will become clearer when you see the entire body of the ‘while’ loop.\nBut that is just an invariant that we are going to maintain. With the initialization, this is definitely true. All the edges on the priority queue, in the beginning, are edges that have one of their endpoints in the source vertex and the source vertex as already seen, to begin with. And as I said, this is something that we will maintain as we go along. So, when we pull out the cheapest edge in the priority queue, notice that it already has the property that it is an edge that has at least one endpoint in the set of seen vertices.\nBut for this to be an edge that is of interest to us, we want to make sure that its other endpoint, in fact, is not seen so far. So, that is the first check that we want to implement. We want to make sure that take[u] is set to 0. So, if this is not the case, then we ignore this edge because this is an ‘edge,’ which has both of its endpoints in the component that we have built so far. And in the terminology that we discussed in the previous segment, this is a useless edge. So, we just want to have nothing to do with it. And that is why we just go back and continue with our loop.\nOn the other hand, if this edge actually lands at a vertex that is not yet seen, then that is an edge that is interesting to us. Notice that this is in fact the cheapest edge that crosses across from the seen territory to the unseen territory at the moment. So, this is essentially a green edge. Remember, every edge that we labeled green was a signal that this is the edge that is going to guide the incorporation of the next vertex.\nSo, this is the point where we have identified a green edge. And what we need to do is essentially look at the vertex that is at the other end of the green edge and make sure that it is incorporated. So, the first step to ensuring that this other vertex, which by the way is ‘u’ here is incorporated is by simply setting it is taken value to 1. So, that indicates that now this vertex has joined the club. The next thing that we want to do is to make sure that we update the cost of our solution with the cost of this edge.\nSo, this edge has a cost of ‘w’ that is what we get out of the priority queue. So, we add w to the mst_cost variable. And finally, what we want to do is actually identify any other red edges. So, remember what we did while we were doing the simulation when we brought in a new vertex was to check if there are any other edges that now go from the seen territory to the unseen territory because of the incorporation of this vertex.\nSo, what we are going to do is go over all the neighbors of this newly minted vertex, and check if any of those neighbors are unseen. That is, they have not been taken yet. Then these edges need to be pushed into our priority queue for consideration. So, that is what we are doing here. We are essentially processing this vertex to ensure that all of the edges (that are) incident on it are (being) now recognized in the system.\nNow, once you are done with this, all you have to do is update the number of taken edges by 1 and implement the sanity check that we discussed. If at this point, you have taken ‘n-1’ edges already, then you can quit this loop, and you are done. And once you are out of the loop, of course, you can print the cost of the MST or, if required, you could write a loop to print all the edges that belong to the MST.\nFor this, you might need to do a little bit of extra bookkeeping within the ‘while’ loop just like you would do with something like Dijkstra. You could have a predecessor array that tells you about how each vertex got roped into the component T. And those are the edges that will basically form the MST for you. So, that is it. That is pretty much the entire algorithm.\n(Refer Slide Time: 17:24)\n\nLet us quickly talk about its running time. Notice that every edge gets enqueued and dequeued at most once there are ‘m’ edges and these enqueue and dequeue operations cost you log ‘n.’ This is the bulk of the cost of Prim’s algorithm. There are some costs associated with the initialization and so on. But those are all dominated by this m log n expression. So, it turns out that once we get to analyzing Kruskal’s algorithm, you are going to get a very similar running time.\nSo, if you are pressed for a choice, either algorithm would work out similarly in terms of performance. But for some problems, it is just more natural to use one algorithm compared to the other and that will become evident as you practice through a number of problems. So, on that note, I would like to conclude our discussion on Prim’s algorithm and I will see you in the final segment for this module where we talk about Kruskal’s algorithm, which is a different way of building up a minimum spanning tree!"
  },
  {
    "objectID": "materials/cpnotes/Lec14.html",
    "href": "materials/cpnotes/Lec14.html",
    "title": "Greedy Algorithms - Module 4 (When Greedy Does Not Work - Guarding a",
    "section": "",
    "text": "Lecture - 14\nGreedy Algorithms - Module 4 (When Greedy Does Not Work - Guarding a Museum)\nLet us continue with our second example of an optimization problem where the natural greedy strategy, in fact, does not work. This problem is called ‘Guarding a Museum’ with some guards. Let us take a look at the problem statement.\n(Refer Slide Time: 0:27)\n\nWhat we have are some paintings that have been placed on a hallway, which you can imagine as just being represented by the number line. You can imagine the paintings as just being some locations on this number line. For convenience, you can imagine that these are integer locations, although that is not really necessary. But that is what our examples will look like. What you are given is some guards.\nThese guards have a certain purview that they can see. This is also a part of your input. For example, here, we have a guard who is able to see, let us say, 3 units to the left and 3 units to the right. We are given this number K. Every guard can see K units to the left, and K units to the right from where he is positioned. Of course, he also sees the position at which he is standing.\nWhen you place a guard, let us say, at the origin of this number line, then you, in some sense, protect the locations 0, +1, +2, +3 and -1, -2, -3. These are all the locations that are currently under the observation of the guard who is standing at the origin. You can think of this visibility range as something that is given to you as input, and we will call it ‘K.’ All guards have the same visibility range. Any guard that you place at position ‘x’ will end up observing position x, as well as any position that is within K units to the left or right of x.\nWith this setting in place, let us now define the optimization objective.\n(Refer Slide Time: 2:08)\n\nWhat we want to do is make sure that every painting is protected or guarded at least once. We want to minimize the number of guards that we deploy to be able to achieve this. There are many variants of this problem. You might be in a situation where you want to be more protective, and you might want your paintings to be observed by at least some number of guards.\nIn other applications, you sometimes do not want 2 guards to observe the same painting. That is usually not in the situation of paintings but other applications that involve, let us say, for instance, the guards may be robotic agents, and maybe when two of them have their sort of range of visibility overlapping, it may cause some undesirable interference.\nSo, there are variations of this problem where you do not want any particular location to be guarded, or to be observed more than once because that is just physically not desirable. But in this variation of the problem that we are discussing now, we do not mind every painting is observed more than once. But we do require that every painting is observed at least once. That is the goal. That is a feasible solution — where every painting is guarded at least once.\nThe thing that you want to minimize is the number of guards that you actually deploy. So, hopefully, the problem statement is clear. At this point, you might want to pause and think about what will be a very natural greedy strategy to come up with a solution. Take a pause and come back when you are ready. Hopefully, you had a chance to think about this. Here is a very natural greedy strategy for solving this problem.\n(Refer Slide Time: 3:54)\n\nFor every location, you can try to count the number of paintings that would be guarded if you were to hypothetically place a guard at that location. Then you could choose the location that has the maximum potential in this sense, in the sense of the number of paintings, that would be taken care of where you to place a guard at that point. If there are multiple locations that have the maximum potential, then you could just pick any one of them arbitrarily. Then you could just delete all the paintings that get taken care of by this choice. Then you could just repeat until you have no paintings left to worry about.\nLet me also quickly point out here that you do not really need to check the potential of every point on the number line for this strategy to work. That is anyway not going to be feasible. Notice that because we assume that our paintings were positioned at integer coordinates, we can assume without loss of generality that our guards are also going to be positioned at integer coordinates, by which I mean that there will always be an optimal solution where this is the case.\nSuppose somebody does come to you with an optimal solution where the guards are not at integer coordinates, then you can identify all the guards who are not standing at integer coordinates and gently nudge them to the closest integer coordinate without really changing the texture of the solution. It will work just the same.\nOnly integer coordinates are really of interest to us. Notice that you can also ignore any integer coordinate that is more than K units to the left of the leftmost painting, or more than K units to the right of the rightmost painting. It will never make sense to place guards at these positions. They are never going to protect any of your paintings. We can simply ignore them. Based on this discussion, you should be able to conclude that the number of locations of interest is really given by the distance between the leftmost and rightmost paintings +2K.\nWhat can we say about the distance between the leftmost and rightmost paintings? Let us say there are N paintings. This distance can be unbounded if you have some two consecutive paintings, which are really, really far apart. But if you think about it, if there are two paintings, which are arbitrarily far apart, then we could shrink this gap down to something like 2K+1 without changing anything about the instance. I will let you think about why this is true.\nBut you should be able to conclude that the number of locations of interest overall is some order NK based on everything that we have said so far. Let us go ahead and compute the potentials of all of these locations, which again, remember is basically the number of paintings that would get taken care of if we were to place a guard at that location.\n(Refer Slide Time: 6:29)\n \nHere is an example with N = 8. We have 8 paintings at various locations. Let us say the visibility ranges of the guards are 3. So, K = 3. We are basically computing the potential of each location. This number is written above each location. You can pause the video here for a minute and verify that these numbers are as you would expect. Let us now think about what the greedy algorithm would do.\nThe greedy algorithm is going to focus on those locations that have the highest potential. Notice that we have 4 locations that are tied at the top, and it is going to pick one of them arbitrarily.\n(Refer Slide Time: 7:08)\n \nLet us say the greedy algorithm picks this location and decides to place a guard there. Once we do this, we can forget about these first 5 paintings that are taken care of by the guard. These are the remaining paintings and the recomputed potentials. At this point, you could pick any one of these locations that have the maximum potential, which in this case is 3.\n(Refer Slide Time: 7:29)\n \nPlace a guard at any of these locations. They will just take care of your remaining paintings. So, you can guard everything with 2 guards. You can also see that this is, in fact, the best possible because if you looked at the original instance, then you will see that there were 2 paintings that were more than 6 units apart. You definitely needed at least 2 guards. That is one run of this greedy strategy that actually worked out.\n(Refer Slide Time: 7:55)\n \nLet us go back to the original instance and see if the tie-break worked out differently, what would happen. This is a good place to pause and think about whether a different tie-break could lead to a less than optimal solution.\nLet us see what would happen if you had picked the second location, which had the maximum potential instead of the leftmost one. In this case, if you place a guard at this position, then you actually leave out the leftmost painting from the purview of the first guard.\n(Refer Slide Time: 8:26)\n\nUnfortunately, this is the instance that you are left with. We have a situation where we still have 2 paintings that are more than 6 units apart from each other. We could calculate the potentials as the greedy algorithm would do at this stage. Then the greedy algorithm would have to position 1 guard in the extreme right and 1 on the extreme left.\nBecause of this situation, we see that the greedy algorithm will need to have 2 more guards on top of the very first guard that it has already positioned, leading to a sub-optimal answer. You might think that it was because of an unlucky tie-break. Correct. There was at least one way of breaking the tie. I think there are at least 2 ways, which would have led to the correct answer.\nThere are 2 things about this. One is that you cannot rely on luck, especially not in contest programming. You cannot just hope that your greedy algorithm will get the tie-breaks right. While there are problems for which tie-breaking is really the main issue, and maybe the greedy algorithm would work well, if there was a promise that you would never have ties at any stage of the greedy algorithm, which by the way, can be very restrictive but suppose that was the case, maybe things would work out.\nBut for this particular example, I would encourage you to, as an exercise, come up with an example where the tie breaks do not matter. At the very first decision, there are no ties. There is a unique position that has the maximum potential. The greedy algorithm will be forced to pick that. But that turns out to be a bad choice. If you can come up with such an example, please do share it in the comments either on this YouTube video or at the Discord community, and we look forward to analyzing them.\nNow, as a part of this lecture, we have one more video left where we will go through one more example of a situation where the greedy algorithm fails, and in some sense, it fails quite miserably. We will see what we mean by that when we talk about the ‘Traveling Salesman’ problem in the next video. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec00.html",
    "href": "materials/cpnotes/Lec00.html",
    "title": "Welcome and Initial Setup",
    "section": "",
    "text": "Lecture - 00\nWelcome and Initial Setup\n(Refer Slide Time: 00:11)\n\nHi, welcome to the NPTEL course on getting started with Competitive Programming. This is the first week of the course, and this is the very first video. So, let me take this opportunity to welcome you to the course and to say thank you for joining us. This should be an exciting journey through a variety of contest problems as we go along.\nThe first week focuses on problems whose solutions are based on AdHoc methods or their direct implementation problems. It is to say that specifically, you do not need any background and algorithms to be able to tackle these problems. The intention of doing this was to give ourselves some time just to get set up to get used to the modalities of the course and basically have some fun.\nIn this lecture, we will not be solving any specific problems. But we will be addressing some of the most frequent questions that came up in the Discord community, launched for this course a couple of weeks ago. In case you missed the announcement, there is a link to the Discord community in the description of this video. It is an invite link, which you can click to join the community.\nSo, if you have not done so already, please do that. There is an introductions channel, and we would love it if you could just introduce yourself in that channel and meet your fellow learners in this course by doing that. There is also a channel for general questions. So, any questions that are related to the course at large, please feel free to post them there. We also have a channel for every week.\nI will request you to post any questions that you have related to the materials that we are covering in the relevant weekly channel. This will allow us to streamline our attention as we try to go through the posts on Discord. So, I hope to see you there, would look forward to it. In the meantime, let me just make a list of the questions that have been coming up. This will also be one way of getting you introduced to the general format of the course. So, let us go ahead and talk about some of these questions.\n(Refer Slide Time: 02:37)\n\nAlright, so I list the questions first all at once, and then we will try to tackle them one by one. By far, the most popular questions that we got were related to the choices of programming languages. For example, what languages are we using? What languages do we recommend for you to be using and so on? We also had a lot of questions about the pre-requisites, like, what do we expect you to already know before starting the course? I will also talk a little bit about the contest platforms that we will be using, as well as the format of the assignments and the exams.\nOkay, the first question is: What programming language are we using in the lectures? The answer to this is C++ and Python. Depending on the problem, we will be describing the solution that is written in one of these two languages. To the extent possible, we will try to provide you with sample solutions in both languages for most problems.\nBut whenever this is not possible, it is usually not that hard to translate the main idea of the solution from one language to another. In fact, I would say that it is probably a good exercise. You can always access the code that we show you in the lectures on a GitHub repository, and there will be a link to the sample solutions in the description of each video.\nHopefully, everything is going to be fairly easy for you to find, as we go along. I would not recommend actually looking up these solutions first. But just keep it as a backup reference and try coding things yourself. In fact, even before we get into the implementation segment in any video, I would strongly recommend just pausing the video and trying to implement the solution yourself and coming back only if you are stuck. Often, we will try to cover the most common mistakes that are bound to happen while coding up a particular kind of solution. So, we hope that you find that helpful.\nThe second question is: What programming language should you use for this course? My answer to that would be whatever programming language you are already comfortable with should be great. On the NPTEL platform, we will have some programming assignments and solutions to those that can be uploaded in C, C++, Java, or Python. As long as you are familiar with one of these languages, that should be enough for our official assignments.\nBut you are probably going to be doing a lot of programming outside of the NPTEL assignments. You will be participating in contests on platforms like CodeChef, Code forces, Google Code Jam, and so on. Most of these platforms do support the languages that I have just mentioned and many more.\nMany of these platforms will even give you extra time for Python submissions, just to compensate for the fact that it can be slower. Of course, not all platforms do this. So, you have to be careful about checking if this is important to you. Specifically, can you get away with just knowing Python? For competitive programming, I think absolutely, yes. A lot of contest programmers have gone quite some distance using languages like Python and other non-mainstream languages. So, the choice of language should not really be a hurdle here.\nI think working with something that you are comfortable with is already a bigger advantage than any other gains that you might make when you are simultaneously trying to learn the syntax of the language as well as the other algorithmic aspects of the problem that you are trying to solve.\nOf course, if you want to use this course as an excuse to pick up a new language and if that language happens to be C++, by all means, it is definitely a great choice. But just be mindful of the fact that it is going to be some more work. If you are not familiar with any programming language at all and you have to pick one, then C++ and Python seem to be the most natural choices, and they both have their own advantages.\nIf you plan to be serious about competitive programming and pursue it long-term, then making the investment in learning C++ is probably a good idea. On the other hand, if you just want to get up and running quickly, then Python may be the better choice because it is generally a friendlier language and is easier to pick up, to begin with.\nI should say though that in this course, we do assume familiarity with some programming language. This is not a programming languages course. So, it does not matter which language you know, but as long as there is some language that you are comfortable coding in, I think that would be very helpful. If this is your first time actually coding, then you might find that this course is a little more challenging for you, than at least we intended for it to be. So, feel free to come back to it after completing the first course in programming.\nThe third question is: Do we have a specific recommendation for an integrated development environment (IDE)? Most people who code like to use an editor that is designed for programmers with, at least, the basic features like syntax highlighting, quick access to compilation, and other tasks that you expect to do frequently.\nSo, I definitely recommend the use of some specialized editor. It does not matter which one, if there is one that you are using, that you are already comfortable with, I see no compelling reason to switch. This is largely a matter of personal taste and there are definitely a lot of different options. But I do recommend using one, it could be anyone. If you are coding in, say something like Notepad, then I think you will find this to be a very significant upgrade. The good thing is that there are lots of choices ranging from traditional choices like vi and Emacs, all the way to more contemporary options like VS Code and Sublime Text, Atom, and so on.\nOne good thing about all of these options is that they are cross-platform and are typically available on the most popular operating systems. So, you should have no trouble finding and downloading the software. They are also supported by really large and passionate communities. So, if you are stuck with something, it will usually be easy to find help.\nIf you are just getting started and you are overwhelmed by all these options, I would recommend downloading something like VS Code and just getting started for the reason that it is, it is a very user-friendly choice. It is easy to get started with but at the same time, it is quite powerful, and you can discover its features as you go along, instead of being overwhelmed right at the start. So, enjoy getting set up. I think this is a useful thing to invest a little bit of time in initially. Hopefully, you can set something up that works really well for you.\nThe next question is: Do we need to know basic algorithms before starting this course? The short answer to this is, yes, this would definitely be ideal. The reason for this is that every video in this course is going to focus completely on solving a contest problem, and we will not really be covering algorithms separately. But at the same time, we will be using many of these algorithms that you would learn typically in an algorithms course, say algorithms like BFS, DFS, minimum spanning trees, shortest paths or network flows, these are all going to come up as solution strategies.\nWe will be mostly focused on why these solutions actually work in the context of a problem. So, once again, we will not be proving why Prim’s algorithm actually outputs a minimum spanning tree. But our focus will be on arguing why a minimum spanning tree is the thing that you are looking for in the context of some problem.\nAlright, the next question is: What contest platforms we will be using? In the lectures, we will be featuring problems from a number of different platforms, including Google Code Jam, CodeChef, Codeforces, AtCoder, and the UVA database of problems. You will find links to all of these platforms in the description of this video. I would suggest spending some time right now just setting up your accounts on all of them and familiarizing yourself a little bit with the layouts of these websites. So, you should know where the active contests are where you can find the editorials, where you can submit your code, where are the contest archives, and things like that. I think this will be useful as you go along.\nThe final question: What is the format of the assignments and exams? Every week, we will have assignments that are in the form of multiple-choice questions, usually based on some contest problems. The questions will address various aspects of the problem, including observations that could lead you to a solution, discussions of possible solution strategies, what are their running times going to be, are these running times good enough for these input limits, and questions of that sort. There will also be programming assignments on the NPTEL platform for most weeks, and we will let you know just in case there are weeks where we do not have programming assignments.\nApart from these programming assignments, I would definitely encourage you to keep solving contest problems on other platforms outside of NPTEL and get as much practice as you can. For this, we will have some recommended problems every week to try out based on that week’s theme. These are completely optional and we will have no way to track them. But I hope that you will be able to make time for them because the more you practice, the better you are going to get at this.\nAs for the exams, we will only have multiple choice questions or short answer questions, questions with numeric answers. None of these questions will require you to write a program to be able to answer them. At best, you may need to do some computations that can be done by a calculator which would be provided. So, there are no programming-based exams for this edition of the course. If you have been comfortable with the assignment problems, then the exams will have questions in a similar format and in a similar spirit.\nSo, I hope that all this information helps you prepare well for this course. But in any case, if you have any questions that remain, please do post them on Discord, and as I said earlier, do introduce yourself. I am looking forward to seeing you in the rest of the videos for week one. Thanks so much for watching and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec28.html",
    "href": "materials/cpnotes/Lec28.html",
    "title": "Graph Foundations - Module 4 (Diamond Inheritance)",
    "section": "",
    "text": "Lecture - 28\nGraph Foundations - Module 4 (Diamond Inheritance)\n(Refer Slide Time: 0:11)\n\nWelcome to the final module of the fifth week in Getting Started with Competitive Programming. So, we continue to look at the applications of graph traversals specifically BFS DFS, and our final example is going to be a problem called Diamond Inheritance. This appeared in Round 1C of the 2012 edition of Google Code Jam.\nAnd one of the reasons we picked this problem was because it gives us an opportunity to work with directed graphs, which I think is interesting. It is good to know that the traversals work out pretty much the same when you are working with directed graphs. But there are also some subtleties that crop up and that are good to be aware of. So, alright, let us get started by looking at the problem statement.\n(Refer Slide Time: 00:56)\n \nWe are told that we need to help diagnose class diagrams to identify instances of diamond inheritance. Now, if you have done object-oriented programming, you might have already encountered this phrase, Diamond inheritance. Some places would more colorfully call it the deadly diamond of death. And the reason is that this is essentially an instance of an ambiguity that occurs when you have basically messed up inheritances that look something like this.\nSo, if you have not done any object-oriented programming, and all of this sounds strange, then do not worry about it. But for those who are familiar with notions of inheritance in that context, basically, suppose you have four classes with two classes inheriting from a common class. So, let us say for instance, that B and C inherit from A and then class D inherits from both B and C. That is also the diagrammatic notation here.\nSo, we see that an arrow pointing from X to Y, for example, from D to C indicates that D inherits from B. So, we have that D inherited from B and C, and B and C inherited from A. So, suppose you have a method in class A that is overwritten differently by B and C, then when D inherits from B and C, what version should it use? It becomes somewhat ambiguous. And this is why you are probably interested in knowing if you land up in this sort of situation.\nNow, if the class and method kind of terminology does not make sense, then do not worry about it. You could just think of this as a situation where you have four nodes or vertices. And wherever they are connected in this very particular way, then we say that we have an instance of diamond inheritance. And this is what we are required to detect. But it does not have to be just four vertices. So in the problem statement, they go on to tell us what exactly we are looking for in slightly more formal, more precise terms.\n(Refer Slide Time: 03:08)\n\nSo, let us take a look at what we really mean when we want to say that there is diamond inheritance. So, first, let us talk about an inheritance path. So, an inheritance path from X to Y is defined as a sequence of classes, X, C1, C2, and so on up to Cn and then followed by Y, where X inherits from C1, Ci inherits from Ci + 1 for all ‘i’ between 1 and n - 1. And finally, Cn inherits from Y.\nSo, this might remind you of the notion of a path that we talked about when we were discussing the notion of connectivity in the second module. And there a path was simply a sequence of vertices, such that every pair of consecutive vertices has had an edge between them.\nAnd now this is pretty much the same idea. You would just have to think of your classes as being vertices of a directed graph, and you add an edge between two vertices if the corresponding classes are such that one inherits from another, and you make sure that the orientation respects the direction of the inheritance.\nNow in this graph, an inheritance path is simply a sequence of vertices so that the consecutive vertices have a directed edge going between them connecting the vertex that appears earlier in the sequence with the vertex that appears later in the sequence. So, you can map this notion of an inheritance path as applied to classes to a directed path in the graph that you derive from these classes.\n(Refer Slide Time: 04:44)\n\nSo, we say that a class diagram has a diamond inheritance if there exists a pair of classes X and Y, such that there are at least two different inheritance paths from X to Y. That is the definition of a diamond inheritance. So, essentially, it does not have to be literally a diamond on four classes, it could be a longer chain in some sense. But as long as you have two classes X and Y so that there are two different paths from X to Y, then you have an instance of diamond inheritance.\nIn the language of graphs, essentially, you are looking for two vertices, X and Y so that there are two different paths that connect X and Y. And these are paths in this directed graph. So, just to make sure that we are on the same page, let us actually take a look at one of the examples given in the sample input.\n(Refer Slide Time: 05:36)\n\nSo, the format of the sample input is such that the first line tells you how many classes there are. So, in this case, there are five classes. And then this is followed by as many lines as there are classes. So, you can see that you have five lines. On the ‘i’th line, the first number tells you how many classes does the ’class i’ inherit from. So, for example, the first class here inherits from two other classes.\nAnd then the next two numbers on that line tell you the IDs of the two classes, or in general, there is going to be as many numbers as there are classes that you inherit from. And each of these would correspond to the IDs of the classes that you inherit from. So, that was a bit of a mouthful. So, let us just walk through this example. We see that the first class inherits from 2 and 3, so we have those arrows there to the classes 2, and 3.\nThe second line corresponding to the second class has just one inheritance, and that is from class 4. So, we have an arrow from 2 to 4. And then the third line corresponding to the third class again has one inheritance. And that is from class 5. And then we have the fourth class also inheriting from 5 and 5 has no inheritances. So, 5 does not have any edges going out of it. So, what sort of an instance is this?\nDoes this have ‘diamond inheritance’ or does it not? Well, I mean, you may not see a direct diamond on four vertices. But as we said before, it could be a more indirect diamond structure. So, if you can spot that diamond structure, then you would say the answer is yes. Otherwise, you would probably not be so sure. So, if you need a moment here, please feel free to pause and ponder for a second before you commit your answer.\nAlright, so you can probably see here that there are choices of X and Y for which we can say that there are two distinct paths between X and Y going from X to Y. So, let us say that X, for instance, is 1, and Y is 5. So, you have the path 1 2 4 5 on the one hand, and then 1 3 5 on the other. So, these are two paths going from X to Y that are different from each other. And that is why you would say that in this case, you do have a diamond inheritance.\nNow let us talk a little bit about what does it mean for the two paths between X and Y to be different? I think there are two natural interpretations of the word ‘different’ as given in the problem statement.\n(Refer Slide Time: 08:16)\n \nSo, the first interpretation could be that these two parts are completely disjoint from each other. And the other could be that they differ on at least one vertex other than the endpoints. Of course, when I said completely disjoint, once again, you exclude the endpoints because these two paths, of course, start and end at the same vertices, namely X and Y. So, let us just argue that it does not really matter which interpretation you go with, they actually amount to the same thing in the following sense.\nSo, first of all, if you have two paths that happened to be completely disjoint, except for the endpoints, then, of course, you do have two paths that differ on at least one vertex because, well, of course, they differ on all vertices, and there is at least one vertex other than X and Y. So, if you have two paths that are different in the first sense, then they are also different in the second sense.\nOn the other hand, suppose you have two paths that are different in the second sense, they differ on at least one vertex, then I would argue that you can find X and Y, maybe not necessarily the same X and Y. But you can find, you know, probably a different diamond of the first kind that is different in the stronger sense of being completely disjoint.\n(Refer Slide Time: 09:30)\n\nAnd the way to see this is that well, let us take a look at the two paths that differ on, you know, at least one vertex. So, here are two paths that are overlapping at a couple of vertices, and are at least different in a few places as well. And X and Y are the two red vertices at the extreme ends. So, basically, what you could do is jot down the list of vertices on these two paths that are guaranteed to differ at at-least one vertex, and essentially you pursue these paths simultaneously.\nIt is possible that the first few vertices are also common. So, you just make a note of the first time that you see two different vertices on the two paths. And then you make a note of the first time that, once again, the paths converge. So, for instance, here, the yellow vertex in the middle is the first time that these two paths end up having a common vertex. And the red vertex is essentially where we started and the paths immediately diverged.\nIt is possible that after the red vertex, you had a little bit of a common thread for some time, in which case, we would push the red vertex forward until the path began to diverge. And notice that it must diverge at least once because we know that they are different at, at least one vertex. So, in this example, choosing the left red vertex and the yellow vertex in the middle as our new choices for X and Y, we get a diamond inheritance.\nIn the first sense, we get a pair of paths that are different in the sense that they are completely disjoint, except for the endpoints, just by the way that we chose them. So, it does not really matter which of these definitions you work with. And for the most part, we will try to be looking for paths that are completely disjoint internally apart from X and Y because that is just going to be generally more convenient.\nAlright, so how are we going to solve this problem? So, essentially, we are looking for something that looks like a cycle in the underlying undirected graph. But in the oriented sense, it is essentially the union of two paths that start and end at the same vertex. So, well, let us think about performing, for instance, a DFS.\n(Refer Slide Time: 11:46 & 12:24)\n \nAnd let us think about what happens when you visit one vertex more than once. Does that tell us something about the potential existence of two different paths? Well, this is meant to be a bit of a hint. So, if you like, please feel free to pause here. And think about if a vertex being visited more than once by, in fact, either a DFS or BFS traversal is something that could help you detect instances of diamond inheritance. Come back once you are ready, and you have given this a thought.\nAlright, so just to make this a little more specific, let us go back to the DFS code that we have been working with. And basically, the question I am asking is, suppose you encounter a vertex, which you have already visited. So, in particular, you are looking up the neighbors of the current vertex. And let us say the first neighbor that you find is a vertex that is already been visited before.\nSo, what does this mean for us? For DFS, of course, it just means that this is a vertex to be avoided. So, it is just going to move on. But for the problem that we are solving right now, this vertex is an interesting vertex because, well, because it was visited, we know that there is already some way of reaching this vertex from the route. And the fact that we are approaching it again, probably means that there was a different route for arriving at this vertex as well and maybe this is a sign that there is some diamond inheritance.\nNow there are two questions that are pertinent at this point. First of all, can we be sure that there is indeed an instance of diamond inheritance if a vertex is visited more than once? And the second thing is, is it possible that there is some diamond inheritance somewhere, but perhaps it does not get identified in this way? So, perhaps if you do encounter this situation, you can be very sure that yes, we do have a diamond inheritance.\nBut if you do not encounter this situation, perhaps there was some instance of diamond inheritance, but you missed it. So, you have to kind of convince yourself in both directions. So, again, I think this is a more elaborate version of the hint and again, if you want to think about things, this would be a good time to pause. When we come back, we are going to actually try and argue both of these aspects of what we are trying to claim here.\n(Refer Slide Time: 14:21)\n \nAlright, so let us do this one step at a time. My first claim is that if the DFS traversal finds some vertex more than once, then there is in fact an instance of diamond inheritance somewhere in this graph. So let us see why. So, since we are considering a vertex that was visited by DFS more than once, let us just consider the scene when it is being visited the second time.\nSo, this means that it was already a visited vertex, and somebody is approaching it again through the DFS traversal. Of course, DFS will kind of ignore this, but we just want to detect this and see if there is something that we can conclude from here. So, let the red vertex denote the visited vertex and let the pink vertex denote the current vertex, which has essentially approached the visited vertex. And as I said in the original DFS implementation, DFS is just going to ignore this vertex and move on.\nBut we want to freeze time here and think about what happens. So, since the read vertex is a visited vertex, it must be the case that there was some path to this vertex from the source. That is why it was visited in the first place. So, we got here somehow, and this path could have been a more, it could have been a more tree-like structure in terms of how the actual traversal played out. But from whatever that structure was, you can extract a path that is fairly straightforward to check.\nSo, I leave that to you to, sort of, confirm offline. But basically, the point is that there is a path from the source vertex to the visited vertex. Now similarly, this is also true for the current vertex. The current vertex is just being visited. And therefore there is some path from the source vertex to the current vertex as well. Now, these paths may not be different in the sense of being completely disjoint.\nSo, for instance, this path could look something like this where there is some overlap with the path from the source vertex to the other visited vertex as you can see here. But because of what we have already argued, as long as we have two paths that are different, and we know these paths to be different because they at least differ on, for instance, the pink vertex and the vertex that is the parent of the red vertex. We know that these vertices cannot possibly be the same.\nSo, since these are two different paths from the source vertex, the vertex in blue to the visited vertex, which is the vertex in red, we know from our previous argument that we can from here actually derive a pair of paths, which are in fact completely internally disjoint. So, therefore, we do have an instance of diamond inheritance. So, that works.\n(Refer Slide Time: 17:17)\n \nNow, is it true that if there is some instance of diamond inheritance somewhere, then there is some DFS, which is going to catch hold of it using this strategy that we have just described? So, in particular, we claim that if there is an instance of diamond inheritance between the vertices X and Y, then if we were to start a DFS from X, then this DFS traversal will, in fact, visit Y more than once for sure. So, to see this, let us prove an auxiliary fact first.\nIn a directed graph, if you have a path from U to V, then V is going to be visited in the DFS that originates at U. This might sound like a reasonably obvious thing to say. But let us just be sure by arguing this a little bit formally. So, suppose not. Right. So, suppose there is a path from U to V. But V is not a visited vertex in the DFS starting at U. Then, well, let us look at this path from U to V.\nAnd let us identify the last vertex on this path that was visited. So, this is well defined, because U is definitely a visited vertex. That is where it all started. And let us just try and pinpoint the last vertex on this path that was visited. Well, whatever that last vertex is, it is not V because we are assuming that V was not visited for the sake of contradiction. So, that last vertex is lying somewhere in the middle of this path.\nBut now notice that the way DFS works is that it is going to approach every out neighbor of this vertex, which was presumably the last visited vertex on this path. And at that point, it would have certainly approached the vertex, which was the very next vertex on this path. And therefore the next vertex would have also been visited contradicting our choice of, you know, the last visited vertex. So, if this argument went by a little bit too quickly then there is a link in the description of this video, which has a write-up of the proof of this fact that every reachable vertex is in fact visited. And you could take a look at that as well. But why are we interested in this fact?\n(Refer Slide Time: 19:29)\n\nWell, remember, what we are given is the fact that there is some diamond inheritance between X and Y. And we want to argue that Y has been found twice by the DFS starting at X, at least twice. So, what does it mean that X and Y are witnessing diamond inheritance? It means because of what we showed earlier, we could just assume that there are two internally vertex disjoint paths between X and Y. So, here are these two paths, for example.\nAnd now let us just look at the vertices that appear just before Y on these paths. Right. So, these are the two pink vertices. Notice that these two pink vertices are reachable from X, therefore they are going to be visited by the DFS traversal starting at X. But if they are visited, then whenever both of these vertices are visited at whatever times, they are going to try and approach Y. Now at this point, Y may or may not be a visited vertex. Let us say that the pink vertex is visited, let us say that the pink vertex that is on the top path is visited first.\nAnd when it approaches Y, perhaps Y is not a visited vertex, or maybe it is being visited already, it does not really matter. The point is that because both of these pink vertices are visited vertices in the DFS traversal starting from X, both of them will witness at least one ping to Y. So, this proves the fact that if there is a diamond inheritance between X and Y, then for sure, you are going to approach Y more than once in the DFS traversal starting at X.\n(Refer Slide Time: 21:08)\n  \nSo, this is the statement that we just proved. And this also motivates our solution. So, how would we basically take advantage of the facts that we have just shown and wrap it up in an algorithm that will help us identify diamond inheritance?\nWell, what we could do is, essentially, guess all possible choices of X. We do not know where the diamond inheritance might originate. So, we simply try all possible vertices. But having fixated on a vertex, essentially, we run a DFS starting from that vertex and watch out for whether this event happens that some other vertex is approached twice, is reached twice, by the DFS traversal. It does not have to be exactly two times, of course, what is important is that it is reached more than once. That is what we want to watch out for.\nAnd notice that this guessing of X is really required. You cannot just start a DFS at your favorite vertex and, you know, if this did not happen, no other vertex got approached more than once, you just call it a day and say that there is no diamond inheritance, that will not work. And I want to flag this and emphasize it because in our example, so far, it has basically not really mattered where we start our BFS or DFS, we just say started at some vertex and, you know, be done with it.\nBut here, you really have to initiate your DFS from every possible vertex. I mean, just to really emphasize that it would not work if you just started from your favorite vertex. Let us go back to the example that we had, where we did have diamond inheritance, this was one of the sample inputs. And now imagine starting your DFS at vertex 5, for instance. You are not going to be able to detect this diamond inheritance here, because the DFS from 5 will simply make no progress. There are no neighbors going out of 5, and therefore the DFS will really not do any work.\nSo, it is really important that you try every single vertex. But once you do that, everything that we have argued so far essentially amounts to proof of correctness for the approach that we are just proposing here. So, with all of that said, I think we are ready to take a look at the implementation.\n(Refer Slide Time: 23:25)\n \nSo, let us go to the standard DFS that we have. So, the first few lines are exactly identical to what we normally do. But what is new here is this else block where we say that look if this is not the first time that we are seeing you, then that means that we have found what we want. So, let us just return and let us make a note of this fact. And the way we do this is or at least the way that I have done it in this implementation is to change the status of a global flag variable.\nSo, we reset ‘flag’ to false, and then basically, this is the outer loop where we are guessing X, and we said that we will run a DFS starting at every vertex. So, that is the ‘for’ loop here right on the top. It is basically trying to run a DFS starting from ‘i’ with ‘i’ ranging from 1 to n. And of course, before you run DFS, make sure that you clean up your visited array so that it is all fresh and ready to use.\nAnd when you come out of DFS, you just check the flag variable. If the flag variable has been set to false that means that you actually found an instance of diamond inheritance and you can return as much. You can say well yes, you did find diamond inheritance. But if this was never triggered, and you tried a DFS starting from every single vertex, then at that point, when you come out of the outer for loop, if you actually survived the whole thing, and you did not return control from inside the for loop, then outside the for loop, you can say, well, there is no diamond inheritance in this instance.\nAnd you can say that with confidence because of everything that we have just argued. So, as usual, this being a Google Code Jam problem, the overall input is going to have a bunch of test cases. So, you want to be careful about remembering to reset your flag variable as you go from one test case to the next one.\nNot doing this will obviously lead to inaccurate answers. And I am speaking from experience. So, make sure that you reset your flag variable properly. I am not showing you the part of the code that does the input-output because that is by now fairly routine. But if you want to take a look at the entire code that actually works, then you can find it in the usual place at the official repository for these lectures.\nAnd once again, all of this code is in C++. So, if you are able to rewrite it in your favorite language, please do that. And please do submit a pull request. So, with that, we have come to an end of our exploration of applications of BFS DFS traversals. And I hope that you enjoyed this. A quick parting comment is in order. So, all the examples that we saw this week, I think by just looking at the problem statement, the graph formulation, basically, was really quite transparent.\nIn the problems of bipartiteness and covering you were literally given a graph as a part of the problem statement and you just had to work with that quite directly. And here, although there was some language with respect to classes, inheritance, and so on, it was really quite clear that this is screaming for a graph formulation. So, this was quite, quite evident. Sometimes the interesting thing about BFS DFS applications and with some of the other things that we will see in the weeks to come, interesting thing is that the graph formulation itself is not so obvious.\nSo, you might be given a problem with permutations, or there might be some random story about something that looks like it has nothing to do with graphs. And yet, the whole problem can be solved quite nicely by just finding the appropriate graph modeling. So, you will find a few practice problems in the extras section on the course website, which give you a couple of examples where I think the graph model is a little less obvious.\nBut since this was the first week that we were talking about graph algorithms, I felt that was okay to focus on problems where you do not have the additional burden of modeling a strange situation as a graph. That does require some imagination and creativity. And we will have plenty of opportunities to see that play out as we go over examples in the coming weeks. So, I hope that you are all excited to be doing more problems based on graphs and I hope that you had a good time with BFS and DFS.\nSo, please let us know what you thought through either the comments on this YouTube video or by letting us know on the Discord community. You could join the conversation there or on the Google Groups mailing list, especially if you are watching this during the active run of a course. Thank you very much, and we will see you back next week. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec29.html",
    "href": "materials/cpnotes/Lec29.html",
    "title": "Shortest Paths - Module 1 (Dijkstra’s Algorithm)",
    "section": "",
    "text": "Lecture - 29\nShortest Paths - Module 1 (Dijkstra’s Algorithm)\n(Refer Slide Time: 0:11)\n\nHello, and welcome to the sixth week of Getting Started with Competitive Programming. So this week, our focus is going to be on the ‘shortest paths’ problem, which is both a very fundamental problem in graph algorithms as well as a really popular theme in contest programming. Typically, you are trying to figure out what is the fastest way of going from one vertex to another in a given graph.\nAnd in this module, which is broken up into four segments for your convenience, we are going to be leading up finally to this problem called ‘sending email,’ and we are going to see Djikstra’s algorithm along the way. But before we get started, let me give you a high-level overview of the different scenarios that we will be addressing this week.\n(Refer Slide Time: 01:02)\n\nSo, generally speaking, we will be working with graphs that are weighted and directed. To say that a graph is weighted, in this context, simply means that there is a weight function that maps every edge in the graph to some number. So actually your weights could be any collection of objects that you have the ability to add and compare. But specifically, we will typically be working with integers and sometimes rational weights.\nAnd to say that the graph is directed, we already know what this means from our discussions last week. But just to repeat, a graph is directed if we think of every edge as being oriented, or we think of the edges as being ordered pairs. So (we distinguish) for a pair of vertices x and y, we distinguish the pair x y from the pair y x.\nSo that is going to be the setting that we are working in. Now we are going to start this off by looking at the special case when all the edge weights are one. This is just another way of saying that you are working with an unweighted graph. Now in this situation, the nice thing is that the cost of a path is simply the number of edges on it.\nNotice that when you have weights, this need not be true because depending on how the weights are, it could be that you have a path with a small number of edges that is super expensive, and you have paths with a large number of edges which are cheap. Again, just because of the way the weights are. When all the weights are uniform, this is not something that you have to worry about.\nSo the lengths of the paths are actually a true reflection of the cost of the path as well. Now, this setting is simple enough that we have actually already seen an algorithm to resolve the problem in this case. And our first exercise will be, essentially, to recap a breadth-first search and consider how it helps us solve the shortest path problem in this special case.\nAfter this, we will allow for weights to enter the picture and we will see that BFS no longer quite works in its default form, and we will have to explore a different way of approaching the problem. But we will still restrict ourselves first to the setting when all edge weights are positive because that is a little bit easier to think about compared to the more general case when we allow for negative edge weights.\nThe thing about negative edge weight is that it can, again, mess up your intuition for what you expect to happen when you are dealing with the shortest paths. So we are going to explore this distinction as we go along. So to begin with, we will not allow for negative edge weights and then we will allow for them. But then we do allow for them again we are going to do it in two phases.\nFirst, we will allow for the presence of negative edge weights but we will disallow the presence of a negative weight cycle. Now a negative weight cycle in a graph is simply a cycle which is such that if you were to go around the cycle and add up all the weights of the edges that you encounter, then the cumulative rate is going to be negative. Now you will have to take my word for this at the moment that this distinction is actually important.\nThe presence of negative weight cycles can cause some substantial disruption in the notion of shortest paths. So we will need to handle them carefully and separately. So in the setting when we also allow for negative cycles, we are going to see an approach that is different from the one that we take when we know or we assume that there are no such cycles.\nSo this is going to be the essence of the three different approaches that we take to the shortest paths problem. First, we are going to see an approach when the graph is essentially unweighted, then we are going to look at an approach that works for positive edge weights, and we are going to modify that slightly to allow for negative arcs, but still, we assume that there are no negative cycles.\nSo I am thinking of this as the second broad approach, and the third approach is going to be when we also allow for negative weight cycles and we will talk about that more when we get to it. Finally, we will also deal with separately the problem of all pairs’ shortest paths.\nNow, it turns out that if you know how to do shortest paths, then you can more or less trivially also find shortest paths between all pairs, by simply running this algorithm as a sub-routine between all pairs. But it turns out that there is a slightly faster approach to this problem which is very elegant and, you know, we are going to explore that and implement it as well.\nSo, as is usually the case, we are going to describe these algorithms and describe their implementations, but we will not really have the time to get into proofs of correctness, which are also important to just have a feel for and to appreciate and understand. So if you are curious about which algorithms we are going to be learning so that you can go look them up in more detail after we are done, then I am just going to throw in the names here.\nSo, first, the case of unweighted graphs, as I mentioned, is really the breadth-first search traversal that we discussed last time. And the case when all edge weights are positive can be handled by Djikstra’s algorithm and a slight modification to Djikstra’s algorithm makes it work even when we have negative edge weights but we do not have negative weight cycles.\nOnce we do allow for the possibility of negative cycles, there is the Bellman-Ford algorithm which allows us to either determine the shortest paths correctly or detect the presence of such a cycle. And once again, when we get to this discussion in more detail, you will see why this sort of output actually makes sense. And for All-Pairs Shortest Path, the improvement that we are going to look at typically goes by Floyd Warshall.\nNow, I should mention that shortest paths being a really fundamental graph algorithms problem has been extensively studied, and some of these algorithms were proposed by several other researchers who are not mentioned on this slide. So if you are interested in the rich history of shortest path algorithms and how some of these really popular ones came about, I would highly recommend the chapter on shortest paths in the ‘algorithms text’ by Jeff Erickson.\nThis book is conveniently available from the textbook’s website and I am going to add a link that you can follow in the description of this video. So please do check it out. It has many more details about how these algorithms came about, and there is a nice historical perspective that you will gain if you were to go through this.\nIn the meantime, let us now get started with the special case when all edge weights are one. That will be the focus of this segment. And in the next two segments, we will consider Djikstra’s and modified Djikstra’s approaches, and we will round this off by looking at an implementation in the context of the sending email problems. So that is going to be the plan for this module.\nIn the next module, we will look at Bellman-Ford. Again, we will split it into two segments. In the first, we will study the algorithm itself and in the second we will implement it in the context of a problem. And then in the third and the final module, we are going to do the same for All-Pairs Shortest Paths as well.\n(Refer Slide Time: 09:04)\n \nOkay, so that is the outline. Now, let us get started with the first case, and let me just begin by recapping the definitions for you here. So as we said, we will be working with weighted, directed graphs.\nTypically you might imagine that you have been given two vertices, which we will usually refer to as the source and the target, and you are trying to figure out what is the path that connects the source to the target that has the cheapest cost.\nThe cost of a path is simply the sum of all the weights of the edges that participate in the path. So this quantity that we have just described here is often referred to as the distance. So we will talk about the distance of the vertex T from the source S as being the length of the shortest path that connects S to T.\n(Refer Slide Time: 09:51)\n\nNow this problem that we have just described is often just called the shortest path problem, so you are given two vertices S and T, and you want to find the length of the shortest path from S to T. A very popular variant is the single-source shortest path problem, SSSP, where you are given a source vertex and you want to know the distance of every other vertex from this source. And this is something that you can of course solve by just solving the shortest path individually on every vertex.\nThat is a valid algorithm. But sometimes it is just useful to think of this more holistically and you could come up with better ideas, which solve SSSP in one shot, so to speak. And the SSSP problem will pretty much be our focus for all of this module, and even the next one. But after that, we will turn our attention to this All-Pairs Shortest Path problem which is again a very popular variant. So here we want to know the distances between every pair of vertices in the graph.\nAnd once again, of course, if you know how to do SSSP, you can do APSP by simply running SSSP as a subroutine. Right. So you run an outer loop, which runs through every vertex, and for every vertex, you just run your SSSP algorithm, and you will then end up having discovered the distances between every pair of vertices.\nNow, that is going to have a certain complexity, which is basically the complexity of the SSSP algorithm with a multiplicative overhead of n, n being the number of vertices. And an interesting question is, can you do better? Can you somehow solve APSP directly? And it turns out that we will have some ideas to address that question as well.\nSo these are the three problems that we will be considering. And before we actually get to try to understand what happens when all edge weights are one, let me also get a little more terminology out of the way.\n(Refer Slide Time: 11:50 & 13:03)\n \nSo, you might remember from the previous week, that we defined a path as a sequence of vertices where every consecutive pair is connected by an edge. And in the context of directed graphs, you want the edge to be from say U I to U I +1 if you are looking at the ’i’th and the ’i+1’th vertices of the sequence. So they have to be oriented exactly in the way that you expect them to be. So that is a path.\nAnd notice that when we define a path, we do not really have any constraints on whether vertices can repeat or not. So by default in a path, you could have a repeating vertex. And if you insist that you do not want vertices to repeat, you want all the vertices on the path to be distinct, then you emphasize that by calling it a simple path.\nSo whenever we refer to paths, we will, generally speaking, allow for repetition of vertices. If we want to emphasize that vertices are not being repeated then we will use the phrase simple path instead. Now as long as you are working with non-negative edge weights and you want to observe shortest paths, this distinction is not very important because all of your shortest paths will automatically be certain paths only. To see this, let us look at an example of a path, which is not a simple path.\nSo here, for instance, starting from S, suppose we go to T in this way. So notice that the vertex x is getting repeated, and then we finally land up at T. And imagine that all the edge weights are one here. It should be reasonably obvious that this is not an optimal path from S to T because this whole detour that we did on the cycle X R Q P could have simply been avoided.\nSo whenever you have a path with these repeated vertices, if you just eliminate the detours then you will see that you always end up with a path that is better than the one that you started off with. So as long as your edge weights are non-negative, your shortest paths will automatically turn out to be simple paths. From this example, you can probably already start getting some sense of why negative cycles can be problematic for the definition of shortest paths.\nThis is something that we will explore more fully later but I just wanted to drop a hint in case you were curious about that. But just went back to our definition here, this is just a reminder that whenever we talk about paths, in general, we will allow for repeating vertices. And whenever you are working with non-negative edge weights, your shortest paths will automatically turn out to be simple paths, anyways.\n(Refer Slide Time: 14:23 & 14:54)\n \nNow, in terms of terminology, I should also point out that in some references, in some textbooks, especially graph theory textbooks, what we are calling a path is usually called a walk or a trail. Okay, and what we are calling a simple path is actually just called a path. So this can sometimes be confusing depending on where you are reading from.\nSo it is just useful, I think, to fix one terminology and stick to it in a particular discussion and since this is the tradition and most algorithms books that you will read, I will just stick to this terminology where a path is a sequence of vertices where the constitutive vertices have an edge between them and the vertices need not be distinct. And if I want to emphasize that the vertices are distinct, I will refer to it as a simple path.\n(Refer Slide Time: 15:18 & 15:42)\n \nSo, with that out of the way, let us finally talk about what can we do when all the edge weights are one. So for this special situation, as we have hinted to earlier, we already know an algorithm that determines the distances from any source vertex for us. And this is in fact the breadth-first search or the BFS traversal that we have seen in the previous week.\nSo, in fact, let us pull up the implementation to remind ourselves of what we were doing. So we had this distance array, which was initialized so that every vertex was initially at a distance of infinity from the source, meaning that these were all unexplored vertices and we do not know anything about how close or how far away they are from the source in the beginning. And the only thing that we know is that the source is immediately reachable from itself. So the distance from the source to itself is initialized to zero.\nAnd after this, we had an implementation where we essentially explored all the neighbors of the source first and then the neighbors of the neighbors, and so on and so forth. At every stage, we were careful to not revisit and already visited. And if you draw out a typical BFS traversal you will see that there is a natural layer-like progression. The BFS tree can be organized fairly naturally into layers and it turns out that all the vertices that are in the ‘k’th layer are in fact at a distance ’k’ from the source and this is something that you can prove.\nNow, although we will not be doing a formal proof of why BFS works as claimed, I would like to go through an example just to build some intuition for why you might expect to believe that this works out the way that it does. For this, it is crucial to understand how vertices enter the ’k’th layer in the BFS traversal.\nNow, our code here already has a trigger, which helps you understand when a new layer has started. This is the first time that the distance of the vertex that you are currently exploring mismatches with the layer number that you are currently storing. So when that happens you can print a statement saying that a new layer has just begun and, of course, after that, you update the layer variable, and so on.\n(Refer Slide Time: 17:42 & 18:38)\n \nBut to help our visualization along, I am just going to introduce a conceptual intervention here, which is the idea of using a token to keep track of what is going on with the layers. So this token is a completely artificial concept. It is just in our imagination. You do not have to change or update your code or anything like this. Just follow along with the example that I am going to show you.\nSo the way the tokens are going to work is that, to begin with, we are going to enqueue the source and a token right behind it. And in general at any step, if we pull a token from the head of the queue, then we will just take the token and push it back to the end.\nNow, the idea is that whatever vertices are sandwiched between these two token operations, so to speak, are the vertices that get into a common layer of the BFS traversal. I think this will become clearer as we go through an example. So let us do that.\nSo here is a graph with a source vertex that is been highlighted. So to begin with, as we said we have on the queue the source vertex followed by a token. Now, when we are currently processing the vertex at the head of the queue, what does BFS do? It is going to figure out what are all the neighbors of this vertex that is currently in the limelight, what are all of its neighbors that have not been visited yet.\nAnd we are going to collect all of those vertices and push them to the back of the queue. Now since this is the very beginning, no vertex has been visited so far. So we will just pick up all of the neighbors of S. In this case, there are three neighbors X, Y, and Z, and we are going to push all of these to the back of the queue, and we are going to mark them as visited.\nNow, as you can see, S left the queue and we pushed the token to the back because the token was the next thing on the queue. And now the next vertex to get processed – the vertex in the head of the queue is the vertex X, and X has two unvisited neighbors. I mean it has altogether four neighbors, but only two of those are unvisited so far. So we are going to queue these up, R and P at the end of the queue, and we are going to mark them as visited.\nLet us bring the queue a little bit to the left so we have a little more space. And at this point, we have finished processing the vertex X. So we will let X exit the queue. And now I am going to color code X with a different color because this is, notice, a shift in the layer numbers. So we have the first layer is, by default, just the source vertex.\nAnd now, until the next time that we see a token, all the other vertices are going to be on the first layer. So I am going to mark all of these vertices ‘yellow,’ just to remember that these have been processed, and they were members of the first layer. So the second vertex in the first layer is vertex Y. So this is our current active vertex. It has only one unvisited neighbor. So we are going to identify this neighbor T and push it to the back of the queue.\nNow, we will let go of Y and again mark it as a vertex that was processed as a part of the first layer. Now the last vertex in the first layer is the vertex Z, and Z has two unvisited neighbors. So let us identify U and V. So we go ahead and add U and V to the back of the queue. At this point, we are ready to let go of Z and we also remember to mark Z as the last vertex to be processed in the first layer.\nNow we see the token, which is a signal that we have finished processing all the vertices in the first layer. So we push the token to the back and we are now mindful of the fact that we have started off a new layer which in this case is going to be the second layer. So let us see what happens in the second layer. The first vertex at the head of the queue is the vertex R and R only has one unvisited neighbor, which is Q.\nSo we identify Q and add it to the back of the queue, and then we let go of R. When we look at P and T, which are the next vertices in the queue, they have no unvisited neighbors. So we simply mark them as being processed. And notice that now the color-coding has changed to denote the fact that we are processing vertices in, now, the second layer. So the next vertex is U and U does have an unvisited neighbor which is W.\nSo we add W to the back of the queue, let go of the vertex U, mark it as processed. And finally, we see V, which has no unvisited neighbors. So we simply let it go. And again mark it, as being processed. And the next thing on the queue is the token, which tells us that we have finished processing all the vertices on the second layer, and this marks the start of a new layer, which in our case is going to be the third layer.\nSo as before, we push the token to the back, and we process the two vertices that we have on the third layer. None of these vertices have any unvisited neighbors. So we are simply going to run through them and let them go and just mark them as being vertices in the third, and in our case, also the last layer because now the only thing left in the queue is the token, which is a sign that BFS has run its course and the algorithm is now complete.\nSo if you were to look at the sequence in which the vertices got processed, organized by layer, you will see that this is how everything panned out. So we started with the source which was on layer zero, and then on the first layer we saw its immediate neighbors X, Y, and Z. And X, Y, and Z were responsible for pulling in collectively the vertices R, P, T, U, V on the queue that constituted the second layer. And these guys brought in Q and W.\nHopefully, it is intuitive that when you are on layer number k, you are at a distance of k from the source. It is clear that you are definitely reachable within k steps. That is for sure because you can just follow your parent pointers and trace your way back to the source. The only question and the thing that actually requires proof is to say that you cannot do it any faster. You cannot do it with fewer steps.\n(Refer Slide Time: 24:23 & 25:07)\n \nAnd the intuition for that is that if you could do it with fewer steps, then you would have been recognized, and you could have been pulled in earlier in a previous layer. This is something that you can formalize using induction. And here are a couple of statements that you may want to think about proving if you have not seen formal proof of this in a previous class. It is worth sitting down and trying to work through this.\nSo essentially, we are saying that when you are at the end of the ’k’th phase when you look at a vertex, its distance is either infinity, so this is distance as recorded in the distance array. So either it is so far an unseen vertex, or if it is a seen vertex then the value that is recorded in the distance array is going to be at most k. And it is exactly k if and only if you are in the queue at the ’k’th phase.\nAlso, the correctness of BFS in the context of capturing distances is given by this claim here, which says that once BFS is done, the values in the distance array are a true reflection of the actual distances in the graph. This is something that you can prove using induction. As usual, I will not be going into proof here. But if you are interested, you could either try figuring this out on your own, or you can look up the pointers in the description of this video where you can read up on proof of this fact.\n(Refer Slide Time: 25:52 & 26:17)\n \nSo the main takeaway from our discussion so far is that if you have an unweighted graph, then BFS is your best choice in terms of computing distances between vertices. However, once edge weights come into play, then BFS might not work out. So in particular, you could try to pause the video here and come up with an example of a graph where BFS does not do the right thing in terms of capturing distances when edges have weights on them. So feel free to pause the video here and come back once you have had a chance to think about this.\nAlright so here is an example. It is a graph with just three vertices, and the edge weights are as shown. And you can see that if you are trying to figure out the distances from the source to all the remaining vertices, then the best way to get from S to B is not via the direct edge, but to actually take a detour and go via A because that is how the edge weights have been set up.\nOn the other hand, because the way BFS works is the algorithm is not really trained anywhere to account for the weights at all. It is just going to blindly pick up both the neighbors of S in the first layer of the exploration. So both A and B will have the same status as vertices on the first layer. And if you were to do backtracking to find the shortest path, then BFS would tell you that the best way to reach B is via the direct edge from S, which in this case is not quite right.\n(Refer Slide Time: 27:27 & 27:39)\n \nAnd it is not surprising once again because BFS is really not trained to look at weights at all. So you could try to fix this in some sense, by making BFS see the weights by potentially messing around with the graph a little bit. So one thing that you could do, which is actually a pretty common trick is to puncture the edges that have weights on them as many times as the weight, roughly.\nSo actually, ‘weight - 1’ many times, so that the edge, which previously was just a direct edge is now automatically elongated to reflect the actual weight of the edge. Now, of course, this will work as long as your weights are positive integer weights so that you can do this puncturing an appropriate number of times. And you can convince yourself that if you run BFS on this modified graph, things will actually work out and you will get the correct distance values.\n(Refer Slide Time: 28:47 & 29:02)\n \nSo this feels like a tempting way to prolong the usefulness of BFS. So at least when you have positive integer weights, maybe you can actually do this. Would I recommend it? Well, unfortunately, no, not really. The reason for that is that this operation of subdividing the edges and inserting these artificial dummy vertices can be extremely expensive. And, in particular, the graph that you generate by doing this trick – the number of vertices in this graph, as you can imagine, is going to be proportional to the weights of the vertices.\nSo if you have the weights of the edges, sorry, so if you have edges whose weights are rather large, you are going to be creating a humungous graph that you do not really want to deal with. Instead, what you might want to think about is – Come up with a way to predict the behavior of BFS. Really the key thing that you want to think about is, what is the next real vertex, not the dummy vertices, what is the next real vertex that BFS is going to add to the queue in this modified graph.\nAnd if you can distill the essence of BFS’ behavior on this graph, if you can predict properly which is the next vertex that gets added to the queue, then hopefully you can bypass the creation of this intermediate graph and you can directly write an algorithm that will do the right thing for graphs that have non-negative edge weights.\nSo that is more or less what we are going to do, and that is going to lead us to a discussion of Djikstra’s algorithm which is what is coming up in the next segment of this video. So before you watch that, maybe just think about what would be your strategy to deal with edge weights, especially when you do not have to worry about negative edge weights. I will see you back in the next segment!"
  },
  {
    "objectID": "materials/cpnotes/Lec01.html",
    "href": "materials/cpnotes/Lec01.html",
    "title": "Ad hoc and Implementation",
    "section": "",
    "text": "Lecture - 01\nAd hoc and Implementation\n(Refer Slide Time: 00:11)\n\nHello, and welcome to the second module of the first week of getting started with competitive programming. Hopefully, you have, by now, set up your coding environment in a way that you like and are comfortable with. If you have seen the previous video, you have also had an overview of the various platforms that we will be submitting code to reading problems from.\nSo, just make sure that you have your accounts set up everywhere, and your basics sorted out about knowing where to submit your code, how to read input and write output, and so on. Also, do not get distracted with things like starter files that you might see from other more experienced competitive programmers.\nEspecially if you are just getting started, it is perfectly fine to keep it pretty basic and simple right now. As you go along and build up your own experience, you will build out your own setup and startup files. I think it is a much better approach than copy-pasting large chunks of code that you probably do not even fully understand or appreciate right now.\nSo, just feel free to keep it simple. If you are having any issues with the logistics of getting set up, please feel free to post a message on the Discord channel. If you are not on Discord, then you can send an email to the Google Groups set up for the course, and one of us will be sure to get back to you.\nSo, with all that said, I hope you are excited to get started on your first problem-solving experience in this course. As you probably have noticed, the first week is called Ad hoc and Implementation. It generally means that these problems do not require any special data structures or algorithms background. They are fairly generic puzzles. You can have a go at them even if you are not particularly familiar with specialized data structures or algorithms.\nUsually, all that is needed is basic programming competence. It is also a great way to learn a new programming language. You might want to just practice with a lot of these implementation-based problems that show up in programming contests.\nTypically, if you go to a CodeChef long challenge or a Codeforces contest, the first problem is of this sort. You need to spend some time just trying to understand the setup. There are probably usually one or two small things that you have to figure out. But after that, the part about translating your thought process into code is generally relatively straightforward.\nOf course, sometimes, there are challenging implementation problems with many annoying corner cases and similar things. However, it will not be the scope of what we do this week. We will just see some interesting problems with fairly simple implementations.\nSo, let us get started with a problem called Reversort. It will be a warm-up to another problem called Engineering Reversort that we will see in the next module. These problems appeared in the qualification round for Google Code Jam 2021. It is a fun problem!\nThe first part is a very direct implementation problem. You see a description of a specific algorithm, and you just have to implement it. It turns out to be a sorting algorithm. We will have a lot more to say about sorting and searching next week. So, it is probably a good trailer for that as well. Let us look at what the problem statement says, and we will take it from there.\n(Refer Slide Time: 03:45)\n\nSo, the problem statement introduces us to the Reversort algorithm. It is essentially a sorting algorithm designed to sort a list of distinct integers in ascending order. At the heart of the algorithm is the so-called reverse operation, which essentially takes a summary and reverses it completely. These summaries are carefully chosen so that after a certain number of iterations, the array ends up being fully sorted. So, we will take a look at the pseudocode for Reversort, understand how the algorithm works, and then we will get to the task that we are supposed to perform based on this algorithm.\n(Refer Slide Time: 04:21)\nHere is the pseudocode for Reversort. It is exactly as given in the problem statement. If you read it, you will discover that what the algorithm is doing is the following:\n\n\n\n\n\n\nThe algorithm goes through the array from beginning to end. At the ith stage, it is trying to figure out what is the smallest element in the array from the current position to the variant. It takes the sub-array from the current position to wherever that minimum element is located. Then, it flips that entire sub-array over.\nSo, this has the effect of bringing the ith smallest element to its correct place in the ith iteration. As a result, after n-1 iterations, your array is completely sorted. Notice that you do not need to do the last iteration explicitly because once you have sorted the first n-1 element, the last element automatically falls in place.\nNow, this may seem like a trivial thing to say, but for the task that we have to perform, these are the kinds of corner cases useful to observe and be careful about. Otherwise, you will end up getting these ‘off by 1’ errors, which can be silly and annoying. So, just be very careful in reading the algorithm down to these simple but minute details.\nNow we will simulate this algorithm on a couple of examples. My suggestion would be that once you see the example, pause the video and work through it yourself. Then resume the video to see if your execution tallied with ours. It is essential to go through these examples to build up your intuition for what the algorithm is doing. Having an accurate understanding of what the algorithm is doing will be crucial to being able to solve the task at hand correctly.\nWe have not yet talked about what we are supposed to do with this algorithm. We will get to that in a minute after working through these examples. So, let us look at the first example. It is an array with just four elements 4, 2, 1, 3, in that order. So, the first iteration discovers element 1, which is in the third position, and the array gets flipped. Notice that the second minimum element is already in its correct place in the second iteration. So, an array of length one effectively gets flipped.\nNotice that the last two elements need to be swapped for the third iteration. That is exactly what happens. As we discussed before, there are no more iterations after this because the fourth element is automatically sorted.\n(Refer Slide Time: 06:46)\nThe next example is going to be a slightly longer and nearly sorted array, in some sense. See if you can spot why I am saying it is nearly sorted.\n\n\n\n\n\n\n\nSo, in the first iteration, notice that the smallest element is right at the end of the array. When we reverse the array, the array becomes sorted. Because what happened was that the array, to begin with, was sorted in the reverse order. So, the very first reverse operation already sorted the array completely.\nBut we do not stop just because the array is sorted. There is no check in the beginning, which says if the array is sorted, then let us not do any more iterations. The algorithm will go through the remaining five iterations just to make sure that everything is in place. This is how the algorithm is going to run on these examples.\n(Refer Slide Time: 07:52)\nNow, let us define the cost of a reverse operation as the length of the sub-array that is being reversed.\n\nRemember, I was saying that we have not really defined the task that we are supposed to do. Now, this is the stage where we realize that we are supposed to compute the total cost of reversorting a given input array. Let us go back to some of our examples to actually calculate the corresponding costs. Remember that when you are sorting the sub-array that spans positions ‘i to j,’ the length of the array that is being reversed is j-i+1.\nOne way to compute the cost is to initialize a cost variable to 0 and just keep adding the lengths of the sub-arrays that are being reversed. This will involve implementing the Reversort algorithm and doing a little bit of extra book-keeping, just to see what is the length of the sub-array that is being reversed at every step. You just have to update your cost variable correctly and you would be done. Let us take a look at what the costs are for reversorting the two arrays that we just reversorted.\nSo, the first example was the array 4, 2, 1, 3.\n(Refer Slide Time: 07:49)\n\n\n\n\n\n\nNotice that in the first step we reversed a sub-array of length three, so that added a cost of 3. In the second step, the minimum element was in its correct position, but we still think of that as reversing an array of length 1. So, it does add one to the cost, it is not a step that comes for free. Do keep that in mind.\nIn the next step, we swapped the last two elements for a cost of 2 and notice there are no steps after this, you get the last element in the array for free. So, the total cost here added up to a total of six.\n(Refer Slide Time: 09:38)\nNow, let us look at the next example where the whole array got sorted in the very first step.\n\n\n\n\n\n\n\n\nThe first step is expensive. You end up reversing the entire array for a cost of 7. But after this, you have to painstakingly investigate every element in the array to find out that the elements are already in their proper position. So, the algorithm in this case will basically continue for the next five steps, adding a cost of 1 per step.\nRemember that the algorithm does not have any sanity check at any step, which says that we can break if the array is already sorted. So, the total cost, in this case, will end up being 7 for the first super expensive step and then 1 unit of cost for each of the remaining five iterations. Only five iterations because the last step is for free. So, the total cost is 12.\nFor the next problem that we will be discussing, we will be interested in constructing arrays whose cost of reversorting is some given number. That is a very interesting follow-up question. Here is a puzzle that you might want to play with. First of all, think about what is the maximum cost that you could incur as you reversort an array? Well, the maximum cost will be incurred, if at every step you need to reversort the entire remaining sub-array.\n(Refer Slide Time: 11:20)\n\nThe specifics of the numbers in this array are not so important. But what do you want to think about is how do you come up with an example like this? Here is an example with 5 numbers. Can you generalize this and, say, give me an array of length 20, where, in every step, you find that the algorithm is forced to reverse the whole sub-array that it is working with? You might also conclude that, maybe, such arrays do not exist. That would also be a valid point to make if that were to be true.\n(Refer Slide Time: 11:40)\n\n\n\n\n\n\n\n\n\nWhat you can see playing out in this example is that in every step, you had to sort out whatever was remaining till the end. So, you have the maximum possible cost. In this case, it turns out to be 14.\n(Refer Slide Time: 12:13)\n\nLet us recap what we have going on here. So, essentially, we simulate the Reversort algorithm and we just keep track of the costs as we go along. At this point, I think we are ready to implement this. So, let us switch to coding.\n(Refer Slide Time: 12:39)\n\nWelcome to the implementation segment of this discussion. I hope you are excited about writing the code for the very first problem that we have solved in this course. Because this is our first discussion about an implementation, I will go through every step of the process. But in the future videos, we might end up skipping some of the more routine paths, for example, taking input and things like that. In general, if you have any issues with the implementations of any programs that we discuss, please feel free to share your doubts in the Discord community that we have set up for this course.\nNotice that there is a separate channel for every week. We would really appreciate it if you could help us keep things streamlined by making sure that you are posting your questions in the correct channel. So, with all that said, I think we can get started here. Let me just walk you through the layout of the screen, which will be more or less the same in all the videos.\nI am using VS Code - that is my choice of ID. You could use anything that you are comfortable with. Just make sure that it is a plain text editor that has support for the basic features like syntax highlighting, and so on. I have divided my workspace into four panes. The main pane is the one that you see on the left, where I will be coding it. There is a floating screenshot of the section of the problem statement that I think will be relevant to us, because it has the details of the input and the output format. I will let that stay for a while, while we are still figuring out how to take the input and how to format the output.\nOn the right, you will see that there are three panes and there are three files, one in each of them. So, there is in.txt and out.txt. These are the files that my program will be reading from and writing to. I find it convenient to redirect the standard input and output to these file streams, and this way, I can see the output of my code in this pane right here as opposed to going back and forth between the terminal or just having a cluttered terminal with the output of the code.\nThis, of course, is a matter of purely personal preference. So, feel free to set up your environment in exactly whatever way you feel is the most comfortable for you. Importantly, I also have an expectedout.txt file. For now, it just has the output data from the sample output in the problem statement. But in general, you might want to be doing your own tests. In this case, you might have to generate this expected output file, either by working out the solutions by hand or in some other way. Or you have a brute force program that you are pretty confident about, which has generated the solutions for some instances. And, you want to compare if your algorithm which is doing something different is actually tallying with the solutions.\nSo, expectedout.txt is a file with solutions that one would be typically confident about for some reason. Then what do you want to do at the very end after you have written your program is to just run a quick diff, either from the terminal or visually. I would recommend doing it from the terminal. Run a diff between these two files to make sure that the output from your program tallies exactly with what is expected.\nSo, that is the overall setup. I will be using this terminal at the bottom to run the files. I have two very simple starter files. Here is the C starter file. And, I typically end up adding things based on what we need. This is some code that redirects the I/O to these file streams. This is something that is just recommended for speed and you will probably see it in many starter files. Most people would recommend using the scanf and printf style C input-output for speed.\nFor most of the problems that we will be tackling, we are not really concerned about that level of optimization. So, I am going to stick to just doing the standard I/O Stream when I am using C++, which is to say I will use Cin and Cout. If you are stuck with program whose efficiency you are really convinced about and you are still getting some sort of TLE error, just check if you are using efficient input-output or not.\nSimilarly, I also have a Python starter file, which I think looks even simpler. So, again, it is just redirecting the I/O Streams. I do have here a little bit of code that helps me track the time that my program is taking to actually produce its output. This is particularly useful for Python because it does tend to be the slower language. Sometimes, it just likes to sanity check that there is not a particular disadvantage. It is important to remember to remove any of these extra print statements.\nRemember that these would actually cause your tests to fail. On some platforms like Google Code Jam, for instance, you will end up just getting a runtime error if you submit your code with stuff like this. So, you just need to make sure that all of these extras are removed before you make your actual submission.\nSome people will have these macro-if statements to say that these things should execute only if you are not in a judging environment. I have personally found those to be a little bit unreliable. So, I just make sure that I manually clean up my files before I actually make a submission.\nOn the other hand, if you do not want to mess around with your files, and you want to keep them clean, but you still want the input to be read from a file and the output to be written to a file, you can also do this using the appropriate commands on the command line. So, I use ‘Bash,’ and I can simply redirect the output to a file quite easily by just appending a small command to the regular compiler invocation.\nThis is just to say that there are many ways of setting things up. I am not getting into any more specifics because the details will really vary based on your operating system, your compiler version and various other details. But there are a lot of resources online. I really encourage you to spend a little bit of time making sure that you have a comfortable working setup. So that you are not wasting any of your precious contest time on things like how to run your program and so forth. This is a small initial investment that is certainly worth making.\n(Refer Slide Time: 20:30)\n\n\n\n\n\nLet us go back to reversort and start the implementation that we were planning to get to. Let me switch back to the C starter file and just hope that the file names are correct, and everything is working fine. Let us test this with a small ‘Hello World’ output. There is ‘Hello World’ in the out file. So, that seems to be all right.\nLet us begin by taking the input. The first line gives the number of test cases T. By the way, before getting started, it is probably useful to just take a look at the limits for the input. Because, especially in languages like C++, one thing to be careful about is the types of the variables that you declare. So, you want to make sure that your variables types are conservatively large enough to hold the kind of values that are going to be thrown at them.\nFortunately, this being a warm-up problem, the limits are fairly small. So, this is not something that we have to worry about specifically right now. I am just going to declare an integer, which can store the value of the number of test cases. Now, T test cases follow. I guess we should have a loop that accounts for each of these test cases. I am just going to use c as the loop variable. C for cases, but it does not really matter so much.\nWhat is the format of each test case? The description says that each test case consists of two lines, the first line contains a single integer, N. Let us read that in. The next thing that we want to read is the actual list itself. The second line of every test case consists of N distinct integers. So, the number N that we just read in is actually the size of the list. We can certainly write a for loop that is going to run N times. We could use this to actually pick up these integers.\nAll the integers are on a single line, but they are separated by spaces. Although the description does not say it explicitly, if you look at the sample inputs right here, you can see that these are space-separated integers, which is going to be fairly convenient for us because we can just read them in like that, and we will be done.\nThese numbers are not going anywhere. So, we need to put them in an array or vector or something similar. I am going to use a vector of integers, because that is what I find convenient. If you would prefer using an array that should be perfectly fine too. We are going to use the push_back() method to add these numbers to the list. This is analogous to append in Python if that is something that you are more comfortable with.\nWe are done at this point in terms of reading the input. Just as a really basic sanity check, let us write this input back to make sure that we have it right, and we have not made any mistakes at this stage. Just remember to print some spaces, otherwise, the output will look unreadable. Let us just give a new line across test cases and tabs to distinguish between tests. If you look at the output file, now it looks like we have managed to read all the arrays correctly.\nNow, I do want to get rid of this floating screenshot. Let us also take care of the output. Of course, coming up with the answer is going to take some time. But let us just take care of it in terms of the formatting. What we want to do is print the case number. Google Code Jam is rather unusual in terms of its output format. Most other platforms would just require you to print the answer in some specified format. But Code Jam explicitly asks you to print the string involving the case number.\nSo, what do we print here? We could invoke a function that we may want to write to solve this instance, and we would be done. Let us actually go ahead and define this function. Let us say it returns an integer, which is the cost of reversorting the array in question. And, let us say for now that we just return a dummy number. We can see that the formatting, at least, is okay in the output file.\nSince we are done with reading the input, I got rid of the references to input and output formatting. Just for our recollection, here is the pseudocode for Reversort. This is a snapshot from the problem description. Remember, our plan was to just implement Reversort, as is suggested here, and use a cost variable to keep track of the costs as we go along.\nLet us begin by introducing that cost variable, which is sufficient to be an integer at the moment. Let us also remember to return the cost. Let us try to implement the Reversort algorithm. So, we are going to need a for loop, where the loop index varies from 1 to the length of L-1.\nThe one thing to keep in mind is that we probably should not be using 1-based indexing because that is not our scene here. So, let us start our loop variable from 0. This is going to go on until the length-1. Let us make sure that that makes sense.\nIf you are going to stop strictly short of the length-1, remember that in our array, the index of the last element is going to be this length-1. And since i will be less than length-1, it will indeed ignore the last element which is exactly as desired. So, I think for us the extreme points of the loop variables make sense.\nWhat is the first step here? We want to find the minimum element, but it has to be the minimum element in a certain sub-array. Then we need to find the position of this minimum element and then execute the reversals. It is essentially these three steps: find the minimum element, find where the minimum element is, and identify the relevant sub-array and perform the reversal. Of course, we also need to track the cost that was associated with that reversal.\nLet us do this one step at a time. So, for finding the minimum, let us use the variable name m to keep track of the minimum value. We are going to use the function min_element() to actually find the min element. What the min element takes as input, we can think of this as the boundaries within which we want to search for the minimum.\nWe are going to essentially say that we want to search from the start but offset by i. Of course, we want to go all the way till the end. You might want to just check that the indexing makes sense. So, in the very first step, you are looking for the minimum in the entire array. When i=0, for instance, notice that you are going to search for the minimum in the entire array. That is what it means to go from L.begin() to L.end(). These are essentially pointers to the start and the end of the list that we have.\nAs the values of i increase, you correctly identify the sub-array within which to search for the minimum. If you are not completely convinced, then you might want to add some print statements here, just to see what is going on. But I believe this to be okay. Let us move on and try to do the circus of figuring out where this minimum element occurs.\nSo, this is going to be an index, and we can use something called find() to find where the minimum element is. Since the elements of this list are all distinct, we can just search in the entire array. That will not hurt. If they were not all distinct, you will have to be a little bit careful in this step. So, I am just going to use the auto type here to keep things simple. And, that is going to keep track of the location of the minimum element. In the next step, we are going to actually perform the reversal.\nNow, you could probably write your own reversal function to do this from scratch. But in most languages, common operations like this are usually implemented through some built-in functions. I would generally recommend using a built-in function if it is accessible because that has been tried and tested and is likely to be more accurate than something that you code up from scratch. At least, for these really basic and fundamental operations.\nIf you are not sure about what that function is or you do not remember the syntax, then that is something that you should feel free to lookup. Even if you are recording this in Python, there are any number of ways to reverse, say, a part of a list. So, there should be no problem to do in either language using just the built-in mechanisms.\nIn C++, it turns out that the built-in function is just called reverse(). The one thing to be careful about, and where it is actually worth looking up the documentation a little bit, is to understand what is it that gets reversed. You probably give the reverse function two indices and it is quite natural that it is the sub-array that lies between those indices that gets reversed.\nThe detail to worry about is whether the indices are inclusive or exclusive or some combination of both. It turns out that the reverse() function considers the first index to be inclusive and the last index to be exclusive. With that in mind, what we should input the reverse function is at the start of the array offset by i, because that is from where we want to start the reversal operation.\nWe want to end at x, which is where the minimum element is located. Since the reverse() function is going to ignore that last index, if we had just given ‘begin plus i to x,’ then we would have reversed a shorter sub-array than what we intended. So, we need to add a plus 1 [L.begin()+i,x+1]. This performs the reversal that we require. Now we are ready for the final step, which is not present in the pseudocode. It is something that we have to do to solve the problem at hand.\nThe very last step is to actually upgrade the cost by the length of the sub-array that we just reversed. So, when we were discussing this a few minutes ago in the lecture, we said that the cost is just going to be j-i+1, where j and i are the indices of the array that got reversed. But here, we have these indices in the slightly awkward format. And, it is not clear if we can just directly do arithmetic here.\nSo, we are again going to use a built-in function to bail us out. So, there is this useful function called distance(), which does exactly what it sounds like it is supposed to do. If you essentially supply two locations, it will tell you how far apart they are. Let us find out how far apart the index of the minimum was from the start of the array. This essentially tells us the value of j in the pseudocode. We can now subtract i, which we know is the place that we are starting. That is our initial offset.\nOf course, this is over subtracting a bit, so I am just going to add a +1 as we had discussed earlier. This appends the right cost of reversing the sub-array that we encounter in the ith iteration. Let me get rid of the pseudocode here. Let us run the code and see what we get.\nIf you look at the output file, it seems to tally quite exactly with the file called expectedout.txt, which is always a good sign. It is quite visible that everything seems okay. But as a matter of general habit, you might just want to run a diff to be sure.\nWhen you are running a diff, no news is good news. If the output of the diff command is empty, it means that the files have matched exactly. Sometimes even though the files are visually matched, diff may still give you some output because, maybe, there was an extra newline in one of the files and things like that.\nFortunately, there seems to be no such indication here. So, nothing to worry about! I would recommend you try and run your code on a few different examples just to make sure that you identify some of the common edge cases, and they are accounted for properly before you actually upload your code.\nOf course, when you are practicing, you can upload your code as many times as you want and there is no penalty. It would be completely understandable if you are just keen to upload your code right away. Just be a little bit careful about making a habit out of this. When you are participating in an actual contest, you might incur penalties on these wrong submissions. So, you have to be a little bit more careful when you are participating in a live contest.\nIn any case, this was a fairly straightforward problem. We have good reason to be confident about this code. You can go ahead and try and submit this on the Code Jam servers and see how that works out for you. One thing to be careful about is the corner cases and the indices. So, do watch out for issues that might occur there.\nJust as a little bit of trivia, if you have seen the intro video for this course, it opened with a bit of frustration about the first version of the code not going through as expected. The problem that we were solving in that video was actually this one. The line of code that was missing I think was the line that involved actually reversing the array. That is a common mistake that can be made.\nYou keep track of everything else but forget to actually reverse your array in the process. Then your array has not been reversed and you are not tracking what you are supposed to be tracking. So, your answers end up being wildly different from what you expect.\nIt is certainly not impossible to make mistakes, even in simple problems. In fact, the simpler the problem, the more frustrating it is that you are getting a wrong-answer kind of status from the judge. So, it is never too early to get into the habit of being careful. Anytime that you are working with a lot of indices or corner cases, it is definitely worth working through some examples and just making sure that you have those down.\nSo, I hope you had a good time walking through this problem. I hope you will also get around to implementing it. As usual, we have the Discord community in case there is anything that you are stuck with, please do reach out there. We have a separate channel for every week. It would be great if you could keep your questions streamlined accordingly. This is week one and we have just finished the very first problem and the very first module. I hope you are all geared up for the next one, and I will see you there. Bye for now, and thanks for watching!"
  },
  {
    "objectID": "materials/cpnotes/Lec15.html",
    "href": "materials/cpnotes/Lec15.html",
    "title": "Greedy Algorithms - Module 4 (When Greedy Does Not Work - Traveling",
    "section": "",
    "text": "Lecture - 15\nGreedy Algorithms - Module 4 (When Greedy Does Not Work - Traveling Salesman)\nWelcome to the last leg of our little tour of problems and situations where greedy algorithms, in fact, do not work. To demonstrate a situation where the greedy approach fails rather dramatically, I have picked the ‘Traveling Salesman Problem.’ You may have heard of this problem before given that it is a classic and famous optimization problem. Nevertheless, let us begin by looking at the definition.\n(Refer Slide Time: 0:37)\n\nIn this problem, you are given a list or a set of N cities or locations and the costs of traveling between any pair of these locations. In the symmetric version, you might assume that the cost of traveling from A to B is the same as the cost of traveling from B to A, for any two cities A and B. In the asymmetric version, you drop this assumption. The cost of going from A to B may be different from the cost of going from B to A. This can happen, for example, in applications where you have some one-way roads between locations, and the situation is truly not symmetric.\nThese costs may not always reflect necessarily physical distances. The costs may be more abstract or may be based on other things, like their costs of actual airline tickets and things like this. In particular, the costs here may not satisfy things like the triangle inequality. It may be cheaper to go from A to C by going through a detour, unlike what would be intuitive if these were really physical locations in a plane.\nLet us say that the costs were reflective of the Euclidean distances, as is the case in this example, which is essentially a recreation of the example on the Wikipedia page for this problem. Assuming that the cost between any pair of points is just proportional to the Euclidean distance between them on the plane, then the tour that has been drawn out right now is the optimal one.\nJust to make our setting a little bit concrete, let us say that we are working with the symmetric version of the problem, wherein the cost of going from A to B is the same as the cost of traveling back from B to A. Further, let us say that we do not have the triangle inequality. The costs are arbitrary. They do not come from any underlying distance metric or anything like that. Let us also say that the costs are not bounded in any way. These could be arbitrary numbers. We do not assume, for example, that the costs have to come from the set: 1, 2, 3, 7, 10.\nThis is a fairly general version of the problem. Notice that intuitively, the more restrictions you put on the setting of the problem, the easier your job becomes as an algorithms designer. Because the hope is that you can leverage these extra assumptions and use them to your advantage when you are coming up with an algorithm. But you can imagine that your life as the designer of counter-examples to greedy approaches may become a little bit harder.\nBecause the more assumptions you make about the setting of the problem, the less wiggle-room you have while you are constructing your counter-examples. You are now constrained to operate within these assumptions. Hopefully, that bit of intuition made sense. As I said, the choices of assumptions, that I just described, are relatively arbitrary. I would welcome you to play around with a different setting and see what you find.\nNow, if you are interested in the traveling salesman problem, in general, then the good news for you is that this is very much an active topic of research in computer science.\n(Refer Slide Time: 3:41)\n \nThere was a paper that appeared in 2020, and it gives an improvement that has been long sought after. Despite the fact that the improvement may appear to be small, from reading the abstract, it caused much excitement.\nIf you want to get a sense of the excitement that it generated, I would really encourage you to read this article that appeared recently, at the time of this recording, in Quanta magazine, covering mostly the development around this paper, but also covering a lot of interesting history and trivia about the problem. This tweet about this article really reflects the sentiment of Computer Scientists around Traveling Salesman and shows how deeply we care about it and how fundamental the problem is to the field at large.\n(Refer Slide Time: 4:37)\n\nTraveling Salesman is also a bit of a cult classic. It is made its way into XKCD comics, and other popular culture. If you look at the description of this video, you will find a few links that you might want to look at if you are curious about the problem beyond this very short discussion. But let me just pause here and talk about what would be a natural gradient flow to Traveling Salesman?\nYou are in your origin city, thinking about planning your travels to the N cities on your list, the remaining ‘N-1’ cities on your list. You plan to come back once you are done. The natural thing to do is to perhaps just look at what is the cheapest city to go to from the one that you are at currently. In the first step, from the origin city, you just find the closest city in terms of cost the cheapest city to go to next.\nOnce you are at that city, you just repeat this exercise, making sure that you are only considering cities that you have not already visited as you go along. Except for, of course, when you are done, then the last move is forced because you have to come back to the origin.\nAt any intermediate point in your travels, just find the next cheapest city to travel to that you have not visited already, and then when you are done visiting all these cities once, at the very end, you just pick up the ticket back to the origin city. That is the greedy algorithm.\nI would encourage you to think about whether this would work. Given the nature of this lecture, you already know the answer. What I would encourage you to do is pick up some pen and paper, or whatever your favorite way of thinking is. Just try to come up with a concrete counter-example. For this approach before I show you one.\n(Refer Slide Time: 6:30)\n\nHere is a specific example from the book ‘Design Methods and Analysis of Algorithms.’ If you look at the costs here, let us just try to run through what would happen if we applied the greedy algorithm with the origin city being the city on the top left, which is the city labeled A. From A, the most accessible city is B, and it is a cost of ‘one’ to go there. From B, you have two possibilities, you could go to D or C. It is cheaper to go to D. That is what we will do next.\nFrom D, you cannot go to A, you cannot go to B. These are cities that are already visited. You pretty much do not have a choice at this stage and you have to take this rather expensive edge to C. From C, you return to the origin. The total cost of this tour that is inspired by the greedy strategy is 9 units. If you add up those numbers, you see that it is 5+2+1+1 = total cost of 9.\nOnce again, this is a good place to pause the video and think about whether you can beat the outcome of the greedy strategy. Is there a cheaper tour? If yes, by how much? Hopefully, you had a chance to think about this. It turns out that in this example, the greedy output is indeed sub-optimal. You can do better.\n(Refer Slide Time: 7:54)\n\nHere is, for instance, one way that you could do better. Starting at A instead of being distracted by the most tempting option, which is to go to B, let us take a locally sub-optimal option, which is to go to C first. We go from A to C, then from C to B, then from B to D, and from D to A. These last two moves that are essentially forced. But now if you look at the total cost of the store is going to be 2+2+1+3 = 8, which is better than the tour that we had from the greedy approach.\nYou could think about whether we could do even better. You could think about coming up with examples where the gap between the greedy answer and the optimal answer is perhaps larger because here it seems like just a tiny improvement. You could play around with that aspect of this as well. If you remember, in the beginning, I sort of said that ‘greedy’ fails quite badly for this problem.\nThere are many ways of quantifying the idea of how badly greedy fails, or even the idea of whether a greedy algorithm can be salvaged. In some situations, although the greedy algorithm may not get to the optimal answer, it may get to something that is close to optimal in a way that you can actually prove. These will be greedy approximation algorithms and they are quite common. But the comment we are going to make now is going to be in a different spirit.\n(Refer Slide Time: 9:22)\n \nIt is a remark borrowed from the introduction of this paper, which is titled ‘When the Greedy Algorithm Fails.’ If you are curious to look up this paper, you can find a link to the PDF in the description of this video. But here is the comment which I wanted to bring to your attention.\nIt turns out that there are instances of TSP that you can construct, which are such that the space of solutions is abundant with many optimal solutions. Yet somehow the greedy algorithm will end up finding the unique worst solution. Notice that there is just one worst solution and the greedy algorithm will end up finding that one. You can also ensure that the magnitude by which the solution is worse than the optimal ones is rather large. As you can tell, you can make it as large as you want it to be.\nThis is the sense in which we meant that not only does the greedy algorithm fail, it is not that it misses the optimal solution by a whisker or that it fails occasionally. But this quantifiably demonstrates that you could construct instances, arguably artificially, on which the greedy algorithm can be as bad in its performance as you want it to be.\nAll this is not to say that one must completely disregard greedy approaches, even to TSP. It is conceivable that there are subclasses of instances where the greedy approach performs okay or perhaps there are other heuristics, which are a more sophisticated mix of ‘greedy’ inspired strategies, and other common-sense pre-processing that works well in particular situations. So, this definitely been a lot of work along these lines and you can find out more about it if you were to even read the Wikipedia article on Traveling Salesman.\nThe larger point that we really want to drive home with some of these discussions is the fact that you have to be especially careful with greedy algorithms, simply because it is this dangerous mix of looking like a very tempting approach, and seemingly correct while you really do need formal proof of correctness before you can be absolutely sure. I mean, this is true for any algorithm that you come up with, but greedy algorithms can be especially slippery and we just wanted to make this warning a little bit explicit through some of these examples.\nI will just repeat something that I did say at the start of this week as well. If you are in the middle of a contest, and you are working on a problem for which you have a greedy strategy that appears to be very convincing but you do not have the time to prove it rigorously. Let us say you have tried to think of some quick counter-examples but you cannot seem to find one, then it might be a good idea to just code it up and see if you get lucky with the judges.\nThis would make sense to do, especially if you are not penalized for wrong attempts. It is just a quick sanity check. If nothing else, at least you eliminate an approach. It is usually doable because greedy algorithms tend to be simple enough that they can be implemented quickly. However, at least when you are solving, or you do have more time, I would definitely recommend actually going back and trying to confirm why your algorithms worked whenever they did.\nIf they did not work, then you probably have eliminated an approach and you can move on to the next set of ideas. That is useful as well. With that, it is going to be a wrap for Week 3 on ‘Greedy Algorithms.’ I do hope that you found some of these discussions useful. As always, we will keep the conversation going on the Discord community as well as on the Google Groups mailing lists.\nPlease do send any questions or comments, or suggestions over there. Feel free to leave your comments on this YouTube video, especially if you are watching this video outside an active run of this course. We always look forward to hearing from you. Thank you so much and we will see you next week. It is bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec03.html",
    "href": "materials/cpnotes/Lec03.html",
    "title": "Ad hoc and Implementation - Module 03 (Numbers Game)",
    "section": "",
    "text": "Lecture - 03\nAd hoc and Implementation - Module 03 (Numbers Game)\n(Refer Slide Time: 00:11)\n\nWelcome to the third module in the first week on AdHoc and Implementation-based problems. In this video, we will be talking about a problem called Numbers Game. This one is, again, a problem that featured in a Google Code Jam contest, this time from way back in 2010. This was the last problem in round 1A that year. Usually, round 1 is a contest that lasts for 2.5 hours.\nThis particular round had 3 problems that the contestants had to solve in that time. As you can probably tell from the name of the problem, it perhaps involves some sort of a game. I should mention that games are a fairly popular and recurring theme in contest programming. Usually solving these problems requires some background in combinatorial game theory.\nBut fortunately, this problem is an exception. You can unravel the solution pretty much by making observations from first principles. Although it does not hurt to be familiar with a little bit of game theory. So, if that is you, that is great. But if not, then, hopefully, this exploration motivates you to explore game theory more, because it is a really wonderful topic.\nIt is not something that we will be covering much more in this course. But certainly, I hope that you have a chance to investigate it more independently. With all that said, let us get started. I will, as usual, begin by presenting the problem statement to you. But this time, I will defer telling you about the actual task for some time, because I want to spend some of the initial time getting the hang of what is going on in the game. We will do a bunch of examples first to get a feel for what is happening. Then I will introduce you to the task that we actually have to perform. So, you might have to wait for it a little bit. Let us get started.\nSo, this is going to be a 2-player game. The names of the players are Arya and Bran. The situation is that they are given 2 positive integers A and B, which are written on a blackboard in front of them. It is a turn-based game of starting with Arya. So, first, Arya is going to make her move, then it is going to go to Bran and so on. There is no passing: When it is your turn, you have to make a move.\nWhat does a move constitute? What can you do when it is your turn? Well, you can do one of 2 things: You can either update A with ‘A-minus kB,’ or you can update B with ‘B minus kA,’ where k is some positive integer. In other words, you cannot leave the numbers the same as they were before. They have to strictly diminish. The question is, what do you want to achieve?\nYou might want to speculate about what would the goal of such a game be? Before I actually reveal it to you. For instance, could it be that the first player who makes one of these numbers 0 or negative wins the game? Well, if that is all that you had to do to win, then notice that this is not going to be a very interesting game to play.\nIf Arya is playing optimally, when it is her turn in the very first move, she is just going to subtract one copy of the larger number from the smaller one. If the numbers are both the same, then it does not matter which one you subtract from which. Either way, you will end up with a number that is either 0 or negative immediately. So, this is a game that will only last for a very short time, and it is perhaps not worth analyzing further.\nSo, what is the actual objective of this game? It is, in fact, the opposite. The first person who makes one of these numbers 0 or negative, actually loses the game. Now the whole situation is a lot more interesting. It is not obvious at all who is going to win given a pair of numbers. So, let us actually try to get a feel for this by going through some examples. To begin with, let us say that the 2 numbers we have are 12 and 51.\n(Refer Slide Time: 04:12)\n\n\n\n\n\n\n\n\n\nThe boxes around these numbers are color-coded based on whose turn it is. So, if the boxes are red, then it is Arya’s turn and if the boxes are green, then it is Bran’s turn. Let us say Arya makes her first move by subtracting 3 copies of 12 from 51. That is going to leave her with 15. Now it is Bran’s turn. Notice that he does not have much of a choice here.\nSo, he can either subtract one or more copies of 15 from 12. But if he does that, then he immediately loses the game. When he is subtracting k copies of 12 from 15, if k is bigger than 1, then he is again lost immediately. The only valid thing that he can do to stay in the game is to subtract one copy of 12 from 15. Let us say he does that. Then he is left with 12, 3, which is what gets passed on to Arya.\nPlease take a moment here to think about if Arya has a winning move at this stage. In particular, can she do something to ensure that in the next step, Bran is left with no choice, but to make a move that causes him to lose the game? Notice that Arya has limited options here, she can either subtract 1, 2, or 3 copies of 3 from 12. If she subtracts any more then she herself loses the game immediately.\nHowever, Arya does have 3 choices of valid moves that would still keep her in the game. By now, you have probably guessed that among these options, her optimal move is to subtract 3 copies of 3 from 12. Because when she does this, she is left with the configuration of 3, 3, which is what she hands over to Bran. Now you can tell that poor Bran in this situation is completely stuck.\nAny move that he makes will be a losing move. He has, as a result, lost the game and Arya has won. Before we go on to discuss more examples, I would like to introduce a very important concept, which is the notion of a winning position. This is actually a part of the problem statement and is going to be very important for us to understand the tasks that we have to perform later on.\nWe are going to say that A, B is a winning position if Arya can always win a game that starts with A, B on the blackboard, no matter what Bran does. In other words, no matter how cleverly Bran plays his moves, whenever it is his turn, Arya will always have a way to inch closer towards victory. That is when you say that A, B is a winning position. So, in more standard game-theoretic terminology, you would say that Arya has a winning strategy.\nA winning strategy gives Arya a way in which to respond to Bran’s every move in a way that, in the end, she emerges victorious. Of course, it may not always be possible for Arya to have a winning strategy. But it turns out that for games like these, if Arya is not in a winning position, then Bran is in a winning position. So, every conceivable state of the game can be identified as being either winning or losing for one of the players.\nIf you are hearing about the concept of a winning strategy for the first time, you might find it a bit confusing or puzzling. You might wonder how the state of the game determines whether a player is going to win or not? Does not it depend on their individual skill levels? Does not depend on whether they are having a good day or not, and things like that?\nLet me just clarify a couple of things briefly. One is that in such games, we always assume that the players are playing optimally and that they have the skills to make the best move that is theoretically possible, at any given point in the game. This is sort of a working assumption in all of our definitions. Also, notice a few interesting characteristics of this game we are playing that make it different from the games that you might be used to in your day-to-day life, like say, cricket or poker.\nOne thing is that this game does not have any element of chance in it. When either player is making a move, and for example, saying something like ‘reduce A by k*B,’ then that is going to happen. It happens in a very deterministic way. So, there is no element of randomness, unlike in, say, games of cricket, for instance, where you might plan to do something, but that may not happen depending on the circumstances, which are not completely in your control.\nThe other thing about this game is that it is a perfect information game. Everybody knows what is going on unlike, say, games of poker where you may not know what cards your opponent has in their hand. So, it makes these types of games quite special. You can find out more about these games by looking specifically for combinatorial games. The fact that the kinds of games we are discussing here, every position is either winning or losing for one of the players involved, follows by doing some kind of a backward induction argument on an object called the game tree.\n(Refer Slide Time: 09:21)\n\nThe game tree is built out by essentially mapping all the possible moves that can be legitimately made by one of the players from the starting state of the game. You just keep building this out till you reach states from where no more progress can be made. Those states are then labeled as being losing for whatever player is stuck in that state. From here, you can work your way backwards to say that, in general, if you are at a non-terminal state, then that state is winning if and only if you can make a move from here that is losing for the other player.\nIn other words, if you are at a state from where every possible move that you can make leads you to a position that is winning for the other player, then the current position is losing for you. You can fill in the details of this argument to see that every position in the game tree can be uniquely labeled as being winning or losing for one of the 2 players. It is a good idea to think about where our assumptions about things like perfect information, and the absence of randomization are useful in making this argument work. But for now, hopefully, you are convinced that this notion of a winning position is sensible. Let us try to get some practice with this by looking at a few examples.\n(Refer Slide Time: 10:33)\n\nSuppose you have 2 numbers: 1 and 42. It is Arya’s move. Do you think this position is winning for Arya? Well, if one of the numbers is 1, and the other number is some number that is greater than 1, let us say x, then you can simply subtract ‘x-1’ copies of 1 from x. This leads you to configuration 1, 1, which is losing for the other player. So, whenever one of the numbers is 1, the first player has an advantage and can, in fact, win the game in just one move.\n(Refer Slide Time: 11:16)\n\nThe next example is when you have 2 numbers that are identical. Is this a winning position for the first player or not? Hopefully, you have concluded that this is not a winning position. Notice that any move that the first player tries to make in this state is a losing move. There is no way that you can progress to a state where both of the numbers are positive. So, this is not a winning position.\n(Refer Slide Time: 11:43)\n\nWhat about if one of the numbers is a multiple of the other? Just to make sure that we are not in the previous case, let us say it is, the multiplier is strictly greater than 1. In this case, is this a winning position or a losing position? Take a moment to think about it. This scenario is actually winning for the first player, because notice that the first player can remove ‘r-1’ copies of a from ‘ra’ to go to the position ‘aa,’ and that is a position that we saw was losing for the first player. If the first player offers up this position to the second player then the second player is bound to lose. So, this is a winning position for the first player.\n(Refer Slide Time: 12:26)\n\nIn the next example, we have ‘a’ and ‘b’ with the property that ‘a’ lies between b and 2b strictly. Of course, if ‘a’ was equal to ‘b,’ we already know what happens. We will come back to the situation when ‘a’ is at least 2b. But what if ‘a’ is in the range strictly between b and 2b? In this case, can we conclude if this position is winning for the first player or not? I should confess that this was a bit of a trick question.\nWe do not have enough information here to conclude if this position is winning or not for the first player. In fact, you should be able to come up with examples with concrete numbers that satisfy the inequalities here. You could come up with 2 examples, one, which is winning for the first player and the other that is not winning for the first player.\nSo, there is not enough information here. But one thing that I do want to draw your attention to is the fact that this is a forced situation for the first player. There is only one interesting move that the first player can make here. By interesting, I just mean a move that keeps the player in the game.\nApart from removing one copy of ‘b’ from ‘a’ - so, notice that a is the larger number here, there is no other move, that is a valid move, in the sense that any other move is going to lead to the outcome that you lose the game immediately. So, there is only one interesting move here. In some sense, this is a forced configuration. This is a fact that we will make use of later. So, just keep it at the back of your mind.\n(Refer Slide Time: 14:12)\n\n\nLet us go to the final example, which is probably the most interesting of the ones that we have seen so far. What if ‘a’ is at least 2b? Is there something that we can say conclusively? I will give you a hint here. This is not a trick question like before. You can actually conclusively say if this is a winning position or not for the first player. Take your time and pause for a minute here to think about what might happen here.\nLike before, we are in a situation where ‘a’ is larger than ‘b’ but unlike before, it is now substantially larger than b. We have possibly multiple choices for valid moves that we can make. We can certainly remove at least 1 copy of ‘b’ from ‘a,’ but possibly we can remove 2, 3, or more. In fact, let us divide ‘a’ by ‘b’ and suppose it factors as ‘r*b+a remainder c.’\nIf that is what ‘a’ is going to be, then what should your move be? A tempting thing to say is that maybe just remove as many copies of ‘b’ as you can from ‘a,’ so that you are left with c, b. But if you have played around with enough examples, while we were thinking about this case, you may have realized that it may not always be the optimal move.\nHowever, I promised you that this is not a trick question. We can always identify if this is winning for the first player or not. So, let us think about this a little more, go ahead and do the greedy thing that felt natural to us. Let us say that we remove ‘r’ copies of ‘b’ from ‘a.’\n(Refer Slide Time: 15:53)\n\nLet us say we are left with the configuration c b, which goes to the other player. Now there could be 2 possible situations. Either c b is a losing position, in which case, this is great, because if c b is a losing position, then the greedy thing was actually the right thing to do. But suppose c b is not a losing position, then it is a winning position. Somehow, that is a position that we want for ourselves. But remember that since ‘a’ had at least 2 copies of b in it, what we can do is we can force the other player to give us the configuration c b. How can we do that?\n(Refer Slide Time: 16:31)\n\n\n\nWe can do that by subtracting ‘r-1’ copies of ‘b’ instead of r copies of b. When we do that, notice that the other player is left with a configuration b+c and b. Now, this is like the situation that we had before. It is a forced situation, simply because ‘c’ is strictly less than ‘b.’ Remember, c was the remainder we got when we divided ‘a’ by ‘b,’ so, c < b. The only move that is legitimate for the other player to make is removing one copy of b from the number b+c.\n(Refer Slide Time: 17:08)\n\nWhen that move is played by the second player, the first player gets back the configuration c b. But this is something the first player is very happy about because we were in the case when c b was a winning configuration. The point is that irrespective of whether c b is winning or losing, you have a move that you can use to turn the game in your favor.\nJust to summarize what we learned from the last example: We saw that if ‘a’ is at least 2*b, then the position is winning for the first player. This is by no means obvious, but it is going to be very useful. I hope you are convinced that this is actually the case. If not, then please go back and revisit the argument that we just made before moving on.\n(Refer Slide Time: 17:51)\n\nLet us summarize what we have learned so far. Remember, we are interested in understanding if A, B is a winning position or not. Let us assume that A is at least B. What we have done here as we have mapped the values of A on this number line, and we have highlighted the possibilities in terms of B. Notice that we know that if A = B, then it is actually a losing position. And if A is 2B or more, then it is a winning position.\nFor values of A that lie between B+1 and 2B-1, this is a mystery. We do not really know what is going on here. If we had to figure out algorithmically if A, B is a winning position, then what we have right here is a fairly natural recursive approach to determining if A, B is winning or not. So, the algorithm will go like this.\nIf A is at least 2B then say ‘yes,’ if A is B, then say ‘no.’ Of course, the interesting case is the one that remains what happens otherwise. If A is in the range B+1 2B-1 inclusive, then what can we do (at least algorithmically)? One hint at this point is to use some sort of recursive idea. Can you think about what would be a useful configuration to work with?\nTake a moment here just to recall what we have discussed so far, and the answer should be evident. Hopefully, you have identified that the configuration of interest here is A-B, B. The reason for this is that when A is in the range B+1 2B-1 inclusive, then the situation is forced for whichever player is playing this configuration.\nThe only valid move that you can make at this stage is to subtract 1 copy of B from A. What happens from here? Keep in mind that the positions ‘A, B’ and ‘A-B, B’ are being played by 2 different players. Just to make sure that we are on the same page, let me know what do you think should happen if ‘A-B, B’ turns out to be a losing position for whichever player is playing that position?\nWhat can you say about A, B? Well, hopefully, you have concluded that if ‘A-B, B’ is a losing configuration, then A, B is winning. Because from A, B, you are able to generate a configuration that is losing for the other player, which makes you win when you start from A, B. On the other hand, what if ‘A-B, B’ is a winning position? What can you say in this setting?\nIt is probably predictable but please still think through it before coming to an answer. So, if ‘A-B, B’ is a winning position, then in general, it is still possible that the first player can try to divert to a different position for the second player, which is not a winning position, hopefully. But notice that in this case, we have been pushed into a corner where this move has been essentially forced on us.\nTherefore, we can actually conclude that if ‘A-B, B’ is a winning position, then ‘A, B’ is a losing position. Because this is the only position that we can generate starting from A, B, whenever A is in this range. This completes the description of the recursive algorithm. What you do is you try to recursively identify if ‘A-B, B’ is winning or losing. Just remember to flip that outcome to report the correct situation with respect to A, B.\nWhat is the running time of this algorithm? Notice that in every step, if you are not immediately done, then you have generated an instance where the magnitude of the larger number has been reduced by half. As a result, the algorithm will terminate in logarithmically many steps, log of the larger of the 2 numbers that you started within the initial configuration.\nIn some sense, this seems like a nice approach to figuring out if A, B is winning or not. This is a good time to tell you about the actual task that we have to perform, in this problem. The work that we have done is going to be hugely relevant, but we still have some way to go.\n(Refer Slide Time: 22:27)\n\nHere is the problem statement, the rest of it. We are given is 4 integers: A1, A2, and B1, B2. We have to count the number of winning positions A, B, for A in the range, A1, A2, and B in the range B1, B2. You might say that let us just try and go over all possible choices of A, B and we have just described an algorithm to figure out if A, B is winning or not.\nWe can just employ that algorithm and our solution is done. This would be a perfectly valid solution for the smaller data set. But here is the clincher for this problem. If you look at the limits, then it turns out that the ranges of these numbers can be as large as a million. So, now if we were to try and explore the full range of pairs and try to do something for each of them, we are going to be in some serious trouble.\nIn particular, the algorithm that we just described is going to be way too expensive. So, we need a different approach here. In particular, it looks like since examining every pair of numbers is going to be too expensive, we probably need a way to be able to address multiple pairs at once, or to be able to draw a conclusion about a large collection of pairs somehow magically in one shot.\nSpecifically, suppose that we fix a choice of B. Let us say we are looping over the range of values of B between B1 and B2. If it were possible that we can identify somehow directly, the number of A’s for which A, B is winning. Keep in mind that B is fixed. We just want to know how many A’s are there for which A, B is a winning configuration.\nJust remember that the crux of the matter here is to be able to do this in a way that does not involve examining each of the A’s in turn. At this point, this intuition may seem very vague. So, let us just go back to the drawing board and try to understand the problem more, and see if we can make some sense of this very high-level intuition that we have at this point for what our approach should be.\n(Refer Slide Time: 24:39)\n\n\n\n\nLet us go back to the recursive approach that we were just talking about. Remember that this is the interesting range for A. This is the range that we call the mysterious range where we cannot immediately conclude if A, B is a winning position or not. Let us just unravel the recursion and see what it is going to do. The recursion is going to examine the position A, B, B from the perspective of the second player.\nFor the second player, we again know that A-B, B is going to be winning if B [which now remember that B is the larger of the 2 numbers here] is substantially larger than A-B. If that happens to be the case, then this configuration is going to be winning for the second player. And in all these cases, we can again directly conclude that ‘A, B’ was losing for the first player.\nLet us just expand this out a bit. What you will get is that A should be, at most, 3/2B or 1.5B for this position, the original position A, B to be losing for the first player. Notice that this is now strictly new information because earlier, the only case that we knew of where we could directly conclude that A, B is losing was when A=B. But now we are saying that if A is at most 1.5*B, then also, A, B is a losing position. So, that is interesting. But let us try to unravel the recursion even a little bit further.\n(Refer Slide Time: 26:13)\n\n\n\n\nSuppose even at the second layer, you are stuck, you are not able to really conclude anything. This happens when, again, B lies strictly in the range A-B 2*A-B. If B is stuck in this situation, remember that now B is the larger of the 2 numbers and B is in this range, we do not really know. So, we need to recurse further. How do we recurse? Well, of course, we have to remove 1 copy of A-B from B.\nThen we need to give this back to the first player. We need to now check out this configuration more closely. So, of course, B-(A-B) is the same as 2B-A. We know that this configuration is winning for the first player, if A-B, which remember that A-B is the larger the 2 numbers now that one copy of A-B has been stolen from B.\nIf A minus B is substantially larger than 2B-A, then this is winning for player 1. Again, you can do the arithmetic, rearrange the terms and so, on. You will see that this condition boils down to saying that A should be at least (5/3)B. Notice that this is fresh information. Earlier what we knew is that if A is at least 2B then we can do a one-shot answer saying that this is winning. But now we can say that A is winning even if A is at least (5/3)B, which is something like 1.66 or so. So, now we have narrowed down the range that we said was mysterious.\n(Refer Slide Time: 27:55)\n\nIn fact, let us try to summarize where we are in terms of the extra information that we have after unraveling 2 layers of recursion. Now we have 2 new thresholds. We can actually say more about what positions are winning and losing. This is an improvement. There are more cases in which we are able to directly knock out a conclusion for whether A, B is winning or not.\nIt seems tempting to wonder if this range of mystery can be made smaller and smaller by unraveling more and more layers of recursion. The current mystery band ranges between 1.5 B and 1.66 B or so. If you are curious, feel free to pause here and just pick up some pen and paper and unravel a couple of layers of recursion more to see if you can shrink this mystery zone a little bit further. You can come back to tally notes with me in the rest of this lecture.\n(Refer Slide Time: 28:59)\n  \nIf you have had to summarize what we learned by just going further and further into the recursion rabbit hole, these are the inequalities that we discover. These inequalities are color-coded by the situations that are good for the respective players. Whenever a red inequality holds, we have the configuration that is winning for the first player. Whenever a green inequality holds, then that configuration is winning for the second player.\nJust in case you are wondering where these inequalities came from, let me remind you that we obtain these by simply unraveling more and more layers of the recursive algorithm that we discussed a few moments ago. Let us rewrite these inequalities in terms of A and you will see a bunch of fractions emerging when we do this rearrangement of terms.\nBy just staring at these numbers, let me ask if any patterns seem to emerge or if these numbers generally look familiar? Well, if you have seen the Fibonacci numbers before, you might recognize that these fractions are just ratios of consecutive Fibonacci numbers. If you actually know about some properties of these ratios, then you can probably already make an educated guess about where this is going.\nBut if that is not something that strikes is anything significant, let us rewrite the fractions in terms of their decimal counterparts. At least you can see that it seems like we are closing in on the mystery zone. Remember that these numbers signify the ranges of values for which we already know what is happening. In particular, the last 2 inequalities are the tightest and they tell us that we completely understand what is happening when A is at most 1.615*B.\nWe also know what is happening when A at least 1.619*B. So, the values of A about which we are not sure, are values that lie between, these 2 ratios. So, I am not sure if you have, like, a favorite mathematical constant that lies between these 2 numbers. But if you have heard of the golden ratio before, then that might just come to your mind.\nSo, you might make at this point, an educated guess that perhaps it is true that the mystery zone actually shrinks and shrinks and meets at the golden ratio. It turns out that there is a reasonably formal sense in which this is actually true.\n(Refer Slide Time: 31:36)\n\n\n\n\n\n\n\n\nHere is the statement that you can formally prove. It turns out that A, B is a winning position if and only if A is at least Φ*B, where Φ is a mathematical constant known as the golden ratio. If you have not heard of the golden ratio before, do not worry about it. Although it is a really interesting constant to learn more about. You can look it up on Wikipedia, for example.\nFor now, though, let us just contemplate if this statement is useful for our algorithm. Remember, we said that suppose you fix a B, and if you had a one-shot way of figuring out how many A’s in the range A1, A2 are such that A, B is a winning configuration. That is simply a direct count, you just have to look at the quantity Φ*B. You know that all the values of A that are larger than Φ*B are the ones that form winning configurations along with B.\nIt is just a matter of counting how many numbers in this range exceed this threshold. We have been working with the assumption that A is at least B. So, when you write your code, you have to account for this kind of symmetry. We will see that more explicitly when we get to coding. But hopefully, it is clear that this statement is extremely useful in getting to the kind of algorithm that we were hoping to find.\nI think with this, we have the main pieces of the puzzle in place. The main crux of the idea is hopefully beginning to become quite clear. This is probably a good point to pause the lecture and try out your own implementation if you feel inclined. The rest of this video will do essentially 2 things. The first is to discuss why this claim is true. It is not going to be a ‘very formal’ proof.\nIt is just going to be an argument that substantiates why you might believe this claim to be true, and you can probably expand it to a more formal argument if you would like to do that. Then we will write some code and implement the solution that we have just discussed. Before we move on, though, let me just try and address a question that might be occurring to you.\nHow do people come up with such solutions? Especially when we were discussing this solution, the golden ratio seemed to come out of nowhere. You might be concerned if you have not heard of the golden ratio before or if you are not very familiar with the Fibonacci numbers. You might be worried that these intuitions will not emerge as naturally for you.\nLet me say 2 things in response to this question. The first is in the context of this particular problem. I should point out that you do not need the full leverage of this theorem to be able to solve the problem for the large tests. All you need is the intuition that there is some threshold, you do not need to really know what that threshold is, you can instead binary search to find it.\nFor this, you will actually need the algorithm that we discussed in the very beginning. The algorithm for checking if a particular pair is winning or not. Remember, we had a ‘log n’ type of algorithm for that, where n is the larger of the 2 numbers, A and B. So, using that algorithm, what you can do is take the range A1, A2. Take the middle element of this range, and try to figure out if this middle element with B is winning or not.\nIf it turns out to be winning, then you know that the threshold is lower, and if it is losing, then you know that the threshold is higher, and then you can continue your binary search. You just need to play around with enough examples to develop this intuition that there is some mystery interval, which keeps shrinking and shrinking. There is some threshold, which actually distinguishes the winning positions from the losing ones. You do not need to know what exactly that threshold is, although if you know it, your coding will become more convenient.\nWhile binary search is a very fundamental technique, it does require a bit of care in the implementation. We will be talking a lot more about binary search in the next week. But for now, this is actually a really fun exercise in binary search. If you want to go ahead and get some practice, this would be a good time to do it. The other thing that I wanted to say is not so specific to this problem, but just a more general comment, which is that if you have seen this lecture so far, then you are already somebody who is enthusiastic about learning new things.\nI would say that the more you practice, the more you expose yourself to new ideas and new techniques, the more you build up your own toolkit of ideas that you have seen. So, for example, if this happened to be your first encounter with the concept of the golden ratio, then instead of getting worried about the fact that you have not seen it before, approach it with a mindset of positivity by realizing that you have seen it now.\nSo, you can add it to your notes, or however, it is you keep track of all the new ideas that you learn. It is one more idea in your toolkit. That is how you will eventually develop your own creative flair. In short, my suggestion would be to practice as much as you can. Instead of feeling discouraged by the things that you may not know so far, I would suggest focusing on feeling encouraged by all the exciting new things that you are learning.\nNow let us just get back to the statement here. Let us try to figure out why something like this should be true. So, recall that we have the interesting range for A being that it stuck between B and 2B. In this case, we said that the only move that the first player can make is to reduce A to A-B and you go to the configuration A-B, B.\nThe formal framework that we will use to prove this statement here is the framework of mathematical induction, which you might already be familiar with. The idea is to assume that the statement holds for all configurations, which involves smaller values of A and B. Based on that assumption, we will show that it is true for the configuration ‘A, B.’\nThe only missing piece here is to say that the statement is true for some sort of a base case. But it turns out that for this statement, the base cases are trivial. I will leave it to you to validate them. But for now, notice that for the interesting range of values of A, we go into a situation, which we are forced to be in, and in this situation, we can apply the induction hypothesis to say that this position is winning for player 2, if B is at least Φ*A-B.\nWe are able to apply the statement of the theorem directly here. That is the advantage of being able to use what is called the induction hypothesis. We know that this is the condition for this configuration to be winning for player 2. Because this is an ‘if and only if,’ we can turn the inequality around to say that this is the condition for this configuration to be losing for player 2. You might be a bit annoyed that when I am doing not greater than or equal to, I am not saying strictly less than, but notice that A and B are integers and Φ is not an integer.\nThe inequalities do check out. Let us continue this line of argument and write this in terms of player 1. A configuration that is losing for player 2, is equivalently winning for player 1. So, this is the criteria that we have, if we want the original configuration A, B to be a winning configuration for player 1, except the criteria is written in terms of a condition on the configuration that we reach after one step.\nWhat we have here is that B is at most Φ*A-B. If we rearrange those terms, we see that we can rewrite it as Φ*A being at least 1+Φphi*B, or pushing the Φ to the other side, we have 1+Φ/Φ*B is at most A. That is the inequality that you get. It turns out that it is a property of the golden ratio that 1+Φ/Φ is Φ again.\nApplying that we arrive at exactly the statement that we wanted to prove, which is that, for this configuration to be winning for the first player, we need A to be at least Φ*B. With that, we conclude the supporting argument for our main claim. Let us quickly recap what the algorithm is going to do in preparation for the implementation.\n(Refer Slide Time: 40:32)\n\nRemember, we have A1, A2, B1, B2 as the ranges of values of A and B. Let us go over all the values of B from B1 through B2. For each of those values of B, we will directly try to identify the number of values of A in the range A1, A2, for which A, B is a winning position. To do that, we will crucially use this claim.\nWe will just keep adding these numbers to a running tally of the number of winning positions. That is the answer that we will return at the end. So, with this, we have everything we need to know to be able to start the implementation. So, let us just switch to coding.\n(Refer Slide Time: 41:06)\n\n\n\nHere we have the usual sort of setup. You will see that the data from the sample input, the sample output, and the problem description have been copied under these files for a sanity check when we need it. Here we have the input-output formats for our reference. The input is T lines and each line is these 4 numbers a1, a2, b1, b2, signifying the range for ‘a’ and ‘b,’ respectively.\nNow we need to figure out the number of winning positions ‘a, b,’ for ‘a’ and ‘b’ lying in these in these corresponding ranges. The output format is really simple. We just have to essentially print the case number and the answer. Let us just try to compute the answer based on everything that we have discussed so far. What we said is that we will look at all the values of ‘b,’ we will loop over all the possible values of ‘b.’\nLet us say that is ‘b’ in range b1, b2+1. Here, what we said is we will try to figure out how many elements in the range a1 to a2 actually meet the criteria that the ‘a’ is at least Φ*b. This was the threshold that we had. If this threshold is landing somewhere within this range a1 to a2, then you can simply compute the number of a’s, which form a winning position along with ‘b’ by subtracting the threshold Φb from a2 and then taking the seal so that you are left with an integer.\nJust keep in mind that the threshold may not actually land somewhere in the middle of this range. It is possible that for instance, the threshold is below a1 or above a2. If the threshold is above a2, then none of these numbers satisfy the criteria that we have in mind. So, none of them contribute to the count of winning positions.\nBut if the threshold falls below b1, then all the numbers in this range contribute. Let us just make sure that we account for that explicitly. Notice that it is important to account for this explicitly and separately. Because, at least, with the approach that I was describing, if you try to do it in one shot, you will end up overcounting the number of winning pairs.\nBefore we actually write down the conditionals, let us just do some preparation. I think we want to have a variable that represents Φ, the golden ratio. You might be tempted to write down, like, the actual constant, up to a few decimal places. But I found that it can be dangerous. Because you are working with really large numbers here, you may not get the precision that you want, by just listing out a few digits in the decimal version of the constant. We also, may have to do some floor-ceiling sort of thing.\nLet us make sure that the math library is imported. Now we can go back to trying to do the cases that we had in mind. The first thing we said is that if a1 is greater than this threshold, then the entire range of numbers from a1 to a2 actually contributes to the number of winning pairs. So, we need to make sure that our answer is incremented by a2-b1+1.\nThat is the number of numbers that are there in this range. Now let us look at the ‘else’ part. We want to count the number of numbers in the range a1 to a2, which actually exceeded the threshold, golden*b. A natural way to do that is to say a2-golden*b. You can probably already guess that this is going to be problematic because this expression is not even an integer.\nWe really want to be counting the number of pairs. So, this is not the right thing to do. It seems like the appropriate thing to do is to take a floor or a ceiling on this threshold. I have to confess that I am very slow with getting these kinds of things right. This is really where a lot of edge cases and corner cases happen. When I am in this situation, I will do something really silly, like take an example and ask myself, suppose the range a1 to a2 was the numbers from 1 to 10.\nSuppose the threshold was 7.5. It does not have to be a realistic threshold. It is just, let us say, some fractional number. What do we want now? We want to eliminate everything that is less than 7.5. We want to keep everything that is greater than 7.5. So, what should we subtract from 10? What is the correct thing to subtract from 10 for this to happen?\nWell, it happens to be 7. It makes sense to take the floor. That is probably a horribly, non-sort of formal way of saying it. But for these edge cases, I usually find that doing some quick and dirty examples is probably the quickest way of making sure that you got it right. If it is a more tricky corner case situation, you might want to actually really run through some examples like run your code through some test cases and so on before moving forward. But this seems reasonable here.\nSo, we go ahead and do this. Notice that this may still be a little bit problematic because, for example, what happens if your threshold is above a2? So, we said that, in this case, none of these numbers contribute to the number of winning pairs. But this expression does not reflect that. What are you going to get if, say, the threshold is 12 and the range you are looking at is 1 to 10?\nThen, this expression will give you something like 10 minus 12, which is a negative number. That will offset your count in a way that is not good. You just want to stop at 0. When the numbers are negative, you want to basically make sure that they get counted as 0. The simplest way to do that is to take a max with 0. That should work.\nThis seems like everything that we did discuss so far. But it turns out that if you try to submit this code, you will probably end up getting a wrong answer, which can be a little bit frustrating because it seems like exactly what we have discussed. If you remember during our discussion, I made some passing comments about how when we are actually coding, we should account for symmetries.\nNotice that in our entire discussion, we have been saying just assume that ‘a’ is at least ‘b’, and that is without loss of generality. But here, we are really looking at ordered pairs. There is no reason to believe that ‘a’ is at least ‘b’ for the numbers that we are looking at right now. To put this more generally, I would say that the thresholding condition is that max of ‘a, b’ should be at least Φ times min of ‘a, b.’\nNow, when it comes to ‘b’ being the larger of the 2 numbers, this translates to ‘b’ is at least Φ times ‘a.’ If you want to understand the criteria in terms of ‘a,’ then that is going to be ‘a’ is, at most, 1/Φ*b. It turns out that 1/Φ is just Φ-1. That is just a slightly more convenient way of writing this threshold. Now let us go to our cases and clean them up in light of this new information.\nThe other situation where you could have numbers contributing to winning pairs: if ‘a’ is at most Φ-1*b. Now, this is the threshold (Φ-1*b), which was greater than a2. What does that mean? That means that all the numbers from a1 to a2 actually meet this threshold’s criteria. Therefore, they should all contribute to the sum.\nWe need to enhance our first conditional to account for the situation. We want to say that if Φ-1*b is greater than a2, that means all the numbers in the a1 through a2 meet the criteria that we have written above. Therefore, they should all contribute to the sum. That is a fairly straightforward modification there.\nLet us clean up the ‘else’ branch as well. Previously, we had a lower threshold. We were counting everything that essentially went from that threshold, till the end of the range. Now, we have an upper threshold. So, we have to count all the numbers that essentially fall below the threshold, Φ-1*b. So, we need to increment our answer accordingly.\nSo, once again, we want everything to be below this threshold. Let us again, say, floor for now. If this is not clear, I will just come back and justify it in a minute. But let me just write out the threshold, to begin with. We need to take away minus a1, then we have taken away one more than we need to. So, let us compensate for that by adding 1.\nNotice that you might run into the same issue as before, with these numbers being negative. In this case, this could happen when the upper threshold is below a1. If that happens, then this expression will evaluate to a negative number and completely throw off your account. So, it is a simple but important fix to make sure that you take the max with 0.\nThese are the kind of small edge cases that can seem very mysterious when your code is returning some sort of a wrong answer status. Hopefully, the more practice that you have regarding thinking through this sort of thing, the more alert you will be to do the edge cases. Let us just go through the ritual of running this code and checking the output. It does seem like the output matched here.\nThis is a good time to remind ourselves that this does not mean very much. In most cases, the sample tests are not enough to account for all the edge cases. Sometimes they are even deliberately misleading, depending on the problem author and things like that. So, definitely, make sure to try and test a little more expansively, especially given that this is a problem involving large numbers. It is easy to generate some random tests, or even just throw in 4 numbers that match the thresholds of the problem, and see how long your code is going to take on this just to make sure, for example, that your code will not timeout when you submit it.\nIn fact, since this is a fairly easy thing to do, let us just try it right now. Let us say that we set our thresholds to be 1 and a million and run this code again. One of the most common issues that come up when we are discussing choices of programming languages is the issue of Python being slow.\nBut notice here that this code runs in well under a second. We have really pushed the input to its limits. That is kind of what a good algorithm can do for you. That is the leverage that it can buy. By the way, this reminds me that just in case, you are literally using the same start-up file, before you submit on Code Jam, just make sure to remove all of these operating systems specific things, because otherwise, you will end up getting a runtime error.\nSo, just submit the part of the code that is relevant to the problem. That is essentially about it. I think we have discussed this problem quite thoroughly. Hopefully, all aspects are clear. In case any of the floors or ceilings are throwing you off, just be sure to work with small examples. I think there is no shame in just doing some quick and dirty examples, no matter how simple, if they help you sanity check the corner cases of your code. So, thanks for watching all the way. If you are stuck with anything, as usual, do join us on Discord. I look forward to seeing you there as well as in the next lecture. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec17.html",
    "href": "materials/cpnotes/Lec17.html",
    "title": "Disjoint Set Union - Module 1 (An Introduction-Part II)",
    "section": "",
    "text": "Lecture - 17\nDisjoint Set Union - Module 1 (An Introduction-Part II)\n(Refer Slide Time: 0:17)\n\nWelcome back to the second part of the first module on ‘Disjoint Set Union.’ Recall that we were working with the disjoint set union data structure, where our goal is to maintain a collection of disjoint sets over a fixed universe of ‘n’ elements, and every set is identified by a unique representative element.\nBecause these sets are disjoint, if an element is a representative, it represents only one set. There is no ambiguity. We want to support the ‘find’ set and ‘union’ set operations, where the ‘find’ set takes one element as input and returns the representative element of the set that this element belongs to. The ‘union’ set takes 2 elements as the input and it merges the 2 sets that these elements belong to.\nIt could happen that these 2 elements belong to the same set, in which case, this is a trivial union, and no actual work needs to be done. If this went by too fast, I hope that you have actually had a chance to watch the previous part of this module, which motivates this data structure a little bit through an example of how it can be used to maintain, for instance, the connected components of a graph and we go through basically what I just said, but a little more slowly.\nIf you have not seen that one, it may be advisable to watch that first. In this part, our focus will be on actually building out this data structure – actually implementing these operations. Let us start at the beginning.\n(Refer Slide Time: 01:41)\n\nRemember, we said that at the beginning, we have these ‘n’ elements and we have their representatives as being really uniquely identified because every element is a singleton and it can only represent itself. There is really no choice. Now, if you are already thinking about the implementation, then a very natural way to implement this would be to have an array, which stores the values of the representatives.\nWe could declare a parent array or leader array, which basically has the following property. The ‘i’th element of this array will tell us the value of the representative element of the set that ’i’ belongs to. This is a very straightforward thing to do and just to account for indexing issues because the ‘i’th element in an array is going to be indexed by ’i-1.’\nI would typically want to declare an area with ‘n+1’ elements so that I can freely talk about the element in the array that is indexed by ‘i’ having the information about the leader of the set that ‘i’ belongs to. This is a small detail – does not really matter – you could also work with an array of length ‘n’ but in that case, in your code, you just have to account for adjusting the indices appropriately. I just feel that this is more natural to read off and we will see that when we get to the actual code.\nBut for now, hopefully, the semantics of the array is clear, to begin with. The array will be initialized in this fashion, with the first element just being 1, the second element being 2, and so on because every element is simply its own leader. Let us see what happens when we do a union.\n(Refer Slide Time: 03:22)\n \nSuppose we take the union of 2 and 7, then either we want to update the leader for 2 to 7 or we want to update the leader for 7 to 2. This is all that we need to do because we are merging 2 singleton sets here. We will come back and think about what the algorithm has to do in general. But here physically, it is enough for me to just change the leader value of 2 to 7 because the only element in the set that contains element 2 is element 2 itself. This is the only update that I need to do if I want to make 7 the new leader.\n(Refer Slide Time: 04:04)\n \nNow, let us say that we have to take the union of 5 and 6. Just as before, I am going to change the leader of the set 5 to 6. This is going to signify the fact that 5 and 6 have now been merged into a single set.\nLet us say that the next union operation is between 5 and 4. Once again, I can achieve this by updating the leader element of the set 4 to 6. I could have equally achieved this by changing the leader elements of 5 and 6 to 4. But I can just visibly see that this is less work. I am going to do it this way. Once again, we will come back to how would you implement this as a general algorithm. This is something that is not yet clear.\n(Refer Slide Time: 04:48)\n \nBut let us just do a couple of more examples here. Suppose you had to take the union of 3 and 6. Once again, I can achieve this by changing the leader for the element ‘3’ to ‘6.’ So, this will have the effect of merging singleton set 3 with the set that 6 belongs to, which coincidentally is also represented by the element 6.\n(Refer Slide Time: 05:09)\n \nLet us do an example of a union, which does not involve ‘leader’ elements. Suppose you want to do ‘union’ 4 and 2. If you just read off the semantics of the union operation, what this means is that we want to merge the set that 2 belongs to with the set that 4 belongs to. The set that 2 belongs to is represented by 7 and the set that 4 belongs to is represented by 6.\nThese sets are the sets 2 and 7 on the one hand, and 3, 4, 5, 6 on the other hand. These are the 2 sets that we want to merge. Notice that this merge is equivalent to merging the leaders. It is equivalent to taking the union of 6 and 7 and one way to implement this merge is to either change the leaders for all the elements in the set represented by 6 to 7 or to change the leaders of all the elements represented by 7 to 6.\nIf you ask me which way I would prefer to do it, given that I can visibly see the sets right here, it is clear that I would prefer to change the leaders of 2 and 7 to 6 as opposed to changing the leaders of 3, 4, 5, 6 to 7 because the latter just feels like more work. However, what would a general algorithm do? Remember, that all you have is access to this array of representatives and now along comes the request for a union.\nYou are supposed to take the union of 4 and 2. By looking up the representative array, you can quickly figure out in constant time that the representative for the set containing 4 is 6, and the representative for the set containing 2 is 7. You can get this information just by looking up the representative array or the parent array.\nBut knowing that these are the representatives, we know that the way to implement this union is to either change all 6’s to 7 in this representative array or to change all 7’s to 6. The only way that we know to do this is to actually go through the whole array. Even if we knew which change we want to make. Let us say we managed to track the sizes of the sets a priori.\nWe know that we want to change all 7’s to 6. But can we actually directly probe all the elements that are 7 in the representative array? There seems to be no way to quickly access exactly those elements. What we would be forced to do is to go through the whole representative array and yes, it is true that the number of updates we perform will be not too many. So, here is our first ‘change.’\nThen we just trudge along and go through all of these other elements. We see that they are not 7. Now we see 7, so we switch it to 6. For the ones that are not 7, we do not need to do anything. That is the entire union set operation. What you would have to do is if you are taking the union of ‘i’ and ‘j,’ using one array look-up, you can figure out what are the representative elements of the sets that ‘i’ and ‘j’ belong to. Let us say that the representatives are some ‘x’ and ‘y.’\nIf ‘x’ happens to be equal to ‘y,’ you do not have to do anything. You can just go home. This just means that ‘i’ and ‘j’ were already in the same set. But if ‘x’ is different from ‘y,’ you have to either change every occurrence of ‘x’ in this representative array to ‘y’ or you would have to change every occurrence of ‘y’ to ‘x.’ This is essentially a way of saying that look, all the elements that were there in the set that ‘i’ belonged to, well we want to now signify that you belong to the set, which is represented by ‘y,’ which is the representative of the set that ‘j’ belonged to.\nWe either make those updates or we do it the other way. But whichever way we do it, even if one of those ways is cheaper in terms of the number of updates we make, just to be able to identify which updates we want to make, we will have to do a pass of the entire representative array. If we do it this way, we are going to get a perfectly valid algorithm and this merger will always happen accurately.\n(Refer Slide Time: 09:11)\n\nBut let us take a look at the complexity of these operations if they are implemented this way. The ‘find’ set is completely straightforward. We just have to look up the value in the representative array. That is just constant time. But ‘union’ set in general will involve one pass over the representative array. Every time we do a union, it is going to cost us ‘order n time.’ It is a linear-time operation.\nSometimes, you may get lucky. If ‘i’ and ‘j’ happen to be in the same set then there will be to find set calls which will detect that and you do not have to do any work. But in the worst case and typically most of the time, you will end up spending linear time doing your unions. Now, it turns out that this is not quite fast enough for the applications that we will be looking at and therefore we need to worry about doing better.\n(Refer Slide Time: 10:09)\n  \n  \nIn the spirit of looking for a better approach let us see if we can store things a little bit differently, hopefully, in a way that helps us cut down on the time that it takes to do the union operations. The key idea here is to essentially think of these elements as pointers. Where do they point to? Every element is going to point to some other element of the set.\nWhen you want to find who is the leader of the set that you belong to, hopefully, you can follow these pointers. Let us say that you want to find a set of ‘i.’ You go to the ‘i’th entry in the array and it is pointing to let us say ’j’ and then ‘j’ is pointing to ‘k.’ You just follow these pointers till you get stuck and, hopefully, the way this is designed is that you get stuck when you arrive at the leader element and that is the information that you want to output.\nFor this to actually work out, you will want the leader elements to point to themselves because that is when you get stuck. If you are a leader element at any stage, then the pointer corresponding to that element is just going to point to itself. In the beginning, when every set is a singleton set, every pointer is a pointer to itself because they have nobody else to point to. This is the natural thing that you do.\nBut as union operations come along, these pointers are going to evolve and if you walk through an example, as we will do here, you will see that visually this is going to evolve in a tree-like fashion and that is a useful thing to aid your imagination. We are not going to explicitly use a tree data structure or anything. It is just going to be an array of pointers. But it is really helpful to see the sets evolve as trees.\nLet us take a look at what happens when we do our first union operation here. As before, let us say we want to do a union on 2 and 7. Initially, 2 was pointing to itself and 7 is also pointing to itself. Now what we want to do is, essentially carry out this union by saying, look, let us have the leader of the first set point to the leader of the second set, or you could also do it the other way.\nAt the moment, let us just say we make this choice arbitrarily. The leader of the set that 2 belongs to is just 2. Similarly, the leader of the set that 7 belongs to is just 7. Let us have 2 become a pointer to 7. That essentially glues together 2 and 7 in one set. Now, let us say that we want to do the union for 5 and 6. Very similarly, let us say that we have 5 now pointing to 6. Now, let us say we want to do the union of 5 and 4.\nWhat are we going to do here? The algorithm is the following. You basically look up the leaders of these two elements. You can do that by running the ‘find’ set and remember, we briefly talked about how the ‘find’ set might work in the setting. When you want to do the ‘find’ set of ‘i,’ you just follow the pointers till you get stuck and you have information about your leader. We will come back and talk about the complexities of these operations.\nBut for now, just assume that you can actually execute them. When we want to merge 5 and 4, we discovered that the leader element for the set containing 5 is 6 and the leader element for the set containing 4 is just 4. Let us have the leader of the set ‘4’ point to the leader of the set containing element ‘5.’ We are going to have a pointer that looks like that.\nSimilarly, if we were to merge 3 and 6, the same story plays out, and let us say that we decide to have the leader of the set containing ‘3’ point to the leader of the set containing 6, which just happens to be 6 in this case. Suppose we are doing a union between 4 and 2. Once again, none of these elements are representatives. But if we run a ‘find’ set, we see that the leader of the set that 4 belongs to is 6, and the leader of the set that 2 belongs to is 7.\nWe are going to have either ‘6’ point to ‘7’ or ‘7’ point to ‘6.’ Either of these would work. Let us say that we have ‘6’ point to ‘7.’ So, 7 is the new leader element, and these sets are now merged. Now, you could think about, whether we could have done it the other way. You could also think about: Do we really need to find the leaders? Cannot we just, for instance, draw a pointer from 4 to 2? Would that not work?\nThese are good questions to ask and I would suggest that you spend some time exploring them thinking about other ways in which you could implement this pointer-based approach. In the meantime, let us go ahead and analyze the complexity of the algorithms that we just described. In fact, let us just recap the algorithms, to begin with, just to make sure that we are on the same page with respect to how they work.\n(Refer Slide Time: 15:07)\n\nFirst, let us say we want to perform a union of ‘i’ and ‘j.’ Then we said that we are going to invoke ‘find’ set on ‘i’ and ‘j.’ Let us say that we have discovered that the leader element of the set that ‘i’ belongs to is ‘x,’ and the leader element of the set that ‘j’ belongs to is ‘y.’ Now what you could do is simply make sure that either ‘x’ points to ‘y’ or ‘y’ points to ‘x.’ Either way, this will achieve what you want, which is that now every element in the set that ‘i’ belongs to will eventually get stuck at ‘y’ as the leader element or the other way around, which is essentially to say that all elements in A ∪ B, where A and B are the sets that ‘i’ and ‘j’ belong to respectively, essentially get merged and have a common leader element.\nSo, let us say that we settle for ‘y’ pointing to ‘x.’ The parent of ‘y’ is now ‘x.’ You can do it the other way, as well as of now not making a distinction between these 2 possibilities. But we will in due course. But that is a bit of a spoiler. Let me not go into that for now.\nNotice that the complexity of the ‘union’ depends on the complexity of the ‘find’ set. Now, in the previous implementation, the ‘find’ set was completely straightforward. You just had to go and look up the parent array or the representative array to figure out who is the ‘leader’ element of the set that ‘i’ belongs to. But now if you try to do this lookup, you might find that you get stuck, which would happen if ‘i’ is a leader element in its own right. Then you get a pointer to itself.\nThat is what I mean by getting stuck or you do not really discover an element directly, but you discover a pointer to some other element. What you would have to do is follow these pointers for as long as you do not get stuck. When you do eventually get stuck, at that point, you could return the element at which you got stuck.\nNotice that you will get stuck at some point because you are working with a fixed collection of elements. Notice the way in which these pointers are introduced, quite importantly you will never have a cycle. This is something that you can show formally. You never go around in a loop and you will always end up at the leader element for the set that ‘i’ belongs to.\nAgain, in the description that we have in these videos here, we are not really digging into formal proofs of the correctness of either the mechanics or the complexities. These are all fairly informal and high-level overviews. If you are really interested in the theory, I would definitely recommend looking up the book chapter that is been linked to in the description of this video.\nBut for now, hopefully, this is enough to get a sense of how the data structure works. We just want to get to the point where we understand enough of it to be able to implement it and just know what the complexities are. As I said, the emphasis here is not so much on the theoretical aspects, but they are definitely very interesting and worth knowing in their own right.\nPerhaps you know them already from a previous course in which case that is awesome. But if you do not and you are curious, then there are resources that you can certainly check out. With all of those disclaimers out of the way, these are the two algorithms for a union set and find set and now let us think about the complexities of these operations.\n(Refer Slide Time: 18:32)\n\nThe complexity of the union set is, well, you have to adjust this pointer – make sure that either ‘x’ points to ‘y’ or ‘y’ points to ‘x.’ That is a simple constant time operation. But it also has two invocations for ‘find’ sets. The complexity of the union set depends on the complexity of the ‘find’ set. But once you have done that, then it is really a simple constant time operation.\nWhat about the ‘find’ set? You are following these pointers around and I would really encourage you to take a pause here and try and come up with a sequence of unions that would force find set to take a lot of time. Do take a moment here to figure that out and come back when you have a guess of your own for the complexity of find set in the worst case.\nIf you thought about that, you might have been able to come up with an example that really pushes find set to take order ‘n’ time. This will only happen once your sets have developed sufficiently in the first few calls to the union. Assuming you are starting with all singletons, your sets are going to be fairly small. All of those find set operations will be cheap just because the sizes of the sets are cheap.\nBut once the sets start becoming bigger, you might end up doing your pointing of parent pointers in such a way that the trees that you develop have a large height. Basically, it is going to take a lot of time to get to the root. One way to improve this situation is if you could somehow guarantee that you are always building out shallow trees where the distance of any node to the root is somehow under control.\nAs we said, it is not very hard to come up with a sequence of operations, which forces find set to take order and time. But let us see if we can do better. One natural heuristic is something that we hinted at in the previous part of this module. We were saying that imagine that you are trying to do a merger between two companies. It is only natural that the leader of the larger company will somehow persist.\nNow, I do not want to simply think of this in terms of the sizes of the sets that are involved, but rather, in terms of the depth of the trees that we have developed around these sets. Remember that as you are building these pointers out, you are really developing a tree-like structure. Let us say that you are trying to merge 2 sets, where the corresponding trees have depths D1 and D2. Now, if D1 is smaller than D2, would you want that the tree which has depth D1 to become a subtree of the tree, which has depth D2?\nIn other words, would you want to have the leader of the first set point to the second set, or would you want to have it the other way around? Think about which one is better in terms of giving you a tree with as small a height as is possible once you are finished. Think about that for a second and once again, come back when you are ready. Hopefully, you had a chance to think about this. Let us try and visualize the situation that is been presented to us.\n(Refer Slide Time: 21:47)\n  \nLet us say we have this abstract cartoon for the 2 sets that we are working with, with these triangles, kind of representing the corresponding tree structure on their pointers. Let us say that the heights of the triangles are representative of the depths of the corresponding trees. Remember that the depth of a tree is sort of the longest path that you may have to endure in going from any vertex to the root.\nThe longest route-to-leaf path would be the depth of the tree and what we were presented with was 2 choices. We could either have the smaller tree point to the bigger one, which is to say that the root of the larger tree in terms of the ones that have the greater depth is the new leader. Or we could go the other way, where we say that the leader of the smaller tree, the underdog element, is the new leader. The larger trees route points to the root of the smaller tree.\nIt could work out in one of these 2 ways. But notice that when we run with the second option what happens is that the overall tree that you obtain has a height one more than the tree that you were working with before. Because you could take the longest path that you had to endure in the tree that had a higher depth and that path is now going to get extended by one.\nThis new tree is taller than the one that you were working with before. On the other hand, if you absorbed the smaller tree into the bigger one, then the paths in the smaller tree do get elongated by one. But because the other tree was bigger anyway, the overall depth does not increase. It seems like a fairly natural heuristic to say that we will make the root of the shallower tree a child of the deeper one. We have the root of the smaller tree points to the root of the bigger one.\nSome people would call this the ‘union by depth’ procedure. Whenever you are taking union, try to do it this way. To actually implement this, you will have to keep track of the depths of the trees as you go along. This is not very hard to do. It is just a little bit of extra book-keeping. But you can argue that if you do this then the heights of the trees that you encounter will always be bounded by log ‘n.’\nI will not go through the argument here, but it is really cute proof. If you want to do it formally, you can do it using the framework of induction. Once again, you can look up the book chapter that is been linked to, if you actually want to go over the proof. This proof is not particularly difficult and if you are curious, you should definitely check it out.\nWhat this ensures is that the complexity of your union operations stays the same because it is still constant + the complexity of the find set operations. But the find set operations now will never take more than log ‘n’ time because your trees maintain the invariant that the depth is always at most log ‘n.’ This is already a pretty nice improvement. But it turns out that you can do even more.\n(Refer Slide Time: 24:55)\n\nLet me describe another really popular heuristic called ‘path compression,’ which says the following. Whenever you are doing find set, you are anyway walking up the stream of pointers. Now, you know that every element that you encountered on this path from the current node that you started off with all the way to the root, all of these elements have the root element as the parent. Why do not we just upgrade all of these elements so that they directly point to the root?\nThat will make this a shallower tree potentially and it will definitely speed up future find set queries not only for the current element but for any element that was there on the path from the current element to the root. Essentially, what we do is that we are going to sneakily update the parent pointers as we go through the journey from the current node to the root. It is not going to take any extra time – not in a substantial way – it is just probably going to be constant overhead from what you were doing before.\n(Refer Slide Time: 26:02)\n   \n  \nIn fact, let us just walk through an example so that it is clear as to what we are trying to do. Suppose you have the ‘find’ set invoked on element 7 here. Let us try to think of the ‘find’ set now as a recursive process. What we are going to do is basically return the current element if it is pointing to itself.\nIf it is a leader that is kind of the base case of the recursion. Otherwise, you are going to return the outcome of the ‘find’ set for your parent because that is really the answer. It is representative of the set that your parent belongs to. You could invoke find set on your parent. Let us do that.\nBut now to implement the path compression heuristic, we are actually not just going to return but once we have the information from this recursive call, we know who the leader element is, just before we are completely done, we just want to update the parent pointer of this element directly to the root of the stream. Let us see how that is going to work.\nWe are going to invoke find set on the parent of 7 because 7 is clearly not a leader element. We are going to temporarily just detach the parent pointer because we know that we want to update it. That directly points to the root. At this point, we still do not know what the root is; The program is going to invoke find set on the parent of 5.\nBecause, once again, 5 is not a leader element. We are going to get into this recursive invocation of find set on 3 and we are going to also detach the parent pointer for 5 because we know that we do not want to point to 3 anymore. We want to directly point to the root and notice that we still do not know where the root is.\nHopefully, we are going to find out in the next step. When you come to 3, once again, 3 is not a leader element itself. It is going to invoke find set on its parent, which is 1, and once again, it is going to set aside its parent pointer in the hope of pointing it to the root of the tree once the find set invocation returns an answer.\nBut now find set invocation has actually hit the base case. So, 1 is the root of this tree. It points to itself even though that point is not drawn explicitly. Your recursion is going to bail out at this point and it is going to say: Okay, I can return 1. Now we do a sort of a backtrace. We climb back down the tree and we know that when 3 invoked find set, it was basically waiting for the outcome of this call so that it could point to whatever the answer was.\nNow 3 will point back to 1. For 3 nothing changed, but we could not be sure about that until we went through the process. Let us put the pointer back in place. For 5, something more interesting happens. It was pointing to 3 before but now that find set has done its job and you know that the answer is 1. We can now point 5 directly to 1 instead of what it was pointing to before, which was 3 and we can also do this for 7.\nFor 7 was previously pointing to 5, but now we know that it might as well point to 1. That is the path compression heuristic and if you want to see it in code, essentially what you would normally do if you were just implementing raw find set without path compression is that you would say if ‘i’ is not pointing to itself, then return find set of the parent of ‘i.’\nBut now since we want to do path compression, we have this small extra step here which is to say that we take the output of the ‘find’ set invocation and we update the parent pointer of ‘i’ to whatever was outward by the find set call. Since this is happening in recursion, as we saw in this example, this will update the parent pointer not only of the element that you started off with but in fact, every intermediate element that you encounter in your journey to the root.\nMaybe there are no elements on this journey. Maybe there are very many of them. It is hard to predict what this looks like. But it definitely feels intuitive that you have gained something. In this example, for instance, any future calls to find set on 7, 5, or 3 would actually run in constant time.\nNow, the question of estimating how much of an improvement this really is, what are your gains from doing this is actually quite non-trivial and if you are really interested and you have some time, then you could roll up your sleeves and look at the arguments that are given in this book chapter from Erickson's algorithms, where there is a fairly detailed analysis of how much of an improvement is guaranteed by path compression.\n(Refer Slide Time: 31:06)\n\nFor us, it is enough to know that this improvement actually gives us effectively constant time for both of these operations. I am using the word ‘amortized,’ which is to say that an individual operation may not run in constant time in the worst case. But if you do ‘m’ of these operations, then the total amount of time that you need is going to be ‘m’ times some constant.\nSome of these operations may require a lot of time. You may have to do a sequence of climbs on some tree. But as you do this, every time you actually pay a price, you are improving your future. The calls that come in later become much cheaper for the hard work that you may have done at a certain step. Typically, the form of what actually happens is that you are going to have a few steps that may be expensive.\nBut this really cleans up the amount of work that you have to do later. Now, even this constant is not truly a constant. What you can argue is that this is some very very slow-growing function of ‘n.’ It is called the inverse Ackermann function. It is a very interesting function to study. But it is also fairly messy to describe. So, in the interest of time, I will not be even defining this function.\nBut the reason I am writing down order one here is: Because the inverse Ackermann function is such a slow-growing function of ‘n’ that it only takes values up to 4, I think, even if ‘n’ is very, very large, even in the billions. For contest programming for the kinds of values of ‘n’ that you are going to encounter, this function is definitely going to just be a very small constant. The behind-the-scenes statement is really the following.\n(Refer Slide Time: 32:53)\n\nIf you have ‘M’ calls to find set – these could be direct calls to find set as is given by your query sequence or these could be calls to find set that are embedded inside the union algorithm – either way, if you are making ‘m’ total calls to find set, then all of that can be executed in time M x αn where α is this inverse Ackermann function. As we said, this is something that we do not need to worry about for the kind of values of ‘n’ that we will be working with.\nSo, M calls can be executed in order M time and that is what we mean when we say that it is constant amortized time per operation. If you are literally in the middle of a specific operation, the worst-case time may not be a constant. It may be that you are in a situation that is bad. But every time you go through a bad experience, you end up doing some amount of clean-up, which helps the future operations along.\nNow the analysis of how exactly this intuition plays out is actually pretty non-trivial and it is a complicated argument. We will not really be getting into it. But if you are really curious about it, then if you have some time, please roll up your sleeves and look at the disjoint sets chapter in the text on algorithms by Erickson. It is again linked to in the description and you can find a fairly detailed analysis of how this bound actually works out.\nThat is what is going on with the ‘find’ set and with the ‘union.’ It is essentially composed of two calls to find set and then one pointer adjustment after comparing ranks.\n(Refer Slide Time: 34:39)\n\nIn fact, that reminds me that I should say that these two heuristics play reasonably nice with each other. Remember, we had a union by depth heuristic before we talked about path compression. Now, when you do path compression, the way that you do the book-keeping for the depths of the trees, that might get messed up a little bit because your trees are becoming shallower and the depths may in fact reduce.\nGenerally speaking, it is a bit expensive to go and re-compute depth. We do not really re-compute depth but we just work with whatever information we have at hand. It turns out that all the claims that we have made work with this combination. Implementing depth in a slightly non-accurate way the best we can and combining it with path compression works out just fine.\nThis is sometimes called ‘union by rank and path compression.’ Just to keep in mind that the depth information that you are storing may not be reflective of the true depth because of the adjustments made by path compression. But it is still a valid upper bound on the depth of the trees that you are maintaining and it turns out to be a good heuristic to use.\nThat is essentially what we are going to do. Just to come back to the complexity of the union operation – you just have to compare the depths and update the depths whenever necessary. When you are merging 2 trees that have the exact same depth, then you would have to increment one of them by one. All of this is essentially constant time operations over and above the two calls to the ‘find’ set. Since the complexity of the ‘find’ set has already been accounted for, you can think of the union operation as really being a constant time operation.\nI will still say constant time amortized because it has these find set invocations involved. But just know that it is the complexity of the ‘find’ set + a constant amount of work. That completes the description of all the algorithms that are involved in the disjoint set union data structure. Now, it is time to take a look at the implementation and we are going to do that in the final part of this module, which is in a separate video. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec16.html",
    "href": "materials/cpnotes/Lec16.html",
    "title": "Disjoint Set Union - Module 1 (An Introduction)",
    "section": "",
    "text": "Lecture - 16\nDisjoint Set Union - Module 1 (An Introduction)\n(Refer Slide Time: 0:11)\n\nHello and welcome to a brand new week in Getting Started with Competitive Programming. So, this is week 4 and this week we will be talking about problems that can be solved using a data structure that helps you keep track of a collection of disjoint sets. The data structure itself goes by many names. Some people like to simply call it ‘disjoint sets.’ Some people call it ‘union-find disjoint sets,’ and so on.\nWe are going to call it ‘disjoint set union’ because that abbreviates to DSU and that is the most common abbreviation that I have seen when it comes to tagging systems on contest programming platforms. So, the plan is the following. In this module, we will introduce the data structure itself. We will explain what operations it is expected to support and we will talk about a couple of natural ways to implement the data structure, which turn out to be not efficient enough for use in practice.\nWe will then improve it to the professional version, which you can actually go ahead and use in your contests. Now, we will not be actually proving the guarantees that come with these implementations. If you are really curious, there is a beautiful book chapter, which goes over the details, and that is linked to in the description of this video.\nPlease go ahead and check that out. Let us begin by talking about the data structure itself. Notice that the description of a data structure is fully specified once you tell me what information it is supposed to maintain and what operations on that information you wanted to support. So, what do we want to store in a disjoint set union data structure?\n(Refer Slide Time: 02:00)\n\nWell, we want to maintain a collection of disjoint sets, as the name suggests, over some fixed universe. Throughout this discussion, I am going to use numbers from 1 to ‘n’ to denote the elements of my universe. Remember that in a specific application, you may not have numbers from 1 to ‘n’ as your universe; they could be something else. They could be characters, they could be the vertices of a graph, or just something completely different.\nHowever, typically, the elements that you are working with can be indexed by numbers from 1 to ‘n,’ if there are ‘n’ of them. I think this is a convenient abstract notation to work with. Just remember that this may not always literally be your universe, depending on the situation you are working in. Now, each of these sets is represented by what is usually called a ‘leader element.’ Sometimes, it is also just called a ‘representative element.’\nJust think of each set as being labeled by one of the elements in that set. If I want to talk about a specific set in this collection, I will be able to point to it or I will be able to talk about it by simply specifying its leader element. You can think of the sets as being packaged into boxes, each box has a label, and that label is essentially the value of the leader element or the representative element.\nThe leader element could be any element of the set. But what is important is that every set has exactly one of these. Since your sets are disjoint, the leader element completely specifies the set unambiguously. No element can be representing two sets because no element belongs to more than one set. That is the information that we want to maintain. What are the operations that we want to support? We want to support two kinds of operations. Sometimes you might want to support a few more, some routine ones, and we will see that when we get to the implementation.\nBut this is really the crux of it. Given an element, you want to be able to find the set that it belongs to. If I give you a number between 1 and ‘n,’ you want to be able to tell me which set it belongs to, and because of what we just discussed, this basically amounts to returning the leader element of the set that the element ‘i’ belongs to. It could be that ‘i’ itself is a leader element, in which case, we just return ‘i’ as the answer to this query.\nOtherwise, if ‘i’ belongs to a set for which it is not the leader element, then we want to return the leader element of that set as the response to this query. The other thing that we want to do, and it is again hidden in the name, is a union operation. If I give you two elements ‘i’ and ‘j,’ then we want to be able to merge the two sets that ‘i’ and ‘j’ belong to. It is possible that when you are given this query, ‘i’ and ‘j’ happen to already belong to the same set.\nIf that is the case, in this query, we do not have to do anything. But if they happen to belong to two different sets, then we want to be able to merge them. That is the entire data structure. Now, in some situations, you may not know the entire universe upfront and elements of the universe may reveal themselves as a part of some process.\nTo handle such scenarios, you may want to implement an extra operation which you could call ‘make set’ or ‘create set’ or something like that, where the input is going to be a single element and your task will be to create a singleton set out of that one element. I have not written that down explicitly because we will not really be needing this most of the time.\nBut if you are in a situation where you do need it, it is usually very straightforward to implement. You can go ahead and do that as a simple exercise. It turns out that DSU is really useful in a wide variety of situations. Sometimes you can look at a problem statement and by just seeing the structure of the queries, you see that the problem is screaming DSU. It is very clear that is what you need to use.\nSometimes the connection is a little more subtle and you may have to really use your imagination to see that this is a DSU based problem or that DSU would come in handy here. In some advanced problems, you need to use DSU in combination with other techniques. Overall, this is a really useful tool to add to your toolkit. Just to demonstrate, let me show you how you can use this data structure, for example, to keep track of connected components in a graph, if that is what you need to do.\n(Refer Slide Time: 06:53)\n  \n  \nLet us say that you are given that you are working with a graph on some ‘n’ vertices, and to begin with, that is all that you know. All the vertices are just isolated and they form singleton sets on their own right and as you go along, you start getting information about the edges. Whenever a new edge is added to the graph, what you want to do is take the union of the connected components that the endpoints of the edge belong to.\nBecause, now essentially, the two components, which could potentially be the same, in which case, you do not need to do anything, but the two components that the two endpoints of the edge belong to now become connected by virtue of this edge being added. Notice that just in case you had a situation where edges were being added and removed, then it is going to be a bit tricky to use DSU. Remember that DSU only supports union operations. It does not support breakages. It does not allow you to separate the elements of a set once it is been created.\nOnce a gluing is done, it is a little bit like what you see in the Fevicol advertisements. It is permanent and you cannot really separate the set out later. If edges are coming and going, if they are being deleted as well, then you need a slightly different approach. But let us just look at how this would work if edges were only being added. To begin with, every element is a singleton set and it is the leader of its set because there is no choice.\nEvery element is a representative element and throughout this example, we will use these dark black circles to signify that an element is currently a leader element. As we go along, the ones that are not representatives will sort of fade away a little bit. Let us say, that to begin with, we are adding an edge between elements 1 and 2.\nThat gives us this one connected component with an edge. There are just two vertices in it and we can capture this by invoking the union operation on the endpoints of the edge. We combine 1 and 2 into one set and this currently has two representatives, which is a violation of our convention. Let us identify a leader element.\nIn this example, I will be identifying representatives quite arbitrarily. I am not going to evaluate these elements for their leadership skills or anything like that. But in general, you can imagine that if you are trying to merge or take the union of two sets, both of these sets already have their leader elements and when you do the union there are two natural choices for who should be the representative of the new set.\nIt could either be the leader element of the first set or it could be the leader element of the second set. You can imagine that if these are two corporations that are going through a merger, there may be a discussion about which one should persist as the new leader or the new face of the company. It could be that you might want to do a totally bizarre thing of picking some other element from one of the two sets as the leader.\nBut typically, that is not something that we would do because it is usually simpler to just assign one of the existing leaders as the new leader for the set that is obtained after taking the union. In general, it would be perfectly valid to make this choice arbitrarily. But again, thinking about the analogy of the merger, sometimes it may feel like it is natural that the bigger company retains rights to leadership.\nIt turns out that is sometimes a useful heuristic to employ. In fact, it can give you some provable performance guarantees. That is something that we will come back to later. We are getting a little bit ahead of ourselves at this point. As I said, in this example, the choices for leader elements are going to be completely arbitrary. So here, let us go ahead and assign 1 as the leader element. Next, let us say we have an edge between 4 and 3.\nThat gives us this set, which is obtained by taking the union (denoted by the symbol ‘🇺’) of 4 and 3, and once again, let us arbitrarily designate 4 to be the leader element. Next, let us say we have an edge from 5 to 1. So, we will just invoke union ‘5, 1.’ We want to take the union of the set that 5 belongs to, which happens to be a singleton set, and the set that 1 belongs to, which happens to be this component with two vertices.\nNotice that in this example, the endpoints of the edge that you have introduced happened to correspond to the leader elements of their respective sets. This may not always be the case and it is not really relevant. All we need to do is make sure that the sets that these elements belong to get merged and we can do that in this case by just expanding the scope of the set 1, 2 so that it now includes 5.\nAs usual, let us make sure that this set has a unique leader element, and let us say that continues to be 1. Now, let us say that in the next step, we add an edge between 6 and 7. Once again, we invoke 6 🇺 7. That will give us this set here with two elements in it. Let us again make sure that this set has a unique leader element. Let us say that is going to be 7, and now let us add an edge between 4 and 6.\nNotice here that this edge is connecting a leader element with a non-representative element. Once again, it does not really matter. The semantics of the operation is that we need to merge the sets that these two elements belong to and if they happen to be the same set, we do not have to do anything. But that is not the case here.\n(Refer Slide Time: 12:47)\n  \n \nLet us go ahead and merge these two sets to obtain a bigger set with four elements in it. Once again, it currently has two representatives and since that is not allowed, let us make sure that there is just one. In this case, let us say we pick 7 as the choice of representative. Let us say that the next stage that we add is between 2 and 3, and notice that this time, you are actually connecting two elements, which are both not leaders in their own sets.\nOnce again, not so relevant. Remember that our task is to make sure that the set that 2 belongs to is merged with the set that 3 belongs to. Let us carry that out and once we have this merger, we get this one giant component. Again, there are two competing representatives, 1 and 7. Let us make sure that we knock one of them out.\nIn this case, let us identify 7 as the new leader element. Right now, our graph has three connected components: one involving 7 vertices, and then there are two other isolated components. Let us say that now the edge that we add is between 4 and 7. Notice that this has no real effect. For the record, you will want to invoke 4 🇺 7 but what that will do is basically lead to the discovery that 4 and 7 already belong to the same set.\nSo, there is no union. No actual merging is required in this case. This also happens for instance, if you add the edge between 5 and 4. In general, if you add an edge such that both of its endpoints are sitting in the same component, you will of course have to invoke the union operation to respect the fact that you have taken note of the fact that this edge is been added.\nBut when you actually try to execute the union, nothing non-trivial happens because nothing really needs to happen. Of course, until you actually check you will not know. Remember that when an edge comes in, you have no idea what effect it is going to have. It is only when you invoke the union operation that you get to discover if this actually created a non-trivial merger or whether it is just an edge that got added to an existing component.\nThat brings us to the end of this particular example. I will say that tracking connected components are one of the most common applications of DSU. If you can somehow identify that is what is going on in a problem that you are solving, that you can model it somehow as a graph and your task boils down to keeping an eye on the connected components, then chances are that DSU will come in handy somewhere.\nRemember that if the process involves both the addition and removal of edges then what I just described will not quite work and you need slightly different techniques in that setting. But at least if you are in a situation where the edges are just being added, then this would certainly be a very relevant data structure to use. Now notice that in our entire discussion, we did not really talk about how to implement these operations.\nWe just assumed that if we could do these operations then we can track the connected components, as we just described. In fact, we only used the union operation so far. You could use the ‘find’ operation as well to identify which component a vertex belongs to, and with a little bit of extra book-keeping, you could also track additional interesting information about the state of the graph.\nFor instance, you could track the number of connected components. You could also track the sizes of the individual components. You will just have to remember to update them after you perform a union operation. But all of this can be done and once you have the basic data structure in place, these additions are really fairly straightforward to do.\nIn fact, in the implementation that we will see, we will actually track these two pieces of extra information, which is the number of components and the sizes of the sets and we will try to see how they evolve as we perform the base operations. So, let us take a pause here. I will encourage you to think about how you would implement this data structure on your own, especially if you have not seen it before.\nIf you have encountered it before, you probably will find a lot of our discussion familiar. But if you are seeing this for the first time, just spend some time thinking about how you will implement this yourself? What are the complexities of the individual operations? How long will it take you to perform a find? How long will it take you to perform a union?\nI will say that I think there are two fairly natural ways of going about this and I expect that you will probably discover one or both of them. Whenever you are ready, come back and watch the second part of this module where we dig deeper into the actual implementation of this data structure. We will first discuss it theoretically and then we will finally wrap it up with actual code that you can use!"
  },
  {
    "objectID": "materials/cpnotes/Lec02.html",
    "href": "materials/cpnotes/Lec02.html",
    "title": "Ad hoc and Implementation - Module 2 (Reversort Engineering)",
    "section": "",
    "text": "Lecture - 02\nAd hoc and Implementation - Module 2 (Reversort Engineering)\n(Refer Slide Time: 00:11)\n\nWelcome back to the second module of the first week of getting started with competitive programming. In this video, we will be talking about a problem called Reversort Engineering. This will be building upon the reversort algorithm that we discussed in the previous video. So, just in case you have not watched that, please make sure that you do before starting this video. Now, let us get started as usual with the problem statement.\n(Refer Slide Time: 00:36)\n\nIn the previous problem, which was reversort, we were given a list of numbers as input, and our task was to calculate the cost of reversorting that list. In this problem, our task is going to be exactly the opposite, which is to say that we are now given a cost as input, and our task is to produce a list, which has that cost.\n(Refer Slide Time: 00:52)\n\nSpecifically, we are given two integers n and C as input, and we have to find a list of n distinct integers between 1 and n, such that the cost of applying reversort to this list is exactly C or we conclude correctly that there is no such list. How do you go about tackling something like this? To begin with, notice that the question allows for the possibility that there might be some values of C for which this task is not feasible at all. So, maybe that is a good place to start - To try and understand what is a reasonable range of values for C where this task even makes sense.\n(Refer Slide Time: 01:36)\n\nLet us begin by recollecting what reversort actually does. Remember that it goes through N-1 iterations. In each iteration, it tries to locate the minimum element and reverses the sub-array from the current location all the way up to wherever the minimum element is.\nLet us recall a couple of minor but important details. The first is that if at any point, you are reversing a sub-array of length 1, it may not feel like you are doing any reversing at all, but it still has a cost of 1 unit. The other thing to remember is that the total number of iterations is N-1 for lists of length N. So, essentially, the last step is something you get for free.\nWith that in mind, let us try and come up with a lower bound for the cost C. In other words if you are reversorting some array of length N, is there a minimum cost that you have to pay, irrespective of what the array looks like? If you feel like it, take a moment here to pause and think about this question.\nSo you might notice that reversort has N-1 iterations and because of what we just said, the cost of every iteration is at least 1. There are no free lunches in this entire process at all. So, the cost of reversorting any array of length N is at least N-1. So, if the value of C is strictly less than N-1, then it is pretty safe to declare that there is no such list.\nOn the other hand, let us think about if there is a list whose cost is exactly N-1. Feel free to take a minute if you needed to think about this. So, if you did have a list whose cost was N-1, what would it look like? We already know that there are N-1 iterations and each of them has a cost of at least 1. So, if the total cost had to be exactly N-1, then we could not afford to have a cost of greater than 1 in any iteration.\n(Refer Slide Time: 03:36)\n\nEventually,\n\nIn other words, every iteration must have a cost of exactly 1. When does that happen? Notice that that can only happen if, at every step, the minimum element in that step is already in its correct position. Therefore, the only arrays who have a reversorting cost of N-1 are those which are already sorted, to begin with. In fact, it is interesting to know that for this value of C, the solution is in fact unique.\n(Refer Slide Time: 04:15)\n\n\nSo far, we have seen that the cost has to be at least N-1 for us to have a chance of constructing a list with cost C. Now, let us try to understand what is happening on the other end of the spectrum, which is to say, can we come up with an upper bound for the cost C? How large can C be for us to have some hope of constructing a list with cost C?\nThis time, you want to think about coming up with a scenario where the cost of reversals is as large as it can be in every single iteration. This will lead to some sort of an upper bound. Think about this for a minute and come back when you are ready. So, let us recall that there are N-1 iterations.\nBut notice that the length of the array that the algorithm is working with is shrinking in each step. So, in the very first step, you are looking at the entire array, and in the worst case, maybe you have to reverse the whole array. In fact, we have seen examples where this actually happens. Right?\nSo, in the first step, your cost could be as high as N. But in the second step, since the first element has fallen in place, the sub-array under consideration starts from the second index and goes all the way, till the end. Again here, in the worst case, it is possible that your cost of reversal is N-1, but it is certainly no more than N-1.\nMore generally, in the ith step, the cost of reversal can be as bad as N-i, but no more. And remember that the iterations only go on till the N-1th index. Putting everything together, we know that the cost of reversorting is no more than this sum. If you work it out, it turns out to be and into {[N(N+1)]/2}-1. This is the maximum cost of reversorting any array of length N.\nOnce again, like before, if the cost that we have is greater than this bound, then we can immediately conclude that there is no list of length N, whose cost is exactly C. But now the more interesting question is the issue of finding a list, which actually realizes this upper bound.\nFor a given N, can you come up with a list of numbers from 1 to N, whose cost of getting reversorted is exactly the expression that you see here? Feel free to try this out for some small values of N. I will say that this question is slightly harder than the question of coming up with a list whose cost was exactly N-1. So, take your time and come back to this lecture when you are ready.\n(Refer Slide Time: 06:36)\n\nAs I was suggesting, let us look at some small values of N. The smallest possible value of N that makes sense is 1. Notice that the cost of reversorting, the only array of length 1 is actually 0 because remember, we have N-1 iterations and here, therefore we will have none.\nThe next value of N is 2. There are only two arrays of length 2 over the numbers 1 and 2. So, the array ‘1, 2’ is already in its proper order and the cost of reversorting it is just 1. The array ‘2, 1’ requires a swap in the first step and has a reversort cost of 2. This, of course, is perfectly valid. But notice that we took a brute force approach to coming up with the solution. This is not likely to scale well for large values of N.\nLet us try to arrive at the same conclusion but in a slightly more general way. This may be a slightly funny exercise, because we are dealing with a really small array, but bear with me. We will also go through this when N=3. Hopefully, things will become clearer as we go along.\nLet us think in slightly more general terms about the task of coming up with a list whose cost is as high as it can be. What should we aim for in the first step? Well, in the first step, the maximum cost that we can have is N, which happens when you have to reverse the entire array. When would you reverse the entire array? You would do that if the minimum element is at the very end. So, we already know that in our array, we are forced to place the number 1 at the last position.\nNow, we have to fill up the rest of the array, just to say that we now turn our attention to the first N-1 slots of the array. Of course, with N being just 2, we only have one slot remaining and it is no surprise what should go in there. But bear with me, let us just continue thinking about a general strategy for filling up these first N-1 slots.\nNotice that in the row above, we already have an array of length N-1 whose cost is as high as it can be. So, it seems like a tempting idea to just copy-paste that array in these N-1 slots that we are yet to fill. What is the effect of this? The first thing is that we are no longer left with a valid permutation because we have copy-pasted an array that consists of numbers from 1 to N-1. We also have a 1 at the very end.\nBut as you will see, what really matters is not the specific numbers, but their relative order. So, to fix this and to turn the current array into a permutation, let us just bump up each of the first N-1 elements by a plus 1. This brings us to the array ‘2, 1,’ which is the solution that we had identified, to begin with, by just exploring both the possibilities that we had at hand.\nLet us just make a note of the cost here and move on to the case when N=3, where this whole process might be a little more visible. Notice that as before, to begin with, we have to place 1 at the very last position, if we want the first step to have the maximum possible cost. After this, to fill in the blanks like before, let us just pull down a copy of the array from the previous row. Noting that we do not have a permutation yet, let us just go ahead and upgrade each of those numbers by 1.\nNotice what happens when you run reversort on this array that we have. In the first step, as we predicted, the whole array gets reversed and that has a cost of 3. But after that, notice that we actually have a fully sorted array. So, in the second iteration, we would not get the maximum cost that we are looking for, it is just going to be a cost of 1 for a total cost of 4. That means that we still have some work to do.\nSo, what is going wrong here? Although we did copy-paste a full cost array from the previous row, notice that that array gets damaged after the first iteration. We have designed our array so that the first iteration reverses the whole list. So, as a result, the list that we carefully copied over from the previous step also gets reversed.\nBut the list that we had in the previous step is the list that we want to see at the start of this second iteration, after the first reversal. So, to ensure that is what happens, all we need to do is reverse the list in advance so that the first reversal will reverse it back to what we actually wanted to see.\nYou can pause the video here and convince yourself that this list that we have here has a cost of 5, which is the maximum cost that you can expect from an array of length 3. Now, you can repeat this process quite predictably for larger and larger values of N. Every time you will be able to leverage the list that you build in the previous step to obtain a full cost list in the current step.\n(Refer Slide Time: 11:38)\n\n\nLet us recap what we have learned so far. We have established some boundaries on the values of C. We said that C has to be at least N-1 and at most {[N(N+1)]/2}-1. Anything outside of this is already impossible. For these specific extreme values, we are also able to come up with strategies for building lists whose costs are these exact values.\nNotice, however, that we are still left with the question of what happens when C lies strictly between these two extremes. Then by just looking at these inequalities, it is not completely obvious if we can always build a list of length N whose cost is exactly C. Let us think about the recursive approach that we just used for building a list of the maximum possible cost. In fact, let us just play with a few scenarios to build up some intuition and from there, hopefully, we will be able to develop an actual algorithm.\n(Refer Slide Time: 12:18)\n\n\n\n\n\n\nEventually,\n\n\nSuppose somebody gifts you an array of numbers from 2 to N, whose cost is D. Can you use the array to build an array of numbers from 1 to N, whose cost is, say, D+1? Notice that that is easy, you can do that by just adding element 1 to the head of the array. This way, the first step essentially has cost 1, and the second step encounters the original array and from there on, the total cost of the algorithm will be D.\nWhat if you wanted to build an array of numbers from 1 to N, whose total cost was D+2, instead? Well, then the natural thing to do seems to be to push element 1 to the second position so that the first step will have a cost of 2. Then, again you are left with the original array that you started with. From the second iteration onwards, you will have a cost of D.\nThis array that you see right here has a total cost of D+2. What if you wanted to build an array whose total cost was D+3? It seems like the natural thing to do again would be to push 1 a little further up. But remember, just like we had this problem before, this particular array will not have a cost of D+3, because the first step will cause a reversal, which will mess up with the structure of the original array.\nIn particular, after the first step, the array is going to look like 1, x2, x1, x3, and so on. So, you have really lost the base array that you started with. To fix this, we should swap the elements x1 and x2. Now this array, overall, will have the desired behavior. Notice that in the first step, the reversal will give us the array 1, x1, x2, and so on. That is exactly what we were looking for.\nYou can probably see where this is headed. If somebody gives you a base array of numbers from 2 to N with the cost of D, then you can make use of this array to build an array of numbers from 1 to N, with a cost of, say, D+4, D+5, and so on. In fact, you can do this for any D+x, for any x in the range 1 to N.\n(Refer Slide Time: 14:33)\n\n\nLet us go back to the big picture and try and understand why all this is useful. To begin with, remember that when you are working with N, here is the valid range of values for C. C has to be at least N-1 and at most {[N(N+1)]/2}-1. Let us add to this picture the valid range of values for C relative to N-1.\nThat is going to be N-2 for the lower bound and {[N(N-1)]/2}-1 for the upper bound. So, the idea is that you are starting with a cost C that is in the green range, and if you can subtract from it some amount that will take you to the red range, then the recursive algorithm pretty much writes itself.\nBut the question is, can you always subtract something appropriate? Can you always subtract something that is workable? Well, notice that the difference between the two upper bounds is exactly N. What this means for us is that no matter where the original cost lies, as long as it is lying within the valid green range, we will always be able to subtract a quantity x, which is such that it is between 1 and N so that we get a cost which lies in the red range.\nThen we can pass this off to the recursion fairy, which will do its thing, and it will be able to give us an array whose elements are between 1 and N-1, and that has caused C-x. And of course, you can just add 1 to each of these elements to get an array of numbers between 2 and N, which have a cost of C-x to be reversorted.\nAs the final step, what you want to do is add the number 1 in the correct place to adjust for the cost of x. You want to add the number 1 at the exit position from the left, and everything that you have before the number 1 needs to be reversed so that when the first reversal happens, you recover the array that you obtained from recursion.\n(Refer Slide Time: 16:40)\n\nBy now, I think we have everything that we need to know to be able to implement this solution. Let us just do a super quick high-level recap, and then we will switch over to coding. The first thing we want to do is check the range of C. If C is not within the valid range, then we can immediately conclude that this is an impossible situation and we say as much. But if C is within the valid range, then we need to figure out how much we need to shave off from C to land in a valid recursive sub-instance.\nOnce we do that, we obtain the array from recursion, adjust its values, place one in the correct place, and execute one final reversal to get to the array that has the desired cost. With all this being said, I think it is time to start coding. If you want to do this yourself, by all means, this is your usual spoiler alert, you might want to pause the lecture here and come back to it after you have given it a shot yourself.\n(Refer Slide Time: 17:29)\n\n\n\n\n\n\n\n\n\n\nSo, we have our usual setup here. As before, I have pulled in the values of the sample input and outputs for your reference in the files to the right. Now, the sample outputs for this problem are a bit different from usual, in the sense that it is not going to be a character-by-character match as it usually is for most problems. Notice that, for some values of N and C there might be multiple arrays of numbers between 1 and N whose cost is exactly C.\nIn this case, the problem description says that as long as you print any one of them, your answer will be accepted. Your judge in this case is not going to be doing a character-by-character comparison with some sample output. But rather, it is going to take up the array that you output and it is going to compute the cost of reversorting it and check if it matches the expected cost.\nIf your output does not match with the sample output, maybe because you had a different way of generating these arrays, then do not worry about it too much. Although I would recommend writing down a function that computes the cost of reversorting an array. You have probably already done this if you have solved the previous problem.\nSo, you could use that function as a way to sanity-check your own answers. Once you are producing an array, just use this function to compute its cost, and see if it matches with the expected cost. Rather than trying to do a character-by-character comparison with the expected output, especially if it does not match.\nMoving on, I have already set up the parts about taking in the input. The output format is the usual Code Jam output format. You have to output case number x, followed by either the list or the word IMPOSSIBLE depending on the situation.\nLet me come back to the code. What is already done for you is the basic case analysis that we discussed in the beginning. So, if the cost C is not in the appropriate range that we discussed, then we just print IMPOSSIBLE directly. Otherwise, we have a helper function, which will actually construct this array for us, and you just print this array in the next step.\nLet us focus on building out this helper function because then we would pretty much be done. So, the construct function takes three parameters as input. The first two are quite natural: it is the length of the array you want to construct, that is N, and it is the cost that you want to achieve, that is C.\nThe third parameter tracks the current minimum value of the array. To begin with, of course, this is 1. But in general, as you unravel the recursion, you will want to increase the value of this minimum element. There are other ways of implementing this, but I just found this one to be the most convenient.\nLet us try and see how we would actually do this. Let me just begin by pasting the function signature to save time. N and C are defined as before and M is the variable that we will use to track the current minimum. Now, whenever I am writing a recursive function, I like to get the base case out of the way first, to avoid dangerous situations. So, the natural base case here is when N=1.\nSo, this is an array of length 1 where the minimum element has to be M. We do not have to worry about whether we are working with a valid cost because we kind of know that to be a precondition. So I am not going to really check for anything. The cost here must, in fact, be 0 by the time we have hit the base case.\nIf you want, you could write a condition to check for this. But I am reasonably confident that because the costs were within the valid range, to begin with, they will continue to be within the valid range when we come down to the base case. So, here, I am just going to return the trivial array with just the element M.\nAlright, the more interesting case is what follows. Let me just pull up the picture, which represents our main solution idea. These are the relevant ranges that we are working with. Just going to get one easy case out of the way, which is to say that, when you reduce the cost by just 1, if you already fall within the valid range for N-1, then let us just do that and add the number 1 in the beginning.\nJust to save time, I am going to copy-paste this section of the code here and just take a look at what we are doing. So, we are saying that if C-1 is at least N-2, and C-1 is at most {[N(N-1)]/2}-1, then let us just invoke this function with length N-1 cost C-1 and of course, the minimum upgraded to N+1. We get this array, and then we just add the current minimum to the start of the array. In the beginning, this will be 1, but in a generic situation, you want to add the minimum element in the beginning and append the constructed array at the end.\nHopefully, this case is clear. Otherwise, we just have a little bit of extra work to do, which is to say that, we have to figure out how much to subtract from the cost C, before delving into the recursion. This is the case when the current value is kind of between the right red point here and the right green point here. When you are here, you essentially know that you are within a length’ band N, but you need to figure out exactly where you fall so that you can subtract the right amount to get into the safe zone with respect to the red range, in some sense.\nLet us write down that difference. It is essentially going to be the current cost minus the lower bound. If you subtract {[N(N-1)]/2}-1 from the current cost, then you would have x, which is what do you want to subtract. So, I am going to call that difference delta.\nNow we want to construct an array whose cost is essentially C - delta, and an array of length N-1 and as usual with an upgraded minimum, which is N+1. So, we are going to invoke the current function. This is essentially the recursive step.\nNow, in the previous case, we could just place M at the head of the array. We have a little more work to do, which is to say that, we need to find the right place to place the minimum element M. Then we need to reverse everything that comes before it.\nLet us go ahead and do that. We will, first of all, convert this string into an array because that is going to be useful for the kind of manipulations that we will need to be doing later, in particular, reversing a part of the array and so on. Notice that this array has the minimum element at the first position because that is all that we have done so far.\nLet us see if we can perform the reversal that we need to do. Let us focus on what is inside the join function, which is the array-manipulation that we are doing. Notice that we are working with a new array, which just has the minimum element followed by everything we got from recursion, and we are walking up to the deltath element.\nRemember, that delta is excluded because of 0 based indexing. We essentially need to reverse that entire chunk. Then, we simply add on all the remaining elements of the array. Since construct needs to be returning a string, all we are doing here is converting this array back to a string. And at this point, we are actually done.\nNow, there are some small formalities that remain. Let us take care of them first. Notice that we have not yet returned the answer that we have so painstakingly created. One thing that is nice about VS Code is that it gives you this muted color for those variables that you have declared, but have not used yet. So, that is already a hint that I have left something hanging.\nLet us return the answer. At this point, all that remains to be done is to actually run this code and see how it works. Let me add the template to redirect the input-output to files. Let us run this program. So, we get some output. Notice that if I were to run a diff on my output with the expected output, then we do get some differences here. You can visibly see that the arrays that we are producing are a little bit different from the official outputs.\nAs I said, in the beginning, this has nothing to worry about. But I will leave it as a bit of an exercise for you to come up with a different way of generating these arrays that possibly match with the sample outputs. Although it is not clear to me if the sample outputs were driven by an algorithm that generated them or if they just wanted to deliberately throw us off by using solutions that are different from, perhaps, the natural algorithm.\nIn any case, what is really worth doing is sanity checking that the arrays that you are generating do have the cost that you expect them to have. So, for instance, for the first array here, we were supposed to have a cost of 6. Let us quickly see what reversort would do here.\nIn the first step, you will have a cost of 1 because the minimum element is sitting right there. The next step: You will have a cost of 3 because the minimum element is at the very end. At this point, your array would look like 1, 2, 4, 3. So, the last two elements would need to be swapped, in the last step. That is an additional cost of 2. This array does have a total cost of 6. You can also verify that the array that appears in case number three has a cost of 12.\nAgain, do try this out. Try writing a version of the solution on your own, and do upload it on the Code Jam platform and let us know how it went for you. I look forward to seeing you in the next video. That will be all for now. Thanks so much and have a great time!"
  },
  {
    "objectID": "materials/cpnotes/Lec48.html",
    "href": "materials/cpnotes/Lec48.html",
    "title": "MaxFlow-MinCut Duality",
    "section": "",
    "text": "Lecture - 48\nMaxFlow-MinCut Duality\n(Refer Slide Time: 0:11)\n\nWelcome to the ninth week of Getting Started with Competitive Programming. So, this week we continue our exploration of network flows. But our perspective this time is going to be slightly different from the one that we had last week. So, if you remember, in week 8, our goal was to find a maximum valued flow in a flow network. So, the goal was to push as much material as we could from a designated source vertex to a designated target vertex.\nThis time, our goal will be somewhat the opposite. We want to see what is the minimum amount of damage that we need to do to the network to make sure that the target is unreachable from the source. So, this is called the problem of finding a minimum cut. And it turns out that it is intimately related to the problem of finding a maximum flow. In fact, so much so that without knowing it, you have already learned an algorithm to find a minimum cut because the Ford-Fulkerson’s algorithm for finding a maximum flow as a by-product automatically finds a minimum cut as well.\nNow, as you can imagine, the minimum cut problem has a variety of applications. One that is easy to visualize but probably a bit depressing to think about is war strategy. So, let us say that you are planning out an attack on the enemy camp. And what you are trying to ensure is that no useful supplies reach them from the other side. Then you may want to strategically destroy roads so that all connections are cut off. You either destroy roads or monitor them, whatever you do.\nNow, monitoring or destroying is expensive. So, you want to be able to identify the smallest number of key roads or locations that need this kind of attention. Minimum cuts are also interesting because they give you a sense of the weak points in your network. Right. So, if you have a minimum cut at hand, then you know that if these edges were to be destroyed, then you lose all contact between the source and the target.\nSo, by identifying such minimum cuts, you may get ideas for how to strengthen your network and make it more robust. That goes into the realm of something called network design, which is a very interesting topic if you want to find out more about it. In the meantime, let us go ahead and talk about the relationship between MaxFlows and MinCuts, which is the topic of this module here.\n(Refer Slide Time: 2:32)\n\nSo, what is a cut? Formally, it is a partition of the vertex set of a flow network into two parts, which we will typically denote by capital S and capital T. So, these capital letters correspond to vertex subsets. And the only thing that this partition must satisfy is the constraint that the source vertex belongs to one of the parts and the target vertex belongs to the other part. That is all that we need. Other than that, you could distribute the remaining vertices however you like, and it will still be a valid S-T cut. Let us take a look at an example of an S-T cut.\n(Refer Slide Time: 3:05 and 3:35)\n  \nHere is a flow network. The capacities are not shown here because they are not so relevant at the moment. You have the source vertex S, and the target vertex T on the extremes of your screen. And you will notice that all the green vertices, being the set capital S and all the red vertices being the set capital T forms a valid S-T cut in this particular flow network. Now, given a cut like this, we are specifically interested in edges that cross the cut. What do I mean by this?\nWell, an edge from u to v is set to cross the cut if u belongs to S and v belongs to T. So, in this example, once again, you can see that these are all the edges that cross the cut. They have been marked in pink. And hopefully, you agree that this is consistent with the definition that we just gave. Now, what is the capacity of this cut? Well, you just add up the capacities of the edges that cross the cut, and that is going to be the capacity of the cut. Okay.\n(Refer Slide Time: 3:59 and 4:08)\n \nNow, think about what happens when you delete all the edges that cross an S-T cut. Take a moment, if you would like to go back to the example and see what happens. And see if you notice something particularly spectacular that happens when you remove all the edges crossing any S-T cut.\n(Refer Slide Time: 4:25)\n  \nWell, let us actually look at what happens in this example. So, we have these edges that cross the cut. And here is what you get when you remove these edges. Notice that when you do this, you have removed all possible connections from S to T. So, I would like to claim that this is true not only for this example but in general. If you were to delete all the edges that cross an S-T cut, then you end up disconnecting S from T in this graph, which is to say that after these edges are gone, there is no way for you to travel from S to T along a valid path.\nTo see why this is true. Let us assume that all the edges in an S-T cut have been deleted. And let us suppose for the sake of contradiction, that you still have a path from S to T. And let us say that path looks like this. So, clearly, just by definition, this path starts from the source vertex and ends at the target vertex. Now, let us label the intermediate vertices of this path depending on which side of the garden they belong to. So, just for simplicity, you could think of coloring these vertices green or red, depending on whether they belong to capital S or capital T. Right.\n(Refer Slide Time: 5:07)\n \nSo, when we go ahead and do that, notice that at some point, you must change color on this path because it is starting with a green vertex, and you are ending at a red vertex. So, at some point, there must be two consecutive vertices on this path, which have opposite colors. Right. So, if you can find such a consecutive pair, then you have also found an edge that crosses the cut.\nBut remember that this edge is not there because we deleted all the edges that cross the cut. Therefore, this particular path has been destroyed and is in fact not there. So, depending on your taste, you can think of this as proof by contradiction, which simply says that this claimed path does not exist. Or you could think of it as a constructive proof, which says, well, let us go and examine every S-T path turn by turn.\nAnd let us argue that at least one of the edges on any of these paths was, in fact, destroyed when we deleted all the edges in an S-T cut. Either way, the point is that removing all the edges in an S-T cut disconnects S from T. And that is why a cut, which has the smallest number of edges that crosses it, would correspond to a minimum effort way of destroying all connections between the source and the target, which was sort of the original goal that we set out for ourselves when I was introducing the MinCut problem back at the beginning of this discussion.\nAlso, recall that we are working with edges that have capacities and you could think of these numbers as being a reflection of how expensive it is going to be to destroy a particular edge. You can imagine that if these edges are modeling a road network, then a six-lane road, which of course has a large capacity is going to be more effort to destroy compared to some kaccha-pakka road, which has a capacity of maybe one bicycle at a time or something like this. Right.\nSo, this naturally motivates the definition of a minimum cut as being a cut, which has the smallest capacity. Once again, remember that the capacity of a cut is simply the sum of the capacities of all the edges that cross the cut. Alright. Now, that the definitions are out of the way, it is time to make our first connection between flows and cuts. So, here is a preliminary claim.\n(Refer Slide Time: 7:43 and 8:23)\n \nI want to say that the value of any valid flow in a flow network is at most the capacity of any S-T cut. Please feel free to pause the video here and just absorb this statement and see if you find it intuitive. See if you can come up with your own reasoning for why something like this would be true. Come back once you are ready.\nAlright. So, we will not be proving this formally. If you are interested in proof that involves proper inequalities and everything, you can take a look at the references that have been linked to in the description. But what I will try to do instead is convey the main intuition for why you might expect this to be true.\nSo, let us consider any flow ‘f.’ Right. And let us fix an S-T cut, S-T, which is capital S capital T. Let us think about what happens if the value of ‘f’ exceeds the capacity of the cut S-T. Alright. So, let us go back to our example here.\n(Refer Slide Time: 8:39)\n\nSo, notice that the highlighted region on the left is the set capital S. Right. And we have that this cut has a certain capacity – could be whatever you like. And let us say that you have managed to push your flow from S to T, which is higher, the value of this flow is greater than the capacity of this cut. Now intuitively, you can think of the cut as being some sort of a bottleneck between S and T.\nIt tells you, remember, when we were working with the trucks, right, we said that, well, there is only so much that you can push from S to T if this is going to be the situation that all of your trucks have to take one of these three roads that have been marked in pink. So, that essentially gives you a ‘bound’ for how many trucks can go through from S to T. So, in other words, if you have managed to push a flow whose value is more than the capacity of these three pink edges combined, then some of that flow is actually stuck on the yellow side of this network.\nIt cannot get out, it cannot go to the other side. But remember when we introduced the flow problem, we also talked about how the flow that goes out of the source is the same as the flow that lands on the target. So, it cannot really be that some of your flow is stuck on one side of the graph and does not reach the target. If that is happening, then somewhere you have violated the conservation constraints.\nSo, if you write down a few equations that involve starting from the starting value of the flow and relating it to the capacity of the cross edges, and applying the conservation constraint, you will see that you will end up with a contradiction if you start off with a flow that is more than the capacity of this particular cut.\n(Refer Slide Time: 10:27)\n\nSo, what we know is that the value of any flow is bounded by the value of any cut. In particular, we could set this flow ‘f’ to be the MaxFlow, and we could choose this cut to be the MinCut, which tells us that the value of the maximum flow that you can achieve is bounded by the capacity of the minimum cut in this flow network. So, what we have discovered so far is that the capacity of a minimum cut gives us a target for the maximum value of the flow that we can hope to achieve. Right.\nSo, if you found a minimum cut and it has some capacity, then this is the best that you can hope for in terms of how much flow you can push from the source to the target. Now, the interesting question is, is this an achievable target? Can you always push this amount of flow corresponding to the capacity of our MinCut from S to T? And this is the question that we will try to address next. Now, let us take a look at the flow that we get from the Ford Fulkerson algorithm. The first thing I want to point out is that this algorithm already gives us an S-T cut.\n(Refer Slide Time: 11:35)\n\nSo, let us look at the residual graph that we get in the last iteration of Ford Fulkerson. Remember, we stop when we are not able to find an S-T path in the residual graph anymore. So, let us look at all the vertices that are reachable from S in the residual graph that we obtained at the last step, the step where we got stuck. Notice that this set of reachable vertices does not contain the target vertex T because if it did, then we would not be stuck here. We would have found a path, and we would have augmented the flow along this path. Right.\nSo, we know that the set of all vertices that are reachable from the source in the residual graph at the end of the Ford Fulkerson algorithm is actually a set that contains the source vertex, and it does not contain the target vertex. That sounds familiar. Right. So, that is essentially a cut. So, you know that this is a valid S-T cut. And this is going to be a particularly interesting cut to work with.\n(Refer Slide Time: 12:33 and 12:59)\n \nLet us say that this particular cut has a capacity of C. Now I want you to think about what is the value of the flow that the Ford Fulkerson algorithm has found in terms of this capacity C. Pause the video here for a moment and just think about whether there might be a connection. Alright. So, it turns out that the value of the flow that is found by the Ford Fulkerson algorithm is also C.\nOkay. Let us try to think about why this might be the case. But before we do that, let us say we believe this for the moment. Then notice that your algorithm has also found a minimum cut. Right. Because you have a flow whose value is C. You have a cut whose capacity is C. You know that this flow whose value is C is actually the maximum possible value of any flow in this flow network. So, you know that you cannot have a cat whose capacity is smaller than C. Right.\nBecause then this would violate the first inequality that we saw. So, in fact, the set of vertices that is reachable from S in the residual graph at the last iteration of Ford Fulkerson is also a minimum cut. The fact that that is a minimum cut, of course, relies on this observation here, which is that you have a flow whose value is equal to this capacity.\nSo, again, let us try and see why this is true. Like before, I will not be proving this formally, but hopefully, I will be able to share enough ideas based on which you can go and work out the details of a formal proof. So, to begin with, let us try to understand the value of a flow in terms of the edges that go between the parts of a cut.\n(Refer Slide Time: 14:18)\n \nSo, in particular, let us fix a flow ‘f’ and let us fix an S-T cut, capital S capital T. Right. Now, it turns out that the value of the flow is the sum of the flows on the edges that cross the cut, and you have to adjust for the flow that is coming back from T to S. So, you also add up the flows on the edges that originate in the set capital T and have the other endpoint in the set capital S. And all the flow that is coming on these so-called back edges, you need to subtract this from the total flow that is going on the cross edges.\nSo, if you do that, the resulting number that you get will equal (to) the value of the flow itself. Now, if you think about it, this is fairly intuitive. It is essentially because of the conservation constraints that the amount of flow that you were able to push from S, or the amount of flow that lands at T, can also be understood in terms of, you know, the amount of flow that crosses any of these intermediate cuts.\nAnd you really want to be looking at the net flow that crosses this intermediate cut, which is the flow that is on the cross edges adjusted for the flow that is coming back into the set capital S. So, again, this is something that you can confirm by a fairly straightforward calculation, which I will not get into. But once you understand that this is true, let us look at what is going on in the cut that is finally discovered by the Ford Fulkerson algorithm.\nSo, let us say that this cut that we are looking at is specifically the cut, which is obtained by considering all the vertices that are reachable from S in the residual graph in the last step of the Ford Fulkerson algorithm. So, now what is happening on the forward edges, which are the cross edges? Notice that each of these edges must be fully saturated by the flow. Because if they are not fully saturated by the flow, then in the residual graph, these edges would still be present with the residual capacity, which means that if you look at the vertices, which are sitting in T right now, at the other ends of these two blue edges, these vertices would not be in T, if these edges were not fully saturated.\nThey would still be reachable from S, and they would be pulled to the other side. So, hopefully, it is clear that the edges that are crossing this cut must be fully saturated by the flow. Again, if this was not the case, then your ‘cut’ would not be looking like this. Okay. So, we need all of these edges to be missing. The only way to make these edges vanish in the residual graph is by fully saturating them so that their residual capacities are 0.\nOn the other hand, let us look at these back edges in the flow network. Okay. So, these edges, I claim, cannot have any flow going through them. Because if you send any flow going through these edges, then in the residue graph, you would have introduced an artificial edge, which goes in the other direction, which would have a non-trivial capacity.\nAnd once again, this would not be an accurate picture of the cut that you obtain at the last step, and you would get a contradiction. So, in fact, if you look at the S-T cut that you obtain, at the very end of Ford Fulkerson, the cut that is obtained by looking at the vertices reachable from S in the residual graph at the last iteration, then it must be the case that your MaxFlow, again, as discovered by Ford Fulkerson, must have the following form.\nIt saturates fully all the edges that cross this cut, and it does not touch the edges that come back from this cut, which is to say, edges that start in T and end in S, these I just do not have any flow going through them. Again, the reason for this is that if the flow did not look like this, then this cut also would not look like this, okay, and that is what we just discussed.\n(Refer Slide Time: 18:18)\n \nSo, essentially, the value of this flow is in fact equal to the capacity of this cut. And both the flow and the cut have been discovered by this Ford Fulkerson algorithm. And we know from our previous discussions, that this flow is in fact, a max flow, from which we can conclude that this S-T cut must, in fact, be a MinCut.\nThis is something that we also mentioned a while ago because notice that if you have a cut, which was smaller than this, then this flow would have trouble getting through. Right. So, Ford Fulkerson witnesses the fact that the minimum cut target is, in fact, achievable. And it also finds this minimum cut for you. So, what more could you ask for? So, in the next module, where we look at a problem that requires you to find the MinCut, we will see how to adapt our implementation slightly, so that we can find this MinCut and work with it.\n(Refer Slide Time: 19:16)\n\nIn the meantime, if you had to have one major takeaway from this module, it would be this equality, the equality of the value of the MaxFlow, and the capacity of a MinCut. The fact that the value of the maximum flow is bounded above by the capacity of a minimum cut, I think, is pretty intuitive. And that is something that can be appreciated just pretty much directly from the definitions.\nBut the fact that this upper bound can always be achieved, and the fact that that is a consequence of Ford Fulkerson, you have a constructive way of getting there, I think, it is absolutely amazing. And this is one of the most elegant dualities in graph theory and it can be used as a basis for proving some other very interesting dualities as well. And we will see one example of that in the last module this week.\nIn the meantime, we would like to talk about how you can implement the process of finding a minimum cut. Because you have already implemented the MaxFlow algorithm, this turns out to be super easy to do. And that is what we are going to see in the context of this specific problem in the next module. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec49.html",
    "href": "materials/cpnotes/Lec49.html",
    "title": "Police Chase",
    "section": "",
    "text": "Lecture - 49\nPolice Chase\n(Refer Slide Time: 0:11)\n\nWelcome back to the second module in the ninth week of Getting Started with Competitive Programming. So, in the previous module, we just saw (about) the deep relationship between the value of a maximum flow in a flow network and the capacity of a minimum cut in the same network. In this short follow-up module, I want to talk about a problem that will give us an opportunity to implement the minimum cut algorithm that we hinted at last time.\nSo, this one is called ‘police chase.’ It is a problem that you can find in the graph section of CSES. If this is the first time you are solving a problem on the CSES platform, you will need to set up an account, but that is very quick and easy to do. So, there is, as always, a link to the problem in the description of this video. So, I hope that you can check it out and follow along.\n(Refer Slide Time: 0:56)\n\nSo, here is the problem statement. Kaaleppi, I hope I am pronouncing that right. Kaaleppi has just robbed a bank and is now heading to the harbor. However, the police want to stop him by closing some of the streets of the city. What is the minimum number of streets that should be closed so that there is no route between the bank and the harbor? So, I am going to assume that our friend is just finished robbing the bank and is at the source vertex, which corresponds to the bank here, and the police want to shut off some of the roads so that no matter what our friend does, he is not going to be able to reach the harbor.\nSo, you can probably already see where this is going. You want to model the streets in the city as some sort of a flow network. And you want to think of the bank as the source and the harbor as the target. And, of course, your goal of closing off the smallest number of streets so as to cut off all the connections from the bank to the harbor is going to correspond to a minimum cut in this flow network. Let us take a look at the example that is given as the sample input in the problem statement.\n(Refer Slide Time: 1:57)\n\nSo, we have four locations. The bank is always the location with index 1. And the harbor is always the location which has index n, which is the number of vertices. In this case, n is 4. So, the source and the target are shown as the green and the red vertices here. The remaining edges are as shown. And if you like, you can pause here for a moment to think about what would be the best solution in terms of what would be the smallest number of roads that you can remove to disconnect the bank from the harbor.\nAlright. If you stare at this for a minute, you can probably conclude that it is not enough to remove just one edge. You could try each edge in turn, for instance, and realize that you are going to need at least two edges to disconnect the source from the target in this example. And it turns out that two edges are in fact enough. So, for example, you could try to delete these two edges here. And you will see that once you do that, you disconnect the harbor from the bank.\n(Refer Slide Time: 2:59)\n\nSo, pretty much just by definition, what you are looking for is a minimum cut between vertex-1 and vertex n. And as I said before, this is something that we are very well equipped to do by now because we already have an implementation of the Ford-Fulkerson algorithm. So, the idea is to find a maximum flow, and then look at the residual graph that you obtain at the end of this process. And look at all the vertices that are reachable from the source. And that is going to be your minimum cut. And what you want to return is the edges that cross this cut. So, let us take a look at how we are going to do this in the implementation.\n(Refer Slide Time: 3:39)\n\nSo, here is what we are going to do after we have finished reading (in) the graph and running the Max Flow algorithm on it. So, the process of reading the graph (in) and running Max Flow on it is completely straightforward. The input is given in a very convenient way. So, you just have to keep reading the edges and adding them to your Max Flow object. And you can simply invoke the Edmonds Karp function after you have built up the graph. So I am not showing you that part of the code.\nBut in case you would like to take a look, you can find it in the usual place in the official repository. And there is a link in the description as always. So, after (all) this is done, what we want to do is find the set of vertices that are reachable from the source vertex, which in this case is the vertex labeled 1. So, we are going to do this using a helper function called reachable_set.\nAnd I am going to talk about how reachable_set is implemented in just a moment. But again, if this is something that you want to try and do on your own, it is a very good exercise. All you have to do is copy-paste the BFS implementation, and just introduce a variable that can keep track of all the vertices that you encounter in the process of running the BFS from the source vertex. So, feel free to try that out on your own. This would be a good point to pause the video and play around with your own implementation, and you could come back and exchange notes.\nSo, let us say that we have some implementation of reachable_set. As I said, we are going to get to that next. But let us suppose that we stored in the variable ‘scomp,’ the set of all vertices that are reachable from the source. Now, the next thing that we do is run a little loop that goes through all the vertices, and figures out, which (are the ones that) do not belong to ‘scomp.’ This will be the set ‘t.’ The reason we want to build out ‘t’ explicitly is because it is just going to help us identify all the edges that cross the cut, which is, in fact, the solution that we are interested in.\nNotice that in the police chase problem, you are actually asked to output a set of edges corresponding to streets that the police can block off. So, if you just had to output the number of streets that need to be blocked off, you do not need to do any of this, you can simply return the value of the Max Flow, and you would be done. However, in this problem, and in many problems of this kind, you are often asked to explicitly output some valid solution.\nAnd fortunately, as we have discussed, the Ford–Fulkerson algorithm automatically gives us access to a minimum cut. And all that remains to be done is to identify all the edges that are crossing this cut. Now, of course, to do this, you do not have to explicitly identify the set ‘t’ like I am doing here. You could instead simply loop over all the vertices in s, look at the edges that are incident on these vertices, and identify all those edges that have their other endpoints, essentially not being in s.\nAnd that is an alternate way to discover all the edges that are crossing the cut. I just found this more convenient to just interpret visually. So, that is why I am doing it this way. So, the first for loop here essentially identifies all of those vertices that do not belong to ‘scomp,’ which is the part of the graph that is reachable from s in the last residual graph from Ford–Fulkerson. And this essentially constitutes our set ‘t,’ which we are calling ‘tcomp’ here.\nFinally, what we do is run a nested pair of ‘for’ loops, which essentially goes through all pairs of vertices, such that one of them is in s and the others in t. I have written a small helper function that just tells me whether a pair of vertices is an edge or not. So, if ‘i comma j’ is an edge, and i is in ‘s,’ and j is in ‘t,’ then I am going to add this to my cut. In this case, I am just printing it out directly.\nBut you could also store it in a solution in case you need to use the cut for something else going forward. For this problem, it is just enough to print this list of edges, and you are done. Now, let us just take a quick look at how reachable_set works.\n(Refer Slide Time: 7:39)\n\nSo, this should look very familiar because it is essentially the BFS sub-routine. But I have decluttered it a bit so that I do not have to keep track of parent information because that is not so relevant here. But instead, we have introduced an ‘answer’ variable, which essentially is going to just keep track of all the vertices that we meet as we do this BFS.\nSo, every time we see a new vertex, just after we push it back on the queue, we also add it to the answer vector. And we just return ‘answer’ that is the set of all the vertices that are reachable from s. By the way, if you are just following along on the video and writing your code, as we discuss, then notice that there are parts of this function that are missing. So, in particular, all of the initialization is missing.\nAnd you will need to declare the variables. Make sure that the queue has the word access, to begin with and that the distance vector has been initialized appropriately. And that the distance of the source vertex is set to 0. So, these are a few things that you do not see on the slide. But you can once again find the complete code in a link that is there in the description. So, you can refer to that instead if you are looking for a fully workable code, but ideally, you are just trying to write this out yourself as well. Just for good practice.\nHowever you choose to do it, I hope that you end up with a working implementation that makes you feel confident about tackling problems that are based on MinCut going forward. In the last module for this week, which is coming up next, we will look at a slightly more sophisticated application of MinCut. And while we are at it, we are going to learn about another fundamental and truly beautiful duality theorem in graph theory. So, I cannot wait to tell you about that. We will see you in the next video. Thanks for watching!"
  },
  {
    "objectID": "materials/cpnotes/Lec9.html",
    "href": "materials/cpnotes/Lec9.html",
    "title": "Greedy Algorithms - Module 1 (Pancake Flipping)",
    "section": "",
    "text": "Lecture - 9\nGreedy Algorithms - Module 1 (Pancake Flipping)\n(Refer Slide Time: 00:11)\n\nWelcome back to the third week of ‘Getting Started with Competitive Programming.’ I hope that you are excited about exploring a new theme. In this week, our focus will be completely on greedy algorithms. So, greedy is a fairly broad algorithms design, paradigm, or technique and it is fairly popular in contest programming.\nIn our first module, we are going to be illustrating the technique through a problem called ‘Pancake Flipping,’ which is from the Google Code Jam qualifiers back in 2017. Before we get started though, let me just say a couple of things about greedy algorithms in general.\n(Refer Slide Time: 00:54)\n\nIn most algorithm textbooks, you will find a lot of warnings about greedy algorithms. For instance, here is the table of contents from Jeff Erickson's Algorithms, which by the way, is an excellent reference that goes along very well with the course incidentally.\n(Refer Slide Time: 01:12)\n\nThe warning here is fairly explicit. It says greedy algorithms never work. Well, this is a bit extreme, they, of course, do sometimes work. But the thing to be careful about is that they often do not work despite being very natural sounding and being the most tempting first card approach to a problem. So, for most optimization problems, you will probably naturally come up with a greedy style or a greedy approach to it, which by the way, is essentially characterized by doing whatever you need to do with minimal effort. Whatever seems like the right thing to do, in the moment. I really do not know of a formal definition of what makes an algorithm greedy. Although there are some really interesting mathematical formalisms around characterizing when a greedy algorithm will actually work. If you are really interested in this, then the thing to look up is matroid structures.\n(Refer Slide Time: 01:39)\n\nBut you can completely ignore this comment for now. If you are curious, there are, of course, more links in the description as usual for you to pursue further. But in any case, as I said, at a high level, a greedy strategy is something that feels like the right thing to do locally. But it turns out that long term, this could have ramifications that make your solution suboptimal and that is what happens most of the time. That is why you need more sophisticated techniques like backtracking or dynamic programming or divide-and-conquer or whatever else that help you get through the search space in a more meaningful way.\nBut it turns out that for many problems, even classic ones, greedy algorithms, sometimes, do get lucky and happen to work out all the way. Our goal with the lectures this week is to develop enough of a feel for why greedy algorithms do work when they do by giving you enough reasonably formal justification for the correctness of the approaches that we do discuss.\nOn the other hand, we will also try to go over examples of when greedy algorithms do not work, so that you develop the practice of looking for counter-examples, to see that these strategies that you have come up with might fail. However, during a contest, you might just find it easier to code up your greedy algorithm and see if it actually passes the tests or not. This would be a reasonable thing to do, especially if you do not have penalties for wrong submissions. It may just be the faster approach because greedy algorithms typically tend to be simple and not so difficult to go up.\nSo, you could do that quickly as a preliminary test if you have an approach for which you cannot quickly come up with a counter-example and it seems like it might be promising. However, outside of a ‘contest environment,’ it is definitely a good idea to actually go through the process of trying to understand why your greedy algorithm works or why it does not work.\nThis is also a good time for me to point out that ‘greedy’ being a fairly universal idea will keep coming up in future weeks as well. So, watch out for the reappearance of greedy-based ideas in various other contexts as we go along. With all that background in place, let us finally talk about ‘Pancake Flipping.’\n(Refer Slide Time: 04:26)\n \nNow, normally, I start off with a problem statement. But here I am going to start off with a bit of logistics. I am going to replace the concept of a pancake with a cookie in the entire story, just because it was easier for me to find pictures of cookies. Sorry about that. But I promise you that nothing changes in terms of the mechanics of the problem statement or the solution for that matter. First, let us talk about the two faces of a cookie. You distinguish between the top side and the bottom side of a cookie.\nThe top is going to look like this (center image) throughout the slides and the bottom is going to look like that (rightmost image). According to the terminology in the problem statement, these are called the ‘happy’ and the ‘blank’ sides respectively. The top side has the chocolate chips and it is the happy face and the back has nothing and it is the blank side.\n(Refer Slide Time: 05:26)\n \nWhat is going on is that these cookies are being baked on a single row. It is some sort of long oven thing and the cookies are just being processed in some left to right order. As you can see, some of them are face up and some of them are face down. Our task is to make sure that all of these cookies are face up and we need to flip the ones that are face down for this to happen.\nWhat we have at our disposal is not something that can flip a single cookie at a time and the oven is too hot for you to do that directly. You have to use a flipper. But unfortunately, the only thing you have been given is an oversized cookie flipper. It is something that can flip cookies in batches.\nHere is an example of an oversized cookie flipper of size three. It can flip any three consecutive cookies at once and notice that it flips them one by one. It does not change the ordering of the cookies; the cookies stay in place. You can imagine scooping up the cookies from the front and just turning them over. So, the left to right order is not affected but the state of all the individual cookies basically flips and gets reversed.\n(Refer Slide Time: 06:55)\n \nLet us do another example. Suppose we move the flipper over here and flip again. Notice that we go from being ‘face-down, face-up, face-up’ to being ‘face-up, face-down, face-down.’ As usual, our first question would be, can we always manage what we have set out to do? We have a row of cookies, some of which are face up and some of which are face down. We also have at our disposal this K cookie flipper. So, K is the number of consecutive cookies that can be flipped in one shot.\n(Refer Slide Time: 07:09)\n \nOnce again, remember that the cookies stay in place. The left to right order is not reversed. It is only the individual states that are flipped and they are guaranteed to be flipped. It does not depend on the skill of the person that is using the flipper. The cookies definitely get flipped, they do not drop anywhere, they do not get lost, etc., etc.\nThat is the mechanics of the problem, hopefully, clear at this point. The question I am asking is, can we always do this? I have for your reference the limits that are given in the problem statement. Let us just go over a little bit of notation. The initial state of all the cookies is given by a string S and the encoding is that it is a ‘+’ if it is initially face-up, and it is a ‘-’ if it is initially face-down.\nRemember, face-up is what we call the happy side and face-down is the blank side. What do you want to know is if you can use a K-sized cookie flipper to fix up all of them, which is to say make everybody face up at the end of the day. Take a pause here and think about whether you can come up with scenarios where this task is impossible or with an argument for why even if it takes some time and it is a tedious process, possibly, but you will still always be able to manage.\nHopefully, you had a chance to think about this and notice that there is something interesting going on with the limits for K. We see that K is at least 2 and notice that if K was in fact 1, which is that you have a flipper, which is like an ordinary cookie flipper, it is not an oversized flipper, it lets you flip one cookie at a time. Then, you can always fix any sequence of cookies by just going to the ones that are facing the wrong way and flipping them over. This is probably not such an exciting question anymore and perhaps that is why the range of K is between 2 and something. It is truly an oversized flipper.\n(Refer Slide Time: 09:51)\n \nNotice that when K = 2 already, it is not very hard to come up with an example, where it is impossible to achieve this task. Again, this is a bit of a spoiler alert. If you did not have a chance to pause before, maybe you want to think about this now with this hint in place.\nNotice that even with K = 2, which is the most basic kind of an oversized flipper that you can be working with, you could get stuck with just 2 cookies in front of you. If one of them is facing the right way and the other is facing the opposite way, then no matter how many times you try to flip them over, you will just get them to being in the opposite situation, but it will never really get fixed.\nNotice that you cannot flip something at the edge of the oven. Essentially, once you have reached the last K cookies on this row, you cannot flip anything that is after that because your pancake flipper just does not have enough place to fit in. You can imagine that it is not an open space where it can hang over the edge. You really get stuck at the very end!\nFor instance, just to make this specific. If you are here, then you might think: Let us flip once to fix the state of the first cookie and now from here, let us try to just flip the second cookie onwards. What I was saying is that it is not allowed in the definition of this problem. There is no onwards from the second cookie, if you have a pancake flipper of size 2 or even more. This is not going to work. You will have to flip both of the cookies that you have in front of you in sync and that is why the situation can never be fixed.\nThere are clearly situations that are impossible and our task at a high level boils down to being able to identify these and distinguish it from those cases where there is a feasible strategy for flipping everything over. In that case, our task is also to additionally find the minimum number of flips that we need to make everything work. Before we start thinking about an algorithmic strategy, let us just continue making some preliminary observations. Here is the first question that I would like to pose to you.\n(Refer Slide Time: 12:18)\n  \nDo you think the order in which we make these flips matter? Suppose somebody comes up to you and says, look here is what we can do for this example. We could flip from the first location, then we could flip at the second location, and then we could flip at the seventh location. So, you could try executing these flips and see what happens.\n(Refer Slide Time: 12:43)\n  \nBut then somebody else comes along and says: No, let us flip at the seventh location first, and then go back and flip at the second location, and then flip at the first location. What do you think? Will the outcomes be for these two different ways of doing it? Will the final state be the same or will it be different? If you can think of some other ordering of these three flips, then try that as well and see if you get to a different final configuration.\nMore generally, if you have a set of flips, where each flip can be uniquely pinned down by identifying the position at which the flip begins and once again, remember that your legitimate starting positions are between the first position and the cookie that is at the N-K+1th location.\nAny location in this range is a valid location for you to start off a flip. Now from here, what we really want to think about is whether the sequence in which we perform these flips matters or not. What do you want to do is either come up with an example of a set of flips that can be played out in two different sequences and they lead you to two different final outcomes. Or, you want an argument, which says that no matter which sequence you pursue these flips in, the final outcome will always be the same. Which one is it? Give it a thought and come back when you are ready. Hopefully, you had a chance to think about this.\n(Refer Slide Time: 14:10)\n \nAs usual, let us try to work through this in the context of a specific example. Let us say that we want to perform the flips that you can see come up on your screen. By default, let us say that we just perform them in the order of appearance from top to bottom. Let us also try to live this experience through the lens of a specific cookie.\nLet us just focus our attention on the sixth cookie that is on the table right now, just as an example, and let us try to focus on the experiences that it goes through as you perform these flips. The first flip does affect the cookie. It is going to get flipped; its state is going to change. The second and the third flips do not influence the state of this cookie. In fact, even the fourth one does not touch this cookie at all, misses a set by a whisker. Right now the state of the cookie is just that it was flipped once from the beginning of the process.\n(Refer Slide Time: 15:11)\n  \nThe next flip is going to flip this cookie over again and so is the next one. In all, this cookie has been flipped three times. Notice that the last flip, again, does not affect the state of this cookie.\nAt the end of the day, this particular cookie was flipped three times and that is going to be true no matter what order you perform the flips in. Hopefully, that is clear. Notice also that there was nothing special about the sixth cookie in this list. Whatever we said is true for every single one of them. Therefore, no matter what the order is in which you perform a set of flips, the final outcome is going to be the same, so the order does not matter.\n(Refer Slide Time: 15:53)\n\nAn easy consequence of this observation is the fact that you never need to repeat a flip. Because if you have a sequence of flips, that does something and there are redundant flips or let us just say repeated flips, they are not redundant yet. What you could do is reorder the flip so that all the repeated ones come one after the other. Now notice that all these repeated flips are not really doing any valuable work for you.\nThe only thing that matters is the parity of the number of times you repeated them. If there is a flip that you perform, say 6 times, then that is as good as not performing the flip at all. That will be the same thing. If there is a flip that you perform 7 times, then that is equivalent to performing it just once. So, why would you perform all of these extra flips? Remember that we are trying to minimize the total number of flips that get us to the answer. We know that without loss of generality, we can assume that flips are never repeated.\n(Refer Slide Time: 16:47)\n  \n \nLet us go back to something that we have said before, which is the total number of possible flips that can happen in the first place. Notice that the legitimate locations where you can start to flip are the locations including the leftmost location on the table and all the way up to the N-K+1th location.\nAt the very end, as we said, there is not enough room and further flips are not possible anymore. You have these ‘N-K+1’ possible flips and at this point, you might be tempted to think about a brute force approach to solving the problem. Given that there are only so many flips you can make and given the fact that the order does not matter, the question really just boils down to which flips are you going to make? Because we also know that flips are never repeated.\nWhat is the complexity of a brute force approach based on all the observations that we have made so far? Think about that for a minute and come back when you are ready. The dominant term in the complexity of the brute force approach is going to be ‘2N-K+1.’\nIt turns out that you could just try all possible subsets of locations where you want to actually flip. If you try all of them and then simulate the flips and basically check if everything works out, then essentially, you are going to be trying all possible subsets of a set of size ‘N-K+1’ and that is going to be the complexity. There is going to be a bit of a polynomial overhead.\nBut I have not written that down because this is really going to be, as I said, the dominant term. If you wanted to do it properly, the running time analysis, then you should also account for the amount of time it takes for you to actually simulate the flips and check if things work or not.\nEven without these observations, you could just try to brute force your way through the space of all possible flips using something like a BFS over this space. You could say that two states are adjacent, if say, reachable one from the other via a single flip at some location. I am not going to elaborate too much on the strategy. But essentially, there are other approaches in the spirit of brute force that would also work if you were working with a small data set on this problem.\nHowever, that is not going to scale when you are working with large data sets. We need to think about this some more. This is where the greedy ploy comes into play. Let us think about what is the absolute minimum work that we need to do at every stage.\n(Refer Slide Time: 19:28)\n\nStarting from left to right, let us begin by focusing on the very first cookie that we encounter, which is facing the wrong way. This right here is the leftmost cookie that has a blank side up, and notice that any valid solution will have to flip this cookie. Now in our solution, what we are going to do is position our first flip to start at this location.\nNotice that all the cookies that have appeared before this are facing the right way, just by definition, and it seems wasteful to start a flip anywhere earlier. Because it seems to be just unsettling things that are already fixed. So as they say, let us not fix what is not broken and position our first flip at the location of the leftmost cookie that is facing the wrong way.\n(Refer Slide Time: 20:14)\n \n \nWe start there, then we execute the flips in the program. You could basically simulate these flips. Then you move the flipper along to the very next cookie that is facing the wrong way. You just walk along, stop when you see another cookie that is facing the wrong way, you position your next flip there and you keep doing this till you reach the very end.\nI am not actually executing these flips for you and I will leave this as an example that you can work out. Feel free to pause the video here and, sort of, go through the process. Now let us think about when we would declare an actual answer versus when would we say that the initial configuration is impossible with the value of K that we have been given to work with.\nWhen we finish, when we stop and get stuck, notice that we have actually fixed the states of the first ‘N-K+1’ cookies, just by the way that we have been performing these flips. That is easy to check.\n(Refer Slide Time: 21:17)\n\nThe only thing that remains to check is the state of the last ‘K-1’ cookies. If these last ‘K-1’ cookies are not already facing the right way, there is nothing that we can do to fix them anymore. At this stage, we will declare that this situation is impossible. But if the last ‘K-1’ cookies are facing the right way, then we will say that we are done and we will report the number of flips that we have made.\nNotice that when your algorithm actually outputs a number, it is definitely doing the right thing because we have seen that we only made those flips that we were absolutely compelled to do. We know that any solution and, in particular, the optimal solution also must make at least that many flips and because we have actually demonstrably managed with that many flips because notice that by construction when we are done and we actually output a number, we have also given you a strategy for making a sequence of flips, which will actually fix everything and that is visible.\nWhenever we output a number, we know that we are at par with optimal and we are doing the right thing. The only thing to be careful about is when we report impossible, then we need to be sure that there is no other solution that actually manages to flip everything to its correct position while we just maybe missed out on it because of our greedy choices.\nYou can actually argue that this algorithm does the right thing, even when it reports impossible. I will leave that as a little exercise for you to figure out in terms of what is the logic for why our impossible output is also always correct. If you are stuck on this, then you can go back and look at the notes on the course website and you will find a more elaborate argument then.\nIn terms of implementation, you could exactly implement what we have discussed so far and that will work. It will have a complexity of something like ‘order N2’ or ‘N*K’ because you are doing sort of a linear pass. But within each pass, you are trying to figure out if a flip needs to happen or not and if it does need to happen, you do have to simulate the flip.\nThat is going to be K units of work in every iteration. Now, this is good enough to pass the large data sets. Please feel free to give it a shot and let me know how it goes. In the meantime, let us discuss a small improvement to the implementation that we have just described. What we will do is, trade-off some space for time, which is to say that by keeping track of a little more information, what we will be able to do is bypass the simulation, which forces us to do order K extra work in all those iterations where we do decide to make a flip.\nAs a result, what will happen is that we will end up with a purely linear time algorithm. One that runs in order N, but it uses order N extra memory to do this additional book-keeping. This is an optimization that has also been described in the official editorial and as it is pointed out there, you do not actually need this improvement for the large tests to go through.\nNonetheless, it is a useful trick to be aware of. That is what we are going to try and understand now and this is also the version that we will implement. However, if you do have an implementation of the simulation-based approach and you want to share it with us, then please feel free to initiate a pull request in the GitHub repository where we are maintaining the codes for these lectures.\n(Refer Slide Time: 25:01)\n\nLet us go back to the original state of the array, and once again, begin with the left-most cookie that needs a bit of a nudge. Our overall strategy will still be to have this ‘for’ loop that is running through the initial state array, and the way we will deal with what we decide to do when we have to make a flip will be slightly different from before. Here is the first location where we do need to make a flip.\nThe natural thing is to track this in a flip or an answer variable to remember that a flip had to be made and now in the simulation approach. What you would have done is you would have either flipped the state of the next ‘K-1’ cookies as well by actually changing the state array or you would have tried to keep track of this information in some other auxiliary array by recording number of flips at every location and incrementing them as appropriate.\nNotice that we really want to avoid having to do something ‘K’ times or ‘K-1’ times or whatever. Think about what is it that we really need to know. When we are processing the cookie at the jth location for some ‘j,’ what we really need to know is: How many times is this cookie been flipped so far? A hint to that is in the flip variable - the flip variable tells us how many flips have happened so far.\nThat may not be the number of times that this cookie has been flipped because many of these flips have happened far away and are not relevant for this cookie. What we really need to know is how many of these flips are obsolete for the current variable. I should not say the current variable, but rather the current cookie, the one that is being processed right now.\nWhat we do is we keep an extra array called the ‘obsolete flips array.’ There what we do is, we make a note of the fact that this flip, the one that is the leftmost flip on your screen right now, is one that should not be counted when you are processing the K+1th cookie away from the current location.\nIt becomes an obsolete flip for that cookie. So, when you are processing that cookie in the future, when you look at the number of flips that have happened, you are going to also subtract whatever is being stored in the ‘obsolete flips array’ at that point, to get the accurate number of flips that actually affect this cookie.\nOf course, you might say, look, this flip is obsolete not only for the K+1th cookie from the current location but for all the ones after that as well. Why do not we increment the values in obsolete flips array for all of the future locations as well? Well, we could do that. But that would defeat the purpose of getting to something faster. Because then that would mean actually doing ‘N-K’ amount of work in the worst case.\nSo, we do not want to do that, instead what we will do is, we will just do some sort of a running sum of the number of obsolete flips. In particular, when I land at the jth cookie, I just look at the obsolete flips value of the j-1th cookie. The number of flips that have been obsolete for the previous cookie - they are all certainly obsolete for me as well. Because if those flips could not reach the cookie to the left of me, then they can certainly not reach the cookie at this location ‘j.’\nWe borrow that value from the previous values stored in the obsolete flips array, and then we also lookup whatever was hinted to us from the flip that happened from this action that we are doing right now. That gives us the total number of obsolete flips, which we subtract from the actual number of flips to recover the correct number of flips that this cookie was actually involved in.\nThis may be a little bit tricky to fully understand. Feel free to pause and take a moment here to really absorb this. Hopefully, it will also become clear as we go into the implementation. Before we can get to the implementation though, there is still one piece left that we need to understand.\nOnce we are processing the jth cookie, we need a way to figure out if it needs to be flipped or not. When we were doing simulations, this was really easy, because you just looked at the state of the cookie, because it has actually gone through all the flips that have happened so far. The state of the cookie is reflective of its current state.\nWe know that if it is facing the correct way we can skip it, and if it is blank side up, then we need to flip it. But now what you have is the original state of the cookie from the state array. You have this number which is the number of flips that it has experienced so far, which once again, you obtained by subtracting from the flips variable the ‘obsolete flips’ value.\nBased on these two pieces of information, which is the original state of the cookie, and the number of flips that it has experienced, can you come up with criteria for when you should actually flip this cookie? Take a moment here to think about this because once you have come up with these criteria, you would have a complete description of the algorithm that you need to implement.\nYou just go through the whole set of cookies from the first position to the N-K+1th of the position, do the flips that are necessary, and then you essentially continue doing this for the last ‘K-1’ cookies as well. But this time, if your criteria do trigger and it says, ‘look you have a cookie that needs to be flipped,’ then instead of incrementing the flips variable and proceeding, what you will do is you will break out of the loop and declare that the situation is impossible.\nIf however, your loop survives for the last ‘K-1’ cookies as well, then you can just report the number that you have in the flips variable. That is your entire algorithm. The only piece that you need to fill in is what is the criteria for determining if the cookie that has been processed currently needs to be flipped or not. Once again, to recap, you have the value of the original state of the cookie and the number of flips that it has experienced so far, what would you do from here? Hopefully, you had a chance to think about this. The criteria are actually fairly natural.\n(Refer Slide Time: 31:28)\n\nIf the cookie was plain side up in the original array and the number of flips that it has experienced is even that means all these flips have canceled out. Even at this stage, the cookie is still the wrong way up. You do need to flip it.\nOn the other hand, suppose the cookie was facing the right way, to begin with. But now it has experienced an odd number of flips, then you are in trouble because you have actually broken something that was correct in the beginning. Now you need to flip it again, to fix the situation and bring it back to the ‘happy’ state.\nThat is your criteria for determining whether the current cookie needs to be flipped or not, and as we were just describing before, with this piece of the puzzle in place, you now have the entire algorithm in your head, hopefully, at this point. Once again, if you want to give this shot, this would be a good time to pause this video and try out the implementation yourself.\nThe implementation that we have for you in the video is going to be in Python. We only use very simple data structures and it should be completely straightforward to translate this into a language of your choice.\n(Refer Slide Time: 32:42)\n\nTo begin with, we just read all the input. ‘T’ is the number of test cases and every line is one test case. The first string is going to be a sequence of characters with no spaces, which essentially is composed of pluses and minuses, reflecting the original state of the cookies. Then there is a space and there is a number ‘K.’\nThat is essentially what we are reading in two variables named ‘S’ and ‘K.’ S is going to be a string and K is going to be a number. Let us just use ‘N’ to record the length of the string because that is going to come in useful for stopping criteria, for our main ‘for’ loop. We have N being the length of the string or the number of cookies, to begin with.\nWe also have this obsolete flips array that we just described. To begin with, everything in this array is 0. There are no obsolete flips to record before the process has even started. We also declare an answer variable. In the description in the video, previously, we call this the flips variable. But you could call it whatever you like in this code. This is the answer variable, which has been initialized to 0.\n(Refer Slide Time: 33:58)\n\nLet us do our first ‘for’ loop, which goes from the start of the array all the way up to the N-K+1th cookie. Notice that because we have 0 indexing, you really need to go on the up to the N-Kth cookie. The way range works in Python, it does not actually go to the last number, the last number is omitted. That is why we have ‘j’ in the range ‘0’ to ‘N-K+1.’ This does the right thing.\nThe initial state of the cookie can be read off from S of j; we do that and we store that in ‘state.’ The first thing we do is borrow the obsolete flips from the previous obsolete flips value. Notice that you might get an out-of-range error when j is 0 because what is j-1? This being Python, it is just going to read of the last element in the array.\nThis is an initial condition thing. You could think of it as an edge case. I have not really bothered to say j > 0 because there is no harm, to begin with, every value is 0. What happens in the first iteration really does not do any harm here. In a different language, you may have to be more careful about what happens at the first index.\nIn general, what you are doing is, you are borrowing the number of obsolete slips from your neighbor because all of those flips are obsolete for you as well. Of course, your current value needs to remain anything that has been explicitly pointed out, you need to retain that value as well.\nThat is why this ‘+’ equals, you are not copying the value over. You are using that value to increment whatever value you had in the first place. This correctly records the number of flips that should not be counted for the jth cookie or pancake. The next thing that we want to do is, record the number of flips that are relevant.\nThat is going to be the total number of flips that have happened so far, which has been stored in the answer variable and you subtract from this the number of obsolete flips. That should be fairly straightforward, and this is the number of actual flips that we need to consider.\nIf you remember from a few minutes ago, we had come up with this criteria for whether the current cookie under consideration should be flipped or not, and what we said was that it should be flipped exactly when either the original state was plain and the number of flips is even or when the original state was happy but the number of flips was odd.\nLet us just record these into Boolean variables. If you are writing this code during a contest, you will probably not really do this. You will most likely write an ‘if’ condition straight out. But I think this is easier to read and since we have all the time, right now, we have these descriptive variables here.\nOriginal destroyed is true, if the original state of the cookie was a plus or a happy state and the number of flips is odd, which is to say that you actually destroyed what was correct, to begin with. The other variable is blank, not fixed, which is to say that the original state of the cookie was that it was plain side up and the number of flips is even. We still have work to do here. If either of these variables happens to be true, then we should actually go ahead and make a flip.\n(Refer Slide Time: 37:27)\n\nThe way we record that is to increment the answer by 1 to say that 1 more flip has been made, and equally importantly, we need to go to the obsolete flips array and make a record there. Look at the cookie that is K steps away from the current one and actually K+1 steps depending on how you are counting. Basically, this is the earliest cookie. The cookie with the smallest index not affected by this flip. We do need to make a note of that. That is what we are doing here.\nThe obsolete flips variable needs to be appropriately incremented, as I said, you could also just increment all the values for obsolete flips for all larger indices. But that would be very expensive to do. We are not doing that and instead, we do the trick of borrowing a previous value as we did at the start of this ‘for’ loop. That is essentially the first part.\n(Refer Slide Time: 38:26)\n\nThe second part is to go over the remaining ‘K-1’ cookie. We run the exact same loop, we do the exact same thing. The only difference is that this time, if you realize that a flip needs to happen, then you do not have the facility to actually make it happen. At this point, you have realized that you have an impossible task upon yourself. You declare the answer to be impossible and you break out of the loop.\nNow, if you do survive the loop, then the answer variable does have the right number. You can just go ahead and directly print the answer. There is a string conversion here because Python will probably not print the integer directly. The string conversion will not hurt if the answer was reset to a string and again, I think if you have a language where you have to worry about types, you may be a little bit careful about how you do this. You may need to store extra flag variable or something like that to detect if you went into that breakpoint in the second ‘for’ loop.\nWhatever you have to do is going to be completely straightforward. So with that, we actually come to the end of pancake-flipping. I hope that whatever we discussed made sense. At any rate, the more basic version of the algorithm without this optimization should be extremely doable, where you just go over the state array and simulate all the flips that need to happen.\nJust check if the last ‘K-1’ pancakes got automatically fixed or not. Hopefully, the optimization also made sense and the one thing that I leave you with is for thought is something I have mentioned earlier about trying to convince yourself that whenever the algorithm says impossible, it did not miss some way of doing things correctly.\nWe have already argued that if you output a number, then that is going to be the right number. You just need to make sure that your impossible outputs are also accurate. It turns out that they are, but you need to convince yourself using some sort of a logical argument. So, with that, we come to an end of this video and next time we will talk about another fun problem called ‘Islands War.’ I will see you there and thanks so much for watching as always. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec44.html",
    "href": "materials/cpnotes/Lec44.html",
    "title": "Network Flows - Module 1 (Ford-Fulkerson for Max Flow)",
    "section": "",
    "text": "Lecture - 44\nNetwork Flows - Module 1 (Ford-Fulkerson for Max Flow)\n(Refer Slide Time: 0:11)\n\nAlright. So, welcome back to the second segment of the first module in week 8, where we are talking about network flows. So, just to recap in the previous segment, we talked about what a flow network is. We also defined the notion of a flow. We talked about what it means for a flow to be feasible. We also described the value of a flow and we set ourselves the target of finding a maximum flow. So, that is what is happened so far.\n(Refer Slide Time: 0:20)\n \n  \nWe even proposed a natural-sounding algorithm or a natural approach to finding some sort of a flow, and the question of whether this approach actually produced a maximum flow was left as food for thought. So, I hope you did have a chance to play around with examples, and you have probably concluded, if you did that, that this algorithm may not actually work in all situations.\n(Refer Slide Time: 1:06 and 1:54)\n \nSo, here is a simple example of where the algorithm might fail. So, recall that what we were doing is, starting off, by finding an S-T path and basically pushing as much flow as we could along that path adjusting the capacities and repeating this for as long as we could. So, here is a graph and the capacities are as indicated in particular every edge, has unit capacity.\nAnd to begin with, for example, your algorithm could potentially find this particular S-T path. And if you choose to push as much flow as you can through this path, which is essentially one unit of flow, notice that, in this example, every edge is a bottleneck edge. So there is not really much to speculate here.\nSo, if we were to actually push flow along this path, then the capacities of all of these edges would be turned down to 0, which means that we effectively do not have these edges with us anymore because they are fully used up.\n(Refer Slide Time: 2:06)\n \nSo, we simply delete these edges from the graph as we said we would. And now you are left with a situation where S and T are completely disconnected and your algorithm comes to a grinding halt. And you, basically, found a valid flow whose value is one. On the other hand, if you go back to the input flow network, by just the algorithm of staring at the picture, you can probably see that there is, in fact, a flow whose value is 2, which is better than the one that is found by your algorithm.\nSo, in particular, you could send flow across the top and the bottom paths, from the factory to the shop, and you would be better off if you simply did not use the edge in the middle from X to Y. So, this shows that the algorithm that we developed is not flawless in terms of finding the maximum flow. But now, let us think about if there is some way that we can build on the ideas that we already had and somehow fix the issue that we were having.\n(Refer Slide Time: 3:10)\n \nSo, basically what we want to do is see if we can correct our mistakes as we go along. So it is possible that we found a path that was not quite the right one because remember what was happening here is that by essentially using up the path that went via the edge X-Y, we kind of blocked ourselves off from being able to leverage some of the other paths that would have put us in a better place. So, if that decision could somehow be rolled back, then that would allow us hopefully the opportunity of discovering the more meaningful paths that are available to us.\n(Refer Slide Time: 3:51)\n \nSo, just to summarize, what we have said so far, essentially if we make a mistake with respect to the S-T path that we choose in a particular round, we want to build up some sort of mechanism that allows us to actually undo the flow that we sent through this particular S-T path. So, you might want to take a moment here to think about how would you build-in this kind of undoing mechanism into your network. As such what we have been doing so far, is clearly not enough.\nBecause once we decide to pass some flow through an edge, in particular, especially, when it has an edge that is saturated to full capacity, what ends up happening is that, that edge simply disappears from that graph, which seems that we have really pushed ourselves into a corner with respect to this choice. There does not seem to be any mechanism for actually saying: No, let us go back and let us not send that flow through that edge. Let us re-route it some other way.\nSo, since that edge is completely gone, we need to really revisit what we are doing and see if we can set up some additional support systems that can guide the flow back if required later on. So, this is I think the place where you really need a little bit of imagination. So, do not worry if this is not something that you are able to see or come up with immediately. In fact, I am not even sure how to present any more intuition.\nSo, what I am going to switch to doing now, is describing what our algorithm is actually going to do. And I hope that it makes sense once it is actually presented to you. But if you want to play with this sort of general idea for a while, please feel free to pause here, and think things over a bit before I do reveal the algorithm that we will be working with. Alright. So, what we are going to do, is the following.\nWe will basically introduce carefully, some extra edges for ourselves, which will basically open up some additional routing options, which will correspond to an indication that some flow decisions should be rolled back.\n(Refer Slide Time: 6:00)\n\nSo, to be able to keep track of these extra edges that we want to be working with, we are going to introduce this notion of a residual graph, which you can basically think of as some sort of an auxiliary graph, which is very intimately connected with the flow network. But it has all of these extra mechanisms to help us with the rollbacks. So, a residual graph is based on both a flow network and a given flow, which right at the beginning, you can just imagine as being the trivial flow, which assigns 0 to every edge.\n(Refer Slide Time: 6:24)\n\nBut once you are given a flow network and a feasible flow ‘f’ then here is what the residual graph looks like. So, to begin with, the vertex set of the residual graph is exactly the same as the vertex set of the flow network. And then if we have an edge, let us say from A to B in the flow network which has a capacity of C and a flow of ‘f’ with respect to this given flow, then in the residual graph, we are going to introduce an edge from A to B with capacity C-f.\nNow, this may sound familiar because this is what, we were doing so far already. So, if you have a flow of ‘f’ going through an edge that has capacity C, then you want to record that by saying that you are now working with an edge of reduced capacity and the capacity is reduced by the amount of flow that you have assigned to that edge. So, so far, the residual network looks very natural.\n(Refer Slide Time: 7:27)\n\nBut the thing that actually allows us to fix our mistakes, is this other edge that we are going to introduce, which is commonly called a back edge. So we are going to introduce an edge also from B to A which has a capacity of F. So, this is, basically, telling us that okay look if you want you can pass a flow through this back edge.\nAnd whenever you do that I will basically know that I should go back to the original graph and reduce the flow that was being originally passed through the edge A to B by whatever amount of flow you are passing through this back edge. So, this mechanism will actually hopefully become clearer with an example. So, let us go back and try it out on the example on which our first algorithm failed and let us see if this construction can actually save that example and actually find the optimal flow.\n(Refer Slide Time: 8:13)\n\nSo, remember here is what we had. We made this bad choice of sending our first flow from S to T via the edge X-Y. So, these were all unit capacity edges that were being used up completely. And other than this we had these two edges as well, so we had edges from S to Y and from X to T.\nIt is drawn up a little bit differently here but if you like, you could just pause and go back to the example from before just to confirm that the structure of the edges is exactly the same. So, this is basically the flow that we have at the end of the first iteration. When we do our first S to T path. Now, let us go ahead and take a look at what the residual graph would look like.\n(Refer Slide Time: 9:03)\n\nFirst of all, for all the edges through which we are passing a flow, we are going to have the same edges but with a reduced capacity and this capacity is going to be 0. Notice that the capacity of the edges other than the three that were involved in the path remains the same. It is unaffected because there was no flow going through these edges in the first place. So, these are all the forward edges. These are the edges corresponding to the real edges in the graph.\nNow let us introduce the artificial back edges. So, notice that for each of the forward edges involved in the path S to X, X to Y, Y to T, we are going to get these back edges and the capacity of these back edges is actually going to be equal to the amount of flow that we were passing through them. Now the other two edges that we have here will also have back edges corresponding to them.\nBut because they had zero flow passing through them, these back edges will also have 0 capacity. So, I am not drawing them for clarity. In fact, we also have some of these forward edges that have 0 capacity, which are edges that are as good as not being there.\n(Refer Slide Time: 10:08)\n \nSo, let me remove those from the picture as well. So, this is the residual network. Just pause the video here and see if you can find an S to T path. And notice that if you can, then this is in contrast to what happened with our original algorithm, where we just got completely stuck after finding that first path. Okay. So, take a pause here and see if you can find an S to T path.\nAlright. So, notice that in this graph, you can in fact find an S to T path, and here is one that looks like this. And the dotted edge is just to remind us that that is actually an edge that is not present in the original graph. So, what does that really signify? What are we going to do if you were the manager at the factory? Then what instructions are you going to give, you know, the buses, the people who are going to be driving the buses across to the shop?\nWell, you are going to tell them that look we did plan to send one bus across from X to Y. But let us not do that anymore and the reason you are able to say that is because you see that in the residual network, you are passing a flow through the back edge, which means you have to roll back the flow through the corresponding real edge in the base flow network.\nSo, you are basically going to say, okay, let us actually take back that decision and let us instead route flow through the edges from S to Y and from X to T. So, you can check that this actually corresponds to the flow that we were hoping to find the one, where we said if we used the top path and the bottom one, ignoring the edge in the middle. Then we would actually have a flow of two units. This is really that flow.\nIn particular, notice that the back edges X to S and T to Y are not being used in this S to T path. So, we are not going to do any rollbacks there. So, originally we had from the previous iteration, one unit of flow (going from the edge) going on the edge from S to X and on the edge from Y to T and that flow is going to remain as it is. But what we have essentially done is, we have peeled off the flow from the edge X to Y and we have essentially rerouted it through these two edges from X to T and from S to Y.\nSo, if you write it out with respect to the older drawing you will see that this is exactly the flow that we were hoping to find. And this is the best that we can actually hope for. So, it is good to see that our intervention with the residual graph actually fixed up the situation for this small example. It actually turns out that this idea works in general, but actually proving this is going to be beyond the scope of this discussion.\nAs usual, if you are interested in the proof of correctness then you are certainly welcome to look up the resources that have been linked up (to) in the description of this video as well as on the course website. In the meantime, let me just recap and summarize the algorithm for you, so that we know at least the mechanics of what is going on here.\n(Refer Slide Time: 13:11)\n\nSo, what we have just been discussing so far, commonly goes by the Ford Fulkerson algorithm, and here is what it does. To begin with, you build the residual graph with respect to the trivial flow, which just assigns a value of 0 to every edge and you initialize an answer variable if you like or a max flow variable to 0 because right now the value of the trivial flow is just 0.\nThen basically you work with the residual graph as long as you can find a path from S to T in the residual graph. Here is what you do. You want to push a flow of ‘f’ units through P, where ‘f’ is the bottleneck capacity of the path P. Remember we said that if you want to push a flow along a path, you need to look at every edge in the path and identify the edge that has the smallest capacity. This is called the bottleneck capacity. And that is the amount of flow that we are going to send through this path. And we are going to increment max flow by ‘f’ because this is the additional amount of value that we gained in our resulting flow.\nNow let me just talk for a moment about this phrase, sending a flow, which is a bit loaded. So how do we send a flow of F units through this path? Well, we look at every edge of this path in turn. If it is an original edge that belongs to the flow network as well then what we do is simple, we take the old flow that we had through this edge and we simply increment it by ‘f.’\nOn the other hand, if it is a back edge in the residual graph that means that what we need to do is, a rollback action, which essentially means the following. We look at the corresponding forward edge in the original graph and what we do is, we look at the old flow and we decrement it by ‘f.’ We reduce it by ‘f.’ So, that is how our flow function is going to evolve based on the S-T path that we have found in the residual graph. So, that is it that is pretty much the entire algorithm.\n(Refer Slide Time: 15:07, 15:48 and 16:15)\n  \nLet me just give you a quick visual to hopefully reaffirm our intuition for how these capacities work. So, what you see with the green bar, is the original capacity of an edge that came with the input flow network. The blue bar tells you the amount of flow that we are sending through it currently with whatever flow we are working with, in the current iteration.\nAnd this will imply that in the residual graph, we have a back edge, which has the same capacity as the current flow. That is what allows us to roll back as much of the current flow as we want by simply sending a flow of that amount through this back edge in the residual graph. Right.\nSo, in particular, if we decide to increase the flow through the original graph (then through the edge of the original graph) then the capacity of the reverse edge will also accordingly increase to account for the possibility of rolling back all of this extra flow as well. On the other hand, if you decide to pass some flow through this reverse edge, in the residual graph that means that essentially you want to decrease the flow that you are passing through the original edge.\nAnd as you do that the capacity of the reverse edge will also correspondingly come down to basically remain in sync with the actual amount of flow that is passing through the edge. So, that is what is going on as you progress through this algorithm. Now when you actually implement this algorithm, you could choose to keep track of the capacities in this way if you like.\n(Refer Slide Time: 16:38)\n\nBut another way of doing it is, to simply fix the capacities upfront. So, every edge corresponding to an original edge in the network will have its given capacity. Whereas, each one of these artificially introduced back edges will always have a capacity of 0 throughout the run of the algorithm. And the way we keep track of what is going on is through the flow function.\nSo, notice that what we are actually interested in is the residual capacity, which is the difference between the capacity and the flow so that we can correctly calculate what is the bottleneck capacity on any S-T path. So, essentially for all the original edges, the capacities are anyway fixed and we just need to make sure that we are correctly keeping track of how much flow we are passing through these edges.\nFor any of the back edges, notice that the capacities are evolving based on what is the flow that is going through the corresponding forward edge. So, instead of letting the capacities change, what we are going to do is, essentially pretend that we are sending a negative flow through this edge.\nSo, for example, let us say that in the first iteration, we decide to send 10 units of flow through a real edge in the flow network, then the way we are going to record that is by saying: Okay, that is +10 units of flow through the real edge and it is -10 units of flow through the corresponding back edge.\nWhen you do that and when it comes to looking at the residual capacity, the capacity of this back edge is going to be 0. And then you are going to subtract -10 from it. So what you will be left with is 10 as the residual capacity. So, it is just enough to track the flows. You do not have to worry about also tracking the capacities. And this just makes your code a little bit cleaner, a little more convenient to work with.\nSo, remember that whenever you are passing a flow of ‘f’ through any edge, record that as an increment of ‘f’ through that edge and an increment of ‘-f,’ or a decrement of ‘f’ through the corresponding edge in the opposite direction. And you will see that this essentially works out exactly as you would like it to, in all possible cases. So, we will take a much more detailed look at the implementation in the last segment for this module. So, if this was not completely clear, hopefully, it will be more explicit and visible, when we get to that part of the discussion.\n(Refer Slide Time: 18:58)\n\nSo, before wrapping this up, let me make a few comments about the running time. So, essentially we know that the number of iterations is bounded by the value of the maximum flow. Because every iteration is guaranteed to increase the value of the flow that we are working with by at least one.\nNow, what is it that is happening in each of these iterations? Well, we do run a BFS. We do some backtracking to actually find the S-T path. And we make sure that we evaluate the bottleneck capacity on this path and adjust all the capacities or the flow values along this path appropriately. So, all of this is essentially linear time work – linear in the number of edges of the graph. So, the overall running time essentially is ‘m’ times the value of the max flow.\nNow, this sounds reasonable, but it can be really terrible if the numbers are large and your max flow value can be really huge. You can come up with adversarial examples where this algorithm takes a really really long time. It painstakingly increments the flow value by literally one in every iteration. I mean ideally, you want your flow to increase by large jumps so that it is not too many iterations.\nSo, notice that this max flow value is totally independent of the number of vertices in the number of edges. It could be a function of the weights or the capacities that you have on the edges, which means that this is a really dangerous sort of upper bound to be working with, especially if the upper bound is tight and it can actually be realized on certain instances.\nSo, it turns out that you can just continue using this framework for finding a max flow. But basically be a little more choosy about which S-T paths you work with, in each iteration, and that already can dramatically improve your running time.\n(Refer Slide Time: 20:42)\n\nSo, the first specific improvement to this is by ensuring that you pick the shortest S-T paths, using BFS. I guess we may have been implicitly doing this all along. But by choosing to pick the shortest S-T path in each iteration, it turns out that you actually guarantee that the number of iterations will not exceed V times E, which is the product of the number of vertices in the number of edges, which brings down the running time in some sense to n times m squared, where m is the number of edges and n is the number of vertices.\nNow, of course, this requires an explicit argument for why the number of iterations is bounded in this way. Once again the specifics of this argument are beyond the scope of this discussion, but there are some very nice explanations provided in other write-ups and videos, so you will find some pointers to those in the description of this video as well as once again on the course website.\nSo, please feel free to look these up. These are really nice arguments that establish these bounds. But for now, we are just going to take this as a given and this is the implementation that we will actually discuss in the last segment of this module.\n(Refer Slide Time: 22:00)\n\nIt turns out that in competitive programming, most people use what is called a Dinic’s algorithm, and this is a further improvement in the sense that it tries to squeeze (out) even more mileage out of each iteration. And it turns out that if you were to follow this approach, then the total number of iterations is actually bounded by n, as opposed to n times m. And the amount of work that you have to do to make each iteration actually succeed is n times m. So, the overall running time is now, n squared m, as opposed to n m squared from before. And this can again be a significant improvement.\nSo, again Dinic’s algorithm, as I said, tries to leverage more using this notion of blocking flows. So, you want to basically again just get more work done in every iteration somehow. I do not want to go into the details of this here because this is something that we will not be getting into.\nIt is a little bit beyond the scope of what I think our discussion here is about, but just for completeness, there is an implementation of the next algorithm that is given in the course repository. So, just in case that is something that you need to invoke as a black box, it is available for you. You can take a look at it and if you are curious, you can even familiarize yourself with what is actually going on. Now it turns out that there could be a few problems for which the Edmonds-Karp implementation will actually fail.\n(Refer Slide Time: 23:29)\n\nBut this one will go through. So on SPOJ, for instance, there is a problem called max flow, and if you try to run the Edmonds-Karp version that we have, it is going to time out. But Dinic’s variant will go through. So, basically, you could be in that situation, and as I said, many people will simply default to using the next algorithm, because that is just, you know, that is just the thing to do if you want to be on the safe side.\nSo, you are welcome to do that, as long as you know what you are doing, and you know how things plugin. Actually, the overall implementation is very similar. Because the way this works is that we are working with a class called max flow. So, the interface remains exactly the same. It is really the internals that has been swapped out. So, you should have no difficulty using this in implementation.\nBut the only thing I want to emphasize is that we are not really discussing how exactly this algorithm actually manages this improvement. And once again, if you are curious, there are some nice explanations that have been linked to in the description of this video. So please do go ahead and check that out if you would like to.\nAlright. So, with that, I believe we have enough information to get to the implementation. And that is going to happen in the last segment. As always, I welcome you to try it out on your own a little bit before actually following along. And I think that would be a good experience, even if you do not get all of it completely. It will be fun, I think, to give this a shot yourself. But one way or the other, I will look forward to meeting you again in the last segment of this first module. So, see you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec50.html",
    "href": "materials/cpnotes/Lec50.html",
    "title": "Minimum Vertex Cover via Max Flow | SAM I AM (UVA 11419)",
    "section": "",
    "text": "Lecture - 50\nMinimum Vertex Cover via Max Flow | SAM I AM (UVA 11419)\n(Refer Slide Time: 0:11)\n\nWelcome to the third and the final module in week 9 of Getting Started with Competitive Programming. So, we have been talking about network flows all along. And this week, the emphasis has been on the minimum cut problem, which by now we have learned is essentially the same as the maximum flow in terms of its value. And we also know how to use our Max Flow algorithm to actually find a minimum cut. So, now we are going to put all of this to some good use on a particular problem that does not directly ask for a minimum cut.\nBut it asks for a different quantity, which it turns out can be found quite nicely with the help of a minimum cut. So, let us take a look at this problem called SAM I AM, which is on the UVA platform. And there is a bit of a story and a background which I am going to kind of skip, but I will tell you what is going on in some sort of averaged form. If you want a little more background on the fictional part of it, then please take a look at the link in the description of this video.\n(Refer Slide Time: 1:12)\n \nSo, here is what is going on, there is some sort of war in the background. And at some point, our protagonist Sam has ended up in a temple, which has some of his enemies. So, it turns out that the temple has a rectangular shape. And Sam has the locations of all the enemies in the temple. It may sound like this is something to do with coordinate geometry because we are given a rectangular region and maybe the locations are points.\nBut it turns out and this is something that you will discover, if you take a closer look at the problem statement, that the situation is a lot more discrete. So, by this rectangle shape, what is meant is a grid. And by locations, we are simply given information about some specific cells in this grid. So, every cell is specified by a row number and a column number that pins down the address of that cell if you like.\nAnd we are given the addresses of all the cells in which we have enemies waiting for us. So, what are we going to do about these enemies? You might be thinking that this is going to involve going into the temple, and finding some sort of an optimal sequence to fight everybody off, and so on.\n(Refer Slide Time: 2:23)\n \nBut it turns out that our friend, Sam, realizes that he can kill all of these enemies without even entering the temple by using some special weaponry that he has access to. So, it turns out that he can attack the temple from the outside. And this machinery is going to essentially release a cannonball, which will be able to destroy everything that is on a single row or a single column of this grid in one shot. So, let us take a look at how this might work for our example from before.\n(Refer Slide Time: 2:53)\n  \nSo, you could shoot cannonballs through rows 2, 3, 5, and 6. And this would take care of all the enemy locations. Or you could shoot cannonballs through columns 2, 3, 5, and 6. And this would again, take care of all the enemy locations. Think about if there is a way that you can use a smaller number of cannonballs in total, and still take care of all the enemies. Remember that you are not obliged to only attack just the rows, or just the columns, as we have been doing here, you could mix them up, just see if you can find a more optimal solution in the sense of using fewer cannonballs.\nAlright. Hopefully, you had a chance to think about that. And it turns out that if you indeed combine the row and the column forces and take advantage of them simultaneously, then you can get away with just using 3 cannonballs. And this is one of the ways that you can do it. And perhaps you can come up with other ways of doing this as well. Now, think about whether you can do with fewer than 3 cannon balls. Is it possible to push this even further? Feel free to pause the video here at this point and think about this for a moment.\n(Refer Slide Time: 4:10)\n\nAlright. So, you might discover that there are these three enemy locations here that happen to not share a row or a column. Meaning that any two of these locations are on different rows as well as on different columns. Because there are three such locations, notice that you are going to need 3 distinct cannon balls to take care of these 3 locations because there is no cannonball that will be able to hit two of these locations at once, simply because they are neither share a row nor share a column.\nSo, this solution that we just had with three cannonballs is the best that you can hope for in terms of minimizing the number of cannonballs, which turns out to be the optimization objective that is handed out to us.\n(Refer Slide Time: 4:52)\n\nSo, the task in this problem is to come up with a solution that uses as few cannonballs as possible to eliminate all the enemies that are in the temple. So, that is the problem statement. And I hope that at this point, all the details, at least about the question, are clear. You might guess that we want to solve this by setting up some sort of a flow network that encodes all the information that is there in this problem.\nAnd hopefully, either a flow or a cut in this network will give us what we want. So, feel free to take a pause here and walk up and down a little bit and think about what would be a natural graph to associate with all the information that you have here. Now, our modeling of this problem as a flow network is going to set up the foundation for the success of the rest of the solution. It is also the part of the solution that I think requires the most imagination.\nSo, once somebody gives you the flow network, you might be wondering: How do you expect me to come up with something like this? So, that is a fairly natural question. And the best answer that I have at this point is to just practice a lot of these problems. Right. And you can find some more in the extras section of the course website. So, I definitely encourage you to take a look at that. And think about how the modeling will work.\nUnfortunately, there is no formulaic approach to this. So, you just get better at it with experience. The more examples you see, the more intuitive the process becomes. And over time, you will just get quicker at the process. And it is also perfectly fine to stumble around a bit and do work with a few ideas that do not work at first, and you keep needing to sort of nudge them and morph them into something that eventually works. It is all a part of the process, really.\nSo, once again, if you want to take this up as a bit of a challenge, you want to pause the video here and think about what would be a way to model the information in this problem as a graph. And when you are ready, just come back so we can exchange notes. Alright. So, at this point, I am going to introduce you to the flow network that we are going to build based on the information that we have about enemy locations in the grid.\n(Refer Slide Time: 6:58)\n \nSo, what I am going to do, to begin with, is I am going to introduce vertices corresponding to the rows and the columns of the grid. Okay. So, in this example, we have 7 rows and 7 columns. So, that corresponds to 7-row vertices and 7-column vertices. And that is what I will continue to call them throughout this discussion.\nNow, how do I want to introduce the edges? I would say this is pretty natural. I want the edges to capture information about the locations of where the enemies are. So, in particular, we are going to add an edge between the vertex that represents the ith row and the vertex that represents the jth column, if and only if there is an enemy at the location given by the intersection of the ith row and the jth column. So, just to be clear about this, let us play this out in this example by looping through all the enemy locations given to us.\n(Refer Slide Time: 7:46)\n  \n  \nSo, let us look at the one that is on the second row in the sixth column. To remember this location, I am going to add an edge between R2 and C6. Then we have the one that is on R3 and C2, so we are going to add an edge from R3 to C2. Then we have this one here, that is again on C2 and a row 5. So, we are going to add this edge between R5 and C2.\nAnd again, we have another location on the fifth row, this time on the fifth column. And that is again going to be remembered by adding this edge between R5 and C5. And finally, we have this location which is on the sixth row and the sixth column. And that is going to bring in this edge between R6 and C6. So, that is essentially the graph that we construct. And at this point, we can completely forget about the grid. This graph essentially captures or encodes all the information that we have about the enemy locations. So, this is the graph that we will be working with.\n(Refer Slide Time: 8:37 and 8:41)\n  \nAgain, just to recap, this is how we constructed the graph. The graph had a vertex for every row and a vertex for every column. And we dropped edges between row-column pairs whenever the corresponding locations had enemies between them. Now, let us also think about what we should be looking for in this graph. Remember, we are trying to fire the smallest number of cannonballs that takes care of all the enemies.\nThe cannonballs can be fired either on a row or on a column. So, naturally, cannonballs correspond to vertices. They correspond to the rows and the columns on which the shots are going to be fired. But now, what do we want to achieve by firing these cannonballs? We want to be able to knock out all the enemy locations. These enemy locations have been modeled as edges.\n(Refer Slide Time: 9:32 and 9:56)\n  \n\nSo, essentially, what we are looking for is a subset of vertices that is incident on all the edges in our graph, which is to say that if we remove these vertices, then all the edges would go with them. Okay. So that is what we are looking for. In graph theory parlance, such a subset of vertices is called a vertex cover. So, I might use that phrase now and then to refer to our solution.\nAlright. So, let us now go back to the graph. And remember, what we are looking for is a vertex cover of the minimum possible size. A vertex cover that involves the smallest number of vertices. Now to find this minimum vertex cover, we want to take help from the Max Flow algorithm. So, we have to expand on this graph and turn it into some sort of a flow network. So, let me give you a hint in terms of what sort of a flow network you might want to build.\nRemember that you have already seen how we can use flows to find maximum matchings. Why am I bringing up matchings? Well, remember what we said earlier about a lower bound on the number of cannonballs that we need to fire. We said that if you have a collection of enemy locations that share no common row or a common column, then all of these locations require their own cannonball to be fired to take care of them. Right.\nThat is how we said that the solution with three cannonballs was optimal for the example that we were looking at earlier. So, what does this sort of a collection of enemy locations that have no rows or columns in common correspond to in this graph? Take a minute here and think about this. I have already hinted at what it might be. But still, Pause the video here and come back when you have had a chance to think through this.\nAlright. If you have a collection of enemy locations, which have no column or no row in common, then that corresponds to a subset of edges that do not share any vertices. But this is precisely our notion of a maximum matching. Right. So, it is at least a notion of a matching. And if you wanted the best possible lower bound on your solution, you would want to find a maximum matching because that gives you the most information. It tells you well, you are definitely going to need at least so many cannonballs.\nSo, let us try and borrow from what we have seen before and build the kind of network that we would have built if we were looking for a maximum matching in this graph. So, remember, the way we did that was to introduce a source vertex that was adjacent to all the vertices on one side of this graph. And we also added our target vertex. And we said everybody on the other side was going to be adjacent to the target vertex. So, I did not say this explicitly, but it should be visually evident that we are working here with a bipartite graph.\nAnd all the edges, of course, have one endpoint in the row vertices and the other endpoint in the column vertices. So, it is pretty natural to set up this flow network. And we could start off by saying that all of the edges (that are) incident to the source and the target vertices have unit capacity. This was crucial to ensuring that what comes out of the flow corresponds to a matching. When we model the matching problem, we also said that all the edges that go in between have unit capacity as well because that did not make a difference.\nBut it turns out that because it does not make a difference, it is going to be more convenient for us to think of the interim edges as not having any capacity constraints at all. And we will see why this makes our lives easier a bit later. So, what we are going to do with the edges that are in between is that, as before, we will orient them from left to right, which is to say that all the edges are sourced on the row side and have their target on the column side.\nIn this case, by target, I just mean where the edges end. So the direction is that they are pointing from rows to the columns. So, we will orient them like that. But we will say that these edges all have infinite capacity. Now, let us think about what a flow looks like in this network.\n(Refer Slide Time: 13:36 and 14:29)\n \nSo, any flow and in particular, a maximum flow will end up picking out a matching from the middle of this network. Okay. So, if you look at all of the edges that go from the rows to the columns that have some flow going through them, this will still be a matching. And this is something that you can verify by just realizing that the capacities of the edges from the source, and the capacities of the edges incident on the target, all have unit capacity.\nSo, it is not possible for these edges to really have a degree more than one on either side. Remember that we are still working with flows that are integral. And that is something that you should find useful as well if you want to argue this a little more formally. Alright. So, we have a flow that identifies a matching for us. And in particular, a maximum flow will identify a maximum matching.\nSo, the value of the maximum flow automatically gives us a lower bound on the number of cannons that we need. So, we know that we are going to need so many cannons for sure because these edges will correspond to enemy locations that do not have any rows or columns in common. So this is a useful starting point, but it is not the solution that we are looking for.\nIf you go back and look at the problem statement, you are not only asked to identify the smallest number of cannonballs that you need (but) you are also asked to identify the specific rows and columns that you should target to get rid of all the enemies. So, we still have some way to go. But just as a teaser for what is coming up, let me tell you that this size of the maximum matching here, or the value of the Max Flow, is not just a lower bound on the answer. It is not just an indication of how much you need, it turns out that it is the answer.\n(Refer Slide Time: 15:20 and 15:55)\n \nNot only do you need at least so many, (but) it is also true that you can manage with so many. So, what we are going to do is use the maximum flow, but actually, more directly, we are going to use the minimum cut associated with this maximum flow to identify a certain number of rows and columns that we need to target. And it will turn out that this number exactly matches with the lower bound. And in fact therefore, that is an easy proof that what we have is, in fact, optimal. So, let us get started with trying to figure out how we can do this.\nSo, let us go back to the maximum flow that we had here. And let us take a look at the residual graph because that is where we get our minimum cut from, if you remember. So, in the residual graph, all the unit capacity edges that are in black will stay the same. All the unit capacity edges that are blue will get reversed. And all the infinite capacity edges that are in blue will, well they will become bi-directional edges because the forward edges will remain with an infinite residual capacity, but you will get some back edges, which have unit capacity. And all the black edges that have infinite capacity will just stay as black edges with infinite residual capacity.\n(Refer Slide Time: 16:34)\n \nSo, if you were to construct this residual graph, this is what it is going to look like, based on what we just discussed. Now, let us look at all the vertices that are reachable from S in this residual graph.\n(Refer Slide Time: 16:47)\n \nWe want to remember that what we are looking at is going to also be a minimum cut back in the original flow network. So, here is what the reachable set of S looks like in the residual graph. So, all of the vertices reachable from S have been marked green, and everything else has been marked red. You can pause the video here and confirm that this is, in fact, what you would obtain if you were to run, let us say a BFS starting from S.\nIn fact, in the very first step, you will catch hold of, say, R1, R6, and R7, and even R4, but you get R2 because there is going to be a path via, I believe, C6, which is reachable from R6. So, you are going to take the path from R6 to C6, and to R2. And essentially, after that you get stuck. So, this is all the vertices that are reachable from the source.\nNow, if you look at this and just think about whether there is something interesting going on here, then what is it that strikes you? Just take a moment here and see if there is anything that occurs to you as being a little bit unusual or interesting about what has just happened in this cut. Alright. So, I am going to think of the row vertices as being S loyalists and the column vertices as being the T loyalists.\nSo, the row vertices were in the original network very close to the source, and the column vertices were very close to the target. And it looks like after we run the MaxFlow and we obtained this cut, it looks like some of these vertices have changed parties. So, now there are these two-row vertices that are accessible, or from where you can go to the target vertex. And there is this column vertex, which is accessible from the source vertex.\n(Refer Slide Time: 18:34 and 19:05)\n \nSo, in some sense, some row vertices have gone away from S, and some column burgesses have joined S. And in some sense, you can think of them as having broken ties with T. Of course, I should emphasize that none of this language is formal or meaningful, as the formal definition would go. But hopefully, it gives you a picture of something that has happened, some upsets that have taken place that will hopefully give you some intuition for what is to come.\nSo, let us call these vertices the misfits, and let us highlight them here. So, remember, the row vertices are the ones that do not belong to S, the ones that have been highlighted, and the highlighted column vertices do belong to S. It is just not their natural state. But that is where we are.\n(Refer Slide Time: 19:24 and 19:35)\n \nNow, let us go ahead and take a look at what this cut looks like back in the original flow network. So, I am going to move things around. And instead of having the edges from the residual graph, you are now going to have the original edges of the flow network.\nSo, that is what this looks like. You have this column vertex that has come on the S side, these two-row vertices that have moved to the C side. And if you think about, well, what are the edges that are crossing this cut? You will see that these edges are exactly the unit capacity edges that are either incident on S or incident to T.\n(Refer Slide Time: 19:54 and 20:10)\n \n\nIn particular, I want to say that every misfit vertex contributes exactly one unit capacity edge to the cut. And, in fact, the capacity of the cut is equal to the number of misfits. There are no other edges that cross the cut.\nAnd the reason for that is, remember that we have a finite value at Max Flow, which is equal to the capacity of the min cut. And remember, every edge that was between a row and a column vertex had infinite capacity. So, such edges are definitely not going to cross the cut. Any edge that crosses the cut must be a unit capacity edge. The unit capacity edges are the ones that are incident to either S or T, and the ones that will cross will essentially have a misfit vertex on the other side. Right.\nSo, in particular, if you look at all the unit capacity edges incident on S, they were the row vertices. And if this edge is crossing the cut, then that is a row vertex that is gone over to the column side. Similarly, if you look at any unit capacity and incident on T, well, that was an edge that started off with a column vertex.\nAnd if this vertex is crossing the cut, then it must have moved over and joined the row side, which again, makes it a misfit vertex. So, hopefully, by staring at this example and thinking about some of the things we have said, you can convince yourself that these misfit vertices are exactly as many as the capacity of this cut. And therefore, in fact, the number of them is equal to the size of a maximum matching because that was equal to the value of the maximum flow.\nSo, in fact, at this point, the number of misfit vertices that we have, is equal to the lower bound that we have on our solution. So, would it not be really cool if the misfits formed a solution? Because then we would be done. And you can probably already sense it from this example. But the fascinating thing is that this is actually always true. The set of misfits actually forms a vertex cover in the original graph.\nSo, every edge in G is incident on a misfit vertex. Let us think about why this is true. How can an edge not be incident on a misfit vertex? Remember, every edge in our graph G that we care about is an edge that goes between a row vertex and a column vertex. Remember that because we are looking at a finite capacity cut, this edge cannot be crossing the cut. So, it is either completely contained on the left side, or it is completely contained on the right side, and it goes between a row and a column.\nSo, if you are on the left, and you add an edge that is between a row and a column, then the column side is a misfit vertex. If you are on the right, and you are an edge between a row and a column, then the row side is a misfit vertex. So, you can think about all the cases involved here. But hopefully, what I have said essentially captures everything that you need to consider.\nSo, the point here is that the set of misfits actually end up killing all the edges that you have, and it is exactly what you are looking for. So, the set of misfit vertices gives you the locations or the indices of the rows and the columns from which it is useful for you to fire cannonballs so that you can get rid of all the enemies in the grid.\n(Refer Slide Time: 23:10)\n \nSo, that is pretty much it, the misfits are the answer. And we just need to write some code to identify all the misfits. And we are going to get to that in a moment. But just to summarize how we came here, we said that the misfits are as many as the capacity of the minimum cut. By the max flow min cut duality, we know that the capacity of this minimum cut is equal to the value of the maximum flow.\nAnd because of our previous discussions, we also know that the value of the maximum flow is the same as the size of a maximum matching in this graph, which we know is a lower bound on the number of cannons. So, that is why we have found not only some solution but, in fact, a solution that is guaranteed to be optimal. I think this is very cool.\nAnd as I said, this is true in general, that in a bipartite graph, the size of a minimum vertex cover is equal to the size of a maximum matching. This may not hold in general. You can come up with examples of graphs; for example, a triangle would do. The size of a maximum match in a triangle is 1, but a minimum vertex cover needs two vertices. So, even though this may not be true in general, and that is something you should be careful about. It is a beautiful duality theorem that holds in the context of bipartite graphs.\nAnd if you want to look it up a little bit more, this often goes by the name of Konig’s theorem. And what we have seen effectively amounts to a proof of Konig’s theorem, based on the duality of the values of the maximum flow and the minimum cut in a flow network. I should say that this is typically not the traditional or the default proof that you will see of this theorem.\nAnd it turns out that this is one of those theorems that have many different proofs and many different approaches and different consequences. So, there is a lot to learn. If you are interested in something like this, please do check out the description of the video or the course website for more pointers. So, having discovered this structural duality, we still have a little bit of work left to do, which is to implement this in code. But knowing what we know by now, the implementation part is super easy once again. So, let us take a quick look.\n(Refer Slide Time: 25:18)\n\nSo, as before, we just read in all the information about the enemy locations, and we construct the appropriate graph. So, the construction of the graph is actually very similar to the construction that you have already seen for the maximum matching problem from last week. Nevertheless, if you want to take a look, as always, you can find the full code in the official repository for the course.\nSo, please take a look if you want to refer to the part of it where we take in the input and build up the flow network. But once you have done that, you just run the maximum flow algorithm. And just like we did with the minimum cut problem in the previous module, we identify the reachable set, this is the set of all vertices that you can reach from the source vertex.\nAnd now remember, we want to identify the misfits. So, we want to look at all the vertices that are reachable from S, which are column vertices, and we want to find out all the vertices that are not reachable from S and which are row vertices. Right. So, this is what we are doing here we are going through all the row vertices. And if a row vertex is not reachable from S, that is what the first ‘if’ condition does.\nSo, it is a row vertex that is not reachable from S. Then that is a misfit vertex. And that is what we are going to output. And similarly, we go over all the column vertices. And if a column vertex is reachable from S, and that is the second ‘if’ condition, then that is a misfit as well. And that is what we are going to report as the output. So, at this point, we have listed all the rows and columns that we need to attack to get rid of all the enemies. And because of all the discussion we have had so far, we know that this answer is. in fact, optimal.\nSo, I hope you enjoyed this, I think this was an elegant problem to think about. And the discovery about the minimum vertex cover being equal to the maximum matching in a bipartite graph, I think is a cool thing to know. And this is not something that you now have to come up with by yourself in a contest situation, now that you already know it. Hopefully, this is information that you can leverage for future problems in future contests. So good luck with that.\nAnd with this, we come to the end of our exploration of graph-based problems in this course, and I hope that you enjoyed this as much as I did. Please keep the conversation going either in the comments in this video or over the mailing list or the Discord community, especially if you are watching this during a live run of the course. For the last three weeks, we will be talking about dynamic programming, and I hope to see you back then. Thank you so much for watching, and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec51.html",
    "href": "materials/cpnotes/Lec51.html",
    "title": "Memoization | Frogs 1 (AtCoder Educational DP Contest)",
    "section": "",
    "text": "Lecture - 51\nMemoization | Frogs 1 (AtCoder Educational DP Contest)\n(Refer Slide Time: 02:55)\n\nHello and welcome to the first module in the 10th week of Getting Started with Competitive Programming. With the 10th week, we are starting a new theme in the course and this is going to be Dynamic Programming. It is a theme that we will continue to explore all the way till the end of the course, which is to say up to week 12.\nAs you probably know already, dynamic programming is a ubiquitous technique that is extremely popular in competitive programming. Almost every contest has at least one problem that involves dynamic programming, either exclusively or in conjunction with other techniques. So, we are going to take our time and go over several examples with different flavors.\nIn this introductory module, I will try to explain the main ideas involved in dynamic programming and we will look at what is usually referred to as the top-down approach or memoization. In the second module this week, we will look at the so-called bottom-up or tables-based approach to dynamic programming. Once you are done watching both of these modules, you should be well prepared to solve basic dynamic programming-based problems. And the good thing is that there are tons of examples out there for practice.\nIn fact, the two problems that we will use as examples are from two problem sets that are really nice to start with. So, the first one is from an AtCoder Educational Contest on Dynamic Programming. It had 26 problems, coded a, b, c through z, one for each letter of the alphabet, and I think, sorted roughly in increasing order of difficulty.\nThere is a lot of material around this problem set; you can find, I think, blogs on Code Forces that try to explain some of these problems. But at least the initial ones are quite doable, based on what you will see in these lectures. So, I would definitely recommend that you try going out there and solving some of them on your own, even without having to look at the editorials.\nIn the next module, we will tackle a problem from the CSES dynamic programming problem set. That is a slightly smaller collection of 19 problems, again progressing in increasing order of difficulty. But once you are done with this, you should definitely be able to tackle the first few problems in that problem set. Again, it is very easy to set up an account on CSES. If you have not already done that before, for some of our previous problems, I think this would be a good time to do it. And try to roll up your sleeves and get some practice with dynamic programming, at least the elementary problems.\nSo, with all that said, let us get started with our first problem for this week. And this one is called Frogs. It is called Frogs 1 actually, I think, because there are three problems with the same premise, the same setup, but slightly different questions, in terms of, what is going on. So, there are Frogs 2 and Frogs 3 at different parts of the problem set, so you might want to go and check that out after you are done with this.\nBut for now, let me tell you about Frogs 1. As usual, we are going to start with a problem statement. This time I will interweave an example as we go through the problem statement itself. And I encourage you to think about, how this example works out, as you go through the problem with me.\n(Refer Slide Time: 03:30)\n \nSo, to begin with, there are N stones, numbered 1 to N, and for each ‘i,’ from 1 to N, we are given the height of stone number i. So, I am going to visualize this, literally with comical-looking stones here. And the numbers that you see at the bottom of your screen are actually the heights of these stone piles. The pictures are not necessarily to scale. And these numbers are taken from the last sample input. Okay. So, we have N stones, left to right, think of them as stones 1, 2, 3, all the way up to N. In this case, as you can see, N is 6. And this will be a running example as we go along.\nNow, there is a frog who is initially on stone one. So, introducing the frog. I should have probably picked up a side profile because the frog is going to jump around. So, this is not very realistic. But that is okay. I think it is nice to be able to see the smiling face of the frog as we try to solve this problem. So, that was the rationale.\nNow, our friend, the frog, will repeat the following action, some number of times, to reach stone N. Remember, he starts from 1 and he is trying to get to the last stone in the series. The first thing that he can do, is that, if he is on stone number ‘i’ currently, he can jump to either stone number ‘i’ + 1 or stone number i + 2. So, let us look at the frog in action.\nSo, right now, the frog is in stone number 1, and from here, he could go to stone number 2, or he could go to stone number 3. Okay. So, both of these stones are accessible to the frog, sitting at stone number 1. But he cannot go in one step. He cannot go to say stone number 4 or any of the later ones. The only way to get there would be via an intermediate jump first. Okay. So, whenever the frog does jump between two stones, he incurs a cost, and the cost is proportional to the difference between the heights of those stones. And we are looking at the absolute difference here. Okay. So, let us again take a look at a couple of jumps and see how that works.\nSo, here, for instance, the frog is on the third stone and he jumps to the fifth one. And notice that the fifth stone and the third stone have the same height. So, this was smooth sailing – apparently, no jumping involved! So, a cost of 0 was incurred in this particular jump. On the other hand, compare this with a jump from stone number 3 to stone number 4. That is a more steep sort of exercise, and the difference between the heights of these 2 stones is 60-10, 50. The absolute difference is 50. And the cost, therefore, is also 50. So, now that we understand how the individual jumps work in terms of their costs. It is time to take a look at, what our task is going to be.\n(Refer Slide Time: 06:22)\n\nIt is actually quite predictable, you might have guessed that what we want to figure out is, what is the best way of jumping around that takes the frog from stone 1 to stone N? And by the best way, we simply mean the way that involves the least cost. And the least total cost, in particular, is going to simply be the costs of all of these individual jumps added up.\nSo, you want the cheapest route from 1 to N, except this is not to be confused with say shortest paths and graphs. There is not really a graph structure underlying this problem here. At least not a very natural one. We just want to figure out, what is the best sequence of jumps that lands the frog at stone number N.\nSo, now that is the entire problem statement and I would say that this is a good place to pause and think about, how you would come up with a solution to this problem. Now, if you are already quite familiar with dynamic programming or recursion as a technique, then you might find the solution pretty easily. It is reasonably predictable.\nOn the other hand, if you are not so familiar with these techniques, then you might treat this as a good warm-up exercise. And finally, if you have never seen dynamic programming, explicitly before, and you are not all that familiar with using recursion, then you might want to think about, what would be a way to solve this problem that does not really involve the use of any of these techniques, but perhaps uses other techniques that you know.\nFor example, would a greedy strategy work? A natural greedy strategy may be to just take the better of the two jumps that are ahead of you. So, wherever you are, there are two possibilities, one of them is going to be cheaper and if not, then you could just break ties arbitrarily. That is a complete algorithm on its own. You could think about whether that would actually work.\nYou could think about what would happen if you tried to come up with a Brute-Force Solution. So, let us say you explored both pathways, and for each of those pathways, you explored both of the options that would await you. If you took either of them and so on and so forth. And what would be the sort of the expense of computing a solution in this way and so on? So, I think there is enough food for thought here for everybody, no matter where you are on the spectrum of pre-existing familiarity with DP or recursion.\nSo, give it a thought and come back once you have done that. Alright. So, it turns out that if you followed a greedy approach, then that would actually not work, and I would encourage you to come up with explicit examples demonstrating that it would not work. On the other hand, if you try to Brute-Force a solution by, say, enumerating all possible sequences that the frog could take then you will find that just the sheer number of sequences that you have to consider is exponential or it at least turns out to be exponential. And for this problem that is not going to be feasible, because if you look at the constraints, N can be as large as 10 to (the) 5. So, that is simply not going to work.\nNow, having said that do not completely trash the Brute-Force approach just yet. Do keep it at the back of your mind for comparison with what we are about to do. In fact, you might find that what we actually end up doing looks suspiciously like a Brute-Force approach. And hopefully, with that, you will be able to appreciate why what we do actually ends up improving on the Brute-Force approach, by somehow coming up with a way to cleverly cut through, what is otherwise a very very large search space. Okay. So, let us think about how we can manage this really large set of possibilities that we actually have to consider which are all possible valid sequences of jumps, from stone number 1 all the way to stone number N.\n(Refer Slide Time: 10:15 and 11:12)\n \nSo, we do know that when the frog is done jumping around at the very end, he ends up at the last stone. So, one thing that we are going to do is, really try to see, if we can play this process back in reverse that is something that is going to be a part of the way we think about this. So, instead of thinking about, what is the next jump from stone number 1, we are going to say, suppose, there is an optimal sequence, of course, there is some optimal sequence, it is well defined.\nIn that optimal sequence and if there are multiple optimal sequences, you could just fix any one of them, it can be arbitrary as long as it is fixed. And in that optimal sequence, you want to ask yourself, well, how did the frog get to the N’th stone in this particular sequence? What was the penultimate step? And then we will try to take it from there. That will help us come up with an appropriate recursive formulation.\nSo, in particular, let us just write down all the possible sequences that are valid. So, they are not all in here. So, this is just sort of a partial list, because of lack of space and also as I was saying earlier, this does look like, we are considering the whole space of valid sequences. So, this might remind you of the Brute-Force approach that we were talking about earlier.\nBut do not worry about it so much, I want to show you this just to talk about how you come up with the idea for a recursive algorithm. We would not actually be going through this list when we come up with the algorithm. So, this is more for just getting used to what is going on. So, hypothetically, this is the space of all possible solutions, and I want to make a couple of observations about this collection of sequences.\n(Refer Slide Time: 12:11)\n \nThe first observation, which was implicit and what we just said earlier, is that all of these sequences end at 6 in our example, and more generally, they would always end at N. That is just a feature of every solution by definition. All of these sequences end at the last stone. What can we say about the second last element of these sequences? Ignore pathological cases like when N = 1. In fact, I think, it is promised in the problem constraints that N is at least 2.\nSo, you do not have to worry about the case when N = 1. It is ok for me to talk about the second last element in any of these solution sequences. Is there something that you notice about the second last element? Especially given the rules of the game. Remember that when jumping ahead, a frog can only jump to the next stone or the next-to-next stone. So, when he lands at stone number N, where could he have come from?\n(Refer Slide Time: 13:16, 13:37 and 13:52)\n \n\nYou just need to turn this around a bit to realize that the second last element is always going to be either N-1 or N-2. Okay. So, in the optimal sequence, we do not know which one of these two it is. That is the million-dollar question. If we knew how to figure that out, then we could just work our way backwards all the way up to stone number 1. So, it could be either of these, but it is always one of these.\nSo, if you look at the second last element in these sequences, then it is always 5 or 4 in the context of our example. So, what I am going to do now is basically partition this space of valid solutions into two buckets. The first bucket consists of all the sequences that have 4 as the penultimate number. And the second bucket has all those sequences that have 5 as the penultimate number. Okay. So, more generally, you want to divide up your search space into 2 collections. In the first collection, you look at all those sequences where the last hop happened from stone number N-2. So, it was a skip over stone number N-1 to get to the last stone.\nAnd in the other bucket, you collect all of those sequences, where the last hop was a direct hop from stone number N-1 to stone number N. Okay. So, why are we doing this? Well, recall that our task here is to figure out the sequence that has the best or the smallest cost. So, you can imagine that each of these sequences here is tagged with a cost, which is simply the sum of the costs of all the individual jumps that happen in the sequence that you are considering. Now, by breaking it up in this way, you might see that the cost of every sequence can be thought of as the cost of getting to either stone number 4 or 5, as the case may be, plus the cost of that last jump.\n(Refer Slide Time: 15:10 and 15:27)\n \nSo, in some sense, if we knew the best way of getting to stone number 4 and the best way of getting to stone number 5, then we could just tag along the costs of the last jumps to figure out the sequence that has the best overall cost.\nIn other words, let us say that we knew, somehow magically, that the cheapest way of arriving at stone number 4 has a cost of Y and the cheapest way of arriving at stone number 5 has a cost of X, then notice that the final answer really boils down to a comparison between, at least in this example, Y + 40 versus X + 10.\n(Refer Slide Time: 15:52)\n\nMore generally, it is going to be the cost of going from stone number N-1 to N, added to the best way of getting to stone number N-1 itself, versus the cost of going from stone number N-2 to N, added to the cost of the best way of getting to stone number N-2. Essentially, these are your two best options, and the final answer is going to be the better of these two. If there is a tie, then you can break it arbitrarily.\nYou can take a moment here to convince yourself of the correctness of the claim that we are making here, that this is indeed the answer. It really follows from the exhaustiveness of our approach. Consider any sequence that claims to be an optimal sequence. Look at the last step that is being made in that sequence. It is going to be either N-1 to N, or it is going to be N-2 to N.\nSo, that is a fixed cost that the sequence has to pay, and beyond that, well, your optimal sequence has to get this turn number N-1 or N-2, as the case may be. And on that front, it cannot really hope to beat the answer of N-1 or the answer of N-2 because these quantities, by definition, are the optimal costs for reaching stones N-1 or N-2, as the case may be. So, hopefully, this sequence of arguments convinces you that this setup that we have here does lead you to the right answer. So, this equation is what we want to compute.\nNow, notice that to compute A and B, we have really two components to worry about. The second term in the sum, which is the cost of going from N-1 to N or N-2 to N, is simply given to us in the input. So, we just pull out the heights of these stones and or take the difference. So, that is straightforward. Now, other than this, we also have the answer of N-1 and the answer of N-2 as terms that we need to compute. And that is something that we are going to compute by magic.\nWe are just going to ship this off to the recursion fairy, which essentially means that the way we will compute the answer of N-1 and the answer of N-2 is exactly the same as the way that we are currently trying to compute answer of N. So, when we want to compute the answer of N-1, we basically pretend that the whole universe, the whole instance that we are dealing with, is now restricted to stones 1 through N-1 only. And then we just solve that on its own. And when we are done, we come back to the current world, which is the world with N stones, and we piece everything together.\n(Refer Slide Time: 18:41)\n\nSo, if you were to translate this to code, it would look something like this. You want to write this inside a function so that it can call itself. And this is essentially the recurrence that we had on the previous slide a few moments ago. Now, if you stare at this for a while, you might realize that something is missing. If you were to actually write this program and implement it, which you are welcome to try, you might find that the program does not really stop. And the reason for that is that we have not really given it a stop signal.\nAnd notice that this is not because we have a bug in the code or something. We have implemented our idea exactly as we had written it down earlier. So, in fact, if you go back to the recurrence that we had and let us say, you try to execute it just on pen and paper, you will have the same experience. You will just keep going because the recurrence does not really tell you, where to stop.\nSo, let us say that you start off with trying to figure out the answer for the 6 tones that we had earlier, and you start by computing ‘A,’ that is going to be an answer of 6-1, 5. That is just the first thing that you need to worry about. So, let us say that you try to unravel that you will get to answer of 4 and then 3, 2, 1, 0 and then -1 and -2 and so on, which is super weird. So, in particular, notice that asking for the answer when N = -1 does not even make sense as a question.\nWhat do we mean by there are ‘-1’ stones? We do not even have the data for that kind of situation. So, that is a hint that that is a place that we should not go to. It is a dangerous place. And we do not want our algorithm to ever have to worry about this. So, when do we get into situations where we may start asking these questions that do not make sense? So, let us think about what happens when N = 1, for example.\nSo, if N = 1 and we try to apply this algorithm, then we will have to worry about the answer of 0 and the answer of -1. And in some sense, both of these questions do not really correspond to scenarios that exist in the context of our problem. We know that we are looking at, at least one stone to begin with for the frog to be on. So, these are unreal scenarios, and that is why we do not really want to get into them. So, N = 1 is something that we want to be able to address without getting into recursion. Similarly, for N = 2, you are thinking about the answer of 1, which is kind of.\nBut we also have again answer of 0, which corresponds to again imaginary world; it does not really correspond to a well-defined problem scenario. So, also, for N = 2, I want to avoid using the recursive method to compute the answer. So, if you are not going to use the recursive method, then how are we going to calculate the answers? Well, the answers can be calculated by hand for these scenarios. Because notice that when you just have 1 or 2 stones, then it is really easy to figure out what to do.\n(Refer Slide Time: 21:42 and 23:28)\n \nIn particular, if you have just one stone then there is nothing to be done. The first and the last stone are the same. So, there is no cost involved in getting from the beginning to the end. So, the answer, in this case, is 0. On the other hand, if you have two stones then there is really no choice; you only have one thing that you can do. So, the answer is going to be the difference between the heights of the first stone and the second stone, the absolute difference.\nSo, these are answers that we are going to compute in some sense by hand and this is what will cut off the recursion and will make sure that the overall algorithm actually terminates and returns a meaningful answer. Of course, you could compute, for instance, the answer of 3 by hand as well, or the answer of 4 by hand, by doing some cases. But the point is that you do not really need to. These are the minimal base cases that make your algorithm work.\nAnd although in some scenarios, it is useful to be clever about what kind of base cases you compute. For the most part, by and large, at least for elementary examples of dynamic programming, the base cases are usually very easy to figure out, but they are also very, very important. Okay.\nSo, just keep in mind that if you do not have a base case specified or you have it improperly specified, because, with some issue with indexing and things like that, this may be really a common source for bugs, certainly, if your program is timing out or it seems like it is taking forever, watch out for the base cases. And if your answers are off by just a little bit, just make sure that your indexing for the base cases has been done properly. Okay. So, let us go back and fix our code here.\nSo, this is the recursion with the base cases thrown in. And if you were to implement this and try it out, you will see that you do get the right answers. But you may find that it is still taking quite a bit of time. This is a really good place to pause and actually play around with this implementation. Try it with small and large examples on your computer and see how long it takes. If you feel like it, you could also try and upload this solution and see if you time out. Also, think about how would you analyze the running time of this algorithm? Right.\nSo, just what is your estimate for how long this takes? Think about all of this, and come back once you have had a chance to play around with this program a bit. All right. So, let me address the question of how long this program takes. The best way of analyzing a recursive program is through what is called a recursion tree.\n(Refer Slide Time: 24:28)\n\nSo, let us just try to visualize, what these function calls are doing, by examining what happens if you start off by invoking it for the case of 6 stones like we have in the running example that we started off with. So, when you invoke the algorithm to try and figure out the answer for 6 stones, it is going to make these 2 function calls to understand the universe of what happens with 5 stones and 4 stones, respectively.\nAnd, well, the first function call that gets executed is the one involving 5 stones. So, what is that going to do? Well, it is going to come back and try and understand what is going on for 4 stones and for 3, and once again, the first branch that gets executed is the one involving 4 stones.\nSo, that is going to degenerate further into 3 and 2, and for 3, you are again going to probe 2 and 1. And now there is going to be no further recursion because, as we have discussed earlier, 2 and 1 form the base cases, so you just go back up and report the answer to the computation for 3 stones. And similarly, 4 is done as well. And now we come back to 5, which on the right branch was also waiting for the answer for 3 stones.\nSo, that is once again going to probe 2 and 1. And now you walk your way back up to 5 and then 5 reports back to 6 and then 6 says okay. So, I understand what is going on when there are 5 stones. Now, let us go ahead and think about what happens when there are 4 stones, and that is going to lead to more recursive calls on 3 and 2. The call for 3 will again go further down and explore 2 and 1. And at this point, you are truly done. Because, well, at this point, all function calls have returned values, and you just have to do some computation to report the final answer at the very end.\nSo, what is the complexity of the algorithm? Well, it is proportional to all of these function calls that are happening here. The number of function calls that you see on your screen, and of course, there is a multiplier for the amount of work that you do at each function call. So, for instance, let us say you were at the node labeled 5, then you were, of course, waiting for the function calls to 4 and 3 to return values. And after that, you still have a little bit of extra computation to do. So, you have some differences in heights to compute, some addition, and taking a minimum.\nBut all of this is essentially constant time. So, the overall running time can really be thought of as being proportional to the size of this recursion tree. So, how many nodes are there in this recursion tree? So, given that the definition of this tree is really driven by a recursive function. It is natural that an expression that determines the number of nodes in this tree is also given recursively. So, if we were to use T of n to denote the number of nodes in the recursion tree for the algorithm when invoked with input n, then we get this expression for T of n.\n(Refer Slide Time: 27:36)\n \nThere is the root node itself, and then there are these 2 function calls to n-1 and n-2, resulting in recursion trees with T of n-1 and T of n-2 nodes, respectively. Okay. So, this is a valid expression for counting the number of nodes in the recursion tree for the algorithm when called with input n. And of course, just like the recursive algorithm, even this expression could use a base case. For it to be well defined, I am not making it explicit here, but you can probably check that T of 1 and T of 2 are both 1, and that will make this function description complete.\nNow, what I want to do here is just get a sense of how fast or slow growing this function is in terms of ‘n?’ The recurrence itself may strike you as a familiar one. It does look a lot like the Fibonacci recurrence, something that has come up before in this course as well. But instead of looking at an exact closed form for this recurrence, I will just try to do a quick and dirty lower bound.\nSo, notice that T of n is going to be strictly greater than T of n-2 + T of n-2. So, I am discarding the 1. And notice that I can claim that T of n-1 is at least T of n-2 because even by definition, T of n-1 is T of n-2 + something. Right. So, we have this simplified expression on the right-hand side, which works out to T of n being strictly more than 2 * T of n-2. And if you were to unravel this further, you will see that you just end up collecting two’s until you hit something like n = 0.\nSo, you could take a moment here to think about how many two’s you will accumulate by the time you hit the base case, which is when n is 0. So, let us say you start with, for example, n = 20. Then basically, the steps here would be from 20 to 18 to 16 to 14, and so on. So, you can see that you need n over 2 steps to go from the current value of n all the way down to zero. So, the number of two’s you accumulate is roughly something like n over 2. Okay.\nSo, I am being a little sloppy here in terms of not worrying about whether n is odd or even, etc. This is just to give you a rough sense of how big T of n is. And hopefully, this sort of back-of-the-envelope rough calculation tells you that T of n is definitely looking pretty scary right now. It is kind of exponential, which is not a good look. It is definitely not going to be feasible for the problem that we are trying to solve.\nAnd so, I would like to take you back to the recursion tree here. And I am going to request you to spend some time staring at this and see what is really going on here. And is there something that we can do to fix the situation that we have landed ourselves in? Incidentally, notice that this recursive tree actually has a leaf corresponding to every possible sequence that the frog could take in going from 1 to n. In that sense, we have really here a visual representation of the entire search space.\nThis is why I said that what we are going to do is going to begin by looking like the Brute-Force solution that we started with and immediately discard it for being too expensive. So, it would be completely understandable if you feel a bit cheated at this point, like I strung you along for the last several minutes, only to bring you back to square one.\nBut I promise you, there is light at the end of this tunnel, and in particular, there are going to be just a couple of lines of code that are going to fix this whole situation for you. So, with a minor but very important change, you can essentially turn this dramatically exponential time algorithm into one that is just linear time.\nAnd the way we are going to do this is by making an observation about how the recursive process here is doing a lot of redundant work. So, I am actually going to stop here, and I encourage you to actually pause the video on the screen and try to look for the redundancy that I was referring to and see if you can figure out this time-saving strategy for yourself before you continue the discussion with me into the next segment.\nSo, I am sorry to be leaving you with a bit of a cliffhanger here. But especially if you are encountering memoization for the first time, I think it would be really worth your while to take a few moments and reflect on what could possibly be the time-saving strategy that we are going to employ when we come back in the next segment. And I will see you there. Thanks!"
  },
  {
    "objectID": "materials/cpnotes/Lec45.html",
    "href": "materials/cpnotes/Lec45.html",
    "title": "Network Flows - Module 1 (Implementing Edmonds-Karp)",
    "section": "",
    "text": "Lecture - 45\nNetwork Flows - Module 1 (Implementing Edmonds-Karp)\n(Refer Slide Time: 00:11)\n\nAlright. Welcome to the last and the final segment of the first module in week 8. And here, we are going to essentially implement the Edmonds-Karp approach to finding a maximum flow in a flow network. So, let us get right to it. You can look up this code, as usual, on the official repository for the website. And if you want something to test it against, you can do that. I mean this, the main function is really designed to take input for this problem, called internet bandwidth.\nThis is UVa 820, and that is something that you can try your code against as well. It is essentially very visibly a max flow problem. So, I am not even going to go through the problem statement for you because it is essentially telling you that there are computers and they are connected through wires. And each of these wires has a certain bandwidth, and what is the maximum browsing speed that you can achieve.\nSo essentially, once you read through it, you, basically, know that you have to set your computers as being the vertices and the connections being the edges, and the bandwidth of the connections are the capacities. And I think the source and the target vertices are given specific IDs. So essentially, it is very, very transparent that it is a max flow problem.\nSo because of this, we will focus our entire attention on basically solving the max flow problem. And will not talk about internet bandwidth specifically anymore. But if you have any difficulties in either parsing the input or passing on the input data into the max flow functions, or even presenting the output, you can always refer to the main function for this code that I will be presenting, which you can find at the usual place. It is the official code repository for this course.\nSo hopefully, that will help. And if anything is unclear despite that, then I always welcome you to post your questions as comments on this video. Or you could also use the Discord community if you are watching this during an active run of the course.\n(Refer Slide Time: 2:13 and 3:49)\n \nSo with that said, let us actually take a look at the implementation. So, to begin with, we have the max flow class, which has the following private entities. So, V is just the number of vertices in the graph, EL & AL, you might recognize the shorthands for edge lists and adjacency lists. The way we implement this here is probably slightly different from what you are already used to. So, you may want to pay attention as we go along.\nThen we have a vector d, which is essentially going to be the distance array for the BFS procedure. Now you also see something called ‘last.’ It is here because I just want to tell you to ignore it. It is something that is useful for Dinic’s implementation. But we would not really be going over that. But you might still see this variable in the code base, and you might wonder what it is about. So, I just left it in here to tell you to not worry about it.\nNow the last thing you see here is a vector of integer pairs called ‘p.’ This is some sort of a parent array, which will help us do the backtracking that we need to do for going along an S-T path, finding the bottleneck capacity and all of that. So, those are essentially the main entities that we will be working with.\nSo, the other thing that you see here is the constructor that is going to be called whenever you create a max flow object, and this essentially just sets the scene and clears the ground for other information to come in. And, in particular, it also makes sure that the adjacency list consists of n vectors of integers, one corresponding to each vertex in the graph.\nSo, all this is fairly standard. Let us look at the first helper function that we have, which is called add_edge. And by default, we are working with a directed graph. So, we are going to assume that when you are adding the edge u comma v, you really mean the edge from u to v. However, we do have a parameter at the end called ‘directed.’ It is a Boolean value, which you can set to false to indicate that you actually want to add an undirected edge.\nNow I did not mention this explicitly but everything we talked about goes through for undirected graphs in a natural way. All you have to do is basically treat the undirected edges as bi-directional edges, going both ways. And you set up their capacities to be equal to the capacity of the original undirected edge that you were working with.\nI am going to leave it as a bit of an exercise for you to figure out how everything plays out if you were working with an undirected graph instead of a directed one. But for the purposes of the discussion that we are going to have, what we are going to be thinking of working with is essentially the default setting of directed graphs.\nSo, essentially what we have here is a directive to add an edge from ‘u’ to ‘v,’ with a capacity of ‘w.’ That is what we want to do. And, okay, so, the first thing that we do here is a sanity check, which says that we do not want to permit self-loop. So, if ‘u’ is ‘v,’ we then do nothing. But otherwise what we want to do is, actually, add this edge to our system. And it is probably a little hard to tell what is going on here by just looking at the code. So, I am going to show you a picture.\n(Refer Slide Time: 5:29)\n\nAnd so here is what is going on. So, on the one hand, we have the edge list. What the edge list is storing is, it is storing the information about the tails of the edges and the capacity and the flow – it is storing these three pieces of information. And the adjacency list for the head of the edge, which is from where the edge is originating – that is essentially going to have a pointer to the entry in the edge list that is recording the tail of the edge.\nSo, you could now go back and tally this picture with the code. You can see that the edge list is getting v comma w comma 0. That basically corresponds to the tail of the edge, the capacity of this edge, whose head we do not know anything about so far. And the flow because we are just starting out is, the trivial flow and it has a value of 0. And now we complete the picture for this edge, by adding the index of this latest entry into the edge list, to the adjacency list of ‘u.’\nSo, that, basically, completes the connection from ‘u’ to ‘v’ essentially. And we do the same for the back edge actually. So, we do this in the other direction as well. But the way we do this is that we are just a little bit careful about what capacity we set for the edge. So, if it is a directed edge, then the back edge is going to have a capacity of 0, as we just discussed.\nBut on the other hand, if this is a bi-directional edge meaning that it is, basically, two sides of an undirected edge, then we want to set the capacity of the back edge to be the same as the capacity of the original one. So, that is why you see this little snippet here, which says that if directed is true, then set the capacity of this edge to 0. This is really an artificially introduced back edge.\nOn the other hand, if it is not directed, it is an undirected graph, then set the capacity of this edge to be w, which is the same as the capacity of the original undirected edge. So that is, essentially, how we add edges into this system. And now the next helper function I want to talk about is the BFS component. So, remember that at every iteration, one of the crucial things that we do is to check if the residual graph has an S-T path. And we do that by initiating a BFS from the source vertex S.\n(Refer Slide Time: 7:55)\n\nSo, I am skipping here the initializations, which are pretty standard. So, you initialize the distance array, the parent array, and make sure that the queue has the source vertex loaded onto it, to begin with. And that the distance of the source vertex is set to 0. So with that in place, really, the heart of the BFS algorithm is this ‘while’ loop here, which keeps going as long as the queue has something to offer.\nAnd the vertex u is now the vertex at the front of the queue which is being currently processed. And a lot of this should look familiar because we have talked about BFS before. So, this is more of both a recap as well as the adaptations that we have to make in our context here. So, the first thing, for example, is that if the vertex that is being processed currently is the vertex ‘t,’ which is the target vertex, then we can actually just break out of this loop.\nBecause we have found what we were looking for. We wanted to know if t was reachable from s, and so this is a done deal. Otherwise what we are going to do is continue in the normal BFS style. So, we explore every vertex on the adjacency list of u. These are original neighbors of u. And we are going to initialize the variables v capacity and flow to being the label of the neighbor or the capacity of the edge from u to v, and the current flow through this edge, respectively, by just looking up the information in the edge list, which actually has this tuple, and contains this information in this order.\nNow what we are going to do is, basically normally in BFS, we would check if v was a visited vertex and if it was not visited then we would process it and if it was already visited then we would continue. So, that is essentially what is happening here, except – so the d of v = -1 is the familiar condition of requiring that v is not a visited vertex. But you also see an additional condition which says that the residual capacity, which is given by the difference between the capacity and the flow is strictly greater than 0.\nSo, if you remember, when we were describing the algorithm, we said that if the residual capacity of some edge becomes 0, then we might as well just delete this edge to remember that this is not a usable edge anymore. And what we are going to do here is, whenever this happens we are not going to actually remove the edges from either the edge list or the adjacency lists because that is just painful to keep track of.\nBut because of this notice that we may therefore have a lot of junk edges in our system, edges that are not really usable because their residual capacities are currently 0. So, in the bargain of this convenience of not having to actually delete edges when their capacities come down to 0, what we have to do is, whenever we are about to use an edge, we have to sanity check first as to whether it is even a usable edge or not.\nSo, that is what the first component of this condition is doing. So, if both of these conditions are met then we have that v is an unvisited vertex. And the edge from ‘u’ to ‘v’ is an edge with non-trivial residual capacity. That means that this is an edge that we can work with. So, we are going to proceed and do the usual BFS things that we do. So, in particular, we set the distance we push v onto the queue. And we also set the parent information for v.\nSo, normally this would have just been the label of the vertex u: ‘u’ is the vertex that is responsible for bringing v onto the queue. But because of the funny way in which we are storing this information, which is spliced across the adjacency list and the edge list, for convenience, we are also going to store in the parent information, the value of the index of the edge from u to v, in the edge list.\nSo, as we will see later this will help us quickly retrieve all the relevant information about this edge that was really responsible for bringing v into the queue. And as you can imagine, this will be particularly useful when we are backtracking our way through an S-T path in due course.\nSo, now that BFS is done, let us talk about the function that will help us actually send an augmenting flow through an S-T path. So, remember the first thing that we do is, use BFS to check if t is reachable from s and if so, then what we want to do is actually look at an S-T path, a shortest S-T path, and find the bottleneck edge on that S-T path and update the values of the flows along all of the edges on this path. That is essentially what we want to do next.\n(Refer Slide Time: 12:33)\n\nAnd that is going to be handled for us with this function called ‘send_one_flow’ from s to t. And it has a third parameter f, which by default is initialized to infinity. This f is essentially what is going to keep track of the bottleneck capacity for us. So to begin with, we do not have any bottlenecks, we do not know what is going on at all.\nBut as we find our way through the path, this f will keep getting updated. And the reason it is being passed as a parameter to this function is because the easiest way to do this is essentially by using this function recursively as we will see. So, this f will essentially help us keep track of what we have found so far, in recursion.\nSo for now, let us actually ignore this base case, which is the opening line of this function. It basically says that if s and t are the same, then we return f and this will make more sense in the end. So, I promise that we will come back to this. So now, let us look at what is happening in the next line. It seems like we are trying to retrieve some information about the parent of t. Why might you want to do this?\nWell, it is reasonably natural because we said we want to do something along the shortest S-T path. We have just finished running BFS in the previous step. So, the parent pointers from t along this BFS tree will essentially help us climb back towards s, via the shortest path. So, that is why we are interested in the parent of t because it is going to help us, you know, start making progress on this S-T path that we are eventually trying to find.\nSo, just to understand how this works, remember how did we store the parent of t or the parent of any vertex when we were doing BFS, we stored it as a pair of integers. The first one was the label of the parent and the other one was a pointer to the, or it was the value of the index of the edge from the parent to the child, in the edge list.\n(Refer Slide Time: 14:33)\n\nSo, in particular, let us say, the parent of t was some vertex z, and let us say that this edge from z to t, had a capacity of 9. Well, what we know is that ‘u’ is going to take the value z.\n(Refer Slide Time: 14:47)\n \n \nAnd the index here is going to basically be the index of this row in the edge list. So, now that we know this we can use this information to retrieve the value of the flow going through this edge from the parent to t, and also the capacity of this edge. So, the next line of code does just that. So, it is going to look up the row or the entry in the edge list corresponding to this index ‘idx.’ And it is going to, that is a tuple involving three numbers or three values. And this ‘get of 1’ and ‘get of 2’ are going to get hold of the second and the third values respectively. And that corresponds to the capacity and the flow essentially by design.\nSo, hopefully, this line here makes sense. And then what we want to do is essentially recurse. So, what we want to say is, now let us try to push a flow from the source to the parent of t, right. And what we are going to do is, also make sure that this recursive call is aware of the bottleneck constraint that we have so far.\nSo, so far, we know that the bottleneck was supposed to be, you know, f, given by f that is the parameter that was passed to the current call. And we also know that the current edge that we are considering, that is the one from the parent of t to t, has a certain capacity and a certain flow and therefore it has a residual capacity of the difference between these two numbers.\nSo, in case that is a tighter value, if that is smaller than f then that is the new bottleneck. Otherwise, we just stick to f as being the best upper bound that we have on the bottleneck. So, that explains, why we are taking the min of these two values and passing that on as the fresh bottleneck information to this recursive call.\n(Refer Slide Time: 16:39)\n \nSo, just to see what is going on a bit visually. So, let us say that this is the S-T path along the BFS edges. Our first focus is on t, and we found the parent of t and we said that parent is z. And now we are performing recursion on s to z essentially. So, we are saying: Okay. Find, you know, the best flow that you can send from s to z, keeping in mind that so far, the bottleneck that we have discovered is 9. Right.\nSo essentially, this function call was initialized with an, you know, initial bottleneck of infinity, which is just to say that we do not know anything about the bottleneck. So, the difference between the capacity and the flow of the edge from z to t is 9 because the capacity is 9 and there is no flow through this edge currently.\n(Refer Slide Time: 17:33)\n \nSo, that is what is going to be passed on as the current best knowledge that we have about the bottleneck. So, it is a good exercise to check how the value of this parameter evolves, as you go further and further into the recursion basically. So, to begin with, as I said, the value of f was infinity. It got overridden by 9 and as you go further along, whenever you encounter an edge whose residual capacity is more than the value that was passed on or is equal, then the value of the parameter does not change.\nBut every time you encounter an edge whose residual capacity is smaller than the value that came in, then this parameter value is going to get overridden. At some point, you keep going back and you get to a point where the parent pointer points to S and that is the point when we know that S = T and the value of f that came in, at this stage is, in fact, the value of the residual capacity of the edge that had the smallest such value in this path. So, at this point, we have really found out the value of the bottleneck capacity.\n(Refer Slide Time: 18:37)\n\nAnd so now if you go back to the code hopefully that first line makes sense. So, when s = t that just means that you have come all the way to the start and you have finished exploring this path, and the value of f at this point is the bottleneck capacity. So, that is what we are going to return. So, you can imagine that the value of this variable ‘pushed’ here is going to be the value of the bottleneck capacity. And now that we have this value all that remains to be done is really to adjust the flows.\n(Refer Slide Time: 19:08)\n\nSo, in particular, the flow of the current edge that we are working with needs to be incremented by ‘pushed.’ So, as you can guess that is going to affect the value of this number here.\n(Refer Slide Time: 19:19)\n\nAnd in this example, this will have to be incremented by three units because that I believe was the bottleneck capacity of the path that we saw earlier. You could go back and confirm that that is indeed the case. But now apart from this remember what we need to do is also make sure that the edge that is going in the opposite direction has its flow decremented by the same amount. Remember we discussed that this is how everything stays nice and synced up exactly, as prescribed by the algorithm. So that is what we want to try and do next.\n(Refer Slide Time: 19:47)\n\nSo, notice here that we have introduced a variable called ‘rflow’, which is presumably the flow that is going through the reversed edge. And the way we do that is by looking up the edge list at the index that is given by ’XOR’ing the current index with 1.\n(Refer Slide Time: 20:10)\n\nSo, what is going on here? Well, notice that our edge list always comes in pairs. That is how we added the edges. Right. So, whenever we had to add an edge from u to v, we also added the edge from v to u. And the capacity of the edge from v to u was either set to being the capacity of the edge from u to v if the graph was undirected. Or it was set to 0 if the graph was directed in which case this would actually be modeling the back edge in the residual graph.\n(Refer Slide Time: 20:41)\n \n \nIn any case, the point is that when you want to be updating the value of the partner reverse edge then essentially you are looking for an adjacent entry in the edge list in one of the two directions, depending on which edge you started with. So, let us say that indexing starts from 0 and you are currently working with the edge whose index is 3, then the edge that you are looking for has an index of 2. On the other hand, if you start with an edge, whose index is 2 then you are looking for the edge whose index is 3.\n(Refer Slide Time: 21:06)\n\nSo, that is exactly what doing an XOR with one gives you. It gives you, essentially, the other partner edge by flipping the last bit. Okay. So, that is how you get to the partner edge succinctly. And all you have to do now is make sure that the flow through that partner edge is decremented by ‘pushed,’ essentially by the same value as the forward edge flow was incremented.\nAnd at this point, you can return ‘pushed’ and you would be done. So that is what is going on with the send_one_flow function. And so this enables us to actually push flow through the paths that we found from the BFS procedure that we did earlier.\n(Refer Slide Time: 21:51)\n\nSo, now it is time to piece everything together and actually look at the Edmonds-Karp algorithm now that we have all the specific pieces in place. So, as we said, to begin with, the maximum flow is initialized to 0. We have not really done anything yet. And now what the algorithm is basically saying is the following.\nFor as long as you can find a path from s to t in the residual graph, find the shortest such path and route as much flow as you can through that path and keep going for as long as possible. Right. So, the part about finding the shortest S-T path is handled by the BFS function. And it is written in such a way that if you cannot reach t from s then, this function returns a false value and that is when the lifetime of this while loop comes to an end.\nBut otherwise, it is going to keep going and what you do within the loop is, basically, execute the send_one_flow function, the recursive one that we just discussed. And what that is going to do is find the bottleneck capacity on this path from s to t. And it is going to route that much additional flow through this path, making adjustments as necessary for the edges that go in the opposite direction as well.\nAnd in this code, you can see that there is a redundant check. Notice that you do not really need to check if f is 0 because the only time that will happen is if you had an edge on the S-T path that actually had a residual capacity of 0. But remember that every edge that we have on this S-T path, is an edge that we discovered by following a parent pointer from the BFS traversal that we just did.\nAnd in the BFS traversal, we only explored those edges which had a non-trivial residual capacity. So, all of the edges on our S-T path are going to have a non-trivial residual capacity. So, this check here is really an extra and redundant check and the algorithm is going to work as advertised even without it.\nRemember to increment your max flow value by f because f is the amount of flow that you manage to push through the S-T path that you just discovered, and that is the amount by which the value of your flow has increased in this iteration. So, that is what is happening in the third line inside the while loop.\nOnce you break out of the while loop, there is nothing left to be done. You cannot implement the flow anymore and you can return max f as the final answer. Once again that this actually works correctly every time does require an argument, which we have skipped but, as always, you can look this up. There are some very interesting resources that have been linked to in the description of the video. So, please feel free to explore, if you are curious about why this actually works all the time, all right.\nSo, that is pretty much it that brings us to the end of the implementation of the Edmonds-Karp max flow algorithm. And now what we are going to do is, put this to good use by discussing a couple of problems. So, there will be one implementation-based problem that we will discuss and there will be one, which is just a problem I wanted to share with you in principle because it is so much fun. But I have not really seen a contest problem around it. So that is going to be just more of a theoretical discussion. But when we come back next week, we will again be able to expand on this algorithm and use it in some other ways as well, and there will be some more implementation to be talked about in week 9. But for now, let us immediately leverage this algorithm to solve a matching-based problem on Codeforces. That is up next in the second module. See you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec8.html",
    "href": "materials/cpnotes/Lec8.html",
    "title": "Searching and Sorting - Module 4 (Simple Skewness)",
    "section": "",
    "text": "Lecture - 8\nSearching and Sorting - Module 4 (Simple Skewness)\n(Refer Slide Time: 00:11)\n\nHello and welcome to the final module of our second week on ‘Searching and Sorting’ algorithms. This time we will talk about a problem called ‘Simple Skewness,’ which appeared in the Venture Cup 2016 elimination round. You can find this problem on ‘Codeforces.’ This problem has a flavor of a little bit of both searching and sorting, which is why I thought it would be a nice problem to end this week on. It is a simple statement in the sense that it is a short statement with no stories. Let us get to it.\n(Refer Slide Time: 00:49)\n\nWe are given this notion of skewness, to begin with. So, defining the skewness of a collection of numbers as the difference between its mean and median. Notice that this is not the absolute difference, it is the literal difference between the mean and the median. The skewness of a set of numbers could either be positive or negative.\nAlthough I will keep using the term ‘collection’ and ‘set’ interchangeably, this is not a set in the strict sense of the word, which is to say that this collection of numbers can have repetitions. You are also required to find a subcollection, which potentially has repetitions. There is no deduplication involved here. I think the usual term for this is multi-set. But I am not going to really keep that distinction in mind. I might often talk about a set of numbers. Keep in mind that this is a set potentially with duplicates all along.\n(Refer Slide Time: 01:47)\n \nJust to make sure that we are on the same page about the basic definitions, let us go over an example. Here we have a collection of numbers, which look pretty neat. By looking at it, you can perhaps already figure out that the mean = 50 and the median = 50. The median is usually defined as the middle element if you look at the sorted order, but the middle is not very well defined if the list has an even size.\nIf you are dealing with an even-sized collection of numbers, then the median is defined to be the average of the middle two elements. Hopefully, these definitions are clear. Now for this particular list, notice that the skewness is 0. It is not a skewed list at all; the mean and the median coincide. But let us see if we can introduce some skewness by playing around with the numbers a little bit.\n(Refer Slide Time: 02:45)\n \nLet us say we take the smallest number and make it even smaller. Then you can see that the impact it has on the mean is that the mean goes down but the median remains the same. In this case, the skewness decreases. On the other hand, if we were to take the largest number and make it even larger, you can see that this increases the mean without touching the median. In this case, the skewness increases.\nHopefully, you have a sense of what skewness means from this example. Feel free to pause here and work out your own examples with small lists of numbers just to, make sure that you are comfortable with the definition at this point. So, what is the task here? We have this definition, what are we supposed to do?\n(Refer Slide Time: 03:30)\n \nGiven this collection of numbers as input, which once again, I will emphasize do not consist of necessarily distinct integers (you could have duplicates), our task is to find a non-empty subset of these integers potentially with repetitions again, which has the largest possible simple skewness. Observe that unlike some of the previous problems that we have talked about, this question always has a valid answer. You do not have a scenario where you might say that there is no subset that maximizes the simple skewness.\n(Refer Slide Time: 04:13)\n \nTo see this, notice that at least in principle, you could just make a list of all the subsets that the given set has. Next to each set, you can just calculate its skewness. Then you can pick up the one that has the largest value of skewness. This already is a brute force algorithm to answer the question of what is the subset that has the largest simple skewness.\n(Refer Slide Time: 04:41)\n\nNotice that this is terribly inadequate because if you look at the input limits, the numbers here are fairly large. Even an n2 solution will not pass given that ‘n’ is 2 lakhs. We really have to think about this substantially more and try and get an improved approach, which is somewhat in the ballpark of ‘n log n,’ that is likely to work out. But before we get there, it is useful to think of an n2 approach even as a warm-up. That is what we are going to do. Then we will see if we can replace one of the things that we are doing with some sort of a binary search, which will get us to the n log n algorithm that we eventually want. This is, I think, a useful way of generally attempting such problems.\nWhen it is too much to tackle all at once to get to the best possible solution, come up with one that is probably not the one that you are looking for. See if you can use that as a stepping stone and improve it to the thing that finally works. In this spirit, let us just try to come up with some decent approach that improves on this very naive brute force solution that we discussed so far.\n(Refer Slide Time: 05:57)\n \nLet us begin by fixing some solution(s). We know for sure that there is at least one solution, maybe there are multiple optimal solutions. But the important thing is that there is at least one. Let us fix an abstract solution in our imagination. We do not know what the solution exactly looks like. This is what our algorithm is looking for. But continuing to just play around with our imagination, let us also reorganize the elements of the solution so that they end up being all sorted. Let us fix our attention on the ‘median element.’\n(Refer Slide Time: 06:29)\n\nAgain, we do not know what this median element is. Since we do not know the solution, we also do not know its median. But notice that it is something that we can guess. What I mean by this is that we do know that this median element must be one of the numbers that is there in the input array. So, let us just try all of them.\nWhat we are going to do is run one ‘for’ loop, which just goes over all the elements of the array and it asks the following question for any fixed element: If the optimal solution had this particular element as its median, then what would the solution look like? It turns out that this is a much easier question to answer. The median gives you a really good anchor point to build out the solution. But before we discuss how that exactly works out, let us do a little bit of housekeeping first, just to make our lives simpler further down the road.\n(Refer Slide Time: 07:30)\n \n \nI am going to assume that there is always an optimal solution that has an odd number of elements. This just makes it easier to talk about everything that we are going to talk about. Why is this true? Let me just trying to give you some intuition for why we can assume this without loss of generality. Suppose somebody gives you an optimal solution that has an even number of elements. Notice that in this solution the skewness must be non-negative.\nWhy is that? Well, it is an optimal solution. It must have a skewness that is, at least, the skewness of any other set. But on the other hand, also notice that you have the singleton sets available to you. So, a singleton set has 0 skewness because the mean and the median are both equal to just the only element that is there in the set.\nBecause of this you already have a baseline. You know that there are sets with 0 skewness. The optimal solution will never have negative skewness. Because if nothing else, it could just use a singleton set. So, we know that the optimal solution is non-negative. Therefore, the skewness of this set that your friend has given you, let us say, which has an even number of elements, we know that the skewness of this set must be non-negative. In particular, this means that the mean is at least the median in this set. Now with this assumption, what you can show is the following.\nLet us look at the middle two elements and eliminate the larger of these two. The set that you are left with, we claim that this set has a skewness, which is at least as much as the skewness that you had before. In other words, what this means is that the change that you experienced in the mean is, so let us say if you are looking at ‘the old mean - the new mean,’ at most the old median - the new median. That is essentially what it means to say that this skewness did not decrease.\nYou can show this by just writing down a bunch of relevant inequalities. Remember to start with the assumption that in the original array the mean was at least the median. Then use the fact that you have dropped the larger of the two middle elements to finally conclude that in this new array, the skewness has not gone down. It has either remained the same or it has only increased. Without the assumption that the array has non-negative skewness, this fact may not be true.\nYou can come up with examples to see that even after you drop the larger of the middle two elements, the skewness can in fact decrease. This little assumption that we are making is important to this claim. I will not be going through the calculations here but it is a good exercise to work through it. Please feel free to take a pause and do that now, or remember to come back to it later, depending on whatever you prefer to do. With this out of the way let us go back to the question: Why is the median a good anchor point?\n(Refer Slide Time: 10:43)\n\nLet me just give you an outline of what we plan to do. The first thing we are going to do is sort the input array. Because we can. This is going to take ‘n log n’ time. I was only half-joking when I said just because we can. There is a very good reason for sorting the array. It will help us systematize the way in which we build out a solution from a median. That is the next thing that we are going to do.\nFirst, we will guess the choice of the median. Just go over this entire array, trying each element out in turn as the choice for the median of a hypothetical optimal solution. Having fixed the choice of the median, let us also fix the size of the output array. We are going to guess how many elements there are in the optimal solution.\nThis guess is again going to cost us another linear expense. I mean the size of the optimal solution can be anything between one and ‘n.’ We are going to disregard the even numbers in this range. So, it is going to be, roughly, ‘n’ by two numbers that we are going to explore. But still, this is something that is going to show up as a nested ‘for’ loop.\nYou can probably already see why this algorithm is going to be order n2 in the worst case. We still will have more work to do even after we have fleshed out this particular algorithm. If you want to think ahead a bit, it is this step that we will replace with some sort of a binary search subroutine. But let us not get ahead of ourselves.\nLet us try to completely understand what is going on here. At this point, we have guessed the median. We have also guessed what is the number of elements in the optimal solution. We also know that the optimal solution contains this one element. We need to figure out the remaining 2k elements that go in there. We will have to, again, just look at the array to figure out what is the best choice for these remaining 2k elements. This is the part that we need to figure out a little more explicitly.\n(Refer Slide Time: 12:58)\n \nLet me switch to showing you, again, an abstract example here. Let us say this is our sorted input array. There is this one highlighted element. Let us say that is our guess for the median. Now I really want you to pause here and think about what is the best choice of an extra 2k elements on top of this one for the optimal solution. Let us say I told you that the optimal solution contains this particular highlighted element.\nWhat can you say about the remaining elements in the optimal solution? Of course, given that you also know that the optimal solution has 2k+1 elements altogether. That is also given to you. That is where we are when we are inside any particular snapshot of this nested ‘for’ loop. You have fixed the choice of the median. You have fixed how many elements you want to pick up.\nThe only thing remaining to do is to figure out which elements to pick up to have your best shot at maximizing the skewness. Think about this for a moment and come back when you are ready. Notice that since the median is fixed, maximizing the skewness essentially amounts to maximizing the mean. Because you know that you have to pick 2k elements. You also know that you have to maintain the fact that the highlighted element is the median.\nThat is the structure that we have sort of guessed for ourselves at this point. We know in particular that k of the elements that we choose must come from before the median element and the remaining k elements must come after the median element. Also, at this point maximizing the mean really amounts to maximizing the sum of the elements that you choose.\nYou want to pick as far as possible the largest elements that are available to you. So, it makes a lot of sense to pick the last k elements and also the k elements that show up just behind the median. It is not the first k elements because that would be suboptimal. Those would be the smallest k elements. You can do much better by just pushing your luck as much as possible.\nYou are constrained to be behind the median. You can just pick the largest 2k elements, for example, because then the highlighted element would no longer be the median. That is not going to work. In most cases, there will be choices of a highlighted element for which you do end up picking the last 2k elements.\nBut in general, what do you have to do is exactly what we just described. You choose the last k elements, and then you choose the k elements that show up just before the median. That is the greedy strategy for augmenting the solution starting from the median.\n(Refer Slide Time: 15:54)\n\nHopefully, you can see why the median was a useful anchor for the initial guess. Let us come to the bit that we were hinting at earlier. We see that this is kind of the bottleneck step in the running time of our algorithm, which is taking a hit because of this. We will now want to think about how we can substitute this guess of the solution size with some sort of a binary search. In particular, we want to not try all possible choices of k. But we want to do some sort of binary search for the right value of k.\nUnlike in the previous problem, where one of the big challenges was to even find the range of the search space, we do not have that issue here. We know that ‘k’ ranges between, say, 0 and n/2. We can go and poke this range right in the middle. No problem! But now what is not clear is what question should we ask.\nHow do we figure out how to cut out the search space to the left or to the right or in some other way? To try and understand what the behavior of ‘k’ is like with respect to skewness, let us just try to go through the slow algorithm, again in an abstract setting, just to get a feel for what is going on with the skewness as we add more and more elements to the array. See if we can pick up some hints from this behavior.\n(Refer Slide Time: 17:24)\n \n \nHere is our abstract array. At this point, we have ventured out from the median. We have added just one element. Let us say that this choice of an array of three elements is better than the previous choice, which was just the singleton element with the guessed median element alone. That one had 0 skewness.\nLet us say that by adding these two elements, we have either 0 skewness again or hopefully, we have even an improved skewness from before. We continue and try to add one more element. Let us say the skewness continues to improve. We add one more element and let us say the skewness continues to improve. One thing that is worth noting about these elements is that the elements that we are adding themselves are getting smaller as we go along.\nThis is because of the fact that we are working with a sorted array. The first element that we added was the largest possible pair of elements that we could have added. Then in the second step, we add elements that are at most the ones that we added in the previous steps, and so on and so forth. That is something that is useful to keep in mind.\nWhat we want to understand is: How does the skewness evolve as we add more and more elements? Notice that this is the same as asking, how does the mean evolve as we add more and more elements? Because the median is fixed the way in which we are building this array out. The median always stays the same. It is enough to just focus on the behavior of the mean.\nHow does the mean change as we add more and more elements? Let us consider a particular snapshot and say that the current array that you have built out has a sum of S. Let us say it has ‘d’ elements where d is going to be ‘2k+1’ for some choice of k. So, the current mean is S/d. Let us say we add the elements ‘a’ and ‘b.’ So, the new mean is going to be (S+a+b)/(d+2) because our array has also grown by two elements.\nWhat we want to understand here is the relationship between the current mean and the new mean. When does it happen that the new mean is less than the current mean? When does it happen that it is the same or it increases and things like that? Notice that if you could show something like the mean always increases or stays the same, then that is wonderful. Because then you do not have to search for, any ‘k’ at all. You can just pick everything and, you would be in business. You can pick as much as you can so that you have an equal number of elements on both sides.\nBut if it was true that the mean always, you know, increases or stays the same. Then there would be no reason to stop except for when, you know, you have run out of elements on one of the sides of the array. So, you could just keep picking. And in particular, you would not need to run an internal ‘for’ loop at all. You would just fixate, you know, on what is the largest k that you can accommodate. And that would have been your answer.\nBut that seems too good to be true. That is indeed the case, which you can verify by just working through a few small examples. The mean does not have a consistently non-decreasing or non-increasing behavior. Once again, this is something that can be verified by just playing around with small examples. On the other hand, what is it that we can hope to show? Whenever you have a binary search, in a broad context, usually some sort of bitonic behavior is very useful to have.\nIf the value kind of keeps increasing for some time and potentially hits a peak and then decreases or remains non-increasing, then that is a useful kind of behavior. Because then we can still find our way around using a binary search spirited technique, which is to say that we keep probing the range and we try and figure out the slope of the change. If it is headed downwards, then we move to the left. If it is headed upwards, then we move to the right.\nWhat we are looking for is of course the peak. We want the place where the mean is as large as it can possibly be. This is something that one would typically anticipate once you are practiced in binary search, and you try to show something like this. Do not be surprised by the fact that we are expecting this behavior. It is just something that shows up quite often. Now that you know it as well, you will know to try and look for this as you encounter new problems as well. Let us try to see if we do experience bitonic behavior here by taking a closer look at what is going on.\n(Refer Slide Time: 22:10)\n \nLet us try to figure this out by comparing the value of the current mean with the average of the two numbers that we are trying to add. The reason we are looking at these two quantities specifically is because we want to anticipate applying the mediant inequality. This is something that you may have seen in school. It is an inequality that relates two fractions in terms of the sum of their numerators and denominators.\nApplying this inequality, this is what we get. But notice that the expression that you have in the middle is precisely the new median. The median that you obtained by adding these two elements to your set. We see that if the average of the two values that you are bringing in exceeds the current mean, then the new mean will also be larger than the previous mean.\nOtherwise, you have the opposite behavior by just applying this inequality in the other direction. If the mean of the currently added elements ‘a’ and ‘b,’ does not exceed the mean of the old set, then the mean of the new set will not be bigger than the mean of the old set. What we want to say is that, okay, we know this. We also want to claim that the mean will increase up to a point potentially, but once it has reached a stage where it is peaked or it is going down, then it will never strictly increase once again.\nThat is the kind of bitonic behavior that we were referring to. The intuition for this is simply that the elements that we are adding just keep getting smaller and smaller. If not strictly smaller, remember, we have arrays with repetitions, at least the elements we are adding are no larger than we had before. This, again, is strangely similar to the overall spirit of the argument that we were trying to make with the ship if you remember from the previous problem.\nThere we were saying that if in the first step, you have kind of lost sight of the safe zone, then you are never coming back. Here also if there is some stage at which the mean fails to increase for the first time, then from there it is all literally downhill. It is never going to come back up.\n(Refer Slide Time: 24:26)\n \nLet us recap what we just said with a visual. We are, again, looking at how the mean evolves as we add more and more elements. Our starting point is just the singleton set with the guest median element alone. Let us say that when we add the first pair of elements, the mean increases a little bit. When we add the next pair of elements, it increases again. Again, it is a good exercise to think about the magnitudes of these increases.\nIs it possible that when you add the second pair of elements the mean increases more sharply compared to when you just added the first pair? Keep in mind that these pairs of elements that you are adding right now are diminishing or the same when compared to the pairs of elements that were added just in the previous step. This is a good exercise to go through. But let us continue our journey here in the meantime. Let us say we add another pair of elements, and the mean goes up again.\nBut at some point, perhaps, you will encounter a first incident where you added a pair of elements and the mean either stayed the same, or it did not increase, which is to say that it strictly went down. The claim that we wanted to make was that once this happens, then there is no hope for the mean to increase ever again. That is why this first point where the behavior flips, that is the global maxima for the mean.\nThat is the thing that you are looking for. That is exactly the bitonic behavior that we were talking about. Let us see why we expect this to be true. Let us say that we kept adding elements for some time and we experience a non-increase of the mean for the first time when we add the elements ‘a’ and ‘b.’ This was the last step that was depicted in the visual in the previous slide. Let us think of this as some sort of a critical event.\nThis is the first time that the mean did not increase. Let us say that in this step, right after this, we are adding the elements ‘p’ and ‘q.’ Again, by the structure of the array, we do know that p+q is at most a+b. I am just going to conveniently write that in terms of averages because that is what will be useful. What we know because of the fact that a, b we are witnessing the critical event is the fact that the average of ‘a’ and ‘b’ is at most the previous mean. So, let us say S was the mean at the step when ‘a’ and ‘b’ were about to be added. We know that the average of a, b is at most the mean in their stage. That is why when you added them, the mean decreased. From here, let us apply the mediant inequality to see that the average of ‘a’ and ‘b’ is also the average of the mean of the array that was obtained after adding in the elements a, b. Remember, S is the sum of the array that a, b were about to get into. It was the previous array in some sense.\nAfter adding a, b we have a new array whose sum is, ‘S+a+b.’ Because of the mediant inequality, we know that the average of a, b is also at most the new mean that you obtained. It is not only at most the previous mean, it is also at most the new mean. Now the important thing is that we can now combine these two inequalities, the fact that p+q is at most a+b, and the fact that the mean of a, b is at most the mean of the current array, to see that p+q is at most the mean of the current array.\nNow this array, whose sum is S+a+b is the array that p+q are trying to enter. The average of p and q is at most the mean of this array. That is what we have from this chain of inequalities. You can repeat this idea for the next step and the step after that. If you want to be formal about it, you could use the language of induction to make this precise.\nThe base case is pretty much what we just discussed. You can formalize what goes on from the ith step to the i+1th step to argue that once you are on a downward journey, it just keeps spiral wing downward, or at least it stays put. But there is no hope of the mean increasing ever again.\n(Refer Slide Time: 28:57)\n \n\nOverall, your evolution of the mean looks something like this. There is a place where it attains a maximum. It is possibly going to peak for some time. But the point is that once it has reached that maximum, it never increases after that. Let us try and see how the binary search would work. Let us say that we probe this range of values for ‘k’ somewhere in the middle. We say that we want to add ‘n’ by 4 elements to the array.\nRemember, ‘k’ ranges from 0 to n/2. Let us begin by trying to add ‘n’ by 4 elements to our median element. Once we have made this initial choice of guess for ‘k,’ what we want to do is try and identify which side of this slope are we on? Are we on the uphill trajectory? Or are we on the downhill trajectory? Well, this is easy to identify by just comparing the current choice of k with the next choice of k.\nWhat we will do is we will say, okay, instead of trying to pick k elements, suppose we were to try and pick the ‘k+1’ element. Let us try to pick one more. Of course, that has to be feasible first of all. If you are on an edge case, you have to just stop because you cannot go any further. But assuming you are not on an edge case, you just compare what is going on. You want to know if the mean improves, by enhancing the size of your set by one.\nIf the mean does improve, then that is a sign that you are on this uphill slope. If the mean does not improve, then it is a sign that you are on the other side. That will allow you to figure out which side of the search you should pursue further. That is kind of the overall description of our algorithm. Basically, you want to begin by sorting the array and guessing the choice of the median, and from here, you want to do a binary search for the size of the array that you want to build.\nOnce the binary search has informed you about the size of the optimal set, given that a specific element is a median, you want to keep track of the best answer that you obtained for this choice of the median. In the end, you just return the best answer that you found overall.\nThe running time of this algorithm will be order ‘n log n’ because you have the sorting step at the beginning that is order ‘n log n.’ Then you have the outer loop, which is going to run at most ‘n’ times for the guess of the median. Then what do you do inside is essentially this binary search.\nThe overall expense of these nested loops is going to be ‘n log n.’ Hopefully, this overall approach sort of made sense. This is a new style of binary searching in the sense that you are not probing and immediately getting a yes-no answer. You are trying to detect some sort of slope behavior for a particular value that evolves in a bitonic fashion.\nHopefully, this sort of overall form of a situation in which you can apply binary search is useful for you to keep in mind. I do know that this is widely applicable. I hope that you are able to leverage this as well. Now that the main ideas of the algorithm are somewhat in place, let us turn to the implementation.\nAs always, this is a good time to pause, if you want to try this yourself. One thing to watch out for in this particular implementation is that there are lots of little edge cases to worry about. Be very careful with your indices because there will be a lot of those floating around. In particular, one edge case that is important to be careful about is the range of the values of k.\nRemember that you are working with some guess have a median that is going to be someplace in the array. Just make sure that your range of values for ‘k’ is a valid range, in the sense that it should never be more than the number of remaining elements that are available on either side of the median. That is the sort of thing that you have to just be a little bit watchful about.\nThe other little tip for efficiency is to compute an array of prefix sums for the input array. This will help you do your mean calculations quickly. Remember that whenever you are probing in the binary search, you are asking questions like does the mean increase after we include these two elements, or does it not increase?\nFor this, you do need to compute the mean several times. This just becomes faster if you have access to an array of prefix sums because it is just a matter of getting to the sum of the relevant sub-array. Remember that you are always looking at contiguous chunks in the sorted array. That is a really helpful thing to have for fast computation of means.\nI have not tried if not using a prefix array will cause a timeout or not, but it definitely does not hurt and it is just good practice to have. With all that said, I think this is your last chance to pause the video. My final spoiler alert! We will be coding in C++ for this one, and I may be skipping some variable initializations in this presentation here. You can find the full code on the official GitHub repository.\nIf you do have Python or Java variants that you would like to contribute, then please do create a pull request on that repository with the appropriate documentation. Remember to attribute yourself. Now let us actually get started here.\n(Refer Slide Time: 35:09)\n\nThe first thing is reading the input in. I have used long data types here. I cannot be sure that that is absolutely necessary. But I think I just wanted to be on the safe side. The only important thing that is happening on the code that you can see is the fact that we are sorting the array. Do not forget to do this in the beginning. It is crucial to the logic of the rest of the program that we are working with a sorted array, to begin with. Other than that, all the input business is fairly standard. There is nothing special going on here.\n(Refer Slide Time: 35:45)\n\nThis is the place where we just compute the partial sums vector. This is just maintaining cumulative sums as we go along. The way we calculate the partial sums for the first ‘i’ elements is that we just refer to the partial sums that we have already calculated for the first time ‘i-1’ elements, and then we add the value of the current element to it.\nThat is all that is happening here. These cumulative sums, as we were saying earlier, will come in handy when we want to do mean calculations while we are in the middle of the binary search. We will have a separate helper function called ‘find mean’ or something like that. I will come to that at the very end because I just want to focus on the main logic of the code first. Let us get to that.\n(Refer Slide Time: 36:36)\n\nThis is the outer ‘for’ loop where we guess the value of the median. Now one important thing to keep in mind is that ‘guess’ is simply guessing the index of the median element. The variable guess does not store the median element itself.\nYou will need to, at some point, actually refer to the median element that you are guessing when you come to the stage where you have to print the output. It is definitely important to remember that you need to print ‘b’ of guess if you want to print the median element, for instance, and not guess. That will be messed up.\nIn general, I think this is just one category of small and annoying bugs where you mix up the index and the element at that index. This is just a heads up to be careful about that. Now, let us first calculate the range in which we want to do our binary search for this particular choice of guess.\nAs we were saying earlier, you have to be careful about ensuring that you have enough of a supply of elements on the left and right for a particular ‘k’.\nFor instance, if you have an array of length 100. Let us say there are 100 elements, and your median is the fifth element in the array. Then notice that you cannot add more than four elements, rather eight total, but you can only add four from the left. You can, of course, add four from the right when there are lots of elements available.\nBut then there are just going to be four steps in the range for ‘k’ that you are going to try out. Just make sure that you get your indices sorted out here. Because we are doing 0 based indexing, if the current median is at the guess index, there are ‘guess many’ elements available before it. For instance, I was just saying that suppose your median is the fifth element, then well, that is indexed by 4 because of 0 based indexing.\nTherefore, we know that we have four elements behind the median. You can similarly calculate the number of elements that are there after the median.\nAgain, for things like this, just to avoid like silly bugs, at some point, with practice, these kinds of calculations will become quite natural, but it is just helpful to do a really small and silly example on pen and paper just to make sure that you sanity check your indices, and you have them right.\nI think this is tried and tested code. I am just going to believe that there are no mistakes here. Hopefully, this is the right range for ‘k.’ We are obviously going to take the min of the two options because it is the smaller sub-array, the smaller side, that is going to be the bottleneck. That is our range.\nHere are some simple initializations for the binary search business. The lower limit for the range is 0, as we have discussed before, and the upper limit is what we have just calculated. That is L and R for you. The midpoint is ‘L+R/2.’ Now we have set the stage for the actual binary search.\n(Refer Slide Time: 39:50)\n\nThis is the heart of the entire algorithm more or less. I mean, there are, of course, a few more details after this as well. But this is really the main thing. As long as we still have some range left where we are not sure, so that is given to you by this ‘while’ condition, R-L is greater than 0, so our left and right endpoints have not conclusively coincided at someplace, we need to continue searching. That is the standard ‘while’ condition for binary searching. Hopefully, that is clear and not confusing.\nNow, what is the current guess of ‘k’ that we are working with? So, remember, by k, I mean, my guess for how many more elements should I have on top of the median in my optimal array. The current guess for k is mid. We are just starting, so, we have come in after the initialization. The current value of mid = ‘L+R/2,’ but in general, also, as we go on, it is going to be a loop invariant that mid is our current point of probing. We are asking ourselves: Is mid a good value of ‘k’ to work with?\nWhere does mid lie on that sort of bitonic picture? Are we on the strictly increasing slope part of it? Or have we come to the part where it is going downhill or it is experiencing a plateau? We know that if things are going downhill, or if it is a plateau, then we need to shift our choice of mid towards the left because we have, in some sense, come too far.\nOn the other hand, if we are at the place where things are looking up, we are in the increasing slope part of the picture, then we need to increase our value of mid, and we need to discard the left half of the search space. How do we check which side we are on? What we said was that we will try to compare the current mean with the mean that we would get by trying to add two more elements to the array.\nThat is what we are going to do here. We are going to tentatively increase ‘k’ to ‘k+1,’ or we are going to probe mid+1 as a possible choice for ‘k.’ We are going to ask ourselves: How did the mean change? Did it increase? Or did it not increase? Now when I am saying increase, I mean a strict increase.\nThis is something just to be careful about, like when you write down your condition for how the search space is going to get pruned. Remember to just make sure that you know when to use a strict inequality and when to use less than or equal to or greater than or equal to, and so on. Let us just do this probe. We are saying our tentative value of k is ‘mid+1.’\nLet us see what are the next elements that we want to pick. Notice that these will be available to us because we are working with an appropriate range of ‘k.’ These will be valid elements to talk about.\nNotice that ‘a’ is the value coming in from the top. It is basically the kth largest element in the array, and ‘b’ is the value that is coming from the left half of the array. So, we are going ‘k’ steps behind the current guess, to incorporate these new elements. This is ‘a’ and ‘b,’ the new elements that are trying to join the array.\nNow, let us recall the criteria that we had evolved to figure out whether we are on the uphill side of the graph that depicted how the mean is changing, or whether we are on the downhill or the plateau side of things. What we had said is that if the mean of the incoming elements dominates the current mean, meaning that it is strictly more than the current mean, then the mean will increase, otherwise, it does not increase.\nThat is exactly the binary search criteria that we have put in here. We have taken the current mean, which by the way, we have computed by function call to this helper function. As I said, we will come back to that later because I do not want to be distracted with those logistics right now. Just assume that we can compute the current mean efficiently.\nWhat we want to do is compare the value of a+b/2 with the current mean. So, if a+b/2 is at most the current mean, then your mean is not going to increase. It is still possible that the value of ‘k,’ which was the current mid, that is the best possible value of ‘k.’ Because this could very well be the inflection point. Maybe a, b is the first time that the mean does not increase.\nThe current value of ‘mid’ may well be the answer that you are looking for. Or it is something smaller. Maybe you are still in the middle of the boring zone of the graph, and you need to roll back further. You do this by essentially bringing R up to mid because it is either mid or less (the answer that you are looking for). I think we are saying that R is ‘max of mid, L.’ Normally you know that ‘max of mid, L’ should always be mid. I mean mid would always be ahead of L.\nI think I have done that just to maintain symmetry with what I have written in the ‘else’ condition. Let me just come to that in a minute. But you could pretty much say R = mid and that should be fine out here. What is going on in the ‘else’ block? Here we are saying that look, the current mean actually increased after we added the elements ‘a’ and ‘b.’\nThis is looking good. We are going uphill, we are strictly getting better. We know that all values of k up to an including mid are useless for us.\nWe know that ‘k’ is going to be at least mid+1 or more because we have already sensed a straight improvement. We are going to be greedy.\nWe are going to reduce our range to ‘mid+1, R’ to say that continue your search on that side of the space. In this case, doing this min of mid+1, R is just necessary to take care of some edge cases, I think, because of the way mid works. I think it is by truncation when L+R is odd, so it is possible that when you add 1, then you actually go overboard, you go beyond R. So this is just a bit of a sanity check condition that is been thrown in here.\nI think I am pretty sure that I had arrived at this by looking at some small values and experimenting with what was going on. Because without putting in the sanity checks, I think there were definitely some edge cases that were not working out. Again, feel free to not, like, copy this over verbatim but just work with your own sort of version and see what you discover in terms of the right limits that you want to impose.\nBut hopefully, it is clear why we are able to disregard the entire search space from L all the way up to mid inclusive and we want to go to mid+1. That is the binary search that we wanted to do. I think you might be wondering if this offset of +1 is really important.\nI do not think I have tried it without that, but I think it should work out the same. Again, if you try variations of this, and they work out just as well, then, please feel free to share those. I would definitely look forward to it. But in the meantime, I think we can move on from here.\n(Refer Slide Time: 48:01)\n\nNow that the main work is done, the heavy lifting of the binary searching and finding the right value of ‘k.’ Notice that when we are out of this ‘while’ loop, we have found the best possible value of ‘k.’ Now what we want to do is find the mean with respect to this choice of ‘k.’ What this ‘find mean’ helper function will do is it will take the value of the current median, the location of the current median, and the value of how many extra elements you want to incorporate.\nThen it will return the mean of that sub-array for you. Calculate the mean and then see if this improves on the best mean that you have discovered so far. You have an answer variable. Again, this is a variable whose initialization I have skipped. You can look up the full code in the repository just to fill in the small details. But essentially, the answer is designed to store the best answer that we have encountered so far. You can always initialize the answer to 0 because as we have discussed, there is always a solution whose skewness is 0.\nThat is the initial bar. Every time we can improve on the current best answer that we have discovered, we would want to update some of these variables. If the current skewness is better than whatever skewness we have stored in the answer variable, then we need to make some updates. Notice that here to compute the skewness, you should do ‘mean - v of guess,’ not ‘mean - guess.’\nSo, ‘guess’ is not the median. It is just the index of the median element. If you want to subtract the value of the median so that is ‘v of guess.’ If you do hit a jackpot, and things got better from all the previous guessing that you have done. I do not know if guessing is a word, but all the previous guesses that you have taken, then let us just update the scene here. Of course, answer gets updated with the new value of skewness. We are also keeping track of the best guess that we had so far and the length of the array.\n(Refer Slide Time: 50:18)\n\nRemember, these are the two things that we need to actually compute the array that witnesses this particular skewness. The reason we are tracking this is that as a part of the output, we are actually required to print an array, which has the best skewness. Again, this is a little bit of like boring logistics. Nothing remarkable going on here. But you just have to make sure that you carefully print all the elements of the subset.\nFortunately, you have on hand the value of the best choice of median and the best choice of size of the subset. It is just a matter of navigating the array properly and printing out all of those elements. If you go further back in this video and remember, there was a place where we showed you how to pick these k elements. Those are the top k elements and the k elements that come right before the choice of the median. That is the combination that you are looking at. That is exactly what this code here is doing. I will not go through it line by line. But I hope that it is kind of self-evident.\nHere is the ‘find mean’ helper function that is the only thing that remains to be discussed. As I said, the ‘find mean’ helper function will take the choice of the location of the current median that you are working with, the value of ‘k,’ and will also have access to the partial sums vector. Here all we are doing is, essentially, if there is only one element in the whole array, which is signified by the fact that ‘k’ is 0. You do not want to add anything, then you just return that element; there is nothing to be done.\nOtherwise, in the more interesting case, you want to compute the sum of the whole array. What we are doing is, essentially, these two expressions here are computing the sums of these two chunks that we have identified. The first chunk is essentially the top ‘k’ elements. You can see that the second term in the expression computes that. So ‘pv of N’ is the partial sum of the whole array, which is essentially the sum of the whole array.\nFrom there you are subtracting the partial sums up to the N-kth element. With the appropriate indexing, you do have to pay attention to the indices here. But it turns out that it will just subtract off the partial sum up to the point where you only have ‘k’ elements left after that. All of that excess baggage goes away. What you are left with is the sum of the last ‘k’ elements. Very similarly, the first expression will calculate the sum of the ‘k’ elements that are just behind the median, and up to the median.\nIt will also include the median element in its calculation. The sum of these two terms gives you the overall sum of the array, whose mean you are trying to find. You return this divided by ‘2k+1’ because 2k+1 is the size of the array that you are working with. Hopefully, this helper function is clear as well. That is essentially the entire code. Just try to keep things clean when you are doing your own version of this because, as I said, the indices can sometimes definitely be a bit confusing.\nOther than that, I think conceptually, once you get the hang of it, what is going on is really nice. Hopefully, also not that hard. I mean, I am not sure if you are somebody who is sort of scared of doing binary searching. I hope that after this, you feel more confident about it, and you feel ready to tackle problems that are based on binary search.\nWith that, we come to the end of all of the problems that we wanted to do this week. I hope you enjoyed it as much as we enjoyed putting this together. Next week, we are going to be talking about greedy algorithms. That is going to be a whole lot of fun as well and a completely new theme. In the meantime, if you had any questions about these lectures, then you can post them in the comments on YouTube.\nOr you can post your questions in the Discord community or add the official mailing list for the course on Google Groups. Any of these methods should work. One of us will get back to you hopefully quickly. In the meantime, have fun coding, and we will see you next week. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec53.html",
    "href": "materials/cpnotes/Lec53.html",
    "title": "Bottom-Up DP | Dice Combinations (CSES Problem Set)",
    "section": "",
    "text": "Lecture - 53\nBottom-Up DP | Dice Combinations (CSES Problem Set)\n(Refer Slide Time: 00:50)\n\nWelcome to the second module of the 10th week in Getting Started with Competitive Programming. This week we are getting started with dynamic programming and in the first module, you have seen an introduction to how dynamic programming can be thought of as memoized recursion or clever Brute-Force.\nSo, in this module, we are going to be doing more of the same with a new problem, except that there will be a small change in the way in which we write up our solution. So, we are going to be using tables instead of recursive functions and this style is sometimes referred to as Bottom-Up Dynamic Programming. So, we are going to get a chance to explore, what that looks like, and contrast it with the top-down approach that we have already seen.\nSo, for this module, the problem that we will be using is called dice combinations. It is a problem from the excellent CSES problem set, which has about 19 problems under the dynamic programming section. And I definitely encourage you to check out some of the other problems in this set as well and share your thoughts on your experiences with solving them.\nI think they are automatically ordered according to the number of people who made successful submissions. So, in some sense, the ordering is a rough indication of an increasing level of difficulty and I think by the time you are done with this week, you should be able to attempt at least the first couple of problems after dice combinations. So, do check that out. In the meantime, let us get started with the question of dice combinations.\n(Refer Slide Time: 01:43)\n\nSo, this is pretty much the entire problem statement. It says that your task is to count the number of ways in which you can construct a sum n, which is a given number by throwing a dice one or more times. Each throw of the dice produces an outcome between 1 and 6. So, one thing that I think I should say right off the bat is that this is a pure counting question. There are no probabilities involved.\nNormally when you think about problems involving throws of dice or coin tosses, you tend to think about chance, and you think about, well, what might happen, what might not happen. So, for example, this question is not asking, what is the probability that a sequence of dice throws adds up to n. That would be a question of chance.\nBut here we are really just asking, in principle, how many sequences of dice throws there are that add up to a given number n. So, really just, think of it as a pure counting question with no element of chance in it. So, to get used to what we are being asked to do, let us work through a few examples, which is always helpful.\nSo, what if n = 1? Well, in this case, there is really only one way that a sequence of dice throws could result in a sum of 1. And that is if you rolled it once and it showed up one. So, there is only one way that this can happen.\nWhat about when n = 2? Here there are two possibilities, either you could throw a dice two times and it shows up 1 on both occasions, or you throw it once and it comes up as 2. Both of these sequences are valid and distinct and lead to a sum of 2.\n(Refer Slide Time: 02:47, 03:04, 03:24, and 04:27)\nn=1  n=2  n=3  n=4 \nWhat about when n = 3? Well, in this case, there are going to be a few more sequences to account for. Feel free to pause the video here and see if you would like to work this out for yourself and come back and exchange notes. The case when n = 3 is actually also part of the problem statement. So, in case you have seen the problem statement separately, you know the answer to this already. All right.\nSo, the first thing that you could do is, to roll a dice once and it comes up 3. That is one way that this could happen. The other is that maybe you roll a dice once and it comes up 2, and then the only thing that can happen from there is that the second roll of dice should show up with a 1. On the other hand, maybe the first roll of dice ends up showing a 1, in which case you are left with the task of creating 2. And we know that we can do this in two ways, either by a single roll of two or two rolls of one each. So, altogether, the number of ways in which a sequence of dice rolls could produce the number 3 happens to be 4.\nWhat happens when n = 4? In this case, again, there is a multitude of possibilities, and here are all of them. Hopefully, I have not forgotten anything. And once again, if you go through the process of trying to categorize these nicely, you could think of it as, what happens on the first roll and think of the first roll as being the last dice in each sequence. It is just probably helpful to think of it that way.\nSo, if the first roll is 4 then there is nothing more to do. If the first roll is 3 then you need to generate 1. 1 is still left and there is only one way to do that. If the first roll is 2 then you still have 2 left to generate and there are two ways of doing that. And if the first roll is a 1 then you are still left with the task of generating 3. And we just saw that there are four ways of doing that. Let me actually highlight some portions so that it becomes visually a bit clearer how we relied on what we have worked out previously to work out the answer for the case when n = 4.\n(Refer Slide Time: 05:29)\n\nSo, you can see that all the green tiles correspond to ways of generating the number 3 by a sequence of dice rolls. And we kind of appended a 1 at the end to get 4. The yellow tiles represent the number of ways of generating 2. The red tile shows the number of ways of generating 1. And there is, of course, this standalone sequence, which is just directly getting to 4, without having to roll any more throws at all.\nSo, you might already begin to appreciate how this as a strategy might generalize to the case when you are trying to generate a sum of n. And if you remind yourself about how we worked out the solution to the frog’s problem in the previous module, we said it is useful to split up the solution space into smaller categories that are manageable by recursively-generated answers.\nSo, remember what we want to do is, see if we can take the space of solutions that we are interested in. In this case, our solution is really the number of these sequences, we want to count how many there are. And we want to take the space and see if we can chop it up into pieces that will then be addressable in some recursive fashion. And then, hopefully, we can just put it all back together in a reasonable way in a decent amount of time. So, here the chopping up at least seems to be fairly natural.\n(Refer Slide Time: 07:01, 07:18)\n  \nThese colored pieces naturally correspond to some instances that we can essentially outsource to recursion. And then when we put them back, it is just a matter of adding up all the numbers that we get. So, just to make this categorization a little more explicit as we did before, let us note that every sequence in our solution ends with one of these numbers, 1, 2, 3, 4, 5, 6.\nYou could think of this as essentially what happened on the last roll of the dice. That is clearly constrained to being one of these six numbers and that leads to a natural categorization of your space into six categories, some of which may be, by the way, empty as we have seen in our example.\nSo, in particular, if n is 4 then there will be no sequence that ends with a 6. Because once you have rolled a 6 that is a point of no return, there is no way of fixing that, so that the sum becomes four. So, that is just an empty category. It is not something that we have to worry about. It may manifest as a bit of an edge case, depending on your implementation. But we will see that it gets handled naturally in the way that we choose to implement the program later. So, let us take a closer look at this categorization so that the recursive nature of our solution also becomes a little bit more explicit.\n(Refer Slide Time: 08:22 and 09:34)\n \nSo, category number ‘k’ is going to collect all those sequences, where you got a k on the last roll. Okay. So, clearly, k ranges from 1 to 6. And if you look at the rest of the sequence in terms of what is happening apart from the last roll, which is represented by the colored tiles in the previous picture that we were looking at, well, these are all going to be sequences that add up to n-k. And that is easy to reverse engineer because you know that the whole sequence must add up to n because this is a sequence in your solution space.\nAnd right now, the categorization, the case that we are in is telling us that the last roll was already, so we know that the rest of it must add up to n-k. So, what we are interested in is, of course, the total number of sequences. And notice that the number of sequences that generate a sum of n-k is something that we can compute recursively. And once we have done that, the final answer is just going to be the sum of these answers that we obtain from recursion. Okay.\nSo, to make the recursion a little more explicit, let us write it down this way. So, the number of ways of generating a sum of n by rolls of dice is equal to the number of ways that you can generate n-1 and -2 and so on and so forth all the way up to n-6. Notice that we do need a base case, as we had explained last time. And here, a natural base case to work with is that the number of ways that you can generate a sum of 0 is 1 because the only way to generate 0 is to do nothing, and doing nothing is something that you can think of as the only way to generate a sum of 0.\nNow, this may not seem completely satisfactory, but we will see that defining the value of the answer for 0 as 1 will be useful in a very natural way in our recursion. Remember that one case where we said that you can get a 4 by just directly rolling a 4. Well, you can think of that as (being) getting a 4 on the last roll, followed by an empty sequence. And so, when you recurse, you naturally account for this one method of generating a 4 by getting a 4 on the last roll.\nActually, let me write out the case for n = 4 a little bit explicitly because it will help me draw your attention to also some edge cases. So, when n = 4, then n-1, n-2, and n-3 all make sense; n-4 is this mysterious the number of ways in which you can generate 0, but as I said, you can really think of that as generating a 4 on the last roll, and having to do nothing after that. I would really like that to contribute 1 to the sum because that is a perfectly legitimate way of generating a 4.\n(Refer Slide Time: 11:23)\n\nAfter this, things start looking a bit suspect. You have n-5 and n-6, being essentially -1 and -2. And, of course, there is no way that you can generate -1 and -2. So, these numbers are 0. And one question is, how do you want your recursion to handle it?\nSo, of course, the recursion could say that if n is less than 0, then you return 0. The other way to do it is to just make sure that when you are working with these smaller numbers, notice that this will not be an issue when n is, say, bigger than 6. But for these smaller numbers, you might just want to ensure that you do not even include these terms in your sum.\nSo, that is an implementation detail, and it is a matter of taste as to how you want to do it. But for now, the main thing to agree on is the recurrence itself and the choice of the base case. So, hopefully going over this explicit example makes it clear as to why we want to say that the number of ways of generating 0 is 1. It kind of aligns nicely with the recurrence that we have just set up for ourselves.\nNow, let us talk about the implementation a little bit. Of course, you could implement this just like we implemented the solution to the frog’s problem. So, you could write down a function called ‘solve,’ and it could call itself 6 times, and the answer would be the sum. And once again, you would, of course, want to memoize to avoid the overhead of doing redundant computation. So, that would have been the de-facto top-down style that we have seen so far. But now, let me take you through the bottom-up style instead, which is just a slightly different way of implementing the same solution.\nNow, what we are going to do is directly use an array to store the values, and we are going to populate this array going from essentially left to right in the context of this particular example. But more generally, when you have sort of a structure, which reflects all the answers, all the information that your solution wants to store, what you do is you directly populate the base cases.\nAnd then from there, you start working in different parts of the storage, making sure that whenever you are trying to fill up a certain entry in your table, all the entries that it relies on for information, have already been filled up before. So, that was a slightly abstract description. Let us come back and make it concrete in the context of this example.\n(Refer Slide Time: 13:47)\n\nSo, here, we just need a simple one-dimensional array with n+1 entries to account for the fact that we have an entry corresponding to 0, which is our base case. And we need to go all the way up to n because we are counting the number of ways in which n can be expressed as a sum of dice throws.\nSo, to begin with, we are going to just make sure that 0 is populated as 1. This is our base case. And then going forward, 1 is going to be equal to 1 again because that is just how the recurrence works out. So, when you look at the number of ways of generating 1, it is the number of ways of generating n-1. And we are going to ignore n-2 and so on because those generate negative numbers and as we said, those are things that we just treat as 0.\nSimilarly, for 2, we get 1+1, which is 2. For 3, we get 1+1+2, which is 4. For 4, you get 1+1+2 +4 that is 8. For 5, you get the sum of all the numbers that you have seen so far, that is 16. And for 6, you get the sum of all the numbers that you have seen so far again, and that is 32.\nFor 7 you do not get the sum of all the numbers you have seen so far, but the last six numbers that you have seen so far. So, that is going to be 63. And similarly, for 8, you are going to again get to the sum of the previous 6 numbers, and that adds up to 125. You can verify that these numbers are okay (and) that the addition was done correctly, I hope.\n(Refer Slide Time: 15:13)\n  \nIn general, when you are somewhere in the middle of this array, and you are trying to compute the i’th entry, the way you do that is by basically looking up the previous six entries and simply pushing the sum of all of these numbers to populate the i’th entry. You can just keep going. Okay.\nSo, essentially, you are doing the work that the recursive algorithm was doing implicitly. You are just carrying it out explicitly through a table and going over it directly. Implementing a bottom-up solution like this requires you to have a good understanding of how exactly the recurrence works. In the sense that you need to be careful about knowing in what order to fill out the table. So, typically for a one-dimensional table, this is not a serious challenge. You would usually just go from left to right.\nBut on the other hand, if you have a more complicated, say, two-dimensional array or something like this, you have to be careful about ensuring that you fill it up in the right order and that whenever you are filling up a particular entry, the entries that you are appealing to for information have actually been properly populated by the algorithm, and do not carry a garbage value or a default value that you have set up, which is still meaningless in the context of the problem. So, that is something to be aware of. This is worth that you are doing quite explicitly here, as opposed to before, where you could just write the recurrence and be done with it essentially.\n(Refer Slide Time: 16:44)\n\nAlright. So, let us take a look at how this would look in code. This is actually the entire program for this problem. And what we have done here, and the only thing I would like to maybe call attention to is the fact that when we are working with small numbers, we add in the small check, which makes sure that we do not get into these negative numbers, which would be either something that causes your program to not work or it leads to bugs.\nBecause in languages like python, for instance, if you have negative array indices, you would not get a complaint. But what it will probably do is just loop around the array and pick up some values from the end or something weird like that. So, we have a small sanity check that just ensures that when you are working with numbers that are at most six, you do not look up the entries that are not relevant to you.\nThere are other ways that you can implement these details concerning edge cases. But I found this one to be convenient and that is what we are doing here. You will also see like a ‘mod’ around here, it turns out that these numbers do get pretty large. And it was a requirement in the problem statement to print out the answer modulo a specific number.\nSo, there is a constant setting that you do not see on your screen right now. But ‘mod’ is essentially 10^9+7 or something like this. So, that is how you would do what is called bottom-up dynamic programming. It is called bottom-up because you start with the base cases, and you literally build the solution quite explicitly with your, if not your own hands, at least with your code, as opposed to just relying on recursion fairy to do all the work for you.\nSo, why would you use an approach like this? For some people, memoization over recursion seems like a more intuitive and easier approach to code (with). Some people find that the bottom-up method is more somehow transparent and intuitive to look at, and especially if you are doing modifications or optimizations on top of some basic routine, then somehow this is just easier to work with.\nSo, in terms of what you find more intuitive, I think is a matter of personal taste. I think I know people, who feel differently about this, so this is totally up to you in terms of preference, either of style or over what feels intuitive. As I said, for at least problems that you encounter at an elementary level, there is really no difference in what approach you follow. Having said that, let me make a few slightly more concrete remarks.\n(Refer Slide Time: 19:13)\n\nThis is just to complete the contrast that I had initiated towards the end of the last module and to basically wrap up that discussion. So, first of all, with bottom-up dynamic programming, you end up typically computing a full DP table, and often you end up actually computing entries that were never used in the computation of the final answer. So, you may end up doing some extra work.\nTypically, this difference is again not noticeable for the easier problems, but it may make a difference for more complicated situations. On the other hand, if you are trying to optimize for memory, then it is useful sometimes to work with the bottom-up approach because just easier to do memory optimization here, as opposed to top-down. To give you a simple example of how a memory optimization trick may work, notice that in the dice combinations problem, you only always needed the previous six entries to compute the current one.\nRight. You do not need to store the whole table. You can actually do everything that we did, using only a constant amount of space. And the way you can implement this is by just using an array with 6 or maybe 7 entries, one for buffer perhaps, and just continuously overwriting things carefully. Right.\nOn the other hand, if you wanted to do something like this with the recursive version it is harder because you really do not control how the recursive stack works, you know, as directly. So, that is the sense in which it can be messier to do memory optimization in the top-down approach.\nOn the other hand, just going back to the first point a little bit, because you are doing things recursively, it is very natural that you only make the function calls that are directly needed for getting to the final answer. Whereas, here you are just blindly following, you know, a way of populating an entire table.\nSo, typically, you would have, let us say, if it is a 2D table, you typically have a nested loop that just computes all the n times m entries or whatever, whether you need it or not. Right. So, again, this is something that you can optimize for, also in the bottom-up approach. But it is just something that would require extra explicit work from your end, whereas the recursive version handles this naturally.\nAgain, there are not many problems where this really makes a difference in terms of getting TLE or MLE, as the case may be. But I think it is just nice to know which approaches are more suitable for what kind of optimizations. So, just to recap, the bottom-up approach is more natural when you want to optimize for memory usage. And the top-down approach is more suitable when you want to optimize for time usage, in terms of just making only those function calls that are absolutely necessary.\nOne final point that I think I have alluded to already, is the fact that when you are doing bottom-up then you are actually explicitly writing out the sequence in which you fill out the table entries. So, typically, the recurrence will already hint or dictate the sequence in which you should be filling out the table entries. But you need to make sure that you understand your recurrence carefully, and there could be subtle errors that creep in, in terms of not getting this sequence right.\nSo, in one of the assignment problems, you will see how changing the sequence in which you populate a DP table can completely change the semantics of what the DP table is actually computing. So, make sure that you are careful about in what order table entries are being populated.\nThe example that we just saw, will not really help you appreciate this fully because it is a simple one-dimensional array, and there is a very predictable way in which you want to fill this out. But when you start working with 2D arrays or just more complex structures, over which you do dynamic programming, then these issues will start manifesting a little more. So, that is just something to be aware of and something to keep in mind.\n(Refer Slide Time: 23:21)\n\nOne thing that I like about the bottom-up approach is that it lets me distill the dynamic programming task into these two questions. Basically, you want to think about. What do I want to keep? And how do I compute what I want to keep? So, this is a little bit like the catchphrase we had last time, where we said dynamic programming is recursion + memoization. But I think, this way of thinking about DP for me has felt a little more concrete.\nSo, you want to say that okay, the ij’th entry of my table or the k’th entry of my table or whatever represents this value. And you want to ask yourself, okay, if I did compute this for the whole table, is my answer hiding somewhere in the table? Is it one of the entries? Is it the sum of some of the entries? Is it the max of some of the entries? You want to make sure that whatever you decide to store actually leads you to the answer in a meaningful way.\nOnce you have determined, what you want to store, you want to think about, well, how do I compute whatever it is that I decided my semantics are going to be? And this is the bit, of course, about recursion, about coming up with the right recurrence, identifying what sub-problems will help you solve the current problem at hand. And typically, your thought process for a non-trivial problem may involve a little bit of a back and forth between two questions. You might decide to store something, and then you might realize that, well, okay, this would be nice to store it takes me to the answer but there is not enough meat in this semantics; it does not give me what I want, because I am not able to compute it.\nThe previous entries are too weak. They do not give me enough information to compute what I want to compute right now. So, then, you go back and change the semantics. You add more masala to it, so to speak, you make it, you strengthen the semantics, and then you come back and try to do the recurrence again.\nSo, this is a process that you will typically go through before you land up at the right recurrence. With enough practice, you will identify patterns, and some problems will just immediately fall into some pattern that you have seen before. But sometimes you will see a problem that is just going to be a new adventure, and you might have to, sort of, do this back and forth process a little bit before you settle down and actually find the right recurrence.\nAnother thing worth mentioning is that for many problems, there will be multiple recurrences that make sense and that are all correct. But one would be superior to another in terms of the running time. So, you want to make sure often that you end up at an efficient recurrence, not just anyone that works. So, in one of the examples, we will see how we start off with a natural recurrence that is perfectly valid, but then we try to enhance it and just go to a sparser sort of a table, which can be computed more quickly.\nSpeaking of optimizations, I should say that there is a whole world of tips, tricks, strategies, and techniques for optimizing DP routines. And there is a lot to be uncovered and discovered here. Unfortunately, we will only get around to barely scratching the surface, and a lot of the advanced techniques are definitely a little bit out of scope for this course. Nonetheless, I think just getting the philosophy right with practice and being able to identify some common patterns will already take you pretty far in the context of solving DP-based problems.\nSo, to that end, in the next week, we will be looking at a couple of examples just to get the hang of how DP-based solutions work. And in the final week, we will round this off with one example, which is relatively a little more sophisticated than any of the ones that we would have seen before.\nSo, that is what is coming up, and I am looking forward to sharing these other examples with you in the coming weeks. In the meantime, I hope that you have a chance to look at the AtCoder DP educational problem set, as well as the CSES problem set, and try out a few of the problems that are there. At least the first few, I think, should be eminently doable from where we stop here, in this week. So, thanks so much for tuning in. And I look forward to seeing you back next week. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec47.html",
    "href": "materials/cpnotes/Lec47.html",
    "title": "Sport Elimination via MaxFlow",
    "section": "",
    "text": "Lecture - 47\nSport Elimination via MaxFlow\n(Refer Slide Time: 0:11)\n\nWelcome to the third and the final module of week 8 in Getting Started with Competitive Programming. So, we are still talking about network flows. And in this module, I want to talk about a textbook problem called ‘sport elimination.’ I could not find a programming contest problem that corresponds to this. So, we would not be doing any implementation.\nBut it is a fun problem to talk about, and goes to show how versatile MaxFlow can be in terms of modeling problems that may not sound like they have anything to do with graphs, at least to begin with. So, let us talk about the problem setting first, and then we will talk about how a flow network could be useful in determining a solution.\nSo, let us say that we have an IPL tournament going on, which is true at the time of this recording. And let us say that we are at some point in the middle of the tournament where some matches have been played. And some matches still remain. So, before going further, let me just clarify the format of the IPL although you probably know this better than me, but just to make sure that we are on the same page about the setting of the problem.\nLet me recall that the IPL tournament is typically a double round robin tournament with playoffs, which just means that in the beginning, we have the league matches where every team faces off every other team twice. So, there are usually 8 teams. And therefore, every team is going to play 14 matches because there are seven other teams. And there are going to be two matches with each team.\nSo, there are going to be 14 matches that every team plays. So, if you add up all the matches that every team is involved in, that is 14 times 8, which is 112. But of course, as an audience, you only get to see 56 matches, because every match just got counted twice the way I described it. So, there are 56 of these league matches. And then ultimately, there are 4 playoff matches, which will determine the ultimate winner of the tournament.\nSo, in this problem, I am just going to focus on the league games, not worry about the playoffs. And for simplicity, we are going to assume that no game ends in a tie. So, we are just interested in tracking the number of wins that every team has.\n(Refer Slide Time: 2:20)\n\nSo, let us say that some league matches have been played. And let us say that these are the four teams that are at the top of the leaderboard right now. So, we have KKR (Kolkata Knight Riders), and we have CSK (Chennai Super Kings), RCB (Royal Challengers Bangalore) and MI (Mumbai Indians). Right. And let us say that all of these 4 teams have played all of their matches against the remaining 4 teams that you do not see. So, which is to say that every team has played these 8 matches.\nAnd let us also assume that they have won all of those 8 matches, and the remaining four teams are at the bottom of the points table. So we are not going to worry about them right now. We are going to focus on just these four teams. And let us say the situation is that these are the matches that are remaining between these four teams. So, between these four teams also some matches have been played.\nFor example, KKR and CSK have played both of the matches that they had to play between them. RCB has played one match each with each of these teams, and it has one match remaining. Mumbai and KKR – they have played one match, and they have one match remaining between them. And Mumbai and CSK – they have played both of the matches that they had, so they have no matches remaining between them. So, I hope I accounted for all the parents, but if not, the information that you have here about the number of remaining matches tells you everything that you need to know.\nNow next, let me also tell you how many matches these teams have won among the games that they have played so far. So, these are the numbers corresponding to their total number of wins. Recall that each of these teams played 8 matches against the four teams that you do not see in this picture. And we assumed that they had won all of those 8 matches. But of course, these teams have played some more games. So, let us look at what may have happened in those. So, let us say that Bangalore lost all of its first matches against Kolkata, Chennai, and Mumbai.\nSo, its total number of wins just remains at 8 from those other games. It does not go beyond that at the moment. As for Kolkata, let us say that, of course, we already know that it won its first match against Bangalore. And let us say that it won both of the matches against Chennai, and it lost the one match that it had with Mumbai. So, that means that its total number of wins is 8+1 for Bangalore and two for Chennai, and 0 from the match with Mumbai. So, that is a +3 and that is 11.\nAs for Chennai, we already know that it has one win against Bangalore, and it has lost both of its matches to Kolkata. It also played two matches against Mumbai. And let us say that it won one of those two matches. So, it has one win against Bangalore and one against Mumbai. And that brings its total score up to 8+2 = 10. Now, for Mumbai you know exactly what has happened. So, it is basically a one-one match each against Kolkata, Bangalore, and Chennai. So, that brings its total score up to 8+3, 11. Okay. So, these are the total number of wins that these teams have accumulated.\n(Refer Slide Time: 5:23)\n\nAnd here is the question that we are interested in. This is what is called the sport elimination problem. What we want to know is for our favorite team, and for this example, I am going to say that, that is RCB, I want to know if there is some way that the remaining matches can be played out so that RCB ends up being on the top of the league table? So by that I mean that RCB accumulates at least as many wins as any other team.\nSo, it is possible that RCB ties for the top spot with some other team and that is fine. But I just want to make sure that there is no other team that scores strictly more wins than RCB. So, remember that this is a question of checking for feasibility. Our predictions for the upcoming matches do not have to be realistic.\nThey do not have to be based on past statistics of how these teams have fared against each other, or what has happened in a particular ground. None of that is relevant here. I just want to know, hypothetically, can I set the outcomes of the remaining games in such a way that RCB ends up as one of the teams on the top of the table? So, I hope that this question is well formed, and it makes sense.\n(Refer Slide Time: 6:28)\n\nLet us go back to the numbers here. I invite you to pause the video here and see if you can figure out the answer to the question that we just asked in the context of this specific example. I am sure all of us have done a lot of this kind of analysis when the actual IPL tournaments are going on. So, most of us have plenty of practice with this kind of question. So, hopefully, this is answerable just by inspection. And this is a particularly simple situation by design. So, pause the video for as long as you need to, and come back when you are ready.\nAlright, so since we want RCB to end up at the top, I think it makes sense that we plan for RCB to win all of its remaining matches. Remember, this is purely a hypothetical, and we get to decide the fate of all the remaining matches anyway we like. So, this seems like a greedy choice. But in this case, you can justify it quite easily.\nSo, what we are going to do is say that for these three matches that RCB is involved in, it is going to win all three of them. And this brings RCB’s total score up to 11. And notice that no matter what happens, RCB’s final score, in terms of its total number of wins, cannot be more than 11. Because among the matches that have already happened, whose fate you cannot change, it has accumulated 8 wins. And the team itself is involved in three more matches.\nAnd this is the best-case scenario estimate on those three matches. So, this is our final score for RCB. But now notice that there is one game that remains between Kolkata and Mumbai. And both of them have accumulated 11 wins so far. And remember, we said that there are no ties. So one of these two teams is going to, in fact, win this game. And whichever team that is, irrespective of how the match goes, you are going to find that you are in a situation where there is a team that has accumulated a score of 12, which is more than what RCB can hope to achieve.\nTherefore, in this particular example, the answer to our question is no. No matter how the future matches play out, it is impossible for RCB to end up at the top of the league table. Of course, with a different combination of numbers and with a different set of games that remain to be played, the story could well be different. So, we want to of course address this question in general.\nSo, given all of this information as input in terms of what are the remaining games, how many wins do these teams have in the games that have been played so far, we want to address the question of whether a team stands eliminated from being on the top or not. So, let us see how we can answer this question by setting up all of this information in an appropriately designed flow network.\n(Refer Slide Time: 9:15)\n\nBefore getting to the description of the network, the first step is going to be what we just did with this example as well, which is that we are going to assume that our favorite team wins all of its remaining games. So, in these matches, there are really no points for guessing which way it should go. It is clear that we want our team to win all the matches that remain for it.\nAnd we are going to use X to denote the maximum possible score that our team, the one that we are focused on saving from elimination, that is the best possible score that this team can achieve. So, that number is the total number of wins that it has had so far, and the number of matches that remain for it. So, in the previous example, this was essentially 8+3, and this final optimistic score was essentially 11. Now, let us take a look at what other information we have.\n(Refer Slide Time: 9:57)\n \nSo, given that X is the most optimal score for our favorite team, the remaining information that we have to deal with is who are all the other teams that we are worried about, and what are the matches that remain between them? So, in this case, we have three other teams: Kolkata, Mumbai, and Chennai. And we pair them up in all possible ways. So, in this case, we have three teams and three pairings. In general, it is going to be some n teams, and some n choose two pairings.\nAnd for each of those pairings, you have a number that has been given to you, which says that this is the number of matches that these two teams have left between them. So, in the IPL format, this number will be 1 of 0, 1, or 2. But in some other tournament in some other format, this could be any number of games really.\nSo, our task here boils down to the following. If you fix a pair of teams, let us say P and Q, and let us say they have some number of games remaining between them, let us say Z, then we want to know how to split Z as a sum of two numbers, A and B so that we can say that team P is going to win A of these games, and team Q is going to win the remaining B games. And we want to be able to say this for each pair in such a way that hopefully the total number of wins accumulated by any team does not exceed X. We want to know if this is possible. Right.\nWe want to know if each of these numbers of games that remain between every pair of teams can be split between them in a way that the total number of wins accumulated by any given team is not too much. So, we are going to try and do that by setting up a flow network on this information. And as a hint, let me tell you that this flow network will have a vertex corresponding to every pair of teams, and a vertex corresponding to every team. So, that is just like what you see on your screen right now.\nAnd apart from these vertices, we will also add two extra vertices, which are going to be our specially designated source and target witnesses. So, our flow network is going to have all of these witnesses. But of course, the description of the network is far from complete. I need to tell you what are the edges, and also what are the capacities of these edges. But this is a great point to pause the video and see if you can complete the design of the flow network for yourself.\nRemember that for every vertex that represents a pair of teams, we need to somehow figure out how to talk about the number of matches that remain for that pair. And how this number gets distributed between the two teams that are involved in that pair. Keeping this in mind, try to think about what kind of edges and what kind of capacities you want to add to this network.\nSo hopefully, you had a chance to pause the video and think through this a little bit. Let me first tell you about how we are going to construct the edges. Already the way that I have positioned the source and the target vertices on the screen might give you a hint about how I want the edges incident on these two vertices. So, we are going to add an edge from the source vertex to every vertex that corresponds to a pair of teams.\nAnd, I am also going to add an edge from every team vertex to the target vertex. This again has a flavor that is similar to what we were doing with the matching problem, although the details here in terms of how the capacities work out and what the flow represents is going to be quite different. So, let us take a look at what is going on between the vertices that represent team pairs, and the vertices that represent the teams.\nA very natural thing here would be to connect a team pair with the two teams that are involved in that pair, because the number of matches that remain between, say Mumbai, and Kolkata is none of anybody else’s business. It is going to be something that Mumbai and Kolkata have to figure out between them as to how many matches is going to be won by Mumbai, and how many by Kolkata.\nSo, with that spirit in mind, what we are going to do is add edges between team pairs and teams so that every team pair has two outgoing edges to the two teams that are involved in that pair. So, that is the construction of the edges in the network. These are all the edges that we are going to have. What still remains to be fixed, of course, is the capacities of all of these edges.\nSo, once again, if you had this already figured out, then that is great, but if not, then this is a good place to pause and think about what kinds of capacities you want to associate with all of these edges here. So, hopefully you had a chance to think this over. So, let us first look at the edges that go between the source vertex and vertices that represent team pairs.\nA natural capacity to impose on these edges is the number of matches that remain to be played by the corresponding team pairs. So, if we have an edge from S to say, the pair Kolkata-Chennai, then we are going to basically look at the number of games that Kolkata and Chennai have remaining between them, and we assign that as the capacity of the edge from the source vertex to the Kolkata-Chennai pair and similarly for all of the other pairs.\nNow next, let us consider the edges that connect a team vertex to the target vertex. Here, we somehow have this intuition that this edge is going to carry an amount of flow that is representative of the number of matches that this team has won. And we do not want to allow this number to be larger than X because once it is larger than X, then the fate of RCB comes under question.\nSo, for example, let us say that RBC’s best possible final score is going to be 11. And let us say that Kolkata has already won 9 matches before this point. In this case, we want to say that Kolkata should not win more than 2 matches among all the remaining games. And we are going to capture this thought, by having the edge from Kolkata to the target vertex have a capacity of 2.\nMore generally, if you have an edge from our Q to T, where Q is some team and T is the target vertex, then this capacity should be X minus the number of wins that Q has already had in the tournament. So, this is the number of matches that is safe for Team Q to win without putting RCB’s position at the top of the leaderboard at risk. So, this is the capacity of all the edges going from the team vertices to the target vertex.\nNow, as for all the remaining edges, it turns out that there is nearly no need to impose a specific capacity constraint on them. So, you could think of them as edges that have infinite capacity. In any case, the amount of flow that goes through these edges is going to be automatically bounded by the capacity of the incoming edges from the source side. So, if you think about it a little bit, then you will see that imposing an infinite capacity and imposing a capacity that is, let us say, a fixed quantity, like the total number of remaining games, essentially amounts to the same thing.\nFor now, we will just think of these edges as free edges that do not have any explicit capacity constraint. So, that completes our description of the flow network. And now let us think about what can we hope to get out of a maximum flow in this network. What we want is an answer to our question, which is, is it possible to set the outcomes of all the remaining games in such a way that our favorite team ends up at the top of the final leaderboard in terms of its total number of wins?\nWell, the claim is the following. If a maximum flow in this network is able to saturate all the edges that are coming out of the source vertex – (and remember that a flow saturates an edge, if it uses it to its full capacity) – so, if the maximum flow can do that, in other words, if the value of the maximum flow is equal to the total number of remaining matches, of course, not counting the ones that our favorite team participated in, because those have been accounted for.\nBut let us say that the maximum flow is the value is equal to the total number of matches other than these, then we claim that there is in fact, a way of setting the outcomes in such a way that the position of our favorite team is protected at the top of the leaderboard. On the other hand, let us say that the value of the maximum flow falls short of this amount. In other words, even the maximum flow fails to saturate every edge coming out of the source.\nThis is going to mean that no matter how the outcomes of the remaining games play out, there is no chance for our favorite team to end up at the top of the leaderboard or to tie for the top position in terms of the number of wins, there is going to be some team in every situation that overtakes our favorite team strictly in terms of the total number of wins. So, that is the claim. And let us at least establish some intuition for why this claim is true. First, suppose that there is a flow that saturates every edge that is coming out of the source. In this case, let us propose the following outcomes for the games.\nSo, in particular, let us look at the Kolkata-Chennai pair. So, there is a certain amount of flow coming into this vertex, which is equal to the number of matches that remain between these two teams, because we know that the flow is saturating every edge coming out of the source. Now, because of the conservation constraint, this number must be split between these two outgoing edges, because this flow has nowhere else to go.\nSo, let us say the incoming flow was something like 10, then it has to be split in some manner between the two blue edges that are going to the vertices corresponding to Kolkata and Chennai. So, this could be 7+3, it could be 5+5, it could be 1+9, but it is going to be some integral split. You remember from our previous module, that you can always assume that your MaxFlow is integral, it associates an integer with every edge, because our capacities here are integers as well.\nSo, that is what we have at this point. And you can probably guess, how we want to interpret this flow for the purposes of predicting outcomes. So, let us say, for instance, we had an incoming flow of 10 units and it got split as 7 and 3 with 7 units of flow going to the KKR vertex and three units of flow going to the CSK vertex. This means that we are going to say that Kolkata wins 7 of these remaining 10 matches, and Chennai wins 3 of the remaining 10 matches.\nSo, this is how we are going to set the outcomes for each of the remaining sets of games that are to be played out between pairs of teams. Now, how do we know that after the matches play out in this particular way, our favorite team is still going to be at the top of the leaderboard. The reason for this is the capacities that were set up on the other side on the edges that go to the target vertex.\nSo, for any team, notice that the total number of matches they win is equal to the total amount of incoming flow on that vertex with respect to the outcomes that we just described. Now, again, by the conservation constraint, all of this flow has to be pushed out along this edge, because there is only one outgoing edge from this vertex, and it goes to the target vertex. But remember that we carefully set the capacity of this edge to be something like X minus the number of wins that this team has already had.\nSo, Kolkata has already won a certain number of matches, and the total number of matches, it is going to win, under the predictions that we just established, is going to be some number that is at most X minus the number of wins that it has already had. So, if you add up these two numbers, you get a number that is at most X. And notice that this is true for every single team in this picture.\nSo, if you do have a flow that saturates every edge coming out of the source, then you can map out a prediction, or you can map out a set of outcomes for all the remaining games in such a way that your favorite team ends up having at least as many wins as any other team. Now on the other hand, it is also true that if somebody gives you a set of predictions, which has this property, that if the matches play out in this way, then your favorite team is at the top of the table, then you can also formulate a corresponding flow, which saturates all the edges coming out of S.\nSo, the process to do this is very similar to the process that we just used to convert a flow into a set of match outcomes. So, now you just go in the other direction, which is to say that you route the flow based on the information that somebody gives you about how the match outcome should play out. So, once you do that, you will see that the following statement is true, that the maximum flow in this network saturates every edge going out of S, if and only if there is a way for these remaining matches to be played out in a manner that puts our favorite team on the top of the leaderboard.\nTherefore, to answer the question, all you have to do is run the MaxFlow algorithm on this flow network. And check if the value of the maximum flow is equal to the number of matches that remain, not counting the ones involving our team, because those we set in the beginning greedily anyway. So, that is essentially the crux of this formulation. And there are a few interesting things that you can think about from here.\nThe first is, well, if we cannot get to the top of the leaderboard, what is the closest that we can come to the top? Does the MaxFlow give us any meaningful information about this version of the question? The other interesting question you can ask is, whenever your team cannot make it, does the MaxFlow algorithm give you some explainable evidence for why it is impossible for your team to make it to the top?\nSo, remember, like in the example that we had, we were able to point to two teams, which were, I think, Kolkata and Mumbai. And we said that, well, they have one match between them, and the scores are already threatening RCB. And no matter how this match goes, one of these teams will end up overtaking RCB score. So, this is an explanation that you can give to a friend who knows nothing about network flows.\nSo, can you use this flow network whenever the flow falls short of the number of remaining games? Or in other words, a flow that fails to saturate all edges coming out at the source – can you use such a flow to build up some explainable evidence for why your team is not going to make it? It turns out that the answer to this question is yes, but we probably do not have the language to talk about how to extract this information from the network flow yet.\nSo, for this, stay tuned to week 9, which is where we will talk about something called the duality of MaxFlow and MinCut. And once you see this sort of duality, you will be able to probably answer this particular question and hopefully a very interesting way. If you cannot wait to see how this works, then you could look up the pointers in the description of this video to find out more details about how to pull out an explainable piece of evidence for why your team will not make it to the top no matter how the matches play out, and this evidence does not involve detailed case analysis, saying, let us just enumerate all of the possibilities and see what happens.\nIt is a lot more elegant and succinct than that. So, hopefully, you will have a chance to check it out. Or the other option is to just wait till you are done with week 9 and think about it for yourself. So, with that, it is a wrap on week 8. And when we move on to week 9, it is still going to be about flows. But from a slightly different perspective, it is going to be from the perspective of a closely related problem called the MinCut problem.\n\nAnd we will look at a couple of examples where it is useful to find the MinCut, and we will do that using the MaxFlow algorithm that we already know. So, I look forward to seeing you there. Thanks so much for watching, and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec46.html",
    "href": "materials/cpnotes/Lec46.html",
    "title": "Network Flows - Module 2 (Maximum Matching via MaxFlow)",
    "section": "",
    "text": "Lecture - 46\nNetwork Flows - Module 2 (Maximum Matching via MaxFlow)\n(Refer Slide Time: 0:11)\n\nWelcome back to the second module of the eighth week in Getting Started with Competitive Programming. So, as you might remember, this week, we are talking about network flows. And in the first module, what we did was set up the problem of finding a maximum flow through a flow network.\nNow, in its own right, this may sound like a fairly specific problem to solve, so you might be wondering why it is presented as a technique. And I had mentioned that one of the reasons it is the case is because a whole host of problems can be essentially modeled as the problem of finding a maximum flow through a flow network, even if it is not, apparently, related to graphs and often many graph problems also can be modeled in this way.\nSo, I want to demonstrate that through a couple of examples. The one that we are going to see in this module is essentially a problem that can be thought of as a classic graph problem. And we are going to see how that essentially boils down to finding a maximum matching in an appropriately set up flow network. And in the next and the last module for this week, we will talk about a fun problem called SPORT elimination, which on the face of it, does not look like it has anything to do with graphs at all, and yet can be solved using maxflow once again.\nSo with that said, let us get started with the problem for this module. This one is called BerSU Ball if I am pronouncing that right. This is from Codeforces, and if you look at the tutorial for this problem, it says that there are like 10,500 ways of solving this problem. And this is going to be one of them. Some of this story might remind you of a problem called stable matching, which we talked about way back when we were doing greedy algorithms. But this turns out to be a much simpler setting.\n(Refer Slide Time: 2:00)\n \nSo, let us take a look at the problem statement. So, we are given n boys and m girls, as part of the inputs. So, let us meet them and let us say that they look like this. What we are also given is their dancing skill levels. So, this is just a number that is associated with every person in the problem. So, let us denote these skill levels by these numbers in the red boxes. We are told that a boy and a girl are a ‘compatible dancing pair’ if their skill levels differ at most by one.\n(Refer Slide Time: 2:30)\n\nSo, let us figure out who the compatible dancing pairs are in our example here. Now, as you can imagine, this is going to be convenient to think of as a graph. So, let us imagine that all the boys and the girls that we have here are vertices of a graph. And the construction of the edges basically reflects the compatibility in the sense that was just defined a moment ago, where we said that a boy and a girl form a compatible dancing pair if their skill levels differ by at most one. So, you could pause the video here and try and enumerate all the compatible dancing pairs, or you could just follow along and verify that, hopefully, we have drawn these correctly. So, we are going to draw an edge between a pair of vertices corresponding to a boy and a girl, if and only if the numbers that are associated with them differ by at most one. So, these are going to be the edges, for our example here.\n(Refer Slide Time: 3:27)\n\nSo, that is the input, and our goal is to form as many pairs as we can for an upcoming event. So, notice that these pairs should be disjoint. So, they are all going to go to this event and be involved in simultaneous dances. So, it is going to be very awkward if you have the same boy or the same girl being involved in multiple pairs. So, that is your main constraint – that you want the pairs to be disjoint.\n(Refer Slide Time: 3:50)\n\nAnd once again, let us take a look at our example. So, here you can see that, well, the maximum number of pairs you can form is actually four because there are only four boys even though there are five girls. So, one of the girls is necessarily going to be left out. And you might wonder if it is actually possible to form four pairs.\nSo, take a moment here and see if you are able to form 4 disjoint pairs of boys and girls who are mutually compatible when it comes to dancing together. Alright. So, if you had a chance to think about it, you will probably find that there is at least one way of forming these pairs so that you actually get four pairs, and as we said, that is the best that we could hope for in this example. So, this is the optimal answer.\nYou could think about if there are other ways of forming these pairs. And it is probably an interesting question to think about, how many ways you can form these pairs. But that is a question for a different occasion. We are just going to focus on the problem of finding the maximum number of compatible disjoint pairs that we can form.\nSo, what we are going to do is, we are going to set up a flow network around this graph or based on this graph and we want to set it up in such a way that the maximum flow through the network corresponds to the answer that we are looking for, which is the maximum number of disjoint pairs, which I will henceforth refer to as a maximum matching because the language of graphs collection of disjoint edges is called a ‘matching.’\nSo, here is the flow network that we are going to set up. I am going to reveal this in a moment. So, if you want to play around with this and try to come up with your own construction, then feel free to take a pause here and come back when you are ready.\n(Refer Slide Time: 5:34)\n\nSo, we are going to work with the graph that we have just built up. But remember that flow networks are directed graphs, and we actually do want to orient these edges. Of course, we have said before that we could work with undirected graphs by modeling them as bi-directional edges, but in this example, we would not really want to do that.\nSo, we are going to take all the edges that we have between boys and girls and orient them so that every edge is going from a girl to a boy. So, they are all oriented from left to right. I do not know if the arrows are clearly visible on your screen, but if not then just keep in mind that, that is the direction that we have associated with these edges. Now, remember that every flow network has two special designated vertices, which we call the source and the sink.\nSo, let us introduce a source vertex. This is an extra artificial vertex on top of what we already have. And what we are going to do is make the source vertex adjacent to all the vertices that are representing the girls. Similarly, we are going to introduce a sink vertex and we are going to make all the vertices representing the boys adjacent to the sink vertex. So, that is going to be the structure of our flow network. But this does not complete the description of the flow network. You want to think for a moment about what information is missing.\nSo, if you recall a flow network was a directed graph with two special designated vertices called the source and the target. But also we had a capacity function. So, our description of this flow network will be complete once we specify capacities for all the edges out here. And this is where, as somebody who is modeling the network, we have full freedom to specify whatever capacities we want.\nAnd we want to engineer the capacities in such a way that a maximum flow through the network actually picks up the solution that we wanted to find for us. So, usually, whenever you are modeling any problem as a flow network, you can think of the capacities as an opportunity to encode, whatever constraints you are working with. So, remember that in this problem our goal is to find the largest collection of matching pairs between the girls and the boys.\nSo, in some sense, I can already anticipate that I want the flow to help me find a solution. So, for instance, if I am routing one unit of flow from the source to a particular girl and from there it has to go to one of the boys and it will finally end up at the target vertex, I do want to be sure that this flow is not something that asks me to either choose two boys for the same girl or ends up going to the same boys starting from two different girls on the left-hand side.\nSo, somehow my mindset is that that is something that should be prevented. So, a flow should not be allowed to behave in that way, (to be) to give me solutions that do not make sense. So, you can think about this question for a moment here: What sort of capacity should you associate with the edges so (that) the flow corresponds in a very natural way to a matching? So, take a pause here and come back once you have had a chance to think through this a bit.\n(Refer Slide Time: 8:55 and 9:15)\n \nAlright. So, here is what we are going to do. We are going to set the capacities of all the edges to one. I should mention that this is not necessarily the only way of doing it. I am just putting it this way because it is easy for me to state what we are going to do. You do have some flexibility in how you design the capacities. You could do it slightly differently and it would still work.\nBut what is really crucial is that all the edges that emanate from the source vertex and all the edges that land on the target vertex – these two sets of edges must have ‘unit’ capacity for this network, to do what we wanted to do. So, we will see exactly how that plays out in a moment. But before we get to that I want to detour and make a small remark about the nature of max flows in networks that have integer capacities because this is a fact that will be useful for our upcoming discussion.\n(Refer Slide Time: 9:43)\n\nSo, it turns out that if all capacities are integers, then you can always find a maximum flow, which associates an integral value to every edge. This is not very hard to see from the behavior of the Ford-Fulkerson algorithm that we discussed in the previous module. So, if all your capacities are integers, then notice that the bottleneck capacity will also be an integer in every iteration.\nSo, the amount of flow that you push in every iteration, the amount by which your max flow gets incremented in every iteration, is also an integer. So, you can formally prove this using induction on the number of iterations and so on. But hopefully, for now, you find it believable that, this statement is true. Notice that all of our capacities are unit capacities.\nSo, essentially when you are looking at an integral maxflow, that just means that every edge is either completely used by the flow or it is not used at all. So, there are no fractional flow values. There is no edge that has a flow of 0.5 passing through it. So, because of this, it is kind of convenient to really describe this flow because every edge is going to either be fully saturated by the flow or is going to be completely avoided by the flow.\nSo, saturated is a term that we use when the flow passing through the edges is equal to the capacity. Because the maxflow is integral and the capacities are one, we are in a situation where every edge that has a flow passing through it is in fact, saturated. And every other edge is basically not used by the flow at all, it does not have any flow passing through it.\n(Refer Slide Time: 11:13 and 12:47)\n \nSo, let us take a look at an example here. So, this is some flow that has been proposed. So, the blue edges are the saturated edges and the other edges are not used by the flow. Pause the video here for a moment and think about whether this could be a maximum flow or whether you can do better.\nAlright. So, one way to check if this is a maximum flow or not is to do what our algorithm would have done, which is to say that you compute the residual graph, which looks like this. Essentially every edge that had a flow going through it gets reversed and all the other edges remain as it is. I have not shown you here, the edges that have a residual capacity of 0 because those edges are effectively missing from the network. We never use them when we find an S-T path. So, this is what the residual graph looks like and the question you are interested in is whether there is an S-T path in this graph.\nSo, if you think about it for a bit you will discover that there is indeed at least one S-T path, and here is one that looks like this. It is been highlighted by the orange edges. So, what happens when you push a unit flow? So, remember that all the edges have unit capacity. So, your bottleneck capacity will also automatically be one. So, you are going to pass a unit flow through this S-T path. Notice that this path has one back edge. So, that essentially means that we are going to reverse our decision of using the edge between the third girl on the left and the first boy on the right.\nSo, we do not want to pass the flow through that edge anymore, and instead, we are going to pass a flow through these other two edges that you can see here on your screen. Now notice two things about this particular flow. First of all, it has a value of four, which seems to be a bit of a coincidence. Remember that when we were working on finding a maximum matching on the example on which this flow network is based, we found that the largest matching that we could find had four edges.\nSo, that is one thing. The other one is, that notice that this is also a maximum flow because if you look at for example all the edges that are incident on the target vertex, the total capacity of these edges is four. So, you cannot possibly have any flow that has a value that is greater than four. So, the maxflow in this network has a value of four, and it seems to coincide with the value of the maximum matching that we found earlier in the graph on which this flow network is based. It turns out that this fact is not a coincidence for this example, and it is actually true in general.\nNow before we talk about why these two values are equal, let us talk about how we can use the flow to obtain a matching in the graph that we originally had. So, to do that, what we are going to do is, reverse the process that we used to construct the flow network from the graph. So, now I want to go back to the graph.\n(Refer Slide Time: 14:06)\n \nSo, I am going to start off by throwing away the source and the target vertices. And in what remains I still see the edges that have been saturated by the flow. So, let us just focus on these edges and notice that these edges actually form a valid matching. So, once again this is no coincidence. The fact that – the edges between the boys and the girls (that are) saturated by any flow form a matching – is something that you can actually prove.\nSo, if you like, take a moment here to think about why this always turns out to be the case, and when you are back, we will continue our discussion and actually establish this as a fact. Alright. So, here is, what we want to claim. We want to claim that any flow of value k in this flow network corresponds to a ‘matching’ with k edges in the graph on which this network is based.\n(Refer Slide Time: 14:44 and 14:52)\n \nTo see this, notice that we had these edges from the source and the edges incident on the target, which had capacities of one each. So, if you focus on the set of edges that are saturated by the flow that goes between the boys and the girls, think about what would happen if those edges had a structure that did not look like a matching.\nSo, that would mean that you either have a situation where you have one girl who is matched with two boys or more. Or you have one boy who has been matched with two girls or more. In the language of graphs, you would say that there is a vertex in the left column, corresponding to the girls, that has a degree of two or more. Or you have a vertex in the right column, which corresponds to the boys, that has again degree two or more, among just the edges that have been saturated by the flow.\nBut notice that this is impossible because, for instance, suppose you had a vertex corresponding to a girl which had degree 2 among the edges saturated by the flow, then you violate the conservation constraint at this vertex. Because notice that the maximum amount of flow that can come into this vertex is one and that means that there is only one unit of flow that you can route out of this vertex.\nAnd remember that every edge that is being used by the flow, is fully saturated because that is the kind of flow that we are working with without loss of generality. Right. So, it is not that you have these two outgoing edges where you are going to split the flow half-and-half because that is just not the kind of flow that we are working with.\nA very similar argument holds if you have a vertex corresponding to a boy that has degree two among the saturated edges. So once again you will violate the conservation constraint. In this case, you have too much flow coming into the vertex and you cannot shake it off because the only edge that is outgoing from this vertex is to the target vertex and that has a capacity of one.\nSo, if you have an incoming flow that is greater than one, then it will necessarily violate the conservation constraint. So, this shows that if you have a flow of value k then you can actually use the flow to obtain a matching on ‘k’ edges as well, by simply looking at those edges between the boys and the girls that are saturated by the flow. It will necessarily have a matching structure.\n(Refer Slide Time: 17:13 and 17:23)\n \nOn the other hand, if somebody gives you a ‘matching’ in the graph that we started with, then you can actually use that matching to also construct a flow whose value is the same as the number of edges in the matching.\nTo see that this is true let us begin by considering a matching in the graph that we started with. Now recall how we built the flow network. We essentially built it on top of this graph. So we oriented all the edges of this graph and then we added a source and a target vertex and some additional edges. The point is that every edge that you see here is in one-one correspondence, in a very natural way, with some edge in the flow network. So, essentially let us find this matching in our flow network.\n(Refer Slide Time: 17:49)\n\nAnd let us begin by saturating these edges. So, I have defined a partial flow, where we have essentially taken the edges of the matching and we have decided to pass one unit of flow through these edges. Now as you can see this is not a valid flow yet because we are violating conservation constraints at both endpoints of these matching edges. So, take a moment here to think about, how you will fix this issue with this partial flow that we have built up so far. This is really a very natural thing that you can do. So, see if you can find it and come back when you are ready.\nAlright. So, to turn this into a valid flow what we are going to do is basically extend it in both directions. So, for every girl who has been matched by this matching, we are going to add a flow of one unit, from the source vertex to the vertex corresponding to the girls. So, we have a flow going through these edges here.\nAnd similarly, for every boy that is matched by the matching, we are going to push one unit of flow through the edge, which has its endpoints as the vertex corresponding to that boy, and the target vertex on the other hand. So, that is a flow going through all of these edges here. So, you can see that this is a perfectly valid flow. And its value is clearly equal to the number of matching edges that we started off with.\nSo, that is how you go from a ‘matching’ to a ‘flow.’ Given both of these statements, you can see why the value of the maximum flow in this network is equal to the size of a maximum matching in the graph that we started with. So, here is what our algorithm is going to do for this problem.\nIt is going to build the flow network and then return the maximum flow by invoking a flow algorithm. Notice that this may not be the most efficient way of finding a maximum matching in a bipartite graph. So, for instance, in SPOJ, there is a problem called fast matching and if you try to use this approach to solve that problem, then you will time out on some of the larger tests.\nSo, there are more fine-tuned maximum matching algorithms and you can find out more about them separately. But it turns out that in many situations if the constraints are reasonable, this is a perfectly valid way of finding a maximum matching. Just keep in mind that if your constraints are crazy, then this may not always work. Alright. So, what does the code look like?\n(Refer Slide Time: 20:00)\n\nIt is actually really simple. You just have to essentially bring in the information about the skill levels of the boys and the girls and then we initialize this max flow object with the number of vertices being the number of boys + the number of girls + 2 because we need those two extra source and target vertices. And then what we do is, basically go over all boy-girl pairs, check if their skill levels differ by at most one, and if they do, then we add an edge from the vertex corresponding to the girl to the vertex corresponding to the boy or the other way around – it does not really matter as long as you are consistent.\nSo at this point, we have built up the bulk of the graph, the middle part. Now we need to add the source and the target vertices. These have been implicitly added just because we have the correct number of vertices. What we really need to add to the system is the edges that are incident on the source and the target vertices.\n(Refer Slide Time: 20:55)\n\nSo, let us go ahead and add these remaining edges. Remember to set these capacities to one. This is really crucial for the algorithm to have the desired behavior. Once you are done with these steps, you have actually completed building out the flow network. Now all you have to do is compute the maxflow and return the value of the maxflow.\nSo, what we are doing here is invoking Edmonds-Karp, which is the function that computes the maxflow the one that we discussed in the first module. So, all that you have to do now is output the value that is returned by this function, and you are done. So, as you can see all the heavy lifting is really done by this function call. All you have to do is really construct the appropriate flow network.\nSo, this is true for most problems that are based on modeling some other problem as an instance of maxflow. The work is really around finding the right construction and convincing yourself to some extent that the construction appropriately captures whatever it is that you are trying to find. But once you have that figured out the implementation typically is quite straightforward, especially assuming that you already have access to the maxflow functions in advance.\nSo, that is about it for this particular module here. We are going to continue our conversation with one more example of maxflow modeling, for a problem that is called sports elimination. So, that is the final module for this week and I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec52.html",
    "href": "materials/cpnotes/Lec52.html",
    "title": "Introduction | Frogs 1 (AtCoder Educational DP Contest)",
    "section": "",
    "text": "Lecture - 52\nIntroduction | Frogs 1 (AtCoder Educational DP Contest)\nAll right. So, welcome back to the second segment of the first module in week 10. Let us continue from where we left off in the previous segment.\n(Refer Slide Time: 00:19)\n\nSo, if you recall, we were looking at this recursion tree that is generated by a recursive algorithm. And we concluded that this tree has an exponential number of nodes, leading to the conclusion that the algorithm that we just wrote has an exponential time complexity because the time complexity is proportional to the number of function calls made. And that is what is depicted in this recursion tree. That is about as far as we got last time.\nAnd what I asked you to do was to think about whether you can identify any redundancy of computation in this recursion tree, which will hopefully give us some way of saving some time. So, one thing that you may have noticed is that there are parts of this recursion tree that look exactly the same. In particular, for instance, if you look at this function call that is being made to 4 here, that looks rather a lot like the function call that was made to 4 earlier. And the information that we are getting out of these function calls is exactly the same.\nSo, this entire computation that is highlighted in orange is completely redundant because, by this time, you have already performed the exact same computations a few moments ago. When you went over the function calls that have been highlighted in yellow in this picture, there to the bottom left of your screen.\nSo, when you look at this picture, it seems like, we are being rather silly in redoing a lot of work that is already been done. So, the question to ask ourselves at this point is, is there any way that we can leverage the information that we have from computations that we have already done so that we do not have to do it again? And that is exactly the process or the strategy of memoization.\n(Refer Slide Time: 02:06)\n \n\nSo, essentially, we want to remember the work that we have done before so that we do not have to do it again. So, let us take a look at how this works. Essentially, we want to store the outcomes of these prior function calls, so that at any point in time, whenever we have a recursive call, what we can do is really examine, if there is a need to go down the recursive rabbit hole prompted by this call.\nThe way we do this is, (to) check if the information that we would get by performing the recursive computation is already available to us. If it is already available to us, then we avoid the recursive call altogether. If it is not available to us that means, we are doing this operation or we are doing this computation the first time and it is okay to actually invoke the recursion.\nSo, notice that overall your algorithm is trying to track N pieces of information, where N is the number of stones that are there in the input that you are working with. So, to implement this in your program, what you would typically do is, declare an array, or a list, or a vector of size N, and use that to actually store the output of the recursive calls as you go along. So, let us take a look at how this would actually pan out in your program.\n(Refer Slide Time: 03:20)\n\nSo, here is the code again, but now, it is fixed to account for memoization. And the difference between this and the recursive program that we saw earlier is so small that I would not be surprised if you did not even notice the difference from a quick glance. So, let me actually highlight the line that makes all the difference. It is this conditional statement here, which is basically saying, look, if you already know the answer, then you do not have to go through the process here. Okay. So, what we have done, behind the scenes in the sense that you do not see it on your screen right now, is we have initialized a memo array or a vector, where all the values by default are -1.\n-1 in this problem is essentially a way of saying, we do not know the answer yet. If you are working with a problem, where the value -1 has some meaning or significance, then that is not a good value to initialize your array with. Basically, use some number, which has nothing to do with your problem, so that you can really use it as a code for saying I do not know yet. So, coming back to our program, here is what the code is doing for you. It is saying, okay, we want to know the answer for N. The first thing we do is check if we know this answer already. So, if the array value at N is something other than -1, that means, well, that is a déjà vu situation. We have already been here, we know, what the answer is.\n(Refer Slide Time: 04:51)\n\nAnd we can simply return in this case. Okay. So, if it is not -1, notice that the code does not execute any of the recursive calls, it does not do any other work. It immediately returns the answer. On the other hand, if the array does report -1. That means that this is unknown territory, we do not know what is going on, and we do need to go down the recursion rabbit hole to figure out what the answer is going to be.\n(Refer Slide Time: 05:22 and 5:47)\n \nSo, with this revised version of the recursive algorithm, let us take a look at what is going on in the recursion tree. So, notice that all of these function calls that have been highlighted here, will actually not execute in terms of recursion, but they will immediately return the answer. Because at the time that these function calls happen, the same computation has already been performed before, and the memo array is actually going to report an actual answer.\nSo, (all of these) all of this work in the recursion tree, basically, does not happen and is avoided. And your recursion tree will now essentially look like a linear path. Notice that this is really the leftmost sequence of executions. And once all of those are complete, as you walk your way back up to the root of the tree, there will be function calls, but they will all return immediately.\n(Refer Slide Time: 06:16 and 06:57)\n \nSo, no new recursive instances will be spawned, and the total amount of work that is being done now is actually linear. So, I do hope that you find this as amazing as I do. I think a little bit of extra space and a couple of lines of code adjusted (for) can lead to really tremendous time savings. So, that is the impact of memoization.\nAnd whenever you come up with recursive solutions, do watch out for the potential to memoize. What you really want is a situation where there is a lot of redundant work, so that you can find ways of avoiding it and saving yourself some time. So, we will have more to say about general principles in just a bit, but while we are at it.\nLet us actually see how this algorithm plays out for the example that we started off with. So, we have the frog here, on the third stone, mainly because as we said for the first two stones we already know what the costs are going to be. These are the base cases. So, in the first stone, let me just recap that the cost we agreed would be 0. And on the second stone, the cost would simply be the absolute differences, the absolute difference between the heights of the first and the second stone. And in this example, that happens to be 20.\n(Refer Slide Time: 07:28)\n\nSo, let us actually go ahead and make a note of this in the recursion tree as well. So these are the values that are returned by these two bottoms most function calls, which is where the work happens directly, and there are no further calls. So, these values are reported and pushed upstream to the calling function, which is trying to figure out, what is the answer, when there are three stones in the picture.\nSo, at this point, remember we are asking ourselves, how did you end up on the third stone? There are two possibilities, either you came in from the second stone, and that jump would have cost you 50, or you came in from the first stone, and that jump would have cost you 30. So, the final answer is the better of the two options between 50+20 and 30+0.\n(Refer Slide Time: 08:16)\n \nSo, here 30+0 is the clear winner. So, we are going to report 30 back to the calling function, which is trying to figure out the answer, for when there are four stones.\n(Refer Slide Time: 08:23)\n  \n \nSo, here again, what we are going to ask ourselves is, where did you come from? Did you come from the third stone or the second one? If you came in from the third stone, then the cost of that jump would have been 50, and the total cost would be 50+30, which is 80, versus if you came in from the second stone, then the cost of that final jump would be 0, and that gets tagged on to 20, so 0+20 is 20. So, clearly, the better of the two options here between 80 versus 20 is 20. So, we are going to record that as our final answer at this stage.\n(Refer Slide Time: 09:05)\n  \nNow, let us go back to what is going on when we land up at the fifth stone. This is what we are trying to understand now, now that we have understood everything, up to the fourth one. So, how could you have come to stone number five? You could either come in from the fourth, which would have involved a cost of 50+20 to get to the fourth stone itself. So, that is 50+20, 70. Versus you could have come in from the third stone, and the cost of that jump would be 0. And the overall cost would be 30+0, which is 30.\n(Refer Slide Time: 09:40)\n  \n \nSo, you can see that 30 wins this round. And that is what we are going to keep track of as we move on to the final stone. And this is going to be our final answer. How did we land up at the final stone? Did we come from 5? In which case the last jump would have cost us 10 and the total cost would be 30+10, 40, or did we come from stone number 4? Where the cost of the final jump would already be 40 and 40+20, the total cost would have been 60.\n(Refer Slide Time: 10:15)\n\nSo, between 60 and 40, again, the winner is 40 and that is what we are going to report as the final answer. And we are pretty much done here because this is all that we have been asked to report the final cost of an optimal solution. But on the other hand, what if the problem also asked you to actually provide a sequence of jumps whose total cost matched the optimum that you are claiming? You might have already seen, as we worked through the example, a way to do this as well. So, all you would need to do is a little bit of extra bookkeeping to keep track of basically what drove your choices as you went along.\nSo, for instance, in the very last step, when we got to 40, we want to make sure we understand how we got to 40. So, the reason the answer was 40, was because we came in from stone number 5 with a cost of 10. And how did we get to stone number 5? Well, we got there from stone number 3 with a cost of 0. And how did we get to stone number 3? Well, we got there from stone number 1 with a cost of 30.\nSo, if you essentially just keep track of where you came from, by figuring out who won the comparison when you calculate the answer, just keep that extra piece of information. Then just like we often do by following parent pointers, you could essentially run a backtrace, to figure out, what choices led to this final conclusion.\nAnd of course, when you are sharing your answer, you typically want to reverse the order so that the jumps happen in the sequence that they are supposed to happen. So, I think it is a fun exercise to modify the program that we have here so that it outputs one of the optimal sequences.\nNotice that you are going to break ties arbitrarily, so which sequence you print, will depend on, how you have broken ties. But no matter which sequence you print, they will all be optimal. But your tie-breaking may be different from mine. So, the actual sequences we print may be different. And most judges, when they ask you for a sequence that is optimal, they will accept any valid sequence. So, they will typically run a check, to make sure that the cost of the sequence that you have printed actually matches the optimal cost and that is what they will care about.\nSometimes occasionally, you may have a requirement, which is along the lines of ‘print the lexicographically smallest optimal sequence.’ In this case, you have to fine-tune your tie-breaking, to prioritize the lexicographically better option at every step. So, these are some details that are worth keeping in mind.\nI should say that this is a common feature of dynamic programming-based approaches, which is that by doing just a little bit of extra work, in terms of tracking the choices that you are making as you go along, you will be able to output, not just the optimum value, but also an actual solution that witnesses that value. So, I think this is a good thing to practice and get used to. Some people call this running a backtrace on your DP, and essentially, it is something that is useful in the competitive programming context because you are often required to actually produce a solution.\nAnd just in case you are using dynamic programming-based approaches for solving real-world problems at work and so on, often, you are interested in an actual solution, not just a value. So, do keep that in mind, and let us move on to making some general remarks about how dynamic programming-based approaches typically work, summing up some of what we have seen even just through this very introductory example.\n(Refer Slide Time: 13:51 and 14:47)\n \nSo, you can broadly think of dynamic programming as being memoization on top of recursion. So, you come up with a recursive approach to solving your problem, and you make it efficient by memoizing it like we did. I would say that usually the memoization part, at least in terms of implementation, is usually routine. You just have to figure out how to allocate space to the answers that you are interested in and make sure that you just modify your recursive subroutine so that there is that initial check for whether we really need to do this or not. Okay.\nBut what enables you to do memoization is, coming up with a recursive algorithm that has enough redundancy built into it so that the memoization is eventually useful. So, usually, the heart of the problem is in coming up with a recursive approach to solving the problem. That is appropriate for memoization going forward.\nSo, to come up with a recursive solution, again, there is no formula and every problem is going to be different. But typically, the mindset, with which you want to think about recursive patterns, is to see how best you can break up your problem into natural sub-problems. And again, as you practice more and more problems, you will begin to get a sense of, how people typically chop up problems into smaller pieces.\nSometimes for array- or sequence-based problems, you are either looking to chop things off from the end or the beginning or even some subsection in the middle. Sometimes your pieces may have to be subsets of some collection of elements. If you are working with graphs, say, for instance, you are working with a tree, then natural subproblems are typically subtrees that you obtain when you delete some root vertex. So, you try to figure out the answer at all of these subtrees and then somehow see if you can piece them together.\nSo, normally when you are doing recursion with the hope of memoizing going forward, you want your recursive sub-instances to actually have enough overlap so that you can leverage that overlap to save yourself time. You also want the pieces to be useful in the sense that you want your answer to be in some way a function of the pieces that you develop. Like we did for the frog problem, the two pieces that we solved were directly helpful in finding our final answer.\nAnd we also had substantial overlap as we just saw and that helped us eliminate a lot of the exponential part of the search space. This is one of the reasons, why some people think of dynamic programming as being essentially clever Brute-Force because when you first write own your recursive approach, it is practically a Brute-Force approach. It is exhaustive, and its correctness is easy to prove because it is exhaustive. But then after that, you take a closer look and you identify all of this redundancy and you memoize and that is going to save you a whole lot of time.\n(Refer Slide Time: 16:48)\n\nSo, this process of doing dynamic programming is usually called top-down dynamic programming, which is essentially you start by solving the problem at the top. That is the original problem. So, you start off by invoking solve of n or something like this. And this is essentially recursion. But we save the day with the modification that allows us to save time by using space, essentially.\nSo, when you write your dynamic programming solutions in this style, one advantage is that you are essentially building off of the recursive paradigm in a small way. So, it is really your recursive code with some small but important tweaks. So, if you are somebody who is already used to writing recursive programs then there is not much additional work to do to elevate it to the status of being an efficient dynamic programming-based solution.\nAlso, the other nice thing is that you only compute what you need based on the recursive calls that actually happen. You will probably appreciate this more when you see the contrast with the bottom-up approach, which is something that we are going to discuss next. And I think one of the reasons it is worth knowing a different way of really implementing the same thing, is because the other style which is the bottom-up style is sometimes cleaner from the point of view of memory optimizations.\nSo, if you wanted to save some space, then it is sometimes easier to do when you visualize this whole thing as a table that you are filling out, as opposed to this stack of recursive calls that are being made and that are doing their thing. They are really doing the same thing behind the scenes. It is just a different way of implementing the same idea.\nSo, we are going to continue this conversation in the next module, where we look at a different problem and we are going to implement it using the so-called bottom-up approach. And I would suggest that for both problems, you do the implementation in the other style, the one that has not been given just to get some practice. I think it is a good idea to be flexible about which style you use, because, in certain situations, one may have a small advantage over the other.\nAlthough it is true that most people have sort of their preferred default styles when it comes to dynamic programming. And they would only switch if there was a specific need to switch from the point of view of a certain kind of optimization and so on. So, as I just said before, I think it is a good idea to at least be aware of both the styles and be reasonably comfortable implementing a given solution in either of these styles because that may be something that is useful in a specific situation.\nHaving said that in the early stages, most elementary dynamic programming-based problems are such that this choice should not really matter. So, if you find one style much more intuitive or natural than the other one. It is perfectly fine to just stick to that for now. Let us continue this conversation in the next module, where we will use another introductory example to exemplify the style of bottom-up dynamic programming!"
  },
  {
    "objectID": "materials/cpnotes/Lec42.html",
    "href": "materials/cpnotes/Lec42.html",
    "title": "Minimum Spanning Trees - Module 4 (Island Hopping)",
    "section": "",
    "text": "Lecture - 42\nMinimum Spanning Trees - Module 4 (Island Hopping)\n(Refer Slide Time: 00:12)\n\nWelcome back to the fourth and the final module in week 7 of Getting Started with Competitive Programming. So, we have been talking about minimum spanning trees. And in this final module, I want to talk about a problem called ‘island hopping,’ which was actually the ICPC World Finals problem from back in 2002. And to practice, you can find this problem on the UVA platform, the problem ID is 1013.\nSo, in the first module, I remarked that there are two kinds of MST problems that you are likely to encounter. One is where even recognizing the graph abstraction is not obvious. And seeing that what you are looking for is an MST is really the bulk of the work. Once you have figured out that, that is what needs to be done, doing it is actually pretty straightforward. And you can simply use the algorithms that you have learned quite directly.\nOn the other hand, the other kinds of problems are where the fact that it is an MST (the fact that there is a graph underlying the story) is reasonably transparent and obvious. But what you are looking for may not exactly be MST, but some quantity that is related to the MST in some way. So, you might need to tweak the algorithms that you know a little bit to get to the answer you want. So, this problem falls somewhat in the second category.\nSo, I think once you go through the problem statement, you will realize that what you are looking for is definitely a spanning tree of some sort. But the objective that you are optimizing for, on top of minimizing the cost of the spanning tree is also something else. And that is what needs to be figured out carefully.\nOnce you figure it out, the tweak you need to make to your MST algorithm is fairly straightforward. But just understanding what needs to be done – I think that is the crux of this problem that we are going to discuss now. So, as always, let us start with the problem statement. This one has a bit of a story, so I will just walk you through it.\n(Refer Slide Time: 02:14 & 02:24)\n \nWe are told that the company Pacific Island Net, PIN for short, has identified several small island groups in the Pacific that do not have a fast internet connection.\nSo, PIN plans to tap into this potential market by offering internet service to the island inhabitants. Each group of islands already has a deep-sea cable that connects the main island to the closest internet hub and the mainland in America, Australia, or Asia. All that remains to be done is to connect the islands in a group to each other.\nAnd you must write a program to help them determine a connection procedure. So, it already feels like we need to connect a bunch of islands within each other. And it seems like this is already feeling like some sort of a spanning tree problem. Let us move on.\n(Refer Slide Time: 03:01 & 03:21)\n \nFor each island, we are given the position of its router and the number of island inhabitants. You might be wondering, why is the number of Island inhabitants relevant, and we are going to get to that in a moment. In the figure that will come up now (this is a figure from the problem statement), the dark dots are the routers, and the numbers are the number of inhabitants.\nSo, here is the example that has been given to us. So, these dark dots are actually specified in the input as XY coordinates. So, you literally know where the routers are placed. And this information actually describes all your edge weights implicitly. So, the graph that we are looking at is really a complete graph. And between any pair of routers, the weight of the edge that connects them is their Euclidean distance in the plane.\nSo, you are going to have to compute that as you go along. So, this is in fact the second problem this week where we are working with a complete graph but unlike cherries mesh where the number of vertices could be as large as 105, here we are given that our graph has at most 50 vertices at a time. So, having to actually compute all pairs of edge weights is not going to be problematic in terms of the constraints.\n(Refer Slide Time: 04:17 & 04:36)\n \nOkay. So, continuing we are told that PIN will build connections between pairs of routers such that each router has a path to the main island. So, the main island is a specific special Island. And we want everybody to ultimately get connected to it, either directly or indirectly.\nNow, PIN has decided to build the network such that the total amount of cable used is minimal. So, the total amount of cable is just going to be equal to the Euclidean distances between the corresponding routers. Under this restriction, there may be several optimal networks and it does not matter to PIN which of these optimal networks is built. So, essentially, you can probably already guess that we want to build a minimum spanning tree on the graph that we have just described.\nTo recap what the graph is, every router is a vertex, and the cost of the edge between any pair of routers corresponds to the Euclidean distance between them. And what you want is for every router to be connected to some main island, which is a specific special router. And this is just going to correspond to building out a spanning tree that has the minimum cost. So, so far, this is sounding like a pretty standard minimum spanning tree problem. But we do have a couple of more things to worry about. So, let us continue reading the problem statement.\nWe told that PIN is interested in the average time required for new customers to access the internet based on the assumption that construction on all cable links in the network begins at the same time.\n(Refer Slide Time: 05:43 & 05:56)\n \nSo, in particular, shorter cable links get completed before the longer links because the construction of the cable links happens at a uniform speed. So, in particular, if you have a path from any vertex to the main island, then the cost of that path, in some sense, is going to correspond to the longest edge on that path because that is the one that will take the longest to complete.\n(Refer Slide Time: 06:23 & 08:00)\n \nSo, in particular, an island will have internet access as soon as there is a path from the island to the main island along completed cable links. And now you can see how the island populations come into play. So, we are told that if ‘mi’ is the number of inhabitants of the ith island and ‘ti’ is the time when this island gets connected to the internet, then the average connection time, overall, is the sum of the products, ti * mi normalized by the total population across all the islands.\nSo, this is in fact the quantity that you have to output. So, for each island, you want to somehow keep track of what is its connection time. So, if you can figure it out ti for every Island corresponding to your spanning tree, then it is just a matter of computing this expression, which is straightforward to do. Now, one question that might occur to you is well, should the spanning-tree be optimized to optimize the average time?\nWell, it turns out that every spanning tree that is optimal will have the same average connection time. Let me see if I can convey some intuition for why this happens. Let us break this discussion up into two parts. First, let me assume that all the edge weights are distinct. In this case, there is only one minimum spanning tree. And the task really boils down to making sure that we correctly capture the information about the tis. So, let us just play out a run of Kruskal’s algorithm on some graph, which has the property that all the edge weights are distinct.\nIn particular, let us say that this is some intermediate stage of Kruskal’s algorithm. The vertex that is marked red is the main island it is the special source vertex. And now, let us say that in the present step of Kruskal’s algorithm, we happen to add this edge to our spanning forest. Now notice that this is going to be the first time that these two verses, here in green, are getting connected to the component that has the special vertex.\nSo, this is the time when these islands, if you like, are getting connected to the internet. And this is the time to make a record of ‘ti.’ Now what is ‘ti?’ It is the most expensive edge on the path to the red vertex. But this expensive edge must be the dotted green edge because we know that all the edges that were added before this, were actually cheaper edges. Because that is just the sequence in which Kruskal’s algorithm is going to be adding edges to the spanning forest.\nAnd since all the edge weights are distinct, we know that this is in fact strictly the heaviest edge on the path. So, for both of these vertices, we just make a record of the weight of this dotted green edge as being the value for ‘ti’ for both of these islands. So, that is how you would keep track of the ti. And now let me try and convince you that whenever ties are to be broken in Kruskal’s algorithm, it does not really matter how you break them. You will end up getting the same ‘ti’ values for all the islands.\n(Refer Slide Time: 09:38 & 09:53)\n \nSo, just to get some intuition for this, let us consider what happens in what I like to think of as the first phase of Kruskal’s algorithm, which is to say let us think about what happens for as long as Kruskal’s algorithm is processing all the edges that have the minimum weight.\nSo, let us say that there are a bunch of edges that all have the smallest weight, and let us say these are all of those edges. Now, once your algorithm is done processing all of these edges in the edge list, you will end up with some spanning forest of these edges. Right. Now notice that no matter which spanning forest you end up with, the set of vertices, which is connected to the main island remains the same, and all of them will actually have the same ‘ti’ value. I hope that makes sense.\nThey will all have the same ‘ti’ value because they are all connected to the main vertex via paths that have uniform edge weights. So, the maximum connection time is just going to be that edge weight. Remember that all of these cables are being built simultaneously. So, that is what is going to happen at the end of the first phase. Now let us bring in all the edges that have the second minimum edge weight. Let us say that these are the blue edges. And now, once again, notice here that there could be different spanning forests that you get depending on the sequence in which these edges were processed. But once again, remember that what is true is that in all of these spanning forests, the set of vertices that get connected to the main island by the time the second phase is over, is exactly the same. And all of them have the same ‘ti’ value.\nAnd in this case, the ‘ti’ value for these islands that newly got connected to the main island (that were not connected at the end of the previous phase) is going to be the weight of the blue edges. And you could keep doing this till you are done, the same argument would apply. So, no matter which spanning tree you get at the end, structurally, they could be different, but the ‘ti’ values are all going to be the same. So, now hopefully, the algorithmic idea is clear.\nWe just run Kruskal’s algorithm and every time we add a safe edge to our spanning forest, we check if the safe edge is connecting some component to the component that contains the special source vertex. If that is happening, then the ti values for all the vertices on this component should get updated to the cost or the weight of this edge. That is how you keep track of the tis. And once you are done, you just have to compute the average connection time and output it. So, now with that being said, we can take a look at the implementation. As usual, I am going to skip the parts about taking input and writing output because they are fairly standard for this problem. One small thing is that the output format requires you to leave an extra blank line at the end of every test case. So, if you forget to do this, as I did, you will end up getting a presentation error message from the UVA judge.\nSo, if that is what is happening, and you are puzzled by it, just double-check that your output format exactly matches their required specification. Other than this, I do not think there is anything special to watch out for. So, I really focus on just the key algorithmic part of the code. If you want the rest of it, the input-output or the UnionFind class, then you can always look up the full code in the repository, which has been linked to in the description of this video. Alright.\n(Refer Slide Time: 13:17 & 15:01)\n \nSo, for each test case, what we are given is the x y coordinates of the locations of all the routers as a list. And we are also given the number of inhabitants of the corresponding island. So, we, of course, take in all this information, but we now have to explicitly build the graph that is implicit in all of this data. So, what we are doing is storing the graph as a list of edges. And remember to clear out your edge list for every fresh test case.\nAnd then what we want to do is build out a complete graph here. So, that is exactly what is being done here. You have this nested ‘for’ loop that essentially goes over all ordered pairs ‘ij.’ Notice that this is an undirected graph. So, the distances from ‘i’ to ‘j’ will be the same as the ones from ‘j’ to ‘i’ and you will never need to consider these edges twice. So, it is enough to just keep track of these ordered pairs here. Now the weight of the edge from ‘i’ to ‘j’ is the Euclidean distance between these two vertices.\nSo, that is something that we can calculate using the built-in ‘hypot’ function, which I presume is short for the hypotenuse. What this function will output is the square root of the sum of the squares of the two numbers that it takes as input, which of course, you can write out as an explicit expression if you so prefer. But this is just a cool shortcut, which I thought was worth sharing for this problem.\nOnce you have computed the weight, you, of course, can now add this edge with its weight to the edge list. And this is essentially the process of building up the graph. As always, because we are going to do Kruskal’s algorithm, we sort this list of edges as the first step and then we declare the UnionFind data structure.\nAnd we are going to have a couple of weight vectors. In one, we are going to try and keep track of the cumulative populations of all the islands that belong to a particular component. So, the root vertex of any component, or, in some sense, the element that corresponds to the representative element of the set carries the information for the total population of all the islands that belong to that set.\nThe reason for doing this is that remember we said that when one component gets connected to the component that has the main island, then all of these islands experience the same ‘ti’ value. So, we can directly multiply ‘ti’ with the sum of these populations. So, it is just useful to keep track of the sum in the element that is representative of this collection of islands for this component. So, that is what we are going to be doing with weight 2.\nSo, we are going to modify the union function in the UnionFind data structure so that whenever you take the union of two sets, the weight two value of the parent is going to be incremented with the value of the weight of the incoming component. So, that is a minor modification that you need to make in the UnionFind class. I am not going to show it here explicitly. But once again, you can look at the code to see how it works.\nWe are also using the weight array to keep track of the sizes of the components that we are building. This will allow us to do some simple union by size heuristics while merging two components. So, again, you can see how that comes in useful in the union function. Alright. Now finally, for the fun part, how do we modify the standard Kruskal’s algorithm so that we can also keep track of the tis? So, notice that we are processing the edge UV right now with weight W.\nAnd the first check is the standard check for whether UV is a safe edge to add or not. So, if it is not a safe edge, meaning it has both of its endpoints in the same component, we anyway ignore it and move on just like we would do in Kruskal’s algorithm. On the other hand, if it is a safe edge, and we are going to add it, the thing that we need to check is if either of these components is the special component, which has the main island in it.\nSo, those are the two ‘if’ conditions that you see here. So, if U has the main island in it, or V has the main island in it, then we have some work to do. So, 0 here, by the way, is the label of the main island. So, let us say that U and 0 belong to the same component. This means that currently, you are merging the component that contains V with the component that contains the main island.\nThat means that every vertex in the component that V belongs to is, at this point getting connected to the internet for the first time, and all of their ‘ti’ values can be updated to the weight of the edge that we are currently processing. In other words, what this means is that to the numerator of our expression, we should be adding the value of ti times the total number of people who inhabit all of the islands in the component of V.\nBut notice that that is exactly the value that we are storing in weight 2 of the parent or the representative element that the set belongs to. So, that is the first term in this expression here. So, we are pulling out with weight 2 of UF a fine set of V, we really pulling out the total number of inhabitants in all the islands that belong to the component that V belongs to. And now we are multiplying this by the weight of the edge that is currently being added because this is going to be all of their tis.\nSo, that is what we do if U contains the main island. On the other hand, if V contains the main island, then we do the same thing. But just with the roles of U and V swapped. So, hopefully, these two conditions make sense. Of course, it is possible that this is a boring update in the sense that it merges two components, neither of which contain the main island. In this case, notice that there is no work to be done. And the flow of control will simply skip both of these conditions here.\nNo matter what the scenario, you do want to physically merge these components, and that is what the union operation in the last line of this block will do for you. So, that is pretty much the whole algorithm. What you want to do at the very end is make sure that you print the value of the sum divided by ‘div,’ which is declared on the third line that you see on your screen right now; ‘div’ essentially is the total number of inhabitants across all the islands.\nSo, sum divided by div is what you want to finally output, and make sure that in terms of formatting, you are restricting yourself only to the first two decimal places. And once again, do remember to print an extra blank line of output after you have actually produced your answer. Otherwise, you will end up getting some kind of presentation error. One more minor point of detail is that when you are recording the weights, remember that these are not going to be integer weights. You are taking the square root of the sum of two squares. This is the Euclidean distance between arbitrary coordinates.\nSo, you want to make sure that the weight component in your edge list is declared as a double. Okay. So, if you declare it as an integer, you will end up getting only approximate counts for the distances, and your final answer will be off by quite a bit. So, that is one more small detail to take care of, especially if you are going to use the standard templates for edge lists and so on, that we have been using. It is easy to forget that we typically declare the edge list to be a tuple of three integers. So, make sure that that first integer is actually swapped out with a double.\nAlright. So, that is, I think, pretty much everything I had to say about this ‘island hopping’ problem. I thought it was a pretty cool problem. And despite sounding a bit complicated at first, I think it has this really elegant implementation, which is not very far off from the algorithms that we have learned this week. So, I hope that everything made sense.\nBut as usual, if not, please feel free to drop your comments or questions on either the Discord channel if you are watching this during an active run of the course, or please feel free to leave your questions as a comment on this video and we will be sure to get back to you. So, thanks so much for watching. With this, we do come to the end of week 7 and our discussion of minimum spanning trees.\nWe will be back next week with a new topic. In particular, we will be talking about network flows, which is a whole lot of fun as well. So, I look forward to seeing you back then. And once again, thanks for watching and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec43.html",
    "href": "materials/cpnotes/Lec43.html",
    "title": "Network Flows - Module 1 (Introduction)",
    "section": "",
    "text": "Lecture - 43\nNetwork Flows - Module 1 (Introduction)\n(Refer Slide Time: 0:11)\n\nWelcome to the eighth week of ‘Getting Started with Competitive Programming.’ For this week and the next, we are going to be focused on ‘network flow,’ which is our last major topic in the context of graph algorithms. If you are seeing the flow problem for the first time, then it may strike you as a really specific problem. And you may wonder if it is worth all the trouble to just learn one specific problem.\nSo, my hope is that through examples that we talk about this week and the next you will also see why it is not just this one problem but a really powerful technique in the sense that there can be so many other problems, which may not look like they have anything to do with flows and in fact they may not even look like they have anything to do with graphs, but they can still be in some sense modeled or converted as an instance of the flow problem and then everything that you have learned here will become really relevant.\nSo, in this module, we are going to start off by just setting up the problem introducing you to what the optimization goals are, and also describing one particularly popular solution to the problem, which we will implement in the context of a UVa problem called ‘internet bandwidth,’ which really very directly asks you to solve an instance of maximum flow.\nThere is not much going on here in terms of disguise. It is a pretty routine maximum flow problem. But the good thing is that it will give us an opportunity to test the correctness of our implementation. So, with that said let us get started. So, before giving you a bunch of formal definitions, let me begin with a story that will hopefully illustrate the major aspects of the flow problem, and then we will get to set it up in a more precise way.\n(Refer Slide Time: 1:55)\n  \nSo, let us say that we live in a city where there is a factory, and there is a shop, and the factory needs to send materials to the shop on a fairly regular basis. The way it has to do this is, by using the road network in the city and let us say that it looks something like this. So, there are four other, sort of, locations, and these locations are connected by one-way roads with directions specified by the arrows and the presence of the roads indicated by the edges that connect these locations.\nSo, as you can see, there is a truck that is waiting in the parking lot of the factory, and what it would normally do is just, you know, take up a path from the factory to the shop and perhaps find its way back. If you wanted to find, in some sense, the shortest path, if you have the length of the roads at hand, then you already know how to do this based on our discussions before about the shortest path problem and so on.\nLet us now imagine that sending one truck across is not really enough. A lot of supplies need to be sent. And they only fit in across multiple trucks, which need to get simultaneously to the destination.\n(Refer Slide Time: 2:46)\n \nSo, let us say that we now have three trucks and the drivers are friends and they just want to go through a common route. So, they all go a particular way that they like which just happens to be different from the one that we saw before. As you can see there are multiple ways of getting from the factory to the shop. And as of now, all of these roads are completely open and fully available to us. So, using any of these paths, from the shop to the factory would be perfectly fine.\nLet us say that at some point we have some construction work going on, on this road from C to B, because of which we are told that you cannot have more than one truck passing through this road at a time. Okay. So, this means that what we just did – have all the ‘three trucks’ that we have, use this road simultaneously – is no longer possible.\nAnd you should also imagine that these trucks are continuously moving. So you cannot say that, oh, I will have the first truck first take up the road and I will keep the other two waiting at C, and once the first truck has reached B, then I will send the second one. So, that is something that we do not really allow. You have to think of all the movement that happens across the road as being, in some sense, simultaneous. Or the other way to think about it is that the trucks are not going to wait. So, they are not permitted to actually stand at a particular location.\nSo, whatever comes into a particular vertex, has to immediately move out, along one of the outgoing edges from that vertex. Okay. But it is just this one road that is constrained, so in fact, we can still continue to send our trucks across other parts. And even if for some reason this was our lucky road and we want to make sure that we send at least one truck across this road, it is still okay because there are a few other options that are still available to us.\nSo, for instance, here we are sending even a collection of 5 trucks, by just exploiting the upper and the lower paths that are still available in an unconstrained sort of fashion. But let us say, a few days go along and now one of the other roads also becomes constrained in terms of how much traffic it can handle.\n(Refer Slide Time: 5:10)\n\nAnd let us say this keeps happening to the point where you are given numbers for every road in the network. And you are told that look this road can only handle so much traffic at a time. And now you are just back to the drawing board and you are trying to figure out, what is the maximum number of trucks that I can send simultaneously from the factory to the shop.\nIn fact just by looking at these numbers, can you come up with a quick upper bound on the maximum number of traffic that you can send from the factory to the shop? So for instance, like before, is it possible to send 5 trucks or 4 or 3? Just think about that for a moment and come back when you are ready. Alright. So, hopefully, you had a chance to think about this for a minute. You might have thought that, for example, if you look at the roads that are going out of S, they have capacities of 9 and 7. So, it is certainly not possible to send out more than 16 trucks at a time.\nBy similar logic, you may have observed that the two edges that come into the shop, which are the only two possible ways of reaching the shop, have capacities 2 and 3, which means that no matter what we do we will not be able to send more than 5 trucks at a time. So, of course, 5 is more informative than 16, so if you discovered that then that is definitely an improvement.\nBut if you looked at the numbers a little bit more, you may have observed that any way of going from the shop, from the factory to the shop, irrespective of how you choose to do it, you cannot avoid these 3 edges that are in the middle, which all have a constraint of one truck at a time. So, these edges are the edges from A to B, from C to B, and from C to D. There is no path from the factory to the shop that does not use one of these edges.\nSo, at any given point of time, let us say, if you are able to send 4 trucks simultaneously, then by the ‘pigeon hole principle,’ you must be sending, at least, two trucks on one of these roads. But then that is a violation of the capacity constraints that we are working with. So if we want to respect these numbers that are there alongside the roads, then well the maximum number of trucks that we can send across this network is certainly at most 3.\nAnd you can probably figure out that this bound is tight in the sense that you can actually find a way of sending 3 trucks across this network without encountering a problem. Notice that when you do come up with a way of doing this, there are going to be at least 3 but very likely 4 edges that you are using to their limit, in the sense that the number of trucks that you are sending across these edges is actually equal to the capacity of the road that they are traveling on.\nSo, in some sense, you can think of these edges as being saturated or as being tight. Different people use different terms to describe this situation, where a certain edge in the network is being completely used up to the brim. Okay. So hopefully, this setting gave you some intuition for the sort of thing that we want to do.\n(Refer Slide Time: 8:10 & 10:16)\n \nSo, let me now introduce the formal definition of a flow network. So, a flow network is simply a directed graph, which has two special vertices, which are called the source and the target. They are often denoted S and T. You can typically assume that the source is a vertex that has in-degree 0, which is to say that all the edges incident on the source, are going out of it. And you can also assume that the target is a vertex that has out-degree 0, which is to say that all the vertices incident on T, are in fact incoming edges, they are coming into T.\nSome people like to refer to this target vertex T as the destination or the sink vertex. So, you will often hear about a source and a sink in a flow network. So, it does not really matter which words you choose to use as long as you know what they mean. Now, apart from specifying these two special vertices, we are also given a ‘capacity’ function, which you can think of as a way of modeling the numbers that we just discussed in the example that we talked about earlier.\nSo, a capacity function simply assigns a non-negative number to every edge in the graph. And you want to allow for the possibility of assigning a so-called infinite capacity to your edges as well if you need to. That is just a way of modeling the idea that some edges do not even have a capacity constraint as such. You can pass as much flow through them as you want.\nNow, even though we have not formally defined what a flow is, hopefully, based on the discussion we have had so far, you know what I mean in an intuitive sense. Now in terms of, where these numbers come from, they could be real numbers. But often based on your application, they could just be integers.\nSo, you have to worry about this, when you have to declare the type of array that is going to store the capacity information. So, just remember to watch out that for a bit. We are going to usually default to integer capacities because for most applications that is, kind of, enough. But just do watch out for scenarios that may be different from this default. Alright. So, this is the input. This is what a flow network is. This is what is given to us.\nNow let us talk about what a flow actually is. So, a flow is also an assignment of numbers to the edges of a flow network, but unlike capacities, for instance, we do not really require these numbers to be non-negative. And we do require them to respect certain constraints. Okay. So, first of all, our concept of a flow needs to model this idea of things not waiting at the junctures.\nRemember when we were talking about having trucks move from the factory to the shop, we said that trucks are not going to wait around at the intersections. So, this idea is captured by what we call a conservation constraint, which roughly speaking says that all the flow that comes into a vertex must also leave that vertex. This is going to be true for all vertices, other than the specially designated source and target vertices.\nSo, what we want is that if we add up all the flow that comes into a vertex, which is the term that you see on the left-hand side of this equation, so, this is basically a sum over all the in neighbors of the vertex v and we are looking at all the flow that is on those edges, that must equal the total amount of flow that is going out of the vertex v, which is to say that this is now a sum over all the out neighbors of v. And we are basically adding up all the flow that has been assigned to all of these out edges.\n(Refer Slide Time: 11:41, 12:16 & 12:51)\n  \nSo, just to visualize this constraint here is a quick picture. So, we have a flow network here. The capacities have not been explicitly mentioned. But if you look at vertex A, then the edges of interest are marked in blue and red. And what we want is that whenever we assign a flow, we would want the total amount of flow on the blue edges to equal the total amount of flow on the pink edge. So, in this case, there is just one out-neighbor. In general, there could be more. And we just want all of these numbers to tally up.\nThe other thing that we are interested in is of course the role of the capacity function. So, we say that a flow is feasible, if it respects the capacity constraints. So, in particular, what we want is that for every edge, the flow that we assign to that edge must be, at most, the given capacity of that edge. Okay. So, that what a valid flow is, it is an assignment of flow values to every edge that respects conservation constraints on every vertex other than the source and the target, and respects capacity constraints on every edge.\nNow what is the optimization objective here? Well, in some sense we want to maximize the flow that we can pass through this network. Well, what does it mean to maximize the flow? What is the value of a flow?\nWell, one way of thinking about the value of the flow, if you go back to the example with the factory and the shop, is essentially how much material was the shop able to receive or how much material was the factory able to push out.\nIt turns out that these two quantities are actually always going to be the same if you are working with a valid flow. Intuitively the reason is that everything that gets out of the factory because there is no possibility of getting stuck at intersections, all of that material must move through the network and is compelled to really come to a halt at the target which is the shop.\nSo that is an intuitive way of imagining why these two quantities must be the same, but let us just look at it in a little more precise sort of language.\n(Refer Slide Time: 13:49 & 14:04)\n \nSo, in particular I am going to say that the value of a flow is just the total amount of flow that is coming out of the source. So, we sum the values of the flow on the edges that are incident to the source vertex.\nAnd what I was just saying is that this is the same as talking about the amount of flow that ends up at the target vertex. So, if we were to sum the flows on all the edges that are incident to the target, this would be the same thing.\n(Refer Slide Time: 14:18, 14:38 & 14:57)\n  \nTo see why this is the case, let us just look at this quantity, which is the sum of all the flows and all the edges written out twice and let us say we subtract one from the other then, of course, since we are subtracting two expressions which are exactly the same, the sum is 0. But let us look at the sum a little more closely. Notice that every edge is incoming for some vertex and outgoing for some vertex. So, every edge is incident on exactly two vertices. And from the point of view of one of these vertices, this is an out edge and from the point of view of the other vertex this is an incoming edge.\nSo basically, what we do is, let us just mark all the edges that are incoming on the vertex ‘u’ and mark all the edges that are outgoing for a vertex ‘u.’ Let us do this separately, for every vertex ‘u’ other than the source and the target. So, when you do this for a specific vertex, when you identify all the numbers corresponding to the flows on the edges incoming to that vertex, and all the edges that are outgoing, well, you will zone in on a subset of numbers which will essentially cancel out because of the fact that this is a flow and it respects the conservation law.\n(Refer Slide Time: 15:42)\n \nSo, these sets of numbers, will just keep cancelling out for every vertex that you consider. And once all the cancellations are done, what you will be left with, is the flow into the sink minus the flow out of the source. But now remember that we started with an expression that was equal to 0. So, this gives us the claim that the flow that comes into the sink or the target vertex is the same as the flow that got out of the source.\nSo, this is the quantity that we are looking to minimize. We are trying to find a maximum flow, a flow that maximizes its value, the value being how much were you able to push out of the source or equivalently, how much were you able to accumulate at the target. Alright. So, that is the goal and what we are going to do in the next segment of this module is to try and come up with an algorithm that actually finds the maximum flow.\nJust to leave you with something to think about, before you come back, let me propose a natural greedy algorithm for maximizing the flow. Remember that we are interested in getting materials across from the source to the target.\n(Refer Slide Time: 16:42 & 19:04)\n \nLet us just go back to the example that we were working with, with the factory and the shop. So, let me just try and see if I can find a path from the factory to the shop. So, for instance, here is a path which is highlighted in yellow and for these edges, I have also jotted down the capacities of these edges for you.\nSo, if you were the manager at the factory and you are considering this particular route to the shop, how many trucks do you think you would be able to send across this particular path? Well, you have probably observed that although the first road on this path can accommodate as many as nine trucks.\nIf you try to send 9 trucks, they would only be able to go as far as B and then after that seven of them would not know what to do because only two of them would be allowed to pass through. And since you know that you cannot have things waiting at interim locations, you know that nine is definitely not feasible. In fact no number larger than 2 is going to be feasible because that is, in some sense, the weakest link in this chain.\nSo, here of course we have assumed also that there is no pre-existing flow and these are the original capacities. In general you might be in a situation, where you have already designated a plan where some trucks may already be using certain edges, in which case you will have to work with the remaining capacity as opposed to the original capacity. But let us not worry about that for now.\nLet us just imagine that we are at the beginning of the process, where the full capacity is available to us. And in this setting, and also more generally, the idea that is worth remembering is that whenever you are thinking about pushing flow along a path, you have to worry about what we normally refer to as the ‘bottleneck’ edge, which is the edge that has the lowest capacity. Because this is what is going to determine the maximum amount of flow that you can actually push along this path.\nSo, applying this general principle to this particular example, we can conclude once again that the maximum amount of flow that you can push through this particular path is two units. So you can plan to send two trucks along this path, which means that one way of remembering that this is something that we decided to do is by adjusting the capacities to reflect our decision.\nSo, in particular, let us reduce all the capacities of these edges by two units, so that we know that, that is what this capacity was reserved for. So, at this point, the last edge on this path is as good as gone. It is a 0 capacity edge. And we will never be able to use it.\n(Refer Slide Time: 19:23)\n\nSo, it makes sense to go ahead and actually delete this edge. And now we could basically do the same thing. We could find a path from S to T, once again, in this graph with the adjusted capacities. And we could again determine the bottleneck capacity on that path and determine that, that is the amount of flow that we could push along this new path.\nWe could again adjust the capacities and we could keep doing this. At some point we are going to get stuck. And that is going to happen when you can no longer reach D from S. So, when S and T are disconnected from each other. That is when we can no longer continue to increment our flow, as I was just describing.\nNotice that you will get stuck at some point, you cannot go on forever. And the reason for that is that in every iteration, you are strictly increasing the value of the flow that you are working with. So, the maximum flow is a finite number that is the bound on the number of iterations that you will go through.\nSo, this is definitely a legitimate procedure for producing a valid flow. But we are interested in more than just coming up with some valid flow. We want a flow that has the maximum possible value. So, does this algorithm do that for you or did I just string you along on something that is potentially sub-optimal?\nI will let you think about that and if you want to find out, you should come back to the next segment of this module, where we will talk about this algorithm and we will build up on it in interesting ways. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec41.html",
    "href": "materials/cpnotes/Lec41.html",
    "title": "Minimum Spanning Trees - Module 3 (Hierarchy)",
    "section": "",
    "text": "Lecture - 41\nMinimum Spanning Trees - Module 3 (Hierarchy)\n(Refer Slide Time: 00:26)\n\nWelcome back to the third module of the seventh week in Getting Started with Competitive Programming. This week, we have been talking about minimum spanning trees. And in this module, I want to talk about a problem called ‘hierarchy’ from Codeforces. So, let us just get started with the problem statement here.\nSo, we are told that Nick’s company employed n people. Now being primed to think about graphs, when you even read this sentence, you are probably thinking about people as vertices, which is excellent. I think that is how things are going to pan out. So, let us take a look at what happens next.\n(Refer Slide Time: 00:49, 01:28 & 01:58)\n  \nNick needs to build a tree hierarchy of supervisor-subordinate relations in the company. This is to say that each employee except one has exactly one supervisor. So, this is all from the problem statement. I have not really added any remarks here. So, we are told that every person has to find one and exactly one supervisor, except for one person whom you could think of as some kind of a root node in this tree structure. Or if you are thinking in terms of the story, this is probably the CEO of the company who does not need to report to anybody.\nSo, there are m applications in the following format. Employee ai is ready to be a supervisor of employee bi at an extra cost of ci. The qualification of each employee is known and for each application, it is true that ai is qualified to supervise bi. Now in this part of the problem statement you are not told anything more about what it means for ai to be qualified to supervise bi.\nBut if you look at the section where the input-output format is described, we are told that for each application, it is promised that qai is greater than qbi, where qx denotes the qualification of employee x. So, it is good to know that that is what it means for one employee to be qualified to supervise another, that their qualifications are strictly greater than the person that they are expressing willingness to supervise.\n(Refer Slide Time: 02:28 & 03:06)\n \n\nWe are also told that different applications can be similar, that is, they can come from one and the same employee, who offered to become a supervisor of the same person, but at a different cost. This is perhaps to say that if you think of these willingness applications as edges between people, then this graph can have multiple edges between the same pair of different costs. So, these remarks were in the input-output format section. So, let us just go back to the problem statement to figure out what our task is, and it turns out to be a fairly predictable task.\nWe are to help Nick calculate the minimum cost of building such a hierarchy or find out that it is impossible to build it. Now, you might be wondering, under what circumstances would it be impossible to build the kind of hierarchy that we are looking for? Well, this can happen. For example, if you have multiple employees that nobody is willing to supervise. Recall that the definition of the hierarchy requires that there is exactly one employee who does not have a supervisor, and everybody else has exactly one supervisor.\nSo, imagine that in your instance, you have two or more employees, whom nobody is willing to supervise among all the applications that you have received, then no matter how hard you try, you will not be able to build up a complete hierarchy. So, these are the kinds of situations that you want to filter out and identify as being impossible. Notice also that what we just described covers all the impossible scenarios.\nBecause if this does not play out, then you have an instance where every employee, except for at most one has at least one person who is willing to supervise him or her. And therefore, if nothing else, you could just arbitrarily identify a supervisor for each employee and you will end up with at least some hierarchy. So, it is not going to be impossible. But our task would still be to figure out the best possible among all the hierarchies that turned out to be valid ones.\n(Refer Slide Time: 04:46)\n \nNow, as you might expect, we would want to model this as some sort of a graph. So, let me just say that if we have vertices A and B corresponding to people then we will have an edge from A to B to indicate that B is potentially going to be supervised by A. So, if you have an application for employ A who says that they are willing to supervise employee B, for some cost C, then you would add this edge from A to B and assign it a cost of C.\nIf there are multiple applications of this kind, you could add multiple edges with their respective costs. So, the first thing to notice is that what you are really looking for is a subgraph with the property that every vertex except for one has in-degree exactly one. Just to recall some terminology, the in-degree of any vertex V is the number of vertices U search that there is an edge from U to V or U comma V is an edge in the graph G.\nSo, that is why we are looking for a subgraph, where the in-degree of every vertex except for one in the subgraph is going to be exactly one. This corresponds to the constraint that every person has exactly one supervisor. Now, beyond the in-degree constraint, we are also looking for a subgraph, which does not have cycles. Because if you recall, in the problem statement, we are given that we have to find a tree hierarchy. In fact, the lack of cycles also follows from the way qualifications are described for supervisor-subordinate relationships.\n(Refer Slide Time: 06:23)\n \nFor example, let us say that we start with employee A, who has a qualification of level 9, for instance, and let us say that we determine that A is going to supervise B. So, B’s qualification necessarily must be strictly less than 9 for this to be a valid supervisor-subordinate relationship. So, for example, let us say that B’s qualification is level 8. Now let us say that B is to supervise C. Let us say this is what we are determining in our solution, then once again, C’s qualification must be strictly less than B’s.\nSo, in particular, it must be less than 8. Let us say that it is 7. And let us say that C, in turn, is planning to supervise D. And once again, we know that for this to be valid, D must have a qualification of level 6 or less. So, let us say that it is 6. And now notice that if you do end up suggesting that D should supervise A, then this will not be a valid supervisor-subordinate relationship because D’s qualification is strictly less than A’s.\nSo, anytime you see a cycle in the supervisor-subordinate relationship structure that you are proposing, you know that it is not going to be a valid structure. So, the fact that what you are looking for is a tree also follows from how we are told valid supervisor-subordinate relationships are established. Notice that this argument worked out because we had this constraint for the applications.\nIf this was not a strict inequality, then our argument would not quite work out in the same way. Of course, we are also told in the problem statement that we are looking for a tree hierarchy. So, we know for more than one reason that the substructure that we are looking for, is in fact, acyclic. So, just to recap what we have so far, let us reframe everything that we know in terms of both ‘input’ and expected ‘output,’ in the language of graphs.\n(Refer Slide Time: 08:28 & 08:35)\n \nSo, first, we said that there are ‘n’ employees. So these employees can be thought of as vertices. And we also know that we have these applications, indicating that employee ‘ai’ is ready to supervise employee ‘bi’ at the cost of ‘ci.’ So, we said that we will model this by an edge from ai to bi with an edge weight of ci. That is what we are going to do for each of the applications that we get. So, we have this graph. And what we are looking for as a subgraph is, well, on the one hand, we said that every vertex except for one must have indegree exactly 1.\n(Refer Slide Time: 09:08, 09:23)\n \nSo, this means that there must be exactly ‘n-1’ edges in our subgraph. And also, we said that we are looking for a tree hierarchy. So, we said that there are going to be no cycles. So, notice that the solution is, in fact, a minimum cost spanning tree.\nBecause, well, you have ‘n-1’ edges, which do not form cycles, and the minimum cost comes from the fact that we have been tasked with finding a minimum cost hierarchy. So that is where the minimum cost comes from. So, we could potentially just run a minimum spanning tree algorithm here. We just have to be a little bit careful because the edges are directed. And we have this in-degree one constraint to be a little bit careful about as we work with these directed edges.\n(Refer Slide Time: 10:01)\n \nSo, one way to try and account for this is to say that whenever you are working with your MST algorithm, if you are trying to add an edge from A to B at any stage, you want to make sure that B does not already have a supervisor. Once you pass this sanity check, then this edge is truly safe to add.\nNow, it seems tempting to use something like Prim’s algorithm for this because of the way you are expanding out, if you only expand out along out-edges seems like the sanity check is built-in for you. But notice that Prim’s algorithm starts with an arbitrary choice of a source vertex. And you can imagine that the spanning tree that Prim’s algorithm will produce at the end will have the source vertex as the root or the CEO, or the person who is eventually not going to have a supervisor. So, you want to be careful about the choice of source.\nSo, you have to go through your applications to figure out which one is that ‘one applicant’ who does not have any willing supervisor. Notice that in any valid instance, there must be exactly one such employee. We already said that if there are two or more employees who have no willing supervisors, then this is an impossible instance, and we will return as much. So, your code should check for this situation separately.\nAnd on the other hand, it also cannot be the case that there is no such employee. Imagine a situation where every employee had at least one willing supervisor. Then in the graph that you have built up, you could just start with any employee, and go to anyone who is willing to supervise him or her and just keep doing this. And you are never going to get stuck because every employee has at least one other employee who is willing to supervise him or her.\nSo, if you keep following along because your graph only has n vertices, and you will never get stuck, it must be that at some point, you repeat a vertex. That is unavoidable. And when you do repeat a vertex, you have actually discovered a cycle. But we just argued a few moments ago that you could not structurally have a cycle because we have been promised that every time any employee is willing to supervise another one, they are actually qualified to do so.\nAnd because of the way this is defined, the qualifications are always strictly increasing or strictly decreasing, depending on which direction you are going around this sequence of employee-supervisor relationships. So, as a result, we know that it cannot be the case that every employee has a willing supervisor. There must be somebody who does not have one for things to make sense.\nTherefore, in a valid instance, there is going to be exactly one employee who does not have any willing supervisor. And that would be the most appropriate choice for a source vertex for Prim’s algorithm. If you start from here, then you should be able to just run Prim’s algorithm and find your optimal answer. Now, this is an approach that I actually have not tried implementing. So, if you do this, and it works out, do let me know; I would look forward to seeing your code.\n(Refer Slide Time: 13:10 & 13:41)\n \nNow, the official editorial mentions a direct greedy approach. Notice that everyone needs one supervisor, so just find the best one for every employee who has at least one supervisor who is willing to supervise him or her. Once again, this will also require the sanity check at the beginning, where you ensure that there is exactly one employee who has no willing supervisors. Once that sanity check is out of the way, this greedy approach can be shown to work.\nYou could also use Kruskal’s algorithm, you just have to be careful about adding safe edges. So, when you are going to add an edge, indicating that U will supervise V, you want to make sure that V does not already have a supervisor. Your parent pointers will naturally keep track of the hierarchy that you are actually looking for. And since this is a fairly elegant solution in terms of the code, this is the approach that I chose to implement for this problem.\n(Refer Slide Time: 14:16 & 15:04)\n \nLet us take a quick look at the implementation. So, the first thing that I did was to modify the union operation in the UnionFind data structure a bit so that it is just directly tracking parent pointers without doing any rank or depth checks. So, when I say that I want to take the union of ‘i’ and ‘j,’ I do mean that I want the parent of j to be i. And this indicates that j is going to be supervised by i. So, that is what we want to do here. So, we are not going to set the direction of the pointer based on what is optimal in terms of the depths of the trees. We are actually going to do exactly what we are told to do. So, this is a minor modification. In fact, it simplifies the way union is performed. And that is what we need for the semantics of this problem.\nNow, in terms of what we do in the main function, after reading all the edges based on the applications and making sure that, you know, we use the standard format of the edge list: the first coordinate in the tuple being the cost and then the second and the third coordinates, corresponding to the directed edge from U to V. After having done that, as usual, we will sort the edges by weights as Kruskal’s algorithm would do. And now you will see that I also have an MST variable, which is a vector that will collect all the edges that we actually add to our spanning tree.\n(Refer Slide Time: 17:19 & 19:51)\n \nNow, you do not literally need to output the tree hierarchy, you just need to output the cost. So, you do not really need this. But I keep talking about how a little bit of extra bookkeeping can actually give you the spanning tree as well. So, this is just to demonstrate that even though we will not use it for generating the final output, we will use it to check if we actually managed to generate a complete hierarchy or not. So, it is useful to know how many edges we managed to add to a spanning tree.\nNotice that if there is more than one employee who has no willing supervisors, then when you run your ‘spanning tree’ algorithm at the very end, you will actually not get a spanning tree, but you will get a spanning forest—one for each employee who does not have any willing supervisor. There will be one component in this forest for every such employee. So, all we need to do is either check the number of sets that were produced at the very end and see if that is greater than one.\nOr we could just tally up the number of edges that were collected in our spanning tree and check if that falls short of n - 1. In that case, a spanning tree is not really a tree but a forest. So, this is one way of figuring out if we are in an impossible situation or one where we were able to successfully build a hierarchy. So, that is another thing that this MST variable may come in handy.\nSo, as always, we are going to initialize the UnionFind data structure. We are going to do it with n + 1 vertices just to keep the indexing a painless experience. And we have the ‘answer’ variable, which will track the costs of the edges that we add to our spanning tree.\nNow, we run Kruskal’s algorithm as usual. If we actually have collected ‘n - 1’ edges, then we make an early exit from this loop. And otherwise, we are basically looking at the current edge, which indicates that U is willing to supervise V. That is how we added the edges in the first place. And the first part of the ‘if’ condition that you see here is the standard Kruskal’s algorithm condition, which determines if the edge is safe or not.\nSo, if U and V happened to be in the same set, then this edge is actually going to create a cycle. So, we are not going to be interested in adding this edge at all. Now at this point, you might have the following question. The edge U V, when the endpoints belong to the same set does form a cycle in the underlying undirected graph. But perhaps they do not form a cycle in the directed graph. So, it is possible that for instance, you have an edge from A to B, and an edge from B to C.\nAnd then the edge that you are about to add is not the edge from C to A but an edge from A to C. That is not going to create a cycle. But notice that if you do not create a cycle in the directed graph, then you end up creating a vertex that has an in-degree more than 1. So, either way, this is going to be a violation. So, if U and V belong to the same set, then we are not going to add it anyway. And beyond this, remember, we said that we need to be sure that V is not getting an extra supervisor. So, we check that V is in fact, the root of the set that it belongs to.\nThat is the only circumstance in which adding this edge from U to V would be a valid addition to the structure that we are building. So, this and V equals the parent of V. That extra condition is what is required to make this algorithm work. This is not a part of the standard Kruskal’s implementation. But that is what we need to do here. Now if both of these conditions work out, then we know that we have a valid addition to our structure.\nSo, we add this edge to our MST, we increment the answer variable with the cost of this edge. And we actually merge these two underlying components as well as we would normally do with Kruskal’s algorithm. So, this is the main body, this is the heart of the computation here.\nAnd after this, all we have to do is a sanity check to figure out if at the end of this we actually managed to build a complete hierarchy or not. So, having built up the MST and kept track of it, I am writing this condition in terms of the number of edges in the MST variable. If we added less than ‘n - 1’ edges, then that means that we do not have a spanning tree. So, we say that this was an impossible scenario that was given to us.\nAnd otherwise, we return the value that we have stored in the answer variable. But instead of the check based on the size of the MST vector, you could equally pull out the number of sets from the UnionFind data structure, and see if that number is > 1, then also, that is an equally valid check for whether we are under impossible scenario or not. So, that is it. That is the entire implementation for this problem. I hope that it made sense.\nIf you want the complete code from which I am sharing snippets here then, as usual, you can just go to the official repository for these videos, there is a link to it in the description. And you should be able to find the complete code there. As you can see, we are writing all this in C++. So, if you have a variation in your favorite language, then please do submit it as a pull request, we always look forward to receiving your versions in other languages.\nSo, we wrap up this discussion here. We have one more module and one more application of MST to discover. This is going to be a problem called ‘island hopping,’ which is a very interesting variation of the basic MST concept. So, I hope that I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec27.html",
    "href": "materials/cpnotes/Lec27.html",
    "title": "Graph Foundations - Module 3 (Cover It!)",
    "section": "",
    "text": "Lecture - 27\nGraph Foundations - Module 3 (Cover It!)\n(Refer Slide Time: 0:12)\n\nWelcome back to the third module of the fifth week in Getting Started with Competitive Programming. So, this week, it is all about graph traversals. We are looking at applications of BFS and DFS. And let us look at another one of them through this problem called ‘cover it,’ which appeared in a Div 3 Codeforces contest. This was contest number 565, and it was the fifth problem in the set. It was a set, which had six problems altogether.\nAnd the fifth problem in the set is usually an indication that this problem is one of the relatively harder problems. In fact, if you look at the stats, you will see that more people solve this problem than the fourth one. But it was still only solved by 1300 people relative to about 7000 odd people who did the first one. So, I think there is a relative difficulty thing there. It turns out that this problem has a really cute and simple solution.\nBut it does require one observation which may not be obvious at all. So, that is what we are going to explore. But the final solution is fairly short and sweet. And especially once you have developed some facility with writing up BFS DFS traversals, it should be a pretty quick thing even to code up once you know what the main idea is. So, this problem does not have too much of a backstory. So, let us just get to it. We have a very specific task to do.\n(Refer Slide Time: 01:36)\n\nSo, what we are given is an undirected, unweighted, connected graph, which has n vertices and m edges. This is also a simple graph. So, there are no self-loops or multiple edges. All of this is straight from the problem statement. And remember that if you go back to the very first video that we did this week, we said that this is going to be our default happy setting where the graph is simple, and it is undirected, unweighted, and in this case, we are also given that it is connected. So, that is, that is a familiar situation. And what are we supposed to do?\nWell, we are supposed to figure out if we can find a subset of at most n/2 vertices, n/2 floor. So, if n is odd, we want the smaller half in some sense. So, we want at most floor n/2 many vertices, which have the property that each unchosen vertex is adjacent to at least one of the chosen vertices. Now, those who are familiar with graph theory terminology may recognize this as what we call a dominating set.\nA dominating set in a graph is a subset of vertices, which is such that every vertex that is outside the dominating set has a neighbor in the dominating set. And essentially, what this problem is telling us is that you are given a connected graph, and you are supposed to find a dominating set that consists only of at most half the vertices. We are also promised that the answer always exists and if there are multiple answers then you can print any of them.\nNow the fact that the answer always exists can be interpreted in two ways. One is that you are only given such graphs that have such a subset. Or it could be that the answer is universally true. That any connected, undirected, unweighted graph on n vertices always has a dominating set on at most floor n/2 many vertices. So, we are about to figure out if this is universally true. But before we do that, let us just get used to the idea of what it means for a subset of vertices to be a dominating set by just pulling up a few examples.\n(Refer Slide Time: 03:37 & 04:04)\n \nSo, here is a graph that you might remember from the first module. So, you can see that there is sort of an outer circle and an inner circle. And they both have the same number of vertices. And it turns out that you could choose either the inner circle or the outer one. And those would be perfectly valid dominating sets. And their sizes are, of course, exactly half of the total number of vertices. So, this is, in fact, exactly what we want.\nIf you look at the graph that we saw in the previous module – this is a bipartite graph, then, well, a valid dominating set would involve simply picking all the vertices on one of the two sides. Right. And if you want the smallest possible dominating set and one that is easy to see, then you could simply pick the smaller of the two sides. And notice that this already guarantees you at least on connected bipartite graphs that you always have a dominating set involving at most half the vertices.\nBecause when you have two parts, at least one of the two parts will have at most half the vertices. Right. It is possible that both of them are exactly half and half. But if they are not both exactly half, then it is going to be that one of them is more than half and the other is less than half. So, you just pick the smaller side and you would have a dominating set of the desired size.\nNow moving beyond these really specific examples, let us just think about what would be a way of finding a small dominating set, whereby small, I simply mean a set whose size is at most half the total number of vertices. So, how would you find a small dominating set on a general graph?\nWell, you could, for example, just try an arbitrary partition of the graph into two subsets of the same size. And then basically examine if neither of them works, then can you move things around a bit, so that you can fix the partition and turn it into a dominating set.\nIf you play around with this a little bit, you might eventually end up coming up with proof of why you can always find a dominating set of size at most floor n/2. Now, I will leave you to think about this a little bit and fool around with some more examples and build up some intuition. But as I said, there is really one key observation after which you end up basically solving the entire problem.\nAlso, knowing that this is a problem that has come up in the context of graph traversals, you might want to execute a BFS or a DFS, and just see if these traversals give you any hints about dominating sets. Like, do they have, somehow in a natural way, a dominating set hiding somewhere if you were to execute one of these traversals?\nSo, take your time. Think about this for a moment. And as I said, when we come back, we will discuss the one key idea that essentially solves this problem. Alright. So, hopefully, you had a chance to think about this a little bit.\n(Refer Slide Time: 06:48)\n  \nLet me show you a picture of a BFS traversal with the layers color-coded so that alternate layers have different colors. So, the solid edges from this picture are the edges along which the traversal actually executed. And all the dotted edges are all the remaining edges from the graph that their traversal did not have to follow. Alright. So, given this picture, is there anything that stands out? Notice that just like we did for the previous problem, the alternate layers have been colored using different colors.\nWe also said that if your graph happens to be bipartite, then you could just pick one of the two parts and that would be a valid dominating set. So, a very reasonable thing for you to think maybe would be that, well, the red and the blue vertices form some sort of partition into two parts. So, maybe we could just pick one of them. But notice that for a general graph, which is not a tree, the red and blue partition may not be actually a bipartition.\nSo, in particular, if somebody just gives you a partition into two parts, you could not just say that you will pick the smaller part. And that would be a dominating set. Right. Because it is possible that the other part has a vertex, and all of its neighbors just sitting on the other side. And so this would not be a valid dominating set. But with this particular bipartition, even though notice that because of these extra graph edges that I have shown here, this is not necessarily a bipartition. It is not, the graph is not bipartite.\nIn fact, you can see that because there is a triangle right on top. But in spite of that, I think these partitions are still fairly helpful in the context of building a dominating set. So, in fact, you might want to treat the picture here as a hint and just work through the problem of finding a small dominating set for this specific example. And I think you might find some pretty nicely generalizable intuition. Really think about not just finding some small dominating set by brute force.\nBut by considering if there is a natural choice for a dominating set based on the way that these vertices have been colored for you. And think about why this will actually always form a dominating set in a more general sort of way. So, please feel free to take a pause here. I think you have a few more pieces of the puzzle in place. And you might just completely discover the solution yourself if you were to spend some time on it at this stage of the discussion.\nAlright. So, hopefully, you had a chance to think through this. Notice that, in fact, both the red vertices as well as the blue vertices form dominating sets on their own. And the reason for this is that, well, let us consider the red vertices first. Notice that because the BFS traversal started out with a red vertex, it is pretty much by the definition of the way that traversal works, every blue vertex is adjacent to a red vertex.\nIn fact, many people when implementing BFS like to maintain an explicit parent array, where the goal is to basically remember: Why did you get added to the queue in the course of the BFS traversal? So, if I got discovered by a particular vertex, and because of that I got pushed to the end of the queue, then I am going to remember that vertex as being some sort of a parent vertex, so the vertex that was responsible for my discovery.\nSo, in particular, notice that every blue vertex is discovered by a red vertex or has a red parent, which means that if we were to choose all the red vertices, then every blue vertex, which would be in this case, the unchosen vertices would end up having a neighbor among the red vertices because that is simply how the traversal worked. Now it is the exact same story for the blue vertices as well.\nSo, every red vertex has a blue parent, except possibly for the red vertex that started the whole traversal. So, that vertex does not have a parent because it was the beginning of it all. But it certainly has blue neighbors and all the remaining red vertices have blue neighbors because they have, in particular, blue parent vertices for sure. Therefore, what we can say is that both the red vertices and the blue vertices, which are essentially vertices that are on the odd layers of a BFS, traversal, and even layers of a BFS traversal. Both of these subsets of vertices are essentially dominating sets.\n(Refer Slide Time: 11:26)\n  \nSo, the BFS traversal essentially gives us a partition of the entire vertex set into two parts. These are the parts that belong to the odd layers, and the even layers, which we had colored red and blue. And notice that these parts may not always have exactly the same size. So, it is possible that the red part is bigger than the blue part, or that the blue part is bigger than the red part. But just like we said, when we were talking about bipartite graphs, it does not really matter.\nAs long as you have a partition of the vertex set into two dominating sets, we know that at least one of them is going to be suitably small, simply because we are only looking for a dominating set, which has at the most floor of n/2 many vertices. So, it cannot be the case that both of these parts are strictly bigger than the floor of n/2. Because if that was true, then the total number of vertices would be greater than n, which would be a contradiction. So, with this one observation, we are basically done.\n(Refer Slide Time: 12:24)\n\nSo, what we do is we collect all the vertices in the odd layers in one part and all the vertices in the even layer in another part. And we essentially, just need to know which of these parts were smaller. And remember, because the problem asks you to actually output a subset of vertices, you also have to keep track of which vertices belong to which part so that you can output them at the end.\nNow, you might remember that I did say that if you wanted to solve the previous problem about bipartiteness using BFS, you might get some hints from here. So, remember that for the previous problem also, you wanted to keep track of vertices on the odd and the even layer separately, but there, all you wanted to track was the sizes of the two parts and that is all that you cared about. So, essentially, the code that we write here would also be relevant to the previous problem. You just have to tweak what you output a little bit for this to work for the previous problem.\n(Refer Slide Time: 13:24)\n\nAlright. So, with that said, let us take a look at the implementation. So, here is the usual BFS code, but we just need to introduce a few extra variables to keep track of what is going on with the odd and the even layers. So, we have these two vectors, odd and even which are designed to actually keep track of the vertices and we have the variables O and E, which will keep track of the sizes.\nSo, to begin with, when we initialize BFS with the first vertex, then let us say that that is an even layer, if you think of it as layer 0, then I think that would make sense. So, we add this vertex to the even list, and we increment the number of even vertices. And then the rest of it is standard BFS initialization.\n(Refer Slide Time: 14:08 & 14:52)\n \nNow when we perform the actual BFS traversal, and we add a new vertex to the queue, we have to basically figure out: Does this go on to an even layer or an odd layer? So, this is where the distance array comes in handy. So, remember that the distance array helps us keep track of distances from the route, the place from where we started the traversal. And if the distance value for this new vertex is odd, then it is on an odd layer.\nAnd if it is even then it is on an even layer. So, that is essentially the if statement here, which lets you appropriately add the vertex to either the odd list or the even list. And you should remember the increment your odd and even counts as well.\nThese counts will be important for the final step where you have to decide which of these lists is a smaller one. Of course, instead of maintaining the counts as you go along, you could of course just evaluate the lengths of these lists once at the end as well. So, either way, works out fine. But the final step would just involve printing all the vertices in the odd list or the even list as the case may be. And then you are pretty much done.\nSo, this is essentially the complete solution to cover it. And as always, you can find this code in the official repository. There is a link in the description of this video as well. And I hope that you have a chance to check this out. And, you know, if you write this up in your favorite programming language, please do submit a pull request. And if you have any questions or comments, or perhaps a different way of doing this, then please let us know by dropping a line in either the mailing lists or the Discord community forums.\nSo, we will see you there. And we want to do one more problem this week called Diamond Inheritance. And that is coming up in the next video. So, I will see you there. Thanks for watching and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec33.html",
    "href": "materials/cpnotes/Lec33.html",
    "title": "Shortest Paths - Module 2 (Wormholes [Bellman-Ford | Negative",
    "section": "",
    "text": "Lecture - 33\nShortest Paths - Module 2 (Wormholes [Bellman-Ford | Negative Cycles])\nWelcome back to the second module of week six and Getting Started with Competitive Programming. So, in this module, I want to focus on the single-source shortest path problem, even in the presence of negative cycles. So we are going to be learning about an algorithm that is popularly known as the Bellman-Ford algorithm.\nAnd we are going to implement this in the context of a problem called ‘wormholes,’ which is available from the UVa platform. So this module is in two segments. In the first one, we will talk about the general algorithmic approach and in the second segment, we will introduce the problem statement for wormholes and also work through its implementation.\n(Refer Slide Time: 00:59)\n \nOkay, so just to recap what we have seen so far – We have broadly identified four different scenarios based on the nature of the weights on the edges. So the first one which is the simplest is when there are no weights at all or you could think of this as all the weights being uniform or set to one. And the slightly more general case is when we have non-negative edge weights.\nAnd then we have a situation where we allow for negative edge weights but we do not have negative cycles, and the final situation is when anything goes and you could also have negative cycles. Now in terms of what we have seen about what we can do for these scenarios, we did say that breadth-first search traversal which you saw last week already is a nice linear time algorithm for the first case and is the preferred approach when you do have a situation without edge weights.\nNow when you do not have negative edge weights, then you could use Dijkstra’s algorithm even in its original form. And when you have negative edge weights but no negative cycles, then a small modification to Dijkstra’s algorithm works and makes it an accurate algorithm for the situation. But one thing to note is that that comes at the price of the algorithm being potentially more expensive, especially on instances that do have negative edge weights.\nIf you are looking at instances of the second category where there are no negative edge weights at all, then it does not matter which version you are working with, they have the same complexity. Okay, but we do know that even the modified version of Dijkstra’s algorithm will run into potentially an infinite loop if there is a negative weight cycle in the input graph.\nSo as we said, the focus of this module is to really address the issue of negative cycles, and why are negative cycles such a problem. Well, first of all, a fundamental issue is that even the very notion of shortest paths becomes ill-defined when you have a negative cycle in the graph. So let us take a look at an example.\n(Refer Slide Time: 03:23)\n\nSo here is a graph, and you can see that there is a cycle on the vertices S, A, C, B, in that order, and the total weight of the cycle is easily seen to be negative. In particular, it is, I think, -37. Now let us say that we want to find the shortest path from A to D. A perfectly reasonable way of reaching D from A seems to be to go via vertex A. So let us see what that would look like. You go from S to A.\nThen you go from A to C, and then the final leg of this journey is going to be from C to D. Now, this path has a total cost of 1 + 2 + 3, which is 6. But do you think you can do better? Pause the video here and try to figure this out for yourself. Is there a path whose cost is less than six? And remember, when we talk about paths, we are allowed to repeat vertices in our journey. That is not a problem.\nSo take a pause here and come back once you have had a chance to think about this whenever you are ready. Alright, so perhaps you were able to see that instead of taking this last hop from C to D, suppose we were to back up a little bit and we came back to the vertex C, and instead of going to D from here, let us say that we go to B instead. And from B we go to S, and then we go from S to A and A to C and then C to D.\nIf you were to do this then you would essentially end up with a path whose length is -37 + 3, which is, I think -34, which is certainly much cheaper than 6. And now the problem is that there is nothing that prevents you from doing this detour twice for instance, or doing it thrice, or doing it four times. In fact, you could do it as many times as you like and every time you will end up making your previous path even shorter.\nSo this could go on really forever and then you could ask yourself the question: What does it even mean to talk about the shortest path from S to D when you have this sort of a negative cycle detour on the way which can be taken as many times as you want to keep making the path shorter and shorter or cheaper and cheaper depending on how you want to think about it?\nSo now that we appreciate why negative cycles can be problematic in the context of shortest paths, in particular, we see that the presence of negative cycles can make the very notion of shortest paths ill-defined. Now we want to think about how do we tackle this kind of situation. So I think there are two natural workarounds.\nThe first is to, perhaps, even change the definition of the problem. One of the reasons we are able to do these infinitely many detours is because we are permitting ourselves to repeat vertices along our journey. We could say that this is intuitively wasteful and we could think about just trying to find the shortest path between S and T which happens to be a simple path, which is to say that we do not allow for vertices to repeat.\nI think this is a very interesting variant, and there is a good reason why it is considered to be a much harder problem than most of the shortest path variants that we are going to see here. So this is something that I am going to leave as food for thought. This is not the variant that we are going to consider.\nThe more standard approach is to simply say that when we do have negative cycles then the notion of the shortest path is not well defined. So in this case we have no obligation to report the shortest path. So we basically detect a negative cycle and produce that as a witness to why we could not find the shortest path, basically because the notion is not well defined.\nSo in this most general situation, our task essentially boils down to detecting the presence of a negative weight cycle if it exists, and if it does not then we just report the shortest paths as we have been doing so far.\n(Refer Slide Time: 08:00)\n\nSo just going back to the summary for the moment so that we can add to this picture: What we are going to look at now is the Bellman-Ford algorithm, which has a running time that is either order ‘n’ cubed or order ‘n’ * ‘m,’ depending on whether we model the graph is adjacency matrices, or adjacency lists, respectively. And this will algorithm will turn out to do exactly what we want, which is to say that it can identify negative cycles when they are present and compute shortest paths and absent.\n(Refer Slide Time: 08:38 & 08:56)\n \nNow, just like Dijkstra’s algorithm, Bellman-Ford also works by relaxing tense edges, in some sense for as long as it can. And before we get to a more explicit description of what the Bellman-Ford algorithm does, let is just quickly recap the notion of a tense edge, and what it means to relax one.\nSo an edge from ‘u’ to ‘v’ with weight ‘w’ is said to be tense if the following inequality holds: ‘t’ + ‘w’ < ‘d,’ where t and d are our current understanding of the distances of the vertices u and v, respectively, from the source. So t can be thought of as the value of d of ‘v,’ if d is the distance array. And d can be thought of as the value of d[v], again, d being the same distance array.\n(Refer Slide Time: 09:44 & 10:18)\n \nSo when this inequality holds, it is clear that we have discovered a better way of getting to v compared to whatever it is that we had in mind so far. So we are going to put that on the record by relaxing this edge, and what it means to relax this edge is to essentially get rid of the information that we had so far about v and replace it with this updated information about this new and better path from the source to the vertex v.\nSo the distance of v, the d array is going to reflect this new value, d + w. Now we have performed this kind of relaxation operation several times in the context of Dijkstra’s algorithm. Now let us take a look at how Bellman-Ford is going to perform these relaxations.\nSo it is really a very elegant and simple algorithm. So what we are going to do is initialize a distance array, as usual, and then what we are going to do is we are going to repeat the following process ‘n-1’ times, the process being: Just relax every tense edge. So you are going to basically go over every edge in the graph, and check if it is tense, and if it is, then you are just going to relax it. That is it.\nThat is pretty much the algorithm, except for one last step which I will come to in a moment, but you can probably already see where the running time is coming from. There is this outer loop that is going to run ‘n-1’ times, and the inner loop is going to run ‘m’ times because you are going to go through every edge to check if it is tense.\nSo just to understand what is happening let is think about what happens in the very first iteration of the outer loop. Now, at this point, you know that the distance array looks something like this. It is just a more visual representation of the first line of code that you see here or at least pseudocode. And basically what we have is that the distance of the source to itself is zero, and everything else is initialized to some very large number.\nAnd at this point, we are going to go through all edges and ask them if they are tense. So which edges are going to be tense at this stage of the algorithm? Take a moment to think about this and come back when you have an answer.\nOkay. So, hopefully, you have also concluded that at the very first stage, the only edges that are tense are the ones that are basically incident on ‘s.’ These edges are definitely tense because you have d[u] being zero, and the weight of u to v, in this case from the source to any other neighborhood of the source, is going to be some finite value. So this is going to definitely be better than this initial infinite value that we have in the array.\n(Refer Slide Time: 12:18 & 13:16)\n \nSo, all of the edges that are incident on s are tense. So every vertex v that is a direct neighbor of ‘s’ has its distance values updated by the end of the first phase. Notice also that none of the other edges are going to be tense in the very beginning because if you consider any edge ‘u v,’ where neither u nor v is the source, then both of the distance values are going to be the same large number that is depicting infinity.\nAnd therefore there is no reason for this image to be tense. So the picture at the end of the first round of Bellman-Ford actually looks pretty similar to what happens in the first round of Dijkstra, but we will see that things pan out a little bit differently as we go along. So in particular, you might want to spend a little bit of time thinking about what happens at the end of the second round, what happens to the end of the third round, and more generally, what happens at the end of ‘i’ iterations of the outer ‘for’ loop in the Bellman-Ford algorithm.\nSo here is a claim that I am going to make once again without proof, and as always, there are links in the description where you can find out more about why this is true, or you can try to prove it yourself using something like induction. So the claim is the following.\nAt the end of ‘i’th round, if there is a vertex v that is reachable from vertex s by a sequence of atmost ’i’ edges, then the value in the distance array for the vertex v is going to reflect the cost of the shortest path sequence on atmost ‘i’ edges. So, among all paths that have length atmost ‘i,’ the value in the distance array is going to be the cost of the cheapest such path or the shortest such path.\n(Refer Slide Time: 14:25 & 14:59)\n \nSo, that is the claim, and that is what happens at the end of the ‘i’th round. So in particular, if I were to just think about ’i’ as being n-1, which is the other extreme, that is the last round. So what we want to say is that if v is reachable from s by a sequence of atmost ‘n-1’ edges, then d[v] reflects the cost of the cheapest such sequence.\nThis is just the statement that we made a moment ago, but with ‘i’ being substituted for by ‘n-1.’ So this is what happens at the end of the algorithm. This is true when the algorithm has finished its course. So what can you say if there is a tense edge in the graph after all the ‘n-1’ rounds of Bellman-Ford have run their course, and have completed their work? What can you say if there is a tense edge after all of this?\n(Refer Slide Time: 15:31)\n \nPlease do think about this for a moment because the answer to this question holds a key insight with regards to this algorithm. So take a pause here and come back once you are ready. Alright, so I claim that if there is a tense edge after all the ‘n-1’ rounds are done, then they must in fact be in a negative weight cycle in the graph. And the reason for this, roughly speaking, is the following.\nIf you did not have negative weight cycles in the graph then all shortest paths would have, in fact, been simple paths. There would never be a reason to repeat a vertex because if you consider a path that repeats a vertex then you can look at the first time that you visit the vertex and the very next time that you visit the vertex.\nSo this subpath is going to be a cycle. And because there are no negative weight cycles, this cycle must have a weight of either zero or positive. Now, if you were to just completely avoid this detour then you obtain a path, which has fewer edges and the cost is either the same as before, which would happen if the cycle had zero weight or it is in fact better than before. So that tells you that in a graph that does not have negative weight cycles, essentially, all shortest paths are in fact simple paths.\nAnd in particular, they will only involve at most ‘v-1’ edges. So, if your graph did not have any negative weight cycles then because of the claim that we made here at the end of ‘n-1’ rounds, we would have, in fact, correctly computed all the shortest paths already. And since all shortest paths have been computed, no remaining edge should be tense anymore because there is nothing to improve on.\nNow, if you turn this around on its head, what this means is that if you still have a tense edge that is left after all of the ‘n-1’ rounds are done, then that implies that there must be a negative weight cycle. So that is essentially how Bellman-Ford works to detect negative weight cycles when they exist and to compute shortest paths correctly when they are not present.\nSo what we do is run ‘n-1’ iterations of this song and dance of identifying all tense edges. And when that is completed, we scan the set of all edges one more time. And in this last scrutiny, if any edge turns out to be tense, then we say: Okay, look, we have evidence that there is a negative weight cycle.\nSo, you could stop there, but if no edges are tense once you have finished the first ‘n minus iterations’ – if in this last scrutiny, all edges are perfectly happy, then we know that the distance array has correctly captured the costs of the shortest paths from the source to the respective vertices. And so, we are done as well.\nOf course, the correctness of this hinges on a claim that we made about what happens in the ’i’th round. And once again, I should emphasize that this claim was made without proof. And if that is something you are interested in, you can certainly read up on the references that accompany the description of this video.\nSo this brings us to the end of the description of the mechanics of Bellman-Ford. It is a really elegant idea, and it is also fairly easy to implement. And we are now going to study the implementation in the context of a problem called ‘wormholes.’ And, this was a problem that is available from the UVA platform, and we are going to continue this discussion in the next segment. I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec32.html",
    "href": "materials/cpnotes/Lec32.html",
    "title": "Shortest Paths - Module 1 (Modified Dijkstra)",
    "section": "",
    "text": "Lecture - 32\nShortest Paths - Module 1 (Modified Dijkstra)\n(Refer Slide Time: 00:11 & 01:29)\n \nSo welcome back to the last segment of the first module in week six on shortest paths. As you might recall, we have been talking about the single-source shortest path problem throughout this module. And so far, we have figured out what to do when all the edge weights are uniform, and also when all the edge weights are guaranteed to be non-negative. In fact, in the previous segment, we saw an implementation of Dijkstra’s algorithm, which is an algorithm designed to handle precisely this kind of situation.\nNow, the focus of this module is going to be the case when we do allow for negative edge weights, but we continue to avoid what are called negative cycles. So a negative cycle is simply a cycle whose total edge weight, when we just add up all the edges that are participating in the cycle, that total is negative. That is a negative cycle. And we are going to assume that we do not have such cycles in our graph.\nWe will have more to say about why negative cycles are problematic in the context of shortest paths in the next module. But for now, let us just take this as a given. So we are going to assume that our graphs do not have negative cycles, but they may still have edges with negative weights.\nAnd remember that where we stopped last time, we said that such edges could be problematic. The proof of correctness was really dependent on the assumption that the edge weights were non-negative. So we also said that you could come up with concrete examples that break the algorithm if you allowed for edges that have negative weight.\n(Refer Slide Time: 01:46 & 02:22)\n \nSo perhaps you have already come up with your own examples or you would like to come up with something yourself. So feel free to pause the video at this stage and play around a little bit because what I am going to do next to start off with an example just to make a point about the ways in which Dijkstra’s algorithm can fail in the form that we had discussed it last time. It could potentially give the wrong answer if you do allow for edges that have negative weights.\nSo let us go ahead and take a look at the following graph. So we have five vertices here. The source vertex is the leftmost vertex on your screen that is labeled S. And the edge weights are as given in the boxes. And what we have on top is the distance array that is going to be maintained by Dijkstra’s algorithm.\nAs we know in the beginning, S is the only vertex for which we know the distance from S, and that happens to be zero, and everything else is initialized to some very large number. So in the first iteration here, we can see that the edges from S to A and from S to B are the tense edges. So we are going to update their distance values to one and ten, respectively.\nAnd now the job of S is done. So we are going to look for the next minimum value that we can find in the distance array and that happens to be the value of A. So we are going to explore all the edges that go out of A and there is one such, which is the edge from A to C, and this is indeed a tense edge.\nSo when we relax it, we update the value of the distance of C to 3 because that is the distance of A plus the weight of the edge from A to C, 1 + 2. And so that is the current state of the distance array. And now that we have finished processing A, we are going to extract the minimum value in this array again and this time, that is owned by the vertex C. And then again we are going to explore the edges that are incident to C, and see if these edges need to be relaxed.\nSo one edge incident on C is the edge from C to D, and as you can see here, this edge could certainly use some relaxing. The new value of the distance of D should be the sum of the value of distance to C + the weight of the edge from C to D. So that would be 3 + 3, amounting to 6.\nThe next minimum value in the distance array is owned by D. So that is the vertex that we are going to process next. Notice that D does not have any edges incident to it. So there is no work to be done. And then we run our final ExtractMin operation and we are going to see that we have only one value left in the set or the priority queue, whatever you are working with. And that is the value corresponding to vertex B.\nSo let us consider vertex B. You will see that there is an edge that is incident on B, the edge from B to C. And one question here is, is this edge tense? So let us think about this. The current value of the distance of C is three. On the other hand, if you look at the distance of B + the weight of the edge from B to C, then you get a value of 10 ± 10. And that is zero. So in fact, it is quicker to reach C from S via B. But unfortunately, we decided to take the longer route based on whatever we have discovered so far.\nIntuitively, the issue with missing out on this edge is that, well, when we did discover B, that was already an expensive proposition and Dijkstra’s algorithm did not think that you are going to be able to do anything better in the future. And indeed if all the edge weights are guaranteed to be non-negative, then you can see here that there is no way that you could have improved on the distance of C by going via B because this edge from B to C would have had a weight of zero, at best, and then you could not possibly beat what you already have for C.\nBut somehow these negative edge weights coming in later could really mess around with your calculations. But at this point, notice that the algorithm cannot really do anything meaningful. The queue is empty. There is no way to actually register this improved distance and make sense of it.\n(Refer Slide Time: 06:46 & 07:38)\n \nSo you can see why Dijkstra’s algorithm is going to fail in the presence of negative edge weights, and this is one example to illustrate that. Now we are going to make a very simple modification to Dijkstra’s algorithm that will actually fix this issue. And once again, you could pause the video here and think about what sort of a modification would you attempt if you had to work around such issues.\nThe natural thing seems to be to somehow allow for these relaxations even after the vertices at the other end of the edges have left the priority queue. Perhaps there is some way of bringing them back in. So please think about this hint, which pretty much gives me the modification that needs to be made, but still feel free to pause here and think this through before you continue the conversation with me.\nOkay, so hopefully you have had a chance to think about this a little bit, and let us take a look at the modified version of Dijkstra’s algorithm here. So remember that previously, what we were doing was that we inserted all the values of the vertex distance pairs into our priority queue. Now what we are going to do is we are just going to insert ‘S,0,’ which is the only vertex about which we know anything at the start. And other than this, the priority queue is empty.\nThis is just a minor difference in the initialization. And what we are going to do going forward is that every time we relax a tense edge, we are going to ask ourselves – Is V, which is the vertex at the receiving end of the tense edge – we are gonna ask ourselves if V is already in the priority queue. If it is then as before, we decrease its value appropriately. And if it is not in the queue, we actually bring it back.\nI said queue and what I really meant was the priority queue or the set or whatever it is that we are using to maintain information. So what we want going to do is make sure that V makes a comeback if an edge incident on V has been relaxed. So this way, it is possible that a vertex gets out of the queue and then comes back and is extracted again, and so on and so forth.\nSo you do have to think about whether a running time analysis from before holds up in the same way. As a matter of fact, it does not. But in some sense, if your input does not have negative edges then there will be a vertex to make a come back into the queue. So, then the analysis is pretty much the same.\nBut in the presence of negative weight edges, what happens is that the previous algorithm is going to have the same running time as before but possibly a wrong answer. And this algorithm is going to have potentially a worse running time, but that is the price you pay for getting to the right answer.\nNow because the running times of both versions of Dijkstra’s algorithm are very similar in the absence of negative edges, you might as well always work with a modified version. Whenever you do not have negative edge weights, you are going to get a performance guarantee that is very similar to the original versions. You have nothing to worry about. And when you do have negative edge weights, then at least you do not have anything to worry about in terms of correctness, even though you are going to them may take longer to run.\nIn fact, it is a nice puzzle to think of adversarial examples for this version of Dijkstra’s algorithm. So you could try to come up with a graph where you have carefully engineered negative edge weights, which really forces this algorithm to take a really long time. I can tell you that the worst-case running time of this version of Dijkstra’s algorithm on graphs that do have negative eight edges is significantly worse than the worst-case running time when restricted to instances that do not have any negative edge weights.\nNow, let me just make a quick comment here about the implementation. In this version of Dijkstra’s algorithm, you could actually use a priority queue directly, even if you do not have a DecreaseKey method for it. We are going to practice something called ‘lazy deletion.’ So basically, whenever we decrease the key value for a particular vertex, the way we are going to do it is just by inserting the new value.\nAnd we are just going to let the old value be present in the priority queue, and we will just leave it there. And whenever we do an ExtractMin operation, we need to add a small check which basically tells us if this is the current value, or if it is one of those stale, older values that is lying around. And that check would essentially amount to comparing the value that we have in the priority queue with the value in the distance array.\nIf the value from the priority queue is higher than the value that we have in the distance array, then we know that this is a stale, old value and this just needs to be rejected from consideration. So let us just look at how this version works in code.\n(Refer Slide Time: 11:53)\n\nSo here is the operational version of the pseudocode that you just saw. So notice that instead of a set, we are here using a priority queue. And if you were using Python, for instance, you could use a heap or something like this from the standard Python libraries.\nAnd the way this works is pretty much the same as before, except that when you are updating, which is what is happening in the last line of code, when we were working with a set, what we said was that we will delete the old element and insert the new one. And here all that we are doing is we are inserting the new element without bothering to delete the old one.\nAnd the reason this works is that whenever we perform an ExtractMin, we are able to distinguish between whether or not we are working with a value that is the current value, or whether it is one of those old and obsolete values. So you can see the line where the accompanying comment is a very important check.\nThat is the line of code that is ensuring that we are always working with valid values when we are doing ExtractMin. So we do ExtractMin as usual in the line that is just before it, and we do a quick check of the value that we extracted. We compare that with the value in the distance array, and if the value is larger than what we have in the distance array, then we know that this value is not a current value. It is an obsolete value. So we just move on.\nSo this implicitly implements the deletion, but we call it ‘lazy deletion’ for this reason. It gets deleted automatically in due course. We do not have to necessarily do the deletion when we are also doing the insertion in the update step. So that is how this works.\nI should mention that this code is based on the code that is in the repository for the competitive programming book. And as usual, you will find a link to their repository in the description of this video, in case you would like to cross-refer it.\n(Refer Slide Time: 14:05)\n\nAlright, so with all this said, let me just summarize everything that we have learned so far. So, when all the edge weights are uniform then BFS works just fine. And this is your best bet, in terms of running time. So if you encounter a shortest path-based problem, if there is a problem that can be modeled as a shortest path situation, and all the edge weights happen to be uniform, by all means, go ahead and use BFS. It is elegant, it gets the job done, and it is fast. So that would be the right choice.\nNow in case you do have edge weights, then you could either use Dijkstra or modified Dijkstra. In particular, if you do have negative edge weights then you should not be using the original form of Dijkstra’s algorithm. Because as we saw, that could give you an answer. So in that case, you definitely want to make sure that you have the modification accounted for. Both of these versions have similar running times when all the edge weights are guaranteed to be positive.\nSo, if you like, you could always default to using what is called modified Dijkstra. In fact, if you look at the reference for this module, this shortest paths chapter in the ‘algorithms text’ by Erickson, the author in that text stays that he really prefers to call modified Dijkstra ‘Dijkstra’s algorithm’ because he thinks the algorithm that is correct for a larger class of graphs is probably the one that should be used by default. So you could certainly do that.\n(Refer Slide Time: 15:59)\n \nOn the other hand, if you do end up using the default version, then just remember to be careful about not using it if the weights can potentially be negative. Now, in terms of implementation, we saw that the original version of Dijkstra can be implemented using sets in C++ and this will also work in Java, for example. But the modified version can be implemented directly with a priority queue combined with this idea of lazy deletion.\nSo there is an important check that you have to do whenever you are extracting the minimum to make sure that you are not working with an obsolete value. But once you do that, everything works out great. And if you are a Python user then you might just want to stick to using this version because that is the one that can be implemented in a straightforward way.\nSo, all of this is great for up to the situation when you have graphs that have potentially negative edge weights but no negative cycles. How does the presence of negative weight cycles shake things up? Well, quite a bit actually. So if you think about modified Dijkstra’s algorithm and if you try to simulate it on graphs that have negative weight cycles, you might discover for yourself that this algorithm potentially gets into an infinite loop, which is of course, not a good thing and a situation that you want to definitely avoid.\nSo whenever you are working with a problem that is based on shortest paths, and you have negative edge weights being allowed, please do check for whether you have been told that there is a promise that there are no negative weight cycles. If such a promise is made explicit, then of course you can go ahead and use all the machinery that we have talked about so far.\nBut without this assumption and with the possibility that there may be negative weight cycles, you want to be a little more careful. And in the next module, we are going to talk about how we can detect the presence of negative weight cycles, and how we can compute the shortest paths when we are confident that the graph does not have negative weight cycles. So all of that is coming up. So this is a good place to stop here, and I will see you back in the next module!"
  },
  {
    "objectID": "materials/cpnotes/Lec26.html",
    "href": "materials/cpnotes/Lec26.html",
    "title": "Graph Foundations - Module 2 (Mahmoud and Ehab and the",
    "section": "",
    "text": "Lecture - 26\nGraph Foundations - Module 2 (Mahmoud and Ehab and the bipartiteness)\n(Refer Slide Time: 0:11)\n\nWelcome back to the second module of the fifth week in Getting Started with Competitive Programming. So, this week our focus is on graph traversals, and specifically, we are looking at BFS and DFS. Just as a recap, let me point out that in the first module, we covered some pretty foundational material. We looked at how to represent graphs. We compared the adjacency matrix and the adjacency list representations, which are two of the most commonly used representations when it comes to graphs, and then we actually went through implementation for both BFS and DFS. And we looked at their complexities based on whether you were using a matrix representation or a list representation.\nSo, all of that has been done and dusted in the first module for this week. So, hopefully, you are here because you have either already finished watching those videos or because you know all of this already. If this is not the case, then you might want to do this first, before beginning to actually work on some of these problems.\nAlso, although for most problems where BFS and DFS are applied, you can actually usually use either approach and make things work. There are certainly applications where the problem is better suited to one traversal over the other. So, really make sure that you are comfortable with both of these algorithms because you never know which one will come in handy and which one will be the more natural approach to use, and in some cases, which one would be the only approach that actually works.\nSo, with all of that said, let us begin by looking at our first problem here, which if I am pronouncing it right, is called ‘Mahmoud and Ehab and the Bipartiteness.’ So, this was from a Codeforces contest, contest number 435. It was the second problem and I think all of the problem statements involve stories around these two characters.\nFor this problem, however, the story plays a negligible role. So, let us just get straight to the problem statement, where we are basically hit with a few definitions. So, let us go through them one by one.\n(Refer Slide Time: 02:12)\n\nSo, first, we are told that a tree is a connected acyclic graph. Now the notion of a tree may already be a familiar one. You have certainly worked with trees in data structures. In the context of graphs, a tree is exactly what is being said here. It is a graph, which is connected and that does not have any cycles. So, just to be sure, let us discuss these terms a little bit.\nFirst, what does it mean for a graph to be connected? Intuitively, it means that every vertex in this graph is reachable from any other vertex. So, imagining that your graph is some sort of a road network, the idea is that you should be able to walk around freely in this graph, as long as you are walking along edges. So, that is a constraint. You cannot jump from one vertex to another one that is not adjacent to it. That does not have a direct edge to it.\nBut that does not mean that you cannot reach it, you can walk around and probably take a longer sequence of edges to get to this other vertex. So, two vertices that have a direct edge between them are adjacent. But for them to be connected, all we need is that there is a sequence of vertices that you can follow where the consecutive vertices are adjacent. They are connected by a direct edge and you can just walk around to get to this other vertex.\n(Refer Slide Time: 03:31)\n\nSo, this sort of sequence is called a path. So, you can use a path to travel around in this graph and a graph is connected if you have such a path between any pair of vertices. So, you could come up with examples of graphs that are not connected. So, for example, if you draw on a piece of paper, let us say two triangles, for instance, which are disjoint from each other, then notice that there is no way for you to start from one triangle and end up in the other one.\nOnce you are in one of these triangles, you are kind of trapped to travel only within that triangle. So, it is easy to come up with examples of graphs that are not connected, and notice that you can use graph traversals to figure out if a graph is connected or not. Because one run of either BFS or DFS will essentially visit every vertex that is reachable from the vertex that you start the traversal from.\nSo, just by checking at the very end if every vertex is visited or not, you know if your graph is connected or not. In fact, if your graph is not connected, then the graph is essentially a collection of connected pieces, which are called connected components and you can even use these graph traversal algorithms, either BFS or DFS, to figure out how many of these pieces there are.\nSo, this is a fun exercise and there is a problem listed in the extra section which will allow you to practice just counting the number of connected components in a graph. So, while on the topic of connectivity, I just felt like I should mention that. But now let us move on to talking about cycles.\n(Refer Slide Time: 05:10)\n \nSo, a cycle is simply a path with its ends also connected by a direct edge and what we are given is that our graph does not have cycles. So, remember we are talking about trees.\nSo, trees are connected acyclic graphs and we were just making sure that both of those terms make sense. Now, the second definition that we have to contend with is this concept of a bipartite graph. So, a bipartite graph is a graph whose vertex set can be partitioned into two parts such that every edge essentially goes across. So, you pick any edge in the graph, it has one of its endpoints in the first part and the other endpoint in the second part.\n(Refer Slide Time: 05:52)\n \nSo, bipartite graphs are typically visualized in this way. You can essentially split the vertex set into some sort of a left part and a right part and you see that all of the edges are going across.\nHere is an example of what is called a complete bipartite graph, which basically means that you have the two parts and you have all possible edges between these two parts. Now, let us say that the two parts of a bipartite graph have ‘a’ and ‘b’ many vertices. So, let us say that small a denotes the number of vertices in one of the parts and small b denotes the number of vertices in the other part. What is the maximum number of edges that your bipartite graph can have?\nSo this example here should give you a clue. But this is essentially a counting question and one that will be relevant to our solving this problem. So, please feel free to pause the video here and think about what would be an answer to this question. Alright. Hopefully, you had a chance to think about this for a bit.\nIn this example, you can see that we have a bipartite graph where the paths have 5 and 3 vertices, and if you were to just count the number of edges, you will see that there are 15 edges, which happens to be 5 x 3 and one of the ways of seeing that it is indeed 5 x 3 for a good reason is to isolate the edges incident on each vertex on one of the sides.\nSo, let us look at it from the perspective of the red vertices. You would see that each of the red vertices has three blue neighbors and this is going to be true in general for any complete bipartite graph with parts that have a and b vertices. So, each of the ‘a vertices’ will have ‘b neighbors,’ which means that the total number of edges is going to be simply the product of the sizes of the two parts, ‘a’ x ‘b.’ So, let us just keep that fact at the back of our minds, and now let us go back to the problem statement.\n(Refer slide Time: 07:51)\n\nSo here, what we are told is that we are given a tree consisting of ‘n’ nodes and we have been asked to add edges to it in such a way that the graph remains bipartite. Notice that the phrase is that the graph is still bipartite, which implicitly tells you that a tree, to begin with, is already bipartite.\nNow, I think this is a really fun fact to try and prove for yourself, especially if you are not already familiar with it and I will not prove it here because the proof is kind of implicit in the algorithm that we will come up with to solve the problem. So, I do not want to give it away completely immediately. But I will leave you with three hints for trying to prove that all trees are bipartite and I hope that you have some fun with this.\n(Refer Slide Time: 08:39 & 09:31)\n \nSo, one way of showing this is to use induction on the number of vertices and a hint in this context is to use the fact that every tree has a leaf. Now that of course sounds like a perfectly reasonable statement in English. But it is also true of graph-theoretic trees. So, a leaf is simply a vertex, which has exactly one neighbor, and if you do not know this already, you can show this by induction as well.\nSo, having proved that every tree has at least one leaf, as long as it has at least two vertices, this is always true, you can actually try and see what happens if you remove the leaf in the induction step of, you know, the statement that every tree is bipartite. It is typically going to be easy to sneak a leaf back in, as you perform the induction step. So, that is the first hint.\nThe second one is to essentially use this famous characterization of bipartite graphs. So, it is well known that a graph is bipartite if and only if it does not have any odd cycles, which are cycles with an odd number of vertices in them. Now of course, here it is easy to put 2 and 2 together.\nA tree not only does not have odd cycles – it does not have any cycles. So, if you knew this categorization, it is just a direct application. But in case you do not know this characterization, I would welcome you to try and actually prove this characterization because this will imply what you want. And once again, think about whether you can use a breadth-first search traversal to actually prove this statement here. So, that would be the second approach.\n(Refer Slide Time: 10:17)\n\nThe third approach will be to actually demonstrate an explicit bipartition. So, you could fix your favorite vertex in this graph, and on the one side, you could collect everything that is at an even distance from this vertex. So, what is the notion of distance in the context of graphs? Well, the distance between any two vertices would be the length of the shortest path that joins them.\nSo, for instance, your immediate neighbors would be at distance 1, the neighbors of your neighbors would be a distance 2, and so on. Importantly, we are working with unweighted graphs here. So, every edge is just going to contribute 1 unit to the distance calculation.\nSo, if we just collect every vertex, which is at an even distance from a fixed vertex and every vertex which is at an odd distance from the fixed vertex with the fixed vertex landing on the even side because it is a distance 0 from itself, so this will turn out to be, at least for trees, a valid bipartition in that every edge will go across. And you want to think about why this is the case and again, if you like, you can use a traversal to help navigate this argument.\nSo, use any of these three approaches and see if you can convince yourself that trees are bipartite. Of course, it also helps as a warm-up to just play around with some examples to build your intuition first. So, once you have done that, you can come back and continue the discussion that we are going to have here, which is again, back to the problem statement. What is our task here? Our task here is to essentially add as many edges as we can while maintaining the bipartiteness of the tree.\nWe are also supposed to maintain the fact that the graph is simple because notice that the question here is to add as many edges as possible. And if we were not constrained to work with a simple graph, at the end of the day, we could just keep adding as many edges as we want between a fixed pair of vertices and this would not make so much sense.\nSo, in a way, this is a good constraint for us that makes the problem nice and well defined. And now the question that we really have to think about is: What is the largest number of edges that we can add to a tree while still keeping it bipartite?\nSo, in some sense, we want a complete bipartite completion of the tree that we are given, and the reason I say that is because we have talked about complete bipartite graphs in an example earlier. Notice that a complete bipartite graph automatically maximizes the number of edges that we can have once the parts are fixed. So, what are the parts that we are working with?\n(Refer Slide Time: 13:03)\n \nRemember, we are given a tree as input and we just said that a tree is bipartite and hopefully you had a chance to convince yourself of this fact. So, let us look at the tree from the bipartite perspective. So, let us redraw this tree so that all the vertices in the left part are in this left circle here and all the vertices in the right part are in the right circle.\nSo, remember, given that trees are bipartite, you can come up with such a partition and you should also be able to convince yourself that up to swapping the left and the right parts, this partition is in fact unique. And that will be a fallout of the way that you proved that every tree is bipartite. So, again, if this is not completely clear that these parts are unambiguously defined, given a tree, then please take a moment here to actually absorb this fact and convince yourself of it.\nSo, now let us take a closer look at the bipartite representation of this tree. Our task here is basically going to be to fill out the gaps here. Notice that since we have to maintain the bipartiteness, we cannot add any edges with both of their endpoints on the left or with both of their endpoints on the right.\nBut any pair of vertices that is one on the left and the other on the right and does not already have an edge between them is fair game in terms of our being able to add that edge. So, let us just fill in the gaps here and you will see that these are all the missing edges that we can add to turn this bipartite graph into a complete bipartite graph.\nNow, what is this number? And is this our answer? Well, this number is definitely our answer because notice that we cannot add any more edges here under the constraints that we have to maintain bipartiteness, and the final graph has to be a simple graph. So, we certainly cannot do better than this and on the other hand, what we are doing is certainly feasible.\nSo, what we have added here constitutes of valid solution in the sense that none of these new edges violate bipartiteness. We carefully introduced them so that they have one leg in one boat and the other leg in the other boat, they all go across. So, that is safe and we never added an edge on top of an existing edge. So, what we are left with at the end of the day is certainly a simple and bipartite graph. So, we have essentially argued the correctness of this approach.\nI will say that it is easy to see the validity of this solution, the feasibility of this solution. To formally argue that this is the best that you can do, you do need a little bit of an argument to convince yourself that this partition is something that we are stuck with. We really just have to build on this, there was not a different way of partitioning the vertices so that this product of the sizes of the two paths could have possibly been higher, for instance.\nThat is not going to happen and this is the comment that we made earlier that once you are given a tree, there is really only a unique bipartition up to renaming the left and the right paths. So, if you convince yourself of that, then this is, you know, complete proof for why this approach is correct.\nBut in case that is something that you are still not sure about, then there is still a small gap in the argument for the correctness of what we are doing. So, make sure you understand why this partition is essentially unambiguous once a tree has been given to you. Alright. So, now that we know what we want to do, let us just look at what the final answer is going to be.\nSo, if the sizes of these parts that came out of the tree were small a and small b, then what do you think the answer would be? I am going to reveal it in 10 seconds. So, if you want to think about it, please pause the video here and come back when you are ready.\n(Refer Slide Time: 17:11)\n\nAlright. So, the answer is going to be ‘a’ x ‘b’ - ‘n’ - 1, where n - 1 is (essentially) all the edges that we already have. Remember, we are given a tree on n vertices. So, it is a well-known fact that any tree on n vertices has ‘n - 1’ edges. So, I am just taking advantage of that fact, to say n - 1 here. You could equally just say m, where m is the number of edges that you took in as input, it would be the same thing. And ‘a x b,’ if you remember from before, is the number of edges that we have after we add all of the missing edges in.\nSo, if the sizes of the two parts were a and b, we just argued a few minutes ago that the number of edges that we will have in the complete bipartite graph with part sizes a and b is exactly ‘a x b.’ So, that is the total number of edges that we get after doing the completion process and we just have to remember to subtract from this n - 1 to get to the number of edges that we actually added on top of what was there.\nAlright. So, now that we know the answer, the only thing that remains to be done is to figure out a and b. What are the sizes of the two parts in the bipartite representation of the given tree? So how do we figure out this partition? If we can come up with an algorithm for doing this, this will essentially answer the two puzzles that we mentioned during this discussion.\nThe first one was to argue that trees are bipartite and the second one was where we said that this by partition is in fact unique. So, just think about this. If somebody gave you a graph and they told you that it was bipartite and they told you to come up with a partition, how would you go about it?\nWell, you could start with your favorite vertex – could be anyone. And then you could say, look, so if this vertex goes on the left, it could also go on the right, it does not really matter. But to begin with, let us just say, we pick an arbitrary vertex and we just throw it in the left bundle. Right. Then we know that all of its neighbors, all the vertices that it is adjacent to, must, in fact, go on the other side. They must all be on the right.\nSo, we dump all of its neighbors on the right. Now we look at all the neighbors of the vertices that landed on the right, and then we know that they must be on the left because we cannot accommodate edges completely on the right-hand side. So, you just keep doing this dance, going back and forth between left and right, and what you will end up with is a partition. And in fact, it is even a valid bipartition.\nAnd the reason for this is that well, you were promised that the graph is bipartite and at every step, you did whatever you were forced to do. You could not have partitioned it any other way. Otherwise, you would have had a violation and if in spite of all this, the partition that you end up with has edges on one part, on one side, then you can essentially use that edge to argue that your graph was not bipartite, to begin with.\nAnd the intuitive reason for that is as we just said, at every step you did what you were forced to do. You could not have had the partition come out any other way and therefore, you could not possibly have edges within the paths because of the promise that the graph was bipartite, to begin with.\nSo, it would be a contradiction if you had a violation at the end and notice that this process will essentially end up exhausting all the vertices, because again, if it did not, then you can (sort of) argue that the graph was not connected, to begin with. So, any vertex that is not accounted for by this process that you just performed, is going to be a vertex that is not reachable from any of the vertices that you have partitioned so far.\nBut that would violate connectivity. So, you actually know that this process ends up coming up with a forced partition of all the vertices in the graph, which also is an argument for why the partition is unique, which is also something that we mentioned a few minutes ago. So, let us now just recap this whole process with an example.\n(Refer Slide Time: 21:29)\n\nLet us say that we were given this tree as input. We said that we will first fix a favorite vertex. Let us just pick the one on the top and then we said that, okay, we are going to designate this as a vertex on the left side of the partition. I am going to remember that by coloring it red and then we said that all of its neighbors go on the other side.\nSo, let us remember that by coloring the neighbors with a different color, in this case blue. And then we said that, well, we will go over all the vertices that we dumped on the other side, and we will find their neighbors and make sure that their neighbors come back to the left. So, we do that.\nSo, these are all of the neighbors in the next layer of the tree. And we color all of those red and finally, as you can imagine, the last layer is going to go back on the other side and will get colored blue. So, this is essentially our partition for this example. So, all the red vertices go on the left, for instance, and all the blue vertices go on the right.\nNow the way this played out – this probably reminds you of a breadth-first search traversal. This is essentially what it is, as you alternate layers in a BFS traversal. It is like you could go back and forth between left and right and notice that all the red vertices and all the blue vertices are never going to have an edge between them.\nEspecially because we are working with a tree. Right. Notice that you cannot have level edges. Because if you have an edge at the same level, then that essentially means that you have a cycle. So, that is not possible, and other than level edges, let us say you have two blue vertices that are not on the same level, then they are separated by at least one layer of red vertices.\nSo, they are, you know, at least two levels apart in some sense and we already know that BFS trees do not have these packages. So, you could see that there is never going to be an edge between any pair of blue vertices. For two reasons. I mean, blue vertices from different levels because of the BFS structure and two blue vertices in the same level because of the tree structure, because the input graph is a tree. And of course, the same applies to the red vertices as well.\nSo, you could simply do a BFS traversal. Keep track of how many red vertices you encounter and how many blue vertices you encounter. Basically, just keep track of the total number of vertices in the odd layers and the total number of vertices in the even layers, and then you would be done. You just keep this count and then you output ‘a’ x ‘b’ - ‘n’ - 1.\nNow what we are going to do in the next problem has a very similar flavor. So, let us do the implementation using DFS, just to see how you could do the same thing a little bit differently. We are going to pursue the same idea with the promise that the graph is bipartite. Essentially, whenever you are coming out of a vertex that is committed to being on the left or on the right, its neighbors just going to be on the opposite side.\nSo, that is all that you have to keep track of, as you try to do this using a DFS. If you are interested, you can code up this solution using BFS just as well and in fact, if you watch the next video, you might get some hints about how you could do that, even for this problem. But, for now, let us move on to the implementation using DFS.\n(Refer Slide Time: 24:50 & 25:31)\n \nSo, to begin with, we have the standard global variables which are the adjacency lists and the not visited array, which helps us keep track of what has and what has not been visited yet. But we also have this variable called side, which could have well been to separate integers as well. But just for convenience, I am going to keep track of it as an array of length 2, where the first element of this array is going to tell us how many vertices have we built up on the left and the second element of this array is going to keep track of how many vertices have we accumulated on the right, as we build out our partitions.\nNext, let us see how we can use DFS to actually build out the partitions. So, most of this should look familiar. This is the standard DFS code that we have already seen before. But now you might notice that there are a couple of important changes. First of all, the invocation itself takes an extra parameter called ‘s,’ and this sort of helps us keep track of whether we are on the left or on the right.\nSo, ‘s’ is going to be either 0 or 1 and the idea is that this tells us if the vertex ‘u’ was supposed to be on the left part. If it is 0, we take that to be left and if s is 1, then the vertex u is supposed to go to the right part. So, that is what this parameter is telling us. So, in fact, the first thing that we do is increment the value of ‘side of s’ appropriately.\nBecause basically, what is happening now is that we are visiting the vertex u for the first time, and the parameter s is telling us on which side it is. So, we put that on the record by incrementing the appropriate variable in the side array. And once that is done when we actually recurse and we find the first fresh neighbor of the vertex u that we are going to invoke the DFS on, that is the exploration that we are going to do recursively.\nFor this vertex, we have to remember to switch sides because remember this is a neighbor of a vertex that is on side s. So, this vertex itself has to go to side 1 - s. So, for example, if the vertex u was on side 0, then this neighbor of u, which is v that is going to be explored next should be on side 1, which is 1 - s or 1 - 0.\nOn the other hand, if u was on side 1, then v should be on side 0, but that is also 1 - s, in this case, that is going to be 1 - 1, which is 0. So, that is what is going to happen in recursion. So, you can see that as this plays out, for every vertex that you visit, notice that you are going to visit this vertex exactly once you correctly increment the appropriate side variable and you put on record how many vertices you have accumulated on both sides. By the time you are done, you will have the two sizes that you are looking for and you can just output that.\n(Refer Slide Time: 27:54)\n\nSo, if you look at the last couple of lines of this code, that is really the key of the solution, you start your DFS at your favorite vertex – could be vertex 1 and it starts off inside 0 for instance – that is like we said, pick a favorite vertex and put it on the left. That is what we are doing here and once the DFS has run its course remember that given that this is a connected graph, which is also a tree, you will see that DFS is going to correctly visit every vertex and place it on the left or the right peacefully without any violations. And once again, remember that this would have been the only way to do it.\nThere would be really no other partition to contend with this one, which is why we know that what we output on the last line is actually the right answer. So, that is the product of the two sizes that we have of the two parts that we built out and we need to remember to adjust for the number of edges that were already there so, that what we are outputting is in fact, the number of extra edges that we added.\nAlright. So, that brings us to the end of the discussion on this problem. If a lot of the notions that we saw here were already familiar to you, for instance, you already knew what a tree was, you already know what bipartite graphs are, perhaps you even know the characterization of bipartite graphs in terms of odd cycles and so on and so forth. Then, you may have honestly been a little bit bored and this I would say is, for somebody who already is familiar with many of these facts, I would say this would be a relatively straightforward problem.\nOn the other hand, if (many of) these notions were new to you, and you are seeing them for the first time, then I think it is perfectly natural that you need some time to absorb all the different ideas that you have been exposed to even in the discussion for just this one problem. So, please feel free to take your time and rewind and go back to any of the parts that did not make sense the first time around.\nAs always, if you are listening to this during an active run of this course we will look forward to hearing from you either on the Google mailing lists or on the Discord community forum. So, if you have any questions do drop in there or any suggestions, everything is welcome. You could also leave comments on this YouTube video and finally, this code is in C ++, as you can probably tell, and a link to it is in the description, as usual, this is on the official repository.\nIf you have a version of this in your favorite language, then please do submit it as a pull request and we will be very happy to incorporate it, so we look forward to hearing from you. Thanks very much for watching and I will see you back in the next video!"
  },
  {
    "objectID": "materials/cpnotes/Lec18.html",
    "href": "materials/cpnotes/Lec18.html",
    "title": "Disjoint Set Union - Module 1 (An Introduction-Part III)",
    "section": "",
    "text": "Lecture - 18\nDisjoint Set Union - Module 1 (An Introduction-Part III)\n(Refer Slide Time 00:11)\n\nWelcome to the final segment of the first module on ‘Disjoint Set Union.’ This is the third and the last video in a three-part series. I hope you have seen the first two videos because I do not expect this one to make a lot of sense without the context from there. This is not a standalone video. We are going to actually implement the algorithms that we have already discussed for the two main DSU operations, which are the ‘find’ set and ‘union’ set.\nIf you recall, we discussed a couple of different heuristics. First, we talked about ‘union by depth,’ and then we talked about ‘path compression’ and ‘union by rank.’ Basically, that is what we are going to implement and the specific implementation here is in C++ but it is quite easily adaptable to Python or any other language of your choice. The implementation here is really elegant and simple and it follows the pseudocode quite closely. I think we will have some fun.\nI should say that this implementation is heavily borrowed from the fourth edition of the competitive programming book. Even if you do not have access to the book, there is a GitHub repository that goes with the book and that is freely accessible. You can look that up. There is a link in the description. They have implemented a lot of other data structures as well. This is a really useful reference to have.\nYou will find code and at least Python, C++ and Java as far as I remember, and maybe some other languages as well. This is a really useful thing to bookmark and keep handy. For DSU in particular, if you want to test out the data structures that you implement, Codeforces has a really nice series of practice problems for DSU.\nIn fact, you will find quite a large collection of DSU based problems there. Unfortunately, we will not have enough time to actually go over all of them. But we are going to look at a couple of more examples from this section. Again, I will point you to exactly where you can go. This is not a standard contest. You will have to have a Codeforces account and then you can go to the EDU tab on the top of the navigation.\nThis is the education section and there is one course that covers many different topics. But you want to look out for the one on ‘Disjoint Set Union,’ which in turn has multiple chapters. Just go to the first one and go to the practice section. You will find a customized contest with a bunch of problems. What we will be talking about here will be kind of geared towards solving the first two problems, which are essentially just asking you to implement DSU.\nThat is the first problem. It is asking you to implement, basically find and union, and also this extra operation which asks you if two elements belong to the same set or not. We are going to look at how to take care of that. In the second problem, it is very similar, except that you are also asked to be able to not just find the set that an element belongs to but you are also asked to return the minimum and the maximum elements from that set.\nThat is the extra book-keeping that we need to do. We are going to discuss both of these problems in this video. But before that, let us actually implement the basic data structure.\n(Refer Slide Time: 03:31)\n\nWe are going to do this in an object-oriented style. You are free to just directly implement this using global arrays or, whatever your preferred method is. But this way, you essentially open up a convenient interface and this becomes code that you can just set aside and invoke quite easily when you actually needed in specific contest problems.\nThis is the style that we are going to adopt. The UnionFind class is going to have a bunch of things. It is going to have a vector array, which is essentially going to store the information about the parent pointers. It is also going to try and store the rank and the sizes of the individual sets. The information in the rank and the set sizes array will evolve to being relevant only for the leader elements. We will see how that works out. We are also storing a little bit of auxiliary information in this integer numSets, which essentially keeps track of the number of sets that we are working with.\n(Refer Slide Time: 04:37)\n\nNow let us look at the public methods. First, we have the constructor, which is going to initialize your object with sensible values. Let us say that you initialize UnionFind with N, which is to say that you want to keep track of N elements. I will come back to this where, as I said to not have to worry about indexing issues if I want to do a disjoint set union with the universe of size N. I will typically instantiate this with N+1 just so that I can freely talk about the element at the ‘i’th index actually being the element ’i.’\nWe will see that when we get to the main function. But suppose we are doing UnionFind with N elements, then what we want to do is initialize a parent array of size N. In this case, this is a vector with N elements. To begin with, remember that these are all singleton sets. We want all the leader pointers to just be pointing to themselves.\nSo, p[i] = ‘i,’ for all ‘i’ from 0 to N-1. Now, the rank tries to keep track of the heights of the trees. As we said because we will be doing path compression, this is not really exactly the depth of the tree, but it is a useful upper bound to work with nevertheless. To begin with, all your trees are just basically one root element. We going to adopt the convention that these trees have depth 0, to begin with. All sets initially are singletons. They all have size 1.\nWe are going to assign a value of 1 to every element in the set size vector and finally, the number of sets that we are working with initially is, in fact, N. Because remember, to begin with, every element is just a singleton set. There are N of these sets. We going to initialize the numSets variable to N. That is all of the initialization work.\nRemember that in a particular application, you might want to track more information. If you do add more stuff here to your class, just make sure that it is properly initialized. Because if not, you might run into all kinds of runtime errors and memory allocation issues. This is simple, but it is really important. So, just double-check that everything that you are trying to keep track of is properly initialized.\n(Refer Slide Time: 07:09)\n\nNow, with this out of the way, let us talk about the first operation that we want to implement, which is the find set operation. The first thing that we want to check for find set – remember that we are doing path compression here, and this is a recursive implementation. So, the first thing we want to check is if we are already working with a leader element. That check is just to see if the pointer is pointing to itself.\nIf the element is pointing to itself, then we can just return that element. That is the first ‘if’ branch out here. But if you are not in this nice base case, then you need to actually walk up the tree. So, one step at a time, let us go to the parent and try to invoke find set on the parent and this is going to give you the value of the root of the tree. Remember, in path compression, we want to actually assign this root as the new parent of the element ‘i.’\nSo, that is what is happening here when we say p[i] = findSet(p[i]). So, that is finding the root and reassigning the parent of ‘i’ all at the same time. This is also what we are going to return. All of this is combined in this succinct one-liner. You could write this down a little more explicitly. But this works out just the same.\n(Refer Slide Time: 08:35)\n\nNow before we move on to working with the union implementation, let me write down a small helper function, which will be useful both for the union as well as for the specific problem that is that on Codeforces. So, this is called the isSameSet function. So, isSameSet will return true if ‘i’ and ‘j’ belong to the same set and will return false otherwise.\nNotice that figuring out if ‘i’ and ‘j’ belong to the same set basically boils down to asking if ‘i’ and ‘j’ have the same leader element. So, it is possible that one of ‘i’ or ‘j’ themselves are leader elements. That is not particularly relevant. All we have to do is invoke the findSet on ‘i’ and ‘j’ and check if the outcomes of the findSet are identical on both ‘i’ and ‘j.’\nIf it is, then i and j do belong to the same set and if it is not, then they belong to different sets. So, hopefully, this is clear. This follows just by the definition of the way representatives work and the promise that the findSet does its job properly. So, that is isSameSet.\n(Refer Slide Time: 09:31)\n\nNow, let us go on to talking about the ‘union’ set. When you want to take the union of the set that ‘i’ belongs to with the set that ‘j’ belongs to, the first sanity check is to see if the sets are the same or not. If the sets are the same, we do not have any work to do. So, we just check if i and j are in the same set and if so then we just do not do anything. We return.\nOtherwise, remember that with the union, we want to just make sure that the parent pointers are carefully adjusted based on the rank heuristic. First, let us find the leader elements of the sets that i and j belong to. Let us call them x and y respectively, and let us make sure that x is always the element that has the smaller rank that belongs to the set whose corresponding tree has a smaller rank (where rank is going to be some sort of a proxy for the depth).\nIf the rank of x is larger than the rank of y, we make sure to swap the two and after this, we can peacefully make sure that x points to y, given that y is the root of the bigger tree in terms of the notion of rank. So, we go ahead and adjust this parent pointer. Notice that the rank does need to be updated if you are combining two trees that have the same rank.\nOriginally, when we were working with depth and we did not have path compression, this would have been a legitimate reason for increasing the depth. If these two trees have exactly the same depth and one of them points to the root of the other, the final tree has a larger depth than before. We are going to do just the same with the rank value.\nIf you are combining two trees that have the same rank, then you increment the rank of the tree that you just generated. Remember, this tree is being tracked by y. That is the current leader element. That is the current root. You make sure to increment the rank of y. Remember that we were also tracking the sizes of the individual sets and the total number of sets. Both of these values are affected by the union operation.\nThe size of the set that y is representing has now been enhanced, and it has a few extra elements. How many extra elements does it have? That is as much as the size of the set that ‘i’ belong to, which is, in turn, the set that used to be tracked by x. We just go and look up the set size of x and update the set size of y.\nNotice that the set size of x is now not giving you accurate information about the size of the set that x belongs to because now x also belongs to this larger set. But this does not matter because when you want to find out the size of a set that some element belongs to, you will not directly look up its set size. But you will look at the size of the set of its representative element.\nThat is why it is okay that some of the values in the set size array are not going to be completely accurate. What is crucial is that they are accurate for the leader elements. Whoever qualifies as a leader element in the current scenario, the set size information should be valid there. That is why we have this update here.\nWhat about the number of sets where you have just merged two distinct sets? That number goes down by 1. Notice that this does not happen if i and j belong to the same set and this code will not execute because you have already returned the control flow back to the main function, if that were the case on the third line in this code snippet that you see on your screen.\nThat is essentially union set. You want to just go back and check that everything that you were tracking has been appropriately updated as it needs to be. I believe we have more or less covered everything. This is the implementation of the ‘union’ set.\n(Refer Slide Time: 13:27)\n\nLet us just write a couple of small helper functions. As I was mentioning earlier, if you want to find the size of a particular set, you do not just return the value in the set size array. But you actually go to the set size array as indexed by the leader element of the set that ‘i’ belongs to. So, you do the findSet of ‘i,’ and you do the set size of that element. That is what you return. If you wanted to know how many sets are right, now you can simply return numSets. These are two useful helper functions to have.\n(Refer Slide Time: 14:00)\n\nNow if you were solving the first problem in the Codeforces contest that I mentioned, which is also linked to in the description, then essentially what you are given is a sequence of queries, which are either union queries or same-set queries. Essentially, you just have to perform a sequence of unions, and sometimes in between, you get this question – Are these two elements in the same set or not? Essentially, this is how you would implement it.\nGiven that all the work has already been done for you, this implementation should be straightforward to understand. In the first few lines, this is pretty typical. We are just taking in the input. Notice that I am initializing UnionFind with size ‘n+1.’ This is once again so that I can conveniently think of the ’i’th index is tracking the ’i’th element.\nIf you were to initialize this with ‘n’ then you would have to remember to adjust for the indexing a little bit. Because even the notation in the input is that the elements are from 1 through n. If the elements were being denoted from 0 to ‘n-1,’ then you would not have to make this adjustment, one way or the other.\nThat is, again, a small detail, but an important one because it is the sort of thing that can be annoying to debug when it does not fall in place correctly. So, I just wanted to flag that. But apart from that, everything else is pretty routine. You read off your queries and depending on whether it is a union query or a same-set query, you invoke the appropriate functions.\nFrom here, it looks like we never really use findSet in spite of implementing it. But notice that both ‘union’ set and ‘isSameSet’ actually make use of findSet in their implementation. Really, everything that we have written is more or less being used, except for some of the helper functions. Those are not really coming into play in this particular example. But again, it is useful to have them because you might need them depending on the situation.\nThat brings us to the end of the first exercise. The second one is actually very similar. It kind of builds on this and just asks for a little more information. Just like here, you have a bunch of union queries. But now you also have these ‘get’ queries in which you are given one particular element and your task is to return the size of the set that this element belongs to. We have already implemented this by the way with the set size helper function.\nBut apart from the size of the set that this element belongs to, you are also asked to output the value of the largest and the smallest elements in the set that this element belongs to. So, let us just briefly outline how you would handle something like this. I am not doing this from scratch but I am just showing you the extra information that you would need to store to be able to output the values of the largest and the smallest elements in any of the sets.\n(Refer Slide Time: 16:58)\n\nTo begin with, let us add the maxSet and the minSet vectors to the class definition and although I am not showing it here, you should remember to initialize them properly. So, maxSet and minSet of ‘i’ will both have the value ‘i’ because you are working with singleton sets. The maximum and the minimum elements are both equal to the only element that you have in that set. Do remember to do that in the initialization function in the constructor.\n(Refer Slide Time: 17:25)\n\nAlso add these helper functions where you are returning the values of the maximum and the minimum elements by not directly returning the value, just like we saw with the set size array, the values at ‘i’ may have become meaningless over time but you will be tracking them correctly for the leader elements.\nTo find out the maximum value in the set that contains the element ‘i,’ first find the representative element of the set that contains ‘i’ and then look up maxSet for that element and this is analogous for minSet. We have these two very simple helper functions, which will give us the values that we want. You can invoke them when you are writing down your output and the main function.\nAgain, I do not show the main function explicitly because this is a really straightforward addition. In any case, if you want to see the entire code, you can always go to the official GitHub repository and look it up there. The one thing that is very important to do is to update the values of maxSet and minSet for the leader elements when you actually implement the union. Notice that these values are not affected when you do things like findSet because nothing about the structure of the sets changes when you do findSet.\n(Refer Slide Time: 18:40)\n\nBut when you do ‘union,’ then the values of the max and the min can change. So, when you are doing union, remember that we had x and y as being the leaders of the sets represented by i and j. Once again, if x = y, you do not need to do anything because the set itself does not change. There is no union that is really happening. We do not have to worry about that case.\nIn the other case, when you are actually merging two sets, remember we said that we will set p[x] to y. The set that was being tracked by x is getting absorbed into the set that is being currently represented by y. We do have to update the values of maxSet y and minSet y to account for this new information. These newly added elements may actually upset the old max and min values.\nThat is essentially what these two lines of code are doing. It is very simple but it is crucial to ensure that you maintain correctness as you go along. Look at the maximum element that was there in the set that was being tracked by x and if that is larger than the maximum element in the old set that was being tracked by y, then the max set of y should be updated so that it reflects this new element as the maximum.\nHowever, if the maximum was smaller than the maximum element of the set being tracked by y previously, then you do not need to change anything. You could write this down as an ‘if-else’ block. But it is equally accurate and perhaps visually simpler to just take a max of the two old maxes, and similarly, for minSet, you take min of the older mins.\nHopefully, this update makes sense and this ensures the accuracy of the maxSet and the minSet arrays at least on all the elements that are representatives at any stage of the algorithm. That brings us to the end of this discussion on basic DSU implementation. Now, that you have your own version of DSU, you are prepared to tackle problems that use this data structure.\nThese two problems that we have discussed so far were very explicitly asking for a DSU implementation. Many problems have the DSU demand kind of hidden away in a more subtle way. We will see a couple of examples of problems where DSU comes in handy. But it may not be completely obvious that that is what you need to invoke.\nThere will be links to a lot of practice problems that you can try out on the course website. But in the meantime, for the rest of this week, we will look at a couple of different problems quite explicitly. In the meantime, I hope that you have a chance to try out everything that we have discussed so far. As usual, if you have alternate implementations in Python or Java or any language of your choice, please do make sure to submit a pull request on the official repository.\nI look forward to seeing your submissions, and we will keep the conversation going on Discord. Thanks so much for watching so far, and I will see you in the next video. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec30.html",
    "href": "materials/cpnotes/Lec30.html",
    "title": "Shortest Paths - Module 1 (Dijkstra’s Algorithm)",
    "section": "",
    "text": "Lecture - 30\nShortest Paths - Module 1 (Dijkstra’s Algorithm)\n(Refer Slide Time: 00:11)\n\nWelcome back. Let us continue from where we left off in the last segment where if you recall we are talking about the single-source shortest path problem. And we said that, well, if you are dealing with an unweighted graph when all the edge weights can be thought of as one, then an algorithm that you have already seen from last week, which is breadth-first search, actually gives you the shortest path information that you are looking for.\nWe also saw that breadth-first search fails even on small examples once edge weights do come into the picture. We discussed a way of making BFS work when all the edge weights were positive integers, and we did this by puncturing the edges with artificial intermediate vertices so that BFS would be sensitized to these weights by having to go through these prolonged paths.\nHowever, we also observed that this can be an expensive trick. So we wanted to see if there was a more efficient way of achieving the same outcome, which is to say, having a way to determine the shortest paths but without having to go through this expensive route of creating these large number of artificial vertices. So that is going to be the focus for this segment. We are going to deal with the case when we have only positive edge weights to worry about, and we will see if we can essentially predict what BFS was doing on that modified graph but without having to go through the trouble of actually modifying the graph.\n(Refer Slide Time: 01:50)\n\nSo we are going to continue working with a distance array, which will typically be initialized in this way. So you have a fixed source vertex and the distance from the source to itself is going to be zero. And to begin with, you do not know anything about the distances of the other vertices. So we will typically initialize these values to infinity in principle. And in your code, you want this to be a sufficiently large number.\n(Refer Slide Time: 02:31)\n\nNow, let me introduce the concept of a tense edge, which is a notion that keeps coming up in many shortest path algorithms. So let us say that we have our source vertex here, and we have an edge from ‘u’ to ‘v’ whose weight happens to be ‘w.’ And let us say that we have some current understanding of how to get from the source to the vertex u, and this is reflected in the distance array with the value ‘t,’ which is to say that there is some path from ‘S’ to u, whose total cost is t.\nAnd similarly, we have some value in the distance array for the vertex v. That value – let us call it ‘d’ – which is again just to say that our current understanding is that the best way to get to v from the source S is via a path whose total cost is d. Now, we say that this edge here is tense if the following inequality holds. The inequality is t + w < d.\nNow, please feel free to pause here for a minute and think about: What does this inequality really mean? Does this inequality imply that there is something about the way you have stored your distances that does not seem quite right? And maybe that is why you are tense because something needs fixing. So please take a moment here and think about what is this inequality really telling you.\nAlright, so hopefully it is fairly visible that what this inequality is telling you is that there is a better way to get to v compared to whatever option you had in mind when you stored the value ‘d.’ And that better option is to simply come to u first in whatever way that you were able to come to u with a total cost of t, and then jump across the edge from u to v with an additional cost of w. Even when you put those two together, you are still better off than d.\nNow, let me just quickly point out that because of the way this picture is drawn, you might be tempted to believe that this definition only makes sense when t and d are finite values and that we actually have these paths that we know something about. But this is just a limitation of the picture. The definition does make sense even when t or d, or both happen to be infinite.\nSo let us consider what happens if t is infinite. Well, that just means that we have no idea about how to get to the vertex u. So, if we do not know how to get to u, then we are not going to be able to leverage the edge from u to v to find a shorter path to v via u. So if you have a vertex for whom the distance value right now is ∞ (infinity), none of the edges that go out of that vertex will ever be tense because infinity is never less than anything.\nSo that is what happens if t is ∞. But on the other hand, if t is finite, but d is ∞, that means that we do not know, anything about how to get to v, but we do know something about how to get to u. So that means that the edge from u to v is going to be tense whenever d of v, the distance value of v is ∞.\nAnd in particular, if you think about what happens in the first step, notice that the distance of S is zero and everything else is ∞. So think about: What you can see about all the edges that are going out of S? Well, as you might guess, all of these edges are going to be tense.\nLet us consider an edge from S to v with a weight of w. Well, we know that t in this example, which is the distance from S to itself, is zero. So what we have is zero + w on the left-hand side and ∞ on the right-hand side. So this equation certainly holds. So at the very first step at the beginning, you definitely have as many tense edges, as there are out neighbors of the source vertex S.\n(Refer Slide Time: 06:58 & 07:12)\n \nNow, what do you do when you see a tense edge? Intuitively, you want to resolve this tension. And this process is typically called relaxation. So whenever you see a tense edge, you probably want to account for the information that you have and somehow fix the situation with the distance array.\nSo the process of relaxing an edge is exactly what you expect it to be. So let us go back to this picture of what a tense edge looks like and what we want to do is get rid of this old information that we have with regards to the distance of the vertex v. So d is clearly outdated, and we can do better.\nSo what we do is we update the value of the distance of v with d + w, which is, as of now, the better way to get to the vertex v. And if you want to maintain a predecessor pointer which tells you, well, what was the previous vertex on the shortest path, you could do that. And you could update that to being the vertex u for the vertex v.\nSo predecessor of v is going to be u because that is the last edge on the current best path that you are working with. So now that we know what a tense edge is and we understand the process of relaxing it, let us present an algorithm, which is based on performing this operation a number of times in a systematic way.\n(Refer Slide Time: 08:24)\n\nSo here is what we are going to do. We are going to identify the vertex that is closest to the source and notice that in the beginning, this is just going to be the source vertex itself. And what we want to do is extract this vertex, which is to say we want to ultimately get rid of this vertex. Just like we do with BFS, we look at the vertex which is at the head of the queue, we put it in the limelight for some time, we process all of its neighbors, all of its unvisited neighbors, and then we get rid of the vertex.\nSo we want to do something analogous here, but in a way that is sensitive to the information about the edge weights. So what we are going to do is pull out the vertex that is closest to the source, and we are going to go to all of its neighbors and if any of those incident edges are tense, then we are going to relax them, and then we throw away this vertex.\n(Refer Slide Time: 09:24)\n\nSo this method is at the heart of what is popularly known as Djikstra’s algorithm and let me just present this to you in a slightly more explicit fashion, and this is still going to be pseudocode. So what we have is the distance array, which to begin with has a zero value for the source and values initialize to infinity for all the other vertices. And what we want to do is insert all of these values into some sort of a priority queue or a heap, which is essentially a data structure that supports fast extraction of the minimum value.\nSo that is why we are interested in using a heap. It is just going to be efficient for the most frequently performed operation in this algorithm. So as long as we have elements left on the heap, what we want to do is extract the element that has the smallest value – the value being the distance from the source. And what we want to do is relax all the tense edges that are incident to the extracted vertex.\nSo recall that what the relaxation step entails is an update in the distance array. You want to make sure that the distance of v is updated to the distance of u + the weight of the edge from u to v, whenever this sum is better than the current value of the distance of v. And also, if you are maintaining a predecessor array then you want to update the predecessor of v so that it becomes the vertex u.\nSo this is what you do with all the tense edges. And remember that whenever you do the relaxation, you also want to remember to update the value of v in the priority queue as well. So that is the decrease key operation here. And this is essentially the whole algorithm.\nSo the idea is to constantly find vertices that are currently the closest to the source, and keep relaxing all the edges that are incident on them. And by the time you have processed all the vertices once your queue becomes empty, then you are pretty much done.\nNow, the interesting claim of course is that once you have finished, then the distance array is a true reflection of the actual shortest path distances from the source to the corresponding vertices. The intuition for this is that this algorithm explores the graph in the order in which the vertices are being extracted.\nSo it is a lot like BFS but somehow has been sensitized to account for the edge weights. And if at the point when a vertex is being extracted, this is not the best way to get to the vertex. The value of the distance of that vertex is worse than the cost of some shortest path to that vertex. Then assuming that you had done everything right up to the previous step, which is like an induction hypothesis, you could argue that the better part would have been a witness for actually being a reason to pull up this vertex even earlier.\nSo in some sense, the framework for how you prove the correctness of this algorithm is the structure of it is similar to how you work out the correctness for the BFS algorithm. But now, you have to carefully account for the way it is, and really the fact that there are no negative weight edges does play a role in the proof of correctness.\nSo just in case you have not seen this proof before, I would encourage you to either puzzle it out on your own based on what we have discussed so far or you could look up the references in the description of this video and read up on the proof of correctness if you are interested. So now let us switch gears a little bit and focus on some implementation issues.\nSo naturally, we want to store the values of the distances in our priority queue so that we can extract the minimum element efficiently, and that is something that we do often. So it makes sense to use a priority queue. Unfortunately, in C++, the built-in priority queue data structure does not have native support for updating key values.\nSo notice that you do have to decrease key values often whenever you are relaxing edges, and there is not a way to do this directly. You might of course say that, well, what about just inserting a new value for v with the updated distance and getting rid of the old one. Well, in a priority queue getting rid of a value is not as easily done.\nYou can get rid of the thing that has the minimum value but getting rid of an arbitrary value is harder. However, this idea of simulating an update by first deleting the element that you are working with, and then inserting the new value for that element – that makes sense, and it can be implemented with what is called a set. So let us review our options in the C ++ STL.\n(Refer Slide Time: 14:15)\n\nSo we have a priority queue or a heap, which is what we were originally proposing to use. And with a priority queue, you get a constant time lookup for the largest element, and you have logarithmic complexity. So this is logarithmic in the size of the collection for either deleting this largest element or for inserting a new element. Right. So that is what you get with a priority queue.\nOn the other hand, you also have the possibility of using a set, which basically will keep track of a sorted collection of items. So you can still have quick access to either the largest or the smallest elements depending on the order in which you set up your sorting, and on top of that, you can also search for elements and insert and remove elements with again a logarithmic expense. So that is comparable to a priority queue.\nSo what we are going to do is essentially use a set instead of a priority queue. By the way, I should mention that although I am quoting the C++ documentation here in saying that you can look up the largest element but even for a priority queue you can pass an additional parameter and change that from largest to smallest.\n(Refer Slide Time: 16:02)\n\nSo that is not really the problem. The issue with using a priority queue is the fact that you cannot update the values after you have inserted them, and you cannot remove an arbitrary value quickly. You can delete the extreme value, but you cannot delete an arbitrary value. So that is why we will be using a set instead of a priority queue. So let us look at what that looks like.\nSo we are going to basically split this decrease key operation into two steps. So first delete the old value, and then insert the appropriate new distance that is going to be the distance of u + the weight of the edge from u to v. So hopefully that makes sense. And notice that extract min is also easy to simulate because the collection is sorted when you use a set, you can just access the first element and that is the one to remove.\n(Refer Slide Time: 17:00 & 17:30)\n \nSo you can also invoke the remove operation which is a part of the set interface on just the first element. So that is very much doable. So this brings us to the end of the description of what Djikstra’s algorithm does and I am going to wrap this discussion up by claiming that the algorithm works correctly when all edge weights are non-negative.\nI am going to state this without proof, but I would encourage you to try and come up with examples that break this algorithm when there are negative edge weights involved. So try to see if you can figure out where exactly the algorithm breaks down.\nSo now that you know the mechanics of what Djikstra’s algorithm does, there are a few things that you can do from here. The first is to play around with some examples, especially if you are seeing this algorithm for the first time, I think it is really helpful to build up your intuition by just working through a few examples simulating what the algorithm would do, and so on.\nSo for instance, on visualgo dot net, there is an entire module dedicated to SSSP algorithms, and you can see that they have both Djikstra and modified Djikstra featured here. So we will be discussing this modification to Djikstra’s algorithm in the last segment of this module. But in the meantime, you could just go ahead and play around with the original version, which is exactly what we have discussed so far. You can work with the prebuilt examples or you could generate your own. So feel free to have some fun doing this.\n(Refer Slide Time: 18:20)\n\nThe other thing is that you might be curious about the proof of the claim that we made about correctness. So we will not really have the time to get into this in these videos. But if you are curious, then I have a few pointers in the description of this video. You could either read up on the proof or watch some other videos to figure out what is going on.\nIf you do this then try and watch out for what part of the argument really uses the assumption about non-negative edge weights. It does come into play in a very specific part of most arguments. So it is interesting to try and identify why this assumption is so important to the correctness of the algorithm. The third thing, of course, is the implementation.\nSo that is what we are going to do in the next segment in the context of a problem. So you could just continue this conversation with me by switching over to the next segment, and we will be solving a problem, and implementing Djikstra’s algorithm at the same time. So I will see you there. And good luck, exploring various facets of this very interesting algorithm!"
  },
  {
    "objectID": "materials/cpnotes/Lec24.html",
    "href": "materials/cpnotes/Lec24.html",
    "title": "Graph Foundations - Module 1 (Graph Traversals)",
    "section": "",
    "text": "Lecture - 24\nGraph Foundations - Module 1 (Graph Traversals)\n(Refer Slide Time: 00:30)\n\nHello and welcome to week five of Getting Started with Competitive Programming. This week marks the start of our graph algorithms journey and we are going to be fairly focused on graph algorithms all the way up to week nine or so. In this week, we will talk a lot about two fundamental graph traversal algorithms called breadth-first search and depth-first search, or BFS and DFS for short.\nThese are very popular traversal algorithms, which have a lot of interesting properties and applications. Chances are that you are already familiar with the traversals themselves. If you are comfortable with implementing them, you should feel free to just skip this video and jump straight into the three problems that we will be solving this week.\nHowever, if you are not super familiar with how to implement these traversals, then you want to stick around. We are going to start with actually the basics of graphs themselves and how we represent them, just to make sure that this presentation is self-contained. To begin with, what is a graph?\n(Refer Slide Time: 01:20)\n\nFormally a graph is usually given by a pair V, E, where V can be any set you like and E is a collection of pairwise relationships between the elements of V. The set V is often called the set of vertices or nodes and the set E is usually referred to as the set of edges or connections.\nNow, this particular formulation may strike you as being a little bit abstract and also overwhelmingly simple. But it turns out that even a simple idea can capture a lot of different scenarios. You have probably encountered graphs already in your day-to-day life. For example, the road network in your city can be thought of as a graph, with the key locations being modeled as vertices and roads that connect these key locations as being the edges or the connections.\nSocial networks that you might be a part of can also be thought of as graphs. For example, you have Facebook, where you could think of the people who use Facebook as being vertices and two individuals being friends is being represented by edges. Another popular social media network is Twitter.\nBut the idea of a relationship on Twitter is slightly different from the way it works on Facebook. Typically, friendships on Facebook are mutual. Whereas, on Twitter, you could follow somebody without having that person follow you back. The pair-wise relationships in Twitter are not necessarily symmetric, whereas they are on Facebook.\nWhen you have a ‘symmetric’ relation, you typically model this with what is called is an undirected graph, where the edges do not have any orientations. Whereas if you have an ‘asymmetric’ relationship, then you model them as a directed graph where the edges do have orientations so that you can remember which way the relationship goes. Sometimes you also have mixed graphs, where you allow for both directed and undirected edges. But that is going to be not very relevant to our discussion right now.\n(Refer Slide Time: 03:24)\n\nGraphs usually have a very neat visual representation. You could think of each vertex as being represented by a dot in the plane and whenever you do have a relationship or an edge between these two vertices, you connect them by a line. If you have an undirected edge, it would look like that. If you have a directed edge coming from an asymmetric relationship, then you could represent it with an arrow, with the arrowhead pointing in whatever direction you want it to based on the way the pair is given.\nOf course, if you have both ‘x y’ and ‘y x,’ then you could have arrows pointing both ways. Or if it is a mixed graph, then some of the edges are going to have arrowheads and some of them will not. Now sometimes you want your graph to actually store additional information. For example, if your graph is modeling a road network, then you might want the edges to have weights on them to somehow represent either the length of the road or the quality of the road or the cost of traveling on that road if there is a toll gate, for example, and so on and so forth.\nYou will often encounter graphs that have weights on either the edges or the vertices or perhaps both. Sometimes your edges could also be colored. For instance, maybe you have a friendship network that not only captures friendships but also captures rivalries. You might say that you have a red edge to denote a rivalry, a green edge to denote friendship, and perhaps no edge to denote neutrality, that perhaps these people do not know each other to begin with.\nNow, in some situations, you might also want to allow for the possibility of having multiple edges between the same pair of vertices in a graph. This is usually not the default situation. So, the set of edges, when thought of as a collection of pairs over V, is usually thought of as a set, as opposed to a multi-set.\nWe would not normally allow for this kind of repetition. But maybe your application requires that, perhaps, you are keeping track of the number of times that something happens between a pair of vertices and so on. Notice that you can also capture this with edge weights. Instead of repeating pairs in E, you could just have a weight function that keeps track of the number of times that a particular edge is repeated.\nNonetheless, graphs, where you do allow for repetitions of edges, are usually called multi-graphs, and graphs, where you do not allow for this, are called simple graphs. Another feature of multi-graphs, which is something that is not allowed in a simple graph, is the possibility of having the so-called self-loop.\nYou could have a vertex, which has an edge to itself. This is not something that will happen in a simple graph. But if you are working with a multi-graph, then multiple edges between distinct pairs of vertices and edges from a vertex to itself, all of this is fair game. Normally, we will be working with simple graphs, which are undirected and unweighted.\nBut of course, depending on the problem that you are trying to solve, you might need edge weights – that is pretty common. You might also need your graph to be directed, which is also fairly common. Everything that we discuss here will (generally speaking) apply to directed graphs for sure. We do have to be careful once we start talking about weights.\nFor example, when we look at breadth-first search, we will see that that is one way of getting the shortest paths between pairs of vertices. But this is under the assumption that we are working with an unweighted graph. Once you bring weights into the mix, this may not be true. In fact, next week, we are going to look at other algorithms that deal with this situation when we do have weights to worry about and we will be looking at the shortest path algorithms that take care of this more general case.\nYou do have to be a little bit careful about what exact situation you are in. But as I said, for the sake of making this discussion concrete, we are going to assume that we are working with simple, undirected, and unweighted graphs with the comment that most of this translates quite easily to directed graphs in a very natural way.\n(Refer Slide Time: 07:40)\n \nLet us just take a look at a couple of examples of graphs so that we can get back to how we store them when we write our code. Here is a couple of examples straight from the Wikipedia page on graphs. Now let us take a look at the first way that we can store a graph in memory. How do we represent a graph when we are writing code?\n(Refer Slide Time: 08:04)\n\nA natural way to do this is the so-called adjacency matrix and this is what this looks like. So, this is an ‘n X n’ matrix, where ‘n’ is the number of vertices in your graph and the ‘i j’th entry, which is to say the entry in the ’i’th row and the ’j’th column is a ’1,’ if and only if there is an edge from ‘i to j.’\nNotice that if your graph is undirected, then the corresponding adjacency matrix will be symmetric, which is to say that, for instance, if you were to take the picture of the matrix that you are seeing on your screen right now and if you were to print it out and if you were to fold this picture along the diagonal, then you will see that the colored boxes are going to line up over each other and the uncolored locations are also going to exactly overlap on each other. That is symmetry around the diagonal.\n(Refer Slide Time: 08:54)\n\nOn the other hand, if you are working with a directed graph, then you will not enjoy necessarily this kind of symmetry, as you can see from this example. Again, please feel free to pause the video here and really spot and appreciate the asymmetry in this adjacency matrix. If you just focus on entries on either side of the diagonal, for instance, you will immediately spot examples of asymmetry. Moving on, let us actually take a closer look at an adjacency matrix construction when weights are involved.\n(Refer Slide Time: 09:26)\n\nHere is an unweighted graph with the edge weights written in green boxes alongside the edges, and here is its adjacency matrix representation. It is exactly as you would expect with the ‘i j’th entry denoting the weight of the edge between the vertices ’i’ and ‘j,’ and because this is an undirected graph, this edge weight gets captured twice in this adjacency matrix.\nBut notice that the formulation works just as well to capture directed and weighted graphs as well. The ‘i j’th entry will simply reflect the weight of the edge from ’i’ to ‘j,’ if this edge were to exist in the graph. Now let us just look at a couple of features of the adjacency matrix representation.\n(Refer Slide Time: 10:13)\n \nFirst, notice that it is pretty space-intensive. It actually will always consume n2 units of space, irrespective of whether the graph actually has n2 edges or not. So, a sparse graph is a graph intuitively where there are not very many edges and in particular, let us say that you have only a linear number of edges like you would have if your graph was a tree, for example.\nEven for such graphs, you are actually consuming n2 units of memory and your adjacency matrix is just going to look like a vast ocean of 0s with a few 1s scattered here and there. It feels very wasteful and in the context of competitive programming, you know that apart from time limits, you also have space limits, which makes the adjacency matrix representation infeasible in any situation where you have more than a few 1000 vertices in your graph.\nDo watch out for that and keep that at the back of your mind. If the number of vertices in your graph is in excess of, let us say, 3000 or 4000, then you probably do not want to be using an adjacency matrix representation. But when is this a good representation? Well, it works pretty well for detecting if a pair of vertices have an edge between them or not.\nIf your application makes frequent use of such queries, then probably this is going to be a relevant representation. Notice that checking if there is an edge between ‘i’ and ‘j’ or from ‘i’ to ‘j’ is simply an array look-up if your graph is stored as an adjacency matrix. On the other hand, let us think about how much time does it take to enumerate all the neighbors of a vertex in a graph?\nWhat are the neighbors of a vertex? For instance, in this example, the vertex labeled 1 has neighbors in the vertices that are labeled 2 and 5. Vertex 2 has neighbors 1, 3, and 5. The vertex 6 has only one neighbor and that is 4 and so on and so forth. If you wanted to use the adjacency matrix to actually enumerate all the neighbors of a vertex, how much time do you think that will take?\nIf you think about it for a moment, you will probably realize that this is going to take order ‘n’ time, irrespective of how many neighbors a vertex has. You could be vertex number 6 with just 1 neighbor. But for the algorithm to be able to know that, it still has to scan the entire row or column corresponding to the vertex 6 to figure out how many neighbors it has.\nOf course, if it is an undirected graph, you could scan either the row or the column. In a directed graph, you have to distinguish between whether you want to enumerate the ‘in’ neighbors, which is all the vertices that have an edge into this vertex, arrowheads pointing inwards or the ‘out’ neighbors, which is all the vertices that this vertex is a neighbor 2. That is the arrowheads pointing outwards.\nOnce again, to enumerate either the ‘in’ neighbors or the ‘out’ neighbors would require a full scan of the row or the column corresponding to this vertex. The point is that it is going to take time proportional to the total number of vertices in the graph, even if this vertex has, relative to the total number of vertices, a very small number of neighbors.\nThe number of neighbors that any vertex has is called the degree of that vertex, and ideally, you would want to be able to enumerate the neighbors and time proportional to the degree of a vertex as opposed to a blanket order ‘n’ kind of a running time. This is a fairly substantial drawback when working with adjacency matrices. As we will see, this is also something that is going to make your graph traversal algorithms a little more expensive if you were to use adjacency matrices instead of adjacency lists, which is the next representation that I want to discuss.\nAn adjacency list is a representation that is motivated by the need to essentially have a more efficient way of being able to traverse the neighborhoods and also have a more space-efficient representation, which hopefully is a function of the actual amount of material in the graphs. We want a representation that is not always going to be order n2 but is actually going to reflect the density or the sparsity of the graph. More edges more space, naturally. But fewer edges, hopefully, less space.\n(Refer Slide Time: 14:57)\n\nHere is what the adjacency list representation looks like. Let us use the same example as before. What we are going to do is essentially store the information about this graph as a collection of lists. There are going to be as many lists as there are vertices in the graph. In this example, we have 6 of them. So, there are going to be 6 lists and each list is essentially going to be ‘information’ about all the neighbors of the corresponding vertices.\nNotice that because we are working with a weighted graph, this list will also have to carry information about the weights of the neighbors. Essentially for each vertex, the list is going to consist of the labels of the neighbors immediately followed by the weights. Of course, for an unweighted graph, you could either just skip the weights or set them all to 1 or some other default, which makes sense in the setting of your problem.\nThis is the adjacency list representation. Notice that the amount of space that you need is just twice the number of edges because every edge is going to feature in exactly two lists corresponding to its two endpoints. The amount of time that you need to enumerate all the neighbors of a vertex is now proportional to its degree because all you have to do is walk through the list corresponding to the vertex. You are going to take just the amount of time that you need, which is to say, you are going to take time proportional to the degree of the vertex to be able to enumerate its neighbors.\nIn this sense, the adjacency list has two advantages over the adjacency matrix representation. But of course, the one thing that it will not do so well is to tell you if there is an edge between a given pair of vertices i and j. This was the one thing that was really easy in the adjacency matrix representation.\nBut here, if you want to know if ‘j’ is a neighbor of ‘i’ or not, then you will have to essentially scan the whole list corresponding to either i or j and look for the other guy and try to figure out if there is an edge between them or not. Hopefully, these two representations make sense.\nThese are not the only representations. There are others. Another common one is the edge list representation, which you are welcome to look up. I am not going to present it here because, for the most part, everything that we are going to do will be very workable with either the adjacency matrix or the adjacency list representations. Now let us just take a quick look at the implementations of these representations starting with the adjacency matrix first.\n(Refer Slide Time: 17:36)\n\nHere, we are basically declaring a two-dimensional array with a substantial amount of space in reserves. You can initialize MAX_V to the maximum amount of space that you would need. You could derive this by just looking at the constraints of your problem and once you have reserved enough space, it is just a matter of populating this matrix.\nNow the code that is written here is designed to take this kind of input, where you literally have the rows of the adjacency matrix being spoon-fed to you. But a more typical representation is of a list of edges.\nYou would just essentially have to go through that list and make sure that the right entry is triggered to 1. It is also going to be equally simple. In fact, in some ways even simpler because all you have to do is run one for loop that traverses the list of edges. Let us say you have taken values U and V from the current line, you just have to make sure that AM of UV is set to 1. If there are weights involved, then typically the list representation will have the weights specified either as the first or the last numbers. Just make sure that you also append the weight. Instead of setting the matrix entry to 1, you actually set it to the value of the weight that has been given to you.\nThat is all that you need to do. So, the adjacency matrix representation has a fairly straightforward implementation and this code is actually from the GitHub repository for the competitive programming book. I will have a link to it in the description. You can go ahead and take a look. Run it and play around with it and make sure that it makes sense.\n(Refer Slide Time: 19:35)\n\nNow let us take a look at the adjacency list representation. The code here seems to be a little bit longer, but it is also equally straightforward to pass. In terms of the representation, as you might remember, an adjacency list representation involves creating ‘n’ different lists, each of which can store the list of neighbors. But remember, we might also have to account for weights.\nEach list is not just a list of vertices, but it is a list of vertices along with information about the weight of the edge that is being represented when you put this vertex in that list. Instead of just having a list of lists of integers, we are going to have a list of lists of pairs of integers. Hopefully, that makes sense. Every pair is going to represent a vertex, the weight of the edge between that vertex, and the vertex represented by the list that this pair is on.\nOnce again, let us go back to the graph that we had earlier and this is going to be represented by this kind of input. There are 6 lines corresponding to the 6 vertices. Every line starts off with a number that represents the degree of the vertex. That tells you how many vertices to anticipate and how many more entries are coming up.\nNow, because we have information about weights, if the degree for example is 2, you should expect 4 entries because you are going to get information about the 2 vertices, which are the neighbors, and also the weights corresponding to the edges that the current vertex has to these two other vertices.\nJust to be sure, let us walk through what is going on here. The very first line tells you how many vertices they are. That gives you a sense of how many times the outer for loop should be run. Once you get into the outer for loop essentially, each snapshot represents what is going on with one vertex.\nWhen you are reading the ‘i’th line, you are essentially populating the adjacency list for vertex number ’i.’ What does the ith line look like for any ‘i’ between 1 and n? Well, the first number is the degree of the vertex ‘i.’ That tells you how many times the inner for loop should run and every time you are inside the inner for loop, you need to take in two pieces of information.\nOne is the label of the neighbor, and the other is the weight that this neighbor brings with it. That is going to be the weight of the edge between ‘i’ and the neighbor that is just going to come in. You read in these two pieces of information, make a pair out of them, and append this pair to the list that is the ’i’th list. The list that is tracking all the information about the ’i’th vertex.\nThat is essentially the adjacency list representation. You might have to adjust this a little bit in case your edges do not have weights or if the edges are being given to you in a different input format. Once again, a pretty common format for graphs is just a list of edges and again, you will have to tweak this code a little bit, if that is the form in which you receive your input.\nWhen there are no weights, you can either use a sensible default value for the weights or you could simply switch to using a list of ‘list of integers’ as opposed to a list of ‘list of pairs of integers’ – so, whatever is convenient in a given situation. You can find a link to this code in the description.\nOnce again, this is from the GitHub repository for the Competitive Programming book. I would again encourage you to play around with this and see if you can adapt it to different settings like especially graphs without weights or graphs where the input is given as a list of edges as opposed to in the adjacency list format, as was the case here. With that said, let us now move on and talk about graph traversals a little bit.\nThis video is split into two parts. We will actually talk about the algorithms in the next video. But just before that, so you have something to think about, I want to give you some intuition about how these two traversals work. I like to think of the breadth-first and the depth-first traversals as capturing two distinct web browsing styles.\n(Refer Slide Time: 24:06)\n \n \nSuppose you are looking at the Wikipedia page for the COVID-19 pandemic. This is a long page with a bunch of different links and we all like to open browser tabs in the background when we are reading something. The two browsing styles that I was talking about are the following.\nOne could be that you just like going down the rabbit hole of distraction. As you are reading, the first time you encounter a link, you just click on it and you open it and you start looking that up.\nNow as you start reading, this is the first link that you encounter, you click on that, and then as you are reading this, you click on the first link that you encounter again and you just keep going. The only thing you are probably careful about is to not visit a link that you have already visited before because if you think about it, that is going to lead you to just going in circles and you want to avoid that.\nBut other than that, you just keep going. The moment you see a link, you cannot help yourself, you just click on it and the only time you stop is when you encounter a page that has no links whatsoever. That is a bit of a dead-end and at that point, you close that tab and go back to the tab that you came from and you look for the next link on that page and you keep doing this.\nThat is essentially the main intuition for a depth-first traversal. As I said, this is going deep into the rabbit hole of distraction in the context of web browsing. But in the context of a general graph, you want to stop somewhere and you want to explore this graph – that is kind of the idea.\nYou go to your neighbor and then you go to your neighbor’s neighbor and you just keep doing this, until you get stuck, until you come to a vertex, which does not have any new neighbors for you to explore. At that point, you back up and then pretty much repeat the same. That is depth-first traversal.\nWhat about breadth-first traversal? Well, it is the opposite philosophy, where essentially, you do not want to go deep in one particular direction. But instead, you want to explore everything at the first level, first. In this case, the way you browse the web would be that you go through this page and you just open background tabs for all the links that you see on this page.\nThere are going to be a bunch of other links as well, but I will spare you going through the whole example. But here, the idea is that once you have opened the tabs for all of the links on this page, then you are basically done with this page and this, of course, is an especially long page, so it is going to take you a while. But let us say that once you are done, then you move on to the next open tab on your list.\nNow chances are that this page has links to some of the pages that you already have open in your browser. Whenever that happens, you essentially ignore such links because these would not be fresh locations as far as you are concerned. You somehow keep track. Your browser tells you by typically coloring the links purple or something when you visited them before.\nBut in your code in your algorithm, you will have to explicitly keep track of what vertices you have visited already. But the idea is that, at the top level, you have explored all the neighbors, or at least in principle, you have visited all the neighbors of the top vertex by just opening up these pages and new tabs, for instance.\nNow you basically go down the ladder and to the first layer and you essentially repeat this process. Every time you are at a vertex, you go through all of their neighbors that are new to you. Once you are done with that, you move to the next open tab in your browser, which when you actually think of this as an algorithm, this is going to be the next vertex in a queue, which is the most natural data structure for implementing this sort of a breadth-first idea.\nTo begin with, you have an empty queue and then you queue up the very first vertex and that is going to be the vertex from which you are starting your exploration. Then you look at all the neighbors of this vertex and you essentially push all of these neighbors onto the queue and mark them as visited vertices. Then you just keep popping the first element in the queue and loading up all of its new neighbors at the back of the queue.\nYou basically keep doing this, until you have nothing left to explore. These are essentially the two traversals. In fact, if you are feeling adventurous, you might want to just see if you want to consider how you would implement both of these traversals. Once again, in depth-first search, you essentially say – Alright, I am at the current vertex, let me find an unvisited neighbor of this vertex and go there.\nThen this is an inherently recursive description. You bail out of the recursion when you have no new unvisited neighbors from the vertex that you are currently standing on. At this point you backtrack. With breadth-first search, the natural thing to do is to basically load up the new unvisited neighbors on a queue, and essentially, once that is done, you pop the head of the queue and do this again. You keep doing this until you have run out of vertices to explore.\nThese traversals are very natural and have a lot of interesting applications, and happen to be very efficient. We will talk more about both of these traversals in the second part of this module. I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec25.html",
    "href": "materials/cpnotes/Lec25.html",
    "title": "Graph Foundations - Module 1 (BFS and DFS)",
    "section": "",
    "text": "Lecture - 25\nGraph Foundations - Module 1 (BFS and DFS)\n(Refer Slide Time: 00:30)\n\nWelcome back, to the second segment of the first module in week 5. We are talking about graph traversals this week and in this segment, we will actually talk about the breadth-first and the depth-first traversals of a graph. In the previous module, we talked about how graphs are represented. We talked about the adjacency matrix and the adjacency list representations and we also had sort of a very intuitive and vague sort of overview of how these traversals might work.\nSo, if you have not seen the first segment, then it might be advisable to watch that first unless you are already familiar with how adjacency matrices and adjacency lists work, in which case you could just start off with this one directly. In fact, if you are already comfortable implementing BFS DFS yourself, then you could even skip this lecture and jump ahead and look at the problems directly.\nThere are three problems that we discuss in this module and if that leaves you hungry for more then please look at the extra section on the course website and you will find more problems to try out your BFS DFS skills on. Now with all that said, let us get started here. We will basically be focusing on what these traversals do and not so much on proving interesting properties that these traversals have. We will not be getting so much into some very common and well-known applications of these traversals.\nWe will give you a bucket list of these things without really explaining them in any detail and there are links in the description of this video where you can find out more if you are interested. In case you have not seen these topics from a previous course that you have done, you might actually be interested in following up and learning a little bit more because these things are pretty foundational and really interesting. I would encourage you to actually look things up a little bit beyond what we are able to fit into this video here. With that said, let us start first with a breadth-first search.\nRemember, for breadth-first search, we said this is like when you start off reading a page on Wikipedia, you open all the links that you see in background tabs. Then you close the page and then you start off with the first page that you have opened and then you do the same thing.\n(Refer Slide Time: 02:31)\n\nLet us take a look at what this might look like on an example. Here is an animation that shows you the sequence in which a BFS traversal would visit the vertices of this graph. Let us take a closer look at what happened. The story begins at the vertex labeled 1 and that is the first vertex that you mark as a visited vertex.\nYour known territory is just this first vertex. Then you look at all of the neighbors of 1 and you pick those that you have not visited yet. Since all of these vertices are new to you right now, all the three vertices 2, 3, and 4 get pushed on the queue. Now, after you have explored all the neighbors of 1, you basically move on from 1.\nThis is like saying you close the first page that you were reading and now you move on to the next thing on the queue. In this case, assuming you load up the vertices in lexicographic order, the next vertex in the queue is 2. Now when you visit 2, you again want to look at a neighbor of 2 that you have not seen before. So, 2 has two neighbors in this graph, 1 and 5.\nBut since 1 is a vertex that you have already seen, you ignore 1 and you basically explore the vertex labeled 5, by pushing it to the end of the queue. Now you have completely explored vertex 2, you move on to the next vertex in the queue, which is vertex 3, and speeding up the explanation a little bit 3, will end up pushing 6 and 7 on the queue. You will push off 3 and turn to 4 because that is the next vertex on the queue.\nNotice that at this point 4 will bring in 8, which is its only unvisited neighbor to the back of the queue and once it hops off the queue, the next thing on the head of the queue is 5, and so on and so forth. In the description of this video, you can find a link to a website called visualgo dot net and they have a really nice interface where you can draw your own graph and you can simulate what the BFS traversal would do, in what order it would visit the vertices and so forth.\nIf you really want to get a feel for how the algorithm executes in different kinds of graphs, then please feel free to try this out. It is also a good idea to just sit down with pen and paper and work through some examples of specific kinds of graphs. For example, what would BFS do if you had a complete graph? That would be a graph where every possible edge is present, every pair of vertices is connected with an edge. In this case, notice that no matter where you start, the BFS traversal would basically finish off in one layer.\nBecause every vertex is adjacent to every other vertex. Irrespective of your starting point, you just kind of visit everything in one shot. You could contrast this with what DFS would do if it was working with such a graph. I think it is really useful to play around with a few examples. At this point, I would like to switch gears a little bit and actually talk about the implementation for BFS.\n(Refer Slide Time: 05:41)\n\n\nTo begin with, we have a ‘distance’ vector that is going to help us keep track of how far away the vertices are from the source. When we have not seen anything, at this point, every vertex is at distance infinity, we just do not know anything about how close these vertices can be. Although I am not formally defining distance here, this is something that you can look up and there are links in the description of the video in case this is not a familiar notion.\nBut for now, you can just intuitively think of the distance between any two vertices in a graph as being the length of the shortest path between them. Where a path is exactly what you think it is – a sequence of vertices that you can follow to get from one vertex to another. You want that there is an edge connecting the consecutive vertices so that you can actually walk along the path.\nTo begin with, as I said, the distance is unknown to us, in the sense that we have not really started exploring this graph at all. We started the source vertex. So, we initialize the distance of ‘s’ from itself to be 0 because you do not have to walk around from s to reach s, that is exactly where you are at already. For the remaining vertices, as we start actually discovering these vertices, we will update the distance vector as we go along.\nThe other thing that we want to keep track of is some sort of a parent array and this essentially tells us who is the reason for our discovery. The parent of any vertex other than the source is going to be the vertex that pulled this vertex into the limelight. That is the one that caused the latter vertex to be discovered by the traversal.\nThis will become clearer as we go along. But just as an example, notice that all the neighbors of the source vertex from where you start the BFS have the source vertex as their parent because, in the very first step, the source vertex is going to immediately find all of its neighbors in one shot.\nAll the neighbors of the source vertex will point to the source as the parent. Everything that you see typically in the second layer of a BFS traversal, all of those vertices will have some vertex in the first layer of the BFS traversal as their parent and so on and so forth. We will update these parent pointers as we go along. Although we will not have any immediate use for them, it is just good to know that we can keep track of them. These may come in handy depending on the application that you might be working with.\nThe rest of it is fairly routine initialization. We want to keep track of the layer numbers in a variable called ‘layer.’ This is mostly so that we can do some pretty-printing of the BFS traversal. We also have a queue, which is going to be the main data structure that we use to actually execute the traversal.\nWe initialize a queue to being ‘empty,’ to begin with, and then we push the source vertex onto the queue. That is the only thing that the queue has in the beginning and now let us see how this goes. We are going to keep processing vertices, while the queue still has vertices on it. That is the outermost while loop and now what we want to do is basically pull out the vertex that is at the front of the queue.\nLet us call that vertex ‘u.’ We read off the front of the queue and we also push this vertex out of the queue and now what we want to do is basically go over all the neighbors of ‘u.’ This is an adjacency list representation. This is one way of going over the neighbors of ‘u.’ The variable ‘w’ essentially stores the weight of the edge from u to v and this is something that is not really relevant to the BFS traversal. We are just going to ignore that and we are going to worry about ‘v.’\nWhat do we want to know about v? This is something that we are interested in processing if we have not seen it before. Notice that this is very important. You only process unvisited neighbors of the vertex that is currently at the head of the queue. If you have seen a vertex before and you try to process it, then you will have a BFS implementation that is just going to potentially run forever. That is a very dangerous thing to do.\nThis check here is very, very crucial. We are going to check if we have visited v already and one way to do that is to check what is the distance of v from the source. If this distance is infinity, which of course is coded as some large finite number, as long as this number is much bigger than ‘n,’ or even strictly bigger than ‘n,’ this will be a valid implementation. If the distance of v is set to infinity, then we know that we have not seen this vertex yet and that is when we will process it.\nOtherwise, we do not do anything and we just continue with the ‘for’ loop. Once we exhaust that, we, sort of, get out and go back to the while loop. That is essentially the overall structure. But what if v is a vertex that we have not seen before? What does it mean to process the vertex v?\nWhat we want to do is, first of all, make sure that we set the distance of v appropriately so that we put it on record now that v is a visited vertex. What is the distance of v? Well, it is going to be the distance of the parent + 1. It took you a distance of ‘u’ many steps to come from the source to the vertex ‘u,’ and now it is going to be one extra hop to reach v by taking the edge from u to v.\nThat is the distance of v from the source, and setting it in this way also implicitly puts it on the record, as we were saying earlier, that v is now a visited vertex and we do not have to visit it again in case it should come up later. The next thing that we want to do is to set the parent pointer of v.\nWe ask ourselves: Who was the vertex that was responsible for v joining the queue? Well, v is going to join the queue because u discovered it. The vertex ‘u’ discovered it. We are going to set the parent of v to u and that is going to fix up the parent point information. To truly wrap up the processing of the vertex v, what we need to do is add v to the end of the queue. This way, when it is v’s turn, v can pull in all of its neighbors, at least the ones that have not been visited so far.\nThat is why it just hops on the bandwagon, so to speak. The rest of this code is mostly routine things to do with printing the order in which the vertices are being traversed. Let us take a quick look. If you just wanted to print out the vertices that are being visited by the BFS traversal, in the order in which they are processed, you could just fill in this blank space with one simple print statement, which just prints the value of ‘u.’\nBut you might also want to print the layer numbers whenever you change a layer. Let us say when you go from the first layer to the second or from the second to the third, and so on. Let us think about when does the layer number change. We have a variable called layer where we are sort of tracking the current layer numbers, so to speak. Whenever we encounter a vertex whose distance is different from the layer number that we have cracked so far, that is when we know that the layer number needs an upgrade.\nThat is when it is worth printing the layer number. Let us say that we see that the distance of the vertex that is being processed currently is different from the layer number. Then let us just go ahead and print the value of the distance of ‘u’ that is going to basically signal the current layer number. We also want to make sure that ‘layer’ is set to the distance of the vertex so that the variable also carries the correct information about which layer we are in. For the most part, as long as you are within the same layer, as long as you are processing vertices that are at the same distance from the source, this piece of code here ‘layer equals a distance of ’u’’ will not really change anything.\nBut every time you do actually switch layers, the ‘if’ condition just before this line will catch that and it will basically print the layer number of the new layer to the output. That is how this works. Essentially, if you were to run this code, you are going to just see a nice output with the layer numbers and after each layer number, you are going to see a list of vertices that were visited at that layer.\nOnce again, do try out visualgo, if you just want to see how this code plays out on some pre-written examples or your own examples. That is an exercise that is definitely worth doing and you could also just run this code for yourself on examples that you come up with. Make sure to combine this with the actual implementation of the graph as an adjacency list and that you read your input and output appropriately. You could also refer to the GitHub repository for the competitive programming book from where this snippet of code has been borrowed. There is a link to that in the description of this video as well.\nSo, that wraps up our discussion on BFS and now let us turn to depth-first search, which is a different style. Going back to our Wikipedia browsing analogy, we said that this is where the moment you see a link that is fresh that you have not visited before. While you are browsing Wikipedia, you click on it and that is the link that you start reading. There as well, if you see a link that you have not visited before, you are going to click on it and so on and so forth.\nThe only time that you have some respite is when you finally land on a page where you have no more links. There is nothing else to follow and then you start backtracking and working your way back up.\n(Refer Slide Time: 16:25)\n\nLet us, again, take a look at an example of a DFS traversal playing out. I will not go through this step by step but I will just let you watch the animation and hopefully, it tallies with your intuition of how you expect the DFS traversal to behave. After this, we will go ahead and take a look at the implementation.\nWe started at the route, the topmost vertex and as you can see, you just keep going all the way down. You go from 1, 2, 3, 4 and then you walk your way back up to 1. Then you take the second neighbor of 1, which is 5 and you go down the path 1, 5, 6, 7. Then you backtrack all the way up to 5 now and 5 has one other unvisited neighbor. You visit 8, and then you walk your way back up all the way to 1. Then you explore 9 followed by 10. Hopefully, this is reasonably intuitive as to what DFS is doing. Let us just take a look at how you would write this in code.\n(Refer Slide Time: 17:25)\n\nNow DFS lends itself very naturally to a recursive implementation, which is why we are isolating its implementation to a function called DFS. The implementation that we saw for BFS could be isolated into a function call as well. But you could also just put it in the main body and it would not make any difference.\nOf course, DFS also can be implemented in a more iterative style and you could directly use, for instance, a stack-based data structure to simulate what is going on in this recursive version of the program, which I think is just closer to the semantics of how we described it. That is why we are going to do the recursive version because it is just easy to tally this with the way that we have described how DFS works.\nBut with just a little more work, you could also come up with a non-recursive implementation. I am going to leave you with a few pointers to do search variants, which you could go and lookup. But for all practical purposes, I think you could work with either one of them and it should not really matter.\nWhat is going on here? Let us say you invoke DFS, starting at a vertex ‘u.’ Notice that what we need in terms of the global variables is, of course, access to an adjacency list representation of the graph. This could also be an adjacency matrix representation, but I am just going with an adjacency list as the default because that is going to be the more efficient choice here in general.\nApart from this, just like with BFS, where we had a distance array, which helped us distinguish between vertices that have been and have not been visited, here also we are going to maintain an array which in this case, is called dfs_num that is going to keep track of whether a vertex was visited or not.\nIn this code, you can see the words ‘visited’ and ‘unvisited.’ These are constants that have been declared separately that you do not see on your screen. Once again, there is a link to the repository from where you can see the whole code. This is just a snippet and it may not run if you were to just try to work with it as is.\nBut in any case, hopefully, the spirit of it is clear. The dfs_num array is going to tell us if a vertex is being visited or not and how does DFS work? Well, just going to ignore the print statement which just tells us, where we are in the DFS traversal. But when we do the DFS on ‘u,’ what we essentially want to do is go through the neighbors of u, till we find the first unvisited neighbor and then just perform a DFS starting and at that vertex.\nAt some point, you are going to reach a vertex, which does not have any unvisited neighbors. All of its neighbors have been visited before. At this point, basically, the if condition within the for loop will never really execute. The for loop exhausts itself and you just return control to wherever the function call was coming from. That is essentially your dead end and that is when you will start your backtracking journey.\nThis is, of course, a very bare-bones implementation of DFS. You could enhance this to track more information about the vertices such as, for instance, you could keep track of the times at which you visited the vertex and at the time at which you decided to go back when you have exhausted all of its neighbors. You could track all of this auxiliary information, and depending on the application that you are working with, this extra information can turn out to be really valuable and relevant.\nOne thing that I did not mention is that the first thing that you should do when you do DFS of ‘u’ is to make sure that you mark this vertex as visited. This is, again, pretty critical. If you forget to do this, then you might accidentally again end up in an endless loop because you have not kept track properly of which vertices you have visited and which you have not. The moment you know that you are going to do a DFS starting at a particular vertex just make sure that you update its visited status so that you do not try to visit it again. You do not try to do a DFS starting from there, a second time when you potentially come in from a different vertex.\nHopefully, this implementation makes sense. I think it covers all of the aspects that we discussed when we were talking about the algorithmic idea of doing a DFS traversal informally. Hopefully, it tallies with your intuition. Once again, you can go to visualgo to actually experiment with how DFS plays out on actual examples. You could either create your own examples or look at some of the ones that are already built into the interface.\nHave some fun with that and you could also play around with how a BFS and DFS work on directed versus undirected graphs. Typically, these traversals do not really account for weights on edges or vertices in any way. That kind of information is completely ignored. The behavior of these traversals would be the same whether your graph had weights on the edges of the vertices or it did not.\nBut the orientations can definitely lead to different outcomes in the sense that if you have a directed graph and you run say, a DFS, that run would look different from the run on the underlying undirected graph. Let us say you took an eraser and you erased all the arrowheads. You are now left with an underlying undirected graph, so to speak and if you run a DFS on that, that is going to look very different from what happened on the directed version, typically. It is a good idea to play around with examples just to get a sense of some of these things. Now that we have seen the implementations, let me just talk very briefly about the complexity.\n(Refer Slide Time: 23:17)\n\nIt turns out that if you were to use the adjacency matrix representation then the worst-case running time can be as bad as order n2. But if you use an adjacency list representation, then your worst-case complexity is order n + m, where I am using n and m to refer to the number of vertices and edges respectively.\nNow, you might say that there could be graphs where m is as bad as n2. For example, that would surely be the case if you were working with a complete graph and so on. Of course, this is true. If you were going to view this purely from the perspective of worst-case complexity, then these running times are not all that different.\nBut the running time order V + E would generally be superior because it accounts for the structure of the graph and would generally give you a much better performance on graphs that happened to be sparse, that do not have as many edges, and so on. This is an important difference to keep in mind.\nI will say that coming up with this performance guarantee to see that the running time is in fact order n + m does require a little bit of work because if you were to just look at the code for BFS DFS and if you analyze it naively, then it will not be very clear as to why the running time can be bounded as being order n + m.\nSo, it does require just a little bit of thought. But the very fact that the complexities are different for the matrix and list representations should give you a hint as to how to analyze the complexity so that you get to this conclusion. But in case it is not clear once again, there are a number of pointers for resources where you can find out more about how we typically analyze the complexity of these traversals and why we get to essentially what I am claiming here.\nWith this out of the way, the major takeaways are that you could use either BFS or DFS. In most scenarios, both of these traversals would be equally applicable. In some scenarios, one would be more natural than the other.\nIn general, it is a good idea to be comfortable implementing either of them and in most cases, you would be better off sticking to an adjacency list representation, as opposed to an adjacency matrix representation. Especially more so in CP, where if the number of vertices you are dealing with is more than a few 1000 vertices, as we mentioned earlier, this is anyway prohibitively expensive, even from a space and memory perspective.\nJust keep these things in mind and, you know, play around with the BFS and DFS implementations that we have discussed in this video. I will just spend a couple of minutes more telling you about some common applications of BFS DFS without actually getting into any of the details. But just in case you are curious about what these traversals are good for and how can you use them other than just exploring the graph. It turns out that there are a lot of interesting things that you could do with BFS DFS.\n(Refer Slide Time: 26:26)\n\nHere are just some of the things that you could do with these traversals. This is by no means an exhaustive list. It is a small subset of the very many applications that are known for BFS DFS. Some of these terms may be unfamiliar. Things like, for instance, bipartiteness or topological sort or what does it mean to talk about distance or connected components – in case some of this is unfamiliar, you could look them up.\nIn the upcoming modules, we will talk a little bit about what it means for a graph to be connected. We will define the notion of distance and in the assignment, you will have an encounter with the notion of ‘topological’ sort. In fact, in the very next module, we are also going to look at what it means for a graph to be bipartite and what it means for a graph to have a cycle and therefore, you would also know what it means for a graph to be acyclic.\nSome of these terms will become clearer as we go along in case they were not already familiar, and once again, we will not really be getting into a lot of proof. If you are really curious about why these algorithms work in these contexts, it would be a good idea for you to look up some of the reference material that you can find on the course website, as well as in the description of this video.\n(Refer Slide Time: 27:44)\n\nSpeaking of statements without proof, I will just make a few comments here again without actually formally arguing them. These are just some properties of these traversals that are useful to keep in mind. The first one is to observe that in a BFS, you cannot have edges that jump levels.\nOf course, you can have edges between consecutive levels, but any more of a gap and you cannot really have edges, for example, going from level 5 to level 9. The reason for this is fairly intuitive. If you did have such an edge, then the other end-points sitting at level 9 should have really been pulled up in level 6 already. It is not very difficult to translate this intuition into an argument for why you will not have edges between vertices that are more than one layer apart.\nIn a BFS, just remember that all edges either go across consecutive levels or they are cross edges, meaning they are edges within the same level, but you are not going to have edges of any other kind. Now, let me also just quickly point out that some people will use terminology like tree edges and non-tree edges to distinguish between the edges that were actually accessed by the traversal.\nThe edges that were involved, for example, when you were pulling in a new vertex into the queue. Let us say your current vertex, the head of the queue, is the vertex u. You are looking at an unvisited neighbor v and you are pushing it to the tail of the queue. That edge between u and v, that is going to be a BFS tree edge because the traversal actually went across that edge.\nBut there would be many other edges in the graph that do not feature in the traversal tree. Those would be the non-tree edges and some people would call them the graph edges. In the context of a BFS traversal, you would basically know that those are the edges that did not show up on the tree. That is the same for DFS as well.\nNow in a DFS traversal, on an undirected graph, you would not have cross edges. By cross edges, I mean edges between pairs of vertices that do not have a direct ancestor-descendant relationship between them. You could have back edges. In a DFS traversal, you could definitely have edges that cut across multiple levels if you like. All the levels are a bit less clear in the context of DFS, but these edges can definitely be present.\nBut in undirected graphs, you will not have edges that basically cut across two different branches of the tree in some sense. This is all very informal and you will have to convince yourself about why this is the case. But once again, there are ways of proving these things formally. There are even ways of articulating these things more precisely than I am doing here. But this is just to give you a general picture of the kind of properties that you might expect from these traversals.\nAs I said, in BFS, you could use this traversal for actually recording distances, which are essentially the length of the shortest paths from the source to the current vertex. The layer number of a vertex essentially tells you what its distance is from the place where you started the traversal.\nAgain, requires an argument! But this can be shown without too much difficulty and that is a very interesting property of BFS. It is completely useless if you want to track shortest paths accounting for edge weights. That is going to be the subject of our discussions next week. But for now, you could still use BFS if your edges do not have weights and you are still somehow interested in distances.\nFinally, if you look at the last layer of a DFS traversal, you should notice that there are no edges between the leaves. The reason is that if you did have an edge, then well you could have gone deeper in one of those leaves and it would not be a leaf really. Once again, you could say this more properly. But I think this is an interesting property that might just come in handy in some situations.\nI just wanted to leave you with some of these nice properties that these traversals have. Of course, there are many more. Think of this as some sort of a sampler and once again, please do look up the links for more information. If you are already fairly comfortable with BFS and DFS, please do look at the extras page for other problems that you can try while you are at it. So, thanks very much. In the next three videos, we are going to solve three different problems that take advantage of these traversals. I will see you there, and let us wrap this up here. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec31.html",
    "href": "materials/cpnotes/Lec31.html",
    "title": "Shortest Paths - Module 1 (Dijkstra’s Algorithm-Sending Email)",
    "section": "",
    "text": "Lecture - 31\nShortest Paths - Module 1 (Dijkstra’s Algorithm-Sending Email)\n(Refer Slide Time: 00:11)\n\nAlright, welcome back to the third segment of the first module in week six where we are talking about the ‘shortest paths’ problem. And in particular, we have been focused on the single-source shortest path problem. And so far in the first two segments, we have discussed the case when all the edge weights are uniform or the edge weights are one.\nThat is essentially the same as working with an unweighted graph. And here we said that the BFS algorithm, which we saw in fact last week, will do the job for you. And then, in the previous segment, we tackled this more general case when you could have arbitrary edge weights but they are all guaranteed to be non-negative.\n(Refer Slide Time: 00:55)\n\nAnd in this case, we said that we could use Dijkstra’s algorithm to solve the problem. And we made a small note about the implementation, where we said that, well, it is natural for the functioning of Dijkstra’s algorithm to use a priority queue to keep track of the values of the distances. But unfortunately, the C++ implementation of ‘priority queue’ does not give you access to a method that can modify the values that have already been entered into the priority queue.\nSo we said that we will, you know, basically simulate the change in key-value operation by simply deleting the value and replacing it with the new value and this is also a bit tricky to do directly within a priority queue. So we are going to be using the set data structure to do this instead.\nAnd this works also I believe in Java. But in Python, well, we do not really have an implementation of set that is internally based on balanced BSTs, which is what C++ uses to give you data structure that can maintain a sorted collection with insertion removal, lookups, or searches costing you only logarithmic time.\n(Refer Slide Time: 02:19)\n\nSo if you are a Python user then, well, you could experiment with using the built-in priority queue data structure. And if you look at the documentation for heaps in Python, you will see that there is some guidance on how to update key values but the idea seems to be very similar to what we have already discussed in the sense that whenever they want to update a particular key value, they would essentially mark it as being removed and they would insert the new value for that key.\nAnd then throughout your implementation, you have to just remember to check for whether an element has been marked as removed or not to be sure about whether it is a real element in the priority queue or not. So you could experiment with this, or you could just wait till the next segment where we talk about modified Dijkstra’s algorithm, where you could actually directly use a priority queue and it will not be a problem because we will never really have to actually decrease the key value.\nWe can do all of our work by simply inserting new values, and everything else will take care of itself. So you could wait till we discuss that. The only caveat is that in general, the modified version has a slightly worse complexity, especially in the worst case. But in practice, it tends to work out just fine.\nSo if you are a Python user then you could do one of two things. Either just stick to using the modified version where you will never have to do key updates. Or, you could use the original version and you could try and see if you can simulate updates with deletions using the method that has been described in the documentation.\nAt the time of this recording, the official repository only has the C++ version for the original Dijkstra’s algorithm. But I am optimistic that we might see some community contributions going forward. And if you just wait for a while, perhaps you will be able to also look at Python variants, which work just as well.\n(Refer Slide Time: 04:24 & 05:17)\n \nSo with all that said, let us move on to a discussion of our first problem this week, which will give us a backdrop in which we can implement and test Dijkstra’s algorithm. So this problem is called ‘Sending Email.’ It is on the UVA platform and the problem statement basically goes like this. We are given that there are ‘n’ SMTP servers connected by network cables.\nThis already screams for a graph formulation. So it seems like our servers should be vertices, and the cables should probably be edges. Indeed, each of the ‘m’ cables connects to computers and it has a certain latency measured in milliseconds, which is required to send an email message, presumably between the two servers that are connected by that cable.\nSo by now, we are even more confident that this looks like it is something that should be modeled using a graph. What is not clear at this stage is whether there should be a directed or an undirected graph. So we will get to that in a bit. But for now, let is go ahead and look at the task at hand. So the question is the following.\nWhat is the shortest time required to send a message from a server S to a server T along a sequence of cables? We are also told that we can assume that there is no delay incurred at the servers, which is to say that when an email arrives at a server, it can be instantly relayed to any other server that is directly connected to it via a cable.\n(Refer Slide Time: 05:59 & 06:03)\n \nSo from this description, I think it is fairly transparent that what we are looking for is a minimum weight path between S and T. And everything that we have learned so far with regards to Dijkstra’s algorithm for instance should be applicable here.\nWe could think of these latencies as the edge weights. And if you take a quick look at the constraints, the number of edges and the number of vertices are in the 10,000s. The edge weights, also range from zero to 10,000, and in particular, this means that we do not have any negative weights to worry about. So in terms of correctness, we are definitely in the clear.\nWe could apply the original version of Dijkstra’s algorithm, the one that we have discussed so far, and be assured that that is the safe thing to do. It will produce the right answer in such instances.\n(Refer Slide Time: 06:46)\n\nBut now, we also have to think about the complexity and for this, we have to understand the worst-case running time of Dijkstra’s algorithm. To do that, let is go back and look at what Dijkstra’s algorithm is actually doing. The two operations that have been highlighted here in the pseudocode are operations whose complexities will depend on the choice of the underlying data structure.\nAs we have discussed, if you were to use a heap or a priority queue, it is possible to implement both of these operations with a cost that is in the worst-case logarithmic in the size of the collection. But because the C++ STL does not provide a decreased key interface to its priority queue implementation, we said that we could also implement these operations using a set, in which case you get a similar guarantee.\nSo the worst-case complexity of running each of the ExtractMin and DecreaseKey operations can be assumed to be logarithmic in the size of the collection. Because the size of the connection is never more than the number of vertices, we see that these operations have a cost of order log n. So the only question that remains is how many times are these operations executed. Note that every vertex is extracted at most once.\nIn particular, if a vertex is reachable from the source, then it is extracted exactly once. And if it is not reachable from the source, then it is not extracted at all. Similarly, every edge is relaxed at most once. Every edge is considered for relaxation exactly once. But depending on how the numbers are, it may or may not actually be up for relaxation. But if it does get relaxed, that is when the DecreaseKey operation is invoked. And this happens at most once for every edge.\nSo if you just look at the algorithm in an overall way, you will see that the total complexity is m + n * log n because that is the product of the number of times that the operations are involved, and the cost of the operations themselves. Since m dominates n asymptotically, this can be simplified to just saying, order m log n. So if you go back and look at the constraints again because m and n are both in the order of 10,000, so you will see that this complexity breaks out just fine for this problem.\nThe one bit of detail that remains to be understood is if the edges that have been given to us are directed or not. Oddly enough, this is not specified in the problem statement, but if you carefully read the section where there is a description of how the input is given to us, you will notice this phrase which says that ‘the servers are connected by bidirectional cables.’\nSo from this, we realize that the edges are, in fact, undirected. And although all of our discussion about Dijkstra’s algorithm has been in the context of directed graphs, it turns out that when you do not have negative edge weights to worry about everything works exactly the same way. You just have to be careful when you take in your input to make sure that you record all of the edges as bidirectional or undirected edges.\n(Refer Slide Time: 09:51)\n\nNow, as is our tradition before we solve the problem, let us just work through an example. And here is an example from the sample input-output for this problem. The way it is formatted, there are multiple test cases one after the other. So I think I have picked the second one here, and the way the test cases are formatted, the first line gives you four numbers representing the number of vertices, the number of edges, and the IDs of the vertices S and T.\nThe vertices are labeled from zero through n-1. And here you can see that there are three vertices, three edges, and you want the distance between the first and the last vertex, the vertex that have IDs zero and two. The next m lines – in this case, of course, there are three edges so there are three lines – the next m lines give you the pairs of vertices corresponding to the ‘m’ edges.\nAnd the last number gives you the weight of that edge and in this case, it is the latency across that cable. So, if you were to draw a picture corresponding to this graph, this is what it would look like, and you are trying to find the distance between zero and two.\nNotice that the direct edge between zero and two has a cost of 200, and the only other option that you have is to go via the server that is labeled one. The total cost of doing that is 100 + 50. It should be reasonably clear that this is the better option and the answer that you are expected to output in this case is going to be 150.\nYou could try and play around with a few other examples but they will be exactly the same as any genetic shortest path instance. So feel free to take a break and consider doing that. And if you would like to give this a stab yourself, by all means, this is the time to do it, because the next thing that we are going to do is actually take a look at the implementation.\nSo we will be working here with an adjacency list representation and our code will be in C++. If you need a reminder of how the adjacency list representation works, then you can find that in our discussions from the previous week.\n(Refer Slide Time: 11:50 & 12:24)\n \nSo let us get started by leading the input in. Most of this is fairly standard stuff. But let me just note that because the edges are undirected, we want to make sure that we add V as a neighbor of U, and U as a neighbor of V. So that is why you will see that we are adding elements to two adjacency lists when we read in a single edge.\nSo this was just taking the input in and, you know, building up the graph. And now, let is get to the implementation of Dijkstra’s algorithm. Let us begin with the initialization. So we have this distance array, which if you remember the way we wanted to initialize that, was to say that, to begin with, we know that the distance from the source to itself is zero, and everything else is initialized to some very large numbers.\nSo we have this constant here, in short for infinity, which is defined to be a suitably large number. And the distance array of course is length ‘n,’ ‘n’ being the number of vertices. And the source vertex here, which is S, in this case, is the S that was given to us in the first line of the input. So we remember to set that to zero. Remember we are looking for the shortest path from S to T, or between S and T.\nAfter this, the next thing that we want to do is make sure that these V and distance V pairs are loaded into a priority queue. But again as we have discussed, instead of the built-in priority queue, we will be working with sets. So we have initialized a set, which we will call PQ. And what we want to do now, is just insert the V and distance V pairs, into this set.\n(Refer Slide Time: 13:24 & 14:08)\n \nSo that is exactly what is happening in these next two lines and remember that the way the set data structure works, it automatically sorts these pairs in the order of non-decreasing distances from S. Of course, to begin with, all this means is that as comma zero is going to be the first element and the others are all tied so, at the moment, there is going to be no special ordering on them.\nBut as we go along, the set will maintain its sortedness and you can always access the minimum element by trying to pull out the first element in the set and that is going to work.\nSo now that all the initializations are out of the way, let us get to the main body of the algorithm. Remember that this was the pseudocode that we had discussed some time ago, and now, this is what we want to translate into operational code. So the outer while loop just says: continue doing this for as long as you still have elements left in your set.\nSo that is just a non-emptiness check that we want to do at the outset. But inside this loop, the first thing that we want to do is extract the minimum element, which is to say we want to identify the element that is closest to the source that has the smallest value of distance. And then we want to remove this element from the set. So here are a couple of lines of code that do just that.\nIn the first step, we are identifying the smallest element. Remember that ‘set’ stores elements in sorted order. So in this case, this is just going to be the first element. And having identified this element and committed it to the variables D and U, D denoting the distance, and U denoting the vertex, we now want to make sure that we remove this element from the set. So that is what the ‘erase’ directive in the next line is doing for us here.\nSo this completes the implementation of the ExtractMin operation. And now, we want to run through all the edges that are incident to the vertex U. This is just a simple matter of going through all the vertices V in the adjacency list of U. And remember that the way we have set up the adjacency list: every vertex that is adjacent to U also comes tagged with the weight of the edge from U to V.\nSo here, V denotes the neighbor and W denotes the weight of the edge from U to V. So that is the for loop that we have going on here. Now, remember that for each of these edges that are going out of U, we want to consider if these edges need to be relaxed. So to implement the ‘if’ condition here, let us just recall what it means for an edge to be tense.\nSo an edge from U to V is tense if the method of getting to V via U is better than whatever method we have currently as given by the distance array. So in particular, if the distance of U + W, W being the weight of the edge from U to V, is smaller than the distance of V, then the edge is tense, and it needs to be relaxed. And on the other hand, if the distance of U + W is at least the distance of V then nothing needs to be done.\nSo that is the next ‘if’ statement here. It basically says that if this edge is not tense then you can move along, there is nothing to be done. But on the other hand, if the edge is tense, then we need to relax it, which is to say that we need to update the distance array with the new value of the distance, which is the distance of U + W. And we also need to update the priority queue pair accordingly.\nAnd since we are doing this with a set, we had agreed that we will simulate this decrease in the key-value with a ‘deletion’ and an ‘insertion.’ So the next few lines of code do exactly that. So first of all we remove the old value V, the distance of V. We update the distance array so that it now has the new value for the distance of V. And finally, we reinsert the new V and distance of V. So that is what is going on here. And this completes the implementation of the algorithm that we had discussed.\nOne useful addition here is to maintain a predecessor array, which gives you information about the penultimate vertex on the shortest path. It tells you where did you come from, to get to this optimal path. If you did have an explicit predecessor array, then this would be the point where you would set the predecessor of V to being U.\n(Refer Slide Time: 18:08 & 18:56)\n \nFor this problem, however, this is not really required because all you need to do is output the length of the shortest path. So let us go ahead and take a look at how we do that. This output is actually pretty straightforward. You just need to look up the value of the distance of T, which is the server that you wanted to reach.\nThe only thing to remember to do is to make sure that you have a check for unreachability because your output is going to be slightly different if T is completely unreachable from S, which is possible. That could happen. There is no promise that the graph is connected, to begin with, and so on. So making that distinction here is the only little detail to keep in mind.\nAnd with that, we are pretty much done here. Let me just make a quick follow-up comment about the detail of adding predecessor information. So if you want to test out Dijkstra in a setting where you have to also print the shortest path that you have found, then you could take a look at this problem on Codeforces, which asks you to do exactly that.\nI think this is a nice problem to again try out on your own based on the code that you have seen so far. But just for the sake of completeness, let me show you how you would print the path if you had maintained some sort of a predecessor array.\n(Refer Slide Time: 19:15)\n\nSo here is just a bit about the output. Once again, just like before, we want to distinguish the situation where the vertex is completely unreachable. In that case, you just print, for this problem, for instance, you just want to print a minus one. But if the vertex is reachable then what you want to do is basically keep moving along the predecessor array until you reach the source.\nSo in particular, in this problem, we have been asked to find the shortest path between the vertices labeled 1 and n. So one is our source vertex and n is the target or the destination vertex. So let us begin by setting a current variable to the vertex n. And now, we just keep moving along the predecessors as described. And as we do that, we want to just track the variables that we encounter, through this journey through the predecessor array. So we have a separate vector called path which will let us do that.\nSo as long as the current variable does not achieve the value one, which is an indication that you have in fact reached the source and that is your exit criteria from this while loop, as long as that does not happen just reset the current vertex to being the predecessor of whatever the current vertex was. And remember to just store the value of the predecessor that you encounter in the path array.\nSo this way the path array gets populated with all the vertices that you encounter in your journey from n to 1. And now, depending on whether the order matters or not, I think for this problem perhaps the order does matter and you want the path to be from 1 to n. So because of the way you have pushed the predecessor vertices that you encountered, you are kind of going backward. So you want to remember to reverse the path array so that you can print the vertices in the order in which they appear on the path from one to n.\nSo that is what is happening here. So I think this is a nice and simple way of just keeping track of an actual path. And whenever you need to do that, you can see that is quite easily doable just by tracking predecessor information as you run Dijkstra’s algorithm.\nSo do remember to also make the modification in the code that we saw for Dijkstra’s algorithm. Whenever you relax an edge from U to V, remember to set the predecessor of V = U. As always, you can find the complete code from which these snippets are being shared in this video on the official repository, a link to which you should find in the description of this video.\nSo with that, we come to the implementation of the original version of Dijkstra’s algorithm. And in the final segment for this module, we will talk about how negative edges impact this algorithm, and what can we do to fix it. So that is going to be a small modification to Dijkstra’s algorithm. And I will see you in the next segment for that discussion!"
  },
  {
    "objectID": "materials/cpnotes/Lec19.html",
    "href": "materials/cpnotes/Lec19.html",
    "title": "Disjoint Set Union - Module 2 (Destroying Array-I)",
    "section": "",
    "text": "Lecture - 19\nDisjoint Set Union - Module 2 (Destroying Array-I)\n(Refer Slide Time 00:11)\n\nWelcome back to the second module of the fourth week of ‘Getting Started with Competitive Programming.’ As you know, this week, we are focusing on the ‘Disjoint Set Union’ data structure and its applications. In this module, I want to tell you about a problem called ‘Destroying Array,’ which is something you can again find on Codeforces. There is a link in the description as usual.\nThis was the third problem in an Intel Code challenge elimination round. It is rated at about 1600. Certainly, ‘disjoint sets’ are not the only way to approach this problem. In fact, I think even the official editorial gives a slightly different approach, which you can go and read up on if you are interested.\nBut the reason I chose this particular problem was that – First of all, it is not obvious that you could use disjoint sets. But there is a small trick, which if you use, then it becomes quite transparent how disjoint sets could be helpful. This is a trick that is, I think, more widely applicable. I thought this would be a cool problem to exemplify it. So with all that said, let us get started with the problem statement.\n(Refer Slide Time: 01:18)\n\nThere is no story in this problem. It is just a straight-up description of a process. You are given an array, which has ‘n’ numbers, which we are going to denote from ‘a1’ through ‘an.’ I think it is important to note that these are non-negative integers. That is something that will come into play later. What is going to happen is that you are going to, as the name of the problem suggests, destroy the elements of this array one by one.\nYou are given a permutation of 1 to n, which tells you in what order you are going to destroy the integers of this array. We will probably make more explicit what this means through an example. Essentially, imagine that you are just deleting the elements according to this permutation, notice the one-based indexing.\nFor instance, if you had a1, a2, a3, and your permutation was three to one, then after the first step, your array would look like a1, a2. After the second step, it would look like a1, and at the third step, there is going to be nothing left. In general, once you are completely done, you have executed all the ‘n’ steps, your array has become completely empty. As I said, we will go through a more elaborate example in just a bit.\nIt will be one of the sample inputs that we will try to break down and observe closely. But let us figure out what is the task. What are we supposed to do with this information? At every stage what you are supposed to figure out is what is the largest surviving contiguous segment of elements that has the maximum possible sum.\nSo you can imagine that as you kill elements in the array, your array breaks down into contiguous chunks of integers. Each of these chunks is going to have a certain, let us call it weight, that is the sum of all the elements in that chunk. We want to figure out what is the heaviest junk that exists at every stage of this destructive process. Let us go through an example and I think all of this will become a little bit clearer.\n(Refer Slide Time: 03:31)\n\nFor instance, let us say that here is the input array. That is denoted in black. All the black circles are the input array. The elements in red are the permutation of the sequence in which the destruction is supposed to happen. The elements in blue are just there for reference; That is the indices of the elements of the array. Remember, we are working with numbers ‘a1’ through ‘an.’ We have one-based indexing. This is just a reminder that that is the case.\nLet us go through the process here. The first element that you are supposed to destroy is the fifth element and we know that that is the number 6. So that is gone.\n(Refer Slide Time: 04:14)\n \nThis leaves us with two chunks, whose sums turned out to be 18 and 16. You can pause the video and confirm for yourself that that is the case. In fact, speaking of pausing the video, if you want, you can pause the video and try to work through this whole example yourself once and then come back and exchange notes.\nFeel free to do that now if you would like to. But in any case here you have two chunks. The first one adds up, I think, to 18 and the second one adds up to 16. The answer at this stage is going to be 18 because that is the heavier chunk.\n(Refer Slide Time: 04:51)\n \nIn the second step, you are supposed to destroy the second element in the array. That is the second 5 there and now this breaks up into three chunks and the weights of these three chunks are 5, 8, and 16.\nThe new maximum is going to be 16. Notice that the maximum chunk, the heaviest chunk that we had in the previous step, got fragmented into two pieces. It is now no longer the ruling chunk and the correct answer at this point is going to be 16\n(Refer Slide Time: 05:22)\n \nNow the next element that is supposed to be deleted is the 8th element. It is the last element of the array. We have three chunks in the weights are 5, 8, and 11. The answer at this stage is 11. The next element to be deleted is the 7th element, and we still have three chunks but the weights now are 5, 8, and 6. The answer at this stage is 8.\n(Refer Slide Time: 05:33)\n \n \nThe next element to be deleted is the first one that completely annihilates one of the chunks. We are left with two chunks now of weights 8 and 6. The answer actually does not change. The previous, the heaviest chunk from the previous step still dominates the situation. The answer is still 8. The next element to be deleted is the element at the third index.\n(Refer Slide Time: 06:06)\n  \nThat is the first four; That is gone. Now we have two chunks of weights 4 and 6. The answer at this point is 6. The next element to be deleted is the one at the fourth index. Now you are only left with one chunk. There are no comparisons to be made and it so happens that the answer actually did not change from the previous step and it remains 6.\n(Refer Slide Time: 06:29)\n\nOnce this last element is gone, there is really nothing left in the array, and the answer is going to be 0. This is what we are required to output – this sequence that you see here: 18, 16, 11, 8, 8, 6, 6, 0. We are supposed to output the sequence of numbers, one on each line. That is essentially the goal of the problem statement. I hope that the statement itself is clear at this point.\nAgain, you might want to pause and think about how would you approach this. A first cut solution is going to be to just simulate the process. But if you go and look at the limits, you will see that the array itself has 106 elements potentially. The numbers themselves range from 1 to 109, I believe.\nIf you work out how expensive it is going to be to simulate the whole process, you will see that that is actually not going to work out. You need something slightly cleverer. Also, I think when we were talking about disjoint set union, I also said that this is inherently a constructive process. You have the sets and you put them together. If you have a process that is instead of breaking things apart, then that is not perhaps so well suited for a disjoint set union.\nI said this in the context of graphs. For instance, when we were trying to track connected components, we said that if you are bringing edges into the picture, then components are building up and gluing together. That is very naturally modeled by DSU. But instead, if you had edges also being deleted, then these breakages are harder to model. It feels less natural. We seem to have a similar situation here.\n(Refer Slide Time: 08:11)\n \nIt looks like we have an object, and the object is falling apart. How would we really hope to use DSU in this sort of setting? Remember, I mentioned that there is one trick that makes it somewhat transparent as to how DSU could be relevant for us here. I am not sure if it is reasonable to ask you to guess what this trick might be. But a hint would be: Think about what happens when you play a video back in reverse.\nImagine that you go through this whole process. But in fact, you could perhaps pause the video here and see what happens if you were to play it back in reverse. To be honest, I have no idea what that would look or sound like, probably a bit weird. But a picture may emerge that might help you think about how DSU would be relevant to this problem. So take a moment here, think about this and come back when you are ready.\nLet us follow through on the hint and see what happens if we actually run the process in reverse. Instead of removing things from the array one by one, what we will try and do is see if we can put things back into the array one by one, but in the opposite order of the destruction sequence that was given to us in the input. Now the visual is that instead of a process that breaks things apart, we have a process that puts things back together. At the very end, you have actually reconstructed your entire array.\n(Refer Slide Time: 09:48)\n\nLet us go back to the example and see what happens when we run the process in reverse order. By the way, you do not see any of the array elements here because we are going in reverse. At the very end, remember that the array became empty. Nothing is really available to us, to begin with. The last element to be deleted will now be the first one to come back into the picture.\nThe last element to be deleted was the one that was at the sixth index. That happened to be the number 6. Then the last but one element that was deleted, which is the next element that needs to be put back is the one that happens to be at the fourth index, and then the one at the third index, and then the one at the first index, and so on and so forth. I am going to build out the rest of it.\nHopefully, you can already see why this can be treated as an instance of disjoint sets. In a sense, the stuff that you are bringing back, either ends up being a singleton set, if it is in an isolated part of the array, or it ends up either extending the chunk, or it ends up merging two chunks. In some sense, that is how the introduction of a new element ends up adding to the landscape of the collection of sets that we have maintained so far.\nAt this point, you probably have enough of a picture of what is happening to think about whether you can build out a complete solution for yourself. If you would like to do that this would be a good time to pause, try it out, and then come back when you have given it a shot yourself. But in the meantime, let us continue our journey here. I think we stopped with restoring the element in the first position.\nThe next one to restore is the element at the seventh position. Notice that this is just extending a previous singleton element so that it is now a set of size 2, then when we put back the eighth element, this gets extended further and becomes a set of size 3, then when we put back the second element, it actually merges a singleton set with a set of size 2.\nWhen we put back the last element, it is no surprise that the two chunks that we had essentially get merged into this one giant set, which consists of all the elements. At this point, we have completed our rundown of the entire process, but now in reverse order. Let us think about how we are going to use a disjoint set union to track the progress that we are making when we go in reverse. Let me highlight the main ideas that are involved here.\n(Refer Slide Time: 12:29)\n\nFirst, as we have been saying, we run the operations in reverse order. The next thing is that we use union operations to appropriately keep track of sets, which is to say that when a new element comes in, we have to figure out if it is isolated, or whether it is extending a previous chunk, or whether it is merging two chunks. These are the only three things that can happen.\nIf you maintain a state array, which tells you which elements are currently present in the array and which elements are not, it will help you make a distinction between these three scenarios. So in particular, if you add an element at the ‘i’th location, and both the ’i-1’ and the ’i+1’th locations are empty, there is nothing in there, then this newly added element is just going to be a singleton set.\nFor this situation, we will actually go ahead and add a makeSet operation to our UnionFind class, which is something that we did not do in the previous video. But in this situation, it just makes things convenient to be able to create singleton elements as and when they appear. The other situations could be that you have an element being added at the ’i’th location, and exactly one of its neighboring slots is occupied and the other one is empty.\nSo either ‘i-1’ is empty and ‘i+1’ is occupied, or the other way around. In both of these cases, we need to execute one union operation to account for the fact that one of the older sets is now getting enhanced with one new element. The final scenario that could arise is that both neighboring locations are occupied from before. So both the ‘i-1’ and the ’i+1’th locations are non-empty.\nIn this case, the introduction of the element at the ‘i’th location is going to actually merge two sets from before. To account for this, we will have to do two union operations, one for ’i’ and ‘i-1’ and then ‘i’ and ‘i+1.’ This will have the desired effect of capturing the full merge. That is actually all the cases but if you want to run off and code this up right now then just be a little bit careful about accounting for the corner cases properly.\nIf you are at the extreme ends of the array, then watch out in terms of probing the ‘i-1’ or the ’i+1’th locations, which may not exist depending on where you are in the array. So after counting carefully for these edge cases, I think you should be in a good place in terms of capturing all the actions that happened. But remember, you still need to output the value of the heaviest chunk.\nFor this, you need to do some extra book-keeping. You need to keep track of the sums of these sets as well. Remember, previously, we have done things like tracking the sizes of the sets and the maximum elements, and the minimum elements. This is just a different quantity to keep track of. We will introduce an extra array, which helps us track the sums of the sets, the sum of the elements in any of these sets.\nRemember that this needs to be properly updated when you execute the union operation. When you have, let us say, x pointing to y, what do you want to do is that the sum set value of y should be incremented with the sum set value of x. That is something that you do need to put on the record. With this, I think you probably have enough hands to go ahead and implement this yourself.\nFeel free to use the DSU class code from the previous module as a starter file and kind of build on it based on what we have discussed so far. You could come back and exchange notes with the implementation that we will discuss separately in the implementation video. I will see you there and that will be all for now. Thanks for watching, have fun implementing this, and do let us know how it goes!"
  },
  {
    "objectID": "materials/cpnotes/Lec35.html",
    "href": "materials/cpnotes/Lec35.html",
    "title": "Shortest Paths - Module 3 (APSP [Floyd-Warshall] | Page Hopping)",
    "section": "",
    "text": "Lecture - 35\nShortest Paths - Module 3 (APSP [Floyd-Warshall] | Page Hopping)\nWelcome to the third and the final module of the sixth week in Getting Started with Competitive Programming. So, far in this week, we have focused completely on the single-source shortest path problem in various scenarios ranging from unweighted graphs all the way to general edge rates, both positive, negative, and even the presence of negative cycles.\nNow in this final module, I want to introduce you to a different variant of the shortest path problem, called the All Pairs Shortest Path Problem, or APSP, for short. And we are going to see an algorithm for this, that popularly goes by the name Floyd Warshall. And are we going to implement this in the context of a problem called ‘page hopping,’ which appeared in the ICPC world finals way back in 2000!\n(Refer Slide Time: 01:05)\n\n \n \n\nSo, let us get started with the problem itself. So, we are trying to tackle all-pairs shortest paths. As usual, will assume that we are working with a directed and a weighted graph. And our goal, in this case, is to compute the shortest paths between every pair of vertices. Now, having worked so much on SSSP, which is ‘single-source shortest path,’ I think a very natural reaction is to say, well, what is the big deal? We just run SSSP from every vertex, and this way, we will end up calculating the length of the shortest paths between any pair of vertices. And that would be absolutely correct. Let us take a look at the SSSP algorithms that we have seen so far.\nAnd let us try to understand: What would be the running time of the APSP algorithm if we were to simply run these SSSP algorithms ‘n’ times? So, as you might guess, to obtain these running times, we simply have to add a multiplicative factor of n to the existing running times to account for this outer for loop, that is going to run n times.\nNow, let us consider these running times for the case when the number of edges is as bad as it can be. And let us say that it is a dense graph, the number of edges is roughly n squared. In that case, these running times end up looking like this. And you can see that it is only the case when we have no weights at all, that we get an n3 running time, which is what we obtained by running BFS n times.\nBut in everything else, we have something that is worse than n cubed. So, a natural question is if we can do all-pairs shortest paths in order n cubed time without having to worry about the extra log n factor in the case of Dijkstra or the extra factor of n that comes in, in Bellman-Ford. So, perhaps we can just try to figure this out.\nFor non-negative edge weights, just getting an improvement over Dijkstra, I think that would be pretty nice. And in fact, what we are going to see, well, we will describe it in the context of graphs that do not have negative edge weights. But you can adapt it. And I think it is a good exercise to do that, to also account for negative weight cycles. So let us go ahead and take a look at what the algorithm does.\nSo, as always, I will describe the mechanics of the algorithm without giving you formal proof of correctness. But hopefully, there will be enough intuition for it to be clear as to why you might expect it to work. And, as always, in case you have not seen this algorithm or its proof of correctness before, but you are curious, you can always look up the references given in the description of this video to find out more. Okay. So, in this algorithm, what we are going to do is, again, work in phases, much like Bellman-Ford.\n(Refer Slide Time: 04:05 & 05:44)\n \nSo, we are going to go through n phases, and at the end of the ’r’th phase, what are we hoping to do? We are hoping to track the cost of the shortest path from u to v that uses vertices that are numbered, at most r. So let us imagine that our vertices are labeled from 1 to n. And, in the ’r’th step, I am restricting you to only use vertices that are labeled with a number that is r or less. Now, notice that when r = n, this means that any vertex is fair game because all vertex labels are at most n any way. So, if you are able to figure out the values of P(u,v,r) correctly for every pair u v and for every value of r, then at the very end what we have is exactly what we are looking for.\nNow you might ask: Why are we slicing this in terms of these r’s? And this, basically, is a fundamental idea, which is to break down what you ultimately want into smaller digestible chunks. And we will see a lot more of this flavor of algorithm play out in the last three weeks of the scores when we work with the concept of dynamic programming.\nHowever, if you have not worked with dynamic programming-based algorithms before, do not worry about it. This description is going to be fairly self-contained. And you are going to feel right at home, as long as you have seen recursion, which you already have, even in the context of this course. So, I think this should be pretty easy to follow along with.\nSo, let us use the distance array to keep track of the costs of these paths that we have defined here. So, in particular, the distance u v r value is going to reflect the cost of the path that goes from u to v using vertices that are labeled at most r. And such paths may not even exist. In that case, these distance values are to be interpreted as being infinity.\nAnd in your code, that is just going to be a very large number. Okay. So, let us think about how do we compute these values? Well, one easy case is when r = 0. Can you think about what the value of distance u v 0 should be, given that vertices are labeled from 1 to n? Alright. So, if vertices are labeled from 1 to n, then we are saying: compute the length of the shortest path from u to v, which passes only through vertices numbered at most 0.\nNow there are no vertices numbered at most 0. So, this is just a twisted way of saying that you are not allowed to use any intermediate vertices. And notice that the only parts that do not use intermediate vertices are the direct edges. So, the distance of u v 0 is going to be the weight of the edge from u to v, if such an edge is available. And if such an edge is not available, then this distance just remains infinity.\nSo, that is what we have in what do you might think of as some sort of a base case for this recursion. Okay. So, we figured out what to do if r = 0. Now let us think about what should happen in a more general setting.\n(Refer Slide Time: 07:29)\n \nSo, here are the vertices u and v. And we are trying to figure out the value for distance u v r. Now, just like we do in an inductive proof, we are going to assume that we already have figured out the values of distance u v r prime, for r prime strictly < r. We can assume that this is true because, well, in general, we have figured it out for r = 0.\nAnd we are going to build our way upwards, step by step. So, if I tell you how to compute distance u v r, provided you already know distance u v r prime, for r prime < r, then you can use this mechanism to go from distance u v 0 to distance u v 1, and from distance u v 1 to distance u v 2, and so on all the way till the end.\nSo, just like we do in a proof by induction, my focus here will be on trying to explain how we compute distance u v r under the assumption that you already know the correct values for distance u v r prime, for r prime < r. So, hopefully, that makes sense. And now let us come back to the question that we were posing earlier.\nHow do we compute distance u v r? Well, we are trying to figure out what is the best path from u to v that uses vertices that are labeled at most r if such a path exists. Now, if such a path exists, there could be two possible scenarios. The first is that it uses the vertex labeled r. And the other is that it does not use the vertex label r.\nWell, if it does not use the vertex label r, and originally, all of the vertices on this path were supposed to have labels at most r, given that we are not using the vertex r, this path must in fact be a path where all the vertex labels are at most r-1. So, in this case, what can we say? Take a moment here and think about how you would compute distance u v r, if I told you that P(u,v,r), in fact, happens to not need the vertex labeled r. Okay. So, in this situation, P(u,v,r) is going to in fact be the same as P(u,v,r-1), because this path simply does not make use of the vertex r.\nSo, r best bet is to just borrow the knowledge that we have from the ’r-1’th phase. So, this is the best that we can do, if we assume that this path from u to v in the ’r’th phase, in fact, happens to not need the vertex labeled r.\n(Refer Slide Time: 10:19)\n\nOn the other hand, it could be that this part uses the vertex label r. In this case, what can we say? Can we somehow use the information that we have already computed to figure out the cost of this path? Remember that the vertex r has already been used. So, the question is what can we say about the paths that go from u to r and from r to v. Just think about breaking it down in that way.\nAnd, you know, take a pause, think about this and come back when you are ready. So, as I was hinting earlier, let us try and think about the path from u to r, and the path from r to v. What can we say about these paths? Well, we have assumed non-negative edge weights. So, we know that our shortest paths, the optimal ones, are also simple paths. So they are not going to really repeat any vertices. And in particular, they are not going to repeat the vertex r.\nSo, we know that the blue and the pink sub-paths – excluding the end vertices, which are u and r and r and v respectively – these paths only use vertices labeled at most r-1 as the intermediate nodes. For this reason, we know that the length or the costs of these paths respectively is given by values that we have already computed, namely, P(u,r,r-1), and P(r,v,r-1). So, we simply sum these two values to get to the cost of the path from u to v.\nNow, you might say that each of these two cases makes sense individually. But how do we figure out which case we are in? What do we know about the best part in the ’r’th phase, we do not really know if it uses the vertex r or not. Well, we do not know this. But we can anticipate this by pretending that we are in one case or the other. And trying to figure out the values that we just calculated here, comparing the two and taking the minimum. That will give us the right answer at the end of the ’r’th phase.\n(Refer Slide Time: 12:35)\n\nSo, let us summarize whatever we have said with this our case analysis. So, we are trying to figure out the distance value for u v r, and the first thing that we said was the base case. So, we said that if r is equal to 0, this is the weight of the edge from u to v. And this is written succinctly. It is to be interpreted as the weight of this edge if it exists, and infinity otherwise.\nNow in the next generic step, what we want to do is to compare these two situations. The first is when the path from u to v, the optimal path, which is supposed to restrict itself to labels at most r, happens to not care for the vertex labeled r. In this case, the answer is going to simply be the distance of u v r-1. But on the other hand, suppose it does use the vertex r, then you can split this path into two sub-paths – the one that goes from u to r, and the other that goes from r to v. And other costs of these paths, notice that they are only going to use vertices whose labels at most r-1 because as we just discussed, vertices are not going to repeat because we do not have negative edge weights so all optimal paths are simple.\nSo, just combining the weights of these two sub-paths, we have this expression here. Now, as we said a moment ago, we do not know which of these two cases we are in, so we just compare the values and take the minimum of the two knowing that is the best that we could have hoped for at this stage.\nNow, this calculation here translates beautifully into just four lines of code. You essentially have three nested loops. The outermost loop essentially goes through all of these phases r, and the two inner loops essentially work through u,v pairs. Now inside these nested loops, you have one line computation that simply handles the update for u v r. And at that point, you are done. So, we are going to look at this implementation but in the context of the page hopping problem, and I am going to take that to the next segment. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec21.html",
    "href": "materials/cpnotes/Lec21.html",
    "title": "Disjoint Set Union - Module 3 (War-I)",
    "section": "",
    "text": "Lecture - 21\nDisjoint Set Union - Module 3 (War-I)\n(Refer Slide Time: 00:11)\n\nHello, and welcome to the third and the final module in the fourth week of Getting Started with Competitive Programming. As you know, this week, we have been talking about applications of the Disjoint Set Union data structure. As our final example, I want to talk about a problem called ‘War.’ You can find this on the UVA online judge. The problem ID is 10158.\nBut you do not really need to remember that because, as usual, a link to the problem statement is in the description of this video. This problem is also available on a platform called UDBug, where you can find additional test cases and hints and things like that. The link to that is provided in the description as well. Do check it out. Now, this problem has several things going on. Apart from an interesting story, there are a few different concepts to keep track of.\nYou might find that the description is a bit longer than usual. In fact, I think in terms of just the number of lines in the code for the solution to this problem, this is probably the longest that we have seen. Actually, conceptually, it is a really clean problem once you get the hang of it. But I will say that it is a bit non-trivial. It takes some time to fully absorb all the moving parts and all the cases that are involved.\nPlease be patient with this. It might take you some time before you can write everything out, especially if you like to write the solution out yourself before you follow along. Give yourself some time to make sure that you get all of the scenarios pinned down correctly. With that said, let us begin as always by taking a look at the problem statement.\n(Refer Slide Time: 01:55)\n  \n \nWe are given that there are ‘n’ people who are present at a party or something like this. That context is not so important. But what we are given about these ‘n’ people is that each one of them belongs to one of two countries. People who are from the same country - so here I have coded the two countries with a maroon-and-black background - so for people who are from the same country, they are all friends with each other.\nHere we have a group of five mutual friends on the one hand, and then three mutual friends on the other hand. Using the terminology from the problem statement, people who are from different countries, so if you pick any pair of people who come from different countries, we think of them as being enemies. Now, that is a pretty strong word. I might just call them rivals instead. We have these friends, and we have rivals.\n(Refer Slide Time: 02:55)\n  \nThat is the information that we are given, to begin with. But the interesting thing about the setting is that you do not actually know who is from which country. You have walked into this party and you see these ‘n’ people, and you do not really know who are friends and who are enemies and so on. The story goes that by observing people’s behavior at this party, by looking at how they are talking to each other, how they are interacting, and so on - who is getting into a fistfight? Who is exchanging pleasantries? - you can figure out, or you can make a pretty good guess about which pairs of people are friends and which pairs are enemies. Of course, you do not get to know all of this upfront; you have to spend some time at the party to infer more and more information. The way this is given to us is that as you spend time and you start inferring this information, you sort of make a record of it in your notebook or whatever.\nLet us say that you observe two people who are hanging out and having a good time. Then you decide to make a note of the fact that they are friends. This is given to you in the form of a query. You should not call this so much a query because it is not asking you for an answer. But this is something you can think of more as an operation. You just make a note of the fact that these two people are friends.\nThis is something that will actually come through in your input. Your input is going to be a sequence of, you can think of them as a mix of, these commands and queries. We will come back to the queries a bit later. But the operations are essentially going to be either MAKE FRIENDS or MAKE ENEMIES, which is the operation that comes in when you observe that there are two people who are very likely to be enemies.\nSo both MAKE FRIENDS and MAKE ENEMIES come with the IDs of two people on whom you want to impose either this friendship structure or this rivalry relationship. As you continue to spend time at this party, you start building up your observations. Let us say you note them down. Whenever you see two people, and you are convinced that they are friends, you make a note of that. If you are convinced they are enemies, you make a note of that as well.\nFormally, of course, the way this works out is that you are given a series of these MAKE FRIENDS and MAKE ENEMIES operations as input. You could just put them on the record as you go along. Let us say these are some of the relationships that you have been able to figure out by direct observation.\n(Refer Slide Time: 05:41)\n \nNow, if you remember, what we said earlier is that there is this friendship and rivalry structure or network that we know exists among these people. Essentially, what is happening is that as you spend more and more time as a neutral, third-party observer, it is like you are building out parts of this picture.\nYou do not know this picture but it is like a few pieces of a jigsaw puzzle have been given to you, and you are trying to piece them together, and hopefully, eventually build up the complete picture as you go along. So far, though, all the information that you have built up is from your direct observations. An interesting aspect of this problem is that you can also build up a little bit of information from indirect inferences.\nMaybe you have not observed a pair of people directly, but you can draw some conclusions about them based on the other information that you have. The way that you can do this is driven by the fact that these friendship and rivalry relationships, because of the way they are, are driven by certain rules. There are basically three rules that we need to keep in mind and see how we can use them to draw these additional inferences. Let us go through these rules.\n(Refer Slide Time: 06:59)\n \nThe first one is that friendship is transitive. What I mean by this is that if A is a friend of B, and B is a friend of C, then A is also a friend of C. Notice that this behavior is not really very intuitive in the sense that if you are thinking about friendships as in Facebook friendships, for instance, you do not really see transitivity.\nFor instance, if you have a friend, just because this person is your friend, you do not automatically become friends with everybody that this person is friends with. However, that is the case in the context of the story that we have in this problem. Let us just keep this in mind and take a look at our example.\nSee if we can infer any new friendships here by an application of this rule. Remember, the rule simply says that the friends of my friends are also my friends, which is to say, if we apply it to a specific people, let us say A is friends with B, and B is friends with C, then that implies that A is friends with C as well. Can you apply this to some three people in this picture and infer a new relationship? This would be a good time to pause and try and confirm this for yourself.\nHopefully, you have also discovered at least this one new relationship that you can establish between two people because they are in this chain situation that I just described. This is one way of applying the first rule of friendship. I do not think there are any more inferences that we can draw just based on this rule.\n(Refer Slide Time: 08:44)\n \nLet us move on to the second rule which says that if you have a common enemy, then that makes two people friends. If you know that A is an enemy of B, and A is also an enemy of C, in that situation B and C have a good reason to be friends with each other because of this common enemy. Again, let us go back to the example that we have been looking at. Take a pause here and see if you can develop or infer any new relationships based on the second rule.\nOnce again, the second rule says that a common enemy makes two people friends. Can you find two people who have a common enemy? You can probably discover that you can infer a new friendship between these two people here because they have a common enemy in the person who is the rightmost person on your screen right now.\nI do not think there are any more inferences that you can make based on this rule because there are just two rivalry relationships that you have so far. Let us move on and talk about the third role connecting friends and rivals.\n(Refer Slide Time: 09:58)\n  \nThe third rule, which I think is also a popular saying is that an enemy of a friend is an enemy. Notice that this is distinct from the previous situation. In the previous rule, what we said is that a common enemy makes two people friends. These are two people who, at least as far as we were concerned, were strangers. But let us say they have a chat, and they realize that they both have the same rival, then that becomes a reason for them to become friends.\nHere, however, you have two people who are already friends. One of them, let us say, realizes that the other person has an enemy, then this person is going to declare a rivalry with the rival of his friend because that is just how this rule works. If you are my friend and you have a rival, that person becomes my rival as well. Let us see how this rule plays out in our example.\nTake a look here and see if you can draw any new conclusions based on this third rule. Once again, remember, the third rule says that an enemy of a friend is an enemy. If you need to please pause here and try to figure out if you can apply this rule. We do have a situation where someone has a friend who has an enemy.\nYou can see this playing out on sort of the bottom right corner of this picture. That is definitely one extra rivalry that you can deduce from the picture that you had built up so far. Now just take a look at this picture once again, and see if you can infer anything new based on what you have so far, especially after this last relationship was added.\nWas there anything new that can be concluded by applying one of the rules that we have discussed so far? You might spot that, here are two people who now have a common enemy. Because they have a common enemy, the second rule comes into play and they become friends. That is the picture that we have so far.\n(Refer Slide Time: 12:19)\n \nLet us just move things around so that this is a bit clearer to see. It is the exact same picture, which is the pieces adjusted a little bit. I think hopefully it is at least visually clear that at this point you have a dead-end in terms of indirect inferences based on the rules that we have discussed so far.\nLet us actually turn this around so that it is easier for me to draw the next connection that I want to draw. Suppose you have a MAKE FRIENDS operation, and this is a new direct observation. Let us say that you make friends between these two people here. Then you can probably guess that by applying the first rule of friendship, which is that your friends are my friends, you can actually infer these two new friendships in this picture. But that is not all.\nYou can actually say more based on one of the other rules. Can you think of any other relationships that you can derive from the three rules that we have seen before? Take a pause here and think about it. Remember that we said that if you are my friend and you have a rival, then that person is also my rival. This was the third rule. Based on that, notice that if you pick any one of the people who are in a yellow circle and any person who is in a blue circle, then they are going to be mutual rivals for this reason.\nBy the way, I should have mentioned this explicitly, but friendship and rivalry are always assumed to be mutual. It is never a one-sided relationship. That is also something that we are given. Let us not add these rivalries explicitly to this picture because it is going to make it crowded. But notice that there is one person who is kind of isolated from the rest of the picture that we have built so far.\n(Refer Slide Time: 14:16)\n \nLet us say that we make a direct inference or direct observation about a rivalry between the person on the bottom-left of your screen and this person who sits in the component on the right. What does this direct observation tell us? Can we infer something more from here? If you remember, we said that if two people have a common enemy, then they themselves become friends. You can probably identify here that these two people do have a common enemy.\nYou can infer this new friendship here. From this new friendship, you can infer many more friendships, and I leave it as an exercise for you to build out the rest of this picture. Fill in the remaining blanks and see if there is anything that still remains to be inferred if you need more direct observations to build up the whole picture. Or, are you really done from here?\nDo think about that when you have a chance. But in the meantime, let us move on to actually describe the task that we are supposed to perform. With all this background in place, I think we are ready to understand what we are supposed to do.\n(Refer Slide Time: 15:29)\n\nThe input is going to be a stream of queries. Some of these are actual queries, while the others are really operations or information about these direct observations. We have seen two of these already. You have: MAKE FRIENDS and MAKE ENEMIES. But apart from these, you will also get queries of the form ARE FRIENDS? and ARE ENEMIES?\nFor these latter two queries, you are expected to output ‘yes’ or ‘no,’ based on the information that you have so far. For example, if you are asked if P and Q are friends, then you are supposed to say ‘yes,’ if you have evidence that they are friends, either from our direct observation or by inference, and you can say ‘no’ otherwise. As you might expect, it is similar to the ‘ARE ENEMIES?’ query.\nIf you are asked if P and Q are enemies, you are supposed to say ‘yes,’ if you can deduce that they are enemies, either by direct observation or by some sort of inference. If this is not the case, then you say ‘no.’ Your task really boils down to keeping track of this picture, the one that we were building up like in the example before, as you get these MAKE FRIENDS and MAKE ENEMIES operations.\nOf course, the important thing is that you do not just make a note of the direct observations, you somehow want to also track all of the inferences, all of the implications that come out of applications of rules, 1, 2, and 3. Remember, the first rule was that all friends of my friend are my friends as well - friendship is transitive. The second rule was that if two people have a common rival, then they become friends.\nThe third rule was that if my friend has a rival, then that person is my rival as well. You want to apply these rules as much as you can to actually infer additional relationships to be able to come up with accurate answers to the ‘ARE FRIENDS?’ and ‘ARE ENEMIES?’ queries, which is really the crux of what is going on here. Let us also point out a little bit of Fineprint, which I think is important.\n(Refer Slide Time: 17:40)\n\nYou might actually get ‘makeFriends’ or ‘makeEnemies’ queries, which contradict your previous knowledge. This could be as simple as the first line of input saying ‘makeFriends 1 comma 2,’ and the second line of input saying ‘makeEnemies 1 comma 2.’ This, of course, is a very direct example of contradictory behavior. But you could also have operations, which contradict the knowledge that you have gained so far by inference.\nEven if these indirect conclusions are contradicted, you are supposed to ignore these commands, or you are supposed to ignore these operations. Here is how this works. Whenever a makeFriends or makeEnemies operation does not contradict your previous knowledge, but it just adds to the picture that you are building, then you might do all this background work of making note of this information and drawing inferences and all of that. But you do not have to do anything in terms of output.\nSo you produce nothing as output for the valid makeFriends and makeEnemies queries. But on the other hand, if you receive a query that contradicts your previous knowledge, then you output -1 to make a note of the fact that you encountered a contradiction, but you move on as if nothing has happened. You simply ignore this query in the context of the picture that you are building.\nThat is how the problem works in terms of the input and the expected output. Now, we really have to think about coming up with a solution. Of course, you could try to brute force emulate everything. You could add this information. You could go over all pairs or triples, whatever it takes to exhaustively examine the impact of the three rules of friendships and rivalries that we discussed. But you can quickly see that that is going to be too expensive.\nWe do need to do something smarter. Where do Disjoint Sets come into this picture? It is reasonably intuitive to think that the friendship relationship can be modeled using disjoint sets. Because of the fact that they are transitive, it would make sense to say that the friendships evolve in these clusters.\nWhenever two people from two different clusters are identified as friends, it makes sense to just mash the two clusters together. Because transitivity will imply that now everyone in the first cluster will become friends with everyone in the second cluster. So I think it is pretty natural to use disjoint sets to keep track of friendships.\n(Refer Slide Time: 20:28)\n\nBut the real question is: how do you keep track of the enemies? That is some extra information that you do need to carry along. You need to find some way for making room for this extra baggage in your disjoint sets data structure. Now, there are multiple approaches to this problem, and we will be describing a specific one, but I think it is really worth taking a break here and seeing if you can puzzle this out for yourself. I think it is a really cute puzzle to work with.\nJust give it a shot. Join me back in the next part of this module. In the next video, we will talk about a complete solution to the problem, which involves using disjoint sets for the friendships and a little bit of extra book-keeping, and some case analysis to carefully track the enemies. I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec20.html",
    "href": "materials/cpnotes/Lec20.html",
    "title": "Disjoint Set Union - Module 2 (Destroying Array-II)",
    "section": "",
    "text": "Lecture - 20\nDisjoint Set Union - Module 2 (Destroying Array-II)\n(Refer Slide Time 00:11)\n\nWelcome back to the second segment of the Destroying Array module. Remember that in this part we only discussed the implementation. This will make a lot more sense if you watched the previous part first. If you have not done that, please go back and take a look at that video where we actually go over the problem statement, the main ideas for a solution and it is that solution that we are going to try and implement now.\nLet us get started here. As usual, you can find a link to the problem itself in the description of this video. You may want to cross-refer that to make sure that the input-output formats are as you expect, and so on.\n(Refer Slide Time: 00:50)\n\nThe first part of the main function is going to be the usual. I think this is a fairly standard parsing of the input. We are going to first take in the number of elements in the array, and then we are going to store the elements of the array in a vector of integers. We are also going to have a state vector, which tells us which locations are currently occupied and which locations are currently empty.\nThe state vector will evolve as we go through the process of adding elements to the array one by one. Then we declare, again, the vector of integers to take in the sequence in which the destruction happens. We just take in all of these inputs. Let me just also point out the limits. I believe the value of ‘n’ ranges from 1 to 100,000. The values of the elements in the array would range between 1 and 109.\nAll of this would fit within the integer data type and that is why everything that you see here has been declared as an integer, except for the index variable in the first for loop, which I think is just really not intentional. So that could very easily also be an integer. That is not really going to be a problem. But remember that we are tracking the sums of elements of segments in this array. When you add up these large numbers, then you might overshoot what can be stored in an integer data type.\n(Refer Slide Time: 02:25)\n\nWhen we declare variables that are going to store the answers for us, at that point, we switch over to the long, long data type, which can handle the larger numbers that we are going to need as we go along. After taking in all of the input, we instantiate the disjoint set union data structure. Again, I do this with ‘n+1’ elements so that I can simply talk about the ’i’th element without having to adjust for indexing to go back and forth between zero-based and one-based indexing. You might have a different taste with regards to this.\nBut if you do it differently in the sense that you initialize it with ‘n’ elements, then please remember to adjust your indices properly because the input sequence is a permutation of 1 to ‘n.’ So you will have to roll it back by 1 if your elements are ranging from 0 to ‘n-1.’ The first thing that we do is to reverse the sequence of instructions.\nWe are going to declare a vector of long, long integers to store the answers that we are supposed to output at the end. We are going to use the variable current answer (currentans) to keep track of the answer in the current stage of the process.\n(Refer Slide Time: 03:38)\n\nLet us move to what is really the heart of the whole algorithm. This is where we actually go through the process. We are going to go over the sequence. Then we are going to do the union operations based on the situations that we have already discussed in the previous video. First of all, when we say that the ’x’th element is now being added, we modify the state of the ’x’th location to 1, to indicate that this location is now occupied.\nNow we create the singleton set that is associated with this location. Normally makeSet will just take one parameter as input, and it will say: I want to create the singleton set involving the ’i’th element and that would have been enough. But remember that we are tracking the sums of the elements, the actual numbers that are sitting at these locations. So we are going to use the indices to keep track of how the sets are evolving.\nBut we also need to keep track of the numbers that are involved at these locations. I am also passing that as a parameter and it is going to be used to initialize the value of sumSet, the sum of the elements in the set. We are going to store that in a separate array. For the singleton set, that is just going to be the value of the array of x. It is going to be that number. We pass that in as a parameter as well so that we can track this value.\nWe need to look at whether the introduction of the element at the ‘x’th location is causing any merges or any extensions of previously existing sets. That is exactly what we are doing here. We are checking if the left neighbor is non-empty. If yes, then we take a union between ’x-1’ and x. If the right neighbor is non-empty, then we take a union between x and ‘x+1.’ This non-emptiness is essentially checked by the value in the state array.\nNotice that the first part of that ‘if’ clause is just safeguarding us from falling off the cliff, so to speak. That accounts for the edge cases that I was mentioning briefly in the previous video. If ‘x’ is zero, then ‘x-1’ will not make sense and if ‘x’ is ‘n’ then ‘x+1’ will not make sense. That is essentially what we are trying to be careful about here. Now that we have done the merging, let us think about what should be the value of the answer at this stage. Remember that we want to return the weight of the heaviest chunk.\nWe know the weight of the heaviest chunk from the situation when this element had not yet come into the picture. We know the heaviest chunk from the previous iteration in the sequence. If we are just at the beginning, then the current answer is initialized to 0 and we really have nothing to check. We just output the value of the singleton chunk that got introduced. Just as a sanity check, that is what happens at the very first step.\nBut in a general iteration, the value of the variable current answer gives us information about the heaviest chunk in the previous snapshot. Now there was this one element that came in, and it potentially merged some sets, or it potentially manifested as a singleton set. But essentially, the only new contender is going to be the set that this new element belongs to. All other sets pretty much remain the same. They have the same weight as the previous step.\nSome sets disappeared. Notice that if one of the sets that disappeared was actually the champion set from the previous iteration, then it is going to at least retain that status when, you know, it gets merged with the new element. The only reason a set disappears from the previous snapshot is that the set got enhanced with the new element that was added. It got merged with 1 or 2 sets depending on the situation that you are in.\nNotice that the value of the set, the weight of the set only gets better because all of the numbers in the array are non-negative. So we do not have to worry about if we lost this set. Maybe the maximum is the crown now needs to shift to one of the other sets. We need to look through all of the other sets and check if one of them got better.\nNotice that if the newly introduced element could have been potentially a large negative value, then this would have been a problem. After this merger, maybe there was a set that was doing very well and was championing the previous round and now it just became much worse and we need to find a new champion. But notice that this is something we do not need to worry about at all because all the elements have non-negative values. When you bring them in, the previous sets, if at all, get better.\nAll that we need to do is check if the new set that came into the picture, which could either be a singleton or it could be the merger of some sets from the previous iteration. We just need to sanity-check the weight of this set against the best value that we had from the previous iteration. So the weight of this newly created set dominates the current answer. Then we need to update the value of the current answer otherwise we leave the current answer as it was.\nThat is essentially what is happening in the penultimate line of this code snippet. After this, we basically just do the formalities. The logistics would be to push the value of the current answer into our answers array so that we are tracking the answers at every iteration.\n(Refer Slide Time: 09:38)\n\nOnce you have gone through the whole process, we need to shave off the last answer that we add to the answers array. The reason for that is, at the very end when you add the last element to the array, you have reconstructed the whole array. The answer that you get at that point is going to be the sum of all the elements in the array. There is just one junk. Your output only starts from the heaviest chunks after the first element has been removed.\nThe last thing that you add to the answers array is not really relevant. We want to get rid of it. That is the pop operation that you see here. After this, your answers array is ready for output. Do remember to reverse the answers array because we have been collecting the answers in the opposite order of what actually transpired.\nWe need to reverse this back so that the output is consistent with what is expected. At this point, we are pretty much done. Let me just quickly recap a couple of small changes that we needed to make to the union-find class. I will not recap the whole class because that is been described in some detail in the previous module. Do check that out if you have not already.\n(Refer Slide Time: 10:55)\n\nOne function that we did need to add here was the makeSet operation. Even before this, I will mention that you have to adjust your initializations a little bit. In the previous constructor, the whole thing was set up to capture the state of ‘n’ singleton sets. We wanted every element to be its own set. What we do instead is lay the groundwork. We create enough room for ‘n’ sets to be or ‘n’ elements to be eventually added. But initially, all the sets are empty.\nAll the parent pointers that point to -1, it is some value to say that these are not yet defined. The depths of the trees are also -1 just to say that these trees do not exist, and things like that. So we made some adjustments to how the constructor works and makeSet is what captures the creation of singleton sets as they come along. There are multiple ways in which you could do this. I chose this because it felt natural to me in terms of just being reflective of the process as we described it.\nBut I am sure there are other equally valid implementation strategies. Although I am not showing you the modified constructor here, you can find the entire code as usual in the official repository. Let us just quickly look at what is happening in makeSet. When you are creating the ’i’th element – as usual, the ’i’th element at this point is a singleton set is its own leader. The parent simply points to itself. This is a tree, which has just one root.\nSo by convention, its depth or rank is going to be 0. It is a set whose size is just 1. It is a singleton element. When we create a new set, we increase the number of sets. We increment the numSets variable accordingly. Notice that the extra thing that we are tracking in this problem is the sum of the elements in any given set. The sumSet array at the location ‘i’ needs to be updated so that it has the value of the element in the array that we were working with.\nRemember, we passed this as a parameter, that is the second parameter here. SumSet of ‘i’ is initialized to ‘x.’ One thing that I am not showing you that is actually quite important is that when you are doing the union operation, you do need to update sumSet there as well. So sumSet of y will become sumSet of y plus sumSet of x. Basically, you want to bring in the sum of all the elements that were there in the set being tracked by x to now the largest set that is being tracked by y.\nThis is very similar to the updates that we did for tracking the minimum element, the maximum element, the number of elements in the sets, the sizes of the individual sets, and things like that. It is very much in that spirit. I hope that you will be able to work through this yourself and just in case you need to cross-check, or you need to refer to it, the entire code is available in the GitHub repository.\nYou are welcome to take a look at that as well. So with that, we come to an end of the description of how we would solve Destroying Array. I hope you enjoyed this. Let me know what you think in the comments or keep the conversation going on Discord. I look forward to seeing you there. We will be discussing one more problem this week. So I will also see you in the next video. Thanks for watching and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec34.html",
    "href": "materials/cpnotes/Lec34.html",
    "title": "Shortest Paths - Module 2 (Wormholes [Bellman-Ford | Negative",
    "section": "",
    "text": "Lecture - 34\nShortest Paths - Module 2 (Wormholes [Bellman-Ford | Negative Cycles])\nWelcome back to the second segment of the second module in the sixth week on shortest paths. So, what we have discussed so far in the previous segment is a method to deal with the most general situation when it comes to edge weights, where we even allowed for the presence of negative cycles.\nAnd the way things work here is that our obligation is to only detect a negative cycle if it exists because, in such a situation, the very notion of shortest paths becomes ill-defined anyway. And in the absence of negative cycles, we are supposed to return the shortest path information, as is usual. So, we saw how to do this using what is popularly known as the Bellman-Ford Algorithm.\nAnd essentially, this involves ‘n-1’ iterations of relaxing every tense edge. And at the very end, we simply check if there are any tense edges that still remain. And if they do, then that is a sure sign of the presence of a negative cycle, and we return as much. But otherwise, we would have, by then, correctly computed all the shortest path distances from the source.\nSo that is what I wanted to say by way of recap. If all of this went by too fast, chances are that is because you have not had a chance to go through the first segment of this module. So, please make sure to do that. Because here what we are going to do is implement whatever we have learned so far. And we are going to do that in the context of this problem called ‘wormholes.’ As usual, you can find a link to the problem statement in the description of this video. And let me begin by telling you about the problem.\n(Refer Slide Time: 02:02)\n\nSo, we are told that in the year 2163, which is when wormholes were discovered. A wormhole is a subspace tunnel through space and time connecting two star systems. And wormholes have a few peculiar properties. Now, you can probably already guess, given the context in which I am presenting this problem that we want to think about star systems as the vertices of some graph and a wormhole as an edge that connects them.\nSo, let us just keep that at the back of our minds, and then continue with the story here. Now, I should mention that in the original problem, these properties are given as a list. And I have taken the liberty of rearranging the items on the list in a way that the sequence is just more convenient for me to share with you; your experience may be slightly different if you are reading the problem statement directly.\n(Refer Slide Time: 2:59 & 03:19)\n \nAlright. So, the first thing that I want to tell you is that a wormhole has two endpoints, each situated in a star system. This sounds very convenient. And it confirms our earlier suspicion that we want to model wormholes as edges and star systems as vertices in some sort of a graph abstraction.\nAlright. The next thing we are told is that the wormholes are one way only. This also has a fairly natural interpretation in the language of graphs. We want to say here that our edges are directed.\n(Refer Slide Time: 03:31 & 04:22)\n \nNow the next thing that we have is the following. The time that it takes to travel through a wormhole is negligible. Now, wait a minute. This does sound a little bit funny. Because we are thinking of wormholes as edges, this is making it sound like we do not have any natural concept of edge weight.\nRemember, when we were working with the email problem, the cables that connected to servers had some latency going on. So, that was a natural notion of edge weight. But here, it seems like we are getting travel time through the wormhole for free. So, that does make you wonder: So, maybe edge weights are coming up in some other form that we have to watch out for – So, let us just keep this in mind that the wormhole travel comes for free, at least in terms of time.\nNow, we are told that a star system may have more than one wormhole endpoint within its boundaries. This just means that our vertices may have in-out degrees that are possibly greater than one. That is what it would mean for a single star system to accommodate more than one wormhole endpoint. So, this is perfectly fine.\n(Refer Slide Time: 4:44 & 05:13)\n \nThe next thing that we are told is that for some unknown reason, starting from our solar system, it is always possible to end up in any star system by following a sequence of wormholes. So, this means that there is a path starting from a particular vertex in a graph, the one that corresponds to our solar system to any other vertex in the graph. So, this is some sort of reachability promise in the graph structure.\nNext, we are told that between any pair of star systems there is at most one wormhole in either direction. So, this is essentially an assurance that there are no multiple edges. And there even are not any directed cycles of length. So, you cannot go and immediately come back. So, this is just that there are no multi edges.\n(Refer Slide Time: 5:37 & 06:05)\n \nThe next thing is that there are no wormholes with both endpoints in the same star system. Again, in the language of graphs, this simply means that there are no self-loops. And combined with the previous fact, what we have is that we are working with a simple graph here. So, far, so good. There does not seem to be a whole lot of drama. Everything seems to fall in place nicely with our anticipated graph model.\nLet us look at the next property. So, we are also told that all wormholes have a constant time difference between their endpoints. Let us elaborate on this a little bit further because this is now beginning to sound possibly a bit confusing.\n(Refer Slide Time: 6:20)\n \nSo, here are a couple of examples to illustrate what the previous property might mean. So, a specific wormhole may cause the person traveling through it to end up 15 years in the future. And another wormhole may cause the person to end up 42 years in the past. Okay. So, this could happen. And perhaps this is our first indication of some sort of edge weight concept. Maybe the weights have to somehow reflect these time differences.\nBut how exactly do we specify the weights? And to what end? Well, only time will tell I guess because we still have to figure out what our task is going to be. What are we supposed to do with all of this information about star systems and wormholes, and what not?\n(Refer Slide Time: 07:11 & 07:55)\n \nSo, what we are told next is that we have a brilliant physicist living on earth, who wants to use wormholes to study the Big Bang. Now, that does sound pretty ambitious. Let us look at what else we have in store. So, we are told that advanced means of transportation have not been invented yet. So, you cannot simply go from any star system to any other star system directly. But you can use these wormholes to find your way around.\nAnd this of course falls in line nicely with all the graph modeling that we have been doing in parallel. So, transportation between star systems seems to manifest naturally as paths in our graph. But with all that said, we still do not know what we are looking for. So, let us continue reading the problem statement here.\nSo, we are told that our scientist friend wants to reach a cycle of wormholes somewhere in the universe that causes her to end up in the past. And we are also told why this is of interest to her. Because once she finds such a cycle of wormholes, then she can keep going round and round around that cycle. And that will keep taking her back further and further in the past.\nAnd hopefully, ultimately, at some point, she will be so far back in the past that she would be witnessing the Big Bang, and that would presumably allow her to study it. Or so the story goes. So, that is what we are looking for. We are looking for a cycle of wormholes, that takes our scientist friend back in the past.\nNow, intuitively by now, this is probably ringing some bells. And perhaps, well, since we are told that we are looking for the cycle of wormholes, it is probably not very farfetched to imagine that we are looking for a cycle in our graph. And since we are told that this cycle of wormholes must have this property, that it takes the scientists back in the past, we probably want to imagine that this cycle is some sort of a negative weight cycle.\nBut for that to actually happen, we need to figure out how exactly we want to model our edge weights. So, this would be a good time to pause and think about how would you ascribe weights to the edges so that a cycle of wormholes that takes the scientist back in the past will correspond to a negative weight cycle in the graph that we have built up so far? Take a moment and come back once you are ready.\nSo, I think a fairly natural thing to do is to use the time difference as the edge weight. So, let us say that we have a wormhole that takes somebody ‘x’ years into the future, then we might want to associate a weight of x with the edge that represents this wormhole. Similarly, if we have a wormhole that takes somebody ‘x’ years in the past, then the edge corresponding to this wormhole should have a weight of -x to signify that you are moving backward in the passage of time.\nSo, now notice that if you just add up the edge weights of any sequence of wormholes, then that sum total will reflect the total amount of time travel that you have done if you were to actually embark on a journey that involves this particular sequence of wormholes. And in particular, you can check that a wormhole cycle that takes somebody in the past is going to be a negative weight cycle if we were to use these edge weights.\nSo, we know that with the appropriate graph model, this problem essentially boils down to the issue of detecting whether we have a negative weight cycle in our graph or not. And remember that Bellman-Ford is designed for precisely this purpose. So, we should be able to solve this by simply implementing Bellman-Ford. Before we do that, though, let us just do a quick sanity check on the constraints to be sure that we will be safely within the time limits.\n(Refer Slide Time: 11:11)\n\nSo, of course, the problem statement concludes by asking us to write a program to determine if we have a cycle of wormholes that takes our scientist friend back in the past. And we are also given that the number of star systems and the number of wormholes is at most 2000 each. This means that the product of the number of vertices and edges in our graph is of the order of 4 * 106, which means that we should be pretty safe in trying to implement Bellman-Ford for this problem. So, let us go ahead and take a look at the code.\n(Refer Slide Time: 11:47)\n \nTo begin with, I am going to implement this as an edge list, again, just for convenience because the inner loop in the Bellman-Ford Algorithm just goes over all the edges. So, having all the edges in a list, I felt was a fairly natural way to do things. But you can do this equally using adjacency lists, or even adjacency matrices.\nThe only thing to remember when you are working with adjacency matrices is that the inner loop where you go over all edges will essentially require a scan of the entire matrix. So, the running time of Bellman-Ford becomes order n3 when you are working with an adjacency matrix representation. So, in general, it would be better to stick to an adjacency list or an edge list representation.\nBut if you need to use an adjacency matrix for some other reason, just be mindful of the fact that the worst-case running time would be given by order n cubed. Okay. So, this is just a fairly standard reading-in of the input, let us just move along and talk about how we would present the output, assuming that we have written a function called Bellman-Ford, which returns one if there were no negative cycles, and it returns 0 otherwise.\nSo, here we are simply reporting our outcomes based on what Bellman-Ford tells us. Remember that we invoke the Bellman-Ford function with information about the source vertex, which in this case is the vertex that represents the solar system because that is where we are starting out. Let us move along and talk about how we implement Bellman-Ford.\n(Refer Slide Time: 13:26)\n \nHere is the Bellman-Ford function, which, again, takes just the identity of the source vertices on the parameter. The remaining variables that have the information about the graph are global anyway so that the function can freely access it. So, this is simply the initialization as always, we have a distance array, which is initialized so that every value is some very large number, which is identified by this constant INF.\nBut we always remember to initialize the distance of the source to 0. And here you could also say that the predecessor of the source is the source vertex itself. We are maintaining a predecessor array here, although we do not really need it for this problem.\nIt is very similar in behavior to Dijkstra in the sense that the predecessor array will allow you to go back and retrace a path in case you need to output one. Alright. So, this is the fairly standard initialization step. Let us move on to the main body of the Bellman-Ford algorithm. Remember that in this algorithm, all we do is relax every tense edge and we repeat this ‘n-1’ times.\nSo, the ‘n-1’ repetitions are being taken care of by the outermost ‘for’ loop. And the inner ‘for’ loop is essentially a loop that goes over every edge by simply traversing the edge list. And the logic that you see inside this nested ‘for’ loop is the logic for checking if the edge that is currently under consideration is tense or not.\nAnd if it is tense, then we just appropriately update the values in the distance array, and we also update the predecessor pointer. Remember that in this algorithm, you do not really need any additional special data structures to be storing the distance values because we do not need to keep looking up the minimum values or anything like that. So, this is really all that is there, do it. Now when you want to do the actual detection of the negative cycle, we do this check one final time.\n(Refer Slide Time: 15:40)\n\nSo, we go over the edge list once again, after we come out of this ‘for’ loop. And if we discover even one edge that is tense, then we return 0 to indicate that there is a negative weight cycle and nothing can be done here. But if we survive the slope if the control does not go back from inside this for loop that we have at the end, then we can return one to say that we have properly found all the distances from the source ‘s.’\nSo, this is the complete implementation of Bellman-Ford. And I think it is, again, a really elegant algorithm. And it handles this most general situation that we are working with really, really well. Now, the next thing that we want to consider is moving on from the single-source shortest paths problem to the All Pairs Shortest Path Problem.\nNow, this is where we want to compute the shortest paths between every pair of vertices in the graph. And you could say that is easy, we just run the SSSP algorithm, with every vertex, in turn, being the source. And you could absolutely do that.\nBut then the running time is going to be ‘n’ times the cost of your SSSP algorithm. And the question, as always, is if we can do something slightly better. So, we are going to see an interesting approach to this. And again, that is popularly known as the Floyd Warshall algorithm. And that is what is coming up in the last module for this week. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec22.html",
    "href": "materials/cpnotes/Lec22.html",
    "title": "Disjoint Set Union - Module 3 (War-II)",
    "section": "",
    "text": "Lecture - 22\nDisjoint Set Union - Module 3 (War-II)\nWelcome back to the second segment of our discussion on ‘War.’ This will not make any sense if you have not seen the previous video, where we actually introduced the problem. Just in case you have stumbled on this directly, then please do make sure that you watch the first part first.\n(Refer Slide Time: 00:30)\n \nIf you remember, when we stopped there, we said that we could use disjoint sets to fairly naturally model the friendships. But we were not sure how the enemies can be accounted for. Let me just say that one way of tracking the enemies is to just track the enmities between the leader elements. It turns out that will be sufficient to make all the inferences that we need to make.\nIn particular, let us say that at some intermediate stage, you have developed some of these friendship clusters. Let us say that you know that there is some pair of people, one from the first cluster and one from the second that are enemies, then you can apply your rules to observe that this actually implies that all of these people from the first cluster are enemies with all the people from the other cluster.\nWe are going to just succinctly make a note of that by adding an enemy relationship between the leaders. When we get an ‘ARE ENEMIES?’ query, basically, we ask ourselves, if the representative elements in the sets that the people belong to, if they are enemies. That is essentially necessary and sufficient to produce an affirmative answer to this query. Now, this will become clearer as we go along.\nBut the foundations are the following. We will have a standard DSU data structure to keep track of the friendships between people as they evolve. We will have an array of length N to keep track of the enemies (just of the leaders). Because of the way enmities evolve, and this is something that, as I said, will probably become clearer later. It is sufficient for every leader element to point to at most one other leader element, saying, that that is my current enemy.\nYou will never be in a situation where you need to point to the leader of more than one cluster in your friendship network. We will see why that is as we go along. But in terms of what you need to write down the code, it is going to be your standard disjoint set union data structure + an extra array, which is the book-keeping that we were talking about, to keep track of what is going on with the enemies.\n(Refer Slide Time: 02:56)\n\nBased on this, you can perhaps already anticipate how we will answer the ‘ARE FRIENDS?’ and ‘ARE ENEMIES?’ queries. This part is actually quite straightforward. Because the friendships are being maintained by disjoint sets, the ‘ARE FRIENDS?’ question just boils down to asking if the two people on whom the query is being made belong to the same cluster or the same set or not. We have already seen this as the ‘isSame’ set helper function.\nAll that this does is check if the leader elements of the sets that these two people belong to are the same or not. The answer is ‘yes’ or ‘no,’ just based on that. For the ‘ARE ENEMIES?’ query, it turns out that two people are enemies if and only if their leaders are enemies. If the leader elements of your set are enemies, then of course, by applying the rule which says that the enemy of a friend is an enemy, you can conclude that the two people who are involved are enemies as well.\nIf the two people who are involved are enemies, then very similarly you can infer that the leaders of their sets are also going to be enemies. That is all that you need to do here. You need to go to the leader elements for the two people on whom the query is being made. You need to check if they are mutual enemies. This information is being tracked by this enemy array. That is all that you need to check here.\nThat takes care of two of the four queries that, that we had to worry about. It feels like half the battle won, at least psychologically. But it turns out that the bulk of the work really is in making sure that you build up an accurate picture as you receive operations of the first two kinds, which are the MAKE FRIENDS and the MAKE ENEMIES operations. There you want to make sure that you are building up an accurate picture and you are drawing all the inferences that you can. Let us turn to those operations now and see how we will deal with those.\n(Refer Slide Time: 04:52)\n  \nWe have ‘MAKE FRIENDS.’ Remember that friendships are being tracked by DSU essentially. The natural thing to do here is to interpret this as a union operation. If you remember what we do typically when we are trying to do a union is to first approach the leader elements of the sets that these people belong to. Of course, at the very initial stages, they will be the elements of the people themselves.\nBut, we are talking about a generic situation. We approach the leader elements. Of course, first, we do check if these leaders are already enemies. If this is the case, then you cannot make friends out of people who are already enemies. Notice that if the leader elements of ‘your set’ are already enemies, then by inference, you are enemies as well. You already have this information.\nThis will be the situation where you have a contradiction. Your output -1 and you move along. But suppose there is not a contradiction. Then what are the possible scenarios that could arise? Well, it is possible that the leader elements are the same. If that is the case, then this picture is not very accurate. But if the leader elements are the same, then that means that the two people that you were given in this operation are already friends.\nThere is no work to be done. You could just, again, move along, this time for a different reason. Now, suppose that they are not already friends. But let us also say that the two leaders have no known enemies. If they have no known enemies, then when you merge these two clusters, there are no additional inferences to be made. There are no additional inferences to be made in the context of the enemies.\nWe just do a simple union. Once again, at this point, we are done. But, there are some cases to be taken care of if one or both of these leader elements already have known enemies of their own. Let us take a look at how that could pan out. We know that we have to establish this friendship here. That is a non-contradictory operation and that is going to happen.\n(Refer Slide Time: 07:15)\n \nLet us say that one of the leader elements has a known enemy, and the other leader element has no known enemies at this stage. That is what this picture would look like. But now remember that the enemy of a friend is also an enemy. Based on this, you can infer this additional enmity relation. So once you merge the two sets, you want to make sure that the new leader keeps track of the fact that the leader has an enemy in this, in this other leader element. This enemy is going to be the leader element of some other set.\nWe would want to make a note of that. Normally, if the leader element does not change, after you do the union, you actually do not have to do anything. But it is possible that after the union, the leader element changes. In that case, you do have to update the enemy array to make sure that you continue to track this enmity.\nSimilarly, you could be in a situation where both of these leaders have a known enemy. This is what that situation is going to look like. Once again, by applying the rule of the fact that the enemy of a friend is also an enemy, by applying this rule twice, you infer these two new rivalry relationships. But now based on this, can you say something more? Take a pause here to see if you can infer any new relationships based on the picture that we have built out so far.\nIf you had a chance to think about this, you may notice that these two enemies also become friends after we have made the inferences that we just made. The reason for this is that if you have a common enemy, then you are friends. These two people actually have two common enemies now. This is essentially how the rules would play out in this situation. But in terms of the implementation, what would we like to do?\nNow we not only make the two people friends that we were supposed to make friends according to our operation, but we actually can establish a new friendship. There will be two pairs of clusters that get merged. We want to ensure that the leaders, the potential new leaders of these two clusters, record their enmity. That, again, the information about the enmity is carried forward as we would need it to.\n(Refer Slide Time: 09:44)\n  \nLet us actually take a look at all of these cases, from the viewpoint of the friendship clusters that may have come about. Let us say we are at some intermediate stage and we have developed some friendship clusters. Let us say that these are the leader elements. Now, suppose that you have some known enmities between leaders. Notice that these will always show up as pairs of clusters. You will never have enmity show up in any other way.\nFor example, you will never have this sort of situation. Again, take a moment here, if you need to, to think about why this picture is not a valid one? Why this would never arise? The reason this would never arise is that if you had the structure, then notice that the two clusters on the left would not really continue to persist as disjoint clusters because you have a common enemy situation here.\nThese two clusters would have actually been merged if our algorithm was doing its job correctly up to this point. This picture never really arises. The clusters pair up in terms of known enmities, and some clusters are just hanging in isolation. The cases that we saw so far were the following. First, we said that maybe both of the leaders who are going to become friends have no known enemies.\nThat is essentially a simple merger of two isolated clusters. It is also possible that one of them has a known enemy and the other does not. In this case, what we said was that we will do a simple merge as before but it is possible that after this merger, the leader gets updated. Then we have to make sure that the leader, the enemy pointer, is pointing correctly from the new leader to the old enemy.\nYou could also be in a situation where the two leaders who are coming together, both of them have known enmities. In this case, what was happening is that you not only merge these two clusters, but you also merge the other two clusters that involved the known enemies. Both of these freshly minted clusters will have their own new leaders potentially, and you need to reestablish the enmity between those two leaders of these larger merged clusters.\nHopefully, the algorithm is clear, and all the cases are clear. This is how we will handle the MAKE FRIENDS operation.\n(Refer Slide Time: 12:11)\n  \nNow, let us turn to the MAKE ENEMIES operation. Just like with MAKE FRIENDS, when we are asked to MAKE ENEMIES, we will approach the leaders because those are the people between whom we want to establish the enemy team. That will take care of the clusters pretty much by inference. Also if you remember, the way that we address the ‘ARE ENEMIES?’ query - this is really all that we need to keep track of.\nOnce again, just make sure that you handle the contradictory situation. In particular, if these two people involved here are already friends, then you need to output -1 and completely ignore this query. Similarly, another easy situation is if they are already enemies. In this case, for a different reason, you do not need to do anything because this relationship has already been established.\nWe can move along. But now suppose that they are not already enemies. We want to, again, do a case analysis that is similar to what we had before. Suppose these are coming from two components that are hanging in isolation. Neither of these leaders have any known enemies. Then again, just as before, it is a matter of doing a simple pointer update.\nNotice that we do not need to do any unions here. These clusters, in fact, must remain separated. But, they sort of get magnetically attached through this rivalry relationship. That is being tracked by the red pointers. The red pointers that we were visualizing in the picture from a few moments ago are what is being tracked by the enemy arrays. Just keep that at the back of your mind. That is what we do in this case.\n(Refer Slide Time: 13:48)\n \n \nBut suppose that you are actually connecting a leader who has a known enemy with a leader who does not have any known enemies. In this case, you can actually make some additional inferences. Pause here for a moment and think about what is an extra relationship that comes out of this situation.\nIf you remember the rule about how a common enemy makes for a friendship, you will realize that these two leaders can actually become friends. If you establish an enmity between two leaders, and one of them already has an existing enmity, then you actually have a good reason to merge some two clusters.\nJust to make the cluster perspective a little more explicit, let us actually pull up a picture in terms of clusters. Notice that you are trying to establish an enmity between the cluster on the left and the cluster in the middle. That is the query. That is what we have been asked to do. But the cluster on the left has a known enmity with the cluster on the right, which means that by the common enemy rule we know that these two clusters must actually be friends.\nWhat we do first is we go ahead and merge these two clusters, and just to record that inferred friendship, and now depending on whether this merger created a new leader or not, we have to figure out if the enemy pointer needs to be updated. That is what is going on in this case.\n(Refer Slide Time: 15:18)\n \nThe final situation is: If both the leaders have known enemies. Here, what is going to happen is that you can make some extra inferences as before. In particular, you can infer these two friendships. Once again, the reason that you can infer these friendships is because of the common enemy rule. For example, the person in the red circle is a common enemy for the two people in the yellow circle.\nThat is why you can infer the friendship between them. It is symmetric for the other friendship relationship. How do you handle this situation? How do you put these new friendships on the record? Remember, we are tracking friendships with the standard disjoint sets model. What will happen is, you will end up essentially merging the sets that these pairs belong to.\nThe two people in the yellow circles and the two people in the green circles, we go ahead and merge the sets that they belong to. After that merger is done, each of these two sets is going to have a new leader element emerge, which is going to be one of these existing leaders. But you are going to have the leaders identified after you do the union.\nThe final step is to make sure that these two new leaders have the enmity relationship between them put on the record. That is all that you need to do here. That brings us to the end of the description of how you handle the MAKE ENEMIES operation. With this, we are in fact done with both the MAKE FRIENDS and the MAKE ENEMIES operations.\n(Refer Slide Time: 16:58)\n\nLet us do a high-level summary of what we have discussed so far. First, remember, we handled the contradictory cases and got them out of the way. If you are asked to make friends between two enemies, or you are asked to make enemies between two friends, then we remember to output -1 and we move on.\nSimilarly, if the two people of whom you want to make friends are already friends or the two people you want to make enemies are already enemies, then once again, there is nothing that needs to be done and this is an easy case as well. The third easy case is: When the two people involved in the queries do not have any known enemies of their own.\nIn this case, for MAKE FRIENDS, this was a simple union, a merging of two clusters. In the case of the MAKE ENEMIES operation, it was just a matter of updating the enemy pointers between the leaders. Now, the non-trivial case is where, when one of the leaders had an own enemy and the other one did not, or when both of the leaders had their own known enemies.\nIn both of these cases, you could infer some extra relationships. This involved carefully merging some sets that you did not have to directly merge because of the operation but by inference. Then just keeping track of the new leaders and making sure that the enemy pointers are cleanly updated. The specifics of how you handle these two cases, we have already discussed.\nIn case you missed it, you might want to just go back and look at that part of the discussion in the video. That brings us to the end of the algorithm. I think by now you have all the information that you need to actually implement this. We will do a quick overview of the implementation in the last segment of this module. The code in the implementation actually very closely follows the description.\nI am going to not do a very elaborate overview because this is a slightly non-trivial problem and it is a really good exercise to try on your own. In the implementation video, we will sort of briefly summarize the main modifications to the unionFind class. Go over a few of the cases and leave out the ones that are either symmetric or very similar to the cases that we have seen before. Hopefully, you have a chance to actually work through this yourself and treat the implementation excursion as an elaborate hint, rather than a line-by-line explanation.\nI will see you in the implementation video. In the meantime, if you have any questions or comments about this problem, then please do leave a note in the YouTube comment section. Or feel free to start a conversation in discord or at the Google Groups mailing list. We will as always look forward to hearing from you and I will see you in the final segment, which is going to cover the implementation!"
  },
  {
    "objectID": "materials/cpnotes/Lec36.html",
    "href": "materials/cpnotes/Lec36.html",
    "title": "Shortest Paths - Module 3 (APSP [Floyd-Warshall] | Page Hopping)",
    "section": "",
    "text": "Lecture - 36\nShortest Paths - Module 3 (APSP [Floyd-Warshall] | Page Hopping)\nWelcome back to the second in the last segment of the third and the last module in week six. And we have been discussing ‘shortest paths’ broadly. But in this module, our focus has been on the variant called All Pairs Shortest Paths. And in the previous segment, we described the Floyd-Warshall algorithm that gives us a slightly better running time compared to running, for example, Dijkstra’s algorithm n times, especially when the number of edges is proportional to n squared.\nSo, this is the algorithm that we want to implement in this segment. And to do that, we are going to use a problem called ‘page hopping,’ which was ICPC World Finals problem from 2000. This is probably one of the most straightforward problem statements that we have seen.\n(Refer Slide Time: 00:58)\n\nThis is from the problem statement for page hopping. We are told that you are given a graph in which all the nodes can be reached from any starting point. And your job is to find the average shortest path length between arbitrary pairs of nodes. Of course, the sentence is sandwiched between a bit of a story about the internet and so on. So, I am not going to get into the story. But if you are curious, then you can certainly lookup the link in the description and read the full problem statement. I will give you a few other snippets from the problem statement that will clarify the kind of graph that we are working with and what the constraints are.\n(Refer Slide Time: 01:35)\n\nSo, first of all, we are told that each test case will consist of an arbitrary number of pairs of integers a and b, each representing a link from a page numbered ‘a’ to a page numbered ‘b.’ So, again, we are talking about pages here because the nodes in this graph really correspond to internet pages.\nThat is part of the story. But you can see here that the edges are connecting pairs of vertices in a fashion that is clearly directed.\nAnd in fact, the problem statement even has a picture and an example that makes it quite clear that the graph that we are working with is a directed graph. So, that is the first thing to note.\n(Refer Slide Time: 02:10)\n \nWe are also told that the page numbers or as we know, the vertices, the vertex labels will be in the range 1 to 100. This tells us that this is a small graph. There are only 100 vertices tops. So it is going to be pretty safe to apply our order n cubed algorithm here.\nThe next thing that we are told is that there are no self-referential links, which is the same as saying that there are no self-loops. And we also told that there is at least one path from each node to every other node in the graph. So, in the context of directed graphs, this is essentially a promise of strong connectivity.\nNow, if you are hearing that term for the first time, do not worry about it. It is essentially the analog of connectivity from undirected graphs. And it is exactly what is being said here, which is that you can go from anywhere to anywhere else in the graph. So, this is also given to us. We never going to get stuck with these large infinite values for any better vertices, which is a useful promise to have as we go along.\nSo, with all that said, let us now turn to the implementation. I will say that in this problem, we are given a graph with at most 100 vertices. And we are also told that there are no edge weights involved. So, it would also be perfectly valid to take your BFS implementation from last week and just try to run that ‘n’ times.\nSo, I definitely encourage you to give that a shot. It is a valid alternate solution. But since we want to use this problem as an excuse to implement the Floyd-Warshall algorithm that we discussed in the previous segment, that is what we are going to go ahead and do now.\n(Refer Slide Time: 03:50)\n \nSo, the first part, as usual, is just taking the input in and doing some initializations. I will say that most things here are perfectly routine. But the way the input is specified here is a bit unusual, in that it is just given as a list of edges terminated by pair 00. In particular, you do not have the number of vertices or the number of edges given to you explicitly.\nNow you do need this information to compute the average shortest path distance because remember, in the end, you want to divide by the number of pairs of vertices that you have considered, which is pretty much all pairs here. So, you could essentially count the number of vertices in a number of different ways.\nWhat I am going to do here is just initialize a set. And every time we see an edge, we add both of its endpoints to the set. Notice that the vertices will not get repeated because we are using the set data structure here. And when you want to figure out the number of vertices at the very end, we can just look up the size of the set that we have built on the way and that should take care of it.\nSo, that is why you have this set – the ‘vertices variable’ here, which is in fact, a set. Alright, so we also have a distance array. This is declared, I think, in the global scope. And it is committed to having memory amounting to accommodating 100 vertices. We know that because that is the limit. That is all that we are going to need to reserve for ourselves. All of this is inside a ‘while’ loop, by the way.\nSo, these are just the relevant snippets that I am sharing here. But I think if you want to make sense of the whole thing, you might want to look up the code, the full code, in the repository. Again, as usual, the link is in the description. In any case, when we are processing afresh instances, which is what is happening in this part of the code, you want to initialize your distance array so that the values between pairs of vertices are just initialized to infinity.\nAnd of course, we also have ‘i to i’ being initialized to 0 because (it) does not take any work to go from a vertex to itself. Now, as we process the edges, we are going to update the values of this distance array. You can initially think of the distance array that is just being an adjacency matrix. That is what it is going to be when you read the input n for the first time.\nBut then you can just reuse this adjacency matrix as the distance values that we want to compute using Floyd-Warshall later on. So, let us just read in the input here. So, we get these pairs of vertices, and we keep reading them as long as we do not encounter the ‘00’ vertex. And as you can see, we are inserting these vertices into a set to just keep track of them.\nAnd we are initializing the distance of u-1, v-1 to 1. This is because I just wanted the vertex indices to range from 0 to n-1. You could do this differently. And it is not going to be a problem either way. So, now that we have the initial distances that are just given by the direct edges, remember that we have already implicitly carried out the base case for the Floyd Warshall algorithm.\n(Refer Slide Time: 07:14)\n\nSo, that is the ‘r = 0’ case. That is already done by simply reading in the values coming from the input for the information about the edges. The rest of it, these nested ‘for’ loops that we have here are implementing this reference that we discussed in the previous segment. So, the outermost ‘for’ loop is keeping track of the phases. We are going to then go through every pair of vertices and see if we need to update the value of the distance between i and j.\nSo, essentially, we want to know, do we really use the ’k’th vertex or not. And if we do, the new distance is going to be essentially the sum of the distances: distance [i][k], and distance [k][j]. If that is going to be better than whatever we have previously, then we need to update the value of distance [i][j]. So, you could also write this a little more succinctly as an update of distance [i][j] is being min of distance [i][j], the sum that you see here. Either way, it has the same effect.\nAnd that is essentially all of Floyd-Warshall. Okay. So, if you write it without the comments, and you write it in the style of recomputing a minimum, or overriding the value of distance [i][j] with the minimum between distance [i][j] and the sum that you see here, it is really going to be just four lines of code, which is what makes it an attractive proposition, especially in a contest situation if you just want to go something up quickly.\nJust remember here that the complexity of this approach is fixed at order n cubed because these three loops are going to run their course for sure, irrespective of how many edges are there in the graph, for example. So, just make sure that you apply this algorithm only when you are confident that your constraints can handle it.\nIn particular, watch out for the number of vertices being more than 450, then you might just be in a little bit of trouble with this approach. But if you have a small number of verses, then this is really a good option to have in your toolkit because of just how short the code is and how elegantly everything works out. So, with that, I think we come to an end to our discussion about shortest path algorithms.\n(Refer Slide Time: 09:45)\n \nI will just conclude here with one small comment about a bit of detail that I have not talked about very explicitly before, which is about how you set the value of infinity. So, sometimes you may find that not setting this value properly could lead to bugs, which are hard to detect. So, you want the value of infinity, which is what you initialize your distance array 2, to be on the one hand large enough, but also on the other hand, not too large.\nLet me explain what I mean by this. On the one hand, you do want it to be large enough because remember that when you are relaxing edges, this is the value that often your d of u plus w is going to be computing with. So, for instance, if you have a path, that is an actual path but it is really, really costly, when that is being compared against infinity, if your value of infinity is not large enough, your code might just say that ‘we are better off keeping the infinity-edge.’ Now, that is a problem because that infinity value really represents a path that does not exist.\nSo, you want to make sure that your value of infinity is greater than the sum of all the weights of the edges. So, typically, you will have some upper bound on the values of the weights of the individual edges. So, let us say that that upper bound is some x. And let us say you have m edges, you want to make sure that your value of infinity is set to something that is larger than m * x.\nNow, what did I mean when I said that it should not be too large. Sometimes you may be tempted to say that – let us just make this as large as we can. And particularly, you might be aware of the limits library, which gives you access to the largest possible value that you can store in a variable of a certain type.\nSo, for instance, you could invoke the built-in constant int Max to get the largest value that you can store in an integer variable, which would be something like 231 -1 or something like this. So, you might be tempted to initialize infinity to int Max. Now, what is the problem with this?\nWell, the thing here is that you could run into some really nasty overflow issues. When you are trying to evaluate the condition for relaxation, often, you might be comparing values that look like INF plus w. Because you are comparing d of u + w, and d of u, to begin with, may well be INF. Now, if INF is set to int Max, and you add a value W to it, what might end up happening is that you experience overflow, and this becomes a large negative number.\nAnd this will dominate whatever it is that is on the other side of the equation. This will appear to be smaller than d of v. So you will end up relaxing an edge that you really should not. Because what you want, the behavior that you want from your setting of INF is that INF any finite value should still be INF, it should not become accidentally a small value.\nSo setting your value of INF to be the very limit of the data type that is, you know, storing the value of INF – that is a dangerous thing to do. So, do not make it go all the way to the brink, because that is going to be problematic. Usually, a safe thing to do is to just set it to a value that is sufficiently large.\nSo, just look at your maximum weight limit multiplied by the number of edges, and pick a value that is a bit larger than that. Now, if int cannot handle it, or if that seems like it is going to be suspiciously close to the upper limit, and you might experience an overflow issue, just use a long int instead of an int or something like this.\nSo, just be a little bit careful about how you initialize your distance array. Because this can be a source of bugs that are hard to find. So just a very minor detail, but something that is worth being careful about. So, with that, we do come to an end of our discussion of shortest path algorithms.\nI hope you enjoyed this little journey through various cases starting from BFS all the way up to Floyd-Warshall. And in between, of course, we met Dijkstra’s algorithm, modified Dijkstra’s algorithm, and Bellman-Ford. It can be a lot to keep track of, so I would recommend just having a little bit of a cheat sheet with you, which just summarizes the various complexities and the scenarios in which these algorithms are applicable.\nSo, you know which one you want to use in a particular situation. Now, most of the problems that we saw in the videos were fairly direct applications of shortest paths because the goal really was to have an excuse to implement the algorithms that we were learning. On the other hand, there could be problems where it is not as transparent – that you want to be working with the shortest path algorithm.\nOr maybe you need to modify the shortest path algorithm that you have learned in some subtle way to account for whatever it is that needs to be done. So, there are a couple of examples of these kinds of problems in the ‘extras’ section. So if you have time, be sure to check them out. In the meantime, we will, as always, look forward to your contributions to the official repository.\nSo, once again, we have a week where all the official solutions are coded in C++. So, if you have versions of this that are written in Python or Java, we will really look forward to your pull requests in the repository. Thanks very much in advance. And of course, I hope that we will continue this conversation in Discord or over the Google mailing list, especially if you are listening to this during an active run of the course.\nSo, I will see you around there. Thanks very much for watching and I will see you back in the next module where we are going to talk about minimum spanning trees. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/Lec37.html",
    "href": "materials/cpnotes/Lec37.html",
    "title": "Minimum Spanning Trees - Module 1 (Blingor’s Network | Foundations",
    "section": "",
    "text": "Lecture - 37\nMinimum Spanning Trees - Module 1 (Blingor’s Network | Foundations [SPOJ])\n(Refer Slide Time: 00:11)\n\nHello, and welcome to the seventh week of Getting Started with Competitive Programming. This week we are going to be talking about ‘minimum spanning trees,’ which is yet another cool optimization problem in the context of graphs. This problem may, in fact, remind you of some of our discussions of single-source shortest paths.\nBut it turns out that it is really quite a distinctive problem in its own right, and we will contrast it with the shortest path problem as we go along. As usual, we will spend the first module laying down the foundations. We will discuss a couple of popular algorithmic approaches to this problem. They are usually referred to as Prim’s algorithm and Kruskal’s algorithm. As is the case with most of these algorithmic ideas for fundamental graph problems, these algorithms were also co-invented by other people.\nBut we will stick to these names because they are the standard textbook names, and you will have an easier time finding related material if you do it this way. But if you want to find out more about the history of this problem, then I would definitely recommend checking out the relevant chapter in the ‘algorithms text’ by Erickson. There is a link to it in the description of this video.\nSo, what we are going to do is, first, talk about minimum spanning trees – what the problem is, what we are required to do? We will talk about why it is different from, say, single-source shortest paths. In particular, we will talk about why a solution to SSSP may not actually serve as a solution for MST, even though it may be tempting to think of it that way. And then we will talk about Prim’s algorithm, which turns out to be an algorithm that has a flavor very similar to Dijkstra’s algorithm, again, making that connection with SSSP.\nBut really, the mechanics of it are subtly different. And hopefully, you will be able to see the differences and appreciate them. And finally, we will run this off with Kruskal’s algorithm. And you will see that the implementation of Kruskal’s algorithm relies heavily on the disjoint set union, which is something you have already seen in week four. So, that should tie up quite nicely. So, this module is divided into three segments corresponding to these three separate discussions, the introduction followed by Prim’s algorithm followed by Kruskal’s algorithm.\nWe will be testing both of these implementations using a problem on the sphere-online judge called Blingor’s network. It is a very direct ask for a spanning tree. So, all we have to do is make sure that we read the input carefully and then pass it on to the implementations of our algorithms.\nTheir problem statement promises large inputs, so this should be a good way to stress-test the efficiency of our implementations. So, with all that said, let us talk about minimum spanning trees now. I am going to introduce the problem to you through a story, which is a pretty commonplace thing for us to do.\n(Refer Slide Time: 03:04, 03:52, 04:08 & 04:19)\n \n \nBut this is a bit unusual in that the story is borrowed from a resource called CS unplugged. There is a link to this in the description. It is an amazing collection of activities and stories that introduce computational problems. So, if you are interested in follow-up stories, definitely check this out. But let us talk about this one first. So, once upon a time, there was a city that had no roads. Getting around the city was particularly difficult after rainstorms because the ground became very muddy. Cars got stuck in the mud, and people got their boots dirty.\nSo, the mayor of the city decided that some of the streets must be paved. But she did not want to spend more money than was necessary because the city also wanted to build a swimming pool – so they have a limited budget. The mayor, therefore, specified the following two conditions. The first one says enough streets must be paved so that it is possible for everyone to travel from their house to anyone else’s house only along paved roads. So, you want some sort of a ‘connected’ structure to emerge.\nThe second condition is that the paving should cost as little as possible. So, you want to find the best possible way of doing this. And, you know, the cost of paving any particular road, in particular, we have this example, which you are welcome to pause the video at this point and work out if you like. So, the cost of paving any particular road is proportional to the number of stones that are on that road in this picture. Now an obvious way of meeting the first condition is to just pave everything.\nThis will connect everyone to everyone. But notice that you can check that this does not meet the second condition because there are going to be some redundancies. At least in this particular example, you can see that there are many cycles, and that means that you can actually remove some of the roads and still remain connected. And therefore we know that it is not a minimum cost solution.\nIf you just wanted to optimize the budget, then, of course, you do not have to do anything at all, but then you do not actually connect the houses. So, you need something that is in between and it is not surprising that the structure that you are looking for is a tree because that is exactly what captures this notion of being minimally connected. And not only do you want a tree, (but) you (also) want a tree that, well, touches every vertex and has the smallest possible cost in terms of the sum of the weights of the edges.\nIn this case, the weights simply correspond to the cost of paving the road in question. Now for our convenience, let us replace this lovely sketch of the city with a more useful abstraction. It is pretty natural to want to model this using a graph with the vertices representing the houses, and an edge between two vertices, indicating that it is possible to, in fact, pave a road between the corresponding houses, and a number on that edge would record the cost of actually paving that road.\n(Refer Slide Time: 05:51)\n\nSo, what we are looking for in this graph is a subgraph, which is a tree where the total costs of all the edges in the tree are as small as possible. So, please take a moment here and see if you want to work through this yourself in an ad hoc fashion.\nOr if you are already familiar with a systematic approach, then perhaps try to apply it to this example and see what you get. We can tally notes later. Okay. So, before I get to actually talking about how we compute an optimal solution for this example, and also in general, I want to suggest an approach and I want you to think about whether it will work. Remember, I said that minimum spanning trees are reminiscent of shortest paths in the sense that shortest paths intuitively take us from one place to another as quickly as possible.\nSo, why not just start at one of our favorite houses, and just compute the shortest paths to every other vertex. Now perhaps this can be used as a spanning tree. Well, it is going to be a valid spanning tree for sure because you are going to find paths to every other vertex. And this collection of paths can be shown to be acyclic. But on the other hand, the thing to really think about is, does this have the smallest possible cost among all spanning trees?\nIt is fairly easy to come up with examples where starting from a particular house may just be a bad idea. But we can improve on this idea a little bit, we can say, well, let us just try stopping from every possible house, just like we did for APSP. Our first approach for APSP was to run SSSP on every vertex. So, let us just try and do that. For every vertex in the graph, we figured out the shortest path tree, which is just computing the shortest paths to every other vertex.\nAnd then we take the one that is the best among all of these ‘n’ options. Would this work? Just think about whether this would make sense. I think it is a really instructive exercise to play around with some examples. And I think this really emphasizes the distinction between the goals of shortest paths versus spanning trees. Although at some level, they are similar in the sense that you are trying to optimize for somehow some sort of reachability.\nBut the style in which you are optimizing for reachability is relatively local in SSSP, and somewhat more global in MST. And this really does make a difference. So, feel free to pause here and see if you can figure out this puzzle. And when you come back, we will talk about it more. So, since I have been talking about the contrast between these two problems, the answer should come as no surprise to you. Just trying SSSP from every vertex will not solve the MST problem for you.\n(Refer Slide Time: 08:59)\n  \nLet us take a look at this example. So, what we have here is a complete graph on five vertices. The red edges on your screen have a weight of 1.5, while the black edges have a weight of 1. If you think about a solution to the minimum spanning tree problem on this graph, then you can probably predict that any minimum spanning tree actually looks like a path on this outer rim. It just leaves out one edge and takes on all the rest. This is the best that you can hope for.\nOn the other hand, if you were to start off an exploration based on, say, Dijkstra to perform SSSP from any vertex, so let us pick the one on the top here, for instance, highlighted in blue. Think about what would Dijkstra do here? Well, you are going to get the two neighbors first, for sure. That is the best way of getting to those. But for the two vertices that are at the bottom, the best way to get to them is not via the outer rim. It is actually via the direct edge.\nSo, your shortest-path tree will look something like this, and that is going to be the same story no matter which vertex you start from. So, hopefully, this example illustrates the key difference between our goals with a single-source shortest path versus a minimum spanning tree. So, as you can imagine, MSTs will require a slightly different approach. Although one of the popular ways of finding MST, which is via Prim’s algorithm, feels a lot like Dijkstra.\nSo, it is a common question as to whether they are really different. And I wanted to get that out of the way up front by concretely showing you that it is indeed a slightly different problem. Now, before talking specifically about either Prim’s algorithm or Kruskal’s algorithm, I want to make some comments about a generic MST algorithm.\n(Refer Slide Time: 10:44 & 11:06)\n \nIt turns out that most algorithms can be fit into this framework in some form or fashion. So, it is just a useful way to think about MST approaches. So, what you typically want to do is grow a minimum spanning tree by iteratively building it out of a spanning forest of some sort.\nSo, what is a spanning forest of a graph? Well, the vertex set of a spanning forest is the entire vertex set of the base graph that you are working with. But the edge set is essentially some acyclic subset of edges. There is no requirement that these edges should form a connected subgraph. That is what makes a spanning forest different from a spanning tree. So, you think of it as a collection of trees on the vertex set of G.\nAnd some of these trees could be trivial. In particular, they could be isolated vertices. In fact, most algorithms would start with a spanning forest, which is simply all the isolated vertices in graph G. Now, of course, not every algorithm starts here. So, for instance, you could quite naturally think about your starting point as the entire graph G, all the vertices, and all the edges. And then you could try to erase edges away until you are actually left with a spanning tree.\nBut the approach that we are going to be talking about will be building up to a solution as opposed to chipping away at the whole graph till you are left with something minimal. So, as I said, our generic view is that we are trying to iteratively build up a spanning forest till it evolves and matures to being a single spanning tree.\n(Refer Slide Time: 12:22, 12:41 & 12:54)\n  \nHere is what a typical spanning forest may look like at some intermediate stage of your algorithm. Now, at this point, what we want to say for correctness eventually, is that these intermediate spanning forests that we are building are some partial realizations of an optimal solution that exists somewhere.\nThis is what you would need to prove to show the correctness of your algorithm. And while we would not be getting into the proof, let me introduce some terminology that may help you think about how such a proof would go.\nSo, first, when you have a spanning forest, let us classify the edges into a couple of useful categories. The first one is the category of useless edges.\n(Refer Slide Time: 13:05, 13:28 & 13:54)\n  \nThese are edges that have both of their endpoints in the same tree of the spanning forest. Notice that such edges will induce cycles, and therefore we are never going to add them to our solution if we are committed to extending the solution that we have built up so far. So, the nomenclature of calling such edges useless is actually quite appropriate.\nOn the other hand, we talk about an edge being safe for a particular component if it is the cheapest edge among all the edges that have exactly one endpoint in that component. We do want to talk about uniquely identifying the cheapest edges. So, if there are multiple cheapest edges that are getting out of a component, then we will have some previously agreed upon tie braking mechanism.\nSo, again, let us look at our spanning forest here. Let us identify a component as an example. Let us work with this one. And let us say these are all the edges that are coming out of this component. They have one endpoint inside the component and the other endpoint outside. And let us say that the cheapest edge that comes out of this component happens to be this one. Then this is the edge that we will label as being the safe edge for this component.\nNow, one thing to observe is that the same blue edge may not be the safe edge for the other component that it is incident to. So, this yellow component here may have a different safe edge going out of it to some other component. But notice that once you do collect all the safe edges incident on all the components, then they must together be acyclic. Imagine that you do have a cycle among the safe edges.\nJust start traveling on this cycle. You will notice that you must experience that the weights in fact decrease as you go along. So, you will get a contradiction by the time you hit the end of the cycle. So, just think about this a bit. And I just want you to preserve this intuition that all the safe edges at any stage of your algorithm must, in fact, be acyclic. And in fact, you can show which we will come to in a moment that these safe edges are called safe because they actually do belong to an optimal MST. So, you can pick them without thinking.\n(Refer Slide Time: 15:22 & 15:36)\n \nBut before we get to that, let us also label all the remaining edges as undecided. So, you could have edges that are neither useless nor safe. So, these are edges about which we do not know much, and we will just call them undecided.\nSo, the key to the mechanics of most algorithms is the (following) fact that there is going to be an optimal solution, which does not contain any (of the) useless edges and contains every safe edge at every iteration of your algorithm. As I said, one intuitive thing to appreciate is that adding the safe edges will not violate the structure of the subgraph that you are looking for – the safe edges are already acyclic. But it does require proof that these are the best edges for your solution in terms of the cost.\nIn fact, what we are doing here has a really strong greedy vibe to it. We are seemingly focusing on edges that are locally the cheapest with respect to a component. And it is not obvious at all, that this would be the right thing to do long term. But it turns out that it is and once you know the correctness of the statement, then an algorithm, in fact, naturally suggests itself. Right. What you could do is start with all the isolated vertices, identify all the safe edges. This just amounts to going to every vertex and asking who is the neighbor that is the closest to you.\nAnd once you have the answer to all of these questions, then you (just) have identified all the safe edges so you can freely add them to your solution. If at this point your graph becomes connected, that is fantastic. If not, and it may not be in fact. You can think of examples where you do this once, and you could be left with a graph that has as many as n by 2 components, for instance. So, your graph may not be connected.\nBut you could just repeat this process. You go to every component, and you ask, what is the cheapest edge that is incident on you? Again, having identified the safe edges, just add them to the solution. And repeat this until your graph in fact becomes connected. You can show that in every step, the number of components will in fact go down by half. So, the number of iterations that you have to repeat this process for is in fact only logarithmic in the number of vertices. You do have to think about the cost of identifying the cheapest edges that go out of components.\nAnd this is actually a good exercise to go through and this is a perfectly valid MST algorithm. It is a little bit different from the ones that we are going to discuss. But it is very natural from the observations that we have set up so far. So, I just wanted to point it out to you as a fun thing to think about. The more traditional approaches which are Prim’s algorithm and Kruskal’s algorithm are the ones that we are going to discuss in the next two segments. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/Lec23.html",
    "href": "materials/cpnotes/Lec23.html",
    "title": "Disjoint Set Union - Module 3 (War-III)",
    "section": "",
    "text": "Lecture - 23\nDisjoint Set Union - Module 3 (War-III)\nWelcome back to the last segment of the final module in week four. If you remember, we have been discussing the problem ‘War.’ I should point out that this video is the last in a series of three videos. In the first one, we introduced the problem statement. In the second one, we described a solution.\nIn this short wrap-up video, I am going to show you some snippets from an implementation of the solution that we discussed in the previous video. I would not expect this to make any sense if you have not seen the previous two videos. Please make sure that you have watched those first. Our implementation is going to be in C++ because we will want to just build on the unionFind class that we described in the first module.\nBut it should be pretty straightforward to translate this into your favorite programming language. If you do end up doing that, please do submit a pull request to the official repository as always. We look forward to receiving your submissions. With that said, let us proceed to the implementation.\n(Refer Slide Time 01:04)\n\nI am just going to begin by looking at what the unionFind class looks like. We have just essentially introduced a public entity called ‘enemies.’ This is to keep track of the enemy pointers on the leader elements. The rank and friends are the usual things from the default DSU data structure. So, ‘friends’ is just a renaming of the parent array. I think we have been using P to denote the patent pointers previously.\nNow I have just renamed that to ‘friends,’ just to remember that we are keeping track of the friendship relationship using these pointers. The initialization is pretty straightforward for friends and rank as before. In fact, in the problem statement as well, you will see that it is been made explicit that everybody is a friend of themselves, and nobody is their own enemy. The friends are singleton sets, to begin with. That is our standard initialization.\nFor ‘enemies,’ we just want to basically say that we are starting off with a blank slate and there are no recorded rivalries right in the beginning. We just follow the convention that we are going to use a value of -1 to designate that this person has no known enemies at the moment. That is a simple initialization. In this problem, the N people are in fact indexed from 0 to n-1.\nIn the previous module, I have been saying that I would like to initialize unionFind with N+1 because, for example, in destroying array, the elements were indexed from 1 to N. But here, you can just do standard instantiation with just n and your indices will work out fine. It is quite peaceful, actually.\n(Refer Slide Time 02:58)\n \nLet me just begin by also introducing these two new methods in this class. We have areFriends and areEnemies. You will notice that areFriends behaves very much like isSame set. You just check if the leaders are the same, and you return an appropriate value. As far as enemies, here what we want to do is check if the leaders are enemies of each other. If that happens to be the case, then we return yes, and otherwise, we return no. This is exactly as we discussed. These are two really simple helper functions to write and get out of the way.\nThe crux of the matter is really in figuring out the MAKE FRIENDS operation. Again, I am not showing you the parts of the code where we take in the input and do the case analysis and all that. That is fairly straightforward. In any case, you can always look up the full code from the repository. I am just going to show you some relevant snippets corresponding to the cases that we discussed.\nEven here for MAKE FRIENDS, I have not shown you, at least not on the screen right now, the case where we handle the contradiction. The very first thing to do is check if the input to MAKE FRIENDS, which in this case is x and y, you want to check if they are enemies. If that actually returns yes, then you want to output -1 and just break out of this case altogether. That is a sanity check that you do need to do upfront.\nOnce you are out of that situation, essentially you replace the people x and y with the corresponding leader elements. The first case, which was the simplest one was a situation where x and y have no known enemies to speak of. If the enemy array is -1 at both these indices, then we just do a simple union and that takes care of the situation completely.\n(Refer Slide Time 04:51)\n\nBut now we have a situation where one of the leaders has an enemy and the other one does not. In this case, remember what we said is that you can infer a new enmity, right. So x and y are about to become friends. Let us say x has a known enemy, then that known enemy also becomes an enemy of y. But the way that this plays out in the data structure, the way we are maintaining things is that you go ahead and you do the merger between the clusters of x and y.\nWhat happens now is that it is possible that y may have taken over as the leader, in which case, you need to make sure that the ‘enemies’ array is appropriately updated. That is exactly what is happening here. First, you identify the enemy of x. Then you merge the sets that x and y are currently representing. Now just for the record, you look up the representative of this merged set, and you make sure that this representative becomes enemies with the set.\nIt is possible that nothing changes in the enemies array because possibly x is also the new representative, but just in case y has taken over. This ensures that the enemy is array is properly updated. Now I am going to skip case 2B, which is the exact symmetric situation where y has an enemy but x does not. It is essentially the same logic. But with, of course, the variables appropriately swapped.\n(Refer Slide Time 06:20)\n\nThe final case was when x and y both have enemies. Remember that in this case, we said that the sets that contain these two enemies can also be merged because these two enemies can now be inferred to be friends between them. Let us say that ‘a’ is the enemy of x, and ‘b’ is the enemy of y. We merge x and y, because that is what we had set out to do anyway. But by inference, we also merge the sets that are being represented by ‘a’ and ‘b.’\nNow what we have to do is, once again, make sure that our enemy pointers are appropriately updated. We have these two merged clusters. We identify the potentially ‘new leaders’ of these clusters. Then we make sure that we put their enmity on the record. That takes care of all the scenarios that could arise with MAKE FRIENDS. It is similar to MAKE ENEMIES, although the details are slightly different.\nI think the most non-trivial case for MAKE ENEMIES was again the case when both of the people who are involved, both of the leaders, have enemies of their own. Let me just show you that one case. Remember that this is unlike in many of the other videos; this is not a line-by-line breakdown of the entire code. I am just showing you the parts that I think are the most interesting and non-trivial.\nI hope that what you will be able to do from here is to actually write out all the cases by yourself. Of course, if you do need to look at the entire code, you could always take a look at the repository, which is linked to in the description of this video as well. Let us wrap this up with a look at the last case for the MAKE ENEMIES operation which I think is the one where there is the most going on.\n(Refer Slide Time 08:00)\n\nLet us say that you are supposed to be making enemies of x and y. Let us say that they have enemies of their own, which are denoted by ‘a’ and ‘b’ respectively. Let us say x has a known enemy, in ‘a’ and y has a known enemy in ‘b.’ If you go back and think about how we dealt with this case previously.\n(Refer Slide Time 08:23)\n\nWe said that, well when that happens, so x and y are the two people on the top and a and b are the two people on the bottom. Then we said that, we need to make friends between, let us say x and b and y and ‘a’ because those are the additional friendships that we were able to infer by the common enemy rule. That is exactly what we do in court.\nWe say that, well, if ‘a’ was an enemy of x, then ‘a’ and y have a common enemy in x after you establish the enmity between x and y, which is what you have set out to do. Because ‘a’ and y have a common enemy, we are going to go ahead and merge the sets that ‘a’ and y belong to. For a very similar reason, we are going to merge the sets that b and x belong to. After these merges have been established, we still need to make sure that these big merged sets are actually enemies with each other as well.\nLet us make sure that we pull out the leaders of these newly created sets and establish the enmity between them. That is exactly what is happening in the last four lines of this code snippet. Of course, you do have a few other cases to deal with for the MAKE ENEMIES relationship as well.\nWhen you have one of the leaders having an enemy, the other one not having an enemy, and the even easier cases, when neither of them has a known enemy, in which case it is just two lines to update the respective enemy pointers. Even before that, do not forget to check for a contradiction before you get into any of these cases at all. If x and y are already friends, then you just output -1 and break out of this case.\nAgain, there needs to be a little bit of a wrapper to make sure that you get into the right cases in the right situations based on what the input looks like. You can go and look at the problem statement to make sure that you have the right formatting in terms of input and output. But at this point, I think you hopefully have enough information to piece together your own version of this solution.\nAs I have said before, this is by no means the only approach to this problem, but I found this way of solving it to be fairly natural, and actually quite elegant, really, once you have an understanding of all the possible scenarios that emerge. I do hope that you enjoyed this as much as I did. I will say that this is probably one of the more challenging problems that we have seen so far in this course. If it takes you a while to sort of really absorb all the cases and what is going on, then do take your time.\nI think this problem does require a little bit of patience. But I think it is well worth it in the end. Do let us know how it goes. Please drop in a comment, if you have any questions or any suggestions, and we look forward to hearing from you. With that, it is a wrap for week four. I hope you enjoyed this little excursion through all the ways in which disjoint sets turn out to be useful. As I said, we will probably keep encountering this data structure.\nIt is something that also shows up, as I have mentioned earlier, in more advanced problems as something that is a piece of a bigger puzzle. I think this little bit of practice really is going to be handy. Fortunately, there are a lot of really great resources for learning more about the disjoint set union or unionFind or disjoint sets or whatever you want to call it. If you are interested in the theoretical aspects, you will find a link to a really wonderful book chapter in the description of the first module, or on the course website.\nThat is a great resource for learning more about why path compression works out so well, and so on. If you just want to try more practice problems then the code forces education segment on disjoint set union is a great place to start. They have tons of problems in increasing order of difficulty, roughly speaking, and they also have some great video materials.\nIf you really want to dig deeper, there are a bunch of resources and we will link to some of them in the description of this video. I really hope that you have fun exploring and I hope that you do actually get to use this in a contest that you participate in, in the future. As always, have fun, and please keep the conversation going on Discord and on the mailing list and I will see you back next week!"
  },
  {
    "objectID": "materials/cpnotes/W01/Lec00.html",
    "href": "materials/cpnotes/W01/Lec00.html",
    "title": "Welcome and Initial Setup",
    "section": "",
    "text": "Lecture - 00\nWelcome and Initial Setup\n(Refer Slide Time: 00:11)\n\nHi, welcome to the NPTEL course on getting started with Competitive Programming. This is the first week of the course, and this is the very first video. So, let me take this opportunity to welcome you to the course and to say thank you for joining us. This should be an exciting journey through a variety of contest problems as we go along.\nThe first week focuses on problems whose solutions are based on AdHoc methods or their direct implementation problems. It is to say that specifically, you do not need any background and algorithms to be able to tackle these problems. The intention of doing this was to give ourselves some time just to get set up to get used to the modalities of the course and basically have some fun.\nIn this lecture, we will not be solving any specific problems. But we will be addressing some of the most frequent questions that came up in the Discord community, launched for this course a couple of weeks ago. In case you missed the announcement, there is a link to the Discord community in the description of this video. It is an invite link, which you can click to join the community.\nSo, if you have not done so already, please do that. There is an introductions channel, and we would love it if you could just introduce yourself in that channel and meet your fellow learners in this course by doing that. There is also a channel for general questions. So, any questions that are related to the course at large, please feel free to post them there. We also have a channel for every week.\nI will request you to post any questions that you have related to the materials that we are covering in the relevant weekly channel. This will allow us to streamline our attention as we try to go through the posts on Discord. So, I hope to see you there, would look forward to it. In the meantime, let me just make a list of the questions that have been coming up. This will also be one way of getting you introduced to the general format of the course. So, let us go ahead and talk about some of these questions.\n(Refer Slide Time: 02:37)\n\nAlright, so I list the questions first all at once, and then we will try to tackle them one by one. By far, the most popular questions that we got were related to the choices of programming languages. For example, what languages are we using? What languages do we recommend for you to be using and so on? We also had a lot of questions about the pre-requisites, like, what do we expect you to already know before starting the course? I will also talk a little bit about the contest platforms that we will be using, as well as the format of the assignments and the exams.\nOkay, the first question is: What programming language are we using in the lectures? The answer to this is C++ and Python. Depending on the problem, we will be describing the solution that is written in one of these two languages. To the extent possible, we will try to provide you with sample solutions in both languages for most problems.\nBut whenever this is not possible, it is usually not that hard to translate the main idea of the solution from one language to another. In fact, I would say that it is probably a good exercise. You can always access the code that we show you in the lectures on a GitHub repository, and there will be a link to the sample solutions in the description of each video.\nHopefully, everything is going to be fairly easy for you to find, as we go along. I would not recommend actually looking up these solutions first. But just keep it as a backup reference and try coding things yourself. In fact, even before we get into the implementation segment in any video, I would strongly recommend just pausing the video and trying to implement the solution yourself and coming back only if you are stuck. Often, we will try to cover the most common mistakes that are bound to happen while coding up a particular kind of solution. So, we hope that you find that helpful.\nThe second question is: What programming language should you use for this course? My answer to that would be whatever programming language you are already comfortable with should be great. On the NPTEL platform, we will have some programming assignments and solutions to those that can be uploaded in C, C++, Java, or Python. As long as you are familiar with one of these languages, that should be enough for our official assignments.\nBut you are probably going to be doing a lot of programming outside of the NPTEL assignments. You will be participating in contests on platforms like CodeChef, Code forces, Google Code Jam, and so on. Most of these platforms do support the languages that I have just mentioned and many more.\nMany of these platforms will even give you extra time for Python submissions, just to compensate for the fact that it can be slower. Of course, not all platforms do this. So, you have to be careful about checking if this is important to you. Specifically, can you get away with just knowing Python? For competitive programming, I think absolutely, yes. A lot of contest programmers have gone quite some distance using languages like Python and other non-mainstream languages. So, the choice of language should not really be a hurdle here.\nI think working with something that you are comfortable with is already a bigger advantage than any other gains that you might make when you are simultaneously trying to learn the syntax of the language as well as the other algorithmic aspects of the problem that you are trying to solve.\nOf course, if you want to use this course as an excuse to pick up a new language and if that language happens to be C++, by all means, it is definitely a great choice. But just be mindful of the fact that it is going to be some more work. If you are not familiar with any programming language at all and you have to pick one, then C++ and Python seem to be the most natural choices, and they both have their own advantages.\nIf you plan to be serious about competitive programming and pursue it long-term, then making the investment in learning C++ is probably a good idea. On the other hand, if you just want to get up and running quickly, then Python may be the better choice because it is generally a friendlier language and is easier to pick up, to begin with.\nI should say though that in this course, we do assume familiarity with some programming language. This is not a programming languages course. So, it does not matter which language you know, but as long as there is some language that you are comfortable coding in, I think that would be very helpful. If this is your first time actually coding, then you might find that this course is a little more challenging for you, than at least we intended for it to be. So, feel free to come back to it after completing the first course in programming.\nThe third question is: Do we have a specific recommendation for an integrated development environment (IDE)? Most people who code like to use an editor that is designed for programmers with, at least, the basic features like syntax highlighting, quick access to compilation, and other tasks that you expect to do frequently.\nSo, I definitely recommend the use of some specialized editor. It does not matter which one, if there is one that you are using, that you are already comfortable with, I see no compelling reason to switch. This is largely a matter of personal taste and there are definitely a lot of different options. But I do recommend using one, it could be anyone. If you are coding in, say something like Notepad, then I think you will find this to be a very significant upgrade. The good thing is that there are lots of choices ranging from traditional choices like vi and Emacs, all the way to more contemporary options like VS Code and Sublime Text, Atom, and so on.\nOne good thing about all of these options is that they are cross-platform and are typically available on the most popular operating systems. So, you should have no trouble finding and downloading the software. They are also supported by really large and passionate communities. So, if you are stuck with something, it will usually be easy to find help.\nIf you are just getting started and you are overwhelmed by all these options, I would recommend downloading something like VS Code and just getting started for the reason that it is, it is a very user-friendly choice. It is easy to get started with but at the same time, it is quite powerful, and you can discover its features as you go along, instead of being overwhelmed right at the start. So, enjoy getting set up. I think this is a useful thing to invest a little bit of time in initially. Hopefully, you can set something up that works really well for you.\nThe next question is: Do we need to know basic algorithms before starting this course? The short answer to this is, yes, this would definitely be ideal. The reason for this is that every video in this course is going to focus completely on solving a contest problem, and we will not really be covering algorithms separately. But at the same time, we will be using many of these algorithms that you would learn typically in an algorithms course, say algorithms like BFS, DFS, minimum spanning trees, shortest paths or network flows, these are all going to come up as solution strategies.\nWe will be mostly focused on why these solutions actually work in the context of a problem. So, once again, we will not be proving why Prim’s algorithm actually outputs a minimum spanning tree. But our focus will be on arguing why a minimum spanning tree is the thing that you are looking for in the context of some problem.\nAlright, the next question is: What contest platforms we will be using? In the lectures, we will be featuring problems from a number of different platforms, including Google Code Jam, CodeChef, Codeforces, AtCoder, and the UVA database of problems. You will find links to all of these platforms in the description of this video. I would suggest spending some time right now just setting up your accounts on all of them and familiarizing yourself a little bit with the layouts of these websites. So, you should know where the active contests are where you can find the editorials, where you can submit your code, where are the contest archives, and things like that. I think this will be useful as you go along.\nThe final question: What is the format of the assignments and exams? Every week, we will have assignments that are in the form of multiple-choice questions, usually based on some contest problems. The questions will address various aspects of the problem, including observations that could lead you to a solution, discussions of possible solution strategies, what are their running times going to be, are these running times good enough for these input limits, and questions of that sort. There will also be programming assignments on the NPTEL platform for most weeks, and we will let you know just in case there are weeks where we do not have programming assignments.\nApart from these programming assignments, I would definitely encourage you to keep solving contest problems on other platforms outside of NPTEL and get as much practice as you can. For this, we will have some recommended problems every week to try out based on that week’s theme. These are completely optional and we will have no way to track them. But I hope that you will be able to make time for them because the more you practice, the better you are going to get at this.\nAs for the exams, we will only have multiple choice questions or short answer questions, questions with numeric answers. None of these questions will require you to write a program to be able to answer them. At best, you may need to do some computations that can be done by a calculator which would be provided. So, there are no programming-based exams for this edition of the course. If you have been comfortable with the assignment problems, then the exams will have questions in a similar format and in a similar spirit.\nSo, I hope that all this information helps you prepare well for this course. But in any case, if you have any questions that remain, please do post them on Discord, and as I said earlier, do introduce yourself. I am looking forward to seeing you in the rest of the videos for week one. Thanks so much for watching and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W03/Lec12.html",
    "href": "materials/cpnotes/W03/Lec12.html",
    "title": "M 3 (Stable Marriage-II)",
    "section": "",
    "text": "Lecture - 12\nGreedy Algorithms - Module 3 (Stable Marriage-II)\n(Refer Slide Time: 00:11)\n\nHello, and welcome to this short follow-up video where we discuss the implementation for the ‘Stable Marriage’ problem that we discussed in the previous video. As I mentioned there, this problem is available both in the ICBC Regional Archives as well as the CodeChef problem archive. The code that I am going to share with you right now is tested on the CodeChef platform.\nIf you want to run it on the ICPC platform instead, just make sure that you have appropriately adjusted for proper input-output. Make sure to double-check all the details at least once. With that said, let us get started. Our code for this problem is going to be in C++.\n(Refer Slide Time: 00:49)\n\nAs usual, to begin with, we have the usual reading of input. We want to have 2N vectors to store the 2N rankings that have been given to us. The rankings are given as space-separated integers. The ‘men’ and the ‘women’ are represented as integers between 1 and N. The only little annoying detail to keep in mind is that the lines that give you the preferences begin with a number denoting whose preference it is.\nThe first line is the first women’s preference, and it starts with a ‘1’ and is then followed by N integers between 1 to N in some order, which gives you the actual ranking. You have to remember to ignore this leading number. If you forget to do that, your algorithm is going to be all messed up. It is a very tiny detail, but just useful to note. That is why you have the stand-alone ‘cin’ person outside of the ‘for’ loop, which takes this input and does not really do anything with it. Then you read the rest of it into a vector.\nWe have a collection of N vectors for the N women and a different collection of N vectors for the N men. You will notice that I am also reversing these rankings so that I have the top preferences at the end of the array. This just makes it easy for me to access the top choice that these people have because that is something that we will need to do frequently. But you can absolutely do this also without reversing the list. It would really be the same thing. It is a matter of minor details.\nAll the heavy lifting is done in this ‘solve’ function. Let us go and try to understand what is happening in solve. It is going to use a few helper functions whose objectives will be self-explanatory. I will show you the helper functions at the very end, but I will show you the main function, the main solve function, to begin with.\n(Refer Slide Time: 02:44)\n\nHere, we are going to maintain a list of engagements in the arrays or the vectors WE and ME. So, WE[i] is going to store the current partner of the (i+1)th woman, and ME[i] stores the current partner of the (i+1)th man. The reason this is off by 1 is because the men and the women in the problem statement are denoted as numbers between 1 and N whereas these arrays are indexed from 0 to N minus 1. That is why the offset. Just keep in mind that this is what is happening.\nTo begin with, if you remember also from the pseudocode, everybody is free. There are no engagements. Nobody is matched to anybody. We will use -1 to denote that somebody is currently single. The initialization is clearly that everybody is single. That is what is happening here.\n(Refer Slide Time: 03:39)\n\nNow, we turn to the main logic of actually creating the matching. The first thing we said was that as long as there is a single man left, who still has to propose to somebody, we are going to go ahead and actually execute that proposal. We have this helper function, which tells us if there are any single people remaining, and you could examine either of the arrays because WE and ME are symmetric in reflecting the matched state of all the people involved.\nWe could pass either of them to the ‘singlesRemaining’ helper function. This helper function will return true if there is at least 1 person who is still single at this point and will return false otherwise. Hopefully, this ‘while’ statement makes sense. If there is at least 1 person remaining, who is single, we enter the loop. Then we go over the list of all men. In particular, we focus on those men who are currently single. That is the ‘for’ loop under ‘if’ block here.\nIf we have a man who is single, so if ME[i] is -1, which is to say that the (i+1)th man is currently single, then we want this man to propose to the woman who is currently at the top of his list. That just essentially amounts to pulling back the last element of the array. Because remember, we said that we have reversed the preference list. The top element is really at the bottom of the array, or it is the last element of the array.\nThat is what I am pulling in here and we have a -1 to adjust for the indexing. This is the correct index to refer to in the arrays that we are storing. Of course, what is being stored, is the number or the identity of the woman that this person likes the most currently. We remove this element from M[i]’s vector as well because we will have no need for it later. Remember that you always go further down in your preference list, and you never look back.\nThis is just all about identifying the person that the (i+1)th man will propose to now. Once we are done with this, we actually try and look at what happens when the proposal is made. Here, we have to look at what is going on with the woman that we are now calling ‘top.’ For this woman, we have to distinguish between the cases of whether she is currently single or engaged. Let us do the easy case first.\nIf this woman is currently single, then we go ahead and make the match. There is nothing else that needs to be done. The match can be immediately made. On the other hand, if the woman is currently engaged, then we have to compare the person that she is engaged to with the person who is making the proposal. Let us store in the variable ‘competitor,’ the current match of this woman, and now what we have to do is compare the competitor with the man ‘i+1.’\nWe have another helper function ‘getRank,’ which tells us how the competitor is ranked, and how the current man is ranked. Remember all of these +1s and -1s are just adjusting for the indexing. If you read it carefully, you will see that all of it is consistent. We use the getRank function to retrieve the ranks of these two candidates in the preference list of the woman who is denoted by the variable top and we compare these two ranks.\nRemember that smaller ranks are going to be better. That is how the helper function is set up. If the man ‘i+1’ has a lower rank, then that means that the current engagement needs to be broken, and the previous person that ‘top’ was engaged to, we need to signify that he is back in the single spool of men. We make sure to set the competitors index in the ME array to -1 and we also make sure that man ‘i+1’ is matched with top. That is going to happen with this match helper function. So, that is essentially the heart of the algorithm.\nThat is all the business that we need to do. We check if the woman who is at the top of the (i+1)th man’s preference list is single or not. If she is single, we make the match immediately. If she is not single, then we compare the new match with the old one. If the new match is better then we break off the old engagement and make the new match. Otherwise, we do nothing, and the man who was making the proposal continues to remain single. We just walk out of the ‘else’ block without any work being done in that case. That is the entire algorithm more or less. The only thing left is to show you how the helper functions work.\n(Refer Slide Time: 08:26)\n\nAll of these helper functions are fairly standard. What getRank will do is, it will try to return the rank of the person in a given list. The reason we have N minus here is that we had reversed the list, to begin with. If you did not reverse the list, then you do not need to do this N minus calculation here. You can just directly return the location of the person in the list.\nNow, the way the ‘find’ function works is that it actually gives you an index and memory. You need to adjust that to get the actual rank. You could also use something like distance to figure out the rank. You can have your own version of the getRank function, depending on which built-in functions you use, and whether you reversed the list in the beginning or not. Your version may vary a little bit from what we have here.\nJust make sure that the way you index things — the way you number of things — is consistent between all the functions that you write. The singlesRemaining function is also really simple. It just boils down to identifying if the input array has a -1 or not. All we are doing here is just checking if there is an occurrence of -1 or not. If there is no occurrence of -1, we return false, otherwise, we return true.\nThe exact conditional and this ‘if’ statement here is basically based on the documentation for the find functions. If the ‘find’ function returns an index, which is just after the last location of the array, that is the signal, that the thing that you were looking for was not found. That is what we have here. I am sure there are many other ways of writing this as well. Take your pick. Essentially, the logic that you need to implement is to return false if -1 was not found in the array. Any way you have of doing that should be just fine.\nThe match function essentially updates the ‘engagements’ array to reflect that a particular man got matched with a particular woman. This is really simple. You need to go to the wth index in the women’s engagement array, and make sure that it is updated to ‘m.’ You need to go to the mth index in the men’s engagement array and make sure that it is updated to ‘w.’\nAgain, you could make a choice here about whether you want to reflect the true identity of the person, or do you want to use the index that you are going to be using, which is going to be essentially the identity -1. Whatever you do is fine, as long as you are consistent in your code and how you use it. I have tried to be careful here, and I think everything here is reasonably robust. As usual, you can find the entire code here in the GitHub repository.\nIf you have any feedback, then that would be absolutely very welcome. Also, if you manage to write this in a different language, please do submit a pull request so that we can add it to the official repository. With that, we come to the conclusion of the ‘Stable Marriage’ problem. I think I should quickly mention that the one thing I have not shown you on the slides is the output statement.\nIf you are just working from the video, and you try to imitate all of this code, please do not forget to write your final output statement where you output the stable matching that you found. I think we are done here. Let us call this a wrap. We have one more module left, which is going to be an interesting one because we will not really discuss any more problems.\nWe will, in fact, look at problems for which greedy strategies actually fail. Hopefully, that will serve as a useful warning for us to keep in mind when we are applying this very powerful but also very slippery sort of paradigm in contest programming. So, I will see you there. Thanks for watching and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W03/Lec13.html",
    "href": "materials/cpnotes/W03/Lec13.html",
    "title": "M 4 (When Greedy Does Not Work - Coin Change)",
    "section": "",
    "text": "Lecture - 13\nGreedy Algorithms - Module 4 (When Greedy Does Not Work - Coin Change)\n(Refer Slide Time: 00:11)\n \nHello, and welcome to the final module in the third week of ‘Getting Started with Competitive Programming.’ This video is going to be slightly unusual in the sense that we will not be solving any specific contest problems as we normally do. Instead, we will just take a look at a few examples of situations where the natural greedy strategies that you might come up with for those situations actually end up not working.\nThis is just to really emphasize the point that a ‘Greedy Algorithm’ might look like a very tempting proposition, but it may in fact be wrong. Let us go through a few of these scenarios. There will be no real coding involved in any of these. Hopefully, in due course, we will be able to discover more sophisticated strategies, which would actually help you tackle the sort of problems that we will be talking about in this particular lecture.\nIn terms of logistics, this module is broken up into three shorter videos — each one featuring one example of a problem or a situation where there is a natural greedy strategy, and we will see that it does not work. In some sense, there is no suspense, you already know that the strategy is bound to fail. But I hope that you will still take your time to pause the video, and think about coming up with a counter-example yourself before it is revealed in the lecture.\nWith that said, let us get started here with our very first example, which is a pretty popular one. You may have seen it before. This is called the ‘Coin Change’ problem.\nHere, essentially, imagine that you are trying to get some change for, say, 100 rupees, and you are at a cash counter. The cashier is trying to figure out how to generate 100 rupees from the notes that he or she has at his or her disposal at that time. It could be that you get two 50s, or you get three 20s and four 10s, or you get ten 10s or some such combination.\nThe optimization objective here is usually that you want to minimize the number of notes that are generated. You usually assume that you have an unlimited supply of notes in each specific denomination. A specific version of this problem did show up once on ‘Codeforces.’\n(Refer Slide Time: 02:29)\n\nThis was problem A in Round number 492 in the Second Division. Let us just go over this problem statement here. You want to generate n dollars using bills of denominations 1, 5, 10, 20, and 100. The optimization objective is to minimize the number of bills that you use. It turns out that, here, the natural greedy strategy that you can think of actually does work. You might be thinking that there was a whole lot of false advertising at the start when I said, we would not be solving any contest problems and we will be looking at examples where ‘greedy’ does not work.\nBut it turns out that the reason ‘greedy’ works in this setting is because of a very special property of the denominations. In fact, we will see that once you do not have this special property, ‘greedy’ will no longer work. The reason I picked this as the opening example, is to show you how close you can come to a situation where ‘greedy’ does work for some specific variant if you have some extra special properties. But the moment you drop those structural assumptions, then ‘greedy’ ceases to work. All the more reason to be super careful.\nI just wanted to draw up that contrast, which is why we are starting with this warm-up variant, where greedy does, in fact, work. Just to give you a sense of how to convince yourself that the greedy algorithm is correct, we will go over at least some hints for the proof of the correctness of the greedy algorithm in this setting. We will also try to tease out what is the important property that these denominations have that ensures that the greedy algorithm does work. Before we get to all that: What is the natural greedy algorithm?\nIf it is not clear already, then please take a minute here to pause the video and think about how you would come up with a greedy strategy to solve this problem. The natural greedy thing to do would probably be to use the largest bill that you can possibly use to knock out as much of your remaining task as possible. Remember, you are trying to generate ‘n’ dollars.\nFor instance, if ‘n’ is greater than 100, then I will probably reach out to 100 dollar bill first because that gives me the maximum leverage. It is only when the remaining amount that I have to generate falls below 100 that I will stop using the 100 dollar bills and turn to the next largest denomination that I can use, and so on and so forth.\n(Refer Slide Time: 05:03)\n\nLet us write out the overall strategy. You want to pick the largest denomination of coin, which is not greater than the remaining amount to be made at every stage of this algorithm. You stop once you have generated the entire amount that you were supposed to generate. Let us see how this plays out in a few examples.\n(Refer Slide Time: 05:21)\n\nRemember that the denominations are 1, 5, 10, 20, and 100. Suppose we want to generate 125. Then the first bill I would pick is a 100 dollar bill because 125 is greater than 100. Now since I have accounted for 100, I am left with 25. I can no longer use 100 dollar bill; I would have to use a 20 dollar bill. Once we have done that, we still have to generate 5 dollars more, and there is a 5 dollar bill so we will use that. You could confirm that there is no way of generating 125 using only two distinct bills of the given denominations. Suppose you want to generate 43, then the largest bill that you can use is 20 because 43 is less than 100. Let us throw in a 20 dollar bill to the mix. Now you are left with 23.\nAgain, you can pack in a 20 dollar bill. Now you are left with 3. You cannot use a 20 dollar bill or a 10 dollar bill or even a 5 dollar bill to generate 3 dollars. The only thing to do here is to use 3 one-dollar bills. That is the only valid thing to do at this point. Once again, take a moment here, just play around and see if you can do this with less than 5 bills for the amount: 43. The last example is, let us say, 10,000 dollars.\nNotice that you can just keep using 100 dollar bills. You will have to use 100 of them to generate 10,000 and it should be visibly the best possible. That is what is going on with the greedy algorithm. Hopefully, the mechanics of ‘greedy’ are clear. But to see that this actually does always generate the smallest number of bills for this combination of denominations does require a bit of an argument.\nNow, I will not go through a complete and formal proof. But I will just try to convey some intuition for what is going on. Sometimes these coin systems for which the greedy algorithm does produce the right answer are called Canonical Systems. A property that these canonical systems have is that if you look at the larger denominations, they are always divisible by all of the smaller ones. For instance, here, 100 is divisible by 20, 10, 5, and 1. 20 is divisible by 10, and 5 and 1, and so on. Let us see why this property might be useful to us.\n(Refer Slide Time: 07:48)\n \nSuppose that in some instance, your greedy algorithm produces a solution, and it looks like this. The specific numbers are not important here. Let us just imagine that this is some solution to some instance. Suppose somebody comes up with a competing optimal solution, which uses fewer bills, and let us say it is different from the greedy output. The point is that we want to get to a contradiction because we have assumed that there is a better optimal solution than what is produced by the greedy algorithm.\nIn particular, let us take a look at this optimal solution. Let us take a look at their first denomination for which the optimal solution has a different behavior from the greedy solution. Just to keep things simple, I am assuming here that the optimal solution uses fewer 100 dollar bills than the greedy solution does. This could have also been, say, 20 dollar bills. Maybe the optimal solution uses the same number of 100 dollar bills as the greedy solution but uses fewer 20 dollar bills, or it could be that it uses the same number of 100 and 20 dollar bills as the greedy solution, but fewer 5 dollar bills and so on.\nIn each case, the spirit of the argument will remain the same. Let us just work with this situation. Notice here, in this example, greedy uses five 100 dollar bills, and some optimal solution comes along, claiming to do better than the greedy solution. It is distinct from the greedy solution. Let us say that this was the first point of difference — it uses fewer 100 dollar bills.\nWhat does the optimal solution do in terms of the composition of the other bills? We do not have any details here and for the most part, it will not really matter. What is important to know is the fact that the remaining amount in the optimal solution must add up to at least 100 plus whatever amount remains when you take away all the 100 dollar bills from the greedy solution. So the optimal solution which is competing with the greedy solution also has to generate a total amount of ‘n’ but now it is doing this with 100 dollar bill less. That is what we are assuming.\nThis remaining amount has to be whatever remains in the greedy solution after all 100 dollar bills have been removed that amount for sure but also plus another 100. Because this missing one 100 dollar bill has to be compensated for by the bills that come in from the remaining denominations. What we do know about this is, even though the exact composition of bills may be opaque and unknown to us, we know the total amount sitting here at least is 173 — that is the specific figure for this example here.\nBecause 100 is divisible by all of these smaller denominations. It is divisible by 1, 5, and 20. I know that if there is an amount of at least one 100 sitting here, then I can, in fact, find a subset of coins from here, which adds up to exactly 100.\nJust take a moment to confirm that this makes sense. Once you see that you can do this, then what you could do is just eliminate this subset of coins, which add up to 100. Notice that you do not have to pick the subset in any special way. You can just pick any subset of coins that adds up to 100. You know that you will be picking at least two coins because the denominations here are smaller than 100. In fact, because the next largest denomination happens to be 20, you know that you will be picking at least 5 coins but that detail is not so relevant here.\n(Refer Slide Time: 11:48)\n\nWhat is important is that you are going to be discarding at least 2 coins and let us say you bring in one 100 dollar bill in exchange to compensate for what you have thrown away. Now notice that this is a solution, which manages exactly what the so-called optimal solution was managing, but with fewer bills. The claimed optimal solution was not optimal after all, which is a contradiction.\nNow, of course, we have done this with some specific numbers and in a slightly specific way, assuming that the optimal differs from the greedy in the number of 100 dollar bills that it uses and it differs by exactly 1. Hopefully, even this specialized limited argument gives you a sense of why the greedy algorithm may be expected to be correct. Now you could take pen and paper and try to write out this argument in its full generality.\nTry and appreciate where the divisibility property comes into play when you argue the correctness. All of this is leading up to the idea that for more general non-canonical coin systems, the greedy algorithm may not work. You could take a moment here again to try and come up with your own coin system where you do not have this divisibility property and try and figure out why it does not work.\n(Refer Slide Time: 13:02)\n\nAs a hint, let me give you a coin system. Here is a coin system with 3 denominations, 1, 3, and 4. Can you come up with a choice of ‘n’ for which the greedy strategy will fail? Feel free to pause here for a moment and try to work through this. Here is a value of ‘n’ for which greedy will fail. Suppose you try to generate 6, the greedy algorithm will try to do its maximum leverage backing.\nIt will use one 4 dollar coin or bill and after this, you are still left with an amount of 2 to be generated. You cannot use 4. You also cannot use 3. The only choice you have is to use two 1 dollar bills. On the other hand, you can probably tell that this is not optimal because 6 can instead be generated with just two 3 dollar bills and that would be the optimal solution in this case. So, you can see that the greedy algorithm can land you in trouble in these more general settings.\nIt is a useful exercise to go back and see where the proof ideas that we had for the canonical systems, in fact, break down. Just try and pretend to be prove the greedy algorithm in the setting where you already know in advance that it does not work. Try to go through the experience of the step at which the proof in fact breaks down. So with that, we come to the end of the description of our first greedy failure. Now we are going to do a couple of more examples in the upcoming videos. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/W03/Lec11.html",
    "href": "materials/cpnotes/W03/Lec11.html",
    "title": "M 3 (Stable Marriage-I)",
    "section": "",
    "text": "Lecture - 11\nGreedy Algorithms - Module 3 (Stable Marriage-I)\n(Refer Slide Time: 00:11)\n\nWelcome to the third module in the third week of ‘Getting Started with Competitive Programming.’ This week we have been looking at ‘Greedy Algorithms’ and I hope that the couple of examples that you have seen so far are already giving you a feel for how these things work. This time we are going to look at an example, which is actually a computer science classic, and it is called the ‘Stable Marriage’ problem.\nThis problem has enormous applications and really interesting history. If you are curious about some of the trivia that is associated with this problem, please check out some of the links in the description, which include a pointer to a very cool number file video on the topic and a couple of other really interesting articles. I will be presenting this as a stand-alone puzzle because of limitations of time and will really be doing no justice to the amazing history of this problem.\nPlease do learn more about it after you are done with this video, if you feel so inclined. Back to the context of contests, this problem did make an appearance in one of the ICPC Regionals. It is also available on the CodeChef problem archive. You can find links to both versions in the description of this video and you can use either one for practice, whatever is more convenient. The tasks are exactly the same and if I remember correctly, the limits are also kind of similar. So, it should really make no difference. With all that said, let us get to the problem statement and figure out what our task is going to be.\n(Refer Slide Time: 01:47)\n  \nThe setting is the following. We are given two groups of people, which we will refer to as ‘men’ and ‘women’ and there is always going to be the same number of them. Let us say that there are N men and N women for a total of 2N people. By the way, let me just mention that this terminology, using the word ‘marriage’ to refer to the problem itself and to refer to these groups of people as men and women, is traditional even in the computer science research literature around this problem.\nSo, it is not just from the contest problem statement. Do not be fooled into thinking that this is just a puzzle about matching men and women and getting them into happy marriages. It just turns out that this terminology is a convenient abstraction for modeling a wide array of application scenarios, some of which may even occur to you as we go through the problem statement together.\nFor a more comprehensive view of the many scenarios that can be thought of as instances of this stable marriage problem, I will point you to some of the links in the description. Let us now get back to the problem statement and consider what else we are given. We have these two groups of people: N men and N women, and it turns out that this is a rather judgmental group of people.\nEvery individual here has feelings for the people in the opposite group, and the way these feelings are modeled or given to us is by way of rankings. In particular, every man will have a ranking over the set of all women. You can think of a ranking as simply a permutation of the opposite set. In this case, the set of all women. Similarly, all the women also have rankings over the set of men. These rankings are really individual preferences and there need not be any relationship between the rankings of two different people.\nYou can think of the input as just being N permutations of the set of women corresponding to the N men and N permutations of the set of men corresponding to the N women. Often we will think of these permutations literally as ranked preferences and we will talk about the top preference or the second favorite and things like that. In this example, for instance, the ‘king of spades’ seems to like the ‘queen of diamonds’ the most and that is his top preference. The second-best preference is going to be the ‘queen of spades’ and so on and so forth.\nWe will use that kind of positional terminology to refer to people on a certain rank list. Hopefully, the input is clear. As I said, it is going to be 2N people and correspondingly N permutations of the men and N permutations of the women. What is the output?\n(Refer Slide Time: 04:44)\n \nWhat we want to output is essentially a bijection between the men and the women, which is to say that we want to match every man with exactly one woman. There are many different ways to match men with women. In fact, if you think about it, you will realize that there are N factorial possible matchings. Every matching can be thought of as a permutation of one of these sets and there is going to be N factorial of them.\nWe are not interested in just any arbitrary matching. Since we are given these preferences, we want a matching, which in some sense makes everyone happy. We do have to be careful about what we mean by a matching that makes everyone happy though. A natural definition may be to say, well, why do not we just match everyone with their favorite person from the other side. An immediate issue with this is that it is possible that multiple men, for example, have the same choice of favorite woman or multiple women have the same choice of their favorite man.\nIn this case, coming up with a well-defined matching that gives everybody their favorite person from the other side is going to be impossible. You could say that in these cases, we just say that there is no matching possible. But it turns out that we are going to have a more interesting definition for what we want from our matching.\nTo be able to understand what we mean by a so-called stable matching, which you might have guessed is what we are going to be looking for from the name of the problem, we first have to define an intermediate notion called a ‘blocking pair.’ The notion of a blocking pair only makes sense in the context of a matching. As with most things, let us try to learn about this definition through a concrete example.\n(Refer Slide Time: 06:28)\n \nHere, I have a fragment of a larger matching. I just wanted to focus on these four people here. That is why I am only showing you a part of the matching. We have a situation where the ‘king of spades’ has been matched to the ‘queen of spades,’ and the ‘king of hearts’ has been matched to the ‘queen of hearts.’\nSsuppose that in terms of preferences, we had the following situation. Let us say that the king of spades happens to prefer the queen of hearts over the queen of spades. He likes the queen of hearts more according to his ranking. On the other hand, if you consider the queen of spades, she also likes the king of spades more than the king of hearts.\nShe also prefers the king of spades over the king of hearts in her ranking over the men. With a little imagination, you can probably already guess what happens next. Because the king of spades and the queen of hearts prefer each other over their currently matched partners, they might find it an interesting option to just break off their current alliances and elope with each other.\nThis is why they are called a blocking pair because they put the current matching in some kind of jeopardy because of this mutual incentive to run away with each other. Remember that it is very important for this admiration to be mutual.\nIf only one of these people prefers a different person over their matched partner but said person does not return this admiration, then you do not have a blocking pair. It is not going to be a problem.\nBut as of now, these folks are left stranded and this is not a good situation. By now you have probably developed this intuition that blocking pairs are troublemakers for matchings and that is why you might find this definition of stable matching very natural now.\n(Refer Slide Time: 08:22)\n \nA matching is set to be stable if it simply does not have any blocking pairs and our task with this problem is to find a stable matching if one exists. Now I am saying ‘if one exists’ just to sound fancy.\nIf you actually look at the CodeChef problem statement, the last sentence of this paragraph guarantees that this problem always has a solution, which you might find surprising at first. When we come up with the algorithm, you will see that the algorithm itself doubles up as proof for why these stable matchings always exist.\n(Refer Slide Time: 08:55)\n \nLet us try to think about how we will go about this goal of finding a ‘stable-matching.’ What is the natural greedy choice here?\nA first cut observation to make is that if somebody is matched with their top choice, then they are never going to be involved in a blocking pair. Because they are absolutely happy with what they have and they are not going to really be interested in forming a blocking pair with any other person. A natural greedy choice may be to match as many people with their top choices as is possible. Let us try to pursue this strategy with an example.\n(Refer Slide Time: 09:34)\n \nHere we have again, the four men and four women in our running example, and let me bring up the top choices for the men. You can see that both the king of spades and the king of hearts like the queen of hearts as their favorite option, and both the king of spades and the king of diamonds like the queen of diamonds as their favorite.\nIn the spirit of doing the greedy thing, let us try to see what happens if we try to match all of these gentlemen with their favorite options. As you can see, this is not going to be straightforward because there is clearly some competition. For instance, both the king of hearts as well as the king of spades will reach out and try to get matched with the queen of hearts, while both the king of diamonds and the king of clubs will try to reach out and get matched to the queen of diamonds.\nNotice that both the queen of hearts and the queen of diamonds have a bit of a choice to make here, while the queen of spades and the queen of clubs are left stranded, at least for the moment. From the perspective of the queens that do have a choice, what choice do you think they should make? They can only pick one option because remember that the thing we want to finally output is a proper bijection. It is a matching.\nThese queens have to pick one choice. It may not be a permanent choice. It may be something that they could revisit later for reasons that we will see in a bit. But for now, they have to at least make a temporary choice disregarding one of the offers that they seem to be getting. The natural choice here would be, again in the spirit of ‘greedy,’ to pick the better option.\nNotice that it is possible that these options are not very good for the queens in absolute terms. For instance, it is conceivable that these two options that they have are their bottom-most choices. But still, because there is a choice to be made, you just pick the relatively better one. In this example, let us say that the queen of hearts prefers the king of hearts over the king of spades and the queen of diamonds prefers the king of diamonds over the king of clubs.\nThey go ahead and make those choices, and you are left with this sort of tentative arrangement at this stage. What we have achieved so far is that these two kings have been matched to their favorite options and at least as long as this matching persists, these kings will never participate in blocking pairs. Of course, it is possible that we may have to modify this matching as we go along.\nFor example, especially if these queens receive better options in the future. Remember, we said that we are only looking at the top options from the perspective of the kings. These options that the queens have received may be some of their worst. It is conceivable that the queens receive better offers later on, and they may have to give up on their current alliances to forge new ones.\nNotice that if that happens, the kings will still not participate in a blocking pair because the only people that they would care about forming a blocking pair with were taken away from them because they found better matches for themselves. Any of this admiration that the kings may have will not be reciprocated. This, of course, is getting a little ahead of ourselves.\nIf some of this does not make sense, do not worry about it. We will have more explicit examples and we will go over the overall algorithm once again. Do not worry if some of this sounded a little bit vague. Let us continue with our story here.\nThese kings have already been matched. The other two kings, who did not have any luck in the first round, are now going to move on to the second favorite options on their list. This time, the king of spades has the queen of spades as his second favorite option, and similarly, the king of clubs has the queen of clubs as his second favorite option.\nThese proposals are made to the respective queens and from the perspective of queens — well, it does not even matter where these gentlemen rank on their lists because we are intuitively in a situation where being matched is better than not being matched. Remember, we want to output a matching eventually.\nThe queens are simply going to accept this offer because it is better than nothing. They do not have to make any further comparisons because they do not have a choice, at least at this stage, and therefore these offers are accepted. Notice that all the men have been matched, and we have, in fact, a matching.\nYou can think about why would this matching, in fact, be a stable matching in this case because it was a simple example. We already know that the king of hearts and the king of diamonds have been matched to their top options so they do not participate in any blocking pairs.\nThe king of clubs and the king of spades could have potentially participated in blocking pairs with, say, the queen of hearts or the queen of diamonds. These are queens that they prefer more than their currently matched partners.\nBut notice that these two queens, just by construction, are currently matched to people that they like better than the king of spades and the king of clubs. So, they are not going to reciprocate the love and therefore these blocking pairs will remain incomplete.\nYou can hopefully convince yourself that the matching that we obtained for this particular example is a stable one. Let us go through another example, which is just a little more non-trivial, to really get a feel for what is happening.\n(Refer Slide Time: 15:12)\n \nWe are back to the original situation with four kings and four queens and this time, let us say that the top options look like this. As you can probably tell, we are once again in a situation where the top options are concentrated on two of the queens. In particular, both the king of spades and the king of clubs have the queen of diamonds as their top choice and both the king of hearts and the king of diamonds have the queen of hearts as their top option.\nLet us ask the queens what they make of the proposals that they have received. For the queen of hearts, let us say that the king of hearts happens to be her top choice. If this is the case, then the queen of hearts is going to reject the application from the king of diamonds and the alliance between the king of hearts and the queen of hearts is going to be forged at this stage.\nNotice that this is a really good match because these are two people who have been matched to their mutually top options. This is a match that will never be revisited. In some sense, we will never need to change this because it really does not get any better than this, to put it intuitively.\nLet us turn our attention to the queen of diamonds who has to make a choice between the king of clubs and the king of spades. Let us say that she likes the king of diamonds the best. But she does not have a proposal from him. So, let us ignore that for now.\nBetween the king of spades and the king of clubs, she likes the king of spades better. So, she is going to reject the proposal from the king of clubs and instead settle with the king of spades. This is the tentative arrangement that we have at this stage and we are still left with two kings that do not have a match yet. Let us turn to them and ask them about their next best options.\n(Refer Slide Time: 16:56)\n\nThe king of clubs has the queen of spades as his next best option and the king of diamonds is the queen of diamonds as his next best option. Let us say that these kings go ahead and make these proposals. Notice that now we have an interesting situation. The queen of diamonds already is engaged, in some sense, to the king of spades from the previous round.\nBut now she has a more interesting proposal to consider. If you remember her preferences, she prefers the king of diamonds over the king of spades who is her current partner. Given that this new proposal looks tempting, should the queen of diamonds deflect and basically go with this new proposal breaking her old arrangement? Or should she just be loyal to her current partner and ditch the king of diamonds even though she likes him more?\nJust think about what would be the appropriate thing to do given that we eventually want a stable matching, which is one without any blocking pairs. Hopefully, you had a chance to think about this because it is a really interesting question at this point. There is a tension between doing the seemingly right thing in terms of being loyal to somebody you have been matched with before and doing the thing that seems like the correct greedy choice in terms of optimality to the point where it almost sounds selfish.\nWhat should the queen of diamonds do? Let us consider what happens if she decides to stay true to her current partner who is the king of spades. If she does that, then at the very end, she is matched with the king of spades and on the other hand, the king of diamonds is matched to somebody that he certainly likes less than the queen of diamonds.\nEverybody that he liked more than the queen of diamonds, he has already been rejected by from previous rounds. In the current round, the queen of diamonds decided to reject his proposal as well. In the final matching, the king of diamonds is going to be matched with somebody that he likes less than the queen of diamonds. Notice that the queen of diamonds and the king of diamonds will end up forming a blocking pair because they mutually prefer each other over their ultimate matched partners.\nSince this is precisely the situation that we want to avoid at the end, it would actually make a lot of sense for the queen of diamonds to actually break off her current relationship with the king of spades and accept this new alliance with the king of diamonds. It may seem like a painful thing to do, at the moment, but it will be for the best in the long run.\nNotice that no actual rejections are happening. No actual breakages of engagements are happening. This is all background work that is being done by the algorithm and it is only the final matching at the end that will matter even in the context of a more real-world application.\nDo not worry about any actual heartbreak. This is really all in the analysis. Now, it is much easier to think about the queen of spades who has only one proposal in this round. So, there are no choices to be made, and she just goes ahead and accepts the alliance with the king of clubs.\nNow we still have one unmatched king, that is the king of spades who was matched before, but has now gone back to being single. Let us now consider the next best option for the king of spades.\n(Refer Slide Time: 20:24)\n \nLet us say that this happens to be the queen of spades. The king of spades will go ahead and make that proposal. Now, the queen of spades is in a situation similar to the one that the queen of diamonds was in previously. She has to consider making a choice between accepting this new proposal and breaking off the old one versus rejecting the new proposal and keeping the old one.\nWhat the queen does depends on how she compares her current partner with the potential new partner. Let us bring back her preference lists and observe that she actually prefers the king of spades over the king of clubs, and because of this she would want to actually accept this new proposal and break off her current alliance with the king of spades, much like the queen of diamonds of did before.\nNotice that this may not always happen. If the preference was listed the other way, then the queen of spades would have maintained her current alliance and the king of spades would have to go back and try his luck with the next person on his list. But in this example, that is not how it plays out.\nThis is the current matching that we have at this stage. Now the king of clubs goes back to being single and makes a proposal to the queen of clubs, who is the next person on his list. This proposal gets accepted because the queen of clubs is single at the moment and because something is better than nothing. This is an immediate acceptance and we finally have a ‘matching.’\nYou can try to convince yourself that this matching is stable. That should be intuitive given that we had that at the back of our minds all along. Nonetheless, it is useful to actually prove this formally and instead of working in the context of this example, let us actually turn to the algorithm in full generality and try to argue the correctness also in slightly more general terms.\n(Refer Slide Time: 22:25)\n\nJust to recap what the algorithm is doing. We start off with the list of men and women and initially, nobody is matched to anybody, to begin with. This piece of pseudocode is borrowed from the book ‘Algorithm Design’ by Kleinberg and Tardos and you can find a pointer to the book website in the description of this video.\nWhat we are going to do is basically run a ‘while’ loop for as long as there is a free man. A man who is still single and has not been matched to anybody. As long as there is such a man, what we are going to do is basically look at the highest-ranked woman for this man to whom he has not yet proposed or in other words, the highest-ranked woman who has not yet rejected him.\nWe have this man approach this woman, and what plays out from here will depend on the situation of the woman. If the woman is unmatched herself, if she is single because we have been saying that it is better to be matched than to not be matched, this proposal will have immediate acceptance. So, this match is made and we are done.\nOn the other hand, if ‘w’ is currently engaged, then she would have a choice to make between her current matched partner and this new proposal. We have seen this play out a couple of times in the last example that we discussed, so you should probably be able to predict what the algorithm does here.\nLet us say that the currently matched partner is m’ and the new proposal is coming from “m.” Suppose ‘w’ prefers m’ over “m,” which is to say that she likes her current situation better than the new proposal, then she is just going to reject this new proposal, and “m” remains single and will have to go back and revisit his preferences and propose to the next woman on his list, which will happen naturally as you go back to the start of this ‘while’ loop.\nOn the other hand, if ‘w’ finds this new proposal more exciting than her current alliance, then she is going to break off her current alliance, and m’ now becomes a free man (gets added to the pool of single men) and the engagement between ‘m’ and ‘w’ is established – ‘m’ being the new person who is proposing to ‘w.’\nThat is pretty much it. That is how this progresses and once you stop, that happens when all men have been matched, and at that point, you have a set of engagements that you can finalize and claim to be a stable matching. There are a few useful observations to make about this algorithm.\nFirst of all, let us argue termination. Because there is a ‘while’ loop involved and there are engagements being broken and men going back to being single, you might even suspect if there is a possibility that this algorithm keeps going around in circles and possibly never stops on some cleverly designed input.\nIf this thought is in fact bothering you, then I would encourage you to pause here and take a closer look at the pseudocode and see if you can find an argument for termination. One hint would be to think about the number of proposals that are being made and observe that the running time of this algorithm is really proportional to the number of proposals being made and see if you can bound that in some way. Come back when you are ready. Hopefully, you have had a chance to think about this. As we were just saying, the most basic question here would be one of termination.\n(Refer Slide Time: 25:56)\n \nNotice that the number of proposals that are made over any run of this algorithm is at most n2 because a man never proposes to the same woman twice. He is always walking down his preference list and there are ‘n’ men and every man has ‘n’ women to propose to. The number of proposals may never exceed n2 and this essentially drives the conclusion for termination.\nWe also want to say that the algorithm terminates with a complete matching. Nobody is left free at the very end. One of the reasons for this is that if somebody is single, then there is still some work to be done. There is still somebody that he can propose to. Notice that at every intermediate stage of the algorithm, the set of engagements form a valid partial matching, which is to say that you never have a situation where one man is matched with multiple women or multiple men are matched to the same woman.\nWhat you have is a valid partial matching. It is enough to argue that at the very end, you do not have any single men. But as long as you have a single man, he still has some woman left on his list that he can propose to, so the algorithm has not yet terminated. Notice that the reason for this is that if he really proposed to every woman on his list, and he is still single that means that he was rejected one way or the other by every woman that he proposed to, either outright or by getting into an engagement and then being kicked out of it.\nThis only happens when the women are already engaged to somebody. But you cannot have ‘n’ women being engaged to ‘n-1’ men if what you are maintaining is a valid partial matching at every stage. Therefore, it is not possible for a man to be single, once the algorithm has terminated. But since every man is matched, and you have a valid partial matching at every stage, at the final stage you indeed have a complete matching.\n(Refer Slide Time: 27:53)\n \nThe last thing we want to claim is that this complete matching is, in fact, stable. The intuition for stability was probably already established when we were making some of these greedy choices with respect to the proposals and the rejections. Let us once again recap the reason why the output matching is, in fact, stable. One way to argue this is by contradiction. Let us say that the output matching was not stable.\nThe algorithm output something with a blocking pair and let us say that the blocking pair looks like this. The output matching matches the king of spades to the queen of spades and the king of hearts to the queen of hearts. But the queen of hearts prefers the king of spades over the king of hearts and this love is reciprocated in that the king of spades also prefers the queen of hearts over the queen of spades.\nIf the situation were to really arise, can you think of a contradiction in terms of the behavior of the algorithm? In particular, think about the proposals that the king of spades would have made during the run of the algorithm and think about how the queen of hearts should have reacted at a certain point.\nPlease feel free to pause the video here and really think through the proof yourself before continuing. Consider the king of spades and the proposals that he makes. Before he proposed to the queen of spades which he must have done to be finally engaged with her, he must have first proposed the queen of hearts. Because the assumption here is that the king of spades prefers the queen of hearts over the queen of spades. So, she would have come first in his list and would have been approached before the king of spades approached the queen of spades.\nThe real question now is: What did the queen of hearts do when she was proposed by the king of spades? Given that they are not matched in the output, it must have been the case that the queen of hearts rejected this proposal in one way or the other. Either it was rejected immediately or it was accepted and rejected in a future iteration in favor of a better proposal. But notice that if the queen of hearts did indeed reject the king of spades, either immediately or later on, it must have been because she was in a better situation than the king of spades.\nIt could not be possibly the case that she likes her current matched partner less than the king of spades as stipulated by this blocking pair scenario. Hopefully, it is at least intuitively clear why we are not going to have blocking pairs because really the greedy choices were geared towards avoiding them in the first place.\nPlease feel free to take your time to work through this yourself and hopefully convince yourself that everything does work out in terms of both termination and obtaining a complete matching and also ensuring that this matching was a stable one. This brings us to the end of the description of the algorithm. You probably have enough, especially if you go back to the place where we discussed the pseudocode, you probably have enough to actually code this algorithm yourself now.\nPlease feel free to take a break and do that and come back to the rest of the content once you have given it a shot yourself. For this particular module, we are going to split up the implementation into a separate video and I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/W03/Lec10.html",
    "href": "materials/cpnotes/W03/Lec10.html",
    "title": "M 2 (Islands War)",
    "section": "",
    "text": "Lecture - 10\nGreedy Algorithms - Module 2 (Islands War)\n(Refer Slide Time: 00:11)\n\nWelcome back to the second module of the third week. We continue our exploration of ‘Greedy Algorithms.’ As I mentioned, this time, we will be talking about a problem called the ‘Islands War.’ It was the fourth problem of an ABC contest on ‘AtCoder.’ It was contest number 103. You can find a link to the problem statement in the description of this video, and this one turns out to be a problem with a really fun story about warring islands, as you can guess from the name of the problem.\nSo, there will be a lot of conflict and drama, and your task will be to figure out how you can resolve all of these conflicts with minimum damage. So, we are going to have a lot of fun. Let us get started.\n(Refer Slide Time: 00:56)\n \n Eventually \nWe have ‘n’ islands lining up from west to east connected by ‘n-1’ bridges. These bridges are not completely arbitrary. The ith bridge is given to connect the ith island from the west with the (i+1)th island from the west. So, it is a really clean visual. Here is an example with ten islands and the bridges. There are nine bridges, which just connect them from left to right.\nWest to east has been, sort of, modeled as left to right on your screen. So, the westmost island is the first island here and so on. The real story begins when we are told that some disputes have broken out between some islands, and we want to make traveling between those islands using these bridges impossible. How do we do this? We must have something to work with to be able to meet this goal. The thing that we are allowed to do is we can remove some of these bridges.\nBut as you can imagine, removing bridges is a fairly destructive thing to do. What we are also asked to do is to minimize the number of bridges that need to be removed. So, you want to pacify everybody involved in a dispute. In the language of the problem statement, these disputes are called ‘requests.’\nSo we are given ‘m’ requests. Each request is a pair ‘ai bi,’ indicating which pair of islands are involved in the corresponding dispute. What you want to do is you want to remove bridges in such a way that every request is satisfied. That is the entire problem statement.\nThat is the goal. What we are going to do is just try and think about this first with the help of a few scenarios. Before we get to actually thinking about specific examples, let us go through this one right here. As you probably have noticed already, we have five requests here and a useful way to visualize these requests. Because we want to be thinking about which bridges to remove to satisfy all of these requests.\n(Refer Slide Time: 3:31)\n \n \nWe are going to visualize these requests as lines that have their endpoints at the two islands that are involved in the request. Let us just draw these out here. Maybe you can just try to figure out what is the optimal solution for this example. Just to get a feel for the question to make sure that we are on the same page with respect to the task at hand.\nFeel free to pause here because I am just going to give it away after I finish this sentence. For this example, you may have noticed that it is impossible to meet all requests by destroying just one bridge because, for instance, we have a pair of disjoint requests. So, we have two requests that do not have any bridge that is common to them. There is no single bridge that will handle both of these requests. You need at least two, and the interesting thing is that you can do it with just two bridges.\nYou could, for example, remove these two bridges here, and you would be done. How do we go about thinking about this problem in a greedy fashion? What is a natural greedy strategy? Remember that we have to meet all requests and minimize the number of bridges we use to satisfy these requests.\nWhat sort of bridges should we prioritize? What sorts of bridges are likely to appear in an optimal solution? A natural thing to do is to probably just go over every bridge and count how many requests are such that they would be satisfied if we were to remove that bridge. You could call this the ‘power of a bridge’ or something like that. You could use whatever term seems natural to you. I am just going to go with power.\nLet us say that the power of a bridge is just the number of requests, which would be handled if we were to destroy that bridge hypothetically. Now, it seems to make sense to target the bridges that have the highest power because the more powerful a bridge, in some sense, the more requests you handle in one shot.\n(Refer Slide Time: 05:51)\n\nThis motivates our first greedy approach to this problem. What we could do is compute the power of every bridge. Sort the bridges by their powers, and then pick the most powerful bridges first. In particular, to begin with, we include the most powerful bridge in our solution, breaking ties arbitrarily. Then we delete all of those requests that got handled due to deleting this bridge. Then we keep repeating this as long as we have at least one request left.\nRemember that you may have to re-compute the powers of the bridges because after you delete some requests, some bridges may become less powerful than they were before. You could do all of this and what you would have as a result is a perfectly valid approach. But this is a good time to pause and think about whether it actually works. It will certainly produce a subset of bridges whose removal will handle all the requests just by definition.\nThe real question is whether this is the best that we can do? In other words, are we really getting to the minimum number of bridges that we need to destroy to handle all requests? This is a great time to pause the video and actually think about this. Play with some examples and see if you can come up with either an argument for the correctness or if you can come up with a counter-example showing that this may not actually be the best possible strategy.\nPlease go ahead and take that pause and come back to this video once you are ready. Hopefully, you have had a chance to think about this. It turns out that while extremely tempting, this strategy does not, in fact, work.\n(Refer Slide Time: 07:32)\n \nWe are going to show you an example where the strategy of choosing the most powerful bridges can actually lead you to a solution that is not the optimal solution. Here we have a collection of four disjoint requests, which tells you straight away that the optimal answer has to be at least 4. Then we have a bunch of other requests, which are going to play out over the next couple of seconds.\nLet us try and think about what the greedy strategy will do here. You can check that, to begin with, three bridges have a power of 4, and ‘4, 5’ is one among these most powerful bridges. The greedy algorithm could start by picking ‘4, 5’ followed by ‘8, 9,’ which is one of the most powerful bridges left in the second iteration.\nAfter deleting ‘4, 5,’ and ‘8, 9,’ you are still left with three disjoint requests, which means that the greedy algorithm will have to output a solution involving five bridges. However, notice that four bridges are actually enough for this instance. Remember, earlier, we said that we need at least four, but it turns out that four bridges are even enough.\nNow you might be thinking that was pretty close. It was off by just one. Do I really need to worry about this? So, once again, let me remind you that in contest programming, you have to get it exactly right. There is no partial credit for coming close to the right answer. Sometimes there are problem statements, which will allow for solutions close to the optimal.\nBut these are rare and certainly out of the scope of this course. So, always work with the mindset of shooting for the exact optimum solution. Besides, although this particular example was off by one, you can probably think about coming up with ways of modifying this example so that you can really amplify the gap between the output of a greedy algorithm that follows the strategy of destroying the most powerful bridges first and the true optimal solution.\nI leave that to you as food for thought while we should probably move on, get back to the drawing board, and think about other alternate strategies. To get a feel for what is going on, let us actually begin by looking at two really simple scenarios. These are probably the simplest scenarios that we can come up with, but they will still give us some intuition for what is going on.\n(Refer Slide Time: 10:04)\n  \nFirst, let us think about what if all the requests were disjoint? In this case, you know that there is no bridge that can handle more than one request. You know that the optimal solution must involve at least as many bridges as there are requests. So, ‘opt’ is actually equal to ‘m,’ in this case. In terms of actually coming up with a solution, if you had to, you could simply pick one bridge per request, and it could really be any bridge that kills that request. It would not matter.\n(Refer Slide Time: 10:41)\n  \nOn the other end of the spectrum: What if every request went over some common bridge? In other words, what if there was one bridge that was involved in every single request? Here is one example where this plays out, and you can probably, as we go along, identify the bridge that is common to each request. It is the one that is right in the middle. When you have a situation like this, ‘what should the optimum solution be?’, you can probably guess that the optimum solution is just that one bridge that every request is involved in. A typical instance is going to be some combination of these two very extreme scenarios. So, let us think about a more generic situation.\n(Refer Slide Time: 11:31)\n\nOften it helps to think about what an optimal solution looks like, especially at the extremes. If there is some notion of beginning or end in a problem, it is worth thinking about what is going on the edge. Let us do that here and think about a situation that has no special structure.\nImagine that somebody has given you an optimal solution to look at and one question that I would like you to think about now is: Where is the leftmost bridge on this optimal solution? Where does it lie? Which request is driving the choice of the leftmost bridge? Please take a pause here and think about this because this is going to lead us to the main insight for the final solution. I hope you had a chance to think about that. We are going to work through this with an example.\n(Refer Slide Time: 12:24)\n\nLet us drop some requests right here and, as we said earlier, you really want to be thinking about: Which is that critical request that drives the choice of the leftmost bridge? There are some natural candidates. Is that the one that finishes first? Is it the one that starts first? Is it the one that finishes last? The one that starts the last? If you think about it, you will realize that it is probably the request that finishes first.\nBecause if you choose a bridge that came after this request finished, then you are in deep trouble. We know that we have to, at least, pick the bridge ‘3, 4,’ or one of the ones before it, to make sure that the first request is satisfied. In this example, we know that we have to pick at least one of these three bridges ‘1, 2,’ ‘2, 3,’ and ‘3, 4,’ to satisfy the first request.\nThe thing to think about here is: Between these three bridges, is there a natural greedy choice to be made? Is there a bridge that seems to be at least as powerful as the other ones, so that we can sort of pick it at this stage without having to worry about exploring all the choices that we have?\nA natural thing to target is the last bridge, which is the bridge ‘3, 4’ in this case. Because notice that every request that can be handled by ‘1, 2,’ or ‘2, 3’ can also be handled by ‘3, 4.’ If this was not the case, then we have a request that is being handled by the previous bridges but is not being handled by ‘3, 4,’ and that would contradict our choice of the bridge that finishes first.\nIn case that was not completely clear, please take a moment to work through it. It is a simple argument, but it lies at the crux of why the strategy that we are going to propose is, in fact, correct. The idea here is to simply prioritize the bridge that is on the brink of the request that finishes first. Because, again, the overall intuition is that we know that we do have to pick either this bridge or one of the ones that come before it, and it seems like this bridge is at least as powerful as the ones that come before it. So, we might as well just pick this one. Let us convert this idea into an algorithm.\n(Refer Slide Time: 14:51)\n\n \nThe natural thing to do here is to sort the requests by their right endpoints, which is to say that the requests that finish the earliest will come first in the sorted order. Just to be sure, let us look at this sorted order for one of the examples that we saw just a little bit earlier. Now from here, what does the algorithm do? It is going to look at the first request, pick the last bridge on it, and then eliminate all the requests that are handled by this bridge.\n(Refer Slide Time: 15:11)\n \nThen we simply continue. For as long as we have a request left, we are going to be picking the last bridge on the first request. Notice that the sorted order of the requests remains unchanged, even as bridges get deleted. We just have to make sure that we track which requests are being handled by the bridges that we are including in our solution.\nLet us just play this out on a couple of examples to get a feel for what is going on. At this stage of our discussion, you are actually exposed to the entire algorithm that finds the solution. Hopefully, you have some intuition for why it works. We are going to have more to say about that and the running time in just a minute. But if you cannot wait to implement this yourself, this would be a good time to take a pause and do it.\n(Refer Slide Time: 16:19)\n \nIn the meantime, let us play out the algorithm once again on one of the examples that actually appeared in the problem statement. Speaking of the problem statement, let me also remind you about the constraints that we are given on the inputs. Notice that the number of islands and the number of requests can be as large as 105, which means that an algorithm that is either quadratic in ‘N’ or ‘M’ would not be feasible.\nIn fact, even a solution that has a worst-case complexity of ‘N*M’ might get you into trouble. Let us analyze the running time of the approach that we have just proposed. Recall that in the first step, we sort the requests according to their right endpoints. That is just a standard sorting procedure and it will take you time ‘M log M,’ which is still pretty safe within the given limits.\nThe second phase is where we actually build up the solution. The way we did this was by performing one pass over the sorted list of requests. Every time we encountered a request, we would include the last bridge on that request in our solution. We would also eliminate all the other requests that were handled by this bridge.\nBut if you implemented exactly according to this description, then you have to be a little bit careful because you might end up getting an order ‘M2’ kind of a running time. Because every time you include a bridge, you do one more pass over the list of requests to identify those that need to be eliminated.\nI will leave it to you to think a little bit about how you can implement this in a slightly different way to ensure that all your work is being done in just this one pass over the requests. One hint is that instead of actually explicitly eliminating requests as you go along, can you simply track the last bridge that you have included in your solution and for every request that you are going over, simply check as you go along, if it was handled by that last bridge or not and think about why this approach would also work?\nThat is all that I will have to say about the implementation for now. I would like to go back a little bit to our discussion about the correctness of this algorithm. One of the really neat things about this algorithm is that the solution that it produces carries proof of correctness. If you think about the bridges that we chose finally, each of them corresponds very naturally to a request.\nThat is that request, which triggered the choice of this bridge and the solution. If you think about it, you will realize that all of these requests are, in fact, disjoint. Because if they were not disjoint, then at least one of the overlapping requests would have been eliminated in a previous iteration. You get a really simple contradiction. Now you have a collection of disjoint requests that is exactly the same size as the solution, which means that our solution has to be optimal.\n(Refer Slide Time: 19:31)\n  \nGoing back to one of the first observations that we made, it was this really simple idea that you need at least as many bridges as there are disjoint requests in your instance. What this algorithm is telling you right now is that it is actually enough. You do not need anymore. It is this really nice duality telling you that the largest number of mutually disjoint requests actually determines the number of bridges that you need to destroy. That concludes our discussion about the algorithm and its correctness.\n(Refer Slide Time: 20:07)\n\n\nLet us move on to the implementation. This is your regular spoiler alert at this stage of the discussion. If you want to try this yourself, you should probably come back after you have given it a shot. In the meantime, let us get started here. Let us recall that the first line of the input is just the number of islands and the number of requests given as two space-separated integers.\nLet us just read those in and the next ‘M’ lines give you the ‘M’ requests. Let us declare a list of requests and let us read these in. I am going to store each request as a tuple, you could also store it as a list - does not really make a difference. This is the current request, which we are going to append to the list of requests.\nThe first thing that we have to do is to sort this list of requests according to the right endpoint. What we are going to do is use the built-in sort function on the list of requests. But we also have to tell the ‘sort’ function to sort according to the second coordinate. There are many ways that we can do this.\nFor brevity, I will just use a lambda function here. If you are not familiar with this sort of notation, you can look it up. But intuitively, you can imagine that it is instructing the sort function to sort according to the second coordinate of the tuples. Now that the requests are sorted the way we want them, let us actually get to the bit where we build up the solution.\nLet us declare an answer variable, which we initialize to 0. We will start looking at these requests and figure out if a request really demands that a bridge needs to be added to the solution. Let us start by going over the requests one by one. What do we need to know about this current request?\nWhat we need to know is: Is it being handled already by the solution that we have built up so far or not? If it is not, then we need to add the last bridge on this request to our solution. If it is, then there is nothing to be done and we can move on. How do we check this? How do we check if the current request is being handled by the solution that we have built up so far?\nNotice that if it is being handled by the solution, then certainly the last bridge in our solution covers this request. Because if the last bridge does not cover this request, then none of the previous bridges would either. If it covers the request, then we are done. It is enough to keep track of the last bridge in the solution that we have built up so far.\nIn some sense, what we are going to have is something like this: If the last bridge is at least request of 0. What does this mean? Look at where the request starts, and make sure that the last bridge is after the starting of this request. If this is the case, then the last bridge covers this request. If this is the situation, then we can just keep going.\nBut if it is not, then notice that we do need to add a bridge to our solution to handle this particular request. What is the bridge that we are going to add to the solution? As we have discussed when we were going over the greedy approach, we said that it is enough to pick the last bridge that covers this request.\nThat is given by request of 1. What we want to do is, we want to add this bridge to our solution. When I am talking about the request of one, it is really the bridge that connects the islands’ request of 1-1 with request of 1. So, that is the bridge that I want to add to my solution.\nRemember that we are really just tracking the number of bridges in our solution and as we go through this one pass over the requests, what I need to remember is: What was the last bridge? In other words, what was the rightmost bridge in my solution? At this point, what do you want to update is just the value of last bridge to reflect that the last bridge is now the bridge that ends at request of 1.\nBy the way, I am just thinking of representing the bridges by their right endpoints here. You could also represent a bridge by its left endpoint but then you would have to adapt the ‘if’ condition in the previous block. The other thing that we have to update is the answer variable. We need to increment that by 1, and we need to print this answer.\nOne thing that we have not done is initialization. What happens to the first request? When you start this ‘for’ loop, you are going to run into a problem when you try to execute this ‘if’ statement because there is no last bridge. We have not even started building our solution so far.\nTo make sure that the last bridge of the first request is actually chosen in the solution, what I initialize last bridge is -1 because that way even if the request started at island number 1, it is still not going to be covered by this last bridge. Notice that this is an artificial last bridge, it does not really exist.\nIt is just so that the code that we have written picks up the last bridge of the first request, to begin with. Then it does its thing after that. You could also initialize this as requests of 1 of 0 and then you could start your ‘for’ loop from the second request onwards. That is just going to be a matter of preference.\nBut I believe this should work. I think we have gotten all of the moving parts right here. So, I am going to try and run this. Notice that the output here turns out to be 2. I think this was one of the examples or at least close to one of the examples that we have discussed. We see that the expected output is also 2. In general, as a matter of practice, you just want to make sure that your output tallies exactly with what is expected.\nWe could run this on one of the other examples as well. As usual, you probably also want to run this on examples that you come up with just to have an extra level of sanity check. Let us try running this on the last sample output where the expected answer is 4 and this is also an example that we have actually seen.\nLet us go back and run our program and we will see that the output actually matches and everything seems fine. I think we should have some confidence from the fact that we have discussed our approach by now, in quite some detail. At this point, I would encourage you to actually check this code or a version of it that you might have put together on the full set of test cases and let us know how it went.\nAs usual, if you are stuck anywhere or if you are running into trouble with the logistics of submitting your solution, please give us a heads up on either the Discord channel or drop a message in the Google Forums for this course and one of us will be sure to get back to you. All the best and we will see you in the next problem. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W03/Lec14.html",
    "href": "materials/cpnotes/W03/Lec14.html",
    "title": "M 4 (When Greedy Does Not Work - Guarding a Museum)",
    "section": "",
    "text": "Lecture - 14\nGreedy Algorithms - Module 4 (When Greedy Does Not Work - Guarding a Museum)\nLet us continue with our second example of an optimization problem where the natural greedy strategy, in fact, does not work. This problem is called ‘Guarding a Museum’ with some guards. Let us take a look at the problem statement.\n(Refer Slide Time: 0:27)\n\nWhat we have are some paintings that have been placed on a hallway, which you can imagine as just being represented by the number line. You can imagine the paintings as just being some locations on this number line. For convenience, you can imagine that these are integer locations, although that is not really necessary. But that is what our examples will look like. What you are given is some guards.\nThese guards have a certain purview that they can see. This is also a part of your input. For example, here, we have a guard who is able to see, let us say, 3 units to the left and 3 units to the right. We are given this number K. Every guard can see K units to the left, and K units to the right from where he is positioned. Of course, he also sees the position at which he is standing.\nWhen you place a guard, let us say, at the origin of this number line, then you, in some sense, protect the locations 0, +1, +2, +3 and -1, -2, -3. These are all the locations that are currently under the observation of the guard who is standing at the origin. You can think of this visibility range as something that is given to you as input, and we will call it ‘K.’ All guards have the same visibility range. Any guard that you place at position ‘x’ will end up observing position x, as well as any position that is within K units to the left or right of x.\nWith this setting in place, let us now define the optimization objective.\n(Refer Slide Time: 2:08)\n\nWhat we want to do is make sure that every painting is protected or guarded at least once. We want to minimize the number of guards that we deploy to be able to achieve this. There are many variants of this problem. You might be in a situation where you want to be more protective, and you might want your paintings to be observed by at least some number of guards.\nIn other applications, you sometimes do not want 2 guards to observe the same painting. That is usually not in the situation of paintings but other applications that involve, let us say, for instance, the guards may be robotic agents, and maybe when two of them have their sort of range of visibility overlapping, it may cause some undesirable interference.\nSo, there are variations of this problem where you do not want any particular location to be guarded, or to be observed more than once because that is just physically not desirable. But in this variation of the problem that we are discussing now, we do not mind every painting is observed more than once. But we do require that every painting is observed at least once. That is the goal. That is a feasible solution — where every painting is guarded at least once.\nThe thing that you want to minimize is the number of guards that you actually deploy. So, hopefully, the problem statement is clear. At this point, you might want to pause and think about what will be a very natural greedy strategy to come up with a solution. Take a pause and come back when you are ready. Hopefully, you had a chance to think about this. Here is a very natural greedy strategy for solving this problem.\n(Refer Slide Time: 3:54)\n\nFor every location, you can try to count the number of paintings that would be guarded if you were to hypothetically place a guard at that location. Then you could choose the location that has the maximum potential in this sense, in the sense of the number of paintings, that would be taken care of where you to place a guard at that point. If there are multiple locations that have the maximum potential, then you could just pick any one of them arbitrarily. Then you could just delete all the paintings that get taken care of by this choice. Then you could just repeat until you have no paintings left to worry about.\nLet me also quickly point out here that you do not really need to check the potential of every point on the number line for this strategy to work. That is anyway not going to be feasible. Notice that because we assume that our paintings were positioned at integer coordinates, we can assume without loss of generality that our guards are also going to be positioned at integer coordinates, by which I mean that there will always be an optimal solution where this is the case.\nSuppose somebody does come to you with an optimal solution where the guards are not at integer coordinates, then you can identify all the guards who are not standing at integer coordinates and gently nudge them to the closest integer coordinate without really changing the texture of the solution. It will work just the same.\nOnly integer coordinates are really of interest to us. Notice that you can also ignore any integer coordinate that is more than K units to the left of the leftmost painting, or more than K units to the right of the rightmost painting. It will never make sense to place guards at these positions. They are never going to protect any of your paintings. We can simply ignore them. Based on this discussion, you should be able to conclude that the number of locations of interest is really given by the distance between the leftmost and rightmost paintings +2K.\nWhat can we say about the distance between the leftmost and rightmost paintings? Let us say there are N paintings. This distance can be unbounded if you have some two consecutive paintings, which are really, really far apart. But if you think about it, if there are two paintings, which are arbitrarily far apart, then we could shrink this gap down to something like 2K+1 without changing anything about the instance. I will let you think about why this is true.\nBut you should be able to conclude that the number of locations of interest overall is some order NK based on everything that we have said so far. Let us go ahead and compute the potentials of all of these locations, which again, remember is basically the number of paintings that would get taken care of if we were to place a guard at that location.\n(Refer Slide Time: 6:29)\n \nHere is an example with N = 8. We have 8 paintings at various locations. Let us say the visibility ranges of the guards are 3. So, K = 3. We are basically computing the potential of each location. This number is written above each location. You can pause the video here for a minute and verify that these numbers are as you would expect. Let us now think about what the greedy algorithm would do.\nThe greedy algorithm is going to focus on those locations that have the highest potential. Notice that we have 4 locations that are tied at the top, and it is going to pick one of them arbitrarily.\n(Refer Slide Time: 7:08)\n \nLet us say the greedy algorithm picks this location and decides to place a guard there. Once we do this, we can forget about these first 5 paintings that are taken care of by the guard. These are the remaining paintings and the recomputed potentials. At this point, you could pick any one of these locations that have the maximum potential, which in this case is 3.\n(Refer Slide Time: 7:29)\n \nPlace a guard at any of these locations. They will just take care of your remaining paintings. So, you can guard everything with 2 guards. You can also see that this is, in fact, the best possible because if you looked at the original instance, then you will see that there were 2 paintings that were more than 6 units apart. You definitely needed at least 2 guards. That is one run of this greedy strategy that actually worked out.\n(Refer Slide Time: 7:55)\n \nLet us go back to the original instance and see if the tie-break worked out differently, what would happen. This is a good place to pause and think about whether a different tie-break could lead to a less than optimal solution.\nLet us see what would happen if you had picked the second location, which had the maximum potential instead of the leftmost one. In this case, if you place a guard at this position, then you actually leave out the leftmost painting from the purview of the first guard.\n(Refer Slide Time: 8:26)\n\nUnfortunately, this is the instance that you are left with. We have a situation where we still have 2 paintings that are more than 6 units apart from each other. We could calculate the potentials as the greedy algorithm would do at this stage. Then the greedy algorithm would have to position 1 guard in the extreme right and 1 on the extreme left.\nBecause of this situation, we see that the greedy algorithm will need to have 2 more guards on top of the very first guard that it has already positioned, leading to a sub-optimal answer. You might think that it was because of an unlucky tie-break. Correct. There was at least one way of breaking the tie. I think there are at least 2 ways, which would have led to the correct answer.\nThere are 2 things about this. One is that you cannot rely on luck, especially not in contest programming. You cannot just hope that your greedy algorithm will get the tie-breaks right. While there are problems for which tie-breaking is really the main issue, and maybe the greedy algorithm would work well, if there was a promise that you would never have ties at any stage of the greedy algorithm, which by the way, can be very restrictive but suppose that was the case, maybe things would work out.\nBut for this particular example, I would encourage you to, as an exercise, come up with an example where the tie breaks do not matter. At the very first decision, there are no ties. There is a unique position that has the maximum potential. The greedy algorithm will be forced to pick that. But that turns out to be a bad choice. If you can come up with such an example, please do share it in the comments either on this YouTube video or at the Discord community, and we look forward to analyzing them.\nNow, as a part of this lecture, we have one more video left where we will go through one more example of a situation where the greedy algorithm fails, and in some sense, it fails quite miserably. We will see what we mean by that when we talk about the ‘Traveling Salesman’ problem in the next video. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/W03/Lec15.html",
    "href": "materials/cpnotes/W03/Lec15.html",
    "title": "M 4 (When Greedy Does Not Work - Traveling Salesman)",
    "section": "",
    "text": "Lecture - 15\nGreedy Algorithms - Module 4 (When Greedy Does Not Work - Traveling Salesman)\nWelcome to the last leg of our little tour of problems and situations where greedy algorithms, in fact, do not work. To demonstrate a situation where the greedy approach fails rather dramatically, I have picked the ‘Traveling Salesman Problem.’ You may have heard of this problem before given that it is a classic and famous optimization problem. Nevertheless, let us begin by looking at the definition.\n(Refer Slide Time: 0:37)\n\nIn this problem, you are given a list or a set of N cities or locations and the costs of traveling between any pair of these locations. In the symmetric version, you might assume that the cost of traveling from A to B is the same as the cost of traveling from B to A, for any two cities A and B. In the asymmetric version, you drop this assumption. The cost of going from A to B may be different from the cost of going from B to A. This can happen, for example, in applications where you have some one-way roads between locations, and the situation is truly not symmetric.\nThese costs may not always reflect necessarily physical distances. The costs may be more abstract or may be based on other things, like their costs of actual airline tickets and things like this. In particular, the costs here may not satisfy things like the triangle inequality. It may be cheaper to go from A to C by going through a detour, unlike what would be intuitive if these were really physical locations in a plane.\nLet us say that the costs were reflective of the Euclidean distances, as is the case in this example, which is essentially a recreation of the example on the Wikipedia page for this problem. Assuming that the cost between any pair of points is just proportional to the Euclidean distance between them on the plane, then the tour that has been drawn out right now is the optimal one.\nJust to make our setting a little bit concrete, let us say that we are working with the symmetric version of the problem, wherein the cost of going from A to B is the same as the cost of traveling back from B to A. Further, let us say that we do not have the triangle inequality. The costs are arbitrary. They do not come from any underlying distance metric or anything like that. Let us also say that the costs are not bounded in any way. These could be arbitrary numbers. We do not assume, for example, that the costs have to come from the set: 1, 2, 3, 7, 10.\nThis is a fairly general version of the problem. Notice that intuitively, the more restrictions you put on the setting of the problem, the easier your job becomes as an algorithms designer. Because the hope is that you can leverage these extra assumptions and use them to your advantage when you are coming up with an algorithm. But you can imagine that your life as the designer of counter-examples to greedy approaches may become a little bit harder.\nBecause the more assumptions you make about the setting of the problem, the less wiggle-room you have while you are constructing your counter-examples. You are now constrained to operate within these assumptions. Hopefully, that bit of intuition made sense. As I said, the choices of assumptions, that I just described, are relatively arbitrary. I would welcome you to play around with a different setting and see what you find.\nNow, if you are interested in the traveling salesman problem, in general, then the good news for you is that this is very much an active topic of research in computer science.\n(Refer Slide Time: 3:41)\n \nThere was a paper that appeared in 2020, and it gives an improvement that has been long sought after. Despite the fact that the improvement may appear to be small, from reading the abstract, it caused much excitement.\nIf you want to get a sense of the excitement that it generated, I would really encourage you to read this article that appeared recently, at the time of this recording, in Quanta magazine, covering mostly the development around this paper, but also covering a lot of interesting history and trivia about the problem. This tweet about this article really reflects the sentiment of Computer Scientists around Traveling Salesman and shows how deeply we care about it and how fundamental the problem is to the field at large.\n(Refer Slide Time: 4:37)\n\nTraveling Salesman is also a bit of a cult classic. It is made its way into XKCD comics, and other popular culture. If you look at the description of this video, you will find a few links that you might want to look at if you are curious about the problem beyond this very short discussion. But let me just pause here and talk about what would be a natural gradient flow to Traveling Salesman?\nYou are in your origin city, thinking about planning your travels to the N cities on your list, the remaining ‘N-1’ cities on your list. You plan to come back once you are done. The natural thing to do is to perhaps just look at what is the cheapest city to go to from the one that you are at currently. In the first step, from the origin city, you just find the closest city in terms of cost the cheapest city to go to next.\nOnce you are at that city, you just repeat this exercise, making sure that you are only considering cities that you have not already visited as you go along. Except for, of course, when you are done, then the last move is forced because you have to come back to the origin.\nAt any intermediate point in your travels, just find the next cheapest city to travel to that you have not visited already, and then when you are done visiting all these cities once, at the very end, you just pick up the ticket back to the origin city. That is the greedy algorithm.\nI would encourage you to think about whether this would work. Given the nature of this lecture, you already know the answer. What I would encourage you to do is pick up some pen and paper, or whatever your favorite way of thinking is. Just try to come up with a concrete counter-example. For this approach before I show you one.\n(Refer Slide Time: 6:30)\n\nHere is a specific example from the book ‘Design Methods and Analysis of Algorithms.’ If you look at the costs here, let us just try to run through what would happen if we applied the greedy algorithm with the origin city being the city on the top left, which is the city labeled A. From A, the most accessible city is B, and it is a cost of ‘one’ to go there. From B, you have two possibilities, you could go to D or C. It is cheaper to go to D. That is what we will do next.\nFrom D, you cannot go to A, you cannot go to B. These are cities that are already visited. You pretty much do not have a choice at this stage and you have to take this rather expensive edge to C. From C, you return to the origin. The total cost of this tour that is inspired by the greedy strategy is 9 units. If you add up those numbers, you see that it is 5+2+1+1 = total cost of 9.\nOnce again, this is a good place to pause the video and think about whether you can beat the outcome of the greedy strategy. Is there a cheaper tour? If yes, by how much? Hopefully, you had a chance to think about this. It turns out that in this example, the greedy output is indeed sub-optimal. You can do better.\n(Refer Slide Time: 7:54)\n\nHere is, for instance, one way that you could do better. Starting at A instead of being distracted by the most tempting option, which is to go to B, let us take a locally sub-optimal option, which is to go to C first. We go from A to C, then from C to B, then from B to D, and from D to A. These last two moves that are essentially forced. But now if you look at the total cost of the store is going to be 2+2+1+3 = 8, which is better than the tour that we had from the greedy approach.\nYou could think about whether we could do even better. You could think about coming up with examples where the gap between the greedy answer and the optimal answer is perhaps larger because here it seems like just a tiny improvement. You could play around with that aspect of this as well. If you remember, in the beginning, I sort of said that ‘greedy’ fails quite badly for this problem.\nThere are many ways of quantifying the idea of how badly greedy fails, or even the idea of whether a greedy algorithm can be salvaged. In some situations, although the greedy algorithm may not get to the optimal answer, it may get to something that is close to optimal in a way that you can actually prove. These will be greedy approximation algorithms and they are quite common. But the comment we are going to make now is going to be in a different spirit.\n(Refer Slide Time: 9:22)\n \nIt is a remark borrowed from the introduction of this paper, which is titled ‘When the Greedy Algorithm Fails.’ If you are curious to look up this paper, you can find a link to the PDF in the description of this video. But here is the comment which I wanted to bring to your attention.\nIt turns out that there are instances of TSP that you can construct, which are such that the space of solutions is abundant with many optimal solutions. Yet somehow the greedy algorithm will end up finding the unique worst solution. Notice that there is just one worst solution and the greedy algorithm will end up finding that one. You can also ensure that the magnitude by which the solution is worse than the optimal ones is rather large. As you can tell, you can make it as large as you want it to be.\nThis is the sense in which we meant that not only does the greedy algorithm fail, it is not that it misses the optimal solution by a whisker or that it fails occasionally. But this quantifiably demonstrates that you could construct instances, arguably artificially, on which the greedy algorithm can be as bad in its performance as you want it to be.\nAll this is not to say that one must completely disregard greedy approaches, even to TSP. It is conceivable that there are subclasses of instances where the greedy approach performs okay or perhaps there are other heuristics, which are a more sophisticated mix of ‘greedy’ inspired strategies, and other common-sense pre-processing that works well in particular situations. So, this definitely been a lot of work along these lines and you can find out more about it if you were to even read the Wikipedia article on Traveling Salesman.\nThe larger point that we really want to drive home with some of these discussions is the fact that you have to be especially careful with greedy algorithms, simply because it is this dangerous mix of looking like a very tempting approach, and seemingly correct while you really do need formal proof of correctness before you can be absolutely sure. I mean, this is true for any algorithm that you come up with, but greedy algorithms can be especially slippery and we just wanted to make this warning a little bit explicit through some of these examples.\nI will just repeat something that I did say at the start of this week as well. If you are in the middle of a contest, and you are working on a problem for which you have a greedy strategy that appears to be very convincing but you do not have the time to prove it rigorously. Let us say you have tried to think of some quick counter-examples but you cannot seem to find one, then it might be a good idea to just code it up and see if you get lucky with the judges.\nThis would make sense to do, especially if you are not penalized for wrong attempts. It is just a quick sanity check. If nothing else, at least you eliminate an approach. It is usually doable because greedy algorithms tend to be simple enough that they can be implemented quickly. However, at least when you are solving, or you do have more time, I would definitely recommend actually going back and trying to confirm why your algorithms worked whenever they did.\nIf they did not work, then you probably have eliminated an approach and you can move on to the next set of ideas. That is useful as well. With that, it is going to be a wrap for Week 3 on ‘Greedy Algorithms.’ I do hope that you found some of these discussions useful. As always, we will keep the conversation going on the Discord community as well as on the Google Groups mailing lists.\nPlease do send any questions or comments, or suggestions over there. Feel free to leave your comments on this YouTube video, especially if you are watching this video outside an active run of this course. We always look forward to hearing from you. Thank you so much and we will see you next week. It is bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W03/Lec9.html",
    "href": "materials/cpnotes/W03/Lec9.html",
    "title": "M 1 (Pancake Flipping)",
    "section": "",
    "text": "Lecture - 9\nGreedy Algorithms - Module 1 (Pancake Flipping)\n(Refer Slide Time: 00:11)\n\nWelcome back to the third week of ‘Getting Started with Competitive Programming.’ I hope that you are excited about exploring a new theme. In this week, our focus will be completely on greedy algorithms. So, greedy is a fairly broad algorithms design, paradigm, or technique and it is fairly popular in contest programming.\nIn our first module, we are going to be illustrating the technique through a problem called ‘Pancake Flipping,’ which is from the Google Code Jam qualifiers back in 2017. Before we get started though, let me just say a couple of things about greedy algorithms in general.\n(Refer Slide Time: 00:54)\n\nIn most algorithm textbooks, you will find a lot of warnings about greedy algorithms. For instance, here is the table of contents from Jeff Erickson's Algorithms, which by the way, is an excellent reference that goes along very well with the course incidentally.\n(Refer Slide Time: 01:12)\n\nThe warning here is fairly explicit. It says greedy algorithms never work. Well, this is a bit extreme, they, of course, do sometimes work. But the thing to be careful about is that they often do not work despite being very natural sounding and being the most tempting first card approach to a problem. So, for most optimization problems, you will probably naturally come up with a greedy style or a greedy approach to it, which by the way, is essentially characterized by doing whatever you need to do with minimal effort. Whatever seems like the right thing to do, in the moment. I really do not know of a formal definition of what makes an algorithm greedy. Although there are some really interesting mathematical formalisms around characterizing when a greedy algorithm will actually work. If you are really interested in this, then the thing to look up is matroid structures.\n(Refer Slide Time: 01:39)\n\nBut you can completely ignore this comment for now. If you are curious, there are, of course, more links in the description as usual for you to pursue further. But in any case, as I said, at a high level, a greedy strategy is something that feels like the right thing to do locally. But it turns out that long term, this could have ramifications that make your solution suboptimal and that is what happens most of the time. That is why you need more sophisticated techniques like backtracking or dynamic programming or divide-and-conquer or whatever else that help you get through the search space in a more meaningful way.\nBut it turns out that for many problems, even classic ones, greedy algorithms, sometimes, do get lucky and happen to work out all the way. Our goal with the lectures this week is to develop enough of a feel for why greedy algorithms do work when they do by giving you enough reasonably formal justification for the correctness of the approaches that we do discuss.\nOn the other hand, we will also try to go over examples of when greedy algorithms do not work, so that you develop the practice of looking for counter-examples, to see that these strategies that you have come up with might fail. However, during a contest, you might just find it easier to code up your greedy algorithm and see if it actually passes the tests or not. This would be a reasonable thing to do, especially if you do not have penalties for wrong submissions. It may just be the faster approach because greedy algorithms typically tend to be simple and not so difficult to go up.\nSo, you could do that quickly as a preliminary test if you have an approach for which you cannot quickly come up with a counter-example and it seems like it might be promising. However, outside of a ‘contest environment,’ it is definitely a good idea to actually go through the process of trying to understand why your greedy algorithm works or why it does not work.\nThis is also a good time for me to point out that ‘greedy’ being a fairly universal idea will keep coming up in future weeks as well. So, watch out for the reappearance of greedy-based ideas in various other contexts as we go along. With all that background in place, let us finally talk about ‘Pancake Flipping.’\n(Refer Slide Time: 04:26)\n \nNow, normally, I start off with a problem statement. But here I am going to start off with a bit of logistics. I am going to replace the concept of a pancake with a cookie in the entire story, just because it was easier for me to find pictures of cookies. Sorry about that. But I promise you that nothing changes in terms of the mechanics of the problem statement or the solution for that matter. First, let us talk about the two faces of a cookie. You distinguish between the top side and the bottom side of a cookie.\nThe top is going to look like this (center image) throughout the slides and the bottom is going to look like that (rightmost image). According to the terminology in the problem statement, these are called the ‘happy’ and the ‘blank’ sides respectively. The top side has the chocolate chips and it is the happy face and the back has nothing and it is the blank side.\n(Refer Slide Time: 05:26)\n \nWhat is going on is that these cookies are being baked on a single row. It is some sort of long oven thing and the cookies are just being processed in some left to right order. As you can see, some of them are face up and some of them are face down. Our task is to make sure that all of these cookies are face up and we need to flip the ones that are face down for this to happen.\nWhat we have at our disposal is not something that can flip a single cookie at a time and the oven is too hot for you to do that directly. You have to use a flipper. But unfortunately, the only thing you have been given is an oversized cookie flipper. It is something that can flip cookies in batches.\nHere is an example of an oversized cookie flipper of size three. It can flip any three consecutive cookies at once and notice that it flips them one by one. It does not change the ordering of the cookies; the cookies stay in place. You can imagine scooping up the cookies from the front and just turning them over. So, the left to right order is not affected but the state of all the individual cookies basically flips and gets reversed.\n(Refer Slide Time: 06:55)\n \nLet us do another example. Suppose we move the flipper over here and flip again. Notice that we go from being ‘face-down, face-up, face-up’ to being ‘face-up, face-down, face-down.’ As usual, our first question would be, can we always manage what we have set out to do? We have a row of cookies, some of which are face up and some of which are face down. We also have at our disposal this K cookie flipper. So, K is the number of consecutive cookies that can be flipped in one shot.\n(Refer Slide Time: 07:09)\n \nOnce again, remember that the cookies stay in place. The left to right order is not reversed. It is only the individual states that are flipped and they are guaranteed to be flipped. It does not depend on the skill of the person that is using the flipper. The cookies definitely get flipped, they do not drop anywhere, they do not get lost, etc., etc.\nThat is the mechanics of the problem, hopefully, clear at this point. The question I am asking is, can we always do this? I have for your reference the limits that are given in the problem statement. Let us just go over a little bit of notation. The initial state of all the cookies is given by a string S and the encoding is that it is a ‘+’ if it is initially face-up, and it is a ‘-’ if it is initially face-down.\nRemember, face-up is what we call the happy side and face-down is the blank side. What do you want to know is if you can use a K-sized cookie flipper to fix up all of them, which is to say make everybody face up at the end of the day. Take a pause here and think about whether you can come up with scenarios where this task is impossible or with an argument for why even if it takes some time and it is a tedious process, possibly, but you will still always be able to manage.\nHopefully, you had a chance to think about this and notice that there is something interesting going on with the limits for K. We see that K is at least 2 and notice that if K was in fact 1, which is that you have a flipper, which is like an ordinary cookie flipper, it is not an oversized flipper, it lets you flip one cookie at a time. Then, you can always fix any sequence of cookies by just going to the ones that are facing the wrong way and flipping them over. This is probably not such an exciting question anymore and perhaps that is why the range of K is between 2 and something. It is truly an oversized flipper.\n(Refer Slide Time: 09:51)\n \nNotice that when K = 2 already, it is not very hard to come up with an example, where it is impossible to achieve this task. Again, this is a bit of a spoiler alert. If you did not have a chance to pause before, maybe you want to think about this now with this hint in place.\nNotice that even with K = 2, which is the most basic kind of an oversized flipper that you can be working with, you could get stuck with just 2 cookies in front of you. If one of them is facing the right way and the other is facing the opposite way, then no matter how many times you try to flip them over, you will just get them to being in the opposite situation, but it will never really get fixed.\nNotice that you cannot flip something at the edge of the oven. Essentially, once you have reached the last K cookies on this row, you cannot flip anything that is after that because your pancake flipper just does not have enough place to fit in. You can imagine that it is not an open space where it can hang over the edge. You really get stuck at the very end!\nFor instance, just to make this specific. If you are here, then you might think: Let us flip once to fix the state of the first cookie and now from here, let us try to just flip the second cookie onwards. What I was saying is that it is not allowed in the definition of this problem. There is no onwards from the second cookie, if you have a pancake flipper of size 2 or even more. This is not going to work. You will have to flip both of the cookies that you have in front of you in sync and that is why the situation can never be fixed.\nThere are clearly situations that are impossible and our task at a high level boils down to being able to identify these and distinguish it from those cases where there is a feasible strategy for flipping everything over. In that case, our task is also to additionally find the minimum number of flips that we need to make everything work. Before we start thinking about an algorithmic strategy, let us just continue making some preliminary observations. Here is the first question that I would like to pose to you.\n(Refer Slide Time: 12:18)\n  \nDo you think the order in which we make these flips matter? Suppose somebody comes up to you and says, look here is what we can do for this example. We could flip from the first location, then we could flip at the second location, and then we could flip at the seventh location. So, you could try executing these flips and see what happens.\n(Refer Slide Time: 12:43)\n  \nBut then somebody else comes along and says: No, let us flip at the seventh location first, and then go back and flip at the second location, and then flip at the first location. What do you think? Will the outcomes be for these two different ways of doing it? Will the final state be the same or will it be different? If you can think of some other ordering of these three flips, then try that as well and see if you get to a different final configuration.\nMore generally, if you have a set of flips, where each flip can be uniquely pinned down by identifying the position at which the flip begins and once again, remember that your legitimate starting positions are between the first position and the cookie that is at the N-K+1th location.\nAny location in this range is a valid location for you to start off a flip. Now from here, what we really want to think about is whether the sequence in which we perform these flips matters or not. What do you want to do is either come up with an example of a set of flips that can be played out in two different sequences and they lead you to two different final outcomes. Or, you want an argument, which says that no matter which sequence you pursue these flips in, the final outcome will always be the same. Which one is it? Give it a thought and come back when you are ready. Hopefully, you had a chance to think about this.\n(Refer Slide Time: 14:10)\n \nAs usual, let us try to work through this in the context of a specific example. Let us say that we want to perform the flips that you can see come up on your screen. By default, let us say that we just perform them in the order of appearance from top to bottom. Let us also try to live this experience through the lens of a specific cookie.\nLet us just focus our attention on the sixth cookie that is on the table right now, just as an example, and let us try to focus on the experiences that it goes through as you perform these flips. The first flip does affect the cookie. It is going to get flipped; its state is going to change. The second and the third flips do not influence the state of this cookie. In fact, even the fourth one does not touch this cookie at all, misses a set by a whisker. Right now the state of the cookie is just that it was flipped once from the beginning of the process.\n(Refer Slide Time: 15:11)\n  \nThe next flip is going to flip this cookie over again and so is the next one. In all, this cookie has been flipped three times. Notice that the last flip, again, does not affect the state of this cookie.\nAt the end of the day, this particular cookie was flipped three times and that is going to be true no matter what order you perform the flips in. Hopefully, that is clear. Notice also that there was nothing special about the sixth cookie in this list. Whatever we said is true for every single one of them. Therefore, no matter what the order is in which you perform a set of flips, the final outcome is going to be the same, so the order does not matter.\n(Refer Slide Time: 15:53)\n\nAn easy consequence of this observation is the fact that you never need to repeat a flip. Because if you have a sequence of flips, that does something and there are redundant flips or let us just say repeated flips, they are not redundant yet. What you could do is reorder the flip so that all the repeated ones come one after the other. Now notice that all these repeated flips are not really doing any valuable work for you.\nThe only thing that matters is the parity of the number of times you repeated them. If there is a flip that you perform, say 6 times, then that is as good as not performing the flip at all. That will be the same thing. If there is a flip that you perform 7 times, then that is equivalent to performing it just once. So, why would you perform all of these extra flips? Remember that we are trying to minimize the total number of flips that get us to the answer. We know that without loss of generality, we can assume that flips are never repeated.\n(Refer Slide Time: 16:47)\n  \n \nLet us go back to something that we have said before, which is the total number of possible flips that can happen in the first place. Notice that the legitimate locations where you can start to flip are the locations including the leftmost location on the table and all the way up to the N-K+1th location.\nAt the very end, as we said, there is not enough room and further flips are not possible anymore. You have these ‘N-K+1’ possible flips and at this point, you might be tempted to think about a brute force approach to solving the problem. Given that there are only so many flips you can make and given the fact that the order does not matter, the question really just boils down to which flips are you going to make? Because we also know that flips are never repeated.\nWhat is the complexity of a brute force approach based on all the observations that we have made so far? Think about that for a minute and come back when you are ready. The dominant term in the complexity of the brute force approach is going to be ‘2N-K+1.’\nIt turns out that you could just try all possible subsets of locations where you want to actually flip. If you try all of them and then simulate the flips and basically check if everything works out, then essentially, you are going to be trying all possible subsets of a set of size ‘N-K+1’ and that is going to be the complexity. There is going to be a bit of a polynomial overhead.\nBut I have not written that down because this is really going to be, as I said, the dominant term. If you wanted to do it properly, the running time analysis, then you should also account for the amount of time it takes for you to actually simulate the flips and check if things work or not.\nEven without these observations, you could just try to brute force your way through the space of all possible flips using something like a BFS over this space. You could say that two states are adjacent, if say, reachable one from the other via a single flip at some location. I am not going to elaborate too much on the strategy. But essentially, there are other approaches in the spirit of brute force that would also work if you were working with a small data set on this problem.\nHowever, that is not going to scale when you are working with large data sets. We need to think about this some more. This is where the greedy ploy comes into play. Let us think about what is the absolute minimum work that we need to do at every stage.\n(Refer Slide Time: 19:28)\n\nStarting from left to right, let us begin by focusing on the very first cookie that we encounter, which is facing the wrong way. This right here is the leftmost cookie that has a blank side up, and notice that any valid solution will have to flip this cookie. Now in our solution, what we are going to do is position our first flip to start at this location.\nNotice that all the cookies that have appeared before this are facing the right way, just by definition, and it seems wasteful to start a flip anywhere earlier. Because it seems to be just unsettling things that are already fixed. So as they say, let us not fix what is not broken and position our first flip at the location of the leftmost cookie that is facing the wrong way.\n(Refer Slide Time: 20:14)\n \n \nWe start there, then we execute the flips in the program. You could basically simulate these flips. Then you move the flipper along to the very next cookie that is facing the wrong way. You just walk along, stop when you see another cookie that is facing the wrong way, you position your next flip there and you keep doing this till you reach the very end.\nI am not actually executing these flips for you and I will leave this as an example that you can work out. Feel free to pause the video here and, sort of, go through the process. Now let us think about when we would declare an actual answer versus when would we say that the initial configuration is impossible with the value of K that we have been given to work with.\nWhen we finish, when we stop and get stuck, notice that we have actually fixed the states of the first ‘N-K+1’ cookies, just by the way that we have been performing these flips. That is easy to check.\n(Refer Slide Time: 21:17)\n\nThe only thing that remains to check is the state of the last ‘K-1’ cookies. If these last ‘K-1’ cookies are not already facing the right way, there is nothing that we can do to fix them anymore. At this stage, we will declare that this situation is impossible. But if the last ‘K-1’ cookies are facing the right way, then we will say that we are done and we will report the number of flips that we have made.\nNotice that when your algorithm actually outputs a number, it is definitely doing the right thing because we have seen that we only made those flips that we were absolutely compelled to do. We know that any solution and, in particular, the optimal solution also must make at least that many flips and because we have actually demonstrably managed with that many flips because notice that by construction when we are done and we actually output a number, we have also given you a strategy for making a sequence of flips, which will actually fix everything and that is visible.\nWhenever we output a number, we know that we are at par with optimal and we are doing the right thing. The only thing to be careful about is when we report impossible, then we need to be sure that there is no other solution that actually manages to flip everything to its correct position while we just maybe missed out on it because of our greedy choices.\nYou can actually argue that this algorithm does the right thing, even when it reports impossible. I will leave that as a little exercise for you to figure out in terms of what is the logic for why our impossible output is also always correct. If you are stuck on this, then you can go back and look at the notes on the course website and you will find a more elaborate argument then.\nIn terms of implementation, you could exactly implement what we have discussed so far and that will work. It will have a complexity of something like ‘order N2’ or ‘N*K’ because you are doing sort of a linear pass. But within each pass, you are trying to figure out if a flip needs to happen or not and if it does need to happen, you do have to simulate the flip.\nThat is going to be K units of work in every iteration. Now, this is good enough to pass the large data sets. Please feel free to give it a shot and let me know how it goes. In the meantime, let us discuss a small improvement to the implementation that we have just described. What we will do is, trade-off some space for time, which is to say that by keeping track of a little more information, what we will be able to do is bypass the simulation, which forces us to do order K extra work in all those iterations where we do decide to make a flip.\nAs a result, what will happen is that we will end up with a purely linear time algorithm. One that runs in order N, but it uses order N extra memory to do this additional book-keeping. This is an optimization that has also been described in the official editorial and as it is pointed out there, you do not actually need this improvement for the large tests to go through.\nNonetheless, it is a useful trick to be aware of. That is what we are going to try and understand now and this is also the version that we will implement. However, if you do have an implementation of the simulation-based approach and you want to share it with us, then please feel free to initiate a pull request in the GitHub repository where we are maintaining the codes for these lectures.\n(Refer Slide Time: 25:01)\n\nLet us go back to the original state of the array, and once again, begin with the left-most cookie that needs a bit of a nudge. Our overall strategy will still be to have this ‘for’ loop that is running through the initial state array, and the way we will deal with what we decide to do when we have to make a flip will be slightly different from before. Here is the first location where we do need to make a flip.\nThe natural thing is to track this in a flip or an answer variable to remember that a flip had to be made and now in the simulation approach. What you would have done is you would have either flipped the state of the next ‘K-1’ cookies as well by actually changing the state array or you would have tried to keep track of this information in some other auxiliary array by recording number of flips at every location and incrementing them as appropriate.\nNotice that we really want to avoid having to do something ‘K’ times or ‘K-1’ times or whatever. Think about what is it that we really need to know. When we are processing the cookie at the jth location for some ‘j,’ what we really need to know is: How many times is this cookie been flipped so far? A hint to that is in the flip variable - the flip variable tells us how many flips have happened so far.\nThat may not be the number of times that this cookie has been flipped because many of these flips have happened far away and are not relevant for this cookie. What we really need to know is how many of these flips are obsolete for the current variable. I should not say the current variable, but rather the current cookie, the one that is being processed right now.\nWhat we do is we keep an extra array called the ‘obsolete flips array.’ There what we do is, we make a note of the fact that this flip, the one that is the leftmost flip on your screen right now, is one that should not be counted when you are processing the K+1th cookie away from the current location.\nIt becomes an obsolete flip for that cookie. So, when you are processing that cookie in the future, when you look at the number of flips that have happened, you are going to also subtract whatever is being stored in the ‘obsolete flips array’ at that point, to get the accurate number of flips that actually affect this cookie.\nOf course, you might say, look, this flip is obsolete not only for the K+1th cookie from the current location but for all the ones after that as well. Why do not we increment the values in obsolete flips array for all of the future locations as well? Well, we could do that. But that would defeat the purpose of getting to something faster. Because then that would mean actually doing ‘N-K’ amount of work in the worst case.\nSo, we do not want to do that, instead what we will do is, we will just do some sort of a running sum of the number of obsolete flips. In particular, when I land at the jth cookie, I just look at the obsolete flips value of the j-1th cookie. The number of flips that have been obsolete for the previous cookie - they are all certainly obsolete for me as well. Because if those flips could not reach the cookie to the left of me, then they can certainly not reach the cookie at this location ‘j.’\nWe borrow that value from the previous values stored in the obsolete flips array, and then we also lookup whatever was hinted to us from the flip that happened from this action that we are doing right now. That gives us the total number of obsolete flips, which we subtract from the actual number of flips to recover the correct number of flips that this cookie was actually involved in.\nThis may be a little bit tricky to fully understand. Feel free to pause and take a moment here to really absorb this. Hopefully, it will also become clear as we go into the implementation. Before we can get to the implementation though, there is still one piece left that we need to understand.\nOnce we are processing the jth cookie, we need a way to figure out if it needs to be flipped or not. When we were doing simulations, this was really easy, because you just looked at the state of the cookie, because it has actually gone through all the flips that have happened so far. The state of the cookie is reflective of its current state.\nWe know that if it is facing the correct way we can skip it, and if it is blank side up, then we need to flip it. But now what you have is the original state of the cookie from the state array. You have this number which is the number of flips that it has experienced so far, which once again, you obtained by subtracting from the flips variable the ‘obsolete flips’ value.\nBased on these two pieces of information, which is the original state of the cookie, and the number of flips that it has experienced, can you come up with criteria for when you should actually flip this cookie? Take a moment here to think about this because once you have come up with these criteria, you would have a complete description of the algorithm that you need to implement.\nYou just go through the whole set of cookies from the first position to the N-K+1th of the position, do the flips that are necessary, and then you essentially continue doing this for the last ‘K-1’ cookies as well. But this time, if your criteria do trigger and it says, ‘look you have a cookie that needs to be flipped,’ then instead of incrementing the flips variable and proceeding, what you will do is you will break out of the loop and declare that the situation is impossible.\nIf however, your loop survives for the last ‘K-1’ cookies as well, then you can just report the number that you have in the flips variable. That is your entire algorithm. The only piece that you need to fill in is what is the criteria for determining if the cookie that has been processed currently needs to be flipped or not. Once again, to recap, you have the value of the original state of the cookie and the number of flips that it has experienced so far, what would you do from here? Hopefully, you had a chance to think about this. The criteria are actually fairly natural.\n(Refer Slide Time: 31:28)\n\nIf the cookie was plain side up in the original array and the number of flips that it has experienced is even that means all these flips have canceled out. Even at this stage, the cookie is still the wrong way up. You do need to flip it.\nOn the other hand, suppose the cookie was facing the right way, to begin with. But now it has experienced an odd number of flips, then you are in trouble because you have actually broken something that was correct in the beginning. Now you need to flip it again, to fix the situation and bring it back to the ‘happy’ state.\nThat is your criteria for determining whether the current cookie needs to be flipped or not, and as we were just describing before, with this piece of the puzzle in place, you now have the entire algorithm in your head, hopefully, at this point. Once again, if you want to give this shot, this would be a good time to pause this video and try out the implementation yourself.\nThe implementation that we have for you in the video is going to be in Python. We only use very simple data structures and it should be completely straightforward to translate this into a language of your choice.\n(Refer Slide Time: 32:42)\n\nTo begin with, we just read all the input. ‘T’ is the number of test cases and every line is one test case. The first string is going to be a sequence of characters with no spaces, which essentially is composed of pluses and minuses, reflecting the original state of the cookies. Then there is a space and there is a number ‘K.’\nThat is essentially what we are reading in two variables named ‘S’ and ‘K.’ S is going to be a string and K is going to be a number. Let us just use ‘N’ to record the length of the string because that is going to come in useful for stopping criteria, for our main ‘for’ loop. We have N being the length of the string or the number of cookies, to begin with.\nWe also have this obsolete flips array that we just described. To begin with, everything in this array is 0. There are no obsolete flips to record before the process has even started. We also declare an answer variable. In the description in the video, previously, we call this the flips variable. But you could call it whatever you like in this code. This is the answer variable, which has been initialized to 0.\n(Refer Slide Time: 33:58)\n\nLet us do our first ‘for’ loop, which goes from the start of the array all the way up to the N-K+1th cookie. Notice that because we have 0 indexing, you really need to go on the up to the N-Kth cookie. The way range works in Python, it does not actually go to the last number, the last number is omitted. That is why we have ‘j’ in the range ‘0’ to ‘N-K+1.’ This does the right thing.\nThe initial state of the cookie can be read off from S of j; we do that and we store that in ‘state.’ The first thing we do is borrow the obsolete flips from the previous obsolete flips value. Notice that you might get an out-of-range error when j is 0 because what is j-1? This being Python, it is just going to read of the last element in the array.\nThis is an initial condition thing. You could think of it as an edge case. I have not really bothered to say j > 0 because there is no harm, to begin with, every value is 0. What happens in the first iteration really does not do any harm here. In a different language, you may have to be more careful about what happens at the first index.\nIn general, what you are doing is, you are borrowing the number of obsolete slips from your neighbor because all of those flips are obsolete for you as well. Of course, your current value needs to remain anything that has been explicitly pointed out, you need to retain that value as well.\nThat is why this ‘+’ equals, you are not copying the value over. You are using that value to increment whatever value you had in the first place. This correctly records the number of flips that should not be counted for the jth cookie or pancake. The next thing that we want to do is, record the number of flips that are relevant.\nThat is going to be the total number of flips that have happened so far, which has been stored in the answer variable and you subtract from this the number of obsolete flips. That should be fairly straightforward, and this is the number of actual flips that we need to consider.\nIf you remember from a few minutes ago, we had come up with this criteria for whether the current cookie under consideration should be flipped or not, and what we said was that it should be flipped exactly when either the original state was plain and the number of flips is even or when the original state was happy but the number of flips was odd.\nLet us just record these into Boolean variables. If you are writing this code during a contest, you will probably not really do this. You will most likely write an ‘if’ condition straight out. But I think this is easier to read and since we have all the time, right now, we have these descriptive variables here.\nOriginal destroyed is true, if the original state of the cookie was a plus or a happy state and the number of flips is odd, which is to say that you actually destroyed what was correct, to begin with. The other variable is blank, not fixed, which is to say that the original state of the cookie was that it was plain side up and the number of flips is even. We still have work to do here. If either of these variables happens to be true, then we should actually go ahead and make a flip.\n(Refer Slide Time: 37:27)\n\nThe way we record that is to increment the answer by 1 to say that 1 more flip has been made, and equally importantly, we need to go to the obsolete flips array and make a record there. Look at the cookie that is K steps away from the current one and actually K+1 steps depending on how you are counting. Basically, this is the earliest cookie. The cookie with the smallest index not affected by this flip. We do need to make a note of that. That is what we are doing here.\nThe obsolete flips variable needs to be appropriately incremented, as I said, you could also just increment all the values for obsolete flips for all larger indices. But that would be very expensive to do. We are not doing that and instead, we do the trick of borrowing a previous value as we did at the start of this ‘for’ loop. That is essentially the first part.\n(Refer Slide Time: 38:26)\n\nThe second part is to go over the remaining ‘K-1’ cookie. We run the exact same loop, we do the exact same thing. The only difference is that this time, if you realize that a flip needs to happen, then you do not have the facility to actually make it happen. At this point, you have realized that you have an impossible task upon yourself. You declare the answer to be impossible and you break out of the loop.\nNow, if you do survive the loop, then the answer variable does have the right number. You can just go ahead and directly print the answer. There is a string conversion here because Python will probably not print the integer directly. The string conversion will not hurt if the answer was reset to a string and again, I think if you have a language where you have to worry about types, you may be a little bit careful about how you do this. You may need to store extra flag variable or something like that to detect if you went into that breakpoint in the second ‘for’ loop.\nWhatever you have to do is going to be completely straightforward. So with that, we actually come to the end of pancake-flipping. I hope that whatever we discussed made sense. At any rate, the more basic version of the algorithm without this optimization should be extremely doable, where you just go over the state array and simulate all the flips that need to happen.\nJust check if the last ‘K-1’ pancakes got automatically fixed or not. Hopefully, the optimization also made sense and the one thing that I leave you with is for thought is something I have mentioned earlier about trying to convince yourself that whenever the algorithm says impossible, it did not miss some way of doing things correctly.\nWe have already argued that if you output a number, then that is going to be the right number. You just need to make sure that your impossible outputs are also accurate. It turns out that they are, but you need to convince yourself using some sort of a logical argument. So, with that, we come to an end of this video and next time we will talk about another fun problem called ‘Islands War.’ I will see you there and thanks so much for watching as always. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W04/Lec17.html",
    "href": "materials/cpnotes/W04/Lec17.html",
    "title": "M 1 (An Introduction-Part II)",
    "section": "",
    "text": "Lecture - 17\nDisjoint Set Union - Module 1 (An Introduction-Part II)\n(Refer Slide Time: 0:17)\n\nWelcome back to the second part of the first module on ‘Disjoint Set Union.’ Recall that we were working with the disjoint set union data structure, where our goal is to maintain a collection of disjoint sets over a fixed universe of ‘n’ elements, and every set is identified by a unique representative element.\nBecause these sets are disjoint, if an element is a representative, it represents only one set. There is no ambiguity. We want to support the ‘find’ set and ‘union’ set operations, where the ‘find’ set takes one element as input and returns the representative element of the set that this element belongs to. The ‘union’ set takes 2 elements as the input and it merges the 2 sets that these elements belong to.\nIt could happen that these 2 elements belong to the same set, in which case, this is a trivial union, and no actual work needs to be done. If this went by too fast, I hope that you have actually had a chance to watch the previous part of this module, which motivates this data structure a little bit through an example of how it can be used to maintain, for instance, the connected components of a graph and we go through basically what I just said, but a little more slowly.\nIf you have not seen that one, it may be advisable to watch that first. In this part, our focus will be on actually building out this data structure – actually implementing these operations. Let us start at the beginning.\n(Refer Slide Time: 01:41)\n\nRemember, we said that at the beginning, we have these ‘n’ elements and we have their representatives as being really uniquely identified because every element is a singleton and it can only represent itself. There is really no choice. Now, if you are already thinking about the implementation, then a very natural way to implement this would be to have an array, which stores the values of the representatives.\nWe could declare a parent array or leader array, which basically has the following property. The ‘i’th element of this array will tell us the value of the representative element of the set that ’i’ belongs to. This is a very straightforward thing to do and just to account for indexing issues because the ‘i’th element in an array is going to be indexed by ’i-1.’\nI would typically want to declare an area with ‘n+1’ elements so that I can freely talk about the element in the array that is indexed by ‘i’ having the information about the leader of the set that ‘i’ belongs to. This is a small detail – does not really matter – you could also work with an array of length ‘n’ but in that case, in your code, you just have to account for adjusting the indices appropriately. I just feel that this is more natural to read off and we will see that when we get to the actual code.\nBut for now, hopefully, the semantics of the array is clear, to begin with. The array will be initialized in this fashion, with the first element just being 1, the second element being 2, and so on because every element is simply its own leader. Let us see what happens when we do a union.\n(Refer Slide Time: 03:22)\n \nSuppose we take the union of 2 and 7, then either we want to update the leader for 2 to 7 or we want to update the leader for 7 to 2. This is all that we need to do because we are merging 2 singleton sets here. We will come back and think about what the algorithm has to do in general. But here physically, it is enough for me to just change the leader value of 2 to 7 because the only element in the set that contains element 2 is element 2 itself. This is the only update that I need to do if I want to make 7 the new leader.\n(Refer Slide Time: 04:04)\n \nNow, let us say that we have to take the union of 5 and 6. Just as before, I am going to change the leader of the set 5 to 6. This is going to signify the fact that 5 and 6 have now been merged into a single set.\nLet us say that the next union operation is between 5 and 4. Once again, I can achieve this by updating the leader element of the set 4 to 6. I could have equally achieved this by changing the leader elements of 5 and 6 to 4. But I can just visibly see that this is less work. I am going to do it this way. Once again, we will come back to how would you implement this as a general algorithm. This is something that is not yet clear.\n(Refer Slide Time: 04:48)\n \nBut let us just do a couple of more examples here. Suppose you had to take the union of 3 and 6. Once again, I can achieve this by changing the leader for the element ‘3’ to ‘6.’ So, this will have the effect of merging singleton set 3 with the set that 6 belongs to, which coincidentally is also represented by the element 6.\n(Refer Slide Time: 05:09)\n \nLet us do an example of a union, which does not involve ‘leader’ elements. Suppose you want to do ‘union’ 4 and 2. If you just read off the semantics of the union operation, what this means is that we want to merge the set that 2 belongs to with the set that 4 belongs to. The set that 2 belongs to is represented by 7 and the set that 4 belongs to is represented by 6.\nThese sets are the sets 2 and 7 on the one hand, and 3, 4, 5, 6 on the other hand. These are the 2 sets that we want to merge. Notice that this merge is equivalent to merging the leaders. It is equivalent to taking the union of 6 and 7 and one way to implement this merge is to either change the leaders for all the elements in the set represented by 6 to 7 or to change the leaders of all the elements represented by 7 to 6.\nIf you ask me which way I would prefer to do it, given that I can visibly see the sets right here, it is clear that I would prefer to change the leaders of 2 and 7 to 6 as opposed to changing the leaders of 3, 4, 5, 6 to 7 because the latter just feels like more work. However, what would a general algorithm do? Remember, that all you have is access to this array of representatives and now along comes the request for a union.\nYou are supposed to take the union of 4 and 2. By looking up the representative array, you can quickly figure out in constant time that the representative for the set containing 4 is 6, and the representative for the set containing 2 is 7. You can get this information just by looking up the representative array or the parent array.\nBut knowing that these are the representatives, we know that the way to implement this union is to either change all 6’s to 7 in this representative array or to change all 7’s to 6. The only way that we know to do this is to actually go through the whole array. Even if we knew which change we want to make. Let us say we managed to track the sizes of the sets a priori.\nWe know that we want to change all 7’s to 6. But can we actually directly probe all the elements that are 7 in the representative array? There seems to be no way to quickly access exactly those elements. What we would be forced to do is to go through the whole representative array and yes, it is true that the number of updates we perform will be not too many. So, here is our first ‘change.’\nThen we just trudge along and go through all of these other elements. We see that they are not 7. Now we see 7, so we switch it to 6. For the ones that are not 7, we do not need to do anything. That is the entire union set operation. What you would have to do is if you are taking the union of ‘i’ and ‘j,’ using one array look-up, you can figure out what are the representative elements of the sets that ‘i’ and ‘j’ belong to. Let us say that the representatives are some ‘x’ and ‘y.’\nIf ‘x’ happens to be equal to ‘y,’ you do not have to do anything. You can just go home. This just means that ‘i’ and ‘j’ were already in the same set. But if ‘x’ is different from ‘y,’ you have to either change every occurrence of ‘x’ in this representative array to ‘y’ or you would have to change every occurrence of ‘y’ to ‘x.’ This is essentially a way of saying that look, all the elements that were there in the set that ‘i’ belonged to, well we want to now signify that you belong to the set, which is represented by ‘y,’ which is the representative of the set that ‘j’ belonged to.\nWe either make those updates or we do it the other way. But whichever way we do it, even if one of those ways is cheaper in terms of the number of updates we make, just to be able to identify which updates we want to make, we will have to do a pass of the entire representative array. If we do it this way, we are going to get a perfectly valid algorithm and this merger will always happen accurately.\n(Refer Slide Time: 09:11)\n\nBut let us take a look at the complexity of these operations if they are implemented this way. The ‘find’ set is completely straightforward. We just have to look up the value in the representative array. That is just constant time. But ‘union’ set in general will involve one pass over the representative array. Every time we do a union, it is going to cost us ‘order n time.’ It is a linear-time operation.\nSometimes, you may get lucky. If ‘i’ and ‘j’ happen to be in the same set then there will be to find set calls which will detect that and you do not have to do any work. But in the worst case and typically most of the time, you will end up spending linear time doing your unions. Now, it turns out that this is not quite fast enough for the applications that we will be looking at and therefore we need to worry about doing better.\n(Refer Slide Time: 10:09)\n  \n  \nIn the spirit of looking for a better approach let us see if we can store things a little bit differently, hopefully, in a way that helps us cut down on the time that it takes to do the union operations. The key idea here is to essentially think of these elements as pointers. Where do they point to? Every element is going to point to some other element of the set.\nWhen you want to find who is the leader of the set that you belong to, hopefully, you can follow these pointers. Let us say that you want to find a set of ‘i.’ You go to the ‘i’th entry in the array and it is pointing to let us say ’j’ and then ‘j’ is pointing to ‘k.’ You just follow these pointers till you get stuck and, hopefully, the way this is designed is that you get stuck when you arrive at the leader element and that is the information that you want to output.\nFor this to actually work out, you will want the leader elements to point to themselves because that is when you get stuck. If you are a leader element at any stage, then the pointer corresponding to that element is just going to point to itself. In the beginning, when every set is a singleton set, every pointer is a pointer to itself because they have nobody else to point to. This is the natural thing that you do.\nBut as union operations come along, these pointers are going to evolve and if you walk through an example, as we will do here, you will see that visually this is going to evolve in a tree-like fashion and that is a useful thing to aid your imagination. We are not going to explicitly use a tree data structure or anything. It is just going to be an array of pointers. But it is really helpful to see the sets evolve as trees.\nLet us take a look at what happens when we do our first union operation here. As before, let us say we want to do a union on 2 and 7. Initially, 2 was pointing to itself and 7 is also pointing to itself. Now what we want to do is, essentially carry out this union by saying, look, let us have the leader of the first set point to the leader of the second set, or you could also do it the other way.\nAt the moment, let us just say we make this choice arbitrarily. The leader of the set that 2 belongs to is just 2. Similarly, the leader of the set that 7 belongs to is just 7. Let us have 2 become a pointer to 7. That essentially glues together 2 and 7 in one set. Now, let us say that we want to do the union for 5 and 6. Very similarly, let us say that we have 5 now pointing to 6. Now, let us say we want to do the union of 5 and 4.\nWhat are we going to do here? The algorithm is the following. You basically look up the leaders of these two elements. You can do that by running the ‘find’ set and remember, we briefly talked about how the ‘find’ set might work in the setting. When you want to do the ‘find’ set of ‘i,’ you just follow the pointers till you get stuck and you have information about your leader. We will come back and talk about the complexities of these operations.\nBut for now, just assume that you can actually execute them. When we want to merge 5 and 4, we discovered that the leader element for the set containing 5 is 6 and the leader element for the set containing 4 is just 4. Let us have the leader of the set ‘4’ point to the leader of the set containing element ‘5.’ We are going to have a pointer that looks like that.\nSimilarly, if we were to merge 3 and 6, the same story plays out, and let us say that we decide to have the leader of the set containing ‘3’ point to the leader of the set containing 6, which just happens to be 6 in this case. Suppose we are doing a union between 4 and 2. Once again, none of these elements are representatives. But if we run a ‘find’ set, we see that the leader of the set that 4 belongs to is 6, and the leader of the set that 2 belongs to is 7.\nWe are going to have either ‘6’ point to ‘7’ or ‘7’ point to ‘6.’ Either of these would work. Let us say that we have ‘6’ point to ‘7.’ So, 7 is the new leader element, and these sets are now merged. Now, you could think about, whether we could have done it the other way. You could also think about: Do we really need to find the leaders? Cannot we just, for instance, draw a pointer from 4 to 2? Would that not work?\nThese are good questions to ask and I would suggest that you spend some time exploring them thinking about other ways in which you could implement this pointer-based approach. In the meantime, let us go ahead and analyze the complexity of the algorithms that we just described. In fact, let us just recap the algorithms, to begin with, just to make sure that we are on the same page with respect to how they work.\n(Refer Slide Time: 15:07)\n\nFirst, let us say we want to perform a union of ‘i’ and ‘j.’ Then we said that we are going to invoke ‘find’ set on ‘i’ and ‘j.’ Let us say that we have discovered that the leader element of the set that ‘i’ belongs to is ‘x,’ and the leader element of the set that ‘j’ belongs to is ‘y.’ Now what you could do is simply make sure that either ‘x’ points to ‘y’ or ‘y’ points to ‘x.’ Either way, this will achieve what you want, which is that now every element in the set that ‘i’ belongs to will eventually get stuck at ‘y’ as the leader element or the other way around, which is essentially to say that all elements in A ∪ B, where A and B are the sets that ‘i’ and ‘j’ belong to respectively, essentially get merged and have a common leader element.\nSo, let us say that we settle for ‘y’ pointing to ‘x.’ The parent of ‘y’ is now ‘x.’ You can do it the other way, as well as of now not making a distinction between these 2 possibilities. But we will in due course. But that is a bit of a spoiler. Let me not go into that for now.\nNotice that the complexity of the ‘union’ depends on the complexity of the ‘find’ set. Now, in the previous implementation, the ‘find’ set was completely straightforward. You just had to go and look up the parent array or the representative array to figure out who is the ‘leader’ element of the set that ‘i’ belongs to. But now if you try to do this lookup, you might find that you get stuck, which would happen if ‘i’ is a leader element in its own right. Then you get a pointer to itself.\nThat is what I mean by getting stuck or you do not really discover an element directly, but you discover a pointer to some other element. What you would have to do is follow these pointers for as long as you do not get stuck. When you do eventually get stuck, at that point, you could return the element at which you got stuck.\nNotice that you will get stuck at some point because you are working with a fixed collection of elements. Notice the way in which these pointers are introduced, quite importantly you will never have a cycle. This is something that you can show formally. You never go around in a loop and you will always end up at the leader element for the set that ‘i’ belongs to.\nAgain, in the description that we have in these videos here, we are not really digging into formal proofs of the correctness of either the mechanics or the complexities. These are all fairly informal and high-level overviews. If you are really interested in the theory, I would definitely recommend looking up the book chapter that is been linked to in the description of this video.\nBut for now, hopefully, this is enough to get a sense of how the data structure works. We just want to get to the point where we understand enough of it to be able to implement it and just know what the complexities are. As I said, the emphasis here is not so much on the theoretical aspects, but they are definitely very interesting and worth knowing in their own right.\nPerhaps you know them already from a previous course in which case that is awesome. But if you do not and you are curious, then there are resources that you can certainly check out. With all of those disclaimers out of the way, these are the two algorithms for a union set and find set and now let us think about the complexities of these operations.\n(Refer Slide Time: 18:32)\n\nThe complexity of the union set is, well, you have to adjust this pointer – make sure that either ‘x’ points to ‘y’ or ‘y’ points to ‘x.’ That is a simple constant time operation. But it also has two invocations for ‘find’ sets. The complexity of the union set depends on the complexity of the ‘find’ set. But once you have done that, then it is really a simple constant time operation.\nWhat about the ‘find’ set? You are following these pointers around and I would really encourage you to take a pause here and try and come up with a sequence of unions that would force find set to take a lot of time. Do take a moment here to figure that out and come back when you have a guess of your own for the complexity of find set in the worst case.\nIf you thought about that, you might have been able to come up with an example that really pushes find set to take order ‘n’ time. This will only happen once your sets have developed sufficiently in the first few calls to the union. Assuming you are starting with all singletons, your sets are going to be fairly small. All of those find set operations will be cheap just because the sizes of the sets are cheap.\nBut once the sets start becoming bigger, you might end up doing your pointing of parent pointers in such a way that the trees that you develop have a large height. Basically, it is going to take a lot of time to get to the root. One way to improve this situation is if you could somehow guarantee that you are always building out shallow trees where the distance of any node to the root is somehow under control.\nAs we said, it is not very hard to come up with a sequence of operations, which forces find set to take order and time. But let us see if we can do better. One natural heuristic is something that we hinted at in the previous part of this module. We were saying that imagine that you are trying to do a merger between two companies. It is only natural that the leader of the larger company will somehow persist.\nNow, I do not want to simply think of this in terms of the sizes of the sets that are involved, but rather, in terms of the depth of the trees that we have developed around these sets. Remember that as you are building these pointers out, you are really developing a tree-like structure. Let us say that you are trying to merge 2 sets, where the corresponding trees have depths D1 and D2. Now, if D1 is smaller than D2, would you want that the tree which has depth D1 to become a subtree of the tree, which has depth D2?\nIn other words, would you want to have the leader of the first set point to the second set, or would you want to have it the other way around? Think about which one is better in terms of giving you a tree with as small a height as is possible once you are finished. Think about that for a second and once again, come back when you are ready. Hopefully, you had a chance to think about this. Let us try and visualize the situation that is been presented to us.\n(Refer Slide Time: 21:47)\n  \nLet us say we have this abstract cartoon for the 2 sets that we are working with, with these triangles, kind of representing the corresponding tree structure on their pointers. Let us say that the heights of the triangles are representative of the depths of the corresponding trees. Remember that the depth of a tree is sort of the longest path that you may have to endure in going from any vertex to the root.\nThe longest route-to-leaf path would be the depth of the tree and what we were presented with was 2 choices. We could either have the smaller tree point to the bigger one, which is to say that the root of the larger tree in terms of the ones that have the greater depth is the new leader. Or we could go the other way, where we say that the leader of the smaller tree, the underdog element, is the new leader. The larger trees route points to the root of the smaller tree.\nIt could work out in one of these 2 ways. But notice that when we run with the second option what happens is that the overall tree that you obtain has a height one more than the tree that you were working with before. Because you could take the longest path that you had to endure in the tree that had a higher depth and that path is now going to get extended by one.\nThis new tree is taller than the one that you were working with before. On the other hand, if you absorbed the smaller tree into the bigger one, then the paths in the smaller tree do get elongated by one. But because the other tree was bigger anyway, the overall depth does not increase. It seems like a fairly natural heuristic to say that we will make the root of the shallower tree a child of the deeper one. We have the root of the smaller tree points to the root of the bigger one.\nSome people would call this the ‘union by depth’ procedure. Whenever you are taking union, try to do it this way. To actually implement this, you will have to keep track of the depths of the trees as you go along. This is not very hard to do. It is just a little bit of extra book-keeping. But you can argue that if you do this then the heights of the trees that you encounter will always be bounded by log ‘n.’\nI will not go through the argument here, but it is really cute proof. If you want to do it formally, you can do it using the framework of induction. Once again, you can look up the book chapter that is been linked to, if you actually want to go over the proof. This proof is not particularly difficult and if you are curious, you should definitely check it out.\nWhat this ensures is that the complexity of your union operations stays the same because it is still constant + the complexity of the find set operations. But the find set operations now will never take more than log ‘n’ time because your trees maintain the invariant that the depth is always at most log ‘n.’ This is already a pretty nice improvement. But it turns out that you can do even more.\n(Refer Slide Time: 24:55)\n\nLet me describe another really popular heuristic called ‘path compression,’ which says the following. Whenever you are doing find set, you are anyway walking up the stream of pointers. Now, you know that every element that you encountered on this path from the current node that you started off with all the way to the root, all of these elements have the root element as the parent. Why do not we just upgrade all of these elements so that they directly point to the root?\nThat will make this a shallower tree potentially and it will definitely speed up future find set queries not only for the current element but for any element that was there on the path from the current element to the root. Essentially, what we do is that we are going to sneakily update the parent pointers as we go through the journey from the current node to the root. It is not going to take any extra time – not in a substantial way – it is just probably going to be constant overhead from what you were doing before.\n(Refer Slide Time: 26:02)\n   \n  \nIn fact, let us just walk through an example so that it is clear as to what we are trying to do. Suppose you have the ‘find’ set invoked on element 7 here. Let us try to think of the ‘find’ set now as a recursive process. What we are going to do is basically return the current element if it is pointing to itself.\nIf it is a leader that is kind of the base case of the recursion. Otherwise, you are going to return the outcome of the ‘find’ set for your parent because that is really the answer. It is representative of the set that your parent belongs to. You could invoke find set on your parent. Let us do that.\nBut now to implement the path compression heuristic, we are actually not just going to return but once we have the information from this recursive call, we know who the leader element is, just before we are completely done, we just want to update the parent pointer of this element directly to the root of the stream. Let us see how that is going to work.\nWe are going to invoke find set on the parent of 7 because 7 is clearly not a leader element. We are going to temporarily just detach the parent pointer because we know that we want to update it. That directly points to the root. At this point, we still do not know what the root is; The program is going to invoke find set on the parent of 5.\nBecause, once again, 5 is not a leader element. We are going to get into this recursive invocation of find set on 3 and we are going to also detach the parent pointer for 5 because we know that we do not want to point to 3 anymore. We want to directly point to the root and notice that we still do not know where the root is.\nHopefully, we are going to find out in the next step. When you come to 3, once again, 3 is not a leader element itself. It is going to invoke find set on its parent, which is 1, and once again, it is going to set aside its parent pointer in the hope of pointing it to the root of the tree once the find set invocation returns an answer.\nBut now find set invocation has actually hit the base case. So, 1 is the root of this tree. It points to itself even though that point is not drawn explicitly. Your recursion is going to bail out at this point and it is going to say: Okay, I can return 1. Now we do a sort of a backtrace. We climb back down the tree and we know that when 3 invoked find set, it was basically waiting for the outcome of this call so that it could point to whatever the answer was.\nNow 3 will point back to 1. For 3 nothing changed, but we could not be sure about that until we went through the process. Let us put the pointer back in place. For 5, something more interesting happens. It was pointing to 3 before but now that find set has done its job and you know that the answer is 1. We can now point 5 directly to 1 instead of what it was pointing to before, which was 3 and we can also do this for 7.\nFor 7 was previously pointing to 5, but now we know that it might as well point to 1. That is the path compression heuristic and if you want to see it in code, essentially what you would normally do if you were just implementing raw find set without path compression is that you would say if ‘i’ is not pointing to itself, then return find set of the parent of ‘i.’\nBut now since we want to do path compression, we have this small extra step here which is to say that we take the output of the ‘find’ set invocation and we update the parent pointer of ‘i’ to whatever was outward by the find set call. Since this is happening in recursion, as we saw in this example, this will update the parent pointer not only of the element that you started off with but in fact, every intermediate element that you encounter in your journey to the root.\nMaybe there are no elements on this journey. Maybe there are very many of them. It is hard to predict what this looks like. But it definitely feels intuitive that you have gained something. In this example, for instance, any future calls to find set on 7, 5, or 3 would actually run in constant time.\nNow, the question of estimating how much of an improvement this really is, what are your gains from doing this is actually quite non-trivial and if you are really interested and you have some time, then you could roll up your sleeves and look at the arguments that are given in this book chapter from Erickson's algorithms, where there is a fairly detailed analysis of how much of an improvement is guaranteed by path compression.\n(Refer Slide Time: 31:06)\n\nFor us, it is enough to know that this improvement actually gives us effectively constant time for both of these operations. I am using the word ‘amortized,’ which is to say that an individual operation may not run in constant time in the worst case. But if you do ‘m’ of these operations, then the total amount of time that you need is going to be ‘m’ times some constant.\nSome of these operations may require a lot of time. You may have to do a sequence of climbs on some tree. But as you do this, every time you actually pay a price, you are improving your future. The calls that come in later become much cheaper for the hard work that you may have done at a certain step. Typically, the form of what actually happens is that you are going to have a few steps that may be expensive.\nBut this really cleans up the amount of work that you have to do later. Now, even this constant is not truly a constant. What you can argue is that this is some very very slow-growing function of ‘n.’ It is called the inverse Ackermann function. It is a very interesting function to study. But it is also fairly messy to describe. So, in the interest of time, I will not be even defining this function.\nBut the reason I am writing down order one here is: Because the inverse Ackermann function is such a slow-growing function of ‘n’ that it only takes values up to 4, I think, even if ‘n’ is very, very large, even in the billions. For contest programming for the kinds of values of ‘n’ that you are going to encounter, this function is definitely going to just be a very small constant. The behind-the-scenes statement is really the following.\n(Refer Slide Time: 32:53)\n\nIf you have ‘M’ calls to find set – these could be direct calls to find set as is given by your query sequence or these could be calls to find set that are embedded inside the union algorithm – either way, if you are making ‘m’ total calls to find set, then all of that can be executed in time M x αn where α is this inverse Ackermann function. As we said, this is something that we do not need to worry about for the kind of values of ‘n’ that we will be working with.\nSo, M calls can be executed in order M time and that is what we mean when we say that it is constant amortized time per operation. If you are literally in the middle of a specific operation, the worst-case time may not be a constant. It may be that you are in a situation that is bad. But every time you go through a bad experience, you end up doing some amount of clean-up, which helps the future operations along.\nNow the analysis of how exactly this intuition plays out is actually pretty non-trivial and it is a complicated argument. We will not really be getting into it. But if you are really curious about it, then if you have some time, please roll up your sleeves and look at the disjoint sets chapter in the text on algorithms by Erickson. It is again linked to in the description and you can find a fairly detailed analysis of how this bound actually works out.\nThat is what is going on with the ‘find’ set and with the ‘union.’ It is essentially composed of two calls to find set and then one pointer adjustment after comparing ranks.\n(Refer Slide Time: 34:39)\n\nIn fact, that reminds me that I should say that these two heuristics play reasonably nice with each other. Remember, we had a union by depth heuristic before we talked about path compression. Now, when you do path compression, the way that you do the book-keeping for the depths of the trees, that might get messed up a little bit because your trees are becoming shallower and the depths may in fact reduce.\nGenerally speaking, it is a bit expensive to go and re-compute depth. We do not really re-compute depth but we just work with whatever information we have at hand. It turns out that all the claims that we have made work with this combination. Implementing depth in a slightly non-accurate way the best we can and combining it with path compression works out just fine.\nThis is sometimes called ‘union by rank and path compression.’ Just to keep in mind that the depth information that you are storing may not be reflective of the true depth because of the adjustments made by path compression. But it is still a valid upper bound on the depth of the trees that you are maintaining and it turns out to be a good heuristic to use.\nThat is essentially what we are going to do. Just to come back to the complexity of the union operation – you just have to compare the depths and update the depths whenever necessary. When you are merging 2 trees that have the exact same depth, then you would have to increment one of them by one. All of this is essentially constant time operations over and above the two calls to the ‘find’ set. Since the complexity of the ‘find’ set has already been accounted for, you can think of the union operation as really being a constant time operation.\nI will still say constant time amortized because it has these find set invocations involved. But just know that it is the complexity of the ‘find’ set + a constant amount of work. That completes the description of all the algorithms that are involved in the disjoint set union data structure. Now, it is time to take a look at the implementation and we are going to do that in the final part of this module, which is in a separate video. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/W04/Lec16.html",
    "href": "materials/cpnotes/W04/Lec16.html",
    "title": "M 1 (An Introduction)",
    "section": "",
    "text": "Lecture - 16\nDisjoint Set Union - Module 1 (An Introduction)\n(Refer Slide Time: 0:11)\n\nHello and welcome to a brand new week in Getting Started with Competitive Programming. So, this is week 4 and this week we will be talking about problems that can be solved using a data structure that helps you keep track of a collection of disjoint sets. The data structure itself goes by many names. Some people like to simply call it ‘disjoint sets.’ Some people call it ‘union-find disjoint sets,’ and so on.\nWe are going to call it ‘disjoint set union’ because that abbreviates to DSU and that is the most common abbreviation that I have seen when it comes to tagging systems on contest programming platforms. So, the plan is the following. In this module, we will introduce the data structure itself. We will explain what operations it is expected to support and we will talk about a couple of natural ways to implement the data structure, which turn out to be not efficient enough for use in practice.\nWe will then improve it to the professional version, which you can actually go ahead and use in your contests. Now, we will not be actually proving the guarantees that come with these implementations. If you are really curious, there is a beautiful book chapter, which goes over the details, and that is linked to in the description of this video.\nPlease go ahead and check that out. Let us begin by talking about the data structure itself. Notice that the description of a data structure is fully specified once you tell me what information it is supposed to maintain and what operations on that information you wanted to support. So, what do we want to store in a disjoint set union data structure?\n(Refer Slide Time: 02:00)\n\nWell, we want to maintain a collection of disjoint sets, as the name suggests, over some fixed universe. Throughout this discussion, I am going to use numbers from 1 to ‘n’ to denote the elements of my universe. Remember that in a specific application, you may not have numbers from 1 to ‘n’ as your universe; they could be something else. They could be characters, they could be the vertices of a graph, or just something completely different.\nHowever, typically, the elements that you are working with can be indexed by numbers from 1 to ‘n,’ if there are ‘n’ of them. I think this is a convenient abstract notation to work with. Just remember that this may not always literally be your universe, depending on the situation you are working in. Now, each of these sets is represented by what is usually called a ‘leader element.’ Sometimes, it is also just called a ‘representative element.’\nJust think of each set as being labeled by one of the elements in that set. If I want to talk about a specific set in this collection, I will be able to point to it or I will be able to talk about it by simply specifying its leader element. You can think of the sets as being packaged into boxes, each box has a label, and that label is essentially the value of the leader element or the representative element.\nThe leader element could be any element of the set. But what is important is that every set has exactly one of these. Since your sets are disjoint, the leader element completely specifies the set unambiguously. No element can be representing two sets because no element belongs to more than one set. That is the information that we want to maintain. What are the operations that we want to support? We want to support two kinds of operations. Sometimes you might want to support a few more, some routine ones, and we will see that when we get to the implementation.\nBut this is really the crux of it. Given an element, you want to be able to find the set that it belongs to. If I give you a number between 1 and ‘n,’ you want to be able to tell me which set it belongs to, and because of what we just discussed, this basically amounts to returning the leader element of the set that the element ‘i’ belongs to. It could be that ‘i’ itself is a leader element, in which case, we just return ‘i’ as the answer to this query.\nOtherwise, if ‘i’ belongs to a set for which it is not the leader element, then we want to return the leader element of that set as the response to this query. The other thing that we want to do, and it is again hidden in the name, is a union operation. If I give you two elements ‘i’ and ‘j,’ then we want to be able to merge the two sets that ‘i’ and ‘j’ belong to. It is possible that when you are given this query, ‘i’ and ‘j’ happen to already belong to the same set.\nIf that is the case, in this query, we do not have to do anything. But if they happen to belong to two different sets, then we want to be able to merge them. That is the entire data structure. Now, in some situations, you may not know the entire universe upfront and elements of the universe may reveal themselves as a part of some process.\nTo handle such scenarios, you may want to implement an extra operation which you could call ‘make set’ or ‘create set’ or something like that, where the input is going to be a single element and your task will be to create a singleton set out of that one element. I have not written that down explicitly because we will not really be needing this most of the time.\nBut if you are in a situation where you do need it, it is usually very straightforward to implement. You can go ahead and do that as a simple exercise. It turns out that DSU is really useful in a wide variety of situations. Sometimes you can look at a problem statement and by just seeing the structure of the queries, you see that the problem is screaming DSU. It is very clear that is what you need to use.\nSometimes the connection is a little more subtle and you may have to really use your imagination to see that this is a DSU based problem or that DSU would come in handy here. In some advanced problems, you need to use DSU in combination with other techniques. Overall, this is a really useful tool to add to your toolkit. Just to demonstrate, let me show you how you can use this data structure, for example, to keep track of connected components in a graph, if that is what you need to do.\n(Refer Slide Time: 06:53)\n  \n  \nLet us say that you are given that you are working with a graph on some ‘n’ vertices, and to begin with, that is all that you know. All the vertices are just isolated and they form singleton sets on their own right and as you go along, you start getting information about the edges. Whenever a new edge is added to the graph, what you want to do is take the union of the connected components that the endpoints of the edge belong to.\nBecause, now essentially, the two components, which could potentially be the same, in which case, you do not need to do anything, but the two components that the two endpoints of the edge belong to now become connected by virtue of this edge being added. Notice that just in case you had a situation where edges were being added and removed, then it is going to be a bit tricky to use DSU. Remember that DSU only supports union operations. It does not support breakages. It does not allow you to separate the elements of a set once it is been created.\nOnce a gluing is done, it is a little bit like what you see in the Fevicol advertisements. It is permanent and you cannot really separate the set out later. If edges are coming and going, if they are being deleted as well, then you need a slightly different approach. But let us just look at how this would work if edges were only being added. To begin with, every element is a singleton set and it is the leader of its set because there is no choice.\nEvery element is a representative element and throughout this example, we will use these dark black circles to signify that an element is currently a leader element. As we go along, the ones that are not representatives will sort of fade away a little bit. Let us say, that to begin with, we are adding an edge between elements 1 and 2.\nThat gives us this one connected component with an edge. There are just two vertices in it and we can capture this by invoking the union operation on the endpoints of the edge. We combine 1 and 2 into one set and this currently has two representatives, which is a violation of our convention. Let us identify a leader element.\nIn this example, I will be identifying representatives quite arbitrarily. I am not going to evaluate these elements for their leadership skills or anything like that. But in general, you can imagine that if you are trying to merge or take the union of two sets, both of these sets already have their leader elements and when you do the union there are two natural choices for who should be the representative of the new set.\nIt could either be the leader element of the first set or it could be the leader element of the second set. You can imagine that if these are two corporations that are going through a merger, there may be a discussion about which one should persist as the new leader or the new face of the company. It could be that you might want to do a totally bizarre thing of picking some other element from one of the two sets as the leader.\nBut typically, that is not something that we would do because it is usually simpler to just assign one of the existing leaders as the new leader for the set that is obtained after taking the union. In general, it would be perfectly valid to make this choice arbitrarily. But again, thinking about the analogy of the merger, sometimes it may feel like it is natural that the bigger company retains rights to leadership.\nIt turns out that is sometimes a useful heuristic to employ. In fact, it can give you some provable performance guarantees. That is something that we will come back to later. We are getting a little bit ahead of ourselves at this point. As I said, in this example, the choices for leader elements are going to be completely arbitrary. So here, let us go ahead and assign 1 as the leader element. Next, let us say we have an edge between 4 and 3.\nThat gives us this set, which is obtained by taking the union (denoted by the symbol ‘🇺’) of 4 and 3, and once again, let us arbitrarily designate 4 to be the leader element. Next, let us say we have an edge from 5 to 1. So, we will just invoke union ‘5, 1.’ We want to take the union of the set that 5 belongs to, which happens to be a singleton set, and the set that 1 belongs to, which happens to be this component with two vertices.\nNotice that in this example, the endpoints of the edge that you have introduced happened to correspond to the leader elements of their respective sets. This may not always be the case and it is not really relevant. All we need to do is make sure that the sets that these elements belong to get merged and we can do that in this case by just expanding the scope of the set 1, 2 so that it now includes 5.\nAs usual, let us make sure that this set has a unique leader element, and let us say that continues to be 1. Now, let us say that in the next step, we add an edge between 6 and 7. Once again, we invoke 6 🇺 7. That will give us this set here with two elements in it. Let us again make sure that this set has a unique leader element. Let us say that is going to be 7, and now let us add an edge between 4 and 6.\nNotice here that this edge is connecting a leader element with a non-representative element. Once again, it does not really matter. The semantics of the operation is that we need to merge the sets that these two elements belong to and if they happen to be the same set, we do not have to do anything. But that is not the case here.\n(Refer Slide Time: 12:47)\n  \n \nLet us go ahead and merge these two sets to obtain a bigger set with four elements in it. Once again, it currently has two representatives and since that is not allowed, let us make sure that there is just one. In this case, let us say we pick 7 as the choice of representative. Let us say that the next stage that we add is between 2 and 3, and notice that this time, you are actually connecting two elements, which are both not leaders in their own sets.\nOnce again, not so relevant. Remember that our task is to make sure that the set that 2 belongs to is merged with the set that 3 belongs to. Let us carry that out and once we have this merger, we get this one giant component. Again, there are two competing representatives, 1 and 7. Let us make sure that we knock one of them out.\nIn this case, let us identify 7 as the new leader element. Right now, our graph has three connected components: one involving 7 vertices, and then there are two other isolated components. Let us say that now the edge that we add is between 4 and 7. Notice that this has no real effect. For the record, you will want to invoke 4 🇺 7 but what that will do is basically lead to the discovery that 4 and 7 already belong to the same set.\nSo, there is no union. No actual merging is required in this case. This also happens for instance, if you add the edge between 5 and 4. In general, if you add an edge such that both of its endpoints are sitting in the same component, you will of course have to invoke the union operation to respect the fact that you have taken note of the fact that this edge is been added.\nBut when you actually try to execute the union, nothing non-trivial happens because nothing really needs to happen. Of course, until you actually check you will not know. Remember that when an edge comes in, you have no idea what effect it is going to have. It is only when you invoke the union operation that you get to discover if this actually created a non-trivial merger or whether it is just an edge that got added to an existing component.\nThat brings us to the end of this particular example. I will say that tracking connected components are one of the most common applications of DSU. If you can somehow identify that is what is going on in a problem that you are solving, that you can model it somehow as a graph and your task boils down to keeping an eye on the connected components, then chances are that DSU will come in handy somewhere.\nRemember that if the process involves both the addition and removal of edges then what I just described will not quite work and you need slightly different techniques in that setting. But at least if you are in a situation where the edges are just being added, then this would certainly be a very relevant data structure to use. Now notice that in our entire discussion, we did not really talk about how to implement these operations.\nWe just assumed that if we could do these operations then we can track the connected components, as we just described. In fact, we only used the union operation so far. You could use the ‘find’ operation as well to identify which component a vertex belongs to, and with a little bit of extra book-keeping, you could also track additional interesting information about the state of the graph.\nFor instance, you could track the number of connected components. You could also track the sizes of the individual components. You will just have to remember to update them after you perform a union operation. But all of this can be done and once you have the basic data structure in place, these additions are really fairly straightforward to do.\nIn fact, in the implementation that we will see, we will actually track these two pieces of extra information, which is the number of components and the sizes of the sets and we will try to see how they evolve as we perform the base operations. So, let us take a pause here. I will encourage you to think about how you would implement this data structure on your own, especially if you have not seen it before.\nIf you have encountered it before, you probably will find a lot of our discussion familiar. But if you are seeing this for the first time, just spend some time thinking about how you will implement this yourself? What are the complexities of the individual operations? How long will it take you to perform a find? How long will it take you to perform a union?\nI will say that I think there are two fairly natural ways of going about this and I expect that you will probably discover one or both of them. Whenever you are ready, come back and watch the second part of this module where we dig deeper into the actual implementation of this data structure. We will first discuss it theoretically and then we will finally wrap it up with actual code that you can use!"
  },
  {
    "objectID": "materials/cpnotes/W04/Lec18.html",
    "href": "materials/cpnotes/W04/Lec18.html",
    "title": "M 1 (An Introduction-Part III)",
    "section": "",
    "text": "Lecture - 18\nDisjoint Set Union - Module 1 (An Introduction-Part III)\n(Refer Slide Time 00:11)\n\nWelcome to the final segment of the first module on ‘Disjoint Set Union.’ This is the third and the last video in a three-part series. I hope you have seen the first two videos because I do not expect this one to make a lot of sense without the context from there. This is not a standalone video. We are going to actually implement the algorithms that we have already discussed for the two main DSU operations, which are the ‘find’ set and ‘union’ set.\nIf you recall, we discussed a couple of different heuristics. First, we talked about ‘union by depth,’ and then we talked about ‘path compression’ and ‘union by rank.’ Basically, that is what we are going to implement and the specific implementation here is in C++ but it is quite easily adaptable to Python or any other language of your choice. The implementation here is really elegant and simple and it follows the pseudocode quite closely. I think we will have some fun.\nI should say that this implementation is heavily borrowed from the fourth edition of the competitive programming book. Even if you do not have access to the book, there is a GitHub repository that goes with the book and that is freely accessible. You can look that up. There is a link in the description. They have implemented a lot of other data structures as well. This is a really useful reference to have.\nYou will find code and at least Python, C++ and Java as far as I remember, and maybe some other languages as well. This is a really useful thing to bookmark and keep handy. For DSU in particular, if you want to test out the data structures that you implement, Codeforces has a really nice series of practice problems for DSU.\nIn fact, you will find quite a large collection of DSU based problems there. Unfortunately, we will not have enough time to actually go over all of them. But we are going to look at a couple of more examples from this section. Again, I will point you to exactly where you can go. This is not a standard contest. You will have to have a Codeforces account and then you can go to the EDU tab on the top of the navigation.\nThis is the education section and there is one course that covers many different topics. But you want to look out for the one on ‘Disjoint Set Union,’ which in turn has multiple chapters. Just go to the first one and go to the practice section. You will find a customized contest with a bunch of problems. What we will be talking about here will be kind of geared towards solving the first two problems, which are essentially just asking you to implement DSU.\nThat is the first problem. It is asking you to implement, basically find and union, and also this extra operation which asks you if two elements belong to the same set or not. We are going to look at how to take care of that. In the second problem, it is very similar, except that you are also asked to be able to not just find the set that an element belongs to but you are also asked to return the minimum and the maximum elements from that set.\nThat is the extra book-keeping that we need to do. We are going to discuss both of these problems in this video. But before that, let us actually implement the basic data structure.\n(Refer Slide Time: 03:31)\n\nWe are going to do this in an object-oriented style. You are free to just directly implement this using global arrays or, whatever your preferred method is. But this way, you essentially open up a convenient interface and this becomes code that you can just set aside and invoke quite easily when you actually needed in specific contest problems.\nThis is the style that we are going to adopt. The UnionFind class is going to have a bunch of things. It is going to have a vector array, which is essentially going to store the information about the parent pointers. It is also going to try and store the rank and the sizes of the individual sets. The information in the rank and the set sizes array will evolve to being relevant only for the leader elements. We will see how that works out. We are also storing a little bit of auxiliary information in this integer numSets, which essentially keeps track of the number of sets that we are working with.\n(Refer Slide Time: 04:37)\n\nNow let us look at the public methods. First, we have the constructor, which is going to initialize your object with sensible values. Let us say that you initialize UnionFind with N, which is to say that you want to keep track of N elements. I will come back to this where, as I said to not have to worry about indexing issues if I want to do a disjoint set union with the universe of size N. I will typically instantiate this with N+1 just so that I can freely talk about the element at the ‘i’th index actually being the element ’i.’\nWe will see that when we get to the main function. But suppose we are doing UnionFind with N elements, then what we want to do is initialize a parent array of size N. In this case, this is a vector with N elements. To begin with, remember that these are all singleton sets. We want all the leader pointers to just be pointing to themselves.\nSo, p[i] = ‘i,’ for all ‘i’ from 0 to N-1. Now, the rank tries to keep track of the heights of the trees. As we said because we will be doing path compression, this is not really exactly the depth of the tree, but it is a useful upper bound to work with nevertheless. To begin with, all your trees are just basically one root element. We going to adopt the convention that these trees have depth 0, to begin with. All sets initially are singletons. They all have size 1.\nWe are going to assign a value of 1 to every element in the set size vector and finally, the number of sets that we are working with initially is, in fact, N. Because remember, to begin with, every element is just a singleton set. There are N of these sets. We going to initialize the numSets variable to N. That is all of the initialization work.\nRemember that in a particular application, you might want to track more information. If you do add more stuff here to your class, just make sure that it is properly initialized. Because if not, you might run into all kinds of runtime errors and memory allocation issues. This is simple, but it is really important. So, just double-check that everything that you are trying to keep track of is properly initialized.\n(Refer Slide Time: 07:09)\n\nNow, with this out of the way, let us talk about the first operation that we want to implement, which is the find set operation. The first thing that we want to check for find set – remember that we are doing path compression here, and this is a recursive implementation. So, the first thing we want to check is if we are already working with a leader element. That check is just to see if the pointer is pointing to itself.\nIf the element is pointing to itself, then we can just return that element. That is the first ‘if’ branch out here. But if you are not in this nice base case, then you need to actually walk up the tree. So, one step at a time, let us go to the parent and try to invoke find set on the parent and this is going to give you the value of the root of the tree. Remember, in path compression, we want to actually assign this root as the new parent of the element ‘i.’\nSo, that is what is happening here when we say p[i] = findSet(p[i]). So, that is finding the root and reassigning the parent of ‘i’ all at the same time. This is also what we are going to return. All of this is combined in this succinct one-liner. You could write this down a little more explicitly. But this works out just the same.\n(Refer Slide Time: 08:35)\n\nNow before we move on to working with the union implementation, let me write down a small helper function, which will be useful both for the union as well as for the specific problem that is that on Codeforces. So, this is called the isSameSet function. So, isSameSet will return true if ‘i’ and ‘j’ belong to the same set and will return false otherwise.\nNotice that figuring out if ‘i’ and ‘j’ belong to the same set basically boils down to asking if ‘i’ and ‘j’ have the same leader element. So, it is possible that one of ‘i’ or ‘j’ themselves are leader elements. That is not particularly relevant. All we have to do is invoke the findSet on ‘i’ and ‘j’ and check if the outcomes of the findSet are identical on both ‘i’ and ‘j.’\nIf it is, then i and j do belong to the same set and if it is not, then they belong to different sets. So, hopefully, this is clear. This follows just by the definition of the way representatives work and the promise that the findSet does its job properly. So, that is isSameSet.\n(Refer Slide Time: 09:31)\n\nNow, let us go on to talking about the ‘union’ set. When you want to take the union of the set that ‘i’ belongs to with the set that ‘j’ belongs to, the first sanity check is to see if the sets are the same or not. If the sets are the same, we do not have any work to do. So, we just check if i and j are in the same set and if so then we just do not do anything. We return.\nOtherwise, remember that with the union, we want to just make sure that the parent pointers are carefully adjusted based on the rank heuristic. First, let us find the leader elements of the sets that i and j belong to. Let us call them x and y respectively, and let us make sure that x is always the element that has the smaller rank that belongs to the set whose corresponding tree has a smaller rank (where rank is going to be some sort of a proxy for the depth).\nIf the rank of x is larger than the rank of y, we make sure to swap the two and after this, we can peacefully make sure that x points to y, given that y is the root of the bigger tree in terms of the notion of rank. So, we go ahead and adjust this parent pointer. Notice that the rank does need to be updated if you are combining two trees that have the same rank.\nOriginally, when we were working with depth and we did not have path compression, this would have been a legitimate reason for increasing the depth. If these two trees have exactly the same depth and one of them points to the root of the other, the final tree has a larger depth than before. We are going to do just the same with the rank value.\nIf you are combining two trees that have the same rank, then you increment the rank of the tree that you just generated. Remember, this tree is being tracked by y. That is the current leader element. That is the current root. You make sure to increment the rank of y. Remember that we were also tracking the sizes of the individual sets and the total number of sets. Both of these values are affected by the union operation.\nThe size of the set that y is representing has now been enhanced, and it has a few extra elements. How many extra elements does it have? That is as much as the size of the set that ‘i’ belong to, which is, in turn, the set that used to be tracked by x. We just go and look up the set size of x and update the set size of y.\nNotice that the set size of x is now not giving you accurate information about the size of the set that x belongs to because now x also belongs to this larger set. But this does not matter because when you want to find out the size of a set that some element belongs to, you will not directly look up its set size. But you will look at the size of the set of its representative element.\nThat is why it is okay that some of the values in the set size array are not going to be completely accurate. What is crucial is that they are accurate for the leader elements. Whoever qualifies as a leader element in the current scenario, the set size information should be valid there. That is why we have this update here.\nWhat about the number of sets where you have just merged two distinct sets? That number goes down by 1. Notice that this does not happen if i and j belong to the same set and this code will not execute because you have already returned the control flow back to the main function, if that were the case on the third line in this code snippet that you see on your screen.\nThat is essentially union set. You want to just go back and check that everything that you were tracking has been appropriately updated as it needs to be. I believe we have more or less covered everything. This is the implementation of the ‘union’ set.\n(Refer Slide Time: 13:27)\n\nLet us just write a couple of small helper functions. As I was mentioning earlier, if you want to find the size of a particular set, you do not just return the value in the set size array. But you actually go to the set size array as indexed by the leader element of the set that ‘i’ belongs to. So, you do the findSet of ‘i,’ and you do the set size of that element. That is what you return. If you wanted to know how many sets are right, now you can simply return numSets. These are two useful helper functions to have.\n(Refer Slide Time: 14:00)\n\nNow if you were solving the first problem in the Codeforces contest that I mentioned, which is also linked to in the description, then essentially what you are given is a sequence of queries, which are either union queries or same-set queries. Essentially, you just have to perform a sequence of unions, and sometimes in between, you get this question – Are these two elements in the same set or not? Essentially, this is how you would implement it.\nGiven that all the work has already been done for you, this implementation should be straightforward to understand. In the first few lines, this is pretty typical. We are just taking in the input. Notice that I am initializing UnionFind with size ‘n+1.’ This is once again so that I can conveniently think of the ’i’th index is tracking the ’i’th element.\nIf you were to initialize this with ‘n’ then you would have to remember to adjust for the indexing a little bit. Because even the notation in the input is that the elements are from 1 through n. If the elements were being denoted from 0 to ‘n-1,’ then you would not have to make this adjustment, one way or the other.\nThat is, again, a small detail, but an important one because it is the sort of thing that can be annoying to debug when it does not fall in place correctly. So, I just wanted to flag that. But apart from that, everything else is pretty routine. You read off your queries and depending on whether it is a union query or a same-set query, you invoke the appropriate functions.\nFrom here, it looks like we never really use findSet in spite of implementing it. But notice that both ‘union’ set and ‘isSameSet’ actually make use of findSet in their implementation. Really, everything that we have written is more or less being used, except for some of the helper functions. Those are not really coming into play in this particular example. But again, it is useful to have them because you might need them depending on the situation.\nThat brings us to the end of the first exercise. The second one is actually very similar. It kind of builds on this and just asks for a little more information. Just like here, you have a bunch of union queries. But now you also have these ‘get’ queries in which you are given one particular element and your task is to return the size of the set that this element belongs to. We have already implemented this by the way with the set size helper function.\nBut apart from the size of the set that this element belongs to, you are also asked to output the value of the largest and the smallest elements in the set that this element belongs to. So, let us just briefly outline how you would handle something like this. I am not doing this from scratch but I am just showing you the extra information that you would need to store to be able to output the values of the largest and the smallest elements in any of the sets.\n(Refer Slide Time: 16:58)\n\nTo begin with, let us add the maxSet and the minSet vectors to the class definition and although I am not showing it here, you should remember to initialize them properly. So, maxSet and minSet of ‘i’ will both have the value ‘i’ because you are working with singleton sets. The maximum and the minimum elements are both equal to the only element that you have in that set. Do remember to do that in the initialization function in the constructor.\n(Refer Slide Time: 17:25)\n\nAlso add these helper functions where you are returning the values of the maximum and the minimum elements by not directly returning the value, just like we saw with the set size array, the values at ‘i’ may have become meaningless over time but you will be tracking them correctly for the leader elements.\nTo find out the maximum value in the set that contains the element ‘i,’ first find the representative element of the set that contains ‘i’ and then look up maxSet for that element and this is analogous for minSet. We have these two very simple helper functions, which will give us the values that we want. You can invoke them when you are writing down your output and the main function.\nAgain, I do not show the main function explicitly because this is a really straightforward addition. In any case, if you want to see the entire code, you can always go to the official GitHub repository and look it up there. The one thing that is very important to do is to update the values of maxSet and minSet for the leader elements when you actually implement the union. Notice that these values are not affected when you do things like findSet because nothing about the structure of the sets changes when you do findSet.\n(Refer Slide Time: 18:40)\n\nBut when you do ‘union,’ then the values of the max and the min can change. So, when you are doing union, remember that we had x and y as being the leaders of the sets represented by i and j. Once again, if x = y, you do not need to do anything because the set itself does not change. There is no union that is really happening. We do not have to worry about that case.\nIn the other case, when you are actually merging two sets, remember we said that we will set p[x] to y. The set that was being tracked by x is getting absorbed into the set that is being currently represented by y. We do have to update the values of maxSet y and minSet y to account for this new information. These newly added elements may actually upset the old max and min values.\nThat is essentially what these two lines of code are doing. It is very simple but it is crucial to ensure that you maintain correctness as you go along. Look at the maximum element that was there in the set that was being tracked by x and if that is larger than the maximum element in the old set that was being tracked by y, then the max set of y should be updated so that it reflects this new element as the maximum.\nHowever, if the maximum was smaller than the maximum element of the set being tracked by y previously, then you do not need to change anything. You could write this down as an ‘if-else’ block. But it is equally accurate and perhaps visually simpler to just take a max of the two old maxes, and similarly, for minSet, you take min of the older mins.\nHopefully, this update makes sense and this ensures the accuracy of the maxSet and the minSet arrays at least on all the elements that are representatives at any stage of the algorithm. That brings us to the end of this discussion on basic DSU implementation. Now, that you have your own version of DSU, you are prepared to tackle problems that use this data structure.\nThese two problems that we have discussed so far were very explicitly asking for a DSU implementation. Many problems have the DSU demand kind of hidden away in a more subtle way. We will see a couple of examples of problems where DSU comes in handy. But it may not be completely obvious that that is what you need to invoke.\nThere will be links to a lot of practice problems that you can try out on the course website. But in the meantime, for the rest of this week, we will look at a couple of different problems quite explicitly. In the meantime, I hope that you have a chance to try out everything that we have discussed so far. As usual, if you have alternate implementations in Python or Java or any language of your choice, please do make sure to submit a pull request on the official repository.\nI look forward to seeing your submissions, and we will keep the conversation going on Discord. Thanks so much for watching so far, and I will see you in the next video. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W04/Lec19.html",
    "href": "materials/cpnotes/W04/Lec19.html",
    "title": "M 2 (Destroying Array-I)",
    "section": "",
    "text": "Lecture - 19\nDisjoint Set Union - Module 2 (Destroying Array-I)\n(Refer Slide Time 00:11)\n\nWelcome back to the second module of the fourth week of ‘Getting Started with Competitive Programming.’ As you know, this week, we are focusing on the ‘Disjoint Set Union’ data structure and its applications. In this module, I want to tell you about a problem called ‘Destroying Array,’ which is something you can again find on Codeforces. There is a link in the description as usual.\nThis was the third problem in an Intel Code challenge elimination round. It is rated at about 1600. Certainly, ‘disjoint sets’ are not the only way to approach this problem. In fact, I think even the official editorial gives a slightly different approach, which you can go and read up on if you are interested.\nBut the reason I chose this particular problem was that – First of all, it is not obvious that you could use disjoint sets. But there is a small trick, which if you use, then it becomes quite transparent how disjoint sets could be helpful. This is a trick that is, I think, more widely applicable. I thought this would be a cool problem to exemplify it. So with all that said, let us get started with the problem statement.\n(Refer Slide Time: 01:18)\n\nThere is no story in this problem. It is just a straight-up description of a process. You are given an array, which has ‘n’ numbers, which we are going to denote from ‘a1’ through ‘an.’ I think it is important to note that these are non-negative integers. That is something that will come into play later. What is going to happen is that you are going to, as the name of the problem suggests, destroy the elements of this array one by one.\nYou are given a permutation of 1 to n, which tells you in what order you are going to destroy the integers of this array. We will probably make more explicit what this means through an example. Essentially, imagine that you are just deleting the elements according to this permutation, notice the one-based indexing.\nFor instance, if you had a1, a2, a3, and your permutation was three to one, then after the first step, your array would look like a1, a2. After the second step, it would look like a1, and at the third step, there is going to be nothing left. In general, once you are completely done, you have executed all the ‘n’ steps, your array has become completely empty. As I said, we will go through a more elaborate example in just a bit.\nIt will be one of the sample inputs that we will try to break down and observe closely. But let us figure out what is the task. What are we supposed to do with this information? At every stage what you are supposed to figure out is what is the largest surviving contiguous segment of elements that has the maximum possible sum.\nSo you can imagine that as you kill elements in the array, your array breaks down into contiguous chunks of integers. Each of these chunks is going to have a certain, let us call it weight, that is the sum of all the elements in that chunk. We want to figure out what is the heaviest junk that exists at every stage of this destructive process. Let us go through an example and I think all of this will become a little bit clearer.\n(Refer Slide Time: 03:31)\n\nFor instance, let us say that here is the input array. That is denoted in black. All the black circles are the input array. The elements in red are the permutation of the sequence in which the destruction is supposed to happen. The elements in blue are just there for reference; That is the indices of the elements of the array. Remember, we are working with numbers ‘a1’ through ‘an.’ We have one-based indexing. This is just a reminder that that is the case.\nLet us go through the process here. The first element that you are supposed to destroy is the fifth element and we know that that is the number 6. So that is gone.\n(Refer Slide Time: 04:14)\n \nThis leaves us with two chunks, whose sums turned out to be 18 and 16. You can pause the video and confirm for yourself that that is the case. In fact, speaking of pausing the video, if you want, you can pause the video and try to work through this whole example yourself once and then come back and exchange notes.\nFeel free to do that now if you would like to. But in any case here you have two chunks. The first one adds up, I think, to 18 and the second one adds up to 16. The answer at this stage is going to be 18 because that is the heavier chunk.\n(Refer Slide Time: 04:51)\n \nIn the second step, you are supposed to destroy the second element in the array. That is the second 5 there and now this breaks up into three chunks and the weights of these three chunks are 5, 8, and 16.\nThe new maximum is going to be 16. Notice that the maximum chunk, the heaviest chunk that we had in the previous step, got fragmented into two pieces. It is now no longer the ruling chunk and the correct answer at this point is going to be 16\n(Refer Slide Time: 05:22)\n \nNow the next element that is supposed to be deleted is the 8th element. It is the last element of the array. We have three chunks in the weights are 5, 8, and 11. The answer at this stage is 11. The next element to be deleted is the 7th element, and we still have three chunks but the weights now are 5, 8, and 6. The answer at this stage is 8.\n(Refer Slide Time: 05:33)\n \n \nThe next element to be deleted is the first one that completely annihilates one of the chunks. We are left with two chunks now of weights 8 and 6. The answer actually does not change. The previous, the heaviest chunk from the previous step still dominates the situation. The answer is still 8. The next element to be deleted is the element at the third index.\n(Refer Slide Time: 06:06)\n  \nThat is the first four; That is gone. Now we have two chunks of weights 4 and 6. The answer at this point is 6. The next element to be deleted is the one at the fourth index. Now you are only left with one chunk. There are no comparisons to be made and it so happens that the answer actually did not change from the previous step and it remains 6.\n(Refer Slide Time: 06:29)\n\nOnce this last element is gone, there is really nothing left in the array, and the answer is going to be 0. This is what we are required to output – this sequence that you see here: 18, 16, 11, 8, 8, 6, 6, 0. We are supposed to output the sequence of numbers, one on each line. That is essentially the goal of the problem statement. I hope that the statement itself is clear at this point.\nAgain, you might want to pause and think about how would you approach this. A first cut solution is going to be to just simulate the process. But if you go and look at the limits, you will see that the array itself has 106 elements potentially. The numbers themselves range from 1 to 109, I believe.\nIf you work out how expensive it is going to be to simulate the whole process, you will see that that is actually not going to work out. You need something slightly cleverer. Also, I think when we were talking about disjoint set union, I also said that this is inherently a constructive process. You have the sets and you put them together. If you have a process that is instead of breaking things apart, then that is not perhaps so well suited for a disjoint set union.\nI said this in the context of graphs. For instance, when we were trying to track connected components, we said that if you are bringing edges into the picture, then components are building up and gluing together. That is very naturally modeled by DSU. But instead, if you had edges also being deleted, then these breakages are harder to model. It feels less natural. We seem to have a similar situation here.\n(Refer Slide Time: 08:11)\n \nIt looks like we have an object, and the object is falling apart. How would we really hope to use DSU in this sort of setting? Remember, I mentioned that there is one trick that makes it somewhat transparent as to how DSU could be relevant for us here. I am not sure if it is reasonable to ask you to guess what this trick might be. But a hint would be: Think about what happens when you play a video back in reverse.\nImagine that you go through this whole process. But in fact, you could perhaps pause the video here and see what happens if you were to play it back in reverse. To be honest, I have no idea what that would look or sound like, probably a bit weird. But a picture may emerge that might help you think about how DSU would be relevant to this problem. So take a moment here, think about this and come back when you are ready.\nLet us follow through on the hint and see what happens if we actually run the process in reverse. Instead of removing things from the array one by one, what we will try and do is see if we can put things back into the array one by one, but in the opposite order of the destruction sequence that was given to us in the input. Now the visual is that instead of a process that breaks things apart, we have a process that puts things back together. At the very end, you have actually reconstructed your entire array.\n(Refer Slide Time: 09:48)\n\nLet us go back to the example and see what happens when we run the process in reverse order. By the way, you do not see any of the array elements here because we are going in reverse. At the very end, remember that the array became empty. Nothing is really available to us, to begin with. The last element to be deleted will now be the first one to come back into the picture.\nThe last element to be deleted was the one that was at the sixth index. That happened to be the number 6. Then the last but one element that was deleted, which is the next element that needs to be put back is the one that happens to be at the fourth index, and then the one at the third index, and then the one at the first index, and so on and so forth. I am going to build out the rest of it.\nHopefully, you can already see why this can be treated as an instance of disjoint sets. In a sense, the stuff that you are bringing back, either ends up being a singleton set, if it is in an isolated part of the array, or it ends up either extending the chunk, or it ends up merging two chunks. In some sense, that is how the introduction of a new element ends up adding to the landscape of the collection of sets that we have maintained so far.\nAt this point, you probably have enough of a picture of what is happening to think about whether you can build out a complete solution for yourself. If you would like to do that this would be a good time to pause, try it out, and then come back when you have given it a shot yourself. But in the meantime, let us continue our journey here. I think we stopped with restoring the element in the first position.\nThe next one to restore is the element at the seventh position. Notice that this is just extending a previous singleton element so that it is now a set of size 2, then when we put back the eighth element, this gets extended further and becomes a set of size 3, then when we put back the second element, it actually merges a singleton set with a set of size 2.\nWhen we put back the last element, it is no surprise that the two chunks that we had essentially get merged into this one giant set, which consists of all the elements. At this point, we have completed our rundown of the entire process, but now in reverse order. Let us think about how we are going to use a disjoint set union to track the progress that we are making when we go in reverse. Let me highlight the main ideas that are involved here.\n(Refer Slide Time: 12:29)\n\nFirst, as we have been saying, we run the operations in reverse order. The next thing is that we use union operations to appropriately keep track of sets, which is to say that when a new element comes in, we have to figure out if it is isolated, or whether it is extending a previous chunk, or whether it is merging two chunks. These are the only three things that can happen.\nIf you maintain a state array, which tells you which elements are currently present in the array and which elements are not, it will help you make a distinction between these three scenarios. So in particular, if you add an element at the ‘i’th location, and both the ’i-1’ and the ’i+1’th locations are empty, there is nothing in there, then this newly added element is just going to be a singleton set.\nFor this situation, we will actually go ahead and add a makeSet operation to our UnionFind class, which is something that we did not do in the previous video. But in this situation, it just makes things convenient to be able to create singleton elements as and when they appear. The other situations could be that you have an element being added at the ’i’th location, and exactly one of its neighboring slots is occupied and the other one is empty.\nSo either ‘i-1’ is empty and ‘i+1’ is occupied, or the other way around. In both of these cases, we need to execute one union operation to account for the fact that one of the older sets is now getting enhanced with one new element. The final scenario that could arise is that both neighboring locations are occupied from before. So both the ‘i-1’ and the ’i+1’th locations are non-empty.\nIn this case, the introduction of the element at the ‘i’th location is going to actually merge two sets from before. To account for this, we will have to do two union operations, one for ’i’ and ‘i-1’ and then ‘i’ and ‘i+1.’ This will have the desired effect of capturing the full merge. That is actually all the cases but if you want to run off and code this up right now then just be a little bit careful about accounting for the corner cases properly.\nIf you are at the extreme ends of the array, then watch out in terms of probing the ‘i-1’ or the ’i+1’th locations, which may not exist depending on where you are in the array. So after counting carefully for these edge cases, I think you should be in a good place in terms of capturing all the actions that happened. But remember, you still need to output the value of the heaviest chunk.\nFor this, you need to do some extra book-keeping. You need to keep track of the sums of these sets as well. Remember, previously, we have done things like tracking the sizes of the sets and the maximum elements, and the minimum elements. This is just a different quantity to keep track of. We will introduce an extra array, which helps us track the sums of the sets, the sum of the elements in any of these sets.\nRemember that this needs to be properly updated when you execute the union operation. When you have, let us say, x pointing to y, what do you want to do is that the sum set value of y should be incremented with the sum set value of x. That is something that you do need to put on the record. With this, I think you probably have enough hands to go ahead and implement this yourself.\nFeel free to use the DSU class code from the previous module as a starter file and kind of build on it based on what we have discussed so far. You could come back and exchange notes with the implementation that we will discuss separately in the implementation video. I will see you there and that will be all for now. Thanks for watching, have fun implementing this, and do let us know how it goes!"
  },
  {
    "objectID": "materials/cpnotes/W04/Lec21.html",
    "href": "materials/cpnotes/W04/Lec21.html",
    "title": "M 3 (War-I)",
    "section": "",
    "text": "Lecture - 21\nDisjoint Set Union - Module 3 (War-I)\n(Refer Slide Time: 00:11)\n\nHello, and welcome to the third and the final module in the fourth week of Getting Started with Competitive Programming. As you know, this week, we have been talking about applications of the Disjoint Set Union data structure. As our final example, I want to talk about a problem called ‘War.’ You can find this on the UVA online judge. The problem ID is 10158.\nBut you do not really need to remember that because, as usual, a link to the problem statement is in the description of this video. This problem is also available on a platform called UDBug, where you can find additional test cases and hints and things like that. The link to that is provided in the description as well. Do check it out. Now, this problem has several things going on. Apart from an interesting story, there are a few different concepts to keep track of.\nYou might find that the description is a bit longer than usual. In fact, I think in terms of just the number of lines in the code for the solution to this problem, this is probably the longest that we have seen. Actually, conceptually, it is a really clean problem once you get the hang of it. But I will say that it is a bit non-trivial. It takes some time to fully absorb all the moving parts and all the cases that are involved.\nPlease be patient with this. It might take you some time before you can write everything out, especially if you like to write the solution out yourself before you follow along. Give yourself some time to make sure that you get all of the scenarios pinned down correctly. With that said, let us begin as always by taking a look at the problem statement.\n(Refer Slide Time: 01:55)\n  \n \nWe are given that there are ‘n’ people who are present at a party or something like this. That context is not so important. But what we are given about these ‘n’ people is that each one of them belongs to one of two countries. People who are from the same country - so here I have coded the two countries with a maroon-and-black background - so for people who are from the same country, they are all friends with each other.\nHere we have a group of five mutual friends on the one hand, and then three mutual friends on the other hand. Using the terminology from the problem statement, people who are from different countries, so if you pick any pair of people who come from different countries, we think of them as being enemies. Now, that is a pretty strong word. I might just call them rivals instead. We have these friends, and we have rivals.\n(Refer Slide Time: 02:55)\n  \nThat is the information that we are given, to begin with. But the interesting thing about the setting is that you do not actually know who is from which country. You have walked into this party and you see these ‘n’ people, and you do not really know who are friends and who are enemies and so on. The story goes that by observing people’s behavior at this party, by looking at how they are talking to each other, how they are interacting, and so on - who is getting into a fistfight? Who is exchanging pleasantries? - you can figure out, or you can make a pretty good guess about which pairs of people are friends and which pairs are enemies. Of course, you do not get to know all of this upfront; you have to spend some time at the party to infer more and more information. The way this is given to us is that as you spend time and you start inferring this information, you sort of make a record of it in your notebook or whatever.\nLet us say that you observe two people who are hanging out and having a good time. Then you decide to make a note of the fact that they are friends. This is given to you in the form of a query. You should not call this so much a query because it is not asking you for an answer. But this is something you can think of more as an operation. You just make a note of the fact that these two people are friends.\nThis is something that will actually come through in your input. Your input is going to be a sequence of, you can think of them as a mix of, these commands and queries. We will come back to the queries a bit later. But the operations are essentially going to be either MAKE FRIENDS or MAKE ENEMIES, which is the operation that comes in when you observe that there are two people who are very likely to be enemies.\nSo both MAKE FRIENDS and MAKE ENEMIES come with the IDs of two people on whom you want to impose either this friendship structure or this rivalry relationship. As you continue to spend time at this party, you start building up your observations. Let us say you note them down. Whenever you see two people, and you are convinced that they are friends, you make a note of that. If you are convinced they are enemies, you make a note of that as well.\nFormally, of course, the way this works out is that you are given a series of these MAKE FRIENDS and MAKE ENEMIES operations as input. You could just put them on the record as you go along. Let us say these are some of the relationships that you have been able to figure out by direct observation.\n(Refer Slide Time: 05:41)\n \nNow, if you remember, what we said earlier is that there is this friendship and rivalry structure or network that we know exists among these people. Essentially, what is happening is that as you spend more and more time as a neutral, third-party observer, it is like you are building out parts of this picture.\nYou do not know this picture but it is like a few pieces of a jigsaw puzzle have been given to you, and you are trying to piece them together, and hopefully, eventually build up the complete picture as you go along. So far, though, all the information that you have built up is from your direct observations. An interesting aspect of this problem is that you can also build up a little bit of information from indirect inferences.\nMaybe you have not observed a pair of people directly, but you can draw some conclusions about them based on the other information that you have. The way that you can do this is driven by the fact that these friendship and rivalry relationships, because of the way they are, are driven by certain rules. There are basically three rules that we need to keep in mind and see how we can use them to draw these additional inferences. Let us go through these rules.\n(Refer Slide Time: 06:59)\n \nThe first one is that friendship is transitive. What I mean by this is that if A is a friend of B, and B is a friend of C, then A is also a friend of C. Notice that this behavior is not really very intuitive in the sense that if you are thinking about friendships as in Facebook friendships, for instance, you do not really see transitivity.\nFor instance, if you have a friend, just because this person is your friend, you do not automatically become friends with everybody that this person is friends with. However, that is the case in the context of the story that we have in this problem. Let us just keep this in mind and take a look at our example.\nSee if we can infer any new friendships here by an application of this rule. Remember, the rule simply says that the friends of my friends are also my friends, which is to say, if we apply it to a specific people, let us say A is friends with B, and B is friends with C, then that implies that A is friends with C as well. Can you apply this to some three people in this picture and infer a new relationship? This would be a good time to pause and try and confirm this for yourself.\nHopefully, you have also discovered at least this one new relationship that you can establish between two people because they are in this chain situation that I just described. This is one way of applying the first rule of friendship. I do not think there are any more inferences that we can draw just based on this rule.\n(Refer Slide Time: 08:44)\n \nLet us move on to the second rule which says that if you have a common enemy, then that makes two people friends. If you know that A is an enemy of B, and A is also an enemy of C, in that situation B and C have a good reason to be friends with each other because of this common enemy. Again, let us go back to the example that we have been looking at. Take a pause here and see if you can develop or infer any new relationships based on the second rule.\nOnce again, the second rule says that a common enemy makes two people friends. Can you find two people who have a common enemy? You can probably discover that you can infer a new friendship between these two people here because they have a common enemy in the person who is the rightmost person on your screen right now.\nI do not think there are any more inferences that you can make based on this rule because there are just two rivalry relationships that you have so far. Let us move on and talk about the third role connecting friends and rivals.\n(Refer Slide Time: 09:58)\n  \nThe third rule, which I think is also a popular saying is that an enemy of a friend is an enemy. Notice that this is distinct from the previous situation. In the previous rule, what we said is that a common enemy makes two people friends. These are two people who, at least as far as we were concerned, were strangers. But let us say they have a chat, and they realize that they both have the same rival, then that becomes a reason for them to become friends.\nHere, however, you have two people who are already friends. One of them, let us say, realizes that the other person has an enemy, then this person is going to declare a rivalry with the rival of his friend because that is just how this rule works. If you are my friend and you have a rival, that person becomes my rival as well. Let us see how this rule plays out in our example.\nTake a look here and see if you can draw any new conclusions based on this third rule. Once again, remember, the third rule says that an enemy of a friend is an enemy. If you need to please pause here and try to figure out if you can apply this rule. We do have a situation where someone has a friend who has an enemy.\nYou can see this playing out on sort of the bottom right corner of this picture. That is definitely one extra rivalry that you can deduce from the picture that you had built up so far. Now just take a look at this picture once again, and see if you can infer anything new based on what you have so far, especially after this last relationship was added.\nWas there anything new that can be concluded by applying one of the rules that we have discussed so far? You might spot that, here are two people who now have a common enemy. Because they have a common enemy, the second rule comes into play and they become friends. That is the picture that we have so far.\n(Refer Slide Time: 12:19)\n \nLet us just move things around so that this is a bit clearer to see. It is the exact same picture, which is the pieces adjusted a little bit. I think hopefully it is at least visually clear that at this point you have a dead-end in terms of indirect inferences based on the rules that we have discussed so far.\nLet us actually turn this around so that it is easier for me to draw the next connection that I want to draw. Suppose you have a MAKE FRIENDS operation, and this is a new direct observation. Let us say that you make friends between these two people here. Then you can probably guess that by applying the first rule of friendship, which is that your friends are my friends, you can actually infer these two new friendships in this picture. But that is not all.\nYou can actually say more based on one of the other rules. Can you think of any other relationships that you can derive from the three rules that we have seen before? Take a pause here and think about it. Remember that we said that if you are my friend and you have a rival, then that person is also my rival. This was the third rule. Based on that, notice that if you pick any one of the people who are in a yellow circle and any person who is in a blue circle, then they are going to be mutual rivals for this reason.\nBy the way, I should have mentioned this explicitly, but friendship and rivalry are always assumed to be mutual. It is never a one-sided relationship. That is also something that we are given. Let us not add these rivalries explicitly to this picture because it is going to make it crowded. But notice that there is one person who is kind of isolated from the rest of the picture that we have built so far.\n(Refer Slide Time: 14:16)\n \nLet us say that we make a direct inference or direct observation about a rivalry between the person on the bottom-left of your screen and this person who sits in the component on the right. What does this direct observation tell us? Can we infer something more from here? If you remember, we said that if two people have a common enemy, then they themselves become friends. You can probably identify here that these two people do have a common enemy.\nYou can infer this new friendship here. From this new friendship, you can infer many more friendships, and I leave it as an exercise for you to build out the rest of this picture. Fill in the remaining blanks and see if there is anything that still remains to be inferred if you need more direct observations to build up the whole picture. Or, are you really done from here?\nDo think about that when you have a chance. But in the meantime, let us move on to actually describe the task that we are supposed to perform. With all this background in place, I think we are ready to understand what we are supposed to do.\n(Refer Slide Time: 15:29)\n\nThe input is going to be a stream of queries. Some of these are actual queries, while the others are really operations or information about these direct observations. We have seen two of these already. You have: MAKE FRIENDS and MAKE ENEMIES. But apart from these, you will also get queries of the form ARE FRIENDS? and ARE ENEMIES?\nFor these latter two queries, you are expected to output ‘yes’ or ‘no,’ based on the information that you have so far. For example, if you are asked if P and Q are friends, then you are supposed to say ‘yes,’ if you have evidence that they are friends, either from our direct observation or by inference, and you can say ‘no’ otherwise. As you might expect, it is similar to the ‘ARE ENEMIES?’ query.\nIf you are asked if P and Q are enemies, you are supposed to say ‘yes,’ if you can deduce that they are enemies, either by direct observation or by some sort of inference. If this is not the case, then you say ‘no.’ Your task really boils down to keeping track of this picture, the one that we were building up like in the example before, as you get these MAKE FRIENDS and MAKE ENEMIES operations.\nOf course, the important thing is that you do not just make a note of the direct observations, you somehow want to also track all of the inferences, all of the implications that come out of applications of rules, 1, 2, and 3. Remember, the first rule was that all friends of my friend are my friends as well - friendship is transitive. The second rule was that if two people have a common rival, then they become friends.\nThe third rule was that if my friend has a rival, then that person is my rival as well. You want to apply these rules as much as you can to actually infer additional relationships to be able to come up with accurate answers to the ‘ARE FRIENDS?’ and ‘ARE ENEMIES?’ queries, which is really the crux of what is going on here. Let us also point out a little bit of Fineprint, which I think is important.\n(Refer Slide Time: 17:40)\n\nYou might actually get ‘makeFriends’ or ‘makeEnemies’ queries, which contradict your previous knowledge. This could be as simple as the first line of input saying ‘makeFriends 1 comma 2,’ and the second line of input saying ‘makeEnemies 1 comma 2.’ This, of course, is a very direct example of contradictory behavior. But you could also have operations, which contradict the knowledge that you have gained so far by inference.\nEven if these indirect conclusions are contradicted, you are supposed to ignore these commands, or you are supposed to ignore these operations. Here is how this works. Whenever a makeFriends or makeEnemies operation does not contradict your previous knowledge, but it just adds to the picture that you are building, then you might do all this background work of making note of this information and drawing inferences and all of that. But you do not have to do anything in terms of output.\nSo you produce nothing as output for the valid makeFriends and makeEnemies queries. But on the other hand, if you receive a query that contradicts your previous knowledge, then you output -1 to make a note of the fact that you encountered a contradiction, but you move on as if nothing has happened. You simply ignore this query in the context of the picture that you are building.\nThat is how the problem works in terms of the input and the expected output. Now, we really have to think about coming up with a solution. Of course, you could try to brute force emulate everything. You could add this information. You could go over all pairs or triples, whatever it takes to exhaustively examine the impact of the three rules of friendships and rivalries that we discussed. But you can quickly see that that is going to be too expensive.\nWe do need to do something smarter. Where do Disjoint Sets come into this picture? It is reasonably intuitive to think that the friendship relationship can be modeled using disjoint sets. Because of the fact that they are transitive, it would make sense to say that the friendships evolve in these clusters.\nWhenever two people from two different clusters are identified as friends, it makes sense to just mash the two clusters together. Because transitivity will imply that now everyone in the first cluster will become friends with everyone in the second cluster. So I think it is pretty natural to use disjoint sets to keep track of friendships.\n(Refer Slide Time: 20:28)\n\nBut the real question is: how do you keep track of the enemies? That is some extra information that you do need to carry along. You need to find some way for making room for this extra baggage in your disjoint sets data structure. Now, there are multiple approaches to this problem, and we will be describing a specific one, but I think it is really worth taking a break here and seeing if you can puzzle this out for yourself. I think it is a really cute puzzle to work with.\nJust give it a shot. Join me back in the next part of this module. In the next video, we will talk about a complete solution to the problem, which involves using disjoint sets for the friendships and a little bit of extra book-keeping, and some case analysis to carefully track the enemies. I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/W04/Lec20.html",
    "href": "materials/cpnotes/W04/Lec20.html",
    "title": "M 2 (Destroying Array-II)",
    "section": "",
    "text": "Lecture - 20\nDisjoint Set Union - Module 2 (Destroying Array-II)\n(Refer Slide Time 00:11)\n\nWelcome back to the second segment of the Destroying Array module. Remember that in this part we only discussed the implementation. This will make a lot more sense if you watched the previous part first. If you have not done that, please go back and take a look at that video where we actually go over the problem statement, the main ideas for a solution and it is that solution that we are going to try and implement now.\nLet us get started here. As usual, you can find a link to the problem itself in the description of this video. You may want to cross-refer that to make sure that the input-output formats are as you expect, and so on.\n(Refer Slide Time: 00:50)\n\nThe first part of the main function is going to be the usual. I think this is a fairly standard parsing of the input. We are going to first take in the number of elements in the array, and then we are going to store the elements of the array in a vector of integers. We are also going to have a state vector, which tells us which locations are currently occupied and which locations are currently empty.\nThe state vector will evolve as we go through the process of adding elements to the array one by one. Then we declare, again, the vector of integers to take in the sequence in which the destruction happens. We just take in all of these inputs. Let me just also point out the limits. I believe the value of ‘n’ ranges from 1 to 100,000. The values of the elements in the array would range between 1 and 109.\nAll of this would fit within the integer data type and that is why everything that you see here has been declared as an integer, except for the index variable in the first for loop, which I think is just really not intentional. So that could very easily also be an integer. That is not really going to be a problem. But remember that we are tracking the sums of elements of segments in this array. When you add up these large numbers, then you might overshoot what can be stored in an integer data type.\n(Refer Slide Time: 02:25)\n\nWhen we declare variables that are going to store the answers for us, at that point, we switch over to the long, long data type, which can handle the larger numbers that we are going to need as we go along. After taking in all of the input, we instantiate the disjoint set union data structure. Again, I do this with ‘n+1’ elements so that I can simply talk about the ’i’th element without having to adjust for indexing to go back and forth between zero-based and one-based indexing. You might have a different taste with regards to this.\nBut if you do it differently in the sense that you initialize it with ‘n’ elements, then please remember to adjust your indices properly because the input sequence is a permutation of 1 to ‘n.’ So you will have to roll it back by 1 if your elements are ranging from 0 to ‘n-1.’ The first thing that we do is to reverse the sequence of instructions.\nWe are going to declare a vector of long, long integers to store the answers that we are supposed to output at the end. We are going to use the variable current answer (currentans) to keep track of the answer in the current stage of the process.\n(Refer Slide Time: 03:38)\n\nLet us move to what is really the heart of the whole algorithm. This is where we actually go through the process. We are going to go over the sequence. Then we are going to do the union operations based on the situations that we have already discussed in the previous video. First of all, when we say that the ’x’th element is now being added, we modify the state of the ’x’th location to 1, to indicate that this location is now occupied.\nNow we create the singleton set that is associated with this location. Normally makeSet will just take one parameter as input, and it will say: I want to create the singleton set involving the ’i’th element and that would have been enough. But remember that we are tracking the sums of the elements, the actual numbers that are sitting at these locations. So we are going to use the indices to keep track of how the sets are evolving.\nBut we also need to keep track of the numbers that are involved at these locations. I am also passing that as a parameter and it is going to be used to initialize the value of sumSet, the sum of the elements in the set. We are going to store that in a separate array. For the singleton set, that is just going to be the value of the array of x. It is going to be that number. We pass that in as a parameter as well so that we can track this value.\nWe need to look at whether the introduction of the element at the ‘x’th location is causing any merges or any extensions of previously existing sets. That is exactly what we are doing here. We are checking if the left neighbor is non-empty. If yes, then we take a union between ’x-1’ and x. If the right neighbor is non-empty, then we take a union between x and ‘x+1.’ This non-emptiness is essentially checked by the value in the state array.\nNotice that the first part of that ‘if’ clause is just safeguarding us from falling off the cliff, so to speak. That accounts for the edge cases that I was mentioning briefly in the previous video. If ‘x’ is zero, then ‘x-1’ will not make sense and if ‘x’ is ‘n’ then ‘x+1’ will not make sense. That is essentially what we are trying to be careful about here. Now that we have done the merging, let us think about what should be the value of the answer at this stage. Remember that we want to return the weight of the heaviest chunk.\nWe know the weight of the heaviest chunk from the situation when this element had not yet come into the picture. We know the heaviest chunk from the previous iteration in the sequence. If we are just at the beginning, then the current answer is initialized to 0 and we really have nothing to check. We just output the value of the singleton chunk that got introduced. Just as a sanity check, that is what happens at the very first step.\nBut in a general iteration, the value of the variable current answer gives us information about the heaviest chunk in the previous snapshot. Now there was this one element that came in, and it potentially merged some sets, or it potentially manifested as a singleton set. But essentially, the only new contender is going to be the set that this new element belongs to. All other sets pretty much remain the same. They have the same weight as the previous step.\nSome sets disappeared. Notice that if one of the sets that disappeared was actually the champion set from the previous iteration, then it is going to at least retain that status when, you know, it gets merged with the new element. The only reason a set disappears from the previous snapshot is that the set got enhanced with the new element that was added. It got merged with 1 or 2 sets depending on the situation that you are in.\nNotice that the value of the set, the weight of the set only gets better because all of the numbers in the array are non-negative. So we do not have to worry about if we lost this set. Maybe the maximum is the crown now needs to shift to one of the other sets. We need to look through all of the other sets and check if one of them got better.\nNotice that if the newly introduced element could have been potentially a large negative value, then this would have been a problem. After this merger, maybe there was a set that was doing very well and was championing the previous round and now it just became much worse and we need to find a new champion. But notice that this is something we do not need to worry about at all because all the elements have non-negative values. When you bring them in, the previous sets, if at all, get better.\nAll that we need to do is check if the new set that came into the picture, which could either be a singleton or it could be the merger of some sets from the previous iteration. We just need to sanity-check the weight of this set against the best value that we had from the previous iteration. So the weight of this newly created set dominates the current answer. Then we need to update the value of the current answer otherwise we leave the current answer as it was.\nThat is essentially what is happening in the penultimate line of this code snippet. After this, we basically just do the formalities. The logistics would be to push the value of the current answer into our answers array so that we are tracking the answers at every iteration.\n(Refer Slide Time: 09:38)\n\nOnce you have gone through the whole process, we need to shave off the last answer that we add to the answers array. The reason for that is, at the very end when you add the last element to the array, you have reconstructed the whole array. The answer that you get at that point is going to be the sum of all the elements in the array. There is just one junk. Your output only starts from the heaviest chunks after the first element has been removed.\nThe last thing that you add to the answers array is not really relevant. We want to get rid of it. That is the pop operation that you see here. After this, your answers array is ready for output. Do remember to reverse the answers array because we have been collecting the answers in the opposite order of what actually transpired.\nWe need to reverse this back so that the output is consistent with what is expected. At this point, we are pretty much done. Let me just quickly recap a couple of small changes that we needed to make to the union-find class. I will not recap the whole class because that is been described in some detail in the previous module. Do check that out if you have not already.\n(Refer Slide Time: 10:55)\n\nOne function that we did need to add here was the makeSet operation. Even before this, I will mention that you have to adjust your initializations a little bit. In the previous constructor, the whole thing was set up to capture the state of ‘n’ singleton sets. We wanted every element to be its own set. What we do instead is lay the groundwork. We create enough room for ‘n’ sets to be or ‘n’ elements to be eventually added. But initially, all the sets are empty.\nAll the parent pointers that point to -1, it is some value to say that these are not yet defined. The depths of the trees are also -1 just to say that these trees do not exist, and things like that. So we made some adjustments to how the constructor works and makeSet is what captures the creation of singleton sets as they come along. There are multiple ways in which you could do this. I chose this because it felt natural to me in terms of just being reflective of the process as we described it.\nBut I am sure there are other equally valid implementation strategies. Although I am not showing you the modified constructor here, you can find the entire code as usual in the official repository. Let us just quickly look at what is happening in makeSet. When you are creating the ’i’th element – as usual, the ’i’th element at this point is a singleton set is its own leader. The parent simply points to itself. This is a tree, which has just one root.\nSo by convention, its depth or rank is going to be 0. It is a set whose size is just 1. It is a singleton element. When we create a new set, we increase the number of sets. We increment the numSets variable accordingly. Notice that the extra thing that we are tracking in this problem is the sum of the elements in any given set. The sumSet array at the location ‘i’ needs to be updated so that it has the value of the element in the array that we were working with.\nRemember, we passed this as a parameter, that is the second parameter here. SumSet of ‘i’ is initialized to ‘x.’ One thing that I am not showing you that is actually quite important is that when you are doing the union operation, you do need to update sumSet there as well. So sumSet of y will become sumSet of y plus sumSet of x. Basically, you want to bring in the sum of all the elements that were there in the set being tracked by x to now the largest set that is being tracked by y.\nThis is very similar to the updates that we did for tracking the minimum element, the maximum element, the number of elements in the sets, the sizes of the individual sets, and things like that. It is very much in that spirit. I hope that you will be able to work through this yourself and just in case you need to cross-check, or you need to refer to it, the entire code is available in the GitHub repository.\nYou are welcome to take a look at that as well. So with that, we come to an end of the description of how we would solve Destroying Array. I hope you enjoyed this. Let me know what you think in the comments or keep the conversation going on Discord. I look forward to seeing you there. We will be discussing one more problem this week. So I will also see you in the next video. Thanks for watching and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W04/Lec22.html",
    "href": "materials/cpnotes/W04/Lec22.html",
    "title": "M 3 (War-II)",
    "section": "",
    "text": "Lecture - 22\nDisjoint Set Union - Module 3 (War-II)\nWelcome back to the second segment of our discussion on ‘War.’ This will not make any sense if you have not seen the previous video, where we actually introduced the problem. Just in case you have stumbled on this directly, then please do make sure that you watch the first part first.\n(Refer Slide Time: 00:30)\n \nIf you remember, when we stopped there, we said that we could use disjoint sets to fairly naturally model the friendships. But we were not sure how the enemies can be accounted for. Let me just say that one way of tracking the enemies is to just track the enmities between the leader elements. It turns out that will be sufficient to make all the inferences that we need to make.\nIn particular, let us say that at some intermediate stage, you have developed some of these friendship clusters. Let us say that you know that there is some pair of people, one from the first cluster and one from the second that are enemies, then you can apply your rules to observe that this actually implies that all of these people from the first cluster are enemies with all the people from the other cluster.\nWe are going to just succinctly make a note of that by adding an enemy relationship between the leaders. When we get an ‘ARE ENEMIES?’ query, basically, we ask ourselves, if the representative elements in the sets that the people belong to, if they are enemies. That is essentially necessary and sufficient to produce an affirmative answer to this query. Now, this will become clearer as we go along.\nBut the foundations are the following. We will have a standard DSU data structure to keep track of the friendships between people as they evolve. We will have an array of length N to keep track of the enemies (just of the leaders). Because of the way enmities evolve, and this is something that, as I said, will probably become clearer later. It is sufficient for every leader element to point to at most one other leader element, saying, that that is my current enemy.\nYou will never be in a situation where you need to point to the leader of more than one cluster in your friendship network. We will see why that is as we go along. But in terms of what you need to write down the code, it is going to be your standard disjoint set union data structure + an extra array, which is the book-keeping that we were talking about, to keep track of what is going on with the enemies.\n(Refer Slide Time: 02:56)\n\nBased on this, you can perhaps already anticipate how we will answer the ‘ARE FRIENDS?’ and ‘ARE ENEMIES?’ queries. This part is actually quite straightforward. Because the friendships are being maintained by disjoint sets, the ‘ARE FRIENDS?’ question just boils down to asking if the two people on whom the query is being made belong to the same cluster or the same set or not. We have already seen this as the ‘isSame’ set helper function.\nAll that this does is check if the leader elements of the sets that these two people belong to are the same or not. The answer is ‘yes’ or ‘no,’ just based on that. For the ‘ARE ENEMIES?’ query, it turns out that two people are enemies if and only if their leaders are enemies. If the leader elements of your set are enemies, then of course, by applying the rule which says that the enemy of a friend is an enemy, you can conclude that the two people who are involved are enemies as well.\nIf the two people who are involved are enemies, then very similarly you can infer that the leaders of their sets are also going to be enemies. That is all that you need to do here. You need to go to the leader elements for the two people on whom the query is being made. You need to check if they are mutual enemies. This information is being tracked by this enemy array. That is all that you need to check here.\nThat takes care of two of the four queries that, that we had to worry about. It feels like half the battle won, at least psychologically. But it turns out that the bulk of the work really is in making sure that you build up an accurate picture as you receive operations of the first two kinds, which are the MAKE FRIENDS and the MAKE ENEMIES operations. There you want to make sure that you are building up an accurate picture and you are drawing all the inferences that you can. Let us turn to those operations now and see how we will deal with those.\n(Refer Slide Time: 04:52)\n  \nWe have ‘MAKE FRIENDS.’ Remember that friendships are being tracked by DSU essentially. The natural thing to do here is to interpret this as a union operation. If you remember what we do typically when we are trying to do a union is to first approach the leader elements of the sets that these people belong to. Of course, at the very initial stages, they will be the elements of the people themselves.\nBut, we are talking about a generic situation. We approach the leader elements. Of course, first, we do check if these leaders are already enemies. If this is the case, then you cannot make friends out of people who are already enemies. Notice that if the leader elements of ‘your set’ are already enemies, then by inference, you are enemies as well. You already have this information.\nThis will be the situation where you have a contradiction. Your output -1 and you move along. But suppose there is not a contradiction. Then what are the possible scenarios that could arise? Well, it is possible that the leader elements are the same. If that is the case, then this picture is not very accurate. But if the leader elements are the same, then that means that the two people that you were given in this operation are already friends.\nThere is no work to be done. You could just, again, move along, this time for a different reason. Now, suppose that they are not already friends. But let us also say that the two leaders have no known enemies. If they have no known enemies, then when you merge these two clusters, there are no additional inferences to be made. There are no additional inferences to be made in the context of the enemies.\nWe just do a simple union. Once again, at this point, we are done. But, there are some cases to be taken care of if one or both of these leader elements already have known enemies of their own. Let us take a look at how that could pan out. We know that we have to establish this friendship here. That is a non-contradictory operation and that is going to happen.\n(Refer Slide Time: 07:15)\n \nLet us say that one of the leader elements has a known enemy, and the other leader element has no known enemies at this stage. That is what this picture would look like. But now remember that the enemy of a friend is also an enemy. Based on this, you can infer this additional enmity relation. So once you merge the two sets, you want to make sure that the new leader keeps track of the fact that the leader has an enemy in this, in this other leader element. This enemy is going to be the leader element of some other set.\nWe would want to make a note of that. Normally, if the leader element does not change, after you do the union, you actually do not have to do anything. But it is possible that after the union, the leader element changes. In that case, you do have to update the enemy array to make sure that you continue to track this enmity.\nSimilarly, you could be in a situation where both of these leaders have a known enemy. This is what that situation is going to look like. Once again, by applying the rule of the fact that the enemy of a friend is also an enemy, by applying this rule twice, you infer these two new rivalry relationships. But now based on this, can you say something more? Take a pause here to see if you can infer any new relationships based on the picture that we have built out so far.\nIf you had a chance to think about this, you may notice that these two enemies also become friends after we have made the inferences that we just made. The reason for this is that if you have a common enemy, then you are friends. These two people actually have two common enemies now. This is essentially how the rules would play out in this situation. But in terms of the implementation, what would we like to do?\nNow we not only make the two people friends that we were supposed to make friends according to our operation, but we actually can establish a new friendship. There will be two pairs of clusters that get merged. We want to ensure that the leaders, the potential new leaders of these two clusters, record their enmity. That, again, the information about the enmity is carried forward as we would need it to.\n(Refer Slide Time: 09:44)\n  \nLet us actually take a look at all of these cases, from the viewpoint of the friendship clusters that may have come about. Let us say we are at some intermediate stage and we have developed some friendship clusters. Let us say that these are the leader elements. Now, suppose that you have some known enmities between leaders. Notice that these will always show up as pairs of clusters. You will never have enmity show up in any other way.\nFor example, you will never have this sort of situation. Again, take a moment here, if you need to, to think about why this picture is not a valid one? Why this would never arise? The reason this would never arise is that if you had the structure, then notice that the two clusters on the left would not really continue to persist as disjoint clusters because you have a common enemy situation here.\nThese two clusters would have actually been merged if our algorithm was doing its job correctly up to this point. This picture never really arises. The clusters pair up in terms of known enmities, and some clusters are just hanging in isolation. The cases that we saw so far were the following. First, we said that maybe both of the leaders who are going to become friends have no known enemies.\nThat is essentially a simple merger of two isolated clusters. It is also possible that one of them has a known enemy and the other does not. In this case, what we said was that we will do a simple merge as before but it is possible that after this merger, the leader gets updated. Then we have to make sure that the leader, the enemy pointer, is pointing correctly from the new leader to the old enemy.\nYou could also be in a situation where the two leaders who are coming together, both of them have known enmities. In this case, what was happening is that you not only merge these two clusters, but you also merge the other two clusters that involved the known enemies. Both of these freshly minted clusters will have their own new leaders potentially, and you need to reestablish the enmity between those two leaders of these larger merged clusters.\nHopefully, the algorithm is clear, and all the cases are clear. This is how we will handle the MAKE FRIENDS operation.\n(Refer Slide Time: 12:11)\n  \nNow, let us turn to the MAKE ENEMIES operation. Just like with MAKE FRIENDS, when we are asked to MAKE ENEMIES, we will approach the leaders because those are the people between whom we want to establish the enemy team. That will take care of the clusters pretty much by inference. Also if you remember, the way that we address the ‘ARE ENEMIES?’ query - this is really all that we need to keep track of.\nOnce again, just make sure that you handle the contradictory situation. In particular, if these two people involved here are already friends, then you need to output -1 and completely ignore this query. Similarly, another easy situation is if they are already enemies. In this case, for a different reason, you do not need to do anything because this relationship has already been established.\nWe can move along. But now suppose that they are not already enemies. We want to, again, do a case analysis that is similar to what we had before. Suppose these are coming from two components that are hanging in isolation. Neither of these leaders have any known enemies. Then again, just as before, it is a matter of doing a simple pointer update.\nNotice that we do not need to do any unions here. These clusters, in fact, must remain separated. But, they sort of get magnetically attached through this rivalry relationship. That is being tracked by the red pointers. The red pointers that we were visualizing in the picture from a few moments ago are what is being tracked by the enemy arrays. Just keep that at the back of your mind. That is what we do in this case.\n(Refer Slide Time: 13:48)\n \n \nBut suppose that you are actually connecting a leader who has a known enemy with a leader who does not have any known enemies. In this case, you can actually make some additional inferences. Pause here for a moment and think about what is an extra relationship that comes out of this situation.\nIf you remember the rule about how a common enemy makes for a friendship, you will realize that these two leaders can actually become friends. If you establish an enmity between two leaders, and one of them already has an existing enmity, then you actually have a good reason to merge some two clusters.\nJust to make the cluster perspective a little more explicit, let us actually pull up a picture in terms of clusters. Notice that you are trying to establish an enmity between the cluster on the left and the cluster in the middle. That is the query. That is what we have been asked to do. But the cluster on the left has a known enmity with the cluster on the right, which means that by the common enemy rule we know that these two clusters must actually be friends.\nWhat we do first is we go ahead and merge these two clusters, and just to record that inferred friendship, and now depending on whether this merger created a new leader or not, we have to figure out if the enemy pointer needs to be updated. That is what is going on in this case.\n(Refer Slide Time: 15:18)\n \nThe final situation is: If both the leaders have known enemies. Here, what is going to happen is that you can make some extra inferences as before. In particular, you can infer these two friendships. Once again, the reason that you can infer these friendships is because of the common enemy rule. For example, the person in the red circle is a common enemy for the two people in the yellow circle.\nThat is why you can infer the friendship between them. It is symmetric for the other friendship relationship. How do you handle this situation? How do you put these new friendships on the record? Remember, we are tracking friendships with the standard disjoint sets model. What will happen is, you will end up essentially merging the sets that these pairs belong to.\nThe two people in the yellow circles and the two people in the green circles, we go ahead and merge the sets that they belong to. After that merger is done, each of these two sets is going to have a new leader element emerge, which is going to be one of these existing leaders. But you are going to have the leaders identified after you do the union.\nThe final step is to make sure that these two new leaders have the enmity relationship between them put on the record. That is all that you need to do here. That brings us to the end of the description of how you handle the MAKE ENEMIES operation. With this, we are in fact done with both the MAKE FRIENDS and the MAKE ENEMIES operations.\n(Refer Slide Time: 16:58)\n\nLet us do a high-level summary of what we have discussed so far. First, remember, we handled the contradictory cases and got them out of the way. If you are asked to make friends between two enemies, or you are asked to make enemies between two friends, then we remember to output -1 and we move on.\nSimilarly, if the two people of whom you want to make friends are already friends or the two people you want to make enemies are already enemies, then once again, there is nothing that needs to be done and this is an easy case as well. The third easy case is: When the two people involved in the queries do not have any known enemies of their own.\nIn this case, for MAKE FRIENDS, this was a simple union, a merging of two clusters. In the case of the MAKE ENEMIES operation, it was just a matter of updating the enemy pointers between the leaders. Now, the non-trivial case is where, when one of the leaders had an own enemy and the other one did not, or when both of the leaders had their own known enemies.\nIn both of these cases, you could infer some extra relationships. This involved carefully merging some sets that you did not have to directly merge because of the operation but by inference. Then just keeping track of the new leaders and making sure that the enemy pointers are cleanly updated. The specifics of how you handle these two cases, we have already discussed.\nIn case you missed it, you might want to just go back and look at that part of the discussion in the video. That brings us to the end of the algorithm. I think by now you have all the information that you need to actually implement this. We will do a quick overview of the implementation in the last segment of this module. The code in the implementation actually very closely follows the description.\nI am going to not do a very elaborate overview because this is a slightly non-trivial problem and it is a really good exercise to try on your own. In the implementation video, we will sort of briefly summarize the main modifications to the unionFind class. Go over a few of the cases and leave out the ones that are either symmetric or very similar to the cases that we have seen before. Hopefully, you have a chance to actually work through this yourself and treat the implementation excursion as an elaborate hint, rather than a line-by-line explanation.\nI will see you in the implementation video. In the meantime, if you have any questions or comments about this problem, then please do leave a note in the YouTube comment section. Or feel free to start a conversation in discord or at the Google Groups mailing list. We will as always look forward to hearing from you and I will see you in the final segment, which is going to cover the implementation!"
  },
  {
    "objectID": "materials/cpnotes/W04/Lec23.html",
    "href": "materials/cpnotes/W04/Lec23.html",
    "title": "M 3 (War-III)",
    "section": "",
    "text": "Lecture - 23\nDisjoint Set Union - Module 3 (War-III)\nWelcome back to the last segment of the final module in week four. If you remember, we have been discussing the problem ‘War.’ I should point out that this video is the last in a series of three videos. In the first one, we introduced the problem statement. In the second one, we described a solution.\nIn this short wrap-up video, I am going to show you some snippets from an implementation of the solution that we discussed in the previous video. I would not expect this to make any sense if you have not seen the previous two videos. Please make sure that you have watched those first. Our implementation is going to be in C++ because we will want to just build on the unionFind class that we described in the first module.\nBut it should be pretty straightforward to translate this into your favorite programming language. If you do end up doing that, please do submit a pull request to the official repository as always. We look forward to receiving your submissions. With that said, let us proceed to the implementation.\n(Refer Slide Time 01:04)\n\nI am just going to begin by looking at what the unionFind class looks like. We have just essentially introduced a public entity called ‘enemies.’ This is to keep track of the enemy pointers on the leader elements. The rank and friends are the usual things from the default DSU data structure. So, ‘friends’ is just a renaming of the parent array. I think we have been using P to denote the patent pointers previously.\nNow I have just renamed that to ‘friends,’ just to remember that we are keeping track of the friendship relationship using these pointers. The initialization is pretty straightforward for friends and rank as before. In fact, in the problem statement as well, you will see that it is been made explicit that everybody is a friend of themselves, and nobody is their own enemy. The friends are singleton sets, to begin with. That is our standard initialization.\nFor ‘enemies,’ we just want to basically say that we are starting off with a blank slate and there are no recorded rivalries right in the beginning. We just follow the convention that we are going to use a value of -1 to designate that this person has no known enemies at the moment. That is a simple initialization. In this problem, the N people are in fact indexed from 0 to n-1.\nIn the previous module, I have been saying that I would like to initialize unionFind with N+1 because, for example, in destroying array, the elements were indexed from 1 to N. But here, you can just do standard instantiation with just n and your indices will work out fine. It is quite peaceful, actually.\n(Refer Slide Time 02:58)\n \nLet me just begin by also introducing these two new methods in this class. We have areFriends and areEnemies. You will notice that areFriends behaves very much like isSame set. You just check if the leaders are the same, and you return an appropriate value. As far as enemies, here what we want to do is check if the leaders are enemies of each other. If that happens to be the case, then we return yes, and otherwise, we return no. This is exactly as we discussed. These are two really simple helper functions to write and get out of the way.\nThe crux of the matter is really in figuring out the MAKE FRIENDS operation. Again, I am not showing you the parts of the code where we take in the input and do the case analysis and all that. That is fairly straightforward. In any case, you can always look up the full code from the repository. I am just going to show you some relevant snippets corresponding to the cases that we discussed.\nEven here for MAKE FRIENDS, I have not shown you, at least not on the screen right now, the case where we handle the contradiction. The very first thing to do is check if the input to MAKE FRIENDS, which in this case is x and y, you want to check if they are enemies. If that actually returns yes, then you want to output -1 and just break out of this case altogether. That is a sanity check that you do need to do upfront.\nOnce you are out of that situation, essentially you replace the people x and y with the corresponding leader elements. The first case, which was the simplest one was a situation where x and y have no known enemies to speak of. If the enemy array is -1 at both these indices, then we just do a simple union and that takes care of the situation completely.\n(Refer Slide Time 04:51)\n\nBut now we have a situation where one of the leaders has an enemy and the other one does not. In this case, remember what we said is that you can infer a new enmity, right. So x and y are about to become friends. Let us say x has a known enemy, then that known enemy also becomes an enemy of y. But the way that this plays out in the data structure, the way we are maintaining things is that you go ahead and you do the merger between the clusters of x and y.\nWhat happens now is that it is possible that y may have taken over as the leader, in which case, you need to make sure that the ‘enemies’ array is appropriately updated. That is exactly what is happening here. First, you identify the enemy of x. Then you merge the sets that x and y are currently representing. Now just for the record, you look up the representative of this merged set, and you make sure that this representative becomes enemies with the set.\nIt is possible that nothing changes in the enemies array because possibly x is also the new representative, but just in case y has taken over. This ensures that the enemy is array is properly updated. Now I am going to skip case 2B, which is the exact symmetric situation where y has an enemy but x does not. It is essentially the same logic. But with, of course, the variables appropriately swapped.\n(Refer Slide Time 06:20)\n\nThe final case was when x and y both have enemies. Remember that in this case, we said that the sets that contain these two enemies can also be merged because these two enemies can now be inferred to be friends between them. Let us say that ‘a’ is the enemy of x, and ‘b’ is the enemy of y. We merge x and y, because that is what we had set out to do anyway. But by inference, we also merge the sets that are being represented by ‘a’ and ‘b.’\nNow what we have to do is, once again, make sure that our enemy pointers are appropriately updated. We have these two merged clusters. We identify the potentially ‘new leaders’ of these clusters. Then we make sure that we put their enmity on the record. That takes care of all the scenarios that could arise with MAKE FRIENDS. It is similar to MAKE ENEMIES, although the details are slightly different.\nI think the most non-trivial case for MAKE ENEMIES was again the case when both of the people who are involved, both of the leaders, have enemies of their own. Let me just show you that one case. Remember that this is unlike in many of the other videos; this is not a line-by-line breakdown of the entire code. I am just showing you the parts that I think are the most interesting and non-trivial.\nI hope that what you will be able to do from here is to actually write out all the cases by yourself. Of course, if you do need to look at the entire code, you could always take a look at the repository, which is linked to in the description of this video as well. Let us wrap this up with a look at the last case for the MAKE ENEMIES operation which I think is the one where there is the most going on.\n(Refer Slide Time 08:00)\n\nLet us say that you are supposed to be making enemies of x and y. Let us say that they have enemies of their own, which are denoted by ‘a’ and ‘b’ respectively. Let us say x has a known enemy, in ‘a’ and y has a known enemy in ‘b.’ If you go back and think about how we dealt with this case previously.\n(Refer Slide Time 08:23)\n\nWe said that, well when that happens, so x and y are the two people on the top and a and b are the two people on the bottom. Then we said that, we need to make friends between, let us say x and b and y and ‘a’ because those are the additional friendships that we were able to infer by the common enemy rule. That is exactly what we do in court.\nWe say that, well, if ‘a’ was an enemy of x, then ‘a’ and y have a common enemy in x after you establish the enmity between x and y, which is what you have set out to do. Because ‘a’ and y have a common enemy, we are going to go ahead and merge the sets that ‘a’ and y belong to. For a very similar reason, we are going to merge the sets that b and x belong to. After these merges have been established, we still need to make sure that these big merged sets are actually enemies with each other as well.\nLet us make sure that we pull out the leaders of these newly created sets and establish the enmity between them. That is exactly what is happening in the last four lines of this code snippet. Of course, you do have a few other cases to deal with for the MAKE ENEMIES relationship as well.\nWhen you have one of the leaders having an enemy, the other one not having an enemy, and the even easier cases, when neither of them has a known enemy, in which case it is just two lines to update the respective enemy pointers. Even before that, do not forget to check for a contradiction before you get into any of these cases at all. If x and y are already friends, then you just output -1 and break out of this case.\nAgain, there needs to be a little bit of a wrapper to make sure that you get into the right cases in the right situations based on what the input looks like. You can go and look at the problem statement to make sure that you have the right formatting in terms of input and output. But at this point, I think you hopefully have enough information to piece together your own version of this solution.\nAs I have said before, this is by no means the only approach to this problem, but I found this way of solving it to be fairly natural, and actually quite elegant, really, once you have an understanding of all the possible scenarios that emerge. I do hope that you enjoyed this as much as I did. I will say that this is probably one of the more challenging problems that we have seen so far in this course. If it takes you a while to sort of really absorb all the cases and what is going on, then do take your time.\nI think this problem does require a little bit of patience. But I think it is well worth it in the end. Do let us know how it goes. Please drop in a comment, if you have any questions or any suggestions, and we look forward to hearing from you. With that, it is a wrap for week four. I hope you enjoyed this little excursion through all the ways in which disjoint sets turn out to be useful. As I said, we will probably keep encountering this data structure.\nIt is something that also shows up, as I have mentioned earlier, in more advanced problems as something that is a piece of a bigger puzzle. I think this little bit of practice really is going to be handy. Fortunately, there are a lot of really great resources for learning more about the disjoint set union or unionFind or disjoint sets or whatever you want to call it. If you are interested in the theoretical aspects, you will find a link to a really wonderful book chapter in the description of the first module, or on the course website.\nThat is a great resource for learning more about why path compression works out so well, and so on. If you just want to try more practice problems then the code forces education segment on disjoint set union is a great place to start. They have tons of problems in increasing order of difficulty, roughly speaking, and they also have some great video materials.\nIf you really want to dig deeper, there are a bunch of resources and we will link to some of them in the description of this video. I really hope that you have fun exploring and I hope that you do actually get to use this in a contest that you participate in, in the future. As always, have fun, and please keep the conversation going on Discord and on the mailing list and I will see you back next week!"
  },
  {
    "objectID": "materials/cpnotes/W05/Lec28.html",
    "href": "materials/cpnotes/W05/Lec28.html",
    "title": "M 4 (Diamond Inheritance)",
    "section": "",
    "text": "Lecture - 28\nGraph Foundations - Module 4 (Diamond Inheritance)\n(Refer Slide Time: 0:11)\n\nWelcome to the final module of the fifth week in Getting Started with Competitive Programming. So, we continue to look at the applications of graph traversals specifically BFS DFS, and our final example is going to be a problem called Diamond Inheritance. This appeared in Round 1C of the 2012 edition of Google Code Jam.\nAnd one of the reasons we picked this problem was because it gives us an opportunity to work with directed graphs, which I think is interesting. It is good to know that the traversals work out pretty much the same when you are working with directed graphs. But there are also some subtleties that crop up and that are good to be aware of. So, alright, let us get started by looking at the problem statement.\n(Refer Slide Time: 00:56)\n \nWe are told that we need to help diagnose class diagrams to identify instances of diamond inheritance. Now, if you have done object-oriented programming, you might have already encountered this phrase, Diamond inheritance. Some places would more colorfully call it the deadly diamond of death. And the reason is that this is essentially an instance of an ambiguity that occurs when you have basically messed up inheritances that look something like this.\nSo, if you have not done any object-oriented programming, and all of this sounds strange, then do not worry about it. But for those who are familiar with notions of inheritance in that context, basically, suppose you have four classes with two classes inheriting from a common class. So, let us say for instance, that B and C inherit from A and then class D inherits from both B and C. That is also the diagrammatic notation here.\nSo, we see that an arrow pointing from X to Y, for example, from D to C indicates that D inherits from B. So, we have that D inherited from B and C, and B and C inherited from A. So, suppose you have a method in class A that is overwritten differently by B and C, then when D inherits from B and C, what version should it use? It becomes somewhat ambiguous. And this is why you are probably interested in knowing if you land up in this sort of situation.\nNow, if the class and method kind of terminology does not make sense, then do not worry about it. You could just think of this as a situation where you have four nodes or vertices. And wherever they are connected in this very particular way, then we say that we have an instance of diamond inheritance. And this is what we are required to detect. But it does not have to be just four vertices. So in the problem statement, they go on to tell us what exactly we are looking for in slightly more formal, more precise terms.\n(Refer Slide Time: 03:08)\n\nSo, let us take a look at what we really mean when we want to say that there is diamond inheritance. So, first, let us talk about an inheritance path. So, an inheritance path from X to Y is defined as a sequence of classes, X, C1, C2, and so on up to Cn and then followed by Y, where X inherits from C1, Ci inherits from Ci + 1 for all ‘i’ between 1 and n - 1. And finally, Cn inherits from Y.\nSo, this might remind you of the notion of a path that we talked about when we were discussing the notion of connectivity in the second module. And there a path was simply a sequence of vertices, such that every pair of consecutive vertices has had an edge between them.\nAnd now this is pretty much the same idea. You would just have to think of your classes as being vertices of a directed graph, and you add an edge between two vertices if the corresponding classes are such that one inherits from another, and you make sure that the orientation respects the direction of the inheritance.\nNow in this graph, an inheritance path is simply a sequence of vertices so that the consecutive vertices have a directed edge going between them connecting the vertex that appears earlier in the sequence with the vertex that appears later in the sequence. So, you can map this notion of an inheritance path as applied to classes to a directed path in the graph that you derive from these classes.\n(Refer Slide Time: 04:44)\n\nSo, we say that a class diagram has a diamond inheritance if there exists a pair of classes X and Y, such that there are at least two different inheritance paths from X to Y. That is the definition of a diamond inheritance. So, essentially, it does not have to be literally a diamond on four classes, it could be a longer chain in some sense. But as long as you have two classes X and Y so that there are two different paths from X to Y, then you have an instance of diamond inheritance.\nIn the language of graphs, essentially, you are looking for two vertices, X and Y so that there are two different paths that connect X and Y. And these are paths in this directed graph. So, just to make sure that we are on the same page, let us actually take a look at one of the examples given in the sample input.\n(Refer Slide Time: 05:36)\n\nSo, the format of the sample input is such that the first line tells you how many classes there are. So, in this case, there are five classes. And then this is followed by as many lines as there are classes. So, you can see that you have five lines. On the ‘i’th line, the first number tells you how many classes does the ’class i’ inherit from. So, for example, the first class here inherits from two other classes.\nAnd then the next two numbers on that line tell you the IDs of the two classes, or in general, there is going to be as many numbers as there are classes that you inherit from. And each of these would correspond to the IDs of the classes that you inherit from. So, that was a bit of a mouthful. So, let us just walk through this example. We see that the first class inherits from 2 and 3, so we have those arrows there to the classes 2, and 3.\nThe second line corresponding to the second class has just one inheritance, and that is from class 4. So, we have an arrow from 2 to 4. And then the third line corresponding to the third class again has one inheritance. And that is from class 5. And then we have the fourth class also inheriting from 5 and 5 has no inheritances. So, 5 does not have any edges going out of it. So, what sort of an instance is this?\nDoes this have ‘diamond inheritance’ or does it not? Well, I mean, you may not see a direct diamond on four vertices. But as we said before, it could be a more indirect diamond structure. So, if you can spot that diamond structure, then you would say the answer is yes. Otherwise, you would probably not be so sure. So, if you need a moment here, please feel free to pause and ponder for a second before you commit your answer.\nAlright, so you can probably see here that there are choices of X and Y for which we can say that there are two distinct paths between X and Y going from X to Y. So, let us say that X, for instance, is 1, and Y is 5. So, you have the path 1 2 4 5 on the one hand, and then 1 3 5 on the other. So, these are two paths going from X to Y that are different from each other. And that is why you would say that in this case, you do have a diamond inheritance.\nNow let us talk a little bit about what does it mean for the two paths between X and Y to be different? I think there are two natural interpretations of the word ‘different’ as given in the problem statement.\n(Refer Slide Time: 08:16)\n \nSo, the first interpretation could be that these two parts are completely disjoint from each other. And the other could be that they differ on at least one vertex other than the endpoints. Of course, when I said completely disjoint, once again, you exclude the endpoints because these two paths, of course, start and end at the same vertices, namely X and Y. So, let us just argue that it does not really matter which interpretation you go with, they actually amount to the same thing in the following sense.\nSo, first of all, if you have two paths that happened to be completely disjoint, except for the endpoints, then, of course, you do have two paths that differ on at least one vertex because, well, of course, they differ on all vertices, and there is at least one vertex other than X and Y. So, if you have two paths that are different in the first sense, then they are also different in the second sense.\nOn the other hand, suppose you have two paths that are different in the second sense, they differ on at least one vertex, then I would argue that you can find X and Y, maybe not necessarily the same X and Y. But you can find, you know, probably a different diamond of the first kind that is different in the stronger sense of being completely disjoint.\n(Refer Slide Time: 09:30)\n\nAnd the way to see this is that well, let us take a look at the two paths that differ on, you know, at least one vertex. So, here are two paths that are overlapping at a couple of vertices, and are at least different in a few places as well. And X and Y are the two red vertices at the extreme ends. So, basically, what you could do is jot down the list of vertices on these two paths that are guaranteed to differ at at-least one vertex, and essentially you pursue these paths simultaneously.\nIt is possible that the first few vertices are also common. So, you just make a note of the first time that you see two different vertices on the two paths. And then you make a note of the first time that, once again, the paths converge. So, for instance, here, the yellow vertex in the middle is the first time that these two paths end up having a common vertex. And the red vertex is essentially where we started and the paths immediately diverged.\nIt is possible that after the red vertex, you had a little bit of a common thread for some time, in which case, we would push the red vertex forward until the path began to diverge. And notice that it must diverge at least once because we know that they are different at, at least one vertex. So, in this example, choosing the left red vertex and the yellow vertex in the middle as our new choices for X and Y, we get a diamond inheritance.\nIn the first sense, we get a pair of paths that are different in the sense that they are completely disjoint, except for the endpoints, just by the way that we chose them. So, it does not really matter which of these definitions you work with. And for the most part, we will try to be looking for paths that are completely disjoint internally apart from X and Y because that is just going to be generally more convenient.\nAlright, so how are we going to solve this problem? So, essentially, we are looking for something that looks like a cycle in the underlying undirected graph. But in the oriented sense, it is essentially the union of two paths that start and end at the same vertex. So, well, let us think about performing, for instance, a DFS.\n(Refer Slide Time: 11:46 & 12:24)\n \nAnd let us think about what happens when you visit one vertex more than once. Does that tell us something about the potential existence of two different paths? Well, this is meant to be a bit of a hint. So, if you like, please feel free to pause here. And think about if a vertex being visited more than once by, in fact, either a DFS or BFS traversal is something that could help you detect instances of diamond inheritance. Come back once you are ready, and you have given this a thought.\nAlright, so just to make this a little more specific, let us go back to the DFS code that we have been working with. And basically, the question I am asking is, suppose you encounter a vertex, which you have already visited. So, in particular, you are looking up the neighbors of the current vertex. And let us say the first neighbor that you find is a vertex that is already been visited before.\nSo, what does this mean for us? For DFS, of course, it just means that this is a vertex to be avoided. So, it is just going to move on. But for the problem that we are solving right now, this vertex is an interesting vertex because, well, because it was visited, we know that there is already some way of reaching this vertex from the route. And the fact that we are approaching it again, probably means that there was a different route for arriving at this vertex as well and maybe this is a sign that there is some diamond inheritance.\nNow there are two questions that are pertinent at this point. First of all, can we be sure that there is indeed an instance of diamond inheritance if a vertex is visited more than once? And the second thing is, is it possible that there is some diamond inheritance somewhere, but perhaps it does not get identified in this way? So, perhaps if you do encounter this situation, you can be very sure that yes, we do have a diamond inheritance.\nBut if you do not encounter this situation, perhaps there was some instance of diamond inheritance, but you missed it. So, you have to kind of convince yourself in both directions. So, again, I think this is a more elaborate version of the hint and again, if you want to think about things, this would be a good time to pause. When we come back, we are going to actually try and argue both of these aspects of what we are trying to claim here.\n(Refer Slide Time: 14:21)\n \nAlright, so let us do this one step at a time. My first claim is that if the DFS traversal finds some vertex more than once, then there is in fact an instance of diamond inheritance somewhere in this graph. So let us see why. So, since we are considering a vertex that was visited by DFS more than once, let us just consider the scene when it is being visited the second time.\nSo, this means that it was already a visited vertex, and somebody is approaching it again through the DFS traversal. Of course, DFS will kind of ignore this, but we just want to detect this and see if there is something that we can conclude from here. So, let the red vertex denote the visited vertex and let the pink vertex denote the current vertex, which has essentially approached the visited vertex. And as I said in the original DFS implementation, DFS is just going to ignore this vertex and move on.\nBut we want to freeze time here and think about what happens. So, since the read vertex is a visited vertex, it must be the case that there was some path to this vertex from the source. That is why it was visited in the first place. So, we got here somehow, and this path could have been a more, it could have been a more tree-like structure in terms of how the actual traversal played out. But from whatever that structure was, you can extract a path that is fairly straightforward to check.\nSo, I leave that to you to, sort of, confirm offline. But basically, the point is that there is a path from the source vertex to the visited vertex. Now similarly, this is also true for the current vertex. The current vertex is just being visited. And therefore there is some path from the source vertex to the current vertex as well. Now, these paths may not be different in the sense of being completely disjoint.\nSo, for instance, this path could look something like this where there is some overlap with the path from the source vertex to the other visited vertex as you can see here. But because of what we have already argued, as long as we have two paths that are different, and we know these paths to be different because they at least differ on, for instance, the pink vertex and the vertex that is the parent of the red vertex. We know that these vertices cannot possibly be the same.\nSo, since these are two different paths from the source vertex, the vertex in blue to the visited vertex, which is the vertex in red, we know from our previous argument that we can from here actually derive a pair of paths, which are in fact completely internally disjoint. So, therefore, we do have an instance of diamond inheritance. So, that works.\n(Refer Slide Time: 17:17)\n \nNow, is it true that if there is some instance of diamond inheritance somewhere, then there is some DFS, which is going to catch hold of it using this strategy that we have just described? So, in particular, we claim that if there is an instance of diamond inheritance between the vertices X and Y, then if we were to start a DFS from X, then this DFS traversal will, in fact, visit Y more than once for sure. So, to see this, let us prove an auxiliary fact first.\nIn a directed graph, if you have a path from U to V, then V is going to be visited in the DFS that originates at U. This might sound like a reasonably obvious thing to say. But let us just be sure by arguing this a little bit formally. So, suppose not. Right. So, suppose there is a path from U to V. But V is not a visited vertex in the DFS starting at U. Then, well, let us look at this path from U to V.\nAnd let us identify the last vertex on this path that was visited. So, this is well defined, because U is definitely a visited vertex. That is where it all started. And let us just try and pinpoint the last vertex on this path that was visited. Well, whatever that last vertex is, it is not V because we are assuming that V was not visited for the sake of contradiction. So, that last vertex is lying somewhere in the middle of this path.\nBut now notice that the way DFS works is that it is going to approach every out neighbor of this vertex, which was presumably the last visited vertex on this path. And at that point, it would have certainly approached the vertex, which was the very next vertex on this path. And therefore the next vertex would have also been visited contradicting our choice of, you know, the last visited vertex. So, if this argument went by a little bit too quickly then there is a link in the description of this video, which has a write-up of the proof of this fact that every reachable vertex is in fact visited. And you could take a look at that as well. But why are we interested in this fact?\n(Refer Slide Time: 19:29)\n\nWell, remember, what we are given is the fact that there is some diamond inheritance between X and Y. And we want to argue that Y has been found twice by the DFS starting at X, at least twice. So, what does it mean that X and Y are witnessing diamond inheritance? It means because of what we showed earlier, we could just assume that there are two internally vertex disjoint paths between X and Y. So, here are these two paths, for example.\nAnd now let us just look at the vertices that appear just before Y on these paths. Right. So, these are the two pink vertices. Notice that these two pink vertices are reachable from X, therefore they are going to be visited by the DFS traversal starting at X. But if they are visited, then whenever both of these vertices are visited at whatever times, they are going to try and approach Y. Now at this point, Y may or may not be a visited vertex. Let us say that the pink vertex is visited, let us say that the pink vertex that is on the top path is visited first.\nAnd when it approaches Y, perhaps Y is not a visited vertex, or maybe it is being visited already, it does not really matter. The point is that because both of these pink vertices are visited vertices in the DFS traversal starting from X, both of them will witness at least one ping to Y. So, this proves the fact that if there is a diamond inheritance between X and Y, then for sure, you are going to approach Y more than once in the DFS traversal starting at X.\n(Refer Slide Time: 21:08)\n  \nSo, this is the statement that we just proved. And this also motivates our solution. So, how would we basically take advantage of the facts that we have just shown and wrap it up in an algorithm that will help us identify diamond inheritance?\nWell, what we could do is, essentially, guess all possible choices of X. We do not know where the diamond inheritance might originate. So, we simply try all possible vertices. But having fixated on a vertex, essentially, we run a DFS starting from that vertex and watch out for whether this event happens that some other vertex is approached twice, is reached twice, by the DFS traversal. It does not have to be exactly two times, of course, what is important is that it is reached more than once. That is what we want to watch out for.\nAnd notice that this guessing of X is really required. You cannot just start a DFS at your favorite vertex and, you know, if this did not happen, no other vertex got approached more than once, you just call it a day and say that there is no diamond inheritance, that will not work. And I want to flag this and emphasize it because in our example, so far, it has basically not really mattered where we start our BFS or DFS, we just say started at some vertex and, you know, be done with it.\nBut here, you really have to initiate your DFS from every possible vertex. I mean, just to really emphasize that it would not work if you just started from your favorite vertex. Let us go back to the example that we had, where we did have diamond inheritance, this was one of the sample inputs. And now imagine starting your DFS at vertex 5, for instance. You are not going to be able to detect this diamond inheritance here, because the DFS from 5 will simply make no progress. There are no neighbors going out of 5, and therefore the DFS will really not do any work.\nSo, it is really important that you try every single vertex. But once you do that, everything that we have argued so far essentially amounts to proof of correctness for the approach that we are just proposing here. So, with all of that said, I think we are ready to take a look at the implementation.\n(Refer Slide Time: 23:25)\n \nSo, let us go to the standard DFS that we have. So, the first few lines are exactly identical to what we normally do. But what is new here is this else block where we say that look if this is not the first time that we are seeing you, then that means that we have found what we want. So, let us just return and let us make a note of this fact. And the way we do this is or at least the way that I have done it in this implementation is to change the status of a global flag variable.\nSo, we reset ‘flag’ to false, and then basically, this is the outer loop where we are guessing X, and we said that we will run a DFS starting at every vertex. So, that is the ‘for’ loop here right on the top. It is basically trying to run a DFS starting from ‘i’ with ‘i’ ranging from 1 to n. And of course, before you run DFS, make sure that you clean up your visited array so that it is all fresh and ready to use.\nAnd when you come out of DFS, you just check the flag variable. If the flag variable has been set to false that means that you actually found an instance of diamond inheritance and you can return as much. You can say well yes, you did find diamond inheritance. But if this was never triggered, and you tried a DFS starting from every single vertex, then at that point, when you come out of the outer for loop, if you actually survived the whole thing, and you did not return control from inside the for loop, then outside the for loop, you can say, well, there is no diamond inheritance in this instance.\nAnd you can say that with confidence because of everything that we have just argued. So, as usual, this being a Google Code Jam problem, the overall input is going to have a bunch of test cases. So, you want to be careful about remembering to reset your flag variable as you go from one test case to the next one.\nNot doing this will obviously lead to inaccurate answers. And I am speaking from experience. So, make sure that you reset your flag variable properly. I am not showing you the part of the code that does the input-output because that is by now fairly routine. But if you want to take a look at the entire code that actually works, then you can find it in the usual place at the official repository for these lectures.\nAnd once again, all of this code is in C++. So, if you are able to rewrite it in your favorite language, please do that. And please do submit a pull request. So, with that, we have come to an end of our exploration of applications of BFS DFS traversals. And I hope that you enjoyed this. A quick parting comment is in order. So, all the examples that we saw this week, I think by just looking at the problem statement, the graph formulation, basically, was really quite transparent.\nIn the problems of bipartiteness and covering you were literally given a graph as a part of the problem statement and you just had to work with that quite directly. And here, although there was some language with respect to classes, inheritance, and so on, it was really quite clear that this is screaming for a graph formulation. So, this was quite, quite evident. Sometimes the interesting thing about BFS DFS applications and with some of the other things that we will see in the weeks to come, interesting thing is that the graph formulation itself is not so obvious.\nSo, you might be given a problem with permutations, or there might be some random story about something that looks like it has nothing to do with graphs. And yet, the whole problem can be solved quite nicely by just finding the appropriate graph modeling. So, you will find a few practice problems in the extras section on the course website, which give you a couple of examples where I think the graph model is a little less obvious.\nBut since this was the first week that we were talking about graph algorithms, I felt that was okay to focus on problems where you do not have the additional burden of modeling a strange situation as a graph. That does require some imagination and creativity. And we will have plenty of opportunities to see that play out as we go over examples in the coming weeks. So, I hope that you are all excited to be doing more problems based on graphs and I hope that you had a good time with BFS and DFS.\nSo, please let us know what you thought through either the comments on this YouTube video or by letting us know on the Discord community. You could join the conversation there or on the Google Groups mailing list, especially if you are watching this during the active run of a course. Thank you very much, and we will see you back next week. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W05/Lec27.html",
    "href": "materials/cpnotes/W05/Lec27.html",
    "title": "M 3 (Cover It!)",
    "section": "",
    "text": "Lecture - 27\nGraph Foundations - Module 3 (Cover It!)\n(Refer Slide Time: 0:12)\n\nWelcome back to the third module of the fifth week in Getting Started with Competitive Programming. So, this week, it is all about graph traversals. We are looking at applications of BFS and DFS. And let us look at another one of them through this problem called ‘cover it,’ which appeared in a Div 3 Codeforces contest. This was contest number 565, and it was the fifth problem in the set. It was a set, which had six problems altogether.\nAnd the fifth problem in the set is usually an indication that this problem is one of the relatively harder problems. In fact, if you look at the stats, you will see that more people solve this problem than the fourth one. But it was still only solved by 1300 people relative to about 7000 odd people who did the first one. So, I think there is a relative difficulty thing there. It turns out that this problem has a really cute and simple solution.\nBut it does require one observation which may not be obvious at all. So, that is what we are going to explore. But the final solution is fairly short and sweet. And especially once you have developed some facility with writing up BFS DFS traversals, it should be a pretty quick thing even to code up once you know what the main idea is. So, this problem does not have too much of a backstory. So, let us just get to it. We have a very specific task to do.\n(Refer Slide Time: 01:36)\n\nSo, what we are given is an undirected, unweighted, connected graph, which has n vertices and m edges. This is also a simple graph. So, there are no self-loops or multiple edges. All of this is straight from the problem statement. And remember that if you go back to the very first video that we did this week, we said that this is going to be our default happy setting where the graph is simple, and it is undirected, unweighted, and in this case, we are also given that it is connected. So, that is, that is a familiar situation. And what are we supposed to do?\nWell, we are supposed to figure out if we can find a subset of at most n/2 vertices, n/2 floor. So, if n is odd, we want the smaller half in some sense. So, we want at most floor n/2 many vertices, which have the property that each unchosen vertex is adjacent to at least one of the chosen vertices. Now, those who are familiar with graph theory terminology may recognize this as what we call a dominating set.\nA dominating set in a graph is a subset of vertices, which is such that every vertex that is outside the dominating set has a neighbor in the dominating set. And essentially, what this problem is telling us is that you are given a connected graph, and you are supposed to find a dominating set that consists only of at most half the vertices. We are also promised that the answer always exists and if there are multiple answers then you can print any of them.\nNow the fact that the answer always exists can be interpreted in two ways. One is that you are only given such graphs that have such a subset. Or it could be that the answer is universally true. That any connected, undirected, unweighted graph on n vertices always has a dominating set on at most floor n/2 many vertices. So, we are about to figure out if this is universally true. But before we do that, let us just get used to the idea of what it means for a subset of vertices to be a dominating set by just pulling up a few examples.\n(Refer Slide Time: 03:37 & 04:04)\n \nSo, here is a graph that you might remember from the first module. So, you can see that there is sort of an outer circle and an inner circle. And they both have the same number of vertices. And it turns out that you could choose either the inner circle or the outer one. And those would be perfectly valid dominating sets. And their sizes are, of course, exactly half of the total number of vertices. So, this is, in fact, exactly what we want.\nIf you look at the graph that we saw in the previous module – this is a bipartite graph, then, well, a valid dominating set would involve simply picking all the vertices on one of the two sides. Right. And if you want the smallest possible dominating set and one that is easy to see, then you could simply pick the smaller of the two sides. And notice that this already guarantees you at least on connected bipartite graphs that you always have a dominating set involving at most half the vertices.\nBecause when you have two parts, at least one of the two parts will have at most half the vertices. Right. It is possible that both of them are exactly half and half. But if they are not both exactly half, then it is going to be that one of them is more than half and the other is less than half. So, you just pick the smaller side and you would have a dominating set of the desired size.\nNow moving beyond these really specific examples, let us just think about what would be a way of finding a small dominating set, whereby small, I simply mean a set whose size is at most half the total number of vertices. So, how would you find a small dominating set on a general graph?\nWell, you could, for example, just try an arbitrary partition of the graph into two subsets of the same size. And then basically examine if neither of them works, then can you move things around a bit, so that you can fix the partition and turn it into a dominating set.\nIf you play around with this a little bit, you might eventually end up coming up with proof of why you can always find a dominating set of size at most floor n/2. Now, I will leave you to think about this a little bit and fool around with some more examples and build up some intuition. But as I said, there is really one key observation after which you end up basically solving the entire problem.\nAlso, knowing that this is a problem that has come up in the context of graph traversals, you might want to execute a BFS or a DFS, and just see if these traversals give you any hints about dominating sets. Like, do they have, somehow in a natural way, a dominating set hiding somewhere if you were to execute one of these traversals?\nSo, take your time. Think about this for a moment. And as I said, when we come back, we will discuss the one key idea that essentially solves this problem. Alright. So, hopefully, you had a chance to think about this a little bit.\n(Refer Slide Time: 06:48)\n  \nLet me show you a picture of a BFS traversal with the layers color-coded so that alternate layers have different colors. So, the solid edges from this picture are the edges along which the traversal actually executed. And all the dotted edges are all the remaining edges from the graph that their traversal did not have to follow. Alright. So, given this picture, is there anything that stands out? Notice that just like we did for the previous problem, the alternate layers have been colored using different colors.\nWe also said that if your graph happens to be bipartite, then you could just pick one of the two parts and that would be a valid dominating set. So, a very reasonable thing for you to think maybe would be that, well, the red and the blue vertices form some sort of partition into two parts. So, maybe we could just pick one of them. But notice that for a general graph, which is not a tree, the red and blue partition may not be actually a bipartition.\nSo, in particular, if somebody just gives you a partition into two parts, you could not just say that you will pick the smaller part. And that would be a dominating set. Right. Because it is possible that the other part has a vertex, and all of its neighbors just sitting on the other side. And so this would not be a valid dominating set. But with this particular bipartition, even though notice that because of these extra graph edges that I have shown here, this is not necessarily a bipartition. It is not, the graph is not bipartite.\nIn fact, you can see that because there is a triangle right on top. But in spite of that, I think these partitions are still fairly helpful in the context of building a dominating set. So, in fact, you might want to treat the picture here as a hint and just work through the problem of finding a small dominating set for this specific example. And I think you might find some pretty nicely generalizable intuition. Really think about not just finding some small dominating set by brute force.\nBut by considering if there is a natural choice for a dominating set based on the way that these vertices have been colored for you. And think about why this will actually always form a dominating set in a more general sort of way. So, please feel free to take a pause here. I think you have a few more pieces of the puzzle in place. And you might just completely discover the solution yourself if you were to spend some time on it at this stage of the discussion.\nAlright. So, hopefully, you had a chance to think through this. Notice that, in fact, both the red vertices as well as the blue vertices form dominating sets on their own. And the reason for this is that, well, let us consider the red vertices first. Notice that because the BFS traversal started out with a red vertex, it is pretty much by the definition of the way that traversal works, every blue vertex is adjacent to a red vertex.\nIn fact, many people when implementing BFS like to maintain an explicit parent array, where the goal is to basically remember: Why did you get added to the queue in the course of the BFS traversal? So, if I got discovered by a particular vertex, and because of that I got pushed to the end of the queue, then I am going to remember that vertex as being some sort of a parent vertex, so the vertex that was responsible for my discovery.\nSo, in particular, notice that every blue vertex is discovered by a red vertex or has a red parent, which means that if we were to choose all the red vertices, then every blue vertex, which would be in this case, the unchosen vertices would end up having a neighbor among the red vertices because that is simply how the traversal worked. Now it is the exact same story for the blue vertices as well.\nSo, every red vertex has a blue parent, except possibly for the red vertex that started the whole traversal. So, that vertex does not have a parent because it was the beginning of it all. But it certainly has blue neighbors and all the remaining red vertices have blue neighbors because they have, in particular, blue parent vertices for sure. Therefore, what we can say is that both the red vertices and the blue vertices, which are essentially vertices that are on the odd layers of a BFS, traversal, and even layers of a BFS traversal. Both of these subsets of vertices are essentially dominating sets.\n(Refer Slide Time: 11:26)\n  \nSo, the BFS traversal essentially gives us a partition of the entire vertex set into two parts. These are the parts that belong to the odd layers, and the even layers, which we had colored red and blue. And notice that these parts may not always have exactly the same size. So, it is possible that the red part is bigger than the blue part, or that the blue part is bigger than the red part. But just like we said, when we were talking about bipartite graphs, it does not really matter.\nAs long as you have a partition of the vertex set into two dominating sets, we know that at least one of them is going to be suitably small, simply because we are only looking for a dominating set, which has at the most floor of n/2 many vertices. So, it cannot be the case that both of these parts are strictly bigger than the floor of n/2. Because if that was true, then the total number of vertices would be greater than n, which would be a contradiction. So, with this one observation, we are basically done.\n(Refer Slide Time: 12:24)\n\nSo, what we do is we collect all the vertices in the odd layers in one part and all the vertices in the even layer in another part. And we essentially, just need to know which of these parts were smaller. And remember, because the problem asks you to actually output a subset of vertices, you also have to keep track of which vertices belong to which part so that you can output them at the end.\nNow, you might remember that I did say that if you wanted to solve the previous problem about bipartiteness using BFS, you might get some hints from here. So, remember that for the previous problem also, you wanted to keep track of vertices on the odd and the even layer separately, but there, all you wanted to track was the sizes of the two parts and that is all that you cared about. So, essentially, the code that we write here would also be relevant to the previous problem. You just have to tweak what you output a little bit for this to work for the previous problem.\n(Refer Slide Time: 13:24)\n\nAlright. So, with that said, let us take a look at the implementation. So, here is the usual BFS code, but we just need to introduce a few extra variables to keep track of what is going on with the odd and the even layers. So, we have these two vectors, odd and even which are designed to actually keep track of the vertices and we have the variables O and E, which will keep track of the sizes.\nSo, to begin with, when we initialize BFS with the first vertex, then let us say that that is an even layer, if you think of it as layer 0, then I think that would make sense. So, we add this vertex to the even list, and we increment the number of even vertices. And then the rest of it is standard BFS initialization.\n(Refer Slide Time: 14:08 & 14:52)\n \nNow when we perform the actual BFS traversal, and we add a new vertex to the queue, we have to basically figure out: Does this go on to an even layer or an odd layer? So, this is where the distance array comes in handy. So, remember that the distance array helps us keep track of distances from the route, the place from where we started the traversal. And if the distance value for this new vertex is odd, then it is on an odd layer.\nAnd if it is even then it is on an even layer. So, that is essentially the if statement here, which lets you appropriately add the vertex to either the odd list or the even list. And you should remember the increment your odd and even counts as well.\nThese counts will be important for the final step where you have to decide which of these lists is a smaller one. Of course, instead of maintaining the counts as you go along, you could of course just evaluate the lengths of these lists once at the end as well. So, either way, works out fine. But the final step would just involve printing all the vertices in the odd list or the even list as the case may be. And then you are pretty much done.\nSo, this is essentially the complete solution to cover it. And as always, you can find this code in the official repository. There is a link in the description of this video as well. And I hope that you have a chance to check this out. And, you know, if you write this up in your favorite programming language, please do submit a pull request. And if you have any questions or comments, or perhaps a different way of doing this, then please let us know by dropping a line in either the mailing lists or the Discord community forums.\nSo, we will see you there. And we want to do one more problem this week called Diamond Inheritance. And that is coming up in the next video. So, I will see you there. Thanks for watching and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W05/Lec26.html",
    "href": "materials/cpnotes/W05/Lec26.html",
    "title": "M 2 (Mahmoud and Ehab and the bipartiteness)",
    "section": "",
    "text": "Lecture - 26\nGraph Foundations - Module 2 (Mahmoud and Ehab and the bipartiteness)\n(Refer Slide Time: 0:11)\n\nWelcome back to the second module of the fifth week in Getting Started with Competitive Programming. So, this week our focus is on graph traversals, and specifically, we are looking at BFS and DFS. Just as a recap, let me point out that in the first module, we covered some pretty foundational material. We looked at how to represent graphs. We compared the adjacency matrix and the adjacency list representations, which are two of the most commonly used representations when it comes to graphs, and then we actually went through implementation for both BFS and DFS. And we looked at their complexities based on whether you were using a matrix representation or a list representation.\nSo, all of that has been done and dusted in the first module for this week. So, hopefully, you are here because you have either already finished watching those videos or because you know all of this already. If this is not the case, then you might want to do this first, before beginning to actually work on some of these problems.\nAlso, although for most problems where BFS and DFS are applied, you can actually usually use either approach and make things work. There are certainly applications where the problem is better suited to one traversal over the other. So, really make sure that you are comfortable with both of these algorithms because you never know which one will come in handy and which one will be the more natural approach to use, and in some cases, which one would be the only approach that actually works.\nSo, with all of that said, let us begin by looking at our first problem here, which if I am pronouncing it right, is called ‘Mahmoud and Ehab and the Bipartiteness.’ So, this was from a Codeforces contest, contest number 435. It was the second problem and I think all of the problem statements involve stories around these two characters.\nFor this problem, however, the story plays a negligible role. So, let us just get straight to the problem statement, where we are basically hit with a few definitions. So, let us go through them one by one.\n(Refer Slide Time: 02:12)\n\nSo, first, we are told that a tree is a connected acyclic graph. Now the notion of a tree may already be a familiar one. You have certainly worked with trees in data structures. In the context of graphs, a tree is exactly what is being said here. It is a graph, which is connected and that does not have any cycles. So, just to be sure, let us discuss these terms a little bit.\nFirst, what does it mean for a graph to be connected? Intuitively, it means that every vertex in this graph is reachable from any other vertex. So, imagining that your graph is some sort of a road network, the idea is that you should be able to walk around freely in this graph, as long as you are walking along edges. So, that is a constraint. You cannot jump from one vertex to another one that is not adjacent to it. That does not have a direct edge to it.\nBut that does not mean that you cannot reach it, you can walk around and probably take a longer sequence of edges to get to this other vertex. So, two vertices that have a direct edge between them are adjacent. But for them to be connected, all we need is that there is a sequence of vertices that you can follow where the consecutive vertices are adjacent. They are connected by a direct edge and you can just walk around to get to this other vertex.\n(Refer Slide Time: 03:31)\n\nSo, this sort of sequence is called a path. So, you can use a path to travel around in this graph and a graph is connected if you have such a path between any pair of vertices. So, you could come up with examples of graphs that are not connected. So, for example, if you draw on a piece of paper, let us say two triangles, for instance, which are disjoint from each other, then notice that there is no way for you to start from one triangle and end up in the other one.\nOnce you are in one of these triangles, you are kind of trapped to travel only within that triangle. So, it is easy to come up with examples of graphs that are not connected, and notice that you can use graph traversals to figure out if a graph is connected or not. Because one run of either BFS or DFS will essentially visit every vertex that is reachable from the vertex that you start the traversal from.\nSo, just by checking at the very end if every vertex is visited or not, you know if your graph is connected or not. In fact, if your graph is not connected, then the graph is essentially a collection of connected pieces, which are called connected components and you can even use these graph traversal algorithms, either BFS or DFS, to figure out how many of these pieces there are.\nSo, this is a fun exercise and there is a problem listed in the extra section which will allow you to practice just counting the number of connected components in a graph. So, while on the topic of connectivity, I just felt like I should mention that. But now let us move on to talking about cycles.\n(Refer Slide Time: 05:10)\n \nSo, a cycle is simply a path with its ends also connected by a direct edge and what we are given is that our graph does not have cycles. So, remember we are talking about trees.\nSo, trees are connected acyclic graphs and we were just making sure that both of those terms make sense. Now, the second definition that we have to contend with is this concept of a bipartite graph. So, a bipartite graph is a graph whose vertex set can be partitioned into two parts such that every edge essentially goes across. So, you pick any edge in the graph, it has one of its endpoints in the first part and the other endpoint in the second part.\n(Refer Slide Time: 05:52)\n \nSo, bipartite graphs are typically visualized in this way. You can essentially split the vertex set into some sort of a left part and a right part and you see that all of the edges are going across.\nHere is an example of what is called a complete bipartite graph, which basically means that you have the two parts and you have all possible edges between these two parts. Now, let us say that the two parts of a bipartite graph have ‘a’ and ‘b’ many vertices. So, let us say that small a denotes the number of vertices in one of the parts and small b denotes the number of vertices in the other part. What is the maximum number of edges that your bipartite graph can have?\nSo this example here should give you a clue. But this is essentially a counting question and one that will be relevant to our solving this problem. So, please feel free to pause the video here and think about what would be an answer to this question. Alright. Hopefully, you had a chance to think about this for a bit.\nIn this example, you can see that we have a bipartite graph where the paths have 5 and 3 vertices, and if you were to just count the number of edges, you will see that there are 15 edges, which happens to be 5 x 3 and one of the ways of seeing that it is indeed 5 x 3 for a good reason is to isolate the edges incident on each vertex on one of the sides.\nSo, let us look at it from the perspective of the red vertices. You would see that each of the red vertices has three blue neighbors and this is going to be true in general for any complete bipartite graph with parts that have a and b vertices. So, each of the ‘a vertices’ will have ‘b neighbors,’ which means that the total number of edges is going to be simply the product of the sizes of the two parts, ‘a’ x ‘b.’ So, let us just keep that fact at the back of our minds, and now let us go back to the problem statement.\n(Refer slide Time: 07:51)\n\nSo here, what we are told is that we are given a tree consisting of ‘n’ nodes and we have been asked to add edges to it in such a way that the graph remains bipartite. Notice that the phrase is that the graph is still bipartite, which implicitly tells you that a tree, to begin with, is already bipartite.\nNow, I think this is a really fun fact to try and prove for yourself, especially if you are not already familiar with it and I will not prove it here because the proof is kind of implicit in the algorithm that we will come up with to solve the problem. So, I do not want to give it away completely immediately. But I will leave you with three hints for trying to prove that all trees are bipartite and I hope that you have some fun with this.\n(Refer Slide Time: 08:39 & 09:31)\n \nSo, one way of showing this is to use induction on the number of vertices and a hint in this context is to use the fact that every tree has a leaf. Now that of course sounds like a perfectly reasonable statement in English. But it is also true of graph-theoretic trees. So, a leaf is simply a vertex, which has exactly one neighbor, and if you do not know this already, you can show this by induction as well.\nSo, having proved that every tree has at least one leaf, as long as it has at least two vertices, this is always true, you can actually try and see what happens if you remove the leaf in the induction step of, you know, the statement that every tree is bipartite. It is typically going to be easy to sneak a leaf back in, as you perform the induction step. So, that is the first hint.\nThe second one is to essentially use this famous characterization of bipartite graphs. So, it is well known that a graph is bipartite if and only if it does not have any odd cycles, which are cycles with an odd number of vertices in them. Now of course, here it is easy to put 2 and 2 together.\nA tree not only does not have odd cycles – it does not have any cycles. So, if you knew this categorization, it is just a direct application. But in case you do not know this characterization, I would welcome you to try and actually prove this characterization because this will imply what you want. And once again, think about whether you can use a breadth-first search traversal to actually prove this statement here. So, that would be the second approach.\n(Refer Slide Time: 10:17)\n\nThe third approach will be to actually demonstrate an explicit bipartition. So, you could fix your favorite vertex in this graph, and on the one side, you could collect everything that is at an even distance from this vertex. So, what is the notion of distance in the context of graphs? Well, the distance between any two vertices would be the length of the shortest path that joins them.\nSo, for instance, your immediate neighbors would be at distance 1, the neighbors of your neighbors would be a distance 2, and so on. Importantly, we are working with unweighted graphs here. So, every edge is just going to contribute 1 unit to the distance calculation.\nSo, if we just collect every vertex, which is at an even distance from a fixed vertex and every vertex which is at an odd distance from the fixed vertex with the fixed vertex landing on the even side because it is a distance 0 from itself, so this will turn out to be, at least for trees, a valid bipartition in that every edge will go across. And you want to think about why this is the case and again, if you like, you can use a traversal to help navigate this argument.\nSo, use any of these three approaches and see if you can convince yourself that trees are bipartite. Of course, it also helps as a warm-up to just play around with some examples to build your intuition first. So, once you have done that, you can come back and continue the discussion that we are going to have here, which is again, back to the problem statement. What is our task here? Our task here is to essentially add as many edges as we can while maintaining the bipartiteness of the tree.\nWe are also supposed to maintain the fact that the graph is simple because notice that the question here is to add as many edges as possible. And if we were not constrained to work with a simple graph, at the end of the day, we could just keep adding as many edges as we want between a fixed pair of vertices and this would not make so much sense.\nSo, in a way, this is a good constraint for us that makes the problem nice and well defined. And now the question that we really have to think about is: What is the largest number of edges that we can add to a tree while still keeping it bipartite?\nSo, in some sense, we want a complete bipartite completion of the tree that we are given, and the reason I say that is because we have talked about complete bipartite graphs in an example earlier. Notice that a complete bipartite graph automatically maximizes the number of edges that we can have once the parts are fixed. So, what are the parts that we are working with?\n(Refer Slide Time: 13:03)\n \nRemember, we are given a tree as input and we just said that a tree is bipartite and hopefully you had a chance to convince yourself of this fact. So, let us look at the tree from the bipartite perspective. So, let us redraw this tree so that all the vertices in the left part are in this left circle here and all the vertices in the right part are in the right circle.\nSo, remember, given that trees are bipartite, you can come up with such a partition and you should also be able to convince yourself that up to swapping the left and the right parts, this partition is in fact unique. And that will be a fallout of the way that you proved that every tree is bipartite. So, again, if this is not completely clear that these parts are unambiguously defined, given a tree, then please take a moment here to actually absorb this fact and convince yourself of it.\nSo, now let us take a closer look at the bipartite representation of this tree. Our task here is basically going to be to fill out the gaps here. Notice that since we have to maintain the bipartiteness, we cannot add any edges with both of their endpoints on the left or with both of their endpoints on the right.\nBut any pair of vertices that is one on the left and the other on the right and does not already have an edge between them is fair game in terms of our being able to add that edge. So, let us just fill in the gaps here and you will see that these are all the missing edges that we can add to turn this bipartite graph into a complete bipartite graph.\nNow, what is this number? And is this our answer? Well, this number is definitely our answer because notice that we cannot add any more edges here under the constraints that we have to maintain bipartiteness, and the final graph has to be a simple graph. So, we certainly cannot do better than this and on the other hand, what we are doing is certainly feasible.\nSo, what we have added here constitutes of valid solution in the sense that none of these new edges violate bipartiteness. We carefully introduced them so that they have one leg in one boat and the other leg in the other boat, they all go across. So, that is safe and we never added an edge on top of an existing edge. So, what we are left with at the end of the day is certainly a simple and bipartite graph. So, we have essentially argued the correctness of this approach.\nI will say that it is easy to see the validity of this solution, the feasibility of this solution. To formally argue that this is the best that you can do, you do need a little bit of an argument to convince yourself that this partition is something that we are stuck with. We really just have to build on this, there was not a different way of partitioning the vertices so that this product of the sizes of the two paths could have possibly been higher, for instance.\nThat is not going to happen and this is the comment that we made earlier that once you are given a tree, there is really only a unique bipartition up to renaming the left and the right paths. So, if you convince yourself of that, then this is, you know, complete proof for why this approach is correct.\nBut in case that is something that you are still not sure about, then there is still a small gap in the argument for the correctness of what we are doing. So, make sure you understand why this partition is essentially unambiguous once a tree has been given to you. Alright. So, now that we know what we want to do, let us just look at what the final answer is going to be.\nSo, if the sizes of these parts that came out of the tree were small a and small b, then what do you think the answer would be? I am going to reveal it in 10 seconds. So, if you want to think about it, please pause the video here and come back when you are ready.\n(Refer Slide Time: 17:11)\n\nAlright. So, the answer is going to be ‘a’ x ‘b’ - ‘n’ - 1, where n - 1 is (essentially) all the edges that we already have. Remember, we are given a tree on n vertices. So, it is a well-known fact that any tree on n vertices has ‘n - 1’ edges. So, I am just taking advantage of that fact, to say n - 1 here. You could equally just say m, where m is the number of edges that you took in as input, it would be the same thing. And ‘a x b,’ if you remember from before, is the number of edges that we have after we add all of the missing edges in.\nSo, if the sizes of the two parts were a and b, we just argued a few minutes ago that the number of edges that we will have in the complete bipartite graph with part sizes a and b is exactly ‘a x b.’ So, that is the total number of edges that we get after doing the completion process and we just have to remember to subtract from this n - 1 to get to the number of edges that we actually added on top of what was there.\nAlright. So, now that we know the answer, the only thing that remains to be done is to figure out a and b. What are the sizes of the two parts in the bipartite representation of the given tree? So how do we figure out this partition? If we can come up with an algorithm for doing this, this will essentially answer the two puzzles that we mentioned during this discussion.\nThe first one was to argue that trees are bipartite and the second one was where we said that this by partition is in fact unique. So, just think about this. If somebody gave you a graph and they told you that it was bipartite and they told you to come up with a partition, how would you go about it?\nWell, you could start with your favorite vertex – could be anyone. And then you could say, look, so if this vertex goes on the left, it could also go on the right, it does not really matter. But to begin with, let us just say, we pick an arbitrary vertex and we just throw it in the left bundle. Right. Then we know that all of its neighbors, all the vertices that it is adjacent to, must, in fact, go on the other side. They must all be on the right.\nSo, we dump all of its neighbors on the right. Now we look at all the neighbors of the vertices that landed on the right, and then we know that they must be on the left because we cannot accommodate edges completely on the right-hand side. So, you just keep doing this dance, going back and forth between left and right, and what you will end up with is a partition. And in fact, it is even a valid bipartition.\nAnd the reason for this is that well, you were promised that the graph is bipartite and at every step, you did whatever you were forced to do. You could not have partitioned it any other way. Otherwise, you would have had a violation and if in spite of all this, the partition that you end up with has edges on one part, on one side, then you can essentially use that edge to argue that your graph was not bipartite, to begin with.\nAnd the intuitive reason for that is as we just said, at every step you did what you were forced to do. You could not have had the partition come out any other way and therefore, you could not possibly have edges within the paths because of the promise that the graph was bipartite, to begin with.\nSo, it would be a contradiction if you had a violation at the end and notice that this process will essentially end up exhausting all the vertices, because again, if it did not, then you can (sort of) argue that the graph was not connected, to begin with. So, any vertex that is not accounted for by this process that you just performed, is going to be a vertex that is not reachable from any of the vertices that you have partitioned so far.\nBut that would violate connectivity. So, you actually know that this process ends up coming up with a forced partition of all the vertices in the graph, which also is an argument for why the partition is unique, which is also something that we mentioned a few minutes ago. So, let us now just recap this whole process with an example.\n(Refer Slide Time: 21:29)\n\nLet us say that we were given this tree as input. We said that we will first fix a favorite vertex. Let us just pick the one on the top and then we said that, okay, we are going to designate this as a vertex on the left side of the partition. I am going to remember that by coloring it red and then we said that all of its neighbors go on the other side.\nSo, let us remember that by coloring the neighbors with a different color, in this case blue. And then we said that, well, we will go over all the vertices that we dumped on the other side, and we will find their neighbors and make sure that their neighbors come back to the left. So, we do that.\nSo, these are all of the neighbors in the next layer of the tree. And we color all of those red and finally, as you can imagine, the last layer is going to go back on the other side and will get colored blue. So, this is essentially our partition for this example. So, all the red vertices go on the left, for instance, and all the blue vertices go on the right.\nNow the way this played out – this probably reminds you of a breadth-first search traversal. This is essentially what it is, as you alternate layers in a BFS traversal. It is like you could go back and forth between left and right and notice that all the red vertices and all the blue vertices are never going to have an edge between them.\nEspecially because we are working with a tree. Right. Notice that you cannot have level edges. Because if you have an edge at the same level, then that essentially means that you have a cycle. So, that is not possible, and other than level edges, let us say you have two blue vertices that are not on the same level, then they are separated by at least one layer of red vertices.\nSo, they are, you know, at least two levels apart in some sense and we already know that BFS trees do not have these packages. So, you could see that there is never going to be an edge between any pair of blue vertices. For two reasons. I mean, blue vertices from different levels because of the BFS structure and two blue vertices in the same level because of the tree structure, because the input graph is a tree. And of course, the same applies to the red vertices as well.\nSo, you could simply do a BFS traversal. Keep track of how many red vertices you encounter and how many blue vertices you encounter. Basically, just keep track of the total number of vertices in the odd layers and the total number of vertices in the even layers, and then you would be done. You just keep this count and then you output ‘a’ x ‘b’ - ‘n’ - 1.\nNow what we are going to do in the next problem has a very similar flavor. So, let us do the implementation using DFS, just to see how you could do the same thing a little bit differently. We are going to pursue the same idea with the promise that the graph is bipartite. Essentially, whenever you are coming out of a vertex that is committed to being on the left or on the right, its neighbors just going to be on the opposite side.\nSo, that is all that you have to keep track of, as you try to do this using a DFS. If you are interested, you can code up this solution using BFS just as well and in fact, if you watch the next video, you might get some hints about how you could do that, even for this problem. But, for now, let us move on to the implementation using DFS.\n(Refer Slide Time: 24:50 & 25:31)\n \nSo, to begin with, we have the standard global variables which are the adjacency lists and the not visited array, which helps us keep track of what has and what has not been visited yet. But we also have this variable called side, which could have well been to separate integers as well. But just for convenience, I am going to keep track of it as an array of length 2, where the first element of this array is going to tell us how many vertices have we built up on the left and the second element of this array is going to keep track of how many vertices have we accumulated on the right, as we build out our partitions.\nNext, let us see how we can use DFS to actually build out the partitions. So, most of this should look familiar. This is the standard DFS code that we have already seen before. But now you might notice that there are a couple of important changes. First of all, the invocation itself takes an extra parameter called ‘s,’ and this sort of helps us keep track of whether we are on the left or on the right.\nSo, ‘s’ is going to be either 0 or 1 and the idea is that this tells us if the vertex ‘u’ was supposed to be on the left part. If it is 0, we take that to be left and if s is 1, then the vertex u is supposed to go to the right part. So, that is what this parameter is telling us. So, in fact, the first thing that we do is increment the value of ‘side of s’ appropriately.\nBecause basically, what is happening now is that we are visiting the vertex u for the first time, and the parameter s is telling us on which side it is. So, we put that on the record by incrementing the appropriate variable in the side array. And once that is done when we actually recurse and we find the first fresh neighbor of the vertex u that we are going to invoke the DFS on, that is the exploration that we are going to do recursively.\nFor this vertex, we have to remember to switch sides because remember this is a neighbor of a vertex that is on side s. So, this vertex itself has to go to side 1 - s. So, for example, if the vertex u was on side 0, then this neighbor of u, which is v that is going to be explored next should be on side 1, which is 1 - s or 1 - 0.\nOn the other hand, if u was on side 1, then v should be on side 0, but that is also 1 - s, in this case, that is going to be 1 - 1, which is 0. So, that is what is going to happen in recursion. So, you can see that as this plays out, for every vertex that you visit, notice that you are going to visit this vertex exactly once you correctly increment the appropriate side variable and you put on record how many vertices you have accumulated on both sides. By the time you are done, you will have the two sizes that you are looking for and you can just output that.\n(Refer Slide Time: 27:54)\n\nSo, if you look at the last couple of lines of this code, that is really the key of the solution, you start your DFS at your favorite vertex – could be vertex 1 and it starts off inside 0 for instance – that is like we said, pick a favorite vertex and put it on the left. That is what we are doing here and once the DFS has run its course remember that given that this is a connected graph, which is also a tree, you will see that DFS is going to correctly visit every vertex and place it on the left or the right peacefully without any violations. And once again, remember that this would have been the only way to do it.\nThere would be really no other partition to contend with this one, which is why we know that what we output on the last line is actually the right answer. So, that is the product of the two sizes that we have of the two parts that we built out and we need to remember to adjust for the number of edges that were already there so, that what we are outputting is in fact, the number of extra edges that we added.\nAlright. So, that brings us to the end of the discussion on this problem. If a lot of the notions that we saw here were already familiar to you, for instance, you already knew what a tree was, you already know what bipartite graphs are, perhaps you even know the characterization of bipartite graphs in terms of odd cycles and so on and so forth. Then, you may have honestly been a little bit bored and this I would say is, for somebody who already is familiar with many of these facts, I would say this would be a relatively straightforward problem.\nOn the other hand, if (many of) these notions were new to you, and you are seeing them for the first time, then I think it is perfectly natural that you need some time to absorb all the different ideas that you have been exposed to even in the discussion for just this one problem. So, please feel free to take your time and rewind and go back to any of the parts that did not make sense the first time around.\nAs always, if you are listening to this during an active run of this course we will look forward to hearing from you either on the Google mailing lists or on the Discord community forum. So, if you have any questions do drop in there or any suggestions, everything is welcome. You could also leave comments on this YouTube video and finally, this code is in C ++, as you can probably tell, and a link to it is in the description, as usual, this is on the official repository.\nIf you have a version of this in your favorite language, then please do submit it as a pull request and we will be very happy to incorporate it, so we look forward to hearing from you. Thanks very much for watching and I will see you back in the next video!"
  },
  {
    "objectID": "materials/cpnotes/W05/Lec24.html",
    "href": "materials/cpnotes/W05/Lec24.html",
    "title": "M 1 (Graph Traversals)",
    "section": "",
    "text": "Lecture - 24\nGraph Foundations - Module 1 (Graph Traversals)\n(Refer Slide Time: 00:30)\n\nHello and welcome to week five of Getting Started with Competitive Programming. This week marks the start of our graph algorithms journey and we are going to be fairly focused on graph algorithms all the way up to week nine or so. In this week, we will talk a lot about two fundamental graph traversal algorithms called breadth-first search and depth-first search, or BFS and DFS for short.\nThese are very popular traversal algorithms, which have a lot of interesting properties and applications. Chances are that you are already familiar with the traversals themselves. If you are comfortable with implementing them, you should feel free to just skip this video and jump straight into the three problems that we will be solving this week.\nHowever, if you are not super familiar with how to implement these traversals, then you want to stick around. We are going to start with actually the basics of graphs themselves and how we represent them, just to make sure that this presentation is self-contained. To begin with, what is a graph?\n(Refer Slide Time: 01:20)\n\nFormally a graph is usually given by a pair V, E, where V can be any set you like and E is a collection of pairwise relationships between the elements of V. The set V is often called the set of vertices or nodes and the set E is usually referred to as the set of edges or connections.\nNow, this particular formulation may strike you as being a little bit abstract and also overwhelmingly simple. But it turns out that even a simple idea can capture a lot of different scenarios. You have probably encountered graphs already in your day-to-day life. For example, the road network in your city can be thought of as a graph, with the key locations being modeled as vertices and roads that connect these key locations as being the edges or the connections.\nSocial networks that you might be a part of can also be thought of as graphs. For example, you have Facebook, where you could think of the people who use Facebook as being vertices and two individuals being friends is being represented by edges. Another popular social media network is Twitter.\nBut the idea of a relationship on Twitter is slightly different from the way it works on Facebook. Typically, friendships on Facebook are mutual. Whereas, on Twitter, you could follow somebody without having that person follow you back. The pair-wise relationships in Twitter are not necessarily symmetric, whereas they are on Facebook.\nWhen you have a ‘symmetric’ relation, you typically model this with what is called is an undirected graph, where the edges do not have any orientations. Whereas if you have an ‘asymmetric’ relationship, then you model them as a directed graph where the edges do have orientations so that you can remember which way the relationship goes. Sometimes you also have mixed graphs, where you allow for both directed and undirected edges. But that is going to be not very relevant to our discussion right now.\n(Refer Slide Time: 03:24)\n\nGraphs usually have a very neat visual representation. You could think of each vertex as being represented by a dot in the plane and whenever you do have a relationship or an edge between these two vertices, you connect them by a line. If you have an undirected edge, it would look like that. If you have a directed edge coming from an asymmetric relationship, then you could represent it with an arrow, with the arrowhead pointing in whatever direction you want it to based on the way the pair is given.\nOf course, if you have both ‘x y’ and ‘y x,’ then you could have arrows pointing both ways. Or if it is a mixed graph, then some of the edges are going to have arrowheads and some of them will not. Now sometimes you want your graph to actually store additional information. For example, if your graph is modeling a road network, then you might want the edges to have weights on them to somehow represent either the length of the road or the quality of the road or the cost of traveling on that road if there is a toll gate, for example, and so on and so forth.\nYou will often encounter graphs that have weights on either the edges or the vertices or perhaps both. Sometimes your edges could also be colored. For instance, maybe you have a friendship network that not only captures friendships but also captures rivalries. You might say that you have a red edge to denote a rivalry, a green edge to denote friendship, and perhaps no edge to denote neutrality, that perhaps these people do not know each other to begin with.\nNow, in some situations, you might also want to allow for the possibility of having multiple edges between the same pair of vertices in a graph. This is usually not the default situation. So, the set of edges, when thought of as a collection of pairs over V, is usually thought of as a set, as opposed to a multi-set.\nWe would not normally allow for this kind of repetition. But maybe your application requires that, perhaps, you are keeping track of the number of times that something happens between a pair of vertices and so on. Notice that you can also capture this with edge weights. Instead of repeating pairs in E, you could just have a weight function that keeps track of the number of times that a particular edge is repeated.\nNonetheless, graphs, where you do allow for repetitions of edges, are usually called multi-graphs, and graphs, where you do not allow for this, are called simple graphs. Another feature of multi-graphs, which is something that is not allowed in a simple graph, is the possibility of having the so-called self-loop.\nYou could have a vertex, which has an edge to itself. This is not something that will happen in a simple graph. But if you are working with a multi-graph, then multiple edges between distinct pairs of vertices and edges from a vertex to itself, all of this is fair game. Normally, we will be working with simple graphs, which are undirected and unweighted.\nBut of course, depending on the problem that you are trying to solve, you might need edge weights – that is pretty common. You might also need your graph to be directed, which is also fairly common. Everything that we discuss here will (generally speaking) apply to directed graphs for sure. We do have to be careful once we start talking about weights.\nFor example, when we look at breadth-first search, we will see that that is one way of getting the shortest paths between pairs of vertices. But this is under the assumption that we are working with an unweighted graph. Once you bring weights into the mix, this may not be true. In fact, next week, we are going to look at other algorithms that deal with this situation when we do have weights to worry about and we will be looking at the shortest path algorithms that take care of this more general case.\nYou do have to be a little bit careful about what exact situation you are in. But as I said, for the sake of making this discussion concrete, we are going to assume that we are working with simple, undirected, and unweighted graphs with the comment that most of this translates quite easily to directed graphs in a very natural way.\n(Refer Slide Time: 07:40)\n \nLet us just take a look at a couple of examples of graphs so that we can get back to how we store them when we write our code. Here is a couple of examples straight from the Wikipedia page on graphs. Now let us take a look at the first way that we can store a graph in memory. How do we represent a graph when we are writing code?\n(Refer Slide Time: 08:04)\n\nA natural way to do this is the so-called adjacency matrix and this is what this looks like. So, this is an ‘n X n’ matrix, where ‘n’ is the number of vertices in your graph and the ‘i j’th entry, which is to say the entry in the ’i’th row and the ’j’th column is a ’1,’ if and only if there is an edge from ‘i to j.’\nNotice that if your graph is undirected, then the corresponding adjacency matrix will be symmetric, which is to say that, for instance, if you were to take the picture of the matrix that you are seeing on your screen right now and if you were to print it out and if you were to fold this picture along the diagonal, then you will see that the colored boxes are going to line up over each other and the uncolored locations are also going to exactly overlap on each other. That is symmetry around the diagonal.\n(Refer Slide Time: 08:54)\n\nOn the other hand, if you are working with a directed graph, then you will not enjoy necessarily this kind of symmetry, as you can see from this example. Again, please feel free to pause the video here and really spot and appreciate the asymmetry in this adjacency matrix. If you just focus on entries on either side of the diagonal, for instance, you will immediately spot examples of asymmetry. Moving on, let us actually take a closer look at an adjacency matrix construction when weights are involved.\n(Refer Slide Time: 09:26)\n\nHere is an unweighted graph with the edge weights written in green boxes alongside the edges, and here is its adjacency matrix representation. It is exactly as you would expect with the ‘i j’th entry denoting the weight of the edge between the vertices ’i’ and ‘j,’ and because this is an undirected graph, this edge weight gets captured twice in this adjacency matrix.\nBut notice that the formulation works just as well to capture directed and weighted graphs as well. The ‘i j’th entry will simply reflect the weight of the edge from ’i’ to ‘j,’ if this edge were to exist in the graph. Now let us just look at a couple of features of the adjacency matrix representation.\n(Refer Slide Time: 10:13)\n \nFirst, notice that it is pretty space-intensive. It actually will always consume n2 units of space, irrespective of whether the graph actually has n2 edges or not. So, a sparse graph is a graph intuitively where there are not very many edges and in particular, let us say that you have only a linear number of edges like you would have if your graph was a tree, for example.\nEven for such graphs, you are actually consuming n2 units of memory and your adjacency matrix is just going to look like a vast ocean of 0s with a few 1s scattered here and there. It feels very wasteful and in the context of competitive programming, you know that apart from time limits, you also have space limits, which makes the adjacency matrix representation infeasible in any situation where you have more than a few 1000 vertices in your graph.\nDo watch out for that and keep that at the back of your mind. If the number of vertices in your graph is in excess of, let us say, 3000 or 4000, then you probably do not want to be using an adjacency matrix representation. But when is this a good representation? Well, it works pretty well for detecting if a pair of vertices have an edge between them or not.\nIf your application makes frequent use of such queries, then probably this is going to be a relevant representation. Notice that checking if there is an edge between ‘i’ and ‘j’ or from ‘i’ to ‘j’ is simply an array look-up if your graph is stored as an adjacency matrix. On the other hand, let us think about how much time does it take to enumerate all the neighbors of a vertex in a graph?\nWhat are the neighbors of a vertex? For instance, in this example, the vertex labeled 1 has neighbors in the vertices that are labeled 2 and 5. Vertex 2 has neighbors 1, 3, and 5. The vertex 6 has only one neighbor and that is 4 and so on and so forth. If you wanted to use the adjacency matrix to actually enumerate all the neighbors of a vertex, how much time do you think that will take?\nIf you think about it for a moment, you will probably realize that this is going to take order ‘n’ time, irrespective of how many neighbors a vertex has. You could be vertex number 6 with just 1 neighbor. But for the algorithm to be able to know that, it still has to scan the entire row or column corresponding to the vertex 6 to figure out how many neighbors it has.\nOf course, if it is an undirected graph, you could scan either the row or the column. In a directed graph, you have to distinguish between whether you want to enumerate the ‘in’ neighbors, which is all the vertices that have an edge into this vertex, arrowheads pointing inwards or the ‘out’ neighbors, which is all the vertices that this vertex is a neighbor 2. That is the arrowheads pointing outwards.\nOnce again, to enumerate either the ‘in’ neighbors or the ‘out’ neighbors would require a full scan of the row or the column corresponding to this vertex. The point is that it is going to take time proportional to the total number of vertices in the graph, even if this vertex has, relative to the total number of vertices, a very small number of neighbors.\nThe number of neighbors that any vertex has is called the degree of that vertex, and ideally, you would want to be able to enumerate the neighbors and time proportional to the degree of a vertex as opposed to a blanket order ‘n’ kind of a running time. This is a fairly substantial drawback when working with adjacency matrices. As we will see, this is also something that is going to make your graph traversal algorithms a little more expensive if you were to use adjacency matrices instead of adjacency lists, which is the next representation that I want to discuss.\nAn adjacency list is a representation that is motivated by the need to essentially have a more efficient way of being able to traverse the neighborhoods and also have a more space-efficient representation, which hopefully is a function of the actual amount of material in the graphs. We want a representation that is not always going to be order n2 but is actually going to reflect the density or the sparsity of the graph. More edges more space, naturally. But fewer edges, hopefully, less space.\n(Refer Slide Time: 14:57)\n\nHere is what the adjacency list representation looks like. Let us use the same example as before. What we are going to do is essentially store the information about this graph as a collection of lists. There are going to be as many lists as there are vertices in the graph. In this example, we have 6 of them. So, there are going to be 6 lists and each list is essentially going to be ‘information’ about all the neighbors of the corresponding vertices.\nNotice that because we are working with a weighted graph, this list will also have to carry information about the weights of the neighbors. Essentially for each vertex, the list is going to consist of the labels of the neighbors immediately followed by the weights. Of course, for an unweighted graph, you could either just skip the weights or set them all to 1 or some other default, which makes sense in the setting of your problem.\nThis is the adjacency list representation. Notice that the amount of space that you need is just twice the number of edges because every edge is going to feature in exactly two lists corresponding to its two endpoints. The amount of time that you need to enumerate all the neighbors of a vertex is now proportional to its degree because all you have to do is walk through the list corresponding to the vertex. You are going to take just the amount of time that you need, which is to say, you are going to take time proportional to the degree of the vertex to be able to enumerate its neighbors.\nIn this sense, the adjacency list has two advantages over the adjacency matrix representation. But of course, the one thing that it will not do so well is to tell you if there is an edge between a given pair of vertices i and j. This was the one thing that was really easy in the adjacency matrix representation.\nBut here, if you want to know if ‘j’ is a neighbor of ‘i’ or not, then you will have to essentially scan the whole list corresponding to either i or j and look for the other guy and try to figure out if there is an edge between them or not. Hopefully, these two representations make sense.\nThese are not the only representations. There are others. Another common one is the edge list representation, which you are welcome to look up. I am not going to present it here because, for the most part, everything that we are going to do will be very workable with either the adjacency matrix or the adjacency list representations. Now let us just take a quick look at the implementations of these representations starting with the adjacency matrix first.\n(Refer Slide Time: 17:36)\n\nHere, we are basically declaring a two-dimensional array with a substantial amount of space in reserves. You can initialize MAX_V to the maximum amount of space that you would need. You could derive this by just looking at the constraints of your problem and once you have reserved enough space, it is just a matter of populating this matrix.\nNow the code that is written here is designed to take this kind of input, where you literally have the rows of the adjacency matrix being spoon-fed to you. But a more typical representation is of a list of edges.\nYou would just essentially have to go through that list and make sure that the right entry is triggered to 1. It is also going to be equally simple. In fact, in some ways even simpler because all you have to do is run one for loop that traverses the list of edges. Let us say you have taken values U and V from the current line, you just have to make sure that AM of UV is set to 1. If there are weights involved, then typically the list representation will have the weights specified either as the first or the last numbers. Just make sure that you also append the weight. Instead of setting the matrix entry to 1, you actually set it to the value of the weight that has been given to you.\nThat is all that you need to do. So, the adjacency matrix representation has a fairly straightforward implementation and this code is actually from the GitHub repository for the competitive programming book. I will have a link to it in the description. You can go ahead and take a look. Run it and play around with it and make sure that it makes sense.\n(Refer Slide Time: 19:35)\n\nNow let us take a look at the adjacency list representation. The code here seems to be a little bit longer, but it is also equally straightforward to pass. In terms of the representation, as you might remember, an adjacency list representation involves creating ‘n’ different lists, each of which can store the list of neighbors. But remember, we might also have to account for weights.\nEach list is not just a list of vertices, but it is a list of vertices along with information about the weight of the edge that is being represented when you put this vertex in that list. Instead of just having a list of lists of integers, we are going to have a list of lists of pairs of integers. Hopefully, that makes sense. Every pair is going to represent a vertex, the weight of the edge between that vertex, and the vertex represented by the list that this pair is on.\nOnce again, let us go back to the graph that we had earlier and this is going to be represented by this kind of input. There are 6 lines corresponding to the 6 vertices. Every line starts off with a number that represents the degree of the vertex. That tells you how many vertices to anticipate and how many more entries are coming up.\nNow, because we have information about weights, if the degree for example is 2, you should expect 4 entries because you are going to get information about the 2 vertices, which are the neighbors, and also the weights corresponding to the edges that the current vertex has to these two other vertices.\nJust to be sure, let us walk through what is going on here. The very first line tells you how many vertices they are. That gives you a sense of how many times the outer for loop should be run. Once you get into the outer for loop essentially, each snapshot represents what is going on with one vertex.\nWhen you are reading the ‘i’th line, you are essentially populating the adjacency list for vertex number ’i.’ What does the ith line look like for any ‘i’ between 1 and n? Well, the first number is the degree of the vertex ‘i.’ That tells you how many times the inner for loop should run and every time you are inside the inner for loop, you need to take in two pieces of information.\nOne is the label of the neighbor, and the other is the weight that this neighbor brings with it. That is going to be the weight of the edge between ‘i’ and the neighbor that is just going to come in. You read in these two pieces of information, make a pair out of them, and append this pair to the list that is the ’i’th list. The list that is tracking all the information about the ’i’th vertex.\nThat is essentially the adjacency list representation. You might have to adjust this a little bit in case your edges do not have weights or if the edges are being given to you in a different input format. Once again, a pretty common format for graphs is just a list of edges and again, you will have to tweak this code a little bit, if that is the form in which you receive your input.\nWhen there are no weights, you can either use a sensible default value for the weights or you could simply switch to using a list of ‘list of integers’ as opposed to a list of ‘list of pairs of integers’ – so, whatever is convenient in a given situation. You can find a link to this code in the description.\nOnce again, this is from the GitHub repository for the Competitive Programming book. I would again encourage you to play around with this and see if you can adapt it to different settings like especially graphs without weights or graphs where the input is given as a list of edges as opposed to in the adjacency list format, as was the case here. With that said, let us now move on and talk about graph traversals a little bit.\nThis video is split into two parts. We will actually talk about the algorithms in the next video. But just before that, so you have something to think about, I want to give you some intuition about how these two traversals work. I like to think of the breadth-first and the depth-first traversals as capturing two distinct web browsing styles.\n(Refer Slide Time: 24:06)\n \n \nSuppose you are looking at the Wikipedia page for the COVID-19 pandemic. This is a long page with a bunch of different links and we all like to open browser tabs in the background when we are reading something. The two browsing styles that I was talking about are the following.\nOne could be that you just like going down the rabbit hole of distraction. As you are reading, the first time you encounter a link, you just click on it and you open it and you start looking that up.\nNow as you start reading, this is the first link that you encounter, you click on that, and then as you are reading this, you click on the first link that you encounter again and you just keep going. The only thing you are probably careful about is to not visit a link that you have already visited before because if you think about it, that is going to lead you to just going in circles and you want to avoid that.\nBut other than that, you just keep going. The moment you see a link, you cannot help yourself, you just click on it and the only time you stop is when you encounter a page that has no links whatsoever. That is a bit of a dead-end and at that point, you close that tab and go back to the tab that you came from and you look for the next link on that page and you keep doing this.\nThat is essentially the main intuition for a depth-first traversal. As I said, this is going deep into the rabbit hole of distraction in the context of web browsing. But in the context of a general graph, you want to stop somewhere and you want to explore this graph – that is kind of the idea.\nYou go to your neighbor and then you go to your neighbor’s neighbor and you just keep doing this, until you get stuck, until you come to a vertex, which does not have any new neighbors for you to explore. At that point, you back up and then pretty much repeat the same. That is depth-first traversal.\nWhat about breadth-first traversal? Well, it is the opposite philosophy, where essentially, you do not want to go deep in one particular direction. But instead, you want to explore everything at the first level, first. In this case, the way you browse the web would be that you go through this page and you just open background tabs for all the links that you see on this page.\nThere are going to be a bunch of other links as well, but I will spare you going through the whole example. But here, the idea is that once you have opened the tabs for all of the links on this page, then you are basically done with this page and this, of course, is an especially long page, so it is going to take you a while. But let us say that once you are done, then you move on to the next open tab on your list.\nNow chances are that this page has links to some of the pages that you already have open in your browser. Whenever that happens, you essentially ignore such links because these would not be fresh locations as far as you are concerned. You somehow keep track. Your browser tells you by typically coloring the links purple or something when you visited them before.\nBut in your code in your algorithm, you will have to explicitly keep track of what vertices you have visited already. But the idea is that, at the top level, you have explored all the neighbors, or at least in principle, you have visited all the neighbors of the top vertex by just opening up these pages and new tabs, for instance.\nNow you basically go down the ladder and to the first layer and you essentially repeat this process. Every time you are at a vertex, you go through all of their neighbors that are new to you. Once you are done with that, you move to the next open tab in your browser, which when you actually think of this as an algorithm, this is going to be the next vertex in a queue, which is the most natural data structure for implementing this sort of a breadth-first idea.\nTo begin with, you have an empty queue and then you queue up the very first vertex and that is going to be the vertex from which you are starting your exploration. Then you look at all the neighbors of this vertex and you essentially push all of these neighbors onto the queue and mark them as visited vertices. Then you just keep popping the first element in the queue and loading up all of its new neighbors at the back of the queue.\nYou basically keep doing this, until you have nothing left to explore. These are essentially the two traversals. In fact, if you are feeling adventurous, you might want to just see if you want to consider how you would implement both of these traversals. Once again, in depth-first search, you essentially say – Alright, I am at the current vertex, let me find an unvisited neighbor of this vertex and go there.\nThen this is an inherently recursive description. You bail out of the recursion when you have no new unvisited neighbors from the vertex that you are currently standing on. At this point you backtrack. With breadth-first search, the natural thing to do is to basically load up the new unvisited neighbors on a queue, and essentially, once that is done, you pop the head of the queue and do this again. You keep doing this until you have run out of vertices to explore.\nThese traversals are very natural and have a lot of interesting applications, and happen to be very efficient. We will talk more about both of these traversals in the second part of this module. I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/W05/Lec25.html",
    "href": "materials/cpnotes/W05/Lec25.html",
    "title": "M 1 (BFS and DFS)",
    "section": "",
    "text": "Lecture - 25\nGraph Foundations - Module 1 (BFS and DFS)\n(Refer Slide Time: 00:30)\n\nWelcome back, to the second segment of the first module in week 5. We are talking about graph traversals this week and in this segment, we will actually talk about the breadth-first and the depth-first traversals of a graph. In the previous module, we talked about how graphs are represented. We talked about the adjacency matrix and the adjacency list representations and we also had sort of a very intuitive and vague sort of overview of how these traversals might work.\nSo, if you have not seen the first segment, then it might be advisable to watch that first unless you are already familiar with how adjacency matrices and adjacency lists work, in which case you could just start off with this one directly. In fact, if you are already comfortable implementing BFS DFS yourself, then you could even skip this lecture and jump ahead and look at the problems directly.\nThere are three problems that we discuss in this module and if that leaves you hungry for more then please look at the extra section on the course website and you will find more problems to try out your BFS DFS skills on. Now with all that said, let us get started here. We will basically be focusing on what these traversals do and not so much on proving interesting properties that these traversals have. We will not be getting so much into some very common and well-known applications of these traversals.\nWe will give you a bucket list of these things without really explaining them in any detail and there are links in the description of this video where you can find out more if you are interested. In case you have not seen these topics from a previous course that you have done, you might actually be interested in following up and learning a little bit more because these things are pretty foundational and really interesting. I would encourage you to actually look things up a little bit beyond what we are able to fit into this video here. With that said, let us start first with a breadth-first search.\nRemember, for breadth-first search, we said this is like when you start off reading a page on Wikipedia, you open all the links that you see in background tabs. Then you close the page and then you start off with the first page that you have opened and then you do the same thing.\n(Refer Slide Time: 02:31)\n\nLet us take a look at what this might look like on an example. Here is an animation that shows you the sequence in which a BFS traversal would visit the vertices of this graph. Let us take a closer look at what happened. The story begins at the vertex labeled 1 and that is the first vertex that you mark as a visited vertex.\nYour known territory is just this first vertex. Then you look at all of the neighbors of 1 and you pick those that you have not visited yet. Since all of these vertices are new to you right now, all the three vertices 2, 3, and 4 get pushed on the queue. Now, after you have explored all the neighbors of 1, you basically move on from 1.\nThis is like saying you close the first page that you were reading and now you move on to the next thing on the queue. In this case, assuming you load up the vertices in lexicographic order, the next vertex in the queue is 2. Now when you visit 2, you again want to look at a neighbor of 2 that you have not seen before. So, 2 has two neighbors in this graph, 1 and 5.\nBut since 1 is a vertex that you have already seen, you ignore 1 and you basically explore the vertex labeled 5, by pushing it to the end of the queue. Now you have completely explored vertex 2, you move on to the next vertex in the queue, which is vertex 3, and speeding up the explanation a little bit 3, will end up pushing 6 and 7 on the queue. You will push off 3 and turn to 4 because that is the next vertex on the queue.\nNotice that at this point 4 will bring in 8, which is its only unvisited neighbor to the back of the queue and once it hops off the queue, the next thing on the head of the queue is 5, and so on and so forth. In the description of this video, you can find a link to a website called visualgo dot net and they have a really nice interface where you can draw your own graph and you can simulate what the BFS traversal would do, in what order it would visit the vertices and so forth.\nIf you really want to get a feel for how the algorithm executes in different kinds of graphs, then please feel free to try this out. It is also a good idea to just sit down with pen and paper and work through some examples of specific kinds of graphs. For example, what would BFS do if you had a complete graph? That would be a graph where every possible edge is present, every pair of vertices is connected with an edge. In this case, notice that no matter where you start, the BFS traversal would basically finish off in one layer.\nBecause every vertex is adjacent to every other vertex. Irrespective of your starting point, you just kind of visit everything in one shot. You could contrast this with what DFS would do if it was working with such a graph. I think it is really useful to play around with a few examples. At this point, I would like to switch gears a little bit and actually talk about the implementation for BFS.\n(Refer Slide Time: 05:41)\n\n\nTo begin with, we have a ‘distance’ vector that is going to help us keep track of how far away the vertices are from the source. When we have not seen anything, at this point, every vertex is at distance infinity, we just do not know anything about how close these vertices can be. Although I am not formally defining distance here, this is something that you can look up and there are links in the description of the video in case this is not a familiar notion.\nBut for now, you can just intuitively think of the distance between any two vertices in a graph as being the length of the shortest path between them. Where a path is exactly what you think it is – a sequence of vertices that you can follow to get from one vertex to another. You want that there is an edge connecting the consecutive vertices so that you can actually walk along the path.\nTo begin with, as I said, the distance is unknown to us, in the sense that we have not really started exploring this graph at all. We started the source vertex. So, we initialize the distance of ‘s’ from itself to be 0 because you do not have to walk around from s to reach s, that is exactly where you are at already. For the remaining vertices, as we start actually discovering these vertices, we will update the distance vector as we go along.\nThe other thing that we want to keep track of is some sort of a parent array and this essentially tells us who is the reason for our discovery. The parent of any vertex other than the source is going to be the vertex that pulled this vertex into the limelight. That is the one that caused the latter vertex to be discovered by the traversal.\nThis will become clearer as we go along. But just as an example, notice that all the neighbors of the source vertex from where you start the BFS have the source vertex as their parent because, in the very first step, the source vertex is going to immediately find all of its neighbors in one shot.\nAll the neighbors of the source vertex will point to the source as the parent. Everything that you see typically in the second layer of a BFS traversal, all of those vertices will have some vertex in the first layer of the BFS traversal as their parent and so on and so forth. We will update these parent pointers as we go along. Although we will not have any immediate use for them, it is just good to know that we can keep track of them. These may come in handy depending on the application that you might be working with.\nThe rest of it is fairly routine initialization. We want to keep track of the layer numbers in a variable called ‘layer.’ This is mostly so that we can do some pretty-printing of the BFS traversal. We also have a queue, which is going to be the main data structure that we use to actually execute the traversal.\nWe initialize a queue to being ‘empty,’ to begin with, and then we push the source vertex onto the queue. That is the only thing that the queue has in the beginning and now let us see how this goes. We are going to keep processing vertices, while the queue still has vertices on it. That is the outermost while loop and now what we want to do is basically pull out the vertex that is at the front of the queue.\nLet us call that vertex ‘u.’ We read off the front of the queue and we also push this vertex out of the queue and now what we want to do is basically go over all the neighbors of ‘u.’ This is an adjacency list representation. This is one way of going over the neighbors of ‘u.’ The variable ‘w’ essentially stores the weight of the edge from u to v and this is something that is not really relevant to the BFS traversal. We are just going to ignore that and we are going to worry about ‘v.’\nWhat do we want to know about v? This is something that we are interested in processing if we have not seen it before. Notice that this is very important. You only process unvisited neighbors of the vertex that is currently at the head of the queue. If you have seen a vertex before and you try to process it, then you will have a BFS implementation that is just going to potentially run forever. That is a very dangerous thing to do.\nThis check here is very, very crucial. We are going to check if we have visited v already and one way to do that is to check what is the distance of v from the source. If this distance is infinity, which of course is coded as some large finite number, as long as this number is much bigger than ‘n,’ or even strictly bigger than ‘n,’ this will be a valid implementation. If the distance of v is set to infinity, then we know that we have not seen this vertex yet and that is when we will process it.\nOtherwise, we do not do anything and we just continue with the ‘for’ loop. Once we exhaust that, we, sort of, get out and go back to the while loop. That is essentially the overall structure. But what if v is a vertex that we have not seen before? What does it mean to process the vertex v?\nWhat we want to do is, first of all, make sure that we set the distance of v appropriately so that we put it on record now that v is a visited vertex. What is the distance of v? Well, it is going to be the distance of the parent + 1. It took you a distance of ‘u’ many steps to come from the source to the vertex ‘u,’ and now it is going to be one extra hop to reach v by taking the edge from u to v.\nThat is the distance of v from the source, and setting it in this way also implicitly puts it on the record, as we were saying earlier, that v is now a visited vertex and we do not have to visit it again in case it should come up later. The next thing that we want to do is to set the parent pointer of v.\nWe ask ourselves: Who was the vertex that was responsible for v joining the queue? Well, v is going to join the queue because u discovered it. The vertex ‘u’ discovered it. We are going to set the parent of v to u and that is going to fix up the parent point information. To truly wrap up the processing of the vertex v, what we need to do is add v to the end of the queue. This way, when it is v’s turn, v can pull in all of its neighbors, at least the ones that have not been visited so far.\nThat is why it just hops on the bandwagon, so to speak. The rest of this code is mostly routine things to do with printing the order in which the vertices are being traversed. Let us take a quick look. If you just wanted to print out the vertices that are being visited by the BFS traversal, in the order in which they are processed, you could just fill in this blank space with one simple print statement, which just prints the value of ‘u.’\nBut you might also want to print the layer numbers whenever you change a layer. Let us say when you go from the first layer to the second or from the second to the third, and so on. Let us think about when does the layer number change. We have a variable called layer where we are sort of tracking the current layer numbers, so to speak. Whenever we encounter a vertex whose distance is different from the layer number that we have cracked so far, that is when we know that the layer number needs an upgrade.\nThat is when it is worth printing the layer number. Let us say that we see that the distance of the vertex that is being processed currently is different from the layer number. Then let us just go ahead and print the value of the distance of ‘u’ that is going to basically signal the current layer number. We also want to make sure that ‘layer’ is set to the distance of the vertex so that the variable also carries the correct information about which layer we are in. For the most part, as long as you are within the same layer, as long as you are processing vertices that are at the same distance from the source, this piece of code here ‘layer equals a distance of ’u’’ will not really change anything.\nBut every time you do actually switch layers, the ‘if’ condition just before this line will catch that and it will basically print the layer number of the new layer to the output. That is how this works. Essentially, if you were to run this code, you are going to just see a nice output with the layer numbers and after each layer number, you are going to see a list of vertices that were visited at that layer.\nOnce again, do try out visualgo, if you just want to see how this code plays out on some pre-written examples or your own examples. That is an exercise that is definitely worth doing and you could also just run this code for yourself on examples that you come up with. Make sure to combine this with the actual implementation of the graph as an adjacency list and that you read your input and output appropriately. You could also refer to the GitHub repository for the competitive programming book from where this snippet of code has been borrowed. There is a link to that in the description of this video as well.\nSo, that wraps up our discussion on BFS and now let us turn to depth-first search, which is a different style. Going back to our Wikipedia browsing analogy, we said that this is where the moment you see a link that is fresh that you have not visited before. While you are browsing Wikipedia, you click on it and that is the link that you start reading. There as well, if you see a link that you have not visited before, you are going to click on it and so on and so forth.\nThe only time that you have some respite is when you finally land on a page where you have no more links. There is nothing else to follow and then you start backtracking and working your way back up.\n(Refer Slide Time: 16:25)\n\nLet us, again, take a look at an example of a DFS traversal playing out. I will not go through this step by step but I will just let you watch the animation and hopefully, it tallies with your intuition of how you expect the DFS traversal to behave. After this, we will go ahead and take a look at the implementation.\nWe started at the route, the topmost vertex and as you can see, you just keep going all the way down. You go from 1, 2, 3, 4 and then you walk your way back up to 1. Then you take the second neighbor of 1, which is 5 and you go down the path 1, 5, 6, 7. Then you backtrack all the way up to 5 now and 5 has one other unvisited neighbor. You visit 8, and then you walk your way back up all the way to 1. Then you explore 9 followed by 10. Hopefully, this is reasonably intuitive as to what DFS is doing. Let us just take a look at how you would write this in code.\n(Refer Slide Time: 17:25)\n\nNow DFS lends itself very naturally to a recursive implementation, which is why we are isolating its implementation to a function called DFS. The implementation that we saw for BFS could be isolated into a function call as well. But you could also just put it in the main body and it would not make any difference.\nOf course, DFS also can be implemented in a more iterative style and you could directly use, for instance, a stack-based data structure to simulate what is going on in this recursive version of the program, which I think is just closer to the semantics of how we described it. That is why we are going to do the recursive version because it is just easy to tally this with the way that we have described how DFS works.\nBut with just a little more work, you could also come up with a non-recursive implementation. I am going to leave you with a few pointers to do search variants, which you could go and lookup. But for all practical purposes, I think you could work with either one of them and it should not really matter.\nWhat is going on here? Let us say you invoke DFS, starting at a vertex ‘u.’ Notice that what we need in terms of the global variables is, of course, access to an adjacency list representation of the graph. This could also be an adjacency matrix representation, but I am just going with an adjacency list as the default because that is going to be the more efficient choice here in general.\nApart from this, just like with BFS, where we had a distance array, which helped us distinguish between vertices that have been and have not been visited, here also we are going to maintain an array which in this case, is called dfs_num that is going to keep track of whether a vertex was visited or not.\nIn this code, you can see the words ‘visited’ and ‘unvisited.’ These are constants that have been declared separately that you do not see on your screen. Once again, there is a link to the repository from where you can see the whole code. This is just a snippet and it may not run if you were to just try to work with it as is.\nBut in any case, hopefully, the spirit of it is clear. The dfs_num array is going to tell us if a vertex is being visited or not and how does DFS work? Well, just going to ignore the print statement which just tells us, where we are in the DFS traversal. But when we do the DFS on ‘u,’ what we essentially want to do is go through the neighbors of u, till we find the first unvisited neighbor and then just perform a DFS starting and at that vertex.\nAt some point, you are going to reach a vertex, which does not have any unvisited neighbors. All of its neighbors have been visited before. At this point, basically, the if condition within the for loop will never really execute. The for loop exhausts itself and you just return control to wherever the function call was coming from. That is essentially your dead end and that is when you will start your backtracking journey.\nThis is, of course, a very bare-bones implementation of DFS. You could enhance this to track more information about the vertices such as, for instance, you could keep track of the times at which you visited the vertex and at the time at which you decided to go back when you have exhausted all of its neighbors. You could track all of this auxiliary information, and depending on the application that you are working with, this extra information can turn out to be really valuable and relevant.\nOne thing that I did not mention is that the first thing that you should do when you do DFS of ‘u’ is to make sure that you mark this vertex as visited. This is, again, pretty critical. If you forget to do this, then you might accidentally again end up in an endless loop because you have not kept track properly of which vertices you have visited and which you have not. The moment you know that you are going to do a DFS starting at a particular vertex just make sure that you update its visited status so that you do not try to visit it again. You do not try to do a DFS starting from there, a second time when you potentially come in from a different vertex.\nHopefully, this implementation makes sense. I think it covers all of the aspects that we discussed when we were talking about the algorithmic idea of doing a DFS traversal informally. Hopefully, it tallies with your intuition. Once again, you can go to visualgo to actually experiment with how DFS plays out on actual examples. You could either create your own examples or look at some of the ones that are already built into the interface.\nHave some fun with that and you could also play around with how a BFS and DFS work on directed versus undirected graphs. Typically, these traversals do not really account for weights on edges or vertices in any way. That kind of information is completely ignored. The behavior of these traversals would be the same whether your graph had weights on the edges of the vertices or it did not.\nBut the orientations can definitely lead to different outcomes in the sense that if you have a directed graph and you run say, a DFS, that run would look different from the run on the underlying undirected graph. Let us say you took an eraser and you erased all the arrowheads. You are now left with an underlying undirected graph, so to speak and if you run a DFS on that, that is going to look very different from what happened on the directed version, typically. It is a good idea to play around with examples just to get a sense of some of these things. Now that we have seen the implementations, let me just talk very briefly about the complexity.\n(Refer Slide Time: 23:17)\n\nIt turns out that if you were to use the adjacency matrix representation then the worst-case running time can be as bad as order n2. But if you use an adjacency list representation, then your worst-case complexity is order n + m, where I am using n and m to refer to the number of vertices and edges respectively.\nNow, you might say that there could be graphs where m is as bad as n2. For example, that would surely be the case if you were working with a complete graph and so on. Of course, this is true. If you were going to view this purely from the perspective of worst-case complexity, then these running times are not all that different.\nBut the running time order V + E would generally be superior because it accounts for the structure of the graph and would generally give you a much better performance on graphs that happened to be sparse, that do not have as many edges, and so on. This is an important difference to keep in mind.\nI will say that coming up with this performance guarantee to see that the running time is in fact order n + m does require a little bit of work because if you were to just look at the code for BFS DFS and if you analyze it naively, then it will not be very clear as to why the running time can be bounded as being order n + m.\nSo, it does require just a little bit of thought. But the very fact that the complexities are different for the matrix and list representations should give you a hint as to how to analyze the complexity so that you get to this conclusion. But in case it is not clear once again, there are a number of pointers for resources where you can find out more about how we typically analyze the complexity of these traversals and why we get to essentially what I am claiming here.\nWith this out of the way, the major takeaways are that you could use either BFS or DFS. In most scenarios, both of these traversals would be equally applicable. In some scenarios, one would be more natural than the other.\nIn general, it is a good idea to be comfortable implementing either of them and in most cases, you would be better off sticking to an adjacency list representation, as opposed to an adjacency matrix representation. Especially more so in CP, where if the number of vertices you are dealing with is more than a few 1000 vertices, as we mentioned earlier, this is anyway prohibitively expensive, even from a space and memory perspective.\nJust keep these things in mind and, you know, play around with the BFS and DFS implementations that we have discussed in this video. I will just spend a couple of minutes more telling you about some common applications of BFS DFS without actually getting into any of the details. But just in case you are curious about what these traversals are good for and how can you use them other than just exploring the graph. It turns out that there are a lot of interesting things that you could do with BFS DFS.\n(Refer Slide Time: 26:26)\n\nHere are just some of the things that you could do with these traversals. This is by no means an exhaustive list. It is a small subset of the very many applications that are known for BFS DFS. Some of these terms may be unfamiliar. Things like, for instance, bipartiteness or topological sort or what does it mean to talk about distance or connected components – in case some of this is unfamiliar, you could look them up.\nIn the upcoming modules, we will talk a little bit about what it means for a graph to be connected. We will define the notion of distance and in the assignment, you will have an encounter with the notion of ‘topological’ sort. In fact, in the very next module, we are also going to look at what it means for a graph to be bipartite and what it means for a graph to have a cycle and therefore, you would also know what it means for a graph to be acyclic.\nSome of these terms will become clearer as we go along in case they were not already familiar, and once again, we will not really be getting into a lot of proof. If you are really curious about why these algorithms work in these contexts, it would be a good idea for you to look up some of the reference material that you can find on the course website, as well as in the description of this video.\n(Refer Slide Time: 27:44)\n\nSpeaking of statements without proof, I will just make a few comments here again without actually formally arguing them. These are just some properties of these traversals that are useful to keep in mind. The first one is to observe that in a BFS, you cannot have edges that jump levels.\nOf course, you can have edges between consecutive levels, but any more of a gap and you cannot really have edges, for example, going from level 5 to level 9. The reason for this is fairly intuitive. If you did have such an edge, then the other end-points sitting at level 9 should have really been pulled up in level 6 already. It is not very difficult to translate this intuition into an argument for why you will not have edges between vertices that are more than one layer apart.\nIn a BFS, just remember that all edges either go across consecutive levels or they are cross edges, meaning they are edges within the same level, but you are not going to have edges of any other kind. Now, let me also just quickly point out that some people will use terminology like tree edges and non-tree edges to distinguish between the edges that were actually accessed by the traversal.\nThe edges that were involved, for example, when you were pulling in a new vertex into the queue. Let us say your current vertex, the head of the queue, is the vertex u. You are looking at an unvisited neighbor v and you are pushing it to the tail of the queue. That edge between u and v, that is going to be a BFS tree edge because the traversal actually went across that edge.\nBut there would be many other edges in the graph that do not feature in the traversal tree. Those would be the non-tree edges and some people would call them the graph edges. In the context of a BFS traversal, you would basically know that those are the edges that did not show up on the tree. That is the same for DFS as well.\nNow in a DFS traversal, on an undirected graph, you would not have cross edges. By cross edges, I mean edges between pairs of vertices that do not have a direct ancestor-descendant relationship between them. You could have back edges. In a DFS traversal, you could definitely have edges that cut across multiple levels if you like. All the levels are a bit less clear in the context of DFS, but these edges can definitely be present.\nBut in undirected graphs, you will not have edges that basically cut across two different branches of the tree in some sense. This is all very informal and you will have to convince yourself about why this is the case. But once again, there are ways of proving these things formally. There are even ways of articulating these things more precisely than I am doing here. But this is just to give you a general picture of the kind of properties that you might expect from these traversals.\nAs I said, in BFS, you could use this traversal for actually recording distances, which are essentially the length of the shortest paths from the source to the current vertex. The layer number of a vertex essentially tells you what its distance is from the place where you started the traversal.\nAgain, requires an argument! But this can be shown without too much difficulty and that is a very interesting property of BFS. It is completely useless if you want to track shortest paths accounting for edge weights. That is going to be the subject of our discussions next week. But for now, you could still use BFS if your edges do not have weights and you are still somehow interested in distances.\nFinally, if you look at the last layer of a DFS traversal, you should notice that there are no edges between the leaves. The reason is that if you did have an edge, then well you could have gone deeper in one of those leaves and it would not be a leaf really. Once again, you could say this more properly. But I think this is an interesting property that might just come in handy in some situations.\nI just wanted to leave you with some of these nice properties that these traversals have. Of course, there are many more. Think of this as some sort of a sampler and once again, please do look up the links for more information. If you are already fairly comfortable with BFS and DFS, please do look at the extras page for other problems that you can try while you are at it. So, thanks very much. In the next three videos, we are going to solve three different problems that take advantage of these traversals. I will see you there, and let us wrap this up here. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W02/Lec06.html",
    "href": "materials/cpnotes/W02/Lec06.html",
    "title": "M 2 (The Meeting Place Cannot be",
    "section": "",
    "text": "Lecture - 06\nSearching and Sorting - Module 2 (The Meeting Place Cannot be Changed)\n(Refer Slide Time: 00:11)\n\nWelcome back to the second module of the second week of Getting Started with Competitive Programming. We continue our journey through problems that require some application of either sorting or searching. In this video, it is going to be searching. We will be talking about the Codeforces problem from round number 403. The problem name is, The Meeting Place Cannot Be Changed.\nIt turns out this is also the title of a 1979 soviet five-part television miniseries. That is information that you probably did not need to know. But that is what shows up when you do a Google search for this phrase. So, if you want to get to the Codeforces problem statement make sure to add Codeforces to your search query or just use the link in the description of this lecture video. This problem has a pretty short story. But I will say that the binary search aspect of the solution was not very obvious to me from the outset.\nThere are some problems wherefrom the statement you can quite easily guess that there must be some kind of a binary search involved here. But I will say that in this one, at least to me, it felt a bit hidden. It seemed like the statement was suggesting more of a greedy sort of an approach or something like that. But, of course, once you start thinking about it and you look at the problem limits, it becomes clearer and clearer that you have to do some sort of a binary search. So, let us get started by looking at the problem statement as usual.\n(Refer Slide Time: 01:36)\n\n\nIt all starts with this road in Bytecity, which can be thought of as a straight line that goes from west to east. I should point out that this is not verbatim from the problem statement, where it is a north-south road instead. But I wanted to give myself some horizontal space on these slides. I did not also want to disorient you by calling this horizontal line a north-south road. But this detail is really not relevant to the main mechanics of the problem. So, I just wanted to flag that it is different but it does not matter. This road is demarked by integer coordinates.\nWhat we are told is that there are ‘n’ friends who are standing on this road. In fact, we are given their exact locations as input, as we will see later. We are also told that these people can move around on the road in either direction, and each individual has a maximum speed that they can travel with. So, you have ‘n’ people standing at these ‘n’ locations, which may or may not be distinct. Each one of these people has a speed with which they can travel. They can travel either towards the east or towards the west. So, what do we want to do?\nRemember the name of the problem is ‘The Meeting Place Cannot Be Changed.’ You might guess that the problem itself has something to do with getting these people to meet? Indeed, it turns out that the question we want to address is: What is the minimum time that we need for getting all of these people to meet? By asking them to move of course, if necessary. We can direct the first person, for example, to go eastward, the second person to go westward. Whatever we want them to do, we can just ask them to do it.\nWe want to know, what is the most optimal set of directions that we can give these people so that they come to a common point after a certain amount of time has elapsed. We want this to happen as quickly as possible. So, that is the question. Also, one thing to note is that the place where they meet is not constrained to be an integer coordinate. So they can meet anywhere on this line, as long as they get to meet. That is what is important.\n(Refer Slide Time: 03:54)\n\nLet us, maybe, work through an example. As usual, we will pick up one of these sample inputs and go over it. These distances or these coordinates are measured from the east-most building. We just think of this building as the origin. We have coordinates being given as distances from this origin. What we have is three people who are standing at locations 7, 1, and 3, and their respective speeds are 1, 2, and 1.\nYou can see that the speeds are color-coded according to the people who have those maximum possible speeds. At this point, maybe you want to work through this yourself. What is the smallest amount of time that you will need to get these people to meet up at a common point? Please take a pause here and try to figure this out without, hopefully, looking at the problem statement. This is a nice example to work through. It will give you some intuition for what is going on.\n(Refer Slide Time: 05:11)\n\n\n\nHopefully, you had a chance to think through that. So, let us ask ourselves if, for example, one second is enough. So here is the scope of how much people can travel within one second based on their speeds. You can see that the green and the blue intervals are disjoint. Even if the green guy comes as much to the right as possible and the left chap moves as much to the left as possible (both of them are stretching as much as they can), it will still not be possible for them to meet.\nSo, we know that one second is not enough. Maybe we want to ramp this up and try to work with two seconds. Would that work? Again, if you have not completely worked through the example already, this is another chance to pause and try to figure this out.\n(Refer Slide Time: 06:00)\n\nWith 2 seconds at your disposal, notice that people can move around more and you indeed have a valid meeting point at the fifth coordinate. In particular, you could ask the green point to move 2 steps to the right and the blue point to move 2 steps to the left. The pink point also moves four steps to the left, which it can in 2 seconds because this point has a maximum velocity of 2. This also tells you that anything less than two seconds will not suffice.\nEven if you have 0.9999 seconds at your disposal, the green and the blue points will still fall slightly short of the meeting. This is also a good opportunity for me to point out that the answer in terms of the number of seconds also need not be an integer. We are really looking at 10-6 level of precision here.\nThis will become clear when we start getting to the implementation later. But for now, just keep that at the back of your mind: The number of seconds that you report need not be an integer. So, with this example fully worked out and behind us, let us now address the more general question of whether it is possible to meet within ‘k’ seconds.\n(Refer slide Time: 07:09)\n\n\nIf I tell you that you have a budget of ‘k’ seconds and you have all this information about the starting points of all the ‘n’ friends and their respective maximum velocities, can you figure out if it is possible to get them to meet within ‘k’ seconds? Based on the way we tackled the example, you might already have some thoughts about this.\nBecause we know the initial locations, the maximum velocities, and how much people can move within ‘k’ seconds. We could draw these intervals around each of these points realizing that anything outside of this is not attainable within ‘k’ seconds. Based on this, can you come up with criteria for whether people can meet within ‘k’ seconds or not?\nTake a moment here to think through this because this is one of the key pieces of the puzzle. There is one more coming up that has to do with the theme of this lecture which is binary searching. But we will get to that in just a few minutes. For now, just think about how will you figure out if ‘k’ seconds are enough for people to meet? I guess it is reasonably clear, at least, visually that it is possible for everybody to meet within ‘k’ seconds, if and only if there is a point that belongs to all of these intervals that we have drawn here.\nIn particular for this example, notice that it is not possible for everybody to meet because, for instance, the pink point and the orange point are always going to be divorced from each other. They are never going to come to a commonplace, at least within this time, assuming that these intervals are an accurate representation of how much they can move based on their velocities.\n(Refer Slide Time: 08:58)\n\n\n\n\nOn the other hand, let us look at an example where things do work out. Notice that there is at least one point, in fact, there is an entire range, which could be used as a meeting place because the points on that range are accessible to all people involved here. That brings up the natural question of how can we figure out if a collection of intervals has a common point or not?\nThis is again, a cute question. If you have a collection of intervals given by the left and right endpoints, what would be an algorithm to figure out if there is a point on the line, which is contained in all of these intervals? Again, just take a moment here to think through this and see if you can work it out. Come back once you are ready. Hopefully, you had a chance to think about this. Let us go back to the example from before.\nHere, let me highlight all the left endpoints of all the intervals. One of these is special, the one that is special is encircled in red. Among all the left-end points, it is the rightmost one. Let us also highlight all the right endpoints. The one that I am interested in is the left most of them. The two encircled points are the left most of the right endpoints and the right most of the left endpoints.\nThe criteria for all the intervals to overlap is simply the following. What we want is for the right most of the left endpoints to come before the left most of the right endpoints. If this happens, then you know that essentially everybody meets within this range that is defined by these two points. But if these two points are separated then things do not quite work out. Let us also see an example of when things do work out.\nFor instance, you can see that the rightmost of the left endpoints come first and the leftmost of the right endpoints comes afterward. This works out nicely. You can see that there is a substantial range of potential meeting points in this example. Now, this is a statement that you can actually prove formally.\n(Refer Slide Time: 11:19)\n\nLet me write out the criteria here. So, if the maximum of the Li is at most the minimum of the Ri, then you do have a meeting point. In fact, every point in this range, max Li, min Ri will actually give you a valid meeting point. The reason for this is: Well, suppose that there was one interval that was outside of this range. It did not intersect this range. Then depending on whether the interval was to the right of this range or entirely to the left of this range, you can argue that either its right or left endpoint will contradict our definition of the choices of min and max.\nThis is a really simple two-line proof. I would encourage you to write it out if you are not completely convinced. The other side of the argument is that if this does not work out. In particular, if the max of Li is greater than the min of Ri. Then if you just look at those two intervals, the ones that witness this max and min, you will see that those two intervals themselves are disjoint. There is no hope for these two intervals to intersect.\nTherefore, it is certainly true that all of the intervals do not have a common point on which they overlap. So, these are the criteria that help us determine if ‘k’ seconds are enough or not for everybody to meet. But notice that our actual task is to find the smallest ‘k’ for which a meeting is feasible. How do we go about that? This is where the binary search comes in.\n(Refer slide Time: 13:02)\n\nOnce again, let us go back to this question here. We know how to address this question, given k, and all the xi‘s and the Vi’s. We know how to figure out whether ’k’ is enough or not. Hopefully, it is clear by now that the xi’s are the locations and the Vi’s are the max velocities. So, we know how to figure this out. But notice the following two things.\nFirst of all, if the answer to this question turns out to be ‘no.’ So ‘k’ seconds are not enough, then certainly anything less than ‘k’ is also not enough because already with ‘k’ you are not able to meet. If you have even less than ‘k’ seconds at your hands, then you are even more constrained. Of course, it is not going to work out because if it worked out with less than ‘k,’ then it is going to work out with ‘k’ as well. Hopefully, it is clear that if the answer to this question is ‘no’ for some ‘k,’ then it is also no for every value that is less than ‘k.’\nSimilarly, if the answer to this question is ‘yes,’ then the answer is yes for all values that are bigger than ‘k.’ So, that means that if, let us say, five seconds was enough then, six seconds are also enough and seven seconds are enough and so on. Once you have a ‘k’ that is feasible, the interesting question is, can we do it with a smaller ‘k?’\nThat is what we want to figure out. And if you have a ‘k’ that is infeasible, then the question you ask yourself is, ‘k’ was not enough so we probably need to give ourselves a little more budget, a little more wiggle room. That motivates a very natural binary search over the range of all possible ‘k.’\n(Refer Slide Time: 14:43)\n\n  \nBased on the limits of the problem statement, let us work with the range 0 to some large number. I think something like 109 or so should suffice. With this range we are binary searching. We start in the middle, and we ask ourselves is 50 how many ever seconds enough? Suppose the answer turns out to be ‘yes,’ that this is enough. Then what should we do? We want to throw away half of this range, which half should we throw away?\nJust think about that for a second. Pause the video and take a moment here to think through this because this is the crux of the binary search part of the algorithm. Hopefully, you had a chance to commit to an answer. So, if these many seconds are enough, then we need to challenge ourselves to see if we can do it with even fewer seconds.\n(Refer slide Time: 16:03)\n \nWe do not need to worry about the right half of the range. It is only the left half that is relevant. We bring the right endpoint of our search space down to the midpoint. On the other hand, if the answer is that it was not feasible, then perhaps you can anticipate that the interesting range is the right half because if it is not feasible, we know that anything smaller is also not going to be feasible. So, there is no point in checking for those numbers.\nSo, we search in the right half. In other words, the way we truncate our search space is by bringing the left endpoint to the middle. That is kind of how you would do it in the program. That completes the overall description of the algorithm. You binary search over all possible values that the number of seconds could take, which is the answer. Every time you pose a question ‘is so many seconds enough?’, you use the interval intersecting business that we discussed a few minutes ago to figure out whether the answer to the question is ‘yes’ or ‘no.’\nEvery time you have an answer, you know which way to proceed. Hopefully, by now you have enough information to try and implement this algorithm yourself. Please go ahead and give it a shot. Do keep in mind that the numbers can be big. And the answer is required to be within a 1 over 106 error bound. It is possible that the judge has a particular answer and you have a slightly different one because you are dealing with floating points. Some calculations may not be exact. But you want the absolute difference between the answer of the judge and your answer to be within 10 to the minus 6. So, just make sure that you are using enough precision as you go along. In particular, we are binary searching. So, one way to think of the binary search criteria is when have you narrowed in enough to say that you know the answer?\nRemember, back when we were talking about the problem definition. We said that the output, which is the number of seconds, need not be an integer. You certainly cannot just stop when you have a pair of consecutive integers, one of which reports ‘yes’ and the other reports ‘no.’ Then you just report the one that said ‘yes.’ That is not enough. You have to dig deeper into the gap between these two consecutive integers. For instance, suppose you say that one second is not enough, but two seconds is enough, you still have to probe the possibility that maybe 1.5 seconds are enough.\nIf the answer to that is ‘yes,’ then you have to continue your search between 1 and 1.5. When do you decide to give up because these are not integers? What are the stopping criteria going to be? You have to decide when you have two numbers that are close enough for you to take a call.\nYou keep the search going for as long as the two numbers that you are working with are sufficiently far apart. Since you are looking at a 10-6 kind of precision, you can say that if the numbers are closer than that then this is a good enough approximation of the final answer. That is how we will be implementing it.\nI think that is the spirit in which most of the implementations would be for this problem. Please go ahead, give it a shot and come back to exchange notes. As usual, I will spend a few minutes going through my implementation for this. For this problem, the implementation that I will show you is in Python. By now, we also have an announcement, which is on the mailing list as well as in Discord, where we have shared with you a link to a Google Form, requesting translations of the sample answers in other languages.\nFor instance, for this problem, the GitHub repository will already have the Python code. But it will be great if you have C++, C, or Java versions of the same code, as long as you follow a similar format and document your code well.\nIf your code passes all the test cases, then please do share it with us so that we can add it to the repository with full credit. Make sure you add your name and anything else that you want to add about yourself in the comments. We will be very happy to share this with the rest of the class. Thank you in advance for your contribution to making this course better.\n(Refer Slide Time: 20:32)\n\n\nLet us move on to the implementation here. The first few lines here are, again, accepting the input. The input is always just three lines. The first line is the number of people. The next line is a space-separated list of integers, which talks about the locations. The last line is a space-separated list of integers, which talks about the velocities. You read them in and I have used very short variable names here. But they are still descriptive. So, x for the x[i]s, and v for the v[i]s.\nLet us move along. Here are the criteria for determining if ‘k’ seconds are enough. We have three very short functions. The first one identifies the right-most left endpoint. Remember, the left-hand points are given by the offset from the original location towards the left for how much you can travel in ‘t’ seconds. You say x[i]-v[i]*t. I think that is reasonably natural and easy to understand. On the other hand, we have how much can you move to the right.\nThat is x[i]+v[i]*t. That is an array that collects the right endpoints. The second function is simply returning the leftmost of the right endpoints. Remember, this was the max of Li, min of Ri expression that we had seen a couple of minutes ago. The ‘is feasible’ function takes a number ‘k,’ which represents the number of seconds that you have on your budget. It tries to figure it out by comparing the left-most right endpoint and the right-most left endpoint, whether this is workable or not.\nNotice that the two functions above take ‘t’ as a parameter, which is the number of seconds that you have and that is what we are passing to them when we are writing the ‘is feasible’ function. This, hopefully, is quite closely representative of what we had discussed a few minutes ago.\n(Refer Slide Time: 22:47)\n\nThe only thing left to do now is the actual binary search. We initialize our range. Remember, you could need as little as 0 seconds in case everyone is already in the same position, to begin with. I think if you study the limits, you will see that you will never need more than 109. So, that is what we have here for left and right. As we discussed, we are going to keep searching for as long as the search range has not become tiny. As long as R-L is bigger than a really small number, we are going to continue our search.\nI think we always maintain the invariant that R is at least L. The absolute value here is not really necessary. But it is there anyway, so, it does not hurt, but I think it is not required. That is the criteria for whether you want to keep searching or not. As long as R and L are sufficiently separated, you keep going. What do you do when you are binary searching?\nOf course, the first step is to find the midpoint of your current search range (the value of mid). Based on whether the current mid is feasible or not, you decide to truncate your search interval one way or the other. Remember, we said that if the answer is ‘yes’ (feasible), then we ignore everything, every number that is larger. We want to challenge ourselves to find a smaller number. So, we bring R down to mid.\nOn the other hand, if it is ‘no’ (not feasible), we know that what we have is not enough, so we need to go higher. So, we ignore everything that is smaller. The way to do that is to bring the left-hand point all the way up to the midpoint. That is how we reset the values of L and R. You just keep going until you have a search range that is sufficiently tiny. At that point, you can exit the loop and print the answer. This is, I think, fairly clean and in some sense, also a little bit clever.\nAt least this solution was not completely obvious to me. I think the part about the intervals is pretty natural to do but from there, you start thinking about whether you want to do something that is greedy or something else. But the final solution that does happen to work, I think is really cute. I hope you enjoyed this as much as I did. So, we call it a wrap here and we will see another problem in the next video as usual. So, I will see you there. In the meantime, thanks for watching!"
  },
  {
    "objectID": "materials/cpnotes/W02/Lec07.html",
    "href": "materials/cpnotes/W02/Lec07.html",
    "title": "M 3 (Magic Ship)",
    "section": "",
    "text": "Lecture - 07\nSearching and Sorting - Module 3 (Magic Ship)\n(Refer Slide Time: 00:11)\n\nWelcome back to the third module of the second week on searching and sorting algorithms. This time, we are going to be looking at a really cute problem called Magic Ship. This is from the educational Codeforces round number 60, I believe. It is one of those problems where I think at some point, it does become clear that you have to do some kind of a binary search, just looking at the limits in the input.\nBut it turns out that it is not completely obvious what the upper limit for the binary search range should be, at the outset. Of course, you can make an educated guess. But just thinking through proper argument is a really fun experience as well. So, we are going to see that and a lot more. As usual, let us get started by taking a look at the problem statement.\n(Refer Slide Time: 01:02)\n \n \nThe problem statement begins by proposing that you are the captain of a ship. This picture here is quite appropriate because our task is to figure out if we can steer the ship to a particular destination in the presence of very windy weather. Let us take a closer look at what we are supposed to do. The very poetic concept of an ocean is modeled by simple cartesian coordinates in this problem. To begin with, your ship is at the location x1, y1, and your destination is at the location x2, y2.\nIn one step, you can move one unit to the left or to the right or up or down. You cannot make a diagonal move in a single step. That is how your ship is constrained to move. These are the instructions that you can give your ship if you had to go from where you are currently to where you want to go. It is quite straightforward.\nNotice that it is the best you can hope for in terms of the number of steps that you need to expend. But if this was the entire story, this would probably be an implementation problem that we will have discussed last week. So, the twist is that, as I mentioned earlier, you are navigating the ocean in windy weather and the winds are pushing the ship around in different ways. You have to try and figure out whether you can get to the destination in the presence of these winds. How are the winds modeled? How are we given information about what the winds are doing?\n(Refer Slide Time: 02:50)\n\nThis is through a weather forecast. And the weather forecast is essentially coded in this language. It is a string, which has ‘n’ letters and each of these letters is one of these alphabets here. It is either ‘U, D, L, or R,’ signifying whether the wind is going to blow the ship in the east direction, or west or north or south. The winds also, in one day, will push the ship one unit in one of these directions. That is the behavior of the wind. Let us try to understand this through an example.\n(Refer Slide Time: 03:35)\n\nWe have here the initial state of the ship. We also have the weather forecast for the next 7 days. I was talking about one step so far. But in the language of the problem statement, these steps are codified as days. So, I will talk about days and steps interchangeably. With this one-week weather forecast, let us see what the ship will do if it has no other forces acting on it. Right now the captain is sleeping peacefully and is not steering the ship in any way. So, the winds alone will have the following effect on the ship.\n(Refer Slide Time: 04:02)\n \nOn the first day, the ship will move north one unit. On the second day, it will simply come back down to its original position. On the third day, it will move one unit to the right. On the fourth day, it will again move one unit further to the right. On the fifth day, it will go up. On the sixth day, it will come back down. Finally, on the seventh day, it will move one unit to the left. You can see that the net effect of all of these movements is that the ship moved one unit to the right of where it was originally.\n(Refer Slide Time: 04:11)\n \n \n\nLet us see how these instructions from the weather interleave with actual steering attempts from the captain. While the winds are doing their thing, let us say that the captain has now woken up and decided to steer the ship in some meaningful way. On the first day, the winds are blowing towards the north. Let us say the captain tries to leverage this and also pushes the ship in the northern direction. This will have a compounding effect. These moves are going to add up, and the ship overall will end up moving two steps to the north.\n(Refer Slide Time: 04:45)\n \n \nOn the second day when the wind is trying to push the ship back down, the captain tries to apply an opposing force where the instruction from the captain is to go up. This up and down will have sort of a canceling effect. The final outcome is that the ship will stay put at its location at the start of the day. It does not have any net movement.\nOn the third day, both the captain and the winds are pushing the ship rightwards. So, the overall effect is that the ship moves two units to the right. On the fourth day, the wind is pushing the ship one unit to the right, and the captain observes that this is exactly what he wants. So, there is no instruction from the captain on this day. He chooses to stay put, and the ship just stays in place. Notice that by now the ship has actually arrived at its destination.\nWhat you do from here will turn out to be not so relevant to the mechanics of our problem. One option is to just go back to sleep and be at the mercy of the winds again. This will just mean that the ship will drift around based on the instructions from the weather forecast.\nOn the other hand, if you really wanted to stay put at the destination for longer, then you could simply issue instructions that negate the impact of the wind, and you can stay at the destination for as long as you want. Both possibilities are definitely feasible. But as I said, they will not be as important as getting to the destination in the first place, which will be the main focus of our problem.\nThe next thing I want to talk about is the weather forecast. Here, for instance, we have the forecast for the next 7 days. But if you wanted to know what happens in the next month or the next year, then how do you get that information? This may be important because perhaps it is not possible to get to the destination within 7 days. So, you might need to have an understanding of how the weather will behave beyond these seven days.\n(Refer Slide Time: 07:27)\n \nWhat we are given in the problem statement is that the weather forecast is periodic, which means the same behavior will keep playing out again and again. In some sense, you have a weather forecast, which is indefinite. You know exactly what is going to happen any number of days from now, just by maintaining this information cleverly in your code. We will come to that later in a little more detail. But for now, know that in principle, you have all the information that you could possibly want about how the winds are going to behave over the coming days.\n(Refer Slide Time: 08:07)\n\nOur task is going to be to figure out how quickly can we get from our current position to our ultimate destination? Specifically, we want to find out what is the minimum number of days that we need to reach the destination in the presence of these winds, as they have been described by the weather forecast.\n(Refer Slide Time: 08:27)\n \nIf you look at the actual output format, and this is a screenshot from the problem statement, it says exactly what you would expect. The output has only one line and it prints the minimum number of days that are required for the ship to reach x2, y2. But then it has this interesting follow-up line which says ‘if it is impossible, then print -1.’ This line right here suggests the possibility that our task may, in fact, be impossible in some situations.\nIt is perhaps conceivable that there are choices of starting points and destinations, and weather forecasts, which are such that the forces of nature are so strong that no matter how clever or how hard working a captain you are, you simply cannot get the ship to where it should be.\nThis is a good time to pause and think about whether you can come up with such a concrete example or is it just a trick statement here. Maybe, the problem setters thought that this would be a cute thing to add just to throw you off a bit. Take a pause and try and play around with some examples and see if you can come up with one that is, in fact, impossible. Come back when you are ready.\nHopefully, you had a chance to think about this. One possibility is that you are in the ‘what is impossible camp.’ Maybe, you believe that no matter how adversarial the situation is, if you are determined to get the ship to where it should be then you will manage to do it. However, it turns out that this is not a trick sentence. There could be scenarios, which are, in fact, impossible.\n(Refer Slide Time: 10:09)\n \nHere is one which is very similar to one of the sample input-outputs that are given in the problem statement. Here is a situation where the ship looks temptingly close to its destination. It is just one unit off to the left, or to the right, depending on how you are looking at it. The weather forecast is also very simple. It says that the winds are always blowing northwards. Since the forecast is periodic, we know that we are forever stuck with a wind that is pushing the ship up north.\nLet us think about why the ship under this circumstance will never reach the destination. For this, let us try and analyze what are the possible things that the captain can do. The first possibility, for instance, is that the captain can choose to abstain and say that, ‘okay, we will not do anything.’ In this case, the wind is going to take the ship one unit north, and what happens is that you are truly doomed from here.\nThe reason for that is in all future steps, your ship is only going to gain, I guess, altitude is not the word, but it is either longitude or latitude, one of these things. Basically, the ship will either stay where it is, that will happen when you issue a negating force to what the wind is doing, you try to move downwards, or you just move either North or Northeast or Northwest. But you are never coming back. You will never come back to thinking of this as rows and columns, you will never come back to the ith row if that is where you started out. So, if you decide to do nothing, then it is very clear that there is no looking back.\n(Refer Slide Time: 11:56)\n \nThe other thing that you could do is that perhaps you could try to go North. It seems even more silly, to be honest, than what we did in the previous case. If you choose to move north, then you are only helping the wind in taking you further away from your destination. You just drifting away even faster. It will clearly not work for very similar reasons once again.\nThe other thing you can do is try to move left, which again, intuitively is moving away from where you need to go. This time, you will move northwest. Again, it is the same argument as before. You are going to continue to either stay in the (i+1)th row or actually move even further up and further away, in particular.\n(Refer Slide Time: 12:53)\n\nThe two remaining possibilities are that you either move down or you move to the right. If you move downwards, then all that happens is that you stay where you are because you have negated the wind. If you move to the right, which seems to be the most natural thing to do because that is where you are supposed to go, in the absence of the wind, you would have reached at your destination, but in the presence of the wind, you just miss it.\nSo, you end up going upwards instead of going to the right. All in all, no matter what you try to do, you are not reaching your destination. Here again, with the last case, the same argument applies with regards to once you have shifted one row upwards, it is just going to be downhill from there, or maybe uphill.\nWhat I am saying is that it is, basically, a lost cause. Either you stay where you are permanently, or if you have any movement at all, it is going to be damaging. It is just going to make you drift further away from your destination. The closest you can be is to stay put. But that is not what we are analyzing here. We want to reach the destination. Overall, this tells us that these impossible scenarios do exist, and whatever strategy we come up with should have the ability to recognize them.\nHow do we go about something like this? If you remember the last problem that we discussed, The Meeting Place Cannot Be Changed. One question that we asked ourselves was: Are ‘k’ seconds enough to get everybody to meet at some common point? This turned out to be an insightful question to ask, which eventually led us to our solution.\n(Refer Slide Time: 14:45)\n\nHere we will ask an analogous question, which is essentially going to be: Are ‘k’ days enough for us to reach the destination? If there is a solution at all, it is going to require some number of days. We will show that if there is a solution, then there is also a solution, which is at most something. This will be an upper bound that we identify so that we have a well-defined search space. We say that either it is an impossible situation, or the possibilities are really limited to this range for the value of an optimal solution.\nOnce we do that, notice that we can again binary search on this range. Because if you can get to the destination in at most ‘k’ days, then you can get to the destination in at most ‘k’ prime days for any ‘k’ prime that is larger than ‘k.’ That gives us the sort of a binary searching strategy, just like before.\nIf the answer to this question: ‘Can we reach the destination in k days?’ is yes, then we need to challenge ourselves with smaller values of ‘k.’ But if the answer is no, then we know that we need more time because we certainly cannot do it with fewer than ‘k’ days if we cannot do it in ‘k’ days already. In that case, we will search for values larger than ‘k.’ The overall template is the same as last time.\nBut we do need to fill in a couple of very specific blanks. The first one is identifying the scope of the search space. So, we will have to think about what is an upper bound on the size of any optimal solution, if one exists. The other thing is, how do we answer this question? When we are probing the midpoint of whatever our current search space is, we need to ask ourselves, are so many days enough?\nBased on whether the answer to that question is yes or no, we will prune our search space appropriately. These are the two things that we need to figure out. Let us address the second question first. Let us talk about how to figure out if we can reach our destination in ‘k’ days.\n(Refer Slide Time: 16:58)\n  \nTo address this question, let us just draw up an abstract scenario. Here you can see the ship in its initial location. You have the destination, and you have the weather forecast as usual. To consider the possibilities of what can happen over a period of ‘k’ days, it is useful to just split up the impact of the weather conditions, and the impact of the captain’s instructions. You know that the weather forecast is an inevitable factor in what happens over the next ‘k’ days. Let us consider that first.\nWe let the wind do its thing and just keep track of how the coordinates are going to change as the weather forecast plays out. You can do this by simply looking at the code of the forecast and figuring out how much you have to adjust the ‘x’ and ‘y’ coordinates of the ship in aggregate.\nIn some sense, you know where the ship will end up. If the captain was sleeping throughout these ‘k’ days, if there were no instructions from the captain at all, then you would be at this location that we are for now calling x3, y3. The question is, can we come up with criteria of when the destination is accessible? Given we know that we are going to take a hit of at least so much in our x and y coordinates. Of course, what we are still left with, we have some role to place yet. We have to figure out if we can do some course correction by exploiting the fact that the captain can do some work.\nBut how much course correction is going to be possible? Is it going to be enough for us to reach the destination? Please pause the video here and think about if you can come up with some criteria for whether the destination is reachable or not. Given that the unavoidable impact of the wind takes you to x3, y3 if you do nothing. Hopefully, you had a chance to think about this.\nNote that the thing we need to make precise is the following. We want some kind of clean criteria that will help us identify exactly which points are accessible, given that we start at the starting point and the wind brings us to x3, y3, if considered stand-alone. Also, given the fact that we still have the opportunity of ‘k’ days worth of course correction across both coordinates combined.\nWhen you put all this together, you realize that the points that are ultimately accessible to the ship, starting where it started and given all of these other facts are precisely those points, which have a Manhattan distance of at most ‘k’ from x3, y3. By Manhattan distance, we just mean all points that can be reached by a perturbation of, let us say, ε1 across the ‘x’ coordinate and a perturbation of ε2 on the ‘y’ coordinate, such that the ε1+ε2 is at most ‘k.’\nYou are allowed to move along the x and y coordinates in such a way that the total movement does not exceed ‘k.’ That is, sort of, exactly what we can afford to do. As we were saying earlier, whether you do the compounding of the instructions from the wind and the instructions from the captain on a day-to-day basis, or whether you separate them out and consider the effect of the wind first, and then the effect of the captain’s instructions, the ultimate point where you land up is going to be the same.\nThis reordering of the instructions is useful because you can first focus on x3, y3. You know that that is where you are going to reach by virtue of the weather forecast. Now you can consider what can possibly happen based on the remaining ‘k’ instructions. What can possibly happen is that you can only move around in this sort of ‘k’ neighborhood of x3, y3, but this is not the standard ball around x3, y3. As I said, everything that is accessible through a total movement of ‘k’ units across both coordinates.\nHopefully, that is clear. Of course, in this particular example, you can see that our destination actually does fall in this region that we have identified and is, therefore, accessible. This is only an abstract example. I have not even put in a specific weather forecast or specific numbers. But that is not important. I think what is crucial is just being able to identify this condition. To recap the actual condition, what we are saying is the following.\n(Refer Slide Time: 21:58)\n \nSo, ‘k’ days are enough if and only if the Manhattan distance between x3, y3, and x2, y2 is at most ‘k,’ where x3, y3 is the point that you land up at if you were to start at x1, y1, and just obediently follow the weather forecast for ‘k’ days. Once again, we will have to figure out how to write this in code. Because ‘k’ could very well be more than ‘n,’ which is the number of days for which you have the weather forecast.\nYou have to do a bit of a circus to do the periodic exercise to figure out exactly how much movement is there. Fortunately, it is not hard at all. It is just a matter of being careful about keeping this aspect in mind. Let us recap what we have learned so far.\nRemember, we were trying to address the question of whether we can reach our destination in at most ‘k’ days. In particular, we wanted to come up with a procedure that will help us identify whether the answer to this question is yes or no. We said at a high level that it is useful to separate the impact of the weather forecast from the captain’s instructions. So, as a first step, what we did was we calculated the net effect of the weather forecast up to ‘k’ days on the coordinate x1, y1, and this brought us to the coordinates x3, y3.\nIn the second step, we just had to check if the Manhattan distance between x3, y3, which is where we land up under the influence of the wind, is at most ‘k’ from x2, y2, which is our destination. If it is, then the answer to the question is yes. If it is not, then the answer is no. By now we have a subroutine, which can tell us if ‘k’ days are enough or not.\n(Refer Slide Time: 23:52)\n\nThe only piece of the puzzle that remains is to figure out the scope of the search space. You know the rest of the template. You know you are going to do a binary search. You just have to figure out a valid upper bound for the search. It can be dangerous to work with an ad hoc upper bound, because if it is not good enough, maybe there was a solution that was bigger than the upper bound you were experimenting with, but you just missed out on it.\nTo address this, what we are going to do now is to come up with a guaranteed upper bound, which assures us that if there was a solution at all, there would have been one with cost, at most, this much. It is safe for us to restrict our search space to be 0 to that quantity, whatever that quantity is. I will also say that when you are solving a problem like this in a contest, then coming up with a provable argument of the sort that we are just going to see in the next few minutes may not be completely necessary.\nIf you have some intuition based on the limits of the problem, you could just try to give it a shot with that. Or you could simply try and shoot for the largest upper bound that the time constraints will allow. At this point of solving the problem, we are probably reasonably confident that our overall binary search template is correct. We also know how to handle the probing questions of whether ‘k’ days are enough.\nThe only issue left is, what upper bound should we use? We can do a quick back-of-the-envelope calculation to estimate the amount of time that we need to answer the probes. Then we can actually reverse engineer what is the largest limit that we can afford to have for our code to not timeout. Then we can simply use that limit. So, if we are short on time, you can use tricks like this. But it turns out that there is a very nice argument, which says that you can work with a particular limit. Let us try to understand that a little bit.\n(Refer Slide Time: 26:03)\n\nHere is our abstract picture. Let us use ‘n’ to denote the length of one full forecast cycle, the number of days for which we have the weather forecast. Let us also use ‘d’ to denote the Manhattan distance between the original source and destination points. That is what we have. The claim is going to be that if this is not one of those impossible scenarios, then there is a solution whose cost in terms of the number of days is at most d*n, and d and n are as we just defined.\nLet us try to argue this a little bit. The intuition here is that with every cycle of the movements of the wind according to the forecast, you must somehow reduce the Manhattan distance by at least one. If you do not have a strategy to do that, then you are basically never going to get to the destination in the first place. If you think about it a bit that is what was happening when we were discussing the one impossible scenario example earlier.\nIn one cycle of the weather forecast, which was just essentially one day, we were not able to reduce the Manhattan distance between the source and the destination. Remember that they were one unit apart. We saw that no matter what we did, they remained one unit apart, or they drifted even further apart. That is the kind of spirit of the argument that we are going to make right now as well. Let us get to it.\n(Refer Slide Time: 27:47)\n\nSuppose we do have a solution. The explicit claim we are making is that there is some sequence of ‘n’ instructions that the captain can give, which, if given along with this weather forecast that has been given to us in the first place, when is combined, then the Manhattan distance between the source and destination strictly decreases. That is the claim. So, again, just to recap, because this was quite a handful. What we are saying is that if there was a solution, that means there is a way of getting closer to the destination in one cycle of ‘n’ days.\nTo see that this is true, let us say that suppose this was not the case. That no matter what sequence of instructions the captain comes up with, and there is going to be 4n possible such sequences, for each one of them if we try to run that sequence of instructions in one cycle, then we would be left either where we were, or we would be left further away in terms of Manhattan distance from the destination.\nSuppose this is the case. No matter what you do, you either stay where you were, or you stay within the same Manhattan distance of the destination, or your distance from the destination in fact increases. One of these two things happens. If this is the case, then I want to argue that you cannot have a solution. No matter what solution somebody attempts, you are either going to not make any progress or if at all, you end up moving, then you keep drifting further and further away from the destination. Let us try to just get some intuition for why this is true.\n(Refer Slide Time: 29:41)\n\nSppose, somebody did try to come up with a solution. Even though we know that no matter what set of instructions you use in each cycle, the total amount of movement that you experience, at least in the first cycle, we know by assumption that our Manhattan distance from the solution has not reduced. In particular, it is either stayed the same or it is increased. Tthat is what is going to happen when the ship has finished executing all of these instructions from the first cycle.\n(Refer Slide Time: 30:14)\n \n \nSuppose it gets to the end of the second cycle. I want to claim that, once again, this is true. That the distance between the source and the destination has either stayed the same or it is increased, but it could not have possibly decreased, and so on and so forth. Bcause this just keeps happening, you never actually get to the destination. To understand this a little bit better, let us make the arguments somewhat more explicit by working with actual coordinates.\n(Refer Slide Time: 30:41)\n \nTo make our life a little bit simpler though, instead of working with x1, y1, and x2, y2, let us just say that we are trying to reach the origin from some point x, y. This is without loss of generality because you can always slide your coordinate system so that the origin coincides with the point x2, y2, which is your destination. And I am just relabelling x1, y1 as x, y.\nHopefully, this part is okay, just makes the notation a little bit cleaner. Notice that the Manhattan distance of any point from the origin is just the sum of its x and y coordinates. That comes in useful as well. Notice that in the first cycle of ‘n’ days, let us say we get from x, y to x’, y’, what we know is that x’ + y’ is at least x + y. Right. Because by assumption, we have said that no matter which of the 4n sequences you deploy, you are not going to reduce the Manhattan distance from the destination.\nWe know that we are at least as far away as before. Let me just try to write x’, y’ as ε offsets from the original point x, y. So, we can say that x’ is x + εx, and y’ is y + εy. Note that our information about x’ + y’ being at least x + y simply translates to εx + εy being at least 0. That is what we have in the first step. What is interesting to observe is what happens in the first and the second cycles combined. Let us say we go from x, y to x’‘, y’’.\nLet us say we get there by deploying the first sequence of instructions, the orange ones, and then these green ones. This picture of just being a bit miserly with space may be a bit misleading. What is going on is that to get from x, y to x’‘, y’‘, you essentially go to x’, y’ first, and then from there, you deploy a fresh set of instructions, which are these green ones. We know that if we had deployed the green instructions on just x, y directly and nothing else, we would still be left no closer to the destination.\nLet us see if we can use that to say that even x’‘, y’‘, which is the orange and the green instructions combined, are also no closer to the destination compared to when we started out. So, let us write out x’‘, y’’, and let us say that the effect of the green instructions was ε offsets once again, but this time it is the green epsilon. Let us say that if you had applied the green sequence of instructions on x, y, then you would have landed up at x + εx and y + εy, with these epsilons being the green ones.\nThen if you apply the green instructions to x’‘, y’‘, then what you get is this point here, which is x’ + εx and y’ + εy. Now let us substitute for x’ and y’, in terms of x + εx and y + εy. But this time, it is the orange epsilons from before.\nNotice that we essentially have offsets. We have understood x’’ and y’’ in terms of offsets from x, y, but we also know that the net effect of these offsets is non-negative. What we really want is the total offset to be negative to be able to come closer to the destination.\nNotice that even after two cycles, that is not happening. It is the exact same argument to say that it is not going to happen after three cycles or four cycles, or after any number of cycles. If it was really the case that no matter which set of instructions you apply, you come no closer to your destination.\n(Refer Slide Time: 35:06)\n \nWe know that if there is a solution, then there must be a sequence of instructions, which is such that if you combine it with the weather forecast, then it strictly reduces the Manhattan distance between the source and the destination. Now just keep repeating this argument to see that you must have a sequence that brings you to the destination in, at most, d*n steps. Because in every cycle, you are able to reduce the Manhattan distance by at least 1 by applying the appropriate set of instructions. So, you will never need more than d*n many steps to actually get to the destination.\nIf you look up the actual limits in the problem for ‘n’ and so on, I think it turns out that your upper limit is some 2*1014 or something like this. In any case, at some fixed upper bound, as I said, you do not have to have either a bound that is so precise, nor do you need an argument that is this detailed. You just need to have some either overall intuition for what is going on. So, that you arrive at this d*n as sort of a bound, roughly speaking, or you can, as I said, employ a trick to just let the bound be as large as it can possibly be. Just work with that. That should be perfectly fine.\n(Refer Slide Time: 36:35)\n \n \nLet us just recap how the binary search will work. As usual, you get to the midpoint. If the current midpoint is, let us say, some ‘k,’ we ask ourselves: Are ‘k’ days going to be enough to reach the destination? If ‘k’ days are indeed enough, then we need to challenge ourselves to find smaller values of ‘k’ that are probably better, but we can definitely, confidently eliminate the top half of the search space.\nSimilarly, if ‘k’ days are not enough, then we know for sure that all values of ‘k’ that are smaller are useless for us because we know for sure that none of those are feasible. So, we can just focus on the top half of the search space. With that, notice that we are pretty much done. You might be wondering about when this algorithm returns a verdict of impossible for the task at hand. Notice that it will happen when each of your probes individually returns an output of infeasible.\nYou try with the first midpoint: it says, well, these many days are not enough. You try with a larger value, and it is still not enough and you try with a larger value, and it is still not enough, and so on and so forth. You keep doing this till the very end. If every output is ‘this is not enough,’ then at that point, you know that you have exited the binary search with some sort of a failure to discover a ‘k’ in the range that we had stipulated, which would work for you.\nBut since, we have argued already that if there is an answer at all, then there is an answer in this range. This is sufficient evidence to conclude that your task was indeed impossible. Of course, if any one of the probes says feasible, then you certainly have at least one valid answer. Because of the nature of the binary search, by the time you exit your ‘while’ loop that is controlling the binary search, the value that you have is, in fact, the optimal number of days. That, I think, brings us to the end of our discussion of the overall approach.\nIt is now time to roll up our sleeves and write some code. I think the implementation of this is fairly straightforward, and structurally, very similar to what we saw last time. But one detail to keep in mind is implementing the periodicity so that you can do these little operations in terms of figuring out if ‘k’ is feasible or not, and things like that, comfortably. We will get to that in just a moment. But this is your standard reminder that if you wanted to try this yourself, then please give it a shot and come back when you are ready. In the meantime, let us just go ahead and talk about the implementation.\nSo, we will be looking at some Python code here. The reason is that, first of all, the official editorial for this problem has some nice C++ code already. I recall thinking that it was quite readable. I think you could follow that if you primarily work in C++. The approach is exactly the same as what we have here. There may, of course, be a few very minor implementation details that vary but the algorithm is essentially what we have discussed, so far.\nThe other thing is, this is a problem involving some fairly big numbers. I just wanted to demonstrate that you can do pretty well with a Python-based implementation as well. I think if you look at the problem history, you will see that there have been a number of Python-based solutions that have passed and we are going to look at one such.\n(Refer Slide Time: 40:17)\n \nTo begin with, what we have here is just taking the input in. This is pretty standard. There is nothing unusual here. We take in the coordinates of the origin and the destination and store them with variable names that are consistent with our discussion, so far. We have x1, y1, and x2, y2. Then we have the length of the weather forecast that is an integer, and we have the weather forecast itself, which is a string with that many characters. We take that in as a string and call it ‘S.’\nNow, let us just compute an array. This was essentially the analog of the prefix sums approach for keeping track of the periodicity of the weather forecast. What we want to do here is, essentially, pretend that we are starting at the origin and let the wind drag us around wherever it needs to, based on the weather forecast. This code here is exactly like the code version of the slide where we were explaining what the forecast means, what the different letters mean.\nBased on whether you are going up, down, left or right, you update the ‘y’ or the ‘x’ coordinates respectively. This will kind of be your memory of how you travel, based on the weather forecast alone. We are going to store in walk list your evolution as you go along. For instance, let us say the forecast was R, R, R, then the walk list would be 0, 0, to begin with, then you would append a 1, 0 because you have moved one step to the right and nothing on the y-direction, that is going to be the same.\nThe next element in the walk list will be 2, 0, and the element after that will be 3, 0. You could write down this piece of code here and run some print statements just to sanity check that everything works out the way you expect it to. This is the sort of place where there may be small typos like a + may become a - or something like that. It is always a good idea to sort of sanity check these things as you are writing the code so that once you have moved on from here, you are reasonably sure that there were no typos or bugs here. So this is some auxiliary thing, which will help us later.\n(Refer Slide Time: 42:46)\n\nThe main drama, of course, happens with the binary search. That is what we want to talk about next. Here we have the initial limits. We worked very hard to come up with an upper bound on the search space. We said it is two times 1014. I am just being lazy here, 1015 is my upper bound, that should work just as well, of course. It is even more liberal.\nNow, we have the usual binary search templates. As long as the left and the right endpoints of the search space have not converged to a single conclusive point, we have to keep going. That is the ‘while’ statement that declares the start of the binary search process. We compute the midpoint in the standard way as well, nothing fancy there.\nNow we have to figure out: so, what is mid? Mid is our current guess for the number of days that we want to spend. The question we are asking ourselves now is: Are mid-many days enough to reach the destination?\nRemember, the criteria for figuring out the answer to this question, we had to compute the Manhattan distance between the destination and the place that we will end up at if we were only at the mercy of the weather. We have to, first of all, compute x3, y3. Where do we end up if we just followed the weather forecast?\nFirst, let us figure out how many cycles of the weather forecast are there inside mid and what is the remainder. So, you can use this built-in ‘divmod’ function to quickly figure out the quotient and the remainder. That is exactly how it works. If you give ‘divmod’ two numbers, let us say a and b, it is going to compute ‘a’/‘b.’ It is going to give you the quotient and the remainder. That is what we have done here.\n(Refer Slide Time: 44:29)\n  \nNow that we know this, let us compute the x and the y offsets from the origin point. We start at x1 and y1 respectively. And we know that we have to go through Q cycles of the weather forecast. We have an offset of Q*x and Q*y. If you go back, remember that x and y are essentially storing the total amount of offset that you experienced if you go through one cycle of the weather forecast.\nThat is what we are doing here. We are going through Q cycles. We are adding Q*x and Q*y. But now we also have ‘remainder-many’ days of the weather forecast that we experience. It is not a full cycle; it is a partial cycle. The offsets for all possible partial cycles are stored in the walk list. If you go to the ith element of the walk list, you will know where you would be ‘i’ days after experiencing the weather forecast starting from the origin, so that is essentially the offset. We add that offset to whatever coordinates we have computed, so far.\nThe expression that you see after the negative sign is essentially the values of x3 and y3, and the absolute difference between x2 and y2 with x3 and y3 respectively is essentially giving you the two components of the Manhattan distance between the destination and x3, y3, which is where you land up only under the impact of the event.\nLet us recall what was the defining criteria for whether mid-many days are going to be enough. What we needed was for this distance that we have just calculated between the destination and x3, y3. We needed that distance to be at most mid. If that distance is at most mid, then we know that we can issue appropriate instructions to get to the destination, otherwise, mid-many days are not enough. That is what is happening in the next four lines of this program.\nWe are saying that if the total distance, which is given by the sum of the x and the y offsets, if that distance is at most made, then great. Then mid-many days are enough, and we should be more ambitious. We should aim to work with smaller values of mid and see if that would also work out. What we do is we take the right endpoint of the search space and bring it down to mid because larger values of mid are of no interest to us. We have already managed what we need with mid and now we are going to explore the lower half of the search space.\nOf course, in the ‘else’ block, the exact opposite logic takes over, that mid many days are in fact, not enough. Because of exactly what we said, your distance is too much. Your distance from x3, y3 to destination exceeds mid. Whatever you can do within mid-days, you are not going to arrive at the destination. In this case, you know that mid is not enough. Your search base reduces to ‘mid+1’ all the way up to the end. You can bring the left endpoint all the way up to ‘mid+1.’ Okay. So, these are the two possibilities that play out here.\nNotice that when the answer is impossible, you will never get into the first ‘if’ block. So, R will remain at 1015 or whatever. The left endpoint will just keep getting closer and closer to the R endpoint.\nAt some point, it will just collapse and become 1015 itself. That is in fact, what we have next, what we are saying is that if L becomes 1015 at some point. Then you could have also done this outside of the ‘while loop,’ it does not make a difference. If you have hit the upper limit, if L is equal to R is equal to 1015 then we know that it is impossible to reach the destination.\nWe also flag that for ourselves. So, if it is not impossible, then whatever the value of mid was, which is also the value of L and R when you have exited the loop, that is going to be the answer that you need to print. That is what is happening here. That actually is essentially the entire program. This was the binary search over the number of potential days that you need to get to your destination.\nI hope you have a chance to try this out. If you have your own versions in either C++ or Java with similar documentation, then please remember to submit a pull request on the official repository. Other languages are also equally welcome, of course. Remember to attribute yourself and share your Discord username if you are in the community so that we can give you a shout-out.\nSo, we have one problem left for this week. That is going to be more about numbers. There is not so much of a story there. But it is also really fun. I hope you will join us back for the next and the last lecture of this series this week. Thanks so much for watching, and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W02/Lec05.html",
    "href": "materials/cpnotes/W02/Lec05.html",
    "title": "M 1 (Trouble Sort)",
    "section": "",
    "text": "Lecture - 05\nSearching and Sorting - Module 1 (Trouble Sort)\n(Refer Slide Time: 00:11)\n\nHello, and welcome to the second week of Getting Started with Competitive Programming on NPTEL. I hope you have been having a great time in the course so far. So, this week, we will be focusing on searching and sorting-based problems. These are really fundamental techniques. It turns out that they are extremely useful in competitive programming as well.\nThey show up in all kinds of complex problems, either as pre-processing routines or as useful things to do here and there or as the thing that helps you get to the final answer at the very end. So, it is a good idea to develop some degree of competence in using these techniques. For the most part in this week, we will be focusing on identifying the fact that these techniques come into play.\nIn particular, we will not really be worrying about implementing classic, sorting algorithms, like say, insertion sort, or merge sort, or quick sort, or whatever. If that is something that you feel like doing just to brush up a little bit, then there is a great sequence of exercises on HackerRank. You can go and try that out. If you just want to brush up on the concepts, then there are some really nice articles on Khan Academy. I would recommend those as well.\nYou can find the links either in the description of this lecture video or you can find them on the prerequisites page for week two on the course homepage. Please go ahead and take a look in case your background in sorting algorithms and binary search is a little bit rusty because that will be helpful as you come back here. Another thing that is worth doing in preparation is to look up the documentation for the built-in sorting functions in your language of choice.\nMake sure what parameters they take in, and whether they have any extra superpowers. Also, just double-check that you know how to do simple related tasks like, let us say, sorting an array in reverse order, sorting a subarray, and things like that. With all that said, we can now begin our discussion of the first problem for this week, which is Trouble Sort. It is, once again, a Google Code Jam qualification problem from back in 2018. It might remind you of Reversort because there are some reversals happening. But of course, it is quite a different problem. So, let us get started.\n(Refer Slide Time: 02:34)\n\n\n\nLet us begin as usual by going over the problem statement. We are introduced to trouble sort with some background on bubble sort, to begin with. Remember that in bubble sort, what happens is that we do repeated passes over the array. In each pass, whenever we encounter a consecutive pair of integers, which are out of their natural order, then we swap them to fix it.\nAuthors claim to have come up with a better or an enhanced version of bubble sort, where instead of considering a pair of numbers at a time, they are going to consider triplets of numbers at a time. If a triplet is out of order, by which they mean that the last number in the triplet is smaller than the first number in the triplet, then they are going to reverse this entire triplet. As opposed to swapping adjacent numbers, this entire triplet gets reversed.\nNotice that when you reverse three consecutive numbers, the middle number actually stays in place. It does not shift in any way. That is essentially trouble sort. The claimed reason behind its name is that it is short for a triplet version of bubble sort. So, there is always a cheeky remark in the Code Jam problem statements. This is the one for this example here.\n(Refer Slide Time: 04:04)\n\nLet us take a look at the pseudo-code for trouble sort just to make sure that we are on the same page about what it does. There is going to be a flag variable done, which keeps track of whether we have managed to sort the whole array or not. If done is true, then that means that we can stop doing any further passes on the array.\nWe initialize done to true and then we start our pass. Because we are looking at triplets, we do not have to go all the way up to the (n-1)th element, we only go up to the (n-2)th element because otherwise, you will just fall off the cliff, so to speak. By n I just mean the length of the array.\nSo, I am using n to denote Len of L. What happens in the ith iteration is that you compare the elements in L[i] and L[i+2]. These are the extreme points of the triplet that starts at the ith location. If it turns out that these elements are out of order, so the element that appears earlier is larger than the element that appears later, then we reset the done flag to false. We say: Okay, we did encounter a problem, this array was not sorted in its present form.\nTo fix this particular aberration, we will reverse the sub-list from L[i] to L[i+2]. Once again, notice that this amounts to swapping the elements at L[i] and L[i+2] because the middle element, which is at L[i+1] stays in place during this so-called reversal. That is pretty much the entire algorithm. You keep fixing triplets for as long as you need to.\nWhen you finally are able to make one full pass, without having encountered any broken triplets, then you stop. To understand what is going on, it is useful to walk through an example. Let us just go over the workout example that is given in the problem statement. We have an array here with 5 elements 5, 6, 6, 4, 3, in that order. The numbers written just below these elements are the corresponding array indices for our reference. Let us go over a run of trouble sort on this array.\n(Refer Slide Time: 06:32)\n\n\n\n\nTo begin with, the variable done is initialized to false, and i is not initialized yet. But we will get to that in a minute. We, of course, enter the while loop and reset done to true. Then we initialize ‘i’ to 0. Notice that in the first iteration of the for loop, we are comparing the elements at L[0] and L[2].\nThose elements happen to be 5 and 6. Notice that the conditional does not really trigger because 5 is not greater than 6. So, we move on. We go back to the for loop, we increment ’i’ to 1. Now we are comparing the elements L[1] and L[3]. However, this time, the conditional will trigger because 6 is greater than 4. So, we enter this if block, and we reset done to false.\nThis is a note to say that this pass did have a problem. We want to flag that for ourselves. In the next step, we will try to fix this aberration by swapping these two elements. The language here is that you reverse the sub-list. But as we have mentioned earlier, that is the same as swapping the endpoints. So, this is now done. We can go back to the next iteration of for loop. At this point, ’i’ gets incremented to 2 and we are comparing the elements at L[2] and L[4].\nOnce again, notice that 6 is greater than 3. The conditional will trigger. Done is already false. So, we do not have to do anything there. But we do have to execute the swap. At this point, the array looks like 5, 4, 3, 6, 6. Now, if we go back to the start of for loop, ‘i’ is incremented to 3. But notice that there is no triplet that starts from L[3]. In particular, we have just run out of room.\nSo, this iteration is done. We now go back to the while loop. Are we done? Well, the value of ‘done’ is false. Remember, we had a warning that this pass had some issues, not all the triplets were properly placed. So, we need to do another round of checking. In fact, if you look at the array right now, it is not yet quite sorted. It is a good sign that we are giving this another sort.\n(Refer Slide Time: 09:03)\n\n\n\n\nOnce again, we will begin by resetting the done variable to true and then initialize the ‘for’ loop. So ‘i’ get reset once again to 0. This time, notice that when we compare the elements at L[0] and L[2], this is no longer a valid triplet. Since 5 is greater than 3, we do need to execute a swap before which we should also remember to reset the done variable as before. So, ‘done’ is now false. We have the swap between 5 and 3.\nWe go back to the start of the for loop, and we increment ‘i’ to 1. At this point, we are comparing the elements L[1] and L[3]. Notice that this pair of elements is already in the right order. So, we do not have to do anything. The conditional does not trigger and we go back to incrementing ‘i’ to 2. When i=2, we are comparing the elements by 5 and 6. Once again, these guys are doing fine.\nWe do not need to do anything here. We go back to the ‘for’ loop. But once ‘i’ is incremented to 3, we have essentially run out. So, we go back to the start of the while loop now. Once again, notice that we are not done yet. We will have to do this one more time. We reset done to true. But this time around, notice that every time we compare these triplets, everything is going to work out. You can see this by just observing that the whole array is sorted.\nIn particular, you will never encounter a triplet, which has its elements being in the wrong order. Everything works out here and we are, in fact, this time done. The algorithm stops with the array state being 3, 4, 5, 6, 6, which looks pretty good. Everything is sorted. You might be tempted to think that trouble sort is a real sorting algorithm after going through this example. But it turns out that that would be quite misleading.\n(Refer Slide Time: 11:12)\n\n\nWhy don’t you take a moment here to try ‘trouble sort’ yourself on this small example? Think about what trouble sort would do. See if you can come up with your own examples where trouble sort has suspicious behavior. Hopefully, you had a chance to take a look at this. And if you did, you would have realized that trouble sort is not going to successfully sort this array.\nThe only elements that it has a chance to compare are the elements that are at indices 0 and 2. Those, of course, seem to be perfectly in order. But you can see that the overall array is certainly not sorted. So, trouble sort does fail at this point. In fact, that turns out to be the problem statement.\n(Refer Slide Time: 11:56)\n\n\n\nIt is our task to figure out if a given array gets sorted by trouble sort or not. Further, if trouble sort fails, we also have to identify the first point of failure, which is defined as the smallest index with the property that the value at that index is larger than the value that immediately follows it in the array after trouble sort has finished processing the array. Of course, you might be thinking that trouble sort looks like a reasonably straightforward algorithm.\nWhy not just simulate trouble sort on the input array, and check if the resulting array is sorted or not? That is a perfectly valid approach. But to figure out if that is going to be feasible, we will have to think about the complexity of running trouble sort on a given array. Then we have to take a look at the problem limits. Let us address the first question first. Once again, take a pause here, go back in the lecture if you need to, to look at what trouble sort is doing more closely. Think about what would be a valid upper bound for the complexity of trouble sort, when it is run on an array with ‘n’ elements. Come back when you are ready. Hopefully, you have had a chance to think about this.\n(Refer Slide Time: 13:16)\n\n\nLet us take a look at the trouble sort pseudo-code again. You will see that there is this for loop that clearly runs for ‘n’ iterations, again being the length of the array that we are working with. The real question: How many times do you run this for loop? That is going to be as many times as you need to run the outer while loop. You can probably come up with examples of arrays where the outer while loop actually runs for ‘n’ many iterations.\nSince that can happen, we know that there are certainly instances where the running time can be as bad as ‘n-squared.’ It turns out that the running time can, in fact, also be bounded by ‘n-squared,’ it is never worse. You can show that the outer while loop will never execute more than n times. The reason for this will become clearer as we go along.\nBut hopefully, you had some intuition for why the answer to this question was order n-squared. The question: Is this going to be a reasonable strategy for us? For this, we need to look at the limits of the problem.\n(Refer Slide Time: 14:30)\n\n\n\n\nIt turns out that our arrays can have as many as 109 elements. So, the order n-squared algorithm is not really going to work out. We need a slightly different approach. Let us go back to the drawing board and look more deeply into what trouble sort is doing. Here we have an array with six elements, and I have pulled out the most crucial part of the trouble sort pseudo-code, which emphasizes what is happening during the passes.\nLet us take a look at what happens when we do a one-pass over this array. In the first iteration, the first and the third elements get compared. In the second iteration, the second and the fourth elements get compared. In the third iteration, the third and the fifth elements get compared. In the fourth iteration, which is the final iteration, the fourth and the sixth elements get compared.\nNotice that the green elements get compared to the green elements, and the pink elements get compared to the pink elements in every single iteration. In particular, a green element never gets compared with a pink element, just by design. In some sense, because you are skipping over the middle element of the triplet, whenever you are considering a triplet, you never have a chance to compare an element, which is sitting at an odd index with an element that is sitting at an even index. It means that there are going to be a lot of lost opportunities.\nIf you remember the array 1, 3, 2, this is exactly what was happening. Trouble sort can be thought of as two independent runs of an algorithm that you are already familiar with. Take a moment to pause here and think about if you can fill in the blank in this sentence: So, trouble sort is just two parallel runs of which algorithm? Do not take the word “parallel” too seriously.\nWhat I mean is that it is essentially running a familiar algorithm on some sub-array and it is running the same algorithm on another sub-array. Can you think of ‘trouble sort’ this way? If you have had a chance to think about this, you might have come to the conclusion that trouble sort is essentially just a bubble sort being run separately on the sub-array that consists of the odd indices, and separately on the sub-array that consists of the even indices.\n(Refer Slide Time: 17:00)\n  \nYou can think of trouble sort as sorting the even indices separately from the odd ones, and then putting them back together. This is a really useful perspective on trouble sort because it allows us to implement trouble sort without really implementing it. In particular, what we want to do is take an array and figure out what is the array that trouble sort would output if it was working with this given array as input.\nWe want to get to this information without actually literally implementing trouble sort. Now knowing what trouble sort what is effectively doing, we can do this in our own way. I think by now you have enough hints to piece together the final algorithm. If you want to take a pause here, this would be a good time to try and figure out the rest of the details yourself, and then come back to exchange notes once you have given it a shot. So here is what you could do with the information that you have at hand.\n(Refer Slide Time: 18:09)\n\nTo begin with, you could split the given array into odd and even sub-arrays. Collect all the numbers that are sitting at odd indices, and declare that to be your first array. Then separately, collect all the numbers that are sitting at even indices, and this becomes your second sub-array. Now, you could sort these two sub-arrays independently.\nHere crucially, remember to use an efficient sorting algorithm. Do not use something like bubble sort to stay true to the spirit of trouble sort or something like that. That would just bring you back to square one, in terms of an inefficient implementation that will definitely timeout. At this point, use a built-in sorting function, or even if you are using a sorting function that you have written. Make sure that it is based on an order ‘n log n’ kind of algorithm.\nSort these two sub-arrays independently, and then splice them back together. Put them back to one big array, with the odd elements being in the odd positions and the even elements being in the even positions. If this array is sorted, then that is what you have to output (if trouble sort works). Otherwise, you can do one-pass over the array to figure out the first inversion that you encounter.\nWhat you want is the first pair of adjacent elements that are out of their natural order, and that is fairly straightforward to do. At this point, I think, we have come to the end of discussing how we implement the solution. So we can now move on to the implementation. But let me just make a quick point before that, which is about the running time of trouble sort.\nRemember, I said that the running time can be as bad as n-squared. But how do you show that it is never worse than n-squared? Now that trouble sort is essentially performing two independent runs of bubble sort, you can use what you know about the analysis of bubble sort to argue an upper bound on the running time of trouble sort. In particular, you can observe the behavior of the even and the odd sub-arrays independently, and conclude that the outer while loop will never run for more than ‘n’ iterations.\nOf course, the inner ‘for’ loop by design will run for exactly n-2 iterations every time. The overall complexity is going to be ‘order n-squared.’ That is a claim that we had made earlier. I just wanted to make sure that we have some sense of why it is true.\n(Refer Slide Time: 20:50)\n\n\nLet us take a look at the implementation. I am just going to share the code snippets from the sample solution. You can find the sample solution from the official GitHub repository for these lectures. There is a link in the description of this video, as well as the course website. So, there is nothing special about the input formatting. It is pretty standard stuff. There are ‘T’ test cases. Every test case is a number followed by the elements of the array given as space-separated integers, so you just read them all in.\nThe first thing we want to do is split the input array into these odd and even sub-arrays. We just declare two integer arrays, and we run a loop that goes over the original array. Depending on whether the current index is odd or even, you pull out that element and push it to the correct sub-array.\n(Refer Slide Time: 22:02)\n\nThe next thing we want to do is to sort these sub-arrays that we have generated. This is the part where we need to be careful about using an efficient sorting algorithm. Here, I am just using the built-in sort function in C++. As I said, your language of choice should have an appropriate sorting method that you can use.\nYou could write your own sorting function as well. Just make sure that it is not bubble sort and that you are using or implementing an efficient sorting algorithm here. This is crucial to ensuring that you do not get a timeout. After this, you still need to put these arrays back. That is what is happening in the second half of this code.\nWe declare a new array called ‘sorted,’ which we are going to build out. This array that is named sorted may not be sorted. That is what we have to figure out. Maybe I should have used a variable name like ‘trouble sort output’ or something like that. But anyway, we will live with this. So, what is going on with ‘sorted?’ How are we building it?\nEssentially, it is the opposite of what we were doing previously. We were splitting the array and putting things back trying to ensure that the sorted version of the odd sub-array falls in place in the odd indices. The sorted version of the even array gets into the even indices of this array that we are calling ‘vsorted.’ Once again, you just run a loop. You do different things based on the parity of the current index.\nIf you are at an even index, then you pull an element from the even sub-array. If you are at an odd index, then you pull an element from the odd sub-array that you have sorted. The way I am doing this is that I am always pulling what is at the head of the array and I am able to do that. That is working because notice that I am erasing that element from the array that I am working with.\nThis is just one convenient way of doing it. But there are many other ways. You could instead also have an additional index, for instance, that advances through these arrays instead of deleting them as you go along. Whatever way you decide to do it should be perfectly fine.\n(Refer Slide Time: 24:22)\n\n\nNow that we have put everything back together, all we need to do is check if this array that we are calling sorted is actually sorted or not. Remember that if it is not sorted, we have to report the first inversion that we find, the first pair of adjacent elements that are out of order. This is fairly intuitive. You just go through the array step by step.\nEvery time you are at the ith location in the array, just compare the ith element with the (i+1)th element. If you have a problem, which is to say that the ith element is larger than the (i+1)th element, then you can trigger a flag to say that this is not sorted. The flag can also double up to remember the location so that you can just output the value of the flag as the answer.\nRemember, I am initializing the flag to -1, just so that there is no confusion. Because the first problem could even happen at the 0th index. For instance, in 1, 3, 2, the answer would have been 0. So, initialize your flag to -1. When you come out of this loop, just check if the flag is -1. If it is that means that the flag was never triggered - you never had a problem as you went along. The array is, in fact, sorted.\nBut if the flag is a value that is different from -1, then the value flag is actually the answer that you are looking for. It is the smallest index at which you encounter an adjacent inversion. You output the value of the flag in this case. The other details are pretty routine in terms of the formatting of the output and so forth.\nIn Code Jam, it is pretty standard that they also want the case number and the literal word case spelled out and so forth. Make sure that you get those details right. Then I think you should do well, in terms of getting your code to pass. Please do try this out and let us know how it went over at the Discord community or on the mailing list. We will, as always, look forward to hearing from you. In the next lecture, we will talk about a different problem and I look forward to seeing you there!"
  },
  {
    "objectID": "materials/cpnotes/W02/Lec8.html",
    "href": "materials/cpnotes/W02/Lec8.html",
    "title": "M 4 (Simple Skewness)",
    "section": "",
    "text": "Lecture - 8\nSearching and Sorting - Module 4 (Simple Skewness)\n(Refer Slide Time: 00:11)\n\nHello and welcome to the final module of our second week on ‘Searching and Sorting’ algorithms. This time we will talk about a problem called ‘Simple Skewness,’ which appeared in the Venture Cup 2016 elimination round. You can find this problem on ‘Codeforces.’ This problem has a flavor of a little bit of both searching and sorting, which is why I thought it would be a nice problem to end this week on. It is a simple statement in the sense that it is a short statement with no stories. Let us get to it.\n(Refer Slide Time: 00:49)\n\nWe are given this notion of skewness, to begin with. So, defining the skewness of a collection of numbers as the difference between its mean and median. Notice that this is not the absolute difference, it is the literal difference between the mean and the median. The skewness of a set of numbers could either be positive or negative.\nAlthough I will keep using the term ‘collection’ and ‘set’ interchangeably, this is not a set in the strict sense of the word, which is to say that this collection of numbers can have repetitions. You are also required to find a subcollection, which potentially has repetitions. There is no deduplication involved here. I think the usual term for this is multi-set. But I am not going to really keep that distinction in mind. I might often talk about a set of numbers. Keep in mind that this is a set potentially with duplicates all along.\n(Refer Slide Time: 01:47)\n \nJust to make sure that we are on the same page about the basic definitions, let us go over an example. Here we have a collection of numbers, which look pretty neat. By looking at it, you can perhaps already figure out that the mean = 50 and the median = 50. The median is usually defined as the middle element if you look at the sorted order, but the middle is not very well defined if the list has an even size.\nIf you are dealing with an even-sized collection of numbers, then the median is defined to be the average of the middle two elements. Hopefully, these definitions are clear. Now for this particular list, notice that the skewness is 0. It is not a skewed list at all; the mean and the median coincide. But let us see if we can introduce some skewness by playing around with the numbers a little bit.\n(Refer Slide Time: 02:45)\n \nLet us say we take the smallest number and make it even smaller. Then you can see that the impact it has on the mean is that the mean goes down but the median remains the same. In this case, the skewness decreases. On the other hand, if we were to take the largest number and make it even larger, you can see that this increases the mean without touching the median. In this case, the skewness increases.\nHopefully, you have a sense of what skewness means from this example. Feel free to pause here and work out your own examples with small lists of numbers just to, make sure that you are comfortable with the definition at this point. So, what is the task here? We have this definition, what are we supposed to do?\n(Refer Slide Time: 03:30)\n \nGiven this collection of numbers as input, which once again, I will emphasize do not consist of necessarily distinct integers (you could have duplicates), our task is to find a non-empty subset of these integers potentially with repetitions again, which has the largest possible simple skewness. Observe that unlike some of the previous problems that we have talked about, this question always has a valid answer. You do not have a scenario where you might say that there is no subset that maximizes the simple skewness.\n(Refer Slide Time: 04:13)\n \nTo see this, notice that at least in principle, you could just make a list of all the subsets that the given set has. Next to each set, you can just calculate its skewness. Then you can pick up the one that has the largest value of skewness. This already is a brute force algorithm to answer the question of what is the subset that has the largest simple skewness.\n(Refer Slide Time: 04:41)\n\nNotice that this is terribly inadequate because if you look at the input limits, the numbers here are fairly large. Even an n2 solution will not pass given that ‘n’ is 2 lakhs. We really have to think about this substantially more and try and get an improved approach, which is somewhat in the ballpark of ‘n log n,’ that is likely to work out. But before we get there, it is useful to think of an n2 approach even as a warm-up. That is what we are going to do. Then we will see if we can replace one of the things that we are doing with some sort of a binary search, which will get us to the n log n algorithm that we eventually want. This is, I think, a useful way of generally attempting such problems.\nWhen it is too much to tackle all at once to get to the best possible solution, come up with one that is probably not the one that you are looking for. See if you can use that as a stepping stone and improve it to the thing that finally works. In this spirit, let us just try to come up with some decent approach that improves on this very naive brute force solution that we discussed so far.\n(Refer Slide Time: 05:57)\n \nLet us begin by fixing some solution(s). We know for sure that there is at least one solution, maybe there are multiple optimal solutions. But the important thing is that there is at least one. Let us fix an abstract solution in our imagination. We do not know what the solution exactly looks like. This is what our algorithm is looking for. But continuing to just play around with our imagination, let us also reorganize the elements of the solution so that they end up being all sorted. Let us fix our attention on the ‘median element.’\n(Refer Slide Time: 06:29)\n\nAgain, we do not know what this median element is. Since we do not know the solution, we also do not know its median. But notice that it is something that we can guess. What I mean by this is that we do know that this median element must be one of the numbers that is there in the input array. So, let us just try all of them.\nWhat we are going to do is run one ‘for’ loop, which just goes over all the elements of the array and it asks the following question for any fixed element: If the optimal solution had this particular element as its median, then what would the solution look like? It turns out that this is a much easier question to answer. The median gives you a really good anchor point to build out the solution. But before we discuss how that exactly works out, let us do a little bit of housekeeping first, just to make our lives simpler further down the road.\n(Refer Slide Time: 07:30)\n \n \nI am going to assume that there is always an optimal solution that has an odd number of elements. This just makes it easier to talk about everything that we are going to talk about. Why is this true? Let me just trying to give you some intuition for why we can assume this without loss of generality. Suppose somebody gives you an optimal solution that has an even number of elements. Notice that in this solution the skewness must be non-negative.\nWhy is that? Well, it is an optimal solution. It must have a skewness that is, at least, the skewness of any other set. But on the other hand, also notice that you have the singleton sets available to you. So, a singleton set has 0 skewness because the mean and the median are both equal to just the only element that is there in the set.\nBecause of this you already have a baseline. You know that there are sets with 0 skewness. The optimal solution will never have negative skewness. Because if nothing else, it could just use a singleton set. So, we know that the optimal solution is non-negative. Therefore, the skewness of this set that your friend has given you, let us say, which has an even number of elements, we know that the skewness of this set must be non-negative. In particular, this means that the mean is at least the median in this set. Now with this assumption, what you can show is the following.\nLet us look at the middle two elements and eliminate the larger of these two. The set that you are left with, we claim that this set has a skewness, which is at least as much as the skewness that you had before. In other words, what this means is that the change that you experienced in the mean is, so let us say if you are looking at ‘the old mean - the new mean,’ at most the old median - the new median. That is essentially what it means to say that this skewness did not decrease.\nYou can show this by just writing down a bunch of relevant inequalities. Remember to start with the assumption that in the original array the mean was at least the median. Then use the fact that you have dropped the larger of the two middle elements to finally conclude that in this new array, the skewness has not gone down. It has either remained the same or it has only increased. Without the assumption that the array has non-negative skewness, this fact may not be true.\nYou can come up with examples to see that even after you drop the larger of the middle two elements, the skewness can in fact decrease. This little assumption that we are making is important to this claim. I will not be going through the calculations here but it is a good exercise to work through it. Please feel free to take a pause and do that now, or remember to come back to it later, depending on whatever you prefer to do. With this out of the way let us go back to the question: Why is the median a good anchor point?\n(Refer Slide Time: 10:43)\n\nLet me just give you an outline of what we plan to do. The first thing we are going to do is sort the input array. Because we can. This is going to take ‘n log n’ time. I was only half-joking when I said just because we can. There is a very good reason for sorting the array. It will help us systematize the way in which we build out a solution from a median. That is the next thing that we are going to do.\nFirst, we will guess the choice of the median. Just go over this entire array, trying each element out in turn as the choice for the median of a hypothetical optimal solution. Having fixed the choice of the median, let us also fix the size of the output array. We are going to guess how many elements there are in the optimal solution.\nThis guess is again going to cost us another linear expense. I mean the size of the optimal solution can be anything between one and ‘n.’ We are going to disregard the even numbers in this range. So, it is going to be, roughly, ‘n’ by two numbers that we are going to explore. But still, this is something that is going to show up as a nested ‘for’ loop.\nYou can probably already see why this algorithm is going to be order n2 in the worst case. We still will have more work to do even after we have fleshed out this particular algorithm. If you want to think ahead a bit, it is this step that we will replace with some sort of a binary search subroutine. But let us not get ahead of ourselves.\nLet us try to completely understand what is going on here. At this point, we have guessed the median. We have also guessed what is the number of elements in the optimal solution. We also know that the optimal solution contains this one element. We need to figure out the remaining 2k elements that go in there. We will have to, again, just look at the array to figure out what is the best choice for these remaining 2k elements. This is the part that we need to figure out a little more explicitly.\n(Refer Slide Time: 12:58)\n \nLet me switch to showing you, again, an abstract example here. Let us say this is our sorted input array. There is this one highlighted element. Let us say that is our guess for the median. Now I really want you to pause here and think about what is the best choice of an extra 2k elements on top of this one for the optimal solution. Let us say I told you that the optimal solution contains this particular highlighted element.\nWhat can you say about the remaining elements in the optimal solution? Of course, given that you also know that the optimal solution has 2k+1 elements altogether. That is also given to you. That is where we are when we are inside any particular snapshot of this nested ‘for’ loop. You have fixed the choice of the median. You have fixed how many elements you want to pick up.\nThe only thing remaining to do is to figure out which elements to pick up to have your best shot at maximizing the skewness. Think about this for a moment and come back when you are ready. Notice that since the median is fixed, maximizing the skewness essentially amounts to maximizing the mean. Because you know that you have to pick 2k elements. You also know that you have to maintain the fact that the highlighted element is the median.\nThat is the structure that we have sort of guessed for ourselves at this point. We know in particular that k of the elements that we choose must come from before the median element and the remaining k elements must come after the median element. Also, at this point maximizing the mean really amounts to maximizing the sum of the elements that you choose.\nYou want to pick as far as possible the largest elements that are available to you. So, it makes a lot of sense to pick the last k elements and also the k elements that show up just behind the median. It is not the first k elements because that would be suboptimal. Those would be the smallest k elements. You can do much better by just pushing your luck as much as possible.\nYou are constrained to be behind the median. You can just pick the largest 2k elements, for example, because then the highlighted element would no longer be the median. That is not going to work. In most cases, there will be choices of a highlighted element for which you do end up picking the last 2k elements.\nBut in general, what do you have to do is exactly what we just described. You choose the last k elements, and then you choose the k elements that show up just before the median. That is the greedy strategy for augmenting the solution starting from the median.\n(Refer Slide Time: 15:54)\n\nHopefully, you can see why the median was a useful anchor for the initial guess. Let us come to the bit that we were hinting at earlier. We see that this is kind of the bottleneck step in the running time of our algorithm, which is taking a hit because of this. We will now want to think about how we can substitute this guess of the solution size with some sort of a binary search. In particular, we want to not try all possible choices of k. But we want to do some sort of binary search for the right value of k.\nUnlike in the previous problem, where one of the big challenges was to even find the range of the search space, we do not have that issue here. We know that ‘k’ ranges between, say, 0 and n/2. We can go and poke this range right in the middle. No problem! But now what is not clear is what question should we ask.\nHow do we figure out how to cut out the search space to the left or to the right or in some other way? To try and understand what the behavior of ‘k’ is like with respect to skewness, let us just try to go through the slow algorithm, again in an abstract setting, just to get a feel for what is going on with the skewness as we add more and more elements to the array. See if we can pick up some hints from this behavior.\n(Refer Slide Time: 17:24)\n \n \nHere is our abstract array. At this point, we have ventured out from the median. We have added just one element. Let us say that this choice of an array of three elements is better than the previous choice, which was just the singleton element with the guessed median element alone. That one had 0 skewness.\nLet us say that by adding these two elements, we have either 0 skewness again or hopefully, we have even an improved skewness from before. We continue and try to add one more element. Let us say the skewness continues to improve. We add one more element and let us say the skewness continues to improve. One thing that is worth noting about these elements is that the elements that we are adding themselves are getting smaller as we go along.\nThis is because of the fact that we are working with a sorted array. The first element that we added was the largest possible pair of elements that we could have added. Then in the second step, we add elements that are at most the ones that we added in the previous steps, and so on and so forth. That is something that is useful to keep in mind.\nWhat we want to understand is: How does the skewness evolve as we add more and more elements? Notice that this is the same as asking, how does the mean evolve as we add more and more elements? Because the median is fixed the way in which we are building this array out. The median always stays the same. It is enough to just focus on the behavior of the mean.\nHow does the mean change as we add more and more elements? Let us consider a particular snapshot and say that the current array that you have built out has a sum of S. Let us say it has ‘d’ elements where d is going to be ‘2k+1’ for some choice of k. So, the current mean is S/d. Let us say we add the elements ‘a’ and ‘b.’ So, the new mean is going to be (S+a+b)/(d+2) because our array has also grown by two elements.\nWhat we want to understand here is the relationship between the current mean and the new mean. When does it happen that the new mean is less than the current mean? When does it happen that it is the same or it increases and things like that? Notice that if you could show something like the mean always increases or stays the same, then that is wonderful. Because then you do not have to search for, any ‘k’ at all. You can just pick everything and, you would be in business. You can pick as much as you can so that you have an equal number of elements on both sides.\nBut if it was true that the mean always, you know, increases or stays the same. Then there would be no reason to stop except for when, you know, you have run out of elements on one of the sides of the array. So, you could just keep picking. And in particular, you would not need to run an internal ‘for’ loop at all. You would just fixate, you know, on what is the largest k that you can accommodate. And that would have been your answer.\nBut that seems too good to be true. That is indeed the case, which you can verify by just working through a few small examples. The mean does not have a consistently non-decreasing or non-increasing behavior. Once again, this is something that can be verified by just playing around with small examples. On the other hand, what is it that we can hope to show? Whenever you have a binary search, in a broad context, usually some sort of bitonic behavior is very useful to have.\nIf the value kind of keeps increasing for some time and potentially hits a peak and then decreases or remains non-increasing, then that is a useful kind of behavior. Because then we can still find our way around using a binary search spirited technique, which is to say that we keep probing the range and we try and figure out the slope of the change. If it is headed downwards, then we move to the left. If it is headed upwards, then we move to the right.\nWhat we are looking for is of course the peak. We want the place where the mean is as large as it can possibly be. This is something that one would typically anticipate once you are practiced in binary search, and you try to show something like this. Do not be surprised by the fact that we are expecting this behavior. It is just something that shows up quite often. Now that you know it as well, you will know to try and look for this as you encounter new problems as well. Let us try to see if we do experience bitonic behavior here by taking a closer look at what is going on.\n(Refer Slide Time: 22:10)\n \nLet us try to figure this out by comparing the value of the current mean with the average of the two numbers that we are trying to add. The reason we are looking at these two quantities specifically is because we want to anticipate applying the mediant inequality. This is something that you may have seen in school. It is an inequality that relates two fractions in terms of the sum of their numerators and denominators.\nApplying this inequality, this is what we get. But notice that the expression that you have in the middle is precisely the new median. The median that you obtained by adding these two elements to your set. We see that if the average of the two values that you are bringing in exceeds the current mean, then the new mean will also be larger than the previous mean.\nOtherwise, you have the opposite behavior by just applying this inequality in the other direction. If the mean of the currently added elements ‘a’ and ‘b,’ does not exceed the mean of the old set, then the mean of the new set will not be bigger than the mean of the old set. What we want to say is that, okay, we know this. We also want to claim that the mean will increase up to a point potentially, but once it has reached a stage where it is peaked or it is going down, then it will never strictly increase once again.\nThat is the kind of bitonic behavior that we were referring to. The intuition for this is simply that the elements that we are adding just keep getting smaller and smaller. If not strictly smaller, remember, we have arrays with repetitions, at least the elements we are adding are no larger than we had before. This, again, is strangely similar to the overall spirit of the argument that we were trying to make with the ship if you remember from the previous problem.\nThere we were saying that if in the first step, you have kind of lost sight of the safe zone, then you are never coming back. Here also if there is some stage at which the mean fails to increase for the first time, then from there it is all literally downhill. It is never going to come back up.\n(Refer Slide Time: 24:26)\n \nLet us recap what we just said with a visual. We are, again, looking at how the mean evolves as we add more and more elements. Our starting point is just the singleton set with the guest median element alone. Let us say that when we add the first pair of elements, the mean increases a little bit. When we add the next pair of elements, it increases again. Again, it is a good exercise to think about the magnitudes of these increases.\nIs it possible that when you add the second pair of elements the mean increases more sharply compared to when you just added the first pair? Keep in mind that these pairs of elements that you are adding right now are diminishing or the same when compared to the pairs of elements that were added just in the previous step. This is a good exercise to go through. But let us continue our journey here in the meantime. Let us say we add another pair of elements, and the mean goes up again.\nBut at some point, perhaps, you will encounter a first incident where you added a pair of elements and the mean either stayed the same, or it did not increase, which is to say that it strictly went down. The claim that we wanted to make was that once this happens, then there is no hope for the mean to increase ever again. That is why this first point where the behavior flips, that is the global maxima for the mean.\nThat is the thing that you are looking for. That is exactly the bitonic behavior that we were talking about. Let us see why we expect this to be true. Let us say that we kept adding elements for some time and we experience a non-increase of the mean for the first time when we add the elements ‘a’ and ‘b.’ This was the last step that was depicted in the visual in the previous slide. Let us think of this as some sort of a critical event.\nThis is the first time that the mean did not increase. Let us say that in this step, right after this, we are adding the elements ‘p’ and ‘q.’ Again, by the structure of the array, we do know that p+q is at most a+b. I am just going to conveniently write that in terms of averages because that is what will be useful. What we know because of the fact that a, b we are witnessing the critical event is the fact that the average of ‘a’ and ‘b’ is at most the previous mean. So, let us say S was the mean at the step when ‘a’ and ‘b’ were about to be added. We know that the average of a, b is at most the mean in their stage. That is why when you added them, the mean decreased. From here, let us apply the mediant inequality to see that the average of ‘a’ and ‘b’ is also the average of the mean of the array that was obtained after adding in the elements a, b. Remember, S is the sum of the array that a, b were about to get into. It was the previous array in some sense.\nAfter adding a, b we have a new array whose sum is, ‘S+a+b.’ Because of the mediant inequality, we know that the average of a, b is also at most the new mean that you obtained. It is not only at most the previous mean, it is also at most the new mean. Now the important thing is that we can now combine these two inequalities, the fact that p+q is at most a+b, and the fact that the mean of a, b is at most the mean of the current array, to see that p+q is at most the mean of the current array.\nNow this array, whose sum is S+a+b is the array that p+q are trying to enter. The average of p and q is at most the mean of this array. That is what we have from this chain of inequalities. You can repeat this idea for the next step and the step after that. If you want to be formal about it, you could use the language of induction to make this precise.\nThe base case is pretty much what we just discussed. You can formalize what goes on from the ith step to the i+1th step to argue that once you are on a downward journey, it just keeps spiral wing downward, or at least it stays put. But there is no hope of the mean increasing ever again.\n(Refer Slide Time: 28:57)\n \n\nOverall, your evolution of the mean looks something like this. There is a place where it attains a maximum. It is possibly going to peak for some time. But the point is that once it has reached that maximum, it never increases after that. Let us try and see how the binary search would work. Let us say that we probe this range of values for ‘k’ somewhere in the middle. We say that we want to add ‘n’ by 4 elements to the array.\nRemember, ‘k’ ranges from 0 to n/2. Let us begin by trying to add ‘n’ by 4 elements to our median element. Once we have made this initial choice of guess for ‘k,’ what we want to do is try and identify which side of this slope are we on? Are we on the uphill trajectory? Or are we on the downhill trajectory? Well, this is easy to identify by just comparing the current choice of k with the next choice of k.\nWhat we will do is we will say, okay, instead of trying to pick k elements, suppose we were to try and pick the ‘k+1’ element. Let us try to pick one more. Of course, that has to be feasible first of all. If you are on an edge case, you have to just stop because you cannot go any further. But assuming you are not on an edge case, you just compare what is going on. You want to know if the mean improves, by enhancing the size of your set by one.\nIf the mean does improve, then that is a sign that you are on this uphill slope. If the mean does not improve, then it is a sign that you are on the other side. That will allow you to figure out which side of the search you should pursue further. That is kind of the overall description of our algorithm. Basically, you want to begin by sorting the array and guessing the choice of the median, and from here, you want to do a binary search for the size of the array that you want to build.\nOnce the binary search has informed you about the size of the optimal set, given that a specific element is a median, you want to keep track of the best answer that you obtained for this choice of the median. In the end, you just return the best answer that you found overall.\nThe running time of this algorithm will be order ‘n log n’ because you have the sorting step at the beginning that is order ‘n log n.’ Then you have the outer loop, which is going to run at most ‘n’ times for the guess of the median. Then what do you do inside is essentially this binary search.\nThe overall expense of these nested loops is going to be ‘n log n.’ Hopefully, this overall approach sort of made sense. This is a new style of binary searching in the sense that you are not probing and immediately getting a yes-no answer. You are trying to detect some sort of slope behavior for a particular value that evolves in a bitonic fashion.\nHopefully, this sort of overall form of a situation in which you can apply binary search is useful for you to keep in mind. I do know that this is widely applicable. I hope that you are able to leverage this as well. Now that the main ideas of the algorithm are somewhat in place, let us turn to the implementation.\nAs always, this is a good time to pause, if you want to try this yourself. One thing to watch out for in this particular implementation is that there are lots of little edge cases to worry about. Be very careful with your indices because there will be a lot of those floating around. In particular, one edge case that is important to be careful about is the range of the values of k.\nRemember that you are working with some guess have a median that is going to be someplace in the array. Just make sure that your range of values for ‘k’ is a valid range, in the sense that it should never be more than the number of remaining elements that are available on either side of the median. That is the sort of thing that you have to just be a little bit watchful about.\nThe other little tip for efficiency is to compute an array of prefix sums for the input array. This will help you do your mean calculations quickly. Remember that whenever you are probing in the binary search, you are asking questions like does the mean increase after we include these two elements, or does it not increase?\nFor this, you do need to compute the mean several times. This just becomes faster if you have access to an array of prefix sums because it is just a matter of getting to the sum of the relevant sub-array. Remember that you are always looking at contiguous chunks in the sorted array. That is a really helpful thing to have for fast computation of means.\nI have not tried if not using a prefix array will cause a timeout or not, but it definitely does not hurt and it is just good practice to have. With all that said, I think this is your last chance to pause the video. My final spoiler alert! We will be coding in C++ for this one, and I may be skipping some variable initializations in this presentation here. You can find the full code on the official GitHub repository.\nIf you do have Python or Java variants that you would like to contribute, then please do create a pull request on that repository with the appropriate documentation. Remember to attribute yourself. Now let us actually get started here.\n(Refer Slide Time: 35:09)\n\nThe first thing is reading the input in. I have used long data types here. I cannot be sure that that is absolutely necessary. But I think I just wanted to be on the safe side. The only important thing that is happening on the code that you can see is the fact that we are sorting the array. Do not forget to do this in the beginning. It is crucial to the logic of the rest of the program that we are working with a sorted array, to begin with. Other than that, all the input business is fairly standard. There is nothing special going on here.\n(Refer Slide Time: 35:45)\n\nThis is the place where we just compute the partial sums vector. This is just maintaining cumulative sums as we go along. The way we calculate the partial sums for the first ‘i’ elements is that we just refer to the partial sums that we have already calculated for the first time ‘i-1’ elements, and then we add the value of the current element to it.\nThat is all that is happening here. These cumulative sums, as we were saying earlier, will come in handy when we want to do mean calculations while we are in the middle of the binary search. We will have a separate helper function called ‘find mean’ or something like that. I will come to that at the very end because I just want to focus on the main logic of the code first. Let us get to that.\n(Refer Slide Time: 36:36)\n\nThis is the outer ‘for’ loop where we guess the value of the median. Now one important thing to keep in mind is that ‘guess’ is simply guessing the index of the median element. The variable guess does not store the median element itself.\nYou will need to, at some point, actually refer to the median element that you are guessing when you come to the stage where you have to print the output. It is definitely important to remember that you need to print ‘b’ of guess if you want to print the median element, for instance, and not guess. That will be messed up.\nIn general, I think this is just one category of small and annoying bugs where you mix up the index and the element at that index. This is just a heads up to be careful about that. Now, let us first calculate the range in which we want to do our binary search for this particular choice of guess.\nAs we were saying earlier, you have to be careful about ensuring that you have enough of a supply of elements on the left and right for a particular ‘k’.\nFor instance, if you have an array of length 100. Let us say there are 100 elements, and your median is the fifth element in the array. Then notice that you cannot add more than four elements, rather eight total, but you can only add four from the left. You can, of course, add four from the right when there are lots of elements available.\nBut then there are just going to be four steps in the range for ‘k’ that you are going to try out. Just make sure that you get your indices sorted out here. Because we are doing 0 based indexing, if the current median is at the guess index, there are ‘guess many’ elements available before it. For instance, I was just saying that suppose your median is the fifth element, then well, that is indexed by 4 because of 0 based indexing.\nTherefore, we know that we have four elements behind the median. You can similarly calculate the number of elements that are there after the median.\nAgain, for things like this, just to avoid like silly bugs, at some point, with practice, these kinds of calculations will become quite natural, but it is just helpful to do a really small and silly example on pen and paper just to make sure that you sanity check your indices, and you have them right.\nI think this is tried and tested code. I am just going to believe that there are no mistakes here. Hopefully, this is the right range for ‘k.’ We are obviously going to take the min of the two options because it is the smaller sub-array, the smaller side, that is going to be the bottleneck. That is our range.\nHere are some simple initializations for the binary search business. The lower limit for the range is 0, as we have discussed before, and the upper limit is what we have just calculated. That is L and R for you. The midpoint is ‘L+R/2.’ Now we have set the stage for the actual binary search.\n(Refer Slide Time: 39:50)\n\nThis is the heart of the entire algorithm more or less. I mean, there are, of course, a few more details after this as well. But this is really the main thing. As long as we still have some range left where we are not sure, so that is given to you by this ‘while’ condition, R-L is greater than 0, so our left and right endpoints have not conclusively coincided at someplace, we need to continue searching. That is the standard ‘while’ condition for binary searching. Hopefully, that is clear and not confusing.\nNow, what is the current guess of ‘k’ that we are working with? So, remember, by k, I mean, my guess for how many more elements should I have on top of the median in my optimal array. The current guess for k is mid. We are just starting, so, we have come in after the initialization. The current value of mid = ‘L+R/2,’ but in general, also, as we go on, it is going to be a loop invariant that mid is our current point of probing. We are asking ourselves: Is mid a good value of ‘k’ to work with?\nWhere does mid lie on that sort of bitonic picture? Are we on the strictly increasing slope part of it? Or have we come to the part where it is going downhill or it is experiencing a plateau? We know that if things are going downhill, or if it is a plateau, then we need to shift our choice of mid towards the left because we have, in some sense, come too far.\nOn the other hand, if we are at the place where things are looking up, we are in the increasing slope part of the picture, then we need to increase our value of mid, and we need to discard the left half of the search space. How do we check which side we are on? What we said was that we will try to compare the current mean with the mean that we would get by trying to add two more elements to the array.\nThat is what we are going to do here. We are going to tentatively increase ‘k’ to ‘k+1,’ or we are going to probe mid+1 as a possible choice for ‘k.’ We are going to ask ourselves: How did the mean change? Did it increase? Or did it not increase? Now when I am saying increase, I mean a strict increase.\nThis is something just to be careful about, like when you write down your condition for how the search space is going to get pruned. Remember to just make sure that you know when to use a strict inequality and when to use less than or equal to or greater than or equal to, and so on. Let us just do this probe. We are saying our tentative value of k is ‘mid+1.’\nLet us see what are the next elements that we want to pick. Notice that these will be available to us because we are working with an appropriate range of ‘k.’ These will be valid elements to talk about.\nNotice that ‘a’ is the value coming in from the top. It is basically the kth largest element in the array, and ‘b’ is the value that is coming from the left half of the array. So, we are going ‘k’ steps behind the current guess, to incorporate these new elements. This is ‘a’ and ‘b,’ the new elements that are trying to join the array.\nNow, let us recall the criteria that we had evolved to figure out whether we are on the uphill side of the graph that depicted how the mean is changing, or whether we are on the downhill or the plateau side of things. What we had said is that if the mean of the incoming elements dominates the current mean, meaning that it is strictly more than the current mean, then the mean will increase, otherwise, it does not increase.\nThat is exactly the binary search criteria that we have put in here. We have taken the current mean, which by the way, we have computed by function call to this helper function. As I said, we will come back to that later because I do not want to be distracted with those logistics right now. Just assume that we can compute the current mean efficiently.\nWhat we want to do is compare the value of a+b/2 with the current mean. So, if a+b/2 is at most the current mean, then your mean is not going to increase. It is still possible that the value of ‘k,’ which was the current mid, that is the best possible value of ‘k.’ Because this could very well be the inflection point. Maybe a, b is the first time that the mean does not increase.\nThe current value of ‘mid’ may well be the answer that you are looking for. Or it is something smaller. Maybe you are still in the middle of the boring zone of the graph, and you need to roll back further. You do this by essentially bringing R up to mid because it is either mid or less (the answer that you are looking for). I think we are saying that R is ‘max of mid, L.’ Normally you know that ‘max of mid, L’ should always be mid. I mean mid would always be ahead of L.\nI think I have done that just to maintain symmetry with what I have written in the ‘else’ condition. Let me just come to that in a minute. But you could pretty much say R = mid and that should be fine out here. What is going on in the ‘else’ block? Here we are saying that look, the current mean actually increased after we added the elements ‘a’ and ‘b.’\nThis is looking good. We are going uphill, we are strictly getting better. We know that all values of k up to an including mid are useless for us.\nWe know that ‘k’ is going to be at least mid+1 or more because we have already sensed a straight improvement. We are going to be greedy.\nWe are going to reduce our range to ‘mid+1, R’ to say that continue your search on that side of the space. In this case, doing this min of mid+1, R is just necessary to take care of some edge cases, I think, because of the way mid works. I think it is by truncation when L+R is odd, so it is possible that when you add 1, then you actually go overboard, you go beyond R. So this is just a bit of a sanity check condition that is been thrown in here.\nI think I am pretty sure that I had arrived at this by looking at some small values and experimenting with what was going on. Because without putting in the sanity checks, I think there were definitely some edge cases that were not working out. Again, feel free to not, like, copy this over verbatim but just work with your own sort of version and see what you discover in terms of the right limits that you want to impose.\nBut hopefully, it is clear why we are able to disregard the entire search space from L all the way up to mid inclusive and we want to go to mid+1. That is the binary search that we wanted to do. I think you might be wondering if this offset of +1 is really important.\nI do not think I have tried it without that, but I think it should work out the same. Again, if you try variations of this, and they work out just as well, then, please feel free to share those. I would definitely look forward to it. But in the meantime, I think we can move on from here.\n(Refer Slide Time: 48:01)\n\nNow that the main work is done, the heavy lifting of the binary searching and finding the right value of ‘k.’ Notice that when we are out of this ‘while’ loop, we have found the best possible value of ‘k.’ Now what we want to do is find the mean with respect to this choice of ‘k.’ What this ‘find mean’ helper function will do is it will take the value of the current median, the location of the current median, and the value of how many extra elements you want to incorporate.\nThen it will return the mean of that sub-array for you. Calculate the mean and then see if this improves on the best mean that you have discovered so far. You have an answer variable. Again, this is a variable whose initialization I have skipped. You can look up the full code in the repository just to fill in the small details. But essentially, the answer is designed to store the best answer that we have encountered so far. You can always initialize the answer to 0 because as we have discussed, there is always a solution whose skewness is 0.\nThat is the initial bar. Every time we can improve on the current best answer that we have discovered, we would want to update some of these variables. If the current skewness is better than whatever skewness we have stored in the answer variable, then we need to make some updates. Notice that here to compute the skewness, you should do ‘mean - v of guess,’ not ‘mean - guess.’\nSo, ‘guess’ is not the median. It is just the index of the median element. If you want to subtract the value of the median so that is ‘v of guess.’ If you do hit a jackpot, and things got better from all the previous guessing that you have done. I do not know if guessing is a word, but all the previous guesses that you have taken, then let us just update the scene here. Of course, answer gets updated with the new value of skewness. We are also keeping track of the best guess that we had so far and the length of the array.\n(Refer Slide Time: 50:18)\n\nRemember, these are the two things that we need to actually compute the array that witnesses this particular skewness. The reason we are tracking this is that as a part of the output, we are actually required to print an array, which has the best skewness. Again, this is a little bit of like boring logistics. Nothing remarkable going on here. But you just have to make sure that you carefully print all the elements of the subset.\nFortunately, you have on hand the value of the best choice of median and the best choice of size of the subset. It is just a matter of navigating the array properly and printing out all of those elements. If you go further back in this video and remember, there was a place where we showed you how to pick these k elements. Those are the top k elements and the k elements that come right before the choice of the median. That is the combination that you are looking at. That is exactly what this code here is doing. I will not go through it line by line. But I hope that it is kind of self-evident.\nHere is the ‘find mean’ helper function that is the only thing that remains to be discussed. As I said, the ‘find mean’ helper function will take the choice of the location of the current median that you are working with, the value of ‘k,’ and will also have access to the partial sums vector. Here all we are doing is, essentially, if there is only one element in the whole array, which is signified by the fact that ‘k’ is 0. You do not want to add anything, then you just return that element; there is nothing to be done.\nOtherwise, in the more interesting case, you want to compute the sum of the whole array. What we are doing is, essentially, these two expressions here are computing the sums of these two chunks that we have identified. The first chunk is essentially the top ‘k’ elements. You can see that the second term in the expression computes that. So ‘pv of N’ is the partial sum of the whole array, which is essentially the sum of the whole array.\nFrom there you are subtracting the partial sums up to the N-kth element. With the appropriate indexing, you do have to pay attention to the indices here. But it turns out that it will just subtract off the partial sum up to the point where you only have ‘k’ elements left after that. All of that excess baggage goes away. What you are left with is the sum of the last ‘k’ elements. Very similarly, the first expression will calculate the sum of the ‘k’ elements that are just behind the median, and up to the median.\nIt will also include the median element in its calculation. The sum of these two terms gives you the overall sum of the array, whose mean you are trying to find. You return this divided by ‘2k+1’ because 2k+1 is the size of the array that you are working with. Hopefully, this helper function is clear as well. That is essentially the entire code. Just try to keep things clean when you are doing your own version of this because, as I said, the indices can sometimes definitely be a bit confusing.\nOther than that, I think conceptually, once you get the hang of it, what is going on is really nice. Hopefully, also not that hard. I mean, I am not sure if you are somebody who is sort of scared of doing binary searching. I hope that after this, you feel more confident about it, and you feel ready to tackle problems that are based on binary search.\nWith that, we come to the end of all of the problems that we wanted to do this week. I hope you enjoyed it as much as we enjoyed putting this together. Next week, we are going to be talking about greedy algorithms. That is going to be a whole lot of fun as well and a completely new theme. In the meantime, if you had any questions about these lectures, then you can post them in the comments on YouTube.\nOr you can post your questions in the Discord community or add the official mailing list for the course on Google Groups. Any of these methods should work. One of us will get back to you hopefully quickly. In the meantime, have fun coding, and we will see you next week. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W10/Lec51.html",
    "href": "materials/cpnotes/W10/Lec51.html",
    "title": "Memoization | Frogs 1 (AtCoder Educational DP Contest)",
    "section": "",
    "text": "Lecture - 51\nMemoization | Frogs 1 (AtCoder Educational DP Contest)\n(Refer Slide Time: 02:55)\n\nHello and welcome to the first module in the 10th week of Getting Started with Competitive Programming. With the 10th week, we are starting a new theme in the course and this is going to be Dynamic Programming. It is a theme that we will continue to explore all the way till the end of the course, which is to say up to week 12.\nAs you probably know already, dynamic programming is a ubiquitous technique that is extremely popular in competitive programming. Almost every contest has at least one problem that involves dynamic programming, either exclusively or in conjunction with other techniques. So, we are going to take our time and go over several examples with different flavors.\nIn this introductory module, I will try to explain the main ideas involved in dynamic programming and we will look at what is usually referred to as the top-down approach or memoization. In the second module this week, we will look at the so-called bottom-up or tables-based approach to dynamic programming. Once you are done watching both of these modules, you should be well prepared to solve basic dynamic programming-based problems. And the good thing is that there are tons of examples out there for practice.\nIn fact, the two problems that we will use as examples are from two problem sets that are really nice to start with. So, the first one is from an AtCoder Educational Contest on Dynamic Programming. It had 26 problems, coded a, b, c through z, one for each letter of the alphabet, and I think, sorted roughly in increasing order of difficulty.\nThere is a lot of material around this problem set; you can find, I think, blogs on Code Forces that try to explain some of these problems. But at least the initial ones are quite doable, based on what you will see in these lectures. So, I would definitely recommend that you try going out there and solving some of them on your own, even without having to look at the editorials.\nIn the next module, we will tackle a problem from the CSES dynamic programming problem set. That is a slightly smaller collection of 19 problems, again progressing in increasing order of difficulty. But once you are done with this, you should definitely be able to tackle the first few problems in that problem set. Again, it is very easy to set up an account on CSES. If you have not already done that before, for some of our previous problems, I think this would be a good time to do it. And try to roll up your sleeves and get some practice with dynamic programming, at least the elementary problems.\nSo, with all that said, let us get started with our first problem for this week. And this one is called Frogs. It is called Frogs 1 actually, I think, because there are three problems with the same premise, the same setup, but slightly different questions, in terms of, what is going on. So, there are Frogs 2 and Frogs 3 at different parts of the problem set, so you might want to go and check that out after you are done with this.\nBut for now, let me tell you about Frogs 1. As usual, we are going to start with a problem statement. This time I will interweave an example as we go through the problem statement itself. And I encourage you to think about, how this example works out, as you go through the problem with me.\n(Refer Slide Time: 03:30)\n \nSo, to begin with, there are N stones, numbered 1 to N, and for each ‘i,’ from 1 to N, we are given the height of stone number i. So, I am going to visualize this, literally with comical-looking stones here. And the numbers that you see at the bottom of your screen are actually the heights of these stone piles. The pictures are not necessarily to scale. And these numbers are taken from the last sample input. Okay. So, we have N stones, left to right, think of them as stones 1, 2, 3, all the way up to N. In this case, as you can see, N is 6. And this will be a running example as we go along.\nNow, there is a frog who is initially on stone one. So, introducing the frog. I should have probably picked up a side profile because the frog is going to jump around. So, this is not very realistic. But that is okay. I think it is nice to be able to see the smiling face of the frog as we try to solve this problem. So, that was the rationale.\nNow, our friend, the frog, will repeat the following action, some number of times, to reach stone N. Remember, he starts from 1 and he is trying to get to the last stone in the series. The first thing that he can do, is that, if he is on stone number ‘i’ currently, he can jump to either stone number ‘i’ + 1 or stone number i + 2. So, let us look at the frog in action.\nSo, right now, the frog is in stone number 1, and from here, he could go to stone number 2, or he could go to stone number 3. Okay. So, both of these stones are accessible to the frog, sitting at stone number 1. But he cannot go in one step. He cannot go to say stone number 4 or any of the later ones. The only way to get there would be via an intermediate jump first. Okay. So, whenever the frog does jump between two stones, he incurs a cost, and the cost is proportional to the difference between the heights of those stones. And we are looking at the absolute difference here. Okay. So, let us again take a look at a couple of jumps and see how that works.\nSo, here, for instance, the frog is on the third stone and he jumps to the fifth one. And notice that the fifth stone and the third stone have the same height. So, this was smooth sailing – apparently, no jumping involved! So, a cost of 0 was incurred in this particular jump. On the other hand, compare this with a jump from stone number 3 to stone number 4. That is a more steep sort of exercise, and the difference between the heights of these 2 stones is 60-10, 50. The absolute difference is 50. And the cost, therefore, is also 50. So, now that we understand how the individual jumps work in terms of their costs. It is time to take a look at, what our task is going to be.\n(Refer Slide Time: 06:22)\n\nIt is actually quite predictable, you might have guessed that what we want to figure out is, what is the best way of jumping around that takes the frog from stone 1 to stone N? And by the best way, we simply mean the way that involves the least cost. And the least total cost, in particular, is going to simply be the costs of all of these individual jumps added up.\nSo, you want the cheapest route from 1 to N, except this is not to be confused with say shortest paths and graphs. There is not really a graph structure underlying this problem here. At least not a very natural one. We just want to figure out, what is the best sequence of jumps that lands the frog at stone number N.\nSo, now that is the entire problem statement and I would say that this is a good place to pause and think about, how you would come up with a solution to this problem. Now, if you are already quite familiar with dynamic programming or recursion as a technique, then you might find the solution pretty easily. It is reasonably predictable.\nOn the other hand, if you are not so familiar with these techniques, then you might treat this as a good warm-up exercise. And finally, if you have never seen dynamic programming, explicitly before, and you are not all that familiar with using recursion, then you might want to think about, what would be a way to solve this problem that does not really involve the use of any of these techniques, but perhaps uses other techniques that you know.\nFor example, would a greedy strategy work? A natural greedy strategy may be to just take the better of the two jumps that are ahead of you. So, wherever you are, there are two possibilities, one of them is going to be cheaper and if not, then you could just break ties arbitrarily. That is a complete algorithm on its own. You could think about whether that would actually work.\nYou could think about what would happen if you tried to come up with a Brute-Force Solution. So, let us say you explored both pathways, and for each of those pathways, you explored both of the options that would await you. If you took either of them and so on and so forth. And what would be the sort of the expense of computing a solution in this way and so on? So, I think there is enough food for thought here for everybody, no matter where you are on the spectrum of pre-existing familiarity with DP or recursion.\nSo, give it a thought and come back once you have done that. Alright. So, it turns out that if you followed a greedy approach, then that would actually not work, and I would encourage you to come up with explicit examples demonstrating that it would not work. On the other hand, if you try to Brute-Force a solution by, say, enumerating all possible sequences that the frog could take then you will find that just the sheer number of sequences that you have to consider is exponential or it at least turns out to be exponential. And for this problem that is not going to be feasible, because if you look at the constraints, N can be as large as 10 to (the) 5. So, that is simply not going to work.\nNow, having said that do not completely trash the Brute-Force approach just yet. Do keep it at the back of your mind for comparison with what we are about to do. In fact, you might find that what we actually end up doing looks suspiciously like a Brute-Force approach. And hopefully, with that, you will be able to appreciate why what we do actually ends up improving on the Brute-Force approach, by somehow coming up with a way to cleverly cut through, what is otherwise a very very large search space. Okay. So, let us think about how we can manage this really large set of possibilities that we actually have to consider which are all possible valid sequences of jumps, from stone number 1 all the way to stone number N.\n(Refer Slide Time: 10:15 and 11:12)\n \nSo, we do know that when the frog is done jumping around at the very end, he ends up at the last stone. So, one thing that we are going to do is, really try to see, if we can play this process back in reverse that is something that is going to be a part of the way we think about this. So, instead of thinking about, what is the next jump from stone number 1, we are going to say, suppose, there is an optimal sequence, of course, there is some optimal sequence, it is well defined.\nIn that optimal sequence and if there are multiple optimal sequences, you could just fix any one of them, it can be arbitrary as long as it is fixed. And in that optimal sequence, you want to ask yourself, well, how did the frog get to the N’th stone in this particular sequence? What was the penultimate step? And then we will try to take it from there. That will help us come up with an appropriate recursive formulation.\nSo, in particular, let us just write down all the possible sequences that are valid. So, they are not all in here. So, this is just sort of a partial list, because of lack of space and also as I was saying earlier, this does look like, we are considering the whole space of valid sequences. So, this might remind you of the Brute-Force approach that we were talking about earlier.\nBut do not worry about it so much, I want to show you this just to talk about how you come up with the idea for a recursive algorithm. We would not actually be going through this list when we come up with the algorithm. So, this is more for just getting used to what is going on. So, hypothetically, this is the space of all possible solutions, and I want to make a couple of observations about this collection of sequences.\n(Refer Slide Time: 12:11)\n \nThe first observation, which was implicit and what we just said earlier, is that all of these sequences end at 6 in our example, and more generally, they would always end at N. That is just a feature of every solution by definition. All of these sequences end at the last stone. What can we say about the second last element of these sequences? Ignore pathological cases like when N = 1. In fact, I think, it is promised in the problem constraints that N is at least 2.\nSo, you do not have to worry about the case when N = 1. It is ok for me to talk about the second last element in any of these solution sequences. Is there something that you notice about the second last element? Especially given the rules of the game. Remember that when jumping ahead, a frog can only jump to the next stone or the next-to-next stone. So, when he lands at stone number N, where could he have come from?\n(Refer Slide Time: 13:16, 13:37 and 13:52)\n \n\nYou just need to turn this around a bit to realize that the second last element is always going to be either N-1 or N-2. Okay. So, in the optimal sequence, we do not know which one of these two it is. That is the million-dollar question. If we knew how to figure that out, then we could just work our way backwards all the way up to stone number 1. So, it could be either of these, but it is always one of these.\nSo, if you look at the second last element in these sequences, then it is always 5 or 4 in the context of our example. So, what I am going to do now is basically partition this space of valid solutions into two buckets. The first bucket consists of all the sequences that have 4 as the penultimate number. And the second bucket has all those sequences that have 5 as the penultimate number. Okay. So, more generally, you want to divide up your search space into 2 collections. In the first collection, you look at all those sequences where the last hop happened from stone number N-2. So, it was a skip over stone number N-1 to get to the last stone.\nAnd in the other bucket, you collect all of those sequences, where the last hop was a direct hop from stone number N-1 to stone number N. Okay. So, why are we doing this? Well, recall that our task here is to figure out the sequence that has the best or the smallest cost. So, you can imagine that each of these sequences here is tagged with a cost, which is simply the sum of the costs of all the individual jumps that happen in the sequence that you are considering. Now, by breaking it up in this way, you might see that the cost of every sequence can be thought of as the cost of getting to either stone number 4 or 5, as the case may be, plus the cost of that last jump.\n(Refer Slide Time: 15:10 and 15:27)\n \nSo, in some sense, if we knew the best way of getting to stone number 4 and the best way of getting to stone number 5, then we could just tag along the costs of the last jumps to figure out the sequence that has the best overall cost.\nIn other words, let us say that we knew, somehow magically, that the cheapest way of arriving at stone number 4 has a cost of Y and the cheapest way of arriving at stone number 5 has a cost of X, then notice that the final answer really boils down to a comparison between, at least in this example, Y + 40 versus X + 10.\n(Refer Slide Time: 15:52)\n\nMore generally, it is going to be the cost of going from stone number N-1 to N, added to the best way of getting to stone number N-1 itself, versus the cost of going from stone number N-2 to N, added to the cost of the best way of getting to stone number N-2. Essentially, these are your two best options, and the final answer is going to be the better of these two. If there is a tie, then you can break it arbitrarily.\nYou can take a moment here to convince yourself of the correctness of the claim that we are making here, that this is indeed the answer. It really follows from the exhaustiveness of our approach. Consider any sequence that claims to be an optimal sequence. Look at the last step that is being made in that sequence. It is going to be either N-1 to N, or it is going to be N-2 to N.\nSo, that is a fixed cost that the sequence has to pay, and beyond that, well, your optimal sequence has to get this turn number N-1 or N-2, as the case may be. And on that front, it cannot really hope to beat the answer of N-1 or the answer of N-2 because these quantities, by definition, are the optimal costs for reaching stones N-1 or N-2, as the case may be. So, hopefully, this sequence of arguments convinces you that this setup that we have here does lead you to the right answer. So, this equation is what we want to compute.\nNow, notice that to compute A and B, we have really two components to worry about. The second term in the sum, which is the cost of going from N-1 to N or N-2 to N, is simply given to us in the input. So, we just pull out the heights of these stones and or take the difference. So, that is straightforward. Now, other than this, we also have the answer of N-1 and the answer of N-2 as terms that we need to compute. And that is something that we are going to compute by magic.\nWe are just going to ship this off to the recursion fairy, which essentially means that the way we will compute the answer of N-1 and the answer of N-2 is exactly the same as the way that we are currently trying to compute answer of N. So, when we want to compute the answer of N-1, we basically pretend that the whole universe, the whole instance that we are dealing with, is now restricted to stones 1 through N-1 only. And then we just solve that on its own. And when we are done, we come back to the current world, which is the world with N stones, and we piece everything together.\n(Refer Slide Time: 18:41)\n\nSo, if you were to translate this to code, it would look something like this. You want to write this inside a function so that it can call itself. And this is essentially the recurrence that we had on the previous slide a few moments ago. Now, if you stare at this for a while, you might realize that something is missing. If you were to actually write this program and implement it, which you are welcome to try, you might find that the program does not really stop. And the reason for that is that we have not really given it a stop signal.\nAnd notice that this is not because we have a bug in the code or something. We have implemented our idea exactly as we had written it down earlier. So, in fact, if you go back to the recurrence that we had and let us say, you try to execute it just on pen and paper, you will have the same experience. You will just keep going because the recurrence does not really tell you, where to stop.\nSo, let us say that you start off with trying to figure out the answer for the 6 tones that we had earlier, and you start by computing ‘A,’ that is going to be an answer of 6-1, 5. That is just the first thing that you need to worry about. So, let us say that you try to unravel that you will get to answer of 4 and then 3, 2, 1, 0 and then -1 and -2 and so on, which is super weird. So, in particular, notice that asking for the answer when N = -1 does not even make sense as a question.\nWhat do we mean by there are ‘-1’ stones? We do not even have the data for that kind of situation. So, that is a hint that that is a place that we should not go to. It is a dangerous place. And we do not want our algorithm to ever have to worry about this. So, when do we get into situations where we may start asking these questions that do not make sense? So, let us think about what happens when N = 1, for example.\nSo, if N = 1 and we try to apply this algorithm, then we will have to worry about the answer of 0 and the answer of -1. And in some sense, both of these questions do not really correspond to scenarios that exist in the context of our problem. We know that we are looking at, at least one stone to begin with for the frog to be on. So, these are unreal scenarios, and that is why we do not really want to get into them. So, N = 1 is something that we want to be able to address without getting into recursion. Similarly, for N = 2, you are thinking about the answer of 1, which is kind of.\nBut we also have again answer of 0, which corresponds to again imaginary world; it does not really correspond to a well-defined problem scenario. So, also, for N = 2, I want to avoid using the recursive method to compute the answer. So, if you are not going to use the recursive method, then how are we going to calculate the answers? Well, the answers can be calculated by hand for these scenarios. Because notice that when you just have 1 or 2 stones, then it is really easy to figure out what to do.\n(Refer Slide Time: 21:42 and 23:28)\n \nIn particular, if you have just one stone then there is nothing to be done. The first and the last stone are the same. So, there is no cost involved in getting from the beginning to the end. So, the answer, in this case, is 0. On the other hand, if you have two stones then there is really no choice; you only have one thing that you can do. So, the answer is going to be the difference between the heights of the first stone and the second stone, the absolute difference.\nSo, these are answers that we are going to compute in some sense by hand and this is what will cut off the recursion and will make sure that the overall algorithm actually terminates and returns a meaningful answer. Of course, you could compute, for instance, the answer of 3 by hand as well, or the answer of 4 by hand, by doing some cases. But the point is that you do not really need to. These are the minimal base cases that make your algorithm work.\nAnd although in some scenarios, it is useful to be clever about what kind of base cases you compute. For the most part, by and large, at least for elementary examples of dynamic programming, the base cases are usually very easy to figure out, but they are also very, very important. Okay.\nSo, just keep in mind that if you do not have a base case specified or you have it improperly specified, because, with some issue with indexing and things like that, this may be really a common source for bugs, certainly, if your program is timing out or it seems like it is taking forever, watch out for the base cases. And if your answers are off by just a little bit, just make sure that your indexing for the base cases has been done properly. Okay. So, let us go back and fix our code here.\nSo, this is the recursion with the base cases thrown in. And if you were to implement this and try it out, you will see that you do get the right answers. But you may find that it is still taking quite a bit of time. This is a really good place to pause and actually play around with this implementation. Try it with small and large examples on your computer and see how long it takes. If you feel like it, you could also try and upload this solution and see if you time out. Also, think about how would you analyze the running time of this algorithm? Right.\nSo, just what is your estimate for how long this takes? Think about all of this, and come back once you have had a chance to play around with this program a bit. All right. So, let me address the question of how long this program takes. The best way of analyzing a recursive program is through what is called a recursion tree.\n(Refer Slide Time: 24:28)\n\nSo, let us just try to visualize, what these function calls are doing, by examining what happens if you start off by invoking it for the case of 6 stones like we have in the running example that we started off with. So, when you invoke the algorithm to try and figure out the answer for 6 stones, it is going to make these 2 function calls to understand the universe of what happens with 5 stones and 4 stones, respectively.\nAnd, well, the first function call that gets executed is the one involving 5 stones. So, what is that going to do? Well, it is going to come back and try and understand what is going on for 4 stones and for 3, and once again, the first branch that gets executed is the one involving 4 stones.\nSo, that is going to degenerate further into 3 and 2, and for 3, you are again going to probe 2 and 1. And now there is going to be no further recursion because, as we have discussed earlier, 2 and 1 form the base cases, so you just go back up and report the answer to the computation for 3 stones. And similarly, 4 is done as well. And now we come back to 5, which on the right branch was also waiting for the answer for 3 stones.\nSo, that is once again going to probe 2 and 1. And now you walk your way back up to 5 and then 5 reports back to 6 and then 6 says okay. So, I understand what is going on when there are 5 stones. Now, let us go ahead and think about what happens when there are 4 stones, and that is going to lead to more recursive calls on 3 and 2. The call for 3 will again go further down and explore 2 and 1. And at this point, you are truly done. Because, well, at this point, all function calls have returned values, and you just have to do some computation to report the final answer at the very end.\nSo, what is the complexity of the algorithm? Well, it is proportional to all of these function calls that are happening here. The number of function calls that you see on your screen, and of course, there is a multiplier for the amount of work that you do at each function call. So, for instance, let us say you were at the node labeled 5, then you were, of course, waiting for the function calls to 4 and 3 to return values. And after that, you still have a little bit of extra computation to do. So, you have some differences in heights to compute, some addition, and taking a minimum.\nBut all of this is essentially constant time. So, the overall running time can really be thought of as being proportional to the size of this recursion tree. So, how many nodes are there in this recursion tree? So, given that the definition of this tree is really driven by a recursive function. It is natural that an expression that determines the number of nodes in this tree is also given recursively. So, if we were to use T of n to denote the number of nodes in the recursion tree for the algorithm when invoked with input n, then we get this expression for T of n.\n(Refer Slide Time: 27:36)\n \nThere is the root node itself, and then there are these 2 function calls to n-1 and n-2, resulting in recursion trees with T of n-1 and T of n-2 nodes, respectively. Okay. So, this is a valid expression for counting the number of nodes in the recursion tree for the algorithm when called with input n. And of course, just like the recursive algorithm, even this expression could use a base case. For it to be well defined, I am not making it explicit here, but you can probably check that T of 1 and T of 2 are both 1, and that will make this function description complete.\nNow, what I want to do here is just get a sense of how fast or slow growing this function is in terms of ‘n?’ The recurrence itself may strike you as a familiar one. It does look a lot like the Fibonacci recurrence, something that has come up before in this course as well. But instead of looking at an exact closed form for this recurrence, I will just try to do a quick and dirty lower bound.\nSo, notice that T of n is going to be strictly greater than T of n-2 + T of n-2. So, I am discarding the 1. And notice that I can claim that T of n-1 is at least T of n-2 because even by definition, T of n-1 is T of n-2 + something. Right. So, we have this simplified expression on the right-hand side, which works out to T of n being strictly more than 2 * T of n-2. And if you were to unravel this further, you will see that you just end up collecting two’s until you hit something like n = 0.\nSo, you could take a moment here to think about how many two’s you will accumulate by the time you hit the base case, which is when n is 0. So, let us say you start with, for example, n = 20. Then basically, the steps here would be from 20 to 18 to 16 to 14, and so on. So, you can see that you need n over 2 steps to go from the current value of n all the way down to zero. So, the number of two’s you accumulate is roughly something like n over 2. Okay.\nSo, I am being a little sloppy here in terms of not worrying about whether n is odd or even, etc. This is just to give you a rough sense of how big T of n is. And hopefully, this sort of back-of-the-envelope rough calculation tells you that T of n is definitely looking pretty scary right now. It is kind of exponential, which is not a good look. It is definitely not going to be feasible for the problem that we are trying to solve.\nAnd so, I would like to take you back to the recursion tree here. And I am going to request you to spend some time staring at this and see what is really going on here. And is there something that we can do to fix the situation that we have landed ourselves in? Incidentally, notice that this recursive tree actually has a leaf corresponding to every possible sequence that the frog could take in going from 1 to n. In that sense, we have really here a visual representation of the entire search space.\nThis is why I said that what we are going to do is going to begin by looking like the Brute-Force solution that we started with and immediately discard it for being too expensive. So, it would be completely understandable if you feel a bit cheated at this point, like I strung you along for the last several minutes, only to bring you back to square one.\nBut I promise you, there is light at the end of this tunnel, and in particular, there are going to be just a couple of lines of code that are going to fix this whole situation for you. So, with a minor but very important change, you can essentially turn this dramatically exponential time algorithm into one that is just linear time.\nAnd the way we are going to do this is by making an observation about how the recursive process here is doing a lot of redundant work. So, I am actually going to stop here, and I encourage you to actually pause the video on the screen and try to look for the redundancy that I was referring to and see if you can figure out this time-saving strategy for yourself before you continue the discussion with me into the next segment.\nSo, I am sorry to be leaving you with a bit of a cliffhanger here. But especially if you are encountering memoization for the first time, I think it would be really worth your while to take a few moments and reflect on what could possibly be the time-saving strategy that we are going to employ when we come back in the next segment. And I will see you there. Thanks!"
  },
  {
    "objectID": "materials/cpnotes/W10/Lec53.html",
    "href": "materials/cpnotes/W10/Lec53.html",
    "title": "Bottom-Up DP | Dice Combinations (CSES Problem Set)",
    "section": "",
    "text": "Lecture - 53\nBottom-Up DP | Dice Combinations (CSES Problem Set)\n(Refer Slide Time: 00:50)\n\nWelcome to the second module of the 10th week in Getting Started with Competitive Programming. This week we are getting started with dynamic programming and in the first module, you have seen an introduction to how dynamic programming can be thought of as memoized recursion or clever Brute-Force.\nSo, in this module, we are going to be doing more of the same with a new problem, except that there will be a small change in the way in which we write up our solution. So, we are going to be using tables instead of recursive functions and this style is sometimes referred to as Bottom-Up Dynamic Programming. So, we are going to get a chance to explore, what that looks like, and contrast it with the top-down approach that we have already seen.\nSo, for this module, the problem that we will be using is called dice combinations. It is a problem from the excellent CSES problem set, which has about 19 problems under the dynamic programming section. And I definitely encourage you to check out some of the other problems in this set as well and share your thoughts on your experiences with solving them.\nI think they are automatically ordered according to the number of people who made successful submissions. So, in some sense, the ordering is a rough indication of an increasing level of difficulty and I think by the time you are done with this week, you should be able to attempt at least the first couple of problems after dice combinations. So, do check that out. In the meantime, let us get started with the question of dice combinations.\n(Refer Slide Time: 01:43)\n\nSo, this is pretty much the entire problem statement. It says that your task is to count the number of ways in which you can construct a sum n, which is a given number by throwing a dice one or more times. Each throw of the dice produces an outcome between 1 and 6. So, one thing that I think I should say right off the bat is that this is a pure counting question. There are no probabilities involved.\nNormally when you think about problems involving throws of dice or coin tosses, you tend to think about chance, and you think about, well, what might happen, what might not happen. So, for example, this question is not asking, what is the probability that a sequence of dice throws adds up to n. That would be a question of chance.\nBut here we are really just asking, in principle, how many sequences of dice throws there are that add up to a given number n. So, really just, think of it as a pure counting question with no element of chance in it. So, to get used to what we are being asked to do, let us work through a few examples, which is always helpful.\nSo, what if n = 1? Well, in this case, there is really only one way that a sequence of dice throws could result in a sum of 1. And that is if you rolled it once and it showed up one. So, there is only one way that this can happen.\nWhat about when n = 2? Here there are two possibilities, either you could throw a dice two times and it shows up 1 on both occasions, or you throw it once and it comes up as 2. Both of these sequences are valid and distinct and lead to a sum of 2.\n(Refer Slide Time: 02:47, 03:04, 03:24, and 04:27)\nn=1  n=2  n=3  n=4 \nWhat about when n = 3? Well, in this case, there are going to be a few more sequences to account for. Feel free to pause the video here and see if you would like to work this out for yourself and come back and exchange notes. The case when n = 3 is actually also part of the problem statement. So, in case you have seen the problem statement separately, you know the answer to this already. All right.\nSo, the first thing that you could do is, to roll a dice once and it comes up 3. That is one way that this could happen. The other is that maybe you roll a dice once and it comes up 2, and then the only thing that can happen from there is that the second roll of dice should show up with a 1. On the other hand, maybe the first roll of dice ends up showing a 1, in which case you are left with the task of creating 2. And we know that we can do this in two ways, either by a single roll of two or two rolls of one each. So, altogether, the number of ways in which a sequence of dice rolls could produce the number 3 happens to be 4.\nWhat happens when n = 4? In this case, again, there is a multitude of possibilities, and here are all of them. Hopefully, I have not forgotten anything. And once again, if you go through the process of trying to categorize these nicely, you could think of it as, what happens on the first roll and think of the first roll as being the last dice in each sequence. It is just probably helpful to think of it that way.\nSo, if the first roll is 4 then there is nothing more to do. If the first roll is 3 then you need to generate 1. 1 is still left and there is only one way to do that. If the first roll is 2 then you still have 2 left to generate and there are two ways of doing that. And if the first roll is a 1 then you are still left with the task of generating 3. And we just saw that there are four ways of doing that. Let me actually highlight some portions so that it becomes visually a bit clearer how we relied on what we have worked out previously to work out the answer for the case when n = 4.\n(Refer Slide Time: 05:29)\n\nSo, you can see that all the green tiles correspond to ways of generating the number 3 by a sequence of dice rolls. And we kind of appended a 1 at the end to get 4. The yellow tiles represent the number of ways of generating 2. The red tile shows the number of ways of generating 1. And there is, of course, this standalone sequence, which is just directly getting to 4, without having to roll any more throws at all.\nSo, you might already begin to appreciate how this as a strategy might generalize to the case when you are trying to generate a sum of n. And if you remind yourself about how we worked out the solution to the frog’s problem in the previous module, we said it is useful to split up the solution space into smaller categories that are manageable by recursively-generated answers.\nSo, remember what we want to do is, see if we can take the space of solutions that we are interested in. In this case, our solution is really the number of these sequences, we want to count how many there are. And we want to take the space and see if we can chop it up into pieces that will then be addressable in some recursive fashion. And then, hopefully, we can just put it all back together in a reasonable way in a decent amount of time. So, here the chopping up at least seems to be fairly natural.\n(Refer Slide Time: 07:01, 07:18)\n  \nThese colored pieces naturally correspond to some instances that we can essentially outsource to recursion. And then when we put them back, it is just a matter of adding up all the numbers that we get. So, just to make this categorization a little more explicit as we did before, let us note that every sequence in our solution ends with one of these numbers, 1, 2, 3, 4, 5, 6.\nYou could think of this as essentially what happened on the last roll of the dice. That is clearly constrained to being one of these six numbers and that leads to a natural categorization of your space into six categories, some of which may be, by the way, empty as we have seen in our example.\nSo, in particular, if n is 4 then there will be no sequence that ends with a 6. Because once you have rolled a 6 that is a point of no return, there is no way of fixing that, so that the sum becomes four. So, that is just an empty category. It is not something that we have to worry about. It may manifest as a bit of an edge case, depending on your implementation. But we will see that it gets handled naturally in the way that we choose to implement the program later. So, let us take a closer look at this categorization so that the recursive nature of our solution also becomes a little bit more explicit.\n(Refer Slide Time: 08:22 and 09:34)\n \nSo, category number ‘k’ is going to collect all those sequences, where you got a k on the last roll. Okay. So, clearly, k ranges from 1 to 6. And if you look at the rest of the sequence in terms of what is happening apart from the last roll, which is represented by the colored tiles in the previous picture that we were looking at, well, these are all going to be sequences that add up to n-k. And that is easy to reverse engineer because you know that the whole sequence must add up to n because this is a sequence in your solution space.\nAnd right now, the categorization, the case that we are in is telling us that the last roll was already, so we know that the rest of it must add up to n-k. So, what we are interested in is, of course, the total number of sequences. And notice that the number of sequences that generate a sum of n-k is something that we can compute recursively. And once we have done that, the final answer is just going to be the sum of these answers that we obtain from recursion. Okay.\nSo, to make the recursion a little more explicit, let us write it down this way. So, the number of ways of generating a sum of n by rolls of dice is equal to the number of ways that you can generate n-1 and -2 and so on and so forth all the way up to n-6. Notice that we do need a base case, as we had explained last time. And here, a natural base case to work with is that the number of ways that you can generate a sum of 0 is 1 because the only way to generate 0 is to do nothing, and doing nothing is something that you can think of as the only way to generate a sum of 0.\nNow, this may not seem completely satisfactory, but we will see that defining the value of the answer for 0 as 1 will be useful in a very natural way in our recursion. Remember that one case where we said that you can get a 4 by just directly rolling a 4. Well, you can think of that as (being) getting a 4 on the last roll, followed by an empty sequence. And so, when you recurse, you naturally account for this one method of generating a 4 by getting a 4 on the last roll.\nActually, let me write out the case for n = 4 a little bit explicitly because it will help me draw your attention to also some edge cases. So, when n = 4, then n-1, n-2, and n-3 all make sense; n-4 is this mysterious the number of ways in which you can generate 0, but as I said, you can really think of that as generating a 4 on the last roll, and having to do nothing after that. I would really like that to contribute 1 to the sum because that is a perfectly legitimate way of generating a 4.\n(Refer Slide Time: 11:23)\n\nAfter this, things start looking a bit suspect. You have n-5 and n-6, being essentially -1 and -2. And, of course, there is no way that you can generate -1 and -2. So, these numbers are 0. And one question is, how do you want your recursion to handle it?\nSo, of course, the recursion could say that if n is less than 0, then you return 0. The other way to do it is to just make sure that when you are working with these smaller numbers, notice that this will not be an issue when n is, say, bigger than 6. But for these smaller numbers, you might just want to ensure that you do not even include these terms in your sum.\nSo, that is an implementation detail, and it is a matter of taste as to how you want to do it. But for now, the main thing to agree on is the recurrence itself and the choice of the base case. So, hopefully going over this explicit example makes it clear as to why we want to say that the number of ways of generating 0 is 1. It kind of aligns nicely with the recurrence that we have just set up for ourselves.\nNow, let us talk about the implementation a little bit. Of course, you could implement this just like we implemented the solution to the frog’s problem. So, you could write down a function called ‘solve,’ and it could call itself 6 times, and the answer would be the sum. And once again, you would, of course, want to memoize to avoid the overhead of doing redundant computation. So, that would have been the de-facto top-down style that we have seen so far. But now, let me take you through the bottom-up style instead, which is just a slightly different way of implementing the same solution.\nNow, what we are going to do is directly use an array to store the values, and we are going to populate this array going from essentially left to right in the context of this particular example. But more generally, when you have sort of a structure, which reflects all the answers, all the information that your solution wants to store, what you do is you directly populate the base cases.\nAnd then from there, you start working in different parts of the storage, making sure that whenever you are trying to fill up a certain entry in your table, all the entries that it relies on for information, have already been filled up before. So, that was a slightly abstract description. Let us come back and make it concrete in the context of this example.\n(Refer Slide Time: 13:47)\n\nSo, here, we just need a simple one-dimensional array with n+1 entries to account for the fact that we have an entry corresponding to 0, which is our base case. And we need to go all the way up to n because we are counting the number of ways in which n can be expressed as a sum of dice throws.\nSo, to begin with, we are going to just make sure that 0 is populated as 1. This is our base case. And then going forward, 1 is going to be equal to 1 again because that is just how the recurrence works out. So, when you look at the number of ways of generating 1, it is the number of ways of generating n-1. And we are going to ignore n-2 and so on because those generate negative numbers and as we said, those are things that we just treat as 0.\nSimilarly, for 2, we get 1+1, which is 2. For 3, we get 1+1+2, which is 4. For 4, you get 1+1+2 +4 that is 8. For 5, you get the sum of all the numbers that you have seen so far, that is 16. And for 6, you get the sum of all the numbers that you have seen so far again, and that is 32.\nFor 7 you do not get the sum of all the numbers you have seen so far, but the last six numbers that you have seen so far. So, that is going to be 63. And similarly, for 8, you are going to again get to the sum of the previous 6 numbers, and that adds up to 125. You can verify that these numbers are okay (and) that the addition was done correctly, I hope.\n(Refer Slide Time: 15:13)\n  \nIn general, when you are somewhere in the middle of this array, and you are trying to compute the i’th entry, the way you do that is by basically looking up the previous six entries and simply pushing the sum of all of these numbers to populate the i’th entry. You can just keep going. Okay.\nSo, essentially, you are doing the work that the recursive algorithm was doing implicitly. You are just carrying it out explicitly through a table and going over it directly. Implementing a bottom-up solution like this requires you to have a good understanding of how exactly the recurrence works. In the sense that you need to be careful about knowing in what order to fill out the table. So, typically for a one-dimensional table, this is not a serious challenge. You would usually just go from left to right.\nBut on the other hand, if you have a more complicated, say, two-dimensional array or something like this, you have to be careful about ensuring that you fill it up in the right order and that whenever you are filling up a particular entry, the entries that you are appealing to for information have actually been properly populated by the algorithm, and do not carry a garbage value or a default value that you have set up, which is still meaningless in the context of the problem. So, that is something to be aware of. This is worth that you are doing quite explicitly here, as opposed to before, where you could just write the recurrence and be done with it essentially.\n(Refer Slide Time: 16:44)\n\nAlright. So, let us take a look at how this would look in code. This is actually the entire program for this problem. And what we have done here, and the only thing I would like to maybe call attention to is the fact that when we are working with small numbers, we add in the small check, which makes sure that we do not get into these negative numbers, which would be either something that causes your program to not work or it leads to bugs.\nBecause in languages like python, for instance, if you have negative array indices, you would not get a complaint. But what it will probably do is just loop around the array and pick up some values from the end or something weird like that. So, we have a small sanity check that just ensures that when you are working with numbers that are at most six, you do not look up the entries that are not relevant to you.\nThere are other ways that you can implement these details concerning edge cases. But I found this one to be convenient and that is what we are doing here. You will also see like a ‘mod’ around here, it turns out that these numbers do get pretty large. And it was a requirement in the problem statement to print out the answer modulo a specific number.\nSo, there is a constant setting that you do not see on your screen right now. But ‘mod’ is essentially 10^9+7 or something like this. So, that is how you would do what is called bottom-up dynamic programming. It is called bottom-up because you start with the base cases, and you literally build the solution quite explicitly with your, if not your own hands, at least with your code, as opposed to just relying on recursion fairy to do all the work for you.\nSo, why would you use an approach like this? For some people, memoization over recursion seems like a more intuitive and easier approach to code (with). Some people find that the bottom-up method is more somehow transparent and intuitive to look at, and especially if you are doing modifications or optimizations on top of some basic routine, then somehow this is just easier to work with.\nSo, in terms of what you find more intuitive, I think is a matter of personal taste. I think I know people, who feel differently about this, so this is totally up to you in terms of preference, either of style or over what feels intuitive. As I said, for at least problems that you encounter at an elementary level, there is really no difference in what approach you follow. Having said that, let me make a few slightly more concrete remarks.\n(Refer Slide Time: 19:13)\n\nThis is just to complete the contrast that I had initiated towards the end of the last module and to basically wrap up that discussion. So, first of all, with bottom-up dynamic programming, you end up typically computing a full DP table, and often you end up actually computing entries that were never used in the computation of the final answer. So, you may end up doing some extra work.\nTypically, this difference is again not noticeable for the easier problems, but it may make a difference for more complicated situations. On the other hand, if you are trying to optimize for memory, then it is useful sometimes to work with the bottom-up approach because just easier to do memory optimization here, as opposed to top-down. To give you a simple example of how a memory optimization trick may work, notice that in the dice combinations problem, you only always needed the previous six entries to compute the current one.\nRight. You do not need to store the whole table. You can actually do everything that we did, using only a constant amount of space. And the way you can implement this is by just using an array with 6 or maybe 7 entries, one for buffer perhaps, and just continuously overwriting things carefully. Right.\nOn the other hand, if you wanted to do something like this with the recursive version it is harder because you really do not control how the recursive stack works, you know, as directly. So, that is the sense in which it can be messier to do memory optimization in the top-down approach.\nOn the other hand, just going back to the first point a little bit, because you are doing things recursively, it is very natural that you only make the function calls that are directly needed for getting to the final answer. Whereas, here you are just blindly following, you know, a way of populating an entire table.\nSo, typically, you would have, let us say, if it is a 2D table, you typically have a nested loop that just computes all the n times m entries or whatever, whether you need it or not. Right. So, again, this is something that you can optimize for, also in the bottom-up approach. But it is just something that would require extra explicit work from your end, whereas the recursive version handles this naturally.\nAgain, there are not many problems where this really makes a difference in terms of getting TLE or MLE, as the case may be. But I think it is just nice to know which approaches are more suitable for what kind of optimizations. So, just to recap, the bottom-up approach is more natural when you want to optimize for memory usage. And the top-down approach is more suitable when you want to optimize for time usage, in terms of just making only those function calls that are absolutely necessary.\nOne final point that I think I have alluded to already, is the fact that when you are doing bottom-up then you are actually explicitly writing out the sequence in which you fill out the table entries. So, typically, the recurrence will already hint or dictate the sequence in which you should be filling out the table entries. But you need to make sure that you understand your recurrence carefully, and there could be subtle errors that creep in, in terms of not getting this sequence right.\nSo, in one of the assignment problems, you will see how changing the sequence in which you populate a DP table can completely change the semantics of what the DP table is actually computing. So, make sure that you are careful about in what order table entries are being populated.\nThe example that we just saw, will not really help you appreciate this fully because it is a simple one-dimensional array, and there is a very predictable way in which you want to fill this out. But when you start working with 2D arrays or just more complex structures, over which you do dynamic programming, then these issues will start manifesting a little more. So, that is just something to be aware of and something to keep in mind.\n(Refer Slide Time: 23:21)\n\nOne thing that I like about the bottom-up approach is that it lets me distill the dynamic programming task into these two questions. Basically, you want to think about. What do I want to keep? And how do I compute what I want to keep? So, this is a little bit like the catchphrase we had last time, where we said dynamic programming is recursion + memoization. But I think, this way of thinking about DP for me has felt a little more concrete.\nSo, you want to say that okay, the ij’th entry of my table or the k’th entry of my table or whatever represents this value. And you want to ask yourself, okay, if I did compute this for the whole table, is my answer hiding somewhere in the table? Is it one of the entries? Is it the sum of some of the entries? Is it the max of some of the entries? You want to make sure that whatever you decide to store actually leads you to the answer in a meaningful way.\nOnce you have determined, what you want to store, you want to think about, well, how do I compute whatever it is that I decided my semantics are going to be? And this is the bit, of course, about recursion, about coming up with the right recurrence, identifying what sub-problems will help you solve the current problem at hand. And typically, your thought process for a non-trivial problem may involve a little bit of a back and forth between two questions. You might decide to store something, and then you might realize that, well, okay, this would be nice to store it takes me to the answer but there is not enough meat in this semantics; it does not give me what I want, because I am not able to compute it.\nThe previous entries are too weak. They do not give me enough information to compute what I want to compute right now. So, then, you go back and change the semantics. You add more masala to it, so to speak, you make it, you strengthen the semantics, and then you come back and try to do the recurrence again.\nSo, this is a process that you will typically go through before you land up at the right recurrence. With enough practice, you will identify patterns, and some problems will just immediately fall into some pattern that you have seen before. But sometimes you will see a problem that is just going to be a new adventure, and you might have to, sort of, do this back and forth process a little bit before you settle down and actually find the right recurrence.\nAnother thing worth mentioning is that for many problems, there will be multiple recurrences that make sense and that are all correct. But one would be superior to another in terms of the running time. So, you want to make sure often that you end up at an efficient recurrence, not just anyone that works. So, in one of the examples, we will see how we start off with a natural recurrence that is perfectly valid, but then we try to enhance it and just go to a sparser sort of a table, which can be computed more quickly.\nSpeaking of optimizations, I should say that there is a whole world of tips, tricks, strategies, and techniques for optimizing DP routines. And there is a lot to be uncovered and discovered here. Unfortunately, we will only get around to barely scratching the surface, and a lot of the advanced techniques are definitely a little bit out of scope for this course. Nonetheless, I think just getting the philosophy right with practice and being able to identify some common patterns will already take you pretty far in the context of solving DP-based problems.\nSo, to that end, in the next week, we will be looking at a couple of examples just to get the hang of how DP-based solutions work. And in the final week, we will round this off with one example, which is relatively a little more sophisticated than any of the ones that we would have seen before.\nSo, that is what is coming up, and I am looking forward to sharing these other examples with you in the coming weeks. In the meantime, I hope that you have a chance to look at the AtCoder DP educational problem set, as well as the CSES problem set, and try out a few of the problems that are there. At least the first few, I think, should be eminently doable from where we stop here, in this week. So, thanks so much for tuning in. And I look forward to seeing you back next week. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W10/Lec52.html",
    "href": "materials/cpnotes/W10/Lec52.html",
    "title": "Introduction | Frogs 1 (AtCoder Educational DP Contest)",
    "section": "",
    "text": "Lecture - 52\nIntroduction | Frogs 1 (AtCoder Educational DP Contest)\nAll right. So, welcome back to the second segment of the first module in week 10. Let us continue from where we left off in the previous segment.\n(Refer Slide Time: 00:19)\n\nSo, if you recall, we were looking at this recursion tree that is generated by a recursive algorithm. And we concluded that this tree has an exponential number of nodes, leading to the conclusion that the algorithm that we just wrote has an exponential time complexity because the time complexity is proportional to the number of function calls made. And that is what is depicted in this recursion tree. That is about as far as we got last time.\nAnd what I asked you to do was to think about whether you can identify any redundancy of computation in this recursion tree, which will hopefully give us some way of saving some time. So, one thing that you may have noticed is that there are parts of this recursion tree that look exactly the same. In particular, for instance, if you look at this function call that is being made to 4 here, that looks rather a lot like the function call that was made to 4 earlier. And the information that we are getting out of these function calls is exactly the same.\nSo, this entire computation that is highlighted in orange is completely redundant because, by this time, you have already performed the exact same computations a few moments ago. When you went over the function calls that have been highlighted in yellow in this picture, there to the bottom left of your screen.\nSo, when you look at this picture, it seems like, we are being rather silly in redoing a lot of work that is already been done. So, the question to ask ourselves at this point is, is there any way that we can leverage the information that we have from computations that we have already done so that we do not have to do it again? And that is exactly the process or the strategy of memoization.\n(Refer Slide Time: 02:06)\n \n\nSo, essentially, we want to remember the work that we have done before so that we do not have to do it again. So, let us take a look at how this works. Essentially, we want to store the outcomes of these prior function calls, so that at any point in time, whenever we have a recursive call, what we can do is really examine, if there is a need to go down the recursive rabbit hole prompted by this call.\nThe way we do this is, (to) check if the information that we would get by performing the recursive computation is already available to us. If it is already available to us, then we avoid the recursive call altogether. If it is not available to us that means, we are doing this operation or we are doing this computation the first time and it is okay to actually invoke the recursion.\nSo, notice that overall your algorithm is trying to track N pieces of information, where N is the number of stones that are there in the input that you are working with. So, to implement this in your program, what you would typically do is, declare an array, or a list, or a vector of size N, and use that to actually store the output of the recursive calls as you go along. So, let us take a look at how this would actually pan out in your program.\n(Refer Slide Time: 03:20)\n\nSo, here is the code again, but now, it is fixed to account for memoization. And the difference between this and the recursive program that we saw earlier is so small that I would not be surprised if you did not even notice the difference from a quick glance. So, let me actually highlight the line that makes all the difference. It is this conditional statement here, which is basically saying, look, if you already know the answer, then you do not have to go through the process here. Okay. So, what we have done, behind the scenes in the sense that you do not see it on your screen right now, is we have initialized a memo array or a vector, where all the values by default are -1.\n-1 in this problem is essentially a way of saying, we do not know the answer yet. If you are working with a problem, where the value -1 has some meaning or significance, then that is not a good value to initialize your array with. Basically, use some number, which has nothing to do with your problem, so that you can really use it as a code for saying I do not know yet. So, coming back to our program, here is what the code is doing for you. It is saying, okay, we want to know the answer for N. The first thing we do is check if we know this answer already. So, if the array value at N is something other than -1, that means, well, that is a déjà vu situation. We have already been here, we know, what the answer is.\n(Refer Slide Time: 04:51)\n\nAnd we can simply return in this case. Okay. So, if it is not -1, notice that the code does not execute any of the recursive calls, it does not do any other work. It immediately returns the answer. On the other hand, if the array does report -1. That means that this is unknown territory, we do not know what is going on, and we do need to go down the recursion rabbit hole to figure out what the answer is going to be.\n(Refer Slide Time: 05:22 and 5:47)\n \nSo, with this revised version of the recursive algorithm, let us take a look at what is going on in the recursion tree. So, notice that all of these function calls that have been highlighted here, will actually not execute in terms of recursion, but they will immediately return the answer. Because at the time that these function calls happen, the same computation has already been performed before, and the memo array is actually going to report an actual answer.\nSo, (all of these) all of this work in the recursion tree, basically, does not happen and is avoided. And your recursion tree will now essentially look like a linear path. Notice that this is really the leftmost sequence of executions. And once all of those are complete, as you walk your way back up to the root of the tree, there will be function calls, but they will all return immediately.\n(Refer Slide Time: 06:16 and 06:57)\n \nSo, no new recursive instances will be spawned, and the total amount of work that is being done now is actually linear. So, I do hope that you find this as amazing as I do. I think a little bit of extra space and a couple of lines of code adjusted (for) can lead to really tremendous time savings. So, that is the impact of memoization.\nAnd whenever you come up with recursive solutions, do watch out for the potential to memoize. What you really want is a situation where there is a lot of redundant work, so that you can find ways of avoiding it and saving yourself some time. So, we will have more to say about general principles in just a bit, but while we are at it.\nLet us actually see how this algorithm plays out for the example that we started off with. So, we have the frog here, on the third stone, mainly because as we said for the first two stones we already know what the costs are going to be. These are the base cases. So, in the first stone, let me just recap that the cost we agreed would be 0. And on the second stone, the cost would simply be the absolute differences, the absolute difference between the heights of the first and the second stone. And in this example, that happens to be 20.\n(Refer Slide Time: 07:28)\n\nSo, let us actually go ahead and make a note of this in the recursion tree as well. So these are the values that are returned by these two bottoms most function calls, which is where the work happens directly, and there are no further calls. So, these values are reported and pushed upstream to the calling function, which is trying to figure out, what is the answer, when there are three stones in the picture.\nSo, at this point, remember we are asking ourselves, how did you end up on the third stone? There are two possibilities, either you came in from the second stone, and that jump would have cost you 50, or you came in from the first stone, and that jump would have cost you 30. So, the final answer is the better of the two options between 50+20 and 30+0.\n(Refer Slide Time: 08:16)\n \nSo, here 30+0 is the clear winner. So, we are going to report 30 back to the calling function, which is trying to figure out the answer, for when there are four stones.\n(Refer Slide Time: 08:23)\n  \n \nSo, here again, what we are going to ask ourselves is, where did you come from? Did you come from the third stone or the second one? If you came in from the third stone, then the cost of that jump would have been 50, and the total cost would be 50+30, which is 80, versus if you came in from the second stone, then the cost of that final jump would be 0, and that gets tagged on to 20, so 0+20 is 20. So, clearly, the better of the two options here between 80 versus 20 is 20. So, we are going to record that as our final answer at this stage.\n(Refer Slide Time: 09:05)\n  \nNow, let us go back to what is going on when we land up at the fifth stone. This is what we are trying to understand now, now that we have understood everything, up to the fourth one. So, how could you have come to stone number five? You could either come in from the fourth, which would have involved a cost of 50+20 to get to the fourth stone itself. So, that is 50+20, 70. Versus you could have come in from the third stone, and the cost of that jump would be 0. And the overall cost would be 30+0, which is 30.\n(Refer Slide Time: 09:40)\n  \n \nSo, you can see that 30 wins this round. And that is what we are going to keep track of as we move on to the final stone. And this is going to be our final answer. How did we land up at the final stone? Did we come from 5? In which case the last jump would have cost us 10 and the total cost would be 30+10, 40, or did we come from stone number 4? Where the cost of the final jump would already be 40 and 40+20, the total cost would have been 60.\n(Refer Slide Time: 10:15)\n\nSo, between 60 and 40, again, the winner is 40 and that is what we are going to report as the final answer. And we are pretty much done here because this is all that we have been asked to report the final cost of an optimal solution. But on the other hand, what if the problem also asked you to actually provide a sequence of jumps whose total cost matched the optimum that you are claiming? You might have already seen, as we worked through the example, a way to do this as well. So, all you would need to do is a little bit of extra bookkeeping to keep track of basically what drove your choices as you went along.\nSo, for instance, in the very last step, when we got to 40, we want to make sure we understand how we got to 40. So, the reason the answer was 40, was because we came in from stone number 5 with a cost of 10. And how did we get to stone number 5? Well, we got there from stone number 3 with a cost of 0. And how did we get to stone number 3? Well, we got there from stone number 1 with a cost of 30.\nSo, if you essentially just keep track of where you came from, by figuring out who won the comparison when you calculate the answer, just keep that extra piece of information. Then just like we often do by following parent pointers, you could essentially run a backtrace, to figure out, what choices led to this final conclusion.\nAnd of course, when you are sharing your answer, you typically want to reverse the order so that the jumps happen in the sequence that they are supposed to happen. So, I think it is a fun exercise to modify the program that we have here so that it outputs one of the optimal sequences.\nNotice that you are going to break ties arbitrarily, so which sequence you print, will depend on, how you have broken ties. But no matter which sequence you print, they will all be optimal. But your tie-breaking may be different from mine. So, the actual sequences we print may be different. And most judges, when they ask you for a sequence that is optimal, they will accept any valid sequence. So, they will typically run a check, to make sure that the cost of the sequence that you have printed actually matches the optimal cost and that is what they will care about.\nSometimes occasionally, you may have a requirement, which is along the lines of ‘print the lexicographically smallest optimal sequence.’ In this case, you have to fine-tune your tie-breaking, to prioritize the lexicographically better option at every step. So, these are some details that are worth keeping in mind.\nI should say that this is a common feature of dynamic programming-based approaches, which is that by doing just a little bit of extra work, in terms of tracking the choices that you are making as you go along, you will be able to output, not just the optimum value, but also an actual solution that witnesses that value. So, I think this is a good thing to practice and get used to. Some people call this running a backtrace on your DP, and essentially, it is something that is useful in the competitive programming context because you are often required to actually produce a solution.\nAnd just in case you are using dynamic programming-based approaches for solving real-world problems at work and so on, often, you are interested in an actual solution, not just a value. So, do keep that in mind, and let us move on to making some general remarks about how dynamic programming-based approaches typically work, summing up some of what we have seen even just through this very introductory example.\n(Refer Slide Time: 13:51 and 14:47)\n \nSo, you can broadly think of dynamic programming as being memoization on top of recursion. So, you come up with a recursive approach to solving your problem, and you make it efficient by memoizing it like we did. I would say that usually the memoization part, at least in terms of implementation, is usually routine. You just have to figure out how to allocate space to the answers that you are interested in and make sure that you just modify your recursive subroutine so that there is that initial check for whether we really need to do this or not. Okay.\nBut what enables you to do memoization is, coming up with a recursive algorithm that has enough redundancy built into it so that the memoization is eventually useful. So, usually, the heart of the problem is in coming up with a recursive approach to solving the problem. That is appropriate for memoization going forward.\nSo, to come up with a recursive solution, again, there is no formula and every problem is going to be different. But typically, the mindset, with which you want to think about recursive patterns, is to see how best you can break up your problem into natural sub-problems. And again, as you practice more and more problems, you will begin to get a sense of, how people typically chop up problems into smaller pieces.\nSometimes for array- or sequence-based problems, you are either looking to chop things off from the end or the beginning or even some subsection in the middle. Sometimes your pieces may have to be subsets of some collection of elements. If you are working with graphs, say, for instance, you are working with a tree, then natural subproblems are typically subtrees that you obtain when you delete some root vertex. So, you try to figure out the answer at all of these subtrees and then somehow see if you can piece them together.\nSo, normally when you are doing recursion with the hope of memoizing going forward, you want your recursive sub-instances to actually have enough overlap so that you can leverage that overlap to save yourself time. You also want the pieces to be useful in the sense that you want your answer to be in some way a function of the pieces that you develop. Like we did for the frog problem, the two pieces that we solved were directly helpful in finding our final answer.\nAnd we also had substantial overlap as we just saw and that helped us eliminate a lot of the exponential part of the search space. This is one of the reasons, why some people think of dynamic programming as being essentially clever Brute-Force because when you first write own your recursive approach, it is practically a Brute-Force approach. It is exhaustive, and its correctness is easy to prove because it is exhaustive. But then after that, you take a closer look and you identify all of this redundancy and you memoize and that is going to save you a whole lot of time.\n(Refer Slide Time: 16:48)\n\nSo, this process of doing dynamic programming is usually called top-down dynamic programming, which is essentially you start by solving the problem at the top. That is the original problem. So, you start off by invoking solve of n or something like this. And this is essentially recursion. But we save the day with the modification that allows us to save time by using space, essentially.\nSo, when you write your dynamic programming solutions in this style, one advantage is that you are essentially building off of the recursive paradigm in a small way. So, it is really your recursive code with some small but important tweaks. So, if you are somebody who is already used to writing recursive programs then there is not much additional work to do to elevate it to the status of being an efficient dynamic programming-based solution.\nAlso, the other nice thing is that you only compute what you need based on the recursive calls that actually happen. You will probably appreciate this more when you see the contrast with the bottom-up approach, which is something that we are going to discuss next. And I think one of the reasons it is worth knowing a different way of really implementing the same thing, is because the other style which is the bottom-up style is sometimes cleaner from the point of view of memory optimizations.\nSo, if you wanted to save some space, then it is sometimes easier to do when you visualize this whole thing as a table that you are filling out, as opposed to this stack of recursive calls that are being made and that are doing their thing. They are really doing the same thing behind the scenes. It is just a different way of implementing the same idea.\nSo, we are going to continue this conversation in the next module, where we look at a different problem and we are going to implement it using the so-called bottom-up approach. And I would suggest that for both problems, you do the implementation in the other style, the one that has not been given just to get some practice. I think it is a good idea to be flexible about which style you use, because, in certain situations, one may have a small advantage over the other.\nAlthough it is true that most people have sort of their preferred default styles when it comes to dynamic programming. And they would only switch if there was a specific need to switch from the point of view of a certain kind of optimization and so on. So, as I just said before, I think it is a good idea to at least be aware of both the styles and be reasonably comfortable implementing a given solution in either of these styles because that may be something that is useful in a specific situation.\nHaving said that in the early stages, most elementary dynamic programming-based problems are such that this choice should not really matter. So, if you find one style much more intuitive or natural than the other one. It is perfectly fine to just stick to that for now. Let us continue this conversation in the next module, where we will use another introductory example to exemplify the style of bottom-up dynamic programming!"
  },
  {
    "objectID": "materials/cpnotes/W07/Lec39.html",
    "href": "materials/cpnotes/W07/Lec39.html",
    "title": "M 1 (Kruskal’s Algorithm)",
    "section": "",
    "text": "Lecture - 39\nMinimum Spanning Trees - Module 1 (Kruskal’s Algorithm)\n(Refer Slide Time: 00:11)\n\nWelcome back to the final segment of the first module of Minimum Spanning Trees. So, here I want to tell you about Kruskal’s algorithm, which is a contrasting way of building up a minimum spanning tree and, certainly, a different approach from Prim’s algorithm. While you can visualize Prim’s algorithm as slowly growing out a large component starting from just a single vertex, Kruskal’s algorithm takes a more global view and is closer in spirit to the first algorithm that we discussed, where we said, let us just keep picking safe edges as long as we can. So, that is what is going to more or less happen here. Let us take a look at how we can think of Kruskal’s algorithm in terms of iteratively building up a spanning forest using safe edges.\n(Refer Slide Time: 00:58, 01:11 & 01:18)\n  \nSo, as a standard by now, we are going to initialize the algorithm by thinking of the spanning forest that is just the empty graph on the vertex set of G. And after this, what we are going to do is just consider edges in increasing order of weight. And if an edge is safe to add to the graph, if it is safe in the current graph, then we simply add it.\nThat is all that the algorithm does. It just processes the edges in increasing order of weight and adds the ones that are safe to add. So, you can imagine why something like a disjoint set union would be a useful data structure for implementing this algorithm. I will let you think about that in the back of your mind. While let us just go over a simulation, once again, just to be sure that we have a common understanding of the mechanics of the algorithm.\n(Refer Slide Time: 01:49)\n   \nSo, we are going to use the same example as before. This will also give us an opportunity to check if, you know, we get a different spanning tree. And hopefully, it has the same cost because while you can have multiple ‘minimum spanning trees,’ they should all, of course, by definition, have the same total cost. So, let us see what happens with Kruskal’s algorithm. To begin with, all the vertices that you see here are a part of the forest; none of the edges belong to the forest just yet.\nWhat we are going to do is start processing the edges in increasing order of weight. So, as an example, you might choose to pick this edge. It is one of the ones that has minimum weight. And the question that we want to ask ourselves is, is this edge safe? Well, notice that this edge certainly does not create any cycles. We are just getting started. And notice that at any step, that is actually enough to confirm that the edge is safe.\nIn particular, because this is the globally minimum weight edge, you can be sure that it is also the cheapest edge coming out of whatever components that the edge is incident on. So, to answer the question ‘Is this edge safe?’ in the current iteration, all we have to do is make sure that it is not a part of a cycle. Alright. So, this edge certainly looks safe. So, we go ahead and add it to our spanning tree. And then we look for another edge, which is of minimum weight.\nLet us say we look at this one, once again, looks safe. So, we add it. The next edge we pick is, say this one, again, a safe edge. So, it gets added. The next edge is also safe and also gets added to the structure that we are building up. Now the next edge that has minimum weight again, you have a few choices here. Let us say we pick this one. This again, looks safe – does not really create any cycles – so, we go ahead and add it.\n(Refer Slide Time: 03:56)\n   \nWhat about the next stage we want to pick? Let us say it is this one. Again, does not create any cycle so, we go ahead and add it. Even the next stage that we pick looks pretty safe – does not create any cycles. So, let us go ahead and add it. The next edge that we pick that has minimum weight could be, in fact, has to be this one here. Notice that this is an interesting edge. It actually does create a cycle. So, it is, in fact, what we would call a useless edge.\nAnd in particular, it is not a safe edge. So, we do not add this to the structure that we are building up. Moving on, the next edge of minimum weight has to be one of the edges that have weight 4. So let us try this one here.\n(Refer Slide Time: 04:38)\n   \nNotice that this edge, again, is actually not a safe edge because it creates a cycle. So, we are going to ignore this one as well. And pick one of the other ones. Say, here. This looks pretty safe, so, we go ahead and add it.\nThis one is also safe so we add this as well. And at this point, you could continue drilling down your set of edges but you might also observe that from here on any edge that you try to add is going to actually be a useless edge.\nAnd it will, in fact, create a cycle with what you already have. One of the reasons for this is that at this point, we have actually collected 9 edges. And since we are working with a graph of 10 vertices, we are actually done. So, once again, even in your implementation, it would be useful to just keep track of how many edges you have added so far and exit early.\nOnce you know that you are done, there is no need to analyze edges any further. You can check that the cost of this spanning tree is also 25 tallying with the cost that we got from the outcome of Prim’s algorithm. And once again, you could play around with breaking ties differently to get to different structures.\nSo, you can observe here that both of these algorithms may lead to different spanning trees, and in fact, two different iterations of the same algorithm if ties are broken arbitrarily can lead you to the minimum spanning trees that look different as well. So, at this point, hopefully, we understand what Kruskal’s algorithm is doing. So this is a good place to switch to a discussion of its implementation.\nSo, for Kruskal’s algorithm, we will try to maintain the graph as an edge list because that is convenient. Remember that the main algorithm is really a loop through a sorted list of edges. So, that is what we are going to use to store the graph.\n(Refer Slide Time: 06:20)\n\nSo, to begin with, we are going to actually just sort the edge list after taking input in whatever form. So, once again, please look at the full code on the official repository to look up the initializations and how the data is being incorporated into the edge list EL. At the moment, the way the edge list is structured is that every element of the edge list is a collection of three numbers: The weight of the edge, and the pair of vertices that are involved in the edge itself.\nSo, the way this works (because the weight is the first component of this triplet), when you do the sort of a sort, it is going to sort according to the first component. So, that is nice and convenient from our point of view. So, the next thing is again, the standard initializations. We have these even for Prim’s algorithm. So, mst_cost is initialized to 0. It is the variable that will help us track the cost of the MST that we are building, and num_taken again keeps track of how many edges we have included in our spanning forests so far.\nAnd this will help us with the optimization that I have mentioned before. This is when we just check if num_taken is n minus 1, and we exit the main loop whenever that condition is true. Now the data structure that we want to use to implement Kruskal’s algorithm is the disjoint set union data structure that we have already discussed in week four.\nSo, if you need to recap, you might want to just go back and look at our discussions about UnionFind from back then. For now, let me just say that the elements of our universe will correspond to the vertices and as we go along, the sets will correspond to the components of our spanning forest. So, to begin with, we have sets, which are singletons, which naturally correspond to the spanning forest that we initialize our algorithm with, where every component is just an isolated vertex.\nSo, this initialization that is ‘default’ to a UnionFind works out pretty well for us. Now the main body of the algorithm is going to be this ‘for’ loop, which just goes through the list of edges. And what we want to do is, well, of course, the list of edges has been sorted already according to weight, so you are approaching them in the correct order already. And now let us just look at the current edge. And what we want to know is if this edge is safe to add.\nAs we mentioned earlier, it is enough to check if the addition of this edge creates a cycle or not. So, given the setup that we have here, an edge is safe, if and only if it is not useless. This is not true in general, but because we are attacking the edges in increasing order of weight, we do have this luxury. So all we have to do is check for a cycle. And that is exactly what is happening in this line of code. You have a cycle exactly when the edge has both of its endpoints in the same component. But that is exactly what the same set operation from UnionFind helps you check.\nSo, if both u and v, which is the edge that is under consideration currently belong to the same set, that means that that is in fact a sign of a useless edge. So, we are going to ignore this edge and continue along the main ‘for’ loop. On the other hand, if this edge is not useless, then it is a safe bet to actually add this edge. So, we are going to go through the process of adding this edge by just making sure that we add the cost of this edge to the mst_cost variable.\nWe actually merged the components that the edge has its endpoints in – this is the key step in terms of structurally accounting for the fact that this edge has been added to your spanning tree. And after this, of course, we could also update the num_taken variable to indicate that we have added one more edge to our collection here. And then finally, we add the sanity check, which says that if you have enough edges, you can get out of this loop – if you like, just leave the party early.\nAt this point, we are pretty much done we could come out of this loop and print the cost of the spanning tree that we have built so far. And once again, (it would) be an interesting little bit of extra bookkeeping to keep track of the actual edges that go into your spanning tree. So, see if you can keep track of that and actually output the spanning tree when you are done. So, notice that at the end, you must have exactly one set in your UnionFind data structure for you to have actually found a spanning tree. This will happen as long as your graph is connected, to begin with.\nIf it is not connected, what you will end up with is a spanning forest with as many components as there are sets in your UnionFind data structure. So, that is it, that is pretty much the entire implementation for Kruskal’s Algorithm.\n(Refer Slide Time: 11:14)\n\nLet us just talk a little bit about how long this is going to take in terms of its running time. Well, the first step, of course, is when you sort the edges. That already costs you m log n. And after that, you have this for loop over the edges. So, that is going to run m times. And inside the loop, you do have operations like checking for whether u and v belong to the same set or not. And actually, taking the union of these two sets whenever they do not belong to the same set.\nSo, those are operations from the UnionFind data structure, and their expense will depend a little bit on the implementation. You know that if you do something like path-compression-based implementations with union-by-depth heuristics, then you could get as good as near-constant amortized complexity. But even if you do a fairly simple union by rank implementation, even the worst-case complexity of each of these steps can be bounded by log n.\nSo, it is just easy to think of the complexity of Kruskal’s algorithm as being m log n in the worst case, given that m is at most n squared. So, notice that this is very, very similar to the running time that we already have for Prim’s algorithm. Once again, I will repeat that if you have to make a choice, you could probably use either algorithm for most MST problems that come up in contests.\nPerformance-wise, it should not make a difference. But often, you are not being asked directly for MST. I mean, there are probably two kinds of problems that you will encounter. One is where most of the work is in just recognizing that it is an MST problem in the first place. And being able to come up with a clever graph abstraction where the task can be translated to the MST problem. In this case, either algorithm should work out fine.\nAnd your main work is really in being able to see the graph and, you know, being able to model the problem as a graph. And after that, it is just plug-and-play. On the other hand, there are other kinds of problems where these are basically rip-offs of MST. So you are looking at MST variants. And then you may need to actually use one of these algorithms, but with minor tweaks. So, in that case, it may turn out that one of these approaches is better suited to the problem at hand compared to the other.\nSo, that is a situation in which you might want to be equally comfortable implementing either of these approaches. So, as always, you can find the code that we have discussed in the official repository. And if you are watching this video during the live run of the course, then the Discord forum is going to remain active. So, please share your comments or your questions there.\nAnd if you are not watching this during a live run of the course, please leave your feedback in the comments on this YouTube video, and we look forward to getting back to you. Thanks so much for watching. In the next videos, we will solve some actual problems based on MST, and I will see you in the upcoming modules!"
  },
  {
    "objectID": "materials/cpnotes/W07/Lec38.html",
    "href": "materials/cpnotes/W07/Lec38.html",
    "title": "M 1 (Prim’s Algorithm)",
    "section": "",
    "text": "Lecture - 38\nMinimum Spanning Trees - Module 1 (Prim’s Algorithm)\nWelcome back to the second segment of the first module on Minimum Spanning Trees. In this segment, I want to talk about Prim’s algorithm. And remember, from the previous segment, we talked about how most MST algorithms can be thought of as algorithms that build out a spanning forest step by step while making careful use of safe and useless edges. So, let us see how Prim’s algorithm realizes this framework.\n(Refer Slide Time: 00:40, 00:59 & 01:19)\n  \nTo begin with, we are going to start with the empty spanning forest, which is to say that the vertex set is simply the vertex set of G, and every vertex at the moment is isolated. What Prim’s algorithm is going to do is essentially try and build out one component starting from some specific vertex.\nSo, you can pick any vertex you like for this purpose. Let us just fixate on a vertex called ‘v.’ And let us call this vertex ‘T.’ That is to say, that is the spanning tree that we want to build out. So, this is a component that we want to continue focusing on, and (all of) Prim’s algorithm, the mechanics basically boils down to this.\nSo, we look at the safe edge incident on T, which is to say, let us look at the cheapest edge among all edges that have one endpoint inside T and the other outside. So, to begin with, once again, this is just going to be the cheapest edge that is incident on the vertex v. And that is what is going to get pulled into T. The other endpoint of this edge is going to now become a part of T. And, in a general step, you have built out some ‘component’ starting from this vertex v.\nAnd you are going to look at all the edges that go out of this component, pick the one that has the least cost, and then add the vertex that is at the other end of this edge in component T. So, we continue doing this until T is fully fleshed out into a spanning tree, which is something that you get to know once T has ‘n minus 1’ edges. By this time, it would have automatically visited or accounted for all vertices being reachable from the vertex that you started with. Now, just to make sure that we are on the same page as to how this algorithm works, let us actually run it on an example.\n(Refer Slide Time: 02:30)\n \n \nLet us just pick up the example that we looked at in the first segment. So, here is the graph. And I have highlighted in yellow the vertex that is the vertex that we are going to start with. So, this is our vertex v. So, the vertices do not have labels here just to keep the slide a bit clutter-free. So, let me just explain how color coding works. So, the edges that have been marked red are going to represent edges that are under consideration in the current iteration, which is to say these are edges that have one endpoint inside T and the other endpoint outside of T.\nTypically, what we will do is we will then highlight in green, the cheapest edge among all of these edges that are under consideration. And then, once we have identified this edge, we are going to bring in the vertex, which is at the other endpoint into the fold of T. These are vertices that you can think of as the visited vertices, the seen vertices. So, such witnesses will also be marked yellow. So, as and when we see more and more vertices as the component T bells out, all the vertices that belong to T will be marked yellow.\nSo, hopefully, that makes sense. Let us get started with the first step here. Notice that the edges under consideration are simply all the edges that go out of the vertex v. So, these are the highlighted edges here. And if you just read off the weights, you will see that the cheapest edge is the one that has weight 2. So, we bring in this neighbor into the fold. And now we see if we need to expand our set of edges that have one endpoint in the visited set and the other endpoint outside. And indeed, there are three such edges that need to be added.\nSo, these have been highlighted for you. Now once again, let us go over the edge weights of the red edges. And we see that there are two edges that have a weight of 3, and both of these are in competition for being the current cheapest edge. At this point, I am going to break the tie by picking the edge at the bottom and incorporating this vertex into the fold. Now notice that one of these red edges became yellow because this red edge is now no longer an edge that has one endpoint inside T and the other outside.\nIt has both of its endpoints inside T. So, we are going to mark it yellow as well. Now let us look at all the edges that are crossing T. So, there is one more that needs to be added. And once again, if you evaluate all the edge weights, you will see that now we have this other edge with a weight of 3 being the winner here. So, that brings in this vertex. And once again, we have more edges that cross now, at least one more. And this new edge is, in fact, the edge which has the smallest cost that is currently crossing. So, we use that to bring (in) this vertex into T. And now we have a few more edges that cross the cut.\n(Refer Slide Time: 05:43)\n  \n \nAnd among these edges, among all the red edges right now, you can see that the next cheapest edge that gets chosen is the edge with a weight of 2. There is no contention here. It is the cheapest edge, and it brings in this vertex. And now you have all of these edges crossing the cut. And now, in fact, we have two edges that are both the cheapest from component T.\nAnd we pick one of them. This one that is closer to the center – this brings in the vertex that is the center of your screen into the component T, and it also adds one edge to the cut. Now if you look at all the crossing edges, you see that there is an edge still of weight 2. So, that is the next cheapest edge to go with. It brings (in) the corner vertex into the fold and adds this edge to the cut. And now, among all the crossing edges, you again have a tie between the two edges that have a weight of 4.\nSo, let us break it by picking the vertex that is, once again, in the middle of this path at the bottom – this brings (in) this vertex into T. And at this point, you are going to have this edge crossing the cut, which would be in fact also the minimum edge for the current cut. And that is how the last vertex gets incorporated into your spanning tree. Now, you could try to rerun this simulation here by breaking ties differently, and you will see that you will end up with a different structure for the set of edges that witnessed the incorporation of vertices.\nSo, by the way, all of these edges that are marked green, which were the edges that triggered the incorporation of the next vertex, these trees very naturally form a spanning tree. And this is in fact the minimum spanning tree that is returned by Prim’s algorithm. And as I said, if you had broken the ties differently, you would end up with different tree structures. But notice that all of them will in fact have the same cost. It should be easy for you to believe that the set of edges that you get at the end is spanning and it is a tree. I think these are fairly intuitive properties of the set of edges that you finally get your hands on. But what is quite a bit more non-trivial is the fact that this is in fact the best you can do. So, for example, if you add up the costs here, I think it will amount to 25. But it is not trivial, even for this example, to convince yourself that this is the best that you can hope for, you can do a little bit of trial and error. And, you know, just try and see if you can improve on this.\nBut assuming that I have not made any mistakes in the simulation, this is going to be guaranteed to be the best that you can hope for because of the proof of correctness of Prim’s algorithm. So, this is a good point to remind you once again that in case you have not seen this proof before, although we will not be discussing it here, there are a number of pointers where you can find out more if you are so inclined. So, please do check either the course website or the description of this video for more. Now in the meantime, let us move on to the implementation of the ideas that we have discussed here.\nNotice that we are repeatedly finding the minimum cost edge incident to some ‘component.’ So, it is intuitive that priority queues come in somewhere in the picture. And notice that in spirit, this does seem to follow a very Dijkstra-like pattern, where we are constantly evolving some collection of visited vertices. But unlike Dijkstra, we do not really have to relax any edges or update the weights. So, we do not have to worry about the fact that, in particular, the C++ priority queue interface does not offer us a way to update the values of the keys. It does not matter here because we will never need to. So, we are going to use a priority queue to store the edge weights. And we are just going to carefully try and understand what are the edges that are incident on the component T as we go along. So, let us take a look at the code here.\n(Refer Slide Time: 09:46)\n\nSo, this is just an initialization of a taken array or a visited array. This just keeps track of which vertices have been visited so far by the algorithm. So, this array is basically the information about the yellow vertices from the previous simulation. So, initially, you could say that nothing is visited. And you could start things off by saying that the first vertex is visited. So, in this case, the first vertex is indexed by 0.\nAnd we just said, taken[0] = 1 to indicate that the story has, in fact, started. Now I just want to initialize also the priority queue with the values of the edges that are incident to this first or source vertex. So, let me just go over all the neighbors of the vertex 0 that is what is happening in AL[0]. By the way, I should mention that we are just storing all the information about the graph as an adjacency list because that is just something that happens to be convenient for this.\nSo, we are just going to do the standard thing of visiting all the neighbors of the vertex 0 and loading up the weights of the corresponding edges into a priority queue, which has been initialized. Just before this code snippet, just make sure to initialize the priority queue so that it acts as a min-heap and not as a max-heap, which is the C++ default. Do make sure to take a look at the whole code in the official repository to look at the surrounding details of the initializations, and so on, especially if you are not sure about how to set it up so that it is a min-heap instead of a max-heap.\nAlright. So, now that we are done with the first element in the priority queue let us do a little more initialization. So, we have the variables mst_cost, and then the variable num_taken both initialized to 0: mst_cost is pretty self-explanatory, it is going to store the cost of the solution; the variable num_taken is going to keep track of how many edges are in the spanning tree so far. This allows us to exit as soon as we have seen that we have picked up n-1 edges because that is a signal that your spanning-tree build-up is complete.\nSo, that gives us a way to exit the algorithm potentially earlier than waiting for the whole priority queue to be emptied out. So, that is why we have this extra variable here. You have to be careful about problems where you are handling multiple test cases. So, if you do this early exit, just make sure that you clean up the priority queue before you go to the next case. This is a very common source of bugs to have your adjacency lists or priority queues being corrupted with information from the previous test case.\nSo, do make sure to clear them out or re-declared them, especially when you are using this sort of optimization that does not automatically empty out the priority queue for you. Now let us get to the main loop that is at the heart of this algorithm. So, the way we are going to do this is to actually process the priority queue for as long as it has an edge on it with our check for, you know, getting out of this loop early, if we have actually built out the tree, as just described.\nSo, this is going to be our main outer loop. And what we are going to do is just repeatedly pull out the cheapest edges that we have in stock. Notice that one property of all the edges that get into the priority queue is that at least one of their endpoints is already in the set of the same vertices. That is how these edges got into the priority queue in the first place. This will become clearer when you see the entire body of the ‘while’ loop.\nBut that is just an invariant that we are going to maintain. With the initialization, this is definitely true. All the edges on the priority queue, in the beginning, are edges that have one of their endpoints in the source vertex and the source vertex as already seen, to begin with. And as I said, this is something that we will maintain as we go along. So, when we pull out the cheapest edge in the priority queue, notice that it already has the property that it is an edge that has at least one endpoint in the set of seen vertices.\nBut for this to be an edge that is of interest to us, we want to make sure that its other endpoint, in fact, is not seen so far. So, that is the first check that we want to implement. We want to make sure that take[u] is set to 0. So, if this is not the case, then we ignore this edge because this is an ‘edge,’ which has both of its endpoints in the component that we have built so far. And in the terminology that we discussed in the previous segment, this is a useless edge. So, we just want to have nothing to do with it. And that is why we just go back and continue with our loop.\nOn the other hand, if this edge actually lands at a vertex that is not yet seen, then that is an edge that is interesting to us. Notice that this is in fact the cheapest edge that crosses across from the seen territory to the unseen territory at the moment. So, this is essentially a green edge. Remember, every edge that we labeled green was a signal that this is the edge that is going to guide the incorporation of the next vertex.\nSo, this is the point where we have identified a green edge. And what we need to do is essentially look at the vertex that is at the other end of the green edge and make sure that it is incorporated. So, the first step to ensuring that this other vertex, which by the way is ‘u’ here is incorporated is by simply setting it is taken value to 1. So, that indicates that now this vertex has joined the club. The next thing that we want to do is to make sure that we update the cost of our solution with the cost of this edge.\nSo, this edge has a cost of ‘w’ that is what we get out of the priority queue. So, we add w to the mst_cost variable. And finally, what we want to do is actually identify any other red edges. So, remember what we did while we were doing the simulation when we brought in a new vertex was to check if there are any other edges that now go from the seen territory to the unseen territory because of the incorporation of this vertex.\nSo, what we are going to do is go over all the neighbors of this newly minted vertex, and check if any of those neighbors are unseen. That is, they have not been taken yet. Then these edges need to be pushed into our priority queue for consideration. So, that is what we are doing here. We are essentially processing this vertex to ensure that all of the edges (that are) incident on it are (being) now recognized in the system.\nNow, once you are done with this, all you have to do is update the number of taken edges by 1 and implement the sanity check that we discussed. If at this point, you have taken ‘n-1’ edges already, then you can quit this loop, and you are done. And once you are out of the loop, of course, you can print the cost of the MST or, if required, you could write a loop to print all the edges that belong to the MST.\nFor this, you might need to do a little bit of extra bookkeeping within the ‘while’ loop just like you would do with something like Dijkstra. You could have a predecessor array that tells you about how each vertex got roped into the component T. And those are the edges that will basically form the MST for you. So, that is it. That is pretty much the entire algorithm.\n(Refer Slide Time: 17:24)\n\nLet us quickly talk about its running time. Notice that every edge gets enqueued and dequeued at most once there are ‘m’ edges and these enqueue and dequeue operations cost you log ‘n.’ This is the bulk of the cost of Prim’s algorithm. There are some costs associated with the initialization and so on. But those are all dominated by this m log n expression. So, it turns out that once we get to analyzing Kruskal’s algorithm, you are going to get a very similar running time.\nSo, if you are pressed for a choice, either algorithm would work out similarly in terms of performance. But for some problems, it is just more natural to use one algorithm compared to the other and that will become evident as you practice through a number of problems. So, on that note, I would like to conclude our discussion on Prim’s algorithm and I will see you in the final segment for this module where we talk about Kruskal’s algorithm, which is a different way of building up a minimum spanning tree!"
  },
  {
    "objectID": "materials/cpnotes/W07/Lec42.html",
    "href": "materials/cpnotes/W07/Lec42.html",
    "title": "M 4 (Island Hopping)",
    "section": "",
    "text": "Lecture - 42\nMinimum Spanning Trees - Module 4 (Island Hopping)\n(Refer Slide Time: 00:12)\n\nWelcome back to the fourth and the final module in week 7 of Getting Started with Competitive Programming. So, we have been talking about minimum spanning trees. And in this final module, I want to talk about a problem called ‘island hopping,’ which was actually the ICPC World Finals problem from back in 2002. And to practice, you can find this problem on the UVA platform, the problem ID is 1013.\nSo, in the first module, I remarked that there are two kinds of MST problems that you are likely to encounter. One is where even recognizing the graph abstraction is not obvious. And seeing that what you are looking for is an MST is really the bulk of the work. Once you have figured out that, that is what needs to be done, doing it is actually pretty straightforward. And you can simply use the algorithms that you have learned quite directly.\nOn the other hand, the other kinds of problems are where the fact that it is an MST (the fact that there is a graph underlying the story) is reasonably transparent and obvious. But what you are looking for may not exactly be MST, but some quantity that is related to the MST in some way. So, you might need to tweak the algorithms that you know a little bit to get to the answer you want. So, this problem falls somewhat in the second category.\nSo, I think once you go through the problem statement, you will realize that what you are looking for is definitely a spanning tree of some sort. But the objective that you are optimizing for, on top of minimizing the cost of the spanning tree is also something else. And that is what needs to be figured out carefully.\nOnce you figure it out, the tweak you need to make to your MST algorithm is fairly straightforward. But just understanding what needs to be done – I think that is the crux of this problem that we are going to discuss now. So, as always, let us start with the problem statement. This one has a bit of a story, so I will just walk you through it.\n(Refer Slide Time: 02:14 & 02:24)\n \nWe are told that the company Pacific Island Net, PIN for short, has identified several small island groups in the Pacific that do not have a fast internet connection.\nSo, PIN plans to tap into this potential market by offering internet service to the island inhabitants. Each group of islands already has a deep-sea cable that connects the main island to the closest internet hub and the mainland in America, Australia, or Asia. All that remains to be done is to connect the islands in a group to each other.\nAnd you must write a program to help them determine a connection procedure. So, it already feels like we need to connect a bunch of islands within each other. And it seems like this is already feeling like some sort of a spanning tree problem. Let us move on.\n(Refer Slide Time: 03:01 & 03:21)\n \nFor each island, we are given the position of its router and the number of island inhabitants. You might be wondering, why is the number of Island inhabitants relevant, and we are going to get to that in a moment. In the figure that will come up now (this is a figure from the problem statement), the dark dots are the routers, and the numbers are the number of inhabitants.\nSo, here is the example that has been given to us. So, these dark dots are actually specified in the input as XY coordinates. So, you literally know where the routers are placed. And this information actually describes all your edge weights implicitly. So, the graph that we are looking at is really a complete graph. And between any pair of routers, the weight of the edge that connects them is their Euclidean distance in the plane.\nSo, you are going to have to compute that as you go along. So, this is in fact the second problem this week where we are working with a complete graph but unlike cherries mesh where the number of vertices could be as large as 105, here we are given that our graph has at most 50 vertices at a time. So, having to actually compute all pairs of edge weights is not going to be problematic in terms of the constraints.\n(Refer Slide Time: 04:17 & 04:36)\n \nOkay. So, continuing we are told that PIN will build connections between pairs of routers such that each router has a path to the main island. So, the main island is a specific special Island. And we want everybody to ultimately get connected to it, either directly or indirectly.\nNow, PIN has decided to build the network such that the total amount of cable used is minimal. So, the total amount of cable is just going to be equal to the Euclidean distances between the corresponding routers. Under this restriction, there may be several optimal networks and it does not matter to PIN which of these optimal networks is built. So, essentially, you can probably already guess that we want to build a minimum spanning tree on the graph that we have just described.\nTo recap what the graph is, every router is a vertex, and the cost of the edge between any pair of routers corresponds to the Euclidean distance between them. And what you want is for every router to be connected to some main island, which is a specific special router. And this is just going to correspond to building out a spanning tree that has the minimum cost. So, so far, this is sounding like a pretty standard minimum spanning tree problem. But we do have a couple of more things to worry about. So, let us continue reading the problem statement.\nWe told that PIN is interested in the average time required for new customers to access the internet based on the assumption that construction on all cable links in the network begins at the same time.\n(Refer Slide Time: 05:43 & 05:56)\n \nSo, in particular, shorter cable links get completed before the longer links because the construction of the cable links happens at a uniform speed. So, in particular, if you have a path from any vertex to the main island, then the cost of that path, in some sense, is going to correspond to the longest edge on that path because that is the one that will take the longest to complete.\n(Refer Slide Time: 06:23 & 08:00)\n \nSo, in particular, an island will have internet access as soon as there is a path from the island to the main island along completed cable links. And now you can see how the island populations come into play. So, we are told that if ‘mi’ is the number of inhabitants of the ith island and ‘ti’ is the time when this island gets connected to the internet, then the average connection time, overall, is the sum of the products, ti * mi normalized by the total population across all the islands.\nSo, this is in fact the quantity that you have to output. So, for each island, you want to somehow keep track of what is its connection time. So, if you can figure it out ti for every Island corresponding to your spanning tree, then it is just a matter of computing this expression, which is straightforward to do. Now, one question that might occur to you is well, should the spanning-tree be optimized to optimize the average time?\nWell, it turns out that every spanning tree that is optimal will have the same average connection time. Let me see if I can convey some intuition for why this happens. Let us break this discussion up into two parts. First, let me assume that all the edge weights are distinct. In this case, there is only one minimum spanning tree. And the task really boils down to making sure that we correctly capture the information about the tis. So, let us just play out a run of Kruskal’s algorithm on some graph, which has the property that all the edge weights are distinct.\nIn particular, let us say that this is some intermediate stage of Kruskal’s algorithm. The vertex that is marked red is the main island it is the special source vertex. And now, let us say that in the present step of Kruskal’s algorithm, we happen to add this edge to our spanning forest. Now notice that this is going to be the first time that these two verses, here in green, are getting connected to the component that has the special vertex.\nSo, this is the time when these islands, if you like, are getting connected to the internet. And this is the time to make a record of ‘ti.’ Now what is ‘ti?’ It is the most expensive edge on the path to the red vertex. But this expensive edge must be the dotted green edge because we know that all the edges that were added before this, were actually cheaper edges. Because that is just the sequence in which Kruskal’s algorithm is going to be adding edges to the spanning forest.\nAnd since all the edge weights are distinct, we know that this is in fact strictly the heaviest edge on the path. So, for both of these vertices, we just make a record of the weight of this dotted green edge as being the value for ‘ti’ for both of these islands. So, that is how you would keep track of the ti. And now let me try and convince you that whenever ties are to be broken in Kruskal’s algorithm, it does not really matter how you break them. You will end up getting the same ‘ti’ values for all the islands.\n(Refer Slide Time: 09:38 & 09:53)\n \nSo, just to get some intuition for this, let us consider what happens in what I like to think of as the first phase of Kruskal’s algorithm, which is to say let us think about what happens for as long as Kruskal’s algorithm is processing all the edges that have the minimum weight.\nSo, let us say that there are a bunch of edges that all have the smallest weight, and let us say these are all of those edges. Now, once your algorithm is done processing all of these edges in the edge list, you will end up with some spanning forest of these edges. Right. Now notice that no matter which spanning forest you end up with, the set of vertices, which is connected to the main island remains the same, and all of them will actually have the same ‘ti’ value. I hope that makes sense.\nThey will all have the same ‘ti’ value because they are all connected to the main vertex via paths that have uniform edge weights. So, the maximum connection time is just going to be that edge weight. Remember that all of these cables are being built simultaneously. So, that is what is going to happen at the end of the first phase. Now let us bring in all the edges that have the second minimum edge weight. Let us say that these are the blue edges. And now, once again, notice here that there could be different spanning forests that you get depending on the sequence in which these edges were processed. But once again, remember that what is true is that in all of these spanning forests, the set of vertices that get connected to the main island by the time the second phase is over, is exactly the same. And all of them have the same ‘ti’ value.\nAnd in this case, the ‘ti’ value for these islands that newly got connected to the main island (that were not connected at the end of the previous phase) is going to be the weight of the blue edges. And you could keep doing this till you are done, the same argument would apply. So, no matter which spanning tree you get at the end, structurally, they could be different, but the ‘ti’ values are all going to be the same. So, now hopefully, the algorithmic idea is clear.\nWe just run Kruskal’s algorithm and every time we add a safe edge to our spanning forest, we check if the safe edge is connecting some component to the component that contains the special source vertex. If that is happening, then the ti values for all the vertices on this component should get updated to the cost or the weight of this edge. That is how you keep track of the tis. And once you are done, you just have to compute the average connection time and output it. So, now with that being said, we can take a look at the implementation. As usual, I am going to skip the parts about taking input and writing output because they are fairly standard for this problem. One small thing is that the output format requires you to leave an extra blank line at the end of every test case. So, if you forget to do this, as I did, you will end up getting a presentation error message from the UVA judge.\nSo, if that is what is happening, and you are puzzled by it, just double-check that your output format exactly matches their required specification. Other than this, I do not think there is anything special to watch out for. So, I really focus on just the key algorithmic part of the code. If you want the rest of it, the input-output or the UnionFind class, then you can always look up the full code in the repository, which has been linked to in the description of this video. Alright.\n(Refer Slide Time: 13:17 & 15:01)\n \nSo, for each test case, what we are given is the x y coordinates of the locations of all the routers as a list. And we are also given the number of inhabitants of the corresponding island. So, we, of course, take in all this information, but we now have to explicitly build the graph that is implicit in all of this data. So, what we are doing is storing the graph as a list of edges. And remember to clear out your edge list for every fresh test case.\nAnd then what we want to do is build out a complete graph here. So, that is exactly what is being done here. You have this nested ‘for’ loop that essentially goes over all ordered pairs ‘ij.’ Notice that this is an undirected graph. So, the distances from ‘i’ to ‘j’ will be the same as the ones from ‘j’ to ‘i’ and you will never need to consider these edges twice. So, it is enough to just keep track of these ordered pairs here. Now the weight of the edge from ‘i’ to ‘j’ is the Euclidean distance between these two vertices.\nSo, that is something that we can calculate using the built-in ‘hypot’ function, which I presume is short for the hypotenuse. What this function will output is the square root of the sum of the squares of the two numbers that it takes as input, which of course, you can write out as an explicit expression if you so prefer. But this is just a cool shortcut, which I thought was worth sharing for this problem.\nOnce you have computed the weight, you, of course, can now add this edge with its weight to the edge list. And this is essentially the process of building up the graph. As always, because we are going to do Kruskal’s algorithm, we sort this list of edges as the first step and then we declare the UnionFind data structure.\nAnd we are going to have a couple of weight vectors. In one, we are going to try and keep track of the cumulative populations of all the islands that belong to a particular component. So, the root vertex of any component, or, in some sense, the element that corresponds to the representative element of the set carries the information for the total population of all the islands that belong to that set.\nThe reason for doing this is that remember we said that when one component gets connected to the component that has the main island, then all of these islands experience the same ‘ti’ value. So, we can directly multiply ‘ti’ with the sum of these populations. So, it is just useful to keep track of the sum in the element that is representative of this collection of islands for this component. So, that is what we are going to be doing with weight 2.\nSo, we are going to modify the union function in the UnionFind data structure so that whenever you take the union of two sets, the weight two value of the parent is going to be incremented with the value of the weight of the incoming component. So, that is a minor modification that you need to make in the UnionFind class. I am not going to show it here explicitly. But once again, you can look at the code to see how it works.\nWe are also using the weight array to keep track of the sizes of the components that we are building. This will allow us to do some simple union by size heuristics while merging two components. So, again, you can see how that comes in useful in the union function. Alright. Now finally, for the fun part, how do we modify the standard Kruskal’s algorithm so that we can also keep track of the tis? So, notice that we are processing the edge UV right now with weight W.\nAnd the first check is the standard check for whether UV is a safe edge to add or not. So, if it is not a safe edge, meaning it has both of its endpoints in the same component, we anyway ignore it and move on just like we would do in Kruskal’s algorithm. On the other hand, if it is a safe edge, and we are going to add it, the thing that we need to check is if either of these components is the special component, which has the main island in it.\nSo, those are the two ‘if’ conditions that you see here. So, if U has the main island in it, or V has the main island in it, then we have some work to do. So, 0 here, by the way, is the label of the main island. So, let us say that U and 0 belong to the same component. This means that currently, you are merging the component that contains V with the component that contains the main island.\nThat means that every vertex in the component that V belongs to is, at this point getting connected to the internet for the first time, and all of their ‘ti’ values can be updated to the weight of the edge that we are currently processing. In other words, what this means is that to the numerator of our expression, we should be adding the value of ti times the total number of people who inhabit all of the islands in the component of V.\nBut notice that that is exactly the value that we are storing in weight 2 of the parent or the representative element that the set belongs to. So, that is the first term in this expression here. So, we are pulling out with weight 2 of UF a fine set of V, we really pulling out the total number of inhabitants in all the islands that belong to the component that V belongs to. And now we are multiplying this by the weight of the edge that is currently being added because this is going to be all of their tis.\nSo, that is what we do if U contains the main island. On the other hand, if V contains the main island, then we do the same thing. But just with the roles of U and V swapped. So, hopefully, these two conditions make sense. Of course, it is possible that this is a boring update in the sense that it merges two components, neither of which contain the main island. In this case, notice that there is no work to be done. And the flow of control will simply skip both of these conditions here.\nNo matter what the scenario, you do want to physically merge these components, and that is what the union operation in the last line of this block will do for you. So, that is pretty much the whole algorithm. What you want to do at the very end is make sure that you print the value of the sum divided by ‘div,’ which is declared on the third line that you see on your screen right now; ‘div’ essentially is the total number of inhabitants across all the islands.\nSo, sum divided by div is what you want to finally output, and make sure that in terms of formatting, you are restricting yourself only to the first two decimal places. And once again, do remember to print an extra blank line of output after you have actually produced your answer. Otherwise, you will end up getting some kind of presentation error. One more minor point of detail is that when you are recording the weights, remember that these are not going to be integer weights. You are taking the square root of the sum of two squares. This is the Euclidean distance between arbitrary coordinates.\nSo, you want to make sure that the weight component in your edge list is declared as a double. Okay. So, if you declare it as an integer, you will end up getting only approximate counts for the distances, and your final answer will be off by quite a bit. So, that is one more small detail to take care of, especially if you are going to use the standard templates for edge lists and so on, that we have been using. It is easy to forget that we typically declare the edge list to be a tuple of three integers. So, make sure that that first integer is actually swapped out with a double.\nAlright. So, that is, I think, pretty much everything I had to say about this ‘island hopping’ problem. I thought it was a pretty cool problem. And despite sounding a bit complicated at first, I think it has this really elegant implementation, which is not very far off from the algorithms that we have learned this week. So, I hope that everything made sense.\nBut as usual, if not, please feel free to drop your comments or questions on either the Discord channel if you are watching this during an active run of the course, or please feel free to leave your questions as a comment on this video and we will be sure to get back to you. So, thanks so much for watching. With this, we do come to the end of week 7 and our discussion of minimum spanning trees.\nWe will be back next week with a new topic. In particular, we will be talking about network flows, which is a whole lot of fun as well. So, I look forward to seeing you back then. And once again, thanks for watching and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W07/Lec41.html",
    "href": "materials/cpnotes/W07/Lec41.html",
    "title": "M 3 (Hierarchy)",
    "section": "",
    "text": "Lecture - 41\nMinimum Spanning Trees - Module 3 (Hierarchy)\n(Refer Slide Time: 00:26)\n\nWelcome back to the third module of the seventh week in Getting Started with Competitive Programming. This week, we have been talking about minimum spanning trees. And in this module, I want to talk about a problem called ‘hierarchy’ from Codeforces. So, let us just get started with the problem statement here.\nSo, we are told that Nick’s company employed n people. Now being primed to think about graphs, when you even read this sentence, you are probably thinking about people as vertices, which is excellent. I think that is how things are going to pan out. So, let us take a look at what happens next.\n(Refer Slide Time: 00:49, 01:28 & 01:58)\n  \nNick needs to build a tree hierarchy of supervisor-subordinate relations in the company. This is to say that each employee except one has exactly one supervisor. So, this is all from the problem statement. I have not really added any remarks here. So, we are told that every person has to find one and exactly one supervisor, except for one person whom you could think of as some kind of a root node in this tree structure. Or if you are thinking in terms of the story, this is probably the CEO of the company who does not need to report to anybody.\nSo, there are m applications in the following format. Employee ai is ready to be a supervisor of employee bi at an extra cost of ci. The qualification of each employee is known and for each application, it is true that ai is qualified to supervise bi. Now in this part of the problem statement you are not told anything more about what it means for ai to be qualified to supervise bi.\nBut if you look at the section where the input-output format is described, we are told that for each application, it is promised that qai is greater than qbi, where qx denotes the qualification of employee x. So, it is good to know that that is what it means for one employee to be qualified to supervise another, that their qualifications are strictly greater than the person that they are expressing willingness to supervise.\n(Refer Slide Time: 02:28 & 03:06)\n \n\nWe are also told that different applications can be similar, that is, they can come from one and the same employee, who offered to become a supervisor of the same person, but at a different cost. This is perhaps to say that if you think of these willingness applications as edges between people, then this graph can have multiple edges between the same pair of different costs. So, these remarks were in the input-output format section. So, let us just go back to the problem statement to figure out what our task is, and it turns out to be a fairly predictable task.\nWe are to help Nick calculate the minimum cost of building such a hierarchy or find out that it is impossible to build it. Now, you might be wondering, under what circumstances would it be impossible to build the kind of hierarchy that we are looking for? Well, this can happen. For example, if you have multiple employees that nobody is willing to supervise. Recall that the definition of the hierarchy requires that there is exactly one employee who does not have a supervisor, and everybody else has exactly one supervisor.\nSo, imagine that in your instance, you have two or more employees, whom nobody is willing to supervise among all the applications that you have received, then no matter how hard you try, you will not be able to build up a complete hierarchy. So, these are the kinds of situations that you want to filter out and identify as being impossible. Notice also that what we just described covers all the impossible scenarios.\nBecause if this does not play out, then you have an instance where every employee, except for at most one has at least one person who is willing to supervise him or her. And therefore, if nothing else, you could just arbitrarily identify a supervisor for each employee and you will end up with at least some hierarchy. So, it is not going to be impossible. But our task would still be to figure out the best possible among all the hierarchies that turned out to be valid ones.\n(Refer Slide Time: 04:46)\n \nNow, as you might expect, we would want to model this as some sort of a graph. So, let me just say that if we have vertices A and B corresponding to people then we will have an edge from A to B to indicate that B is potentially going to be supervised by A. So, if you have an application for employ A who says that they are willing to supervise employee B, for some cost C, then you would add this edge from A to B and assign it a cost of C.\nIf there are multiple applications of this kind, you could add multiple edges with their respective costs. So, the first thing to notice is that what you are really looking for is a subgraph with the property that every vertex except for one has in-degree exactly one. Just to recall some terminology, the in-degree of any vertex V is the number of vertices U search that there is an edge from U to V or U comma V is an edge in the graph G.\nSo, that is why we are looking for a subgraph, where the in-degree of every vertex except for one in the subgraph is going to be exactly one. This corresponds to the constraint that every person has exactly one supervisor. Now, beyond the in-degree constraint, we are also looking for a subgraph, which does not have cycles. Because if you recall, in the problem statement, we are given that we have to find a tree hierarchy. In fact, the lack of cycles also follows from the way qualifications are described for supervisor-subordinate relationships.\n(Refer Slide Time: 06:23)\n \nFor example, let us say that we start with employee A, who has a qualification of level 9, for instance, and let us say that we determine that A is going to supervise B. So, B’s qualification necessarily must be strictly less than 9 for this to be a valid supervisor-subordinate relationship. So, for example, let us say that B’s qualification is level 8. Now let us say that B is to supervise C. Let us say this is what we are determining in our solution, then once again, C’s qualification must be strictly less than B’s.\nSo, in particular, it must be less than 8. Let us say that it is 7. And let us say that C, in turn, is planning to supervise D. And once again, we know that for this to be valid, D must have a qualification of level 6 or less. So, let us say that it is 6. And now notice that if you do end up suggesting that D should supervise A, then this will not be a valid supervisor-subordinate relationship because D’s qualification is strictly less than A’s.\nSo, anytime you see a cycle in the supervisor-subordinate relationship structure that you are proposing, you know that it is not going to be a valid structure. So, the fact that what you are looking for is a tree also follows from how we are told valid supervisor-subordinate relationships are established. Notice that this argument worked out because we had this constraint for the applications.\nIf this was not a strict inequality, then our argument would not quite work out in the same way. Of course, we are also told in the problem statement that we are looking for a tree hierarchy. So, we know for more than one reason that the substructure that we are looking for, is in fact, acyclic. So, just to recap what we have so far, let us reframe everything that we know in terms of both ‘input’ and expected ‘output,’ in the language of graphs.\n(Refer Slide Time: 08:28 & 08:35)\n \nSo, first, we said that there are ‘n’ employees. So these employees can be thought of as vertices. And we also know that we have these applications, indicating that employee ‘ai’ is ready to supervise employee ‘bi’ at the cost of ‘ci.’ So, we said that we will model this by an edge from ai to bi with an edge weight of ci. That is what we are going to do for each of the applications that we get. So, we have this graph. And what we are looking for as a subgraph is, well, on the one hand, we said that every vertex except for one must have indegree exactly 1.\n(Refer Slide Time: 09:08, 09:23)\n \nSo, this means that there must be exactly ‘n-1’ edges in our subgraph. And also, we said that we are looking for a tree hierarchy. So, we said that there are going to be no cycles. So, notice that the solution is, in fact, a minimum cost spanning tree.\nBecause, well, you have ‘n-1’ edges, which do not form cycles, and the minimum cost comes from the fact that we have been tasked with finding a minimum cost hierarchy. So that is where the minimum cost comes from. So, we could potentially just run a minimum spanning tree algorithm here. We just have to be a little bit careful because the edges are directed. And we have this in-degree one constraint to be a little bit careful about as we work with these directed edges.\n(Refer Slide Time: 10:01)\n \nSo, one way to try and account for this is to say that whenever you are working with your MST algorithm, if you are trying to add an edge from A to B at any stage, you want to make sure that B does not already have a supervisor. Once you pass this sanity check, then this edge is truly safe to add.\nNow, it seems tempting to use something like Prim’s algorithm for this because of the way you are expanding out, if you only expand out along out-edges seems like the sanity check is built-in for you. But notice that Prim’s algorithm starts with an arbitrary choice of a source vertex. And you can imagine that the spanning tree that Prim’s algorithm will produce at the end will have the source vertex as the root or the CEO, or the person who is eventually not going to have a supervisor. So, you want to be careful about the choice of source.\nSo, you have to go through your applications to figure out which one is that ‘one applicant’ who does not have any willing supervisor. Notice that in any valid instance, there must be exactly one such employee. We already said that if there are two or more employees who have no willing supervisors, then this is an impossible instance, and we will return as much. So, your code should check for this situation separately.\nAnd on the other hand, it also cannot be the case that there is no such employee. Imagine a situation where every employee had at least one willing supervisor. Then in the graph that you have built up, you could just start with any employee, and go to anyone who is willing to supervise him or her and just keep doing this. And you are never going to get stuck because every employee has at least one other employee who is willing to supervise him or her.\nSo, if you keep following along because your graph only has n vertices, and you will never get stuck, it must be that at some point, you repeat a vertex. That is unavoidable. And when you do repeat a vertex, you have actually discovered a cycle. But we just argued a few moments ago that you could not structurally have a cycle because we have been promised that every time any employee is willing to supervise another one, they are actually qualified to do so.\nAnd because of the way this is defined, the qualifications are always strictly increasing or strictly decreasing, depending on which direction you are going around this sequence of employee-supervisor relationships. So, as a result, we know that it cannot be the case that every employee has a willing supervisor. There must be somebody who does not have one for things to make sense.\nTherefore, in a valid instance, there is going to be exactly one employee who does not have any willing supervisor. And that would be the most appropriate choice for a source vertex for Prim’s algorithm. If you start from here, then you should be able to just run Prim’s algorithm and find your optimal answer. Now, this is an approach that I actually have not tried implementing. So, if you do this, and it works out, do let me know; I would look forward to seeing your code.\n(Refer Slide Time: 13:10 & 13:41)\n \nNow, the official editorial mentions a direct greedy approach. Notice that everyone needs one supervisor, so just find the best one for every employee who has at least one supervisor who is willing to supervise him or her. Once again, this will also require the sanity check at the beginning, where you ensure that there is exactly one employee who has no willing supervisors. Once that sanity check is out of the way, this greedy approach can be shown to work.\nYou could also use Kruskal’s algorithm, you just have to be careful about adding safe edges. So, when you are going to add an edge, indicating that U will supervise V, you want to make sure that V does not already have a supervisor. Your parent pointers will naturally keep track of the hierarchy that you are actually looking for. And since this is a fairly elegant solution in terms of the code, this is the approach that I chose to implement for this problem.\n(Refer Slide Time: 14:16 & 15:04)\n \nLet us take a quick look at the implementation. So, the first thing that I did was to modify the union operation in the UnionFind data structure a bit so that it is just directly tracking parent pointers without doing any rank or depth checks. So, when I say that I want to take the union of ‘i’ and ‘j,’ I do mean that I want the parent of j to be i. And this indicates that j is going to be supervised by i. So, that is what we want to do here. So, we are not going to set the direction of the pointer based on what is optimal in terms of the depths of the trees. We are actually going to do exactly what we are told to do. So, this is a minor modification. In fact, it simplifies the way union is performed. And that is what we need for the semantics of this problem.\nNow, in terms of what we do in the main function, after reading all the edges based on the applications and making sure that, you know, we use the standard format of the edge list: the first coordinate in the tuple being the cost and then the second and the third coordinates, corresponding to the directed edge from U to V. After having done that, as usual, we will sort the edges by weights as Kruskal’s algorithm would do. And now you will see that I also have an MST variable, which is a vector that will collect all the edges that we actually add to our spanning tree.\n(Refer Slide Time: 17:19 & 19:51)\n \nNow, you do not literally need to output the tree hierarchy, you just need to output the cost. So, you do not really need this. But I keep talking about how a little bit of extra bookkeeping can actually give you the spanning tree as well. So, this is just to demonstrate that even though we will not use it for generating the final output, we will use it to check if we actually managed to generate a complete hierarchy or not. So, it is useful to know how many edges we managed to add to a spanning tree.\nNotice that if there is more than one employee who has no willing supervisors, then when you run your ‘spanning tree’ algorithm at the very end, you will actually not get a spanning tree, but you will get a spanning forest—one for each employee who does not have any willing supervisor. There will be one component in this forest for every such employee. So, all we need to do is either check the number of sets that were produced at the very end and see if that is greater than one.\nOr we could just tally up the number of edges that were collected in our spanning tree and check if that falls short of n - 1. In that case, a spanning tree is not really a tree but a forest. So, this is one way of figuring out if we are in an impossible situation or one where we were able to successfully build a hierarchy. So, that is another thing that this MST variable may come in handy.\nSo, as always, we are going to initialize the UnionFind data structure. We are going to do it with n + 1 vertices just to keep the indexing a painless experience. And we have the ‘answer’ variable, which will track the costs of the edges that we add to our spanning tree.\nNow, we run Kruskal’s algorithm as usual. If we actually have collected ‘n - 1’ edges, then we make an early exit from this loop. And otherwise, we are basically looking at the current edge, which indicates that U is willing to supervise V. That is how we added the edges in the first place. And the first part of the ‘if’ condition that you see here is the standard Kruskal’s algorithm condition, which determines if the edge is safe or not.\nSo, if U and V happened to be in the same set, then this edge is actually going to create a cycle. So, we are not going to be interested in adding this edge at all. Now at this point, you might have the following question. The edge U V, when the endpoints belong to the same set does form a cycle in the underlying undirected graph. But perhaps they do not form a cycle in the directed graph. So, it is possible that for instance, you have an edge from A to B, and an edge from B to C.\nAnd then the edge that you are about to add is not the edge from C to A but an edge from A to C. That is not going to create a cycle. But notice that if you do not create a cycle in the directed graph, then you end up creating a vertex that has an in-degree more than 1. So, either way, this is going to be a violation. So, if U and V belong to the same set, then we are not going to add it anyway. And beyond this, remember, we said that we need to be sure that V is not getting an extra supervisor. So, we check that V is in fact, the root of the set that it belongs to.\nThat is the only circumstance in which adding this edge from U to V would be a valid addition to the structure that we are building. So, this and V equals the parent of V. That extra condition is what is required to make this algorithm work. This is not a part of the standard Kruskal’s implementation. But that is what we need to do here. Now if both of these conditions work out, then we know that we have a valid addition to our structure.\nSo, we add this edge to our MST, we increment the answer variable with the cost of this edge. And we actually merge these two underlying components as well as we would normally do with Kruskal’s algorithm. So, this is the main body, this is the heart of the computation here.\nAnd after this, all we have to do is a sanity check to figure out if at the end of this we actually managed to build a complete hierarchy or not. So, having built up the MST and kept track of it, I am writing this condition in terms of the number of edges in the MST variable. If we added less than ‘n - 1’ edges, then that means that we do not have a spanning tree. So, we say that this was an impossible scenario that was given to us.\nAnd otherwise, we return the value that we have stored in the answer variable. But instead of the check based on the size of the MST vector, you could equally pull out the number of sets from the UnionFind data structure, and see if that number is > 1, then also, that is an equally valid check for whether we are under impossible scenario or not. So, that is it. That is the entire implementation for this problem. I hope that it made sense.\nIf you want the complete code from which I am sharing snippets here then, as usual, you can just go to the official repository for these videos, there is a link to it in the description. And you should be able to find the complete code there. As you can see, we are writing all this in C++. So, if you have a variation in your favorite language, then please do submit it as a pull request, we always look forward to receiving your versions in other languages.\nSo, we wrap up this discussion here. We have one more module and one more application of MST to discover. This is going to be a problem called ‘island hopping,’ which is a very interesting variation of the basic MST concept. So, I hope that I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/W07/Lec40.html",
    "href": "materials/cpnotes/W07/Lec40.html",
    "title": "M 2 (Cherries Mesh)",
    "section": "",
    "text": "Lecture - 40\nMinimum Spanning Trees - Module 2 (Cherries Mesh)\n(Refer Slide Time: 00:14)\n\nWelcome back to the second module of the seventh week and Getting Started with Competitive Programming. As you know, we are talking about minimum spanning trees this week. And the first problem I want to discuss is this really short and sweet problem called ‘cherries mesh.’ It is literally sweet in the sense that it is based on a ‘dessert preparation.’ And this problem showed up in Google Kick Start 2019 round E.\nAnd if you read the problem, I think you will see quite quickly that it calls for an MST-based solution. However, if you just rush into building up the graph and running your favorite MST algorithm, you might run into a little bit of trouble with the constraints, especially in the large data set. So, you have to do just a little optimization to make sure that your algorithm runs within the given limits. So, let us get started by looking at the problem statement.\n(Refer Slide Time: 01:11)\n \nSo, your friend is recently done with a cooking class. And now he wants to boast in front of his school friends by making a nice dessert. He has come up with an amazing dessert called cherries mesh.\nAnd to make the dish he has already collected N cherries, which are numbered 1 to N. And he has also decided to connect each distinct unordered pair of cherries with a sweet strand made of sugar. So, you can probably already see where the graph modeling comes in. You could quite naturally, I think, think of the cherries as being vertices. And when you see this business about unordered pair of cherries being connected, you obviously think of undirected edges corresponding to these vertices. So, these strands correspond to edges in your graph.\n(Refer Slide Time: 02:05)\n \nWhat we are told is that the sweet strands are either red or black, depending on the sugar content in them. Each black strand contains one unit of sugar, and each red strand contains two units of sugar. So, this, again, quite naturally corresponds to edge weights.\nIf you wanted to visualize this, you know, you could look at an example like this. Notice that all the edges are present. This comes from, again, the problem description, where you are told that every pair of cherries is connected by a strand. So, the only information that makes these strands distinctive is whether they are a black-strand or a red-strand, reflecting the amount of sugar content in them. So, this is the setup. Now let us talk about the task.\n(Refer Slide Time: 02:51)\n \nIt turns out that the desert is too sweet because there are too many edges or too many strands in them. And these days, school friends are dieting, and they usually like dishes with less sugar. So, that is our task now.\nYou want to find out which strands you should remove so that the dessert still hangs together. Okay. So, you want each pair of cherries to still be connected to each other somehow, either by a direct strand or by a sequence of strands. And you want the remaining strands to add up to having the minimum possible sugar content. Now if you read this, this is what I meant when I said that it is reasonably clear that this calls for an MST application.\nBecause if you look at these two conditions, they are exactly like the conditions we spoke about in the first module when we were talking about paving a muddy city. Remember, we said the first condition was that you should be able to go from anywhere to anywhere. The second condition was that the cost of the roads that you build has to be as small as possible. So, these conditions have a very similar flavor.\nThe first condition says that every pair of cherries should be connected directly or indirectly. And the second condition says that you want to minimize the sugar content in the strands that you do decide to keep. So, clearly, what you are looking for, here, is a minimum spanning tree. Although the question in the problem statement is framed as figuring out what you should remove. If you look at the input-output description, you will see that what you are expected to output is the minimum amount of sugar content that will be left behind.\nSo, you are really looking for the cost of a minimum spanning tree in this graph. Now once you recognize this, at least one solution is quite immediate. We just build up the graph and then run our MST algorithm on it. Now for this problem, how do you build up the graph? What are you given? You are given a list of all the black strands. In other words, you are given the list of all the edges that have weight 1.\nAnd it is implicit that every edge that has not been listed is a weight 2 edge or it is a pair that corresponds to a red strand. To make this more explicit, let us just look at the data in the second sample input, or the second test case in the sample input.\n(Refer Slide Time: 05:21)\n\nSo, what you are given is that there are three cherries, and there is one black strand connecting the cherries labeled 2 and 3. So, that is all the information that you have from the sample input. So, when you look at the black edge, you read it in and added to your adjacency lists or your edge lists, as usual, remembering to record also that the weight of these edges is just 1. But now you also have to add all the remaining edges.\nAnd one way of doing that would be, for instance, if you were storing things in an adjacency list, then you could go to every vertex and simply loop through the whole list of vertices and check if these vertices are already present in the list. If yes, then you can ignore them. But if they are missing, then you will add them in with a weight of 2 as we just did here. This will generate your complete graph.\nBut notice that already the complexity of generating this graph is going to be at least n square, which is understandable, because there are n squared edges to be put on the record, given that this is in fact a complete graph that you are working on. In fact, if you just follow the process that I am describing here, using adjacency lists, as I have been suggesting, then you might even need a little more than ‘n’ square time.\nBecause when you are trying to populate the red edges in the adjacency list of some vertex, you have to go through every other vertex, and check if they are already on your adjacency list or not. So, that bit of searching is going to cost you a little bit extra. Now, there are probably ways that you can optimize this. But an easy way of doing this in order n squared time, given that you are committed to spending that n squared time anyway is to simply use an adjacency matrix instead.\nThis is a good point actually to pause the video and try and see if you want to implement this solution, it is a good warm-up to what we are going to see next. And if you actually do this, what you will likely experience is that your solution will work well for the first test set, which has smaller test cases.\n(Refer Slide Time: 07:38)\n\nBut for the second test set, which has the larger tests, you might run into some trouble with these constraints. Notice that the number of vertices can be as large as 105, which means that n square running time will land you in some trouble. Notice also that the number of edges of weight 1 is also guaranteed to be at most 105. So, in some sense, if you look at the subgraph comprised of the black edges – it is sort of a sparse subgraph.\nSo, one question to consider in terms of improving our approach is if we can come up with an algorithm whose running time really depends on the black edges, rather than building up this whole big, dense structure. So, take a moment here and think about this a little bit. Think about, for instance, what would Kruskal’s algorithm do when it is building out the spanning tree. Does it have some special structure, especially in terms of thinking about the black edges first and then the red edges? Come back once you have had a chance to spend a moment reflecting on the whole situation.\nOkay. So, if you think about how Kruskal’s algorithm would work, notice that it will process all the black strands or the edges of weight 1 first before getting to any of the red strands, or the edges of weight 2.\n(Refer Slide Time: 09:03)\n   \nSo, for instance, in this example here, if you were to run Kruskal’s algorithm, you will find that at some point, once you are done processing all the edges of weight 1, you are going to have a spanning forest for the subgraph on the black edges alone. Now the exact structure of the spanning forest on this black subgraph will depend on the nature of the order in which the edges are being processed.\nSo, different runs of Kruskal’s algorithm if ties are being broken differently, might lead you to different spanning forest structures. But the key thing is that the total cost of the spanning forest is going to be the same, no matter how ties were broken, no matter which particular spanning forest you end up on.\nAnd this cost is simply going to be the sum of the sizes of the components in this black subgraph. Of course, you need to subtract 1 from each of those sizes, to get to the actual cost of the spanning forest that you get at the end of this first phase of Kruskal’s algorithm. So, in this example, for instance, we have two components, which have 3 and 2 vertices respectively. So, the cost of any spanning forest on this sub-graph is going to be 3, which is the size of the first component - 1, 3 - 1, 2. And the size of the second component - 1 should be 2 - 1, 1.\nSo, 2 + 1 = 3. And here is what a spanning forest for this graph could look like, for instance. Now, what happens in the second phase of Kruskal’s algorithm, when it is starting to process all of the red edges? Well, all that it would have to do is essentially connect the trees that are there in the spanning forest. And again, there is going to be many different ways that you can do this.\nBut the crucial thing, once again, is that all of them have the same cost. Take a moment to pause the video here and think about what this cost is going to be. And come back once you are ready. Okay. So, if you have ‘k’ components in the spanning forest on the black subgraph, then you are going to need k - 1 edges to connect all of them. And now, since the only edges that remain – that is safe to add – are edges that have a weight of 2, the total cost of extending the spanning forest to a spanning tree, no matter how you do it, is going to be 2 * k - 1.\nIn this example, we have two components. So, we need one edge to tie them together. And this edge will have to be one of the red edges. You can pick your favorite one. And that is it, that would be your final solution. By the way, I said, you can pick your favorite one, which is as long as it is a safe edge, so it has to be an edge that actually connects two components.\nThe key thing is that because you are only being asked for the cost of the minimum spanning tree, you only want to know the amount of sugar that will be left behind after all the strands that can be deleted are deleted. You do not have to actually build up a spanning tree, you just have to compute its cost. Therefore, we do not have to really go through the process of running Kruskal’s algorithm on the whole graph.\nIn particular, we do not even need to build up the whole graph, we can simply work with this sparse black subgraph to just identify how many components are there in the black subgraph and what their sizes are. And this is something that can be done in a fairly natural way using disjoint set union. And we will come to the implementation in just a moment. But I just want you to think about what will the final computation be?\nAnd what is the answer that you are going to output? If you have a piece of pen and paper handy, just see if you could write it out. And then you could come back and tally your solution with mine. Alright. So, the final answer that you want outward is simply the following.\n(Refer Slide Time: 13:18 & 14:22)\n \nSo, it is the number of edges in any spanning forest on the black strands. This is something that you could calculate or just keep track of as you run, you simulate classical Kruskal’s algorithm on the black subgraph. And to this, you want to add the expression 2 * the number of components in this spanning forest - 1, which is to say, the number of red edges is going to be the number of components - 1, but each of them has a cost of 2 units. So, you have a multiplier of 2.\nSo, this is the expression that you want to return. So, you want to make sure that you can compute both of these quantities here, the first being the number of edges in any spanning forest on the black subgraph. The second is the number of components in the spanning forest. Fortunately, we already know how a disjoint set union as a data structure can help us keep track of both of these things. So, let us actually go ahead and take a look at the key part of the implementation.\nSo, by this time, we have actually read in the inputs – n is the number of vertices in the graph. And EL is the list of edges with the weights being the first component of the tuple here. Actually, the weights are not going to matter because we are only working with the black edges. So, this is as good as an un-weighted graph – the path that we are focused on. But nonetheless, just using the traditional edge list format. So I have recorded the edge weights as 1.\nAs always you can find the full code in the official repository. So, there is a link in the description, which you can follow. If you want to look up the part which does the tasks of reading the input in and building up the edge list and so on. But now the first thing we do is create an instance of the UnionFind data structure. This is the same data structure that we used back in week 4. So, we are going to use the exact same code from there.\nAnd we have one-based indexing for the vertices. So, just to keep things simple, I am going to initialize UnionFind with n plus 1 elements, so that I do not have to worry about adjusting the indices as we go along. So, now what we do is we just go through the edge list, and whatever order it does not really matter. Notice that I am not bothering to sort the edge list here. Because once again, there is no sorting that needs to be done. All the edges have the same weight, which is a weight of 1.\nAnd so what is happening here is that you are building a simple spanning forest. You are just seeing if an edge is safe or not. If it is not safe in the sense that it has both of its endpoints, the same component, thereby creating a cycle, then that is an edge that gets ignored. But whenever you have an edge that actually meaningfully connects to components in your current spanning forest, we added and (we) increase the number of edges that go into the spanning tree.\nSo, this is being kept track of in the variable that I am calling ‘answer.’ We just keep incrementing ‘answer’ every time you add an edge to your spanning forest. So, when we come out of the ‘for’ loop, we know exactly how many edges are there in an optimal spanning forest for the black subgraph.\nSo, that is the first quantity in this expression here. And now, once you are done, you need to figure out how many components are there in this spanning forest. And that is something that the UnionFind data structure actually can keep track of for you. And in our implementation of this data structure, we did have a helper function that returns how many disjoint sets there are. And notice that every disjoint set actually corresponds to a tree in the spanning forest.\nSo, the number of components that you are interested in is actually given by the number of disjoint sets in this data structure. Now, the expression that you want here subtracts one from the number of components. But in this code, you might see that we have subtracted two instead. And the reason for this is the silly thing that we did, of initializing UnionFind with ‘n + 1’ elements. So, there is a dummy element there corresponding to vertex 0, which does not really exist in our graph.\nSo, vertex 0 is going to contribute one extra to the count of the number of sets in the disjoint set union data structure. So, this extra -1 is simply to correct for that. So hopefully, that is clear. And this expression is exactly what do you want. And it turns out that this completely solves the problem, even for the larger data sets. So, I hope that this made sense. As always, if you have any questions, please leave them in the comments on this video.\nOr if you are watching this, during an active run of the course you can join us in the Discord community or share your comments over at the mailing list. We will look forward to hearing from you. Next up, is a problem called hierarchy, which is another nice application of minimum spanning trees and that is coming up in the third module. So, I will see you then. Thanks for watching!"
  },
  {
    "objectID": "materials/cpnotes/W07/Lec37.html",
    "href": "materials/cpnotes/W07/Lec37.html",
    "title": "M 1 (Blingor’s Network | Foundations",
    "section": "",
    "text": "Lecture - 37\nMinimum Spanning Trees - Module 1 (Blingor’s Network | Foundations [SPOJ])\n(Refer Slide Time: 00:11)\n\nHello, and welcome to the seventh week of Getting Started with Competitive Programming. This week we are going to be talking about ‘minimum spanning trees,’ which is yet another cool optimization problem in the context of graphs. This problem may, in fact, remind you of some of our discussions of single-source shortest paths.\nBut it turns out that it is really quite a distinctive problem in its own right, and we will contrast it with the shortest path problem as we go along. As usual, we will spend the first module laying down the foundations. We will discuss a couple of popular algorithmic approaches to this problem. They are usually referred to as Prim’s algorithm and Kruskal’s algorithm. As is the case with most of these algorithmic ideas for fundamental graph problems, these algorithms were also co-invented by other people.\nBut we will stick to these names because they are the standard textbook names, and you will have an easier time finding related material if you do it this way. But if you want to find out more about the history of this problem, then I would definitely recommend checking out the relevant chapter in the ‘algorithms text’ by Erickson. There is a link to it in the description of this video.\nSo, what we are going to do is, first, talk about minimum spanning trees – what the problem is, what we are required to do? We will talk about why it is different from, say, single-source shortest paths. In particular, we will talk about why a solution to SSSP may not actually serve as a solution for MST, even though it may be tempting to think of it that way. And then we will talk about Prim’s algorithm, which turns out to be an algorithm that has a flavor very similar to Dijkstra’s algorithm, again, making that connection with SSSP.\nBut really, the mechanics of it are subtly different. And hopefully, you will be able to see the differences and appreciate them. And finally, we will run this off with Kruskal’s algorithm. And you will see that the implementation of Kruskal’s algorithm relies heavily on the disjoint set union, which is something you have already seen in week four. So, that should tie up quite nicely. So, this module is divided into three segments corresponding to these three separate discussions, the introduction followed by Prim’s algorithm followed by Kruskal’s algorithm.\nWe will be testing both of these implementations using a problem on the sphere-online judge called Blingor’s network. It is a very direct ask for a spanning tree. So, all we have to do is make sure that we read the input carefully and then pass it on to the implementations of our algorithms.\nTheir problem statement promises large inputs, so this should be a good way to stress-test the efficiency of our implementations. So, with all that said, let us talk about minimum spanning trees now. I am going to introduce the problem to you through a story, which is a pretty commonplace thing for us to do.\n(Refer Slide Time: 03:04, 03:52, 04:08 & 04:19)\n \n \nBut this is a bit unusual in that the story is borrowed from a resource called CS unplugged. There is a link to this in the description. It is an amazing collection of activities and stories that introduce computational problems. So, if you are interested in follow-up stories, definitely check this out. But let us talk about this one first. So, once upon a time, there was a city that had no roads. Getting around the city was particularly difficult after rainstorms because the ground became very muddy. Cars got stuck in the mud, and people got their boots dirty.\nSo, the mayor of the city decided that some of the streets must be paved. But she did not want to spend more money than was necessary because the city also wanted to build a swimming pool – so they have a limited budget. The mayor, therefore, specified the following two conditions. The first one says enough streets must be paved so that it is possible for everyone to travel from their house to anyone else’s house only along paved roads. So, you want some sort of a ‘connected’ structure to emerge.\nThe second condition is that the paving should cost as little as possible. So, you want to find the best possible way of doing this. And, you know, the cost of paving any particular road, in particular, we have this example, which you are welcome to pause the video at this point and work out if you like. So, the cost of paving any particular road is proportional to the number of stones that are on that road in this picture. Now an obvious way of meeting the first condition is to just pave everything.\nThis will connect everyone to everyone. But notice that you can check that this does not meet the second condition because there are going to be some redundancies. At least in this particular example, you can see that there are many cycles, and that means that you can actually remove some of the roads and still remain connected. And therefore we know that it is not a minimum cost solution.\nIf you just wanted to optimize the budget, then, of course, you do not have to do anything at all, but then you do not actually connect the houses. So, you need something that is in between and it is not surprising that the structure that you are looking for is a tree because that is exactly what captures this notion of being minimally connected. And not only do you want a tree, (but) you (also) want a tree that, well, touches every vertex and has the smallest possible cost in terms of the sum of the weights of the edges.\nIn this case, the weights simply correspond to the cost of paving the road in question. Now for our convenience, let us replace this lovely sketch of the city with a more useful abstraction. It is pretty natural to want to model this using a graph with the vertices representing the houses, and an edge between two vertices, indicating that it is possible to, in fact, pave a road between the corresponding houses, and a number on that edge would record the cost of actually paving that road.\n(Refer Slide Time: 05:51)\n\nSo, what we are looking for in this graph is a subgraph, which is a tree where the total costs of all the edges in the tree are as small as possible. So, please take a moment here and see if you want to work through this yourself in an ad hoc fashion.\nOr if you are already familiar with a systematic approach, then perhaps try to apply it to this example and see what you get. We can tally notes later. Okay. So, before I get to actually talking about how we compute an optimal solution for this example, and also in general, I want to suggest an approach and I want you to think about whether it will work. Remember, I said that minimum spanning trees are reminiscent of shortest paths in the sense that shortest paths intuitively take us from one place to another as quickly as possible.\nSo, why not just start at one of our favorite houses, and just compute the shortest paths to every other vertex. Now perhaps this can be used as a spanning tree. Well, it is going to be a valid spanning tree for sure because you are going to find paths to every other vertex. And this collection of paths can be shown to be acyclic. But on the other hand, the thing to really think about is, does this have the smallest possible cost among all spanning trees?\nIt is fairly easy to come up with examples where starting from a particular house may just be a bad idea. But we can improve on this idea a little bit, we can say, well, let us just try stopping from every possible house, just like we did for APSP. Our first approach for APSP was to run SSSP on every vertex. So, let us just try and do that. For every vertex in the graph, we figured out the shortest path tree, which is just computing the shortest paths to every other vertex.\nAnd then we take the one that is the best among all of these ‘n’ options. Would this work? Just think about whether this would make sense. I think it is a really instructive exercise to play around with some examples. And I think this really emphasizes the distinction between the goals of shortest paths versus spanning trees. Although at some level, they are similar in the sense that you are trying to optimize for somehow some sort of reachability.\nBut the style in which you are optimizing for reachability is relatively local in SSSP, and somewhat more global in MST. And this really does make a difference. So, feel free to pause here and see if you can figure out this puzzle. And when you come back, we will talk about it more. So, since I have been talking about the contrast between these two problems, the answer should come as no surprise to you. Just trying SSSP from every vertex will not solve the MST problem for you.\n(Refer Slide Time: 08:59)\n  \nLet us take a look at this example. So, what we have here is a complete graph on five vertices. The red edges on your screen have a weight of 1.5, while the black edges have a weight of 1. If you think about a solution to the minimum spanning tree problem on this graph, then you can probably predict that any minimum spanning tree actually looks like a path on this outer rim. It just leaves out one edge and takes on all the rest. This is the best that you can hope for.\nOn the other hand, if you were to start off an exploration based on, say, Dijkstra to perform SSSP from any vertex, so let us pick the one on the top here, for instance, highlighted in blue. Think about what would Dijkstra do here? Well, you are going to get the two neighbors first, for sure. That is the best way of getting to those. But for the two vertices that are at the bottom, the best way to get to them is not via the outer rim. It is actually via the direct edge.\nSo, your shortest-path tree will look something like this, and that is going to be the same story no matter which vertex you start from. So, hopefully, this example illustrates the key difference between our goals with a single-source shortest path versus a minimum spanning tree. So, as you can imagine, MSTs will require a slightly different approach. Although one of the popular ways of finding MST, which is via Prim’s algorithm, feels a lot like Dijkstra.\nSo, it is a common question as to whether they are really different. And I wanted to get that out of the way up front by concretely showing you that it is indeed a slightly different problem. Now, before talking specifically about either Prim’s algorithm or Kruskal’s algorithm, I want to make some comments about a generic MST algorithm.\n(Refer Slide Time: 10:44 & 11:06)\n \nIt turns out that most algorithms can be fit into this framework in some form or fashion. So, it is just a useful way to think about MST approaches. So, what you typically want to do is grow a minimum spanning tree by iteratively building it out of a spanning forest of some sort.\nSo, what is a spanning forest of a graph? Well, the vertex set of a spanning forest is the entire vertex set of the base graph that you are working with. But the edge set is essentially some acyclic subset of edges. There is no requirement that these edges should form a connected subgraph. That is what makes a spanning forest different from a spanning tree. So, you think of it as a collection of trees on the vertex set of G.\nAnd some of these trees could be trivial. In particular, they could be isolated vertices. In fact, most algorithms would start with a spanning forest, which is simply all the isolated vertices in graph G. Now, of course, not every algorithm starts here. So, for instance, you could quite naturally think about your starting point as the entire graph G, all the vertices, and all the edges. And then you could try to erase edges away until you are actually left with a spanning tree.\nBut the approach that we are going to be talking about will be building up to a solution as opposed to chipping away at the whole graph till you are left with something minimal. So, as I said, our generic view is that we are trying to iteratively build up a spanning forest till it evolves and matures to being a single spanning tree.\n(Refer Slide Time: 12:22, 12:41 & 12:54)\n  \nHere is what a typical spanning forest may look like at some intermediate stage of your algorithm. Now, at this point, what we want to say for correctness eventually, is that these intermediate spanning forests that we are building are some partial realizations of an optimal solution that exists somewhere.\nThis is what you would need to prove to show the correctness of your algorithm. And while we would not be getting into the proof, let me introduce some terminology that may help you think about how such a proof would go.\nSo, first, when you have a spanning forest, let us classify the edges into a couple of useful categories. The first one is the category of useless edges.\n(Refer Slide Time: 13:05, 13:28 & 13:54)\n  \nThese are edges that have both of their endpoints in the same tree of the spanning forest. Notice that such edges will induce cycles, and therefore we are never going to add them to our solution if we are committed to extending the solution that we have built up so far. So, the nomenclature of calling such edges useless is actually quite appropriate.\nOn the other hand, we talk about an edge being safe for a particular component if it is the cheapest edge among all the edges that have exactly one endpoint in that component. We do want to talk about uniquely identifying the cheapest edges. So, if there are multiple cheapest edges that are getting out of a component, then we will have some previously agreed upon tie braking mechanism.\nSo, again, let us look at our spanning forest here. Let us identify a component as an example. Let us work with this one. And let us say these are all the edges that are coming out of this component. They have one endpoint inside the component and the other endpoint outside. And let us say that the cheapest edge that comes out of this component happens to be this one. Then this is the edge that we will label as being the safe edge for this component.\nNow, one thing to observe is that the same blue edge may not be the safe edge for the other component that it is incident to. So, this yellow component here may have a different safe edge going out of it to some other component. But notice that once you do collect all the safe edges incident on all the components, then they must together be acyclic. Imagine that you do have a cycle among the safe edges.\nJust start traveling on this cycle. You will notice that you must experience that the weights in fact decrease as you go along. So, you will get a contradiction by the time you hit the end of the cycle. So, just think about this a bit. And I just want you to preserve this intuition that all the safe edges at any stage of your algorithm must, in fact, be acyclic. And in fact, you can show which we will come to in a moment that these safe edges are called safe because they actually do belong to an optimal MST. So, you can pick them without thinking.\n(Refer Slide Time: 15:22 & 15:36)\n \nBut before we get to that, let us also label all the remaining edges as undecided. So, you could have edges that are neither useless nor safe. So, these are edges about which we do not know much, and we will just call them undecided.\nSo, the key to the mechanics of most algorithms is the (following) fact that there is going to be an optimal solution, which does not contain any (of the) useless edges and contains every safe edge at every iteration of your algorithm. As I said, one intuitive thing to appreciate is that adding the safe edges will not violate the structure of the subgraph that you are looking for – the safe edges are already acyclic. But it does require proof that these are the best edges for your solution in terms of the cost.\nIn fact, what we are doing here has a really strong greedy vibe to it. We are seemingly focusing on edges that are locally the cheapest with respect to a component. And it is not obvious at all, that this would be the right thing to do long term. But it turns out that it is and once you know the correctness of the statement, then an algorithm, in fact, naturally suggests itself. Right. What you could do is start with all the isolated vertices, identify all the safe edges. This just amounts to going to every vertex and asking who is the neighbor that is the closest to you.\nAnd once you have the answer to all of these questions, then you (just) have identified all the safe edges so you can freely add them to your solution. If at this point your graph becomes connected, that is fantastic. If not, and it may not be in fact. You can think of examples where you do this once, and you could be left with a graph that has as many as n by 2 components, for instance. So, your graph may not be connected.\nBut you could just repeat this process. You go to every component, and you ask, what is the cheapest edge that is incident on you? Again, having identified the safe edges, just add them to the solution. And repeat this until your graph in fact becomes connected. You can show that in every step, the number of components will in fact go down by half. So, the number of iterations that you have to repeat this process for is in fact only logarithmic in the number of vertices. You do have to think about the cost of identifying the cheapest edges that go out of components.\nAnd this is actually a good exercise to go through and this is a perfectly valid MST algorithm. It is a little bit different from the ones that we are going to discuss. But it is very natural from the observations that we have set up so far. So, I just wanted to point it out to you as a fun thing to think about. The more traditional approaches which are Prim’s algorithm and Kruskal’s algorithm are the ones that we are going to discuss in the next two segments. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/W09/Lec48.html",
    "href": "materials/cpnotes/W09/Lec48.html",
    "title": "MaxFlow-MinCut Duality",
    "section": "",
    "text": "Lecture - 48\nMaxFlow-MinCut Duality\n(Refer Slide Time: 0:11)\n\nWelcome to the ninth week of Getting Started with Competitive Programming. So, this week we continue our exploration of network flows. But our perspective this time is going to be slightly different from the one that we had last week. So, if you remember, in week 8, our goal was to find a maximum valued flow in a flow network. So, the goal was to push as much material as we could from a designated source vertex to a designated target vertex.\nThis time, our goal will be somewhat the opposite. We want to see what is the minimum amount of damage that we need to do to the network to make sure that the target is unreachable from the source. So, this is called the problem of finding a minimum cut. And it turns out that it is intimately related to the problem of finding a maximum flow. In fact, so much so that without knowing it, you have already learned an algorithm to find a minimum cut because the Ford-Fulkerson’s algorithm for finding a maximum flow as a by-product automatically finds a minimum cut as well.\nNow, as you can imagine, the minimum cut problem has a variety of applications. One that is easy to visualize but probably a bit depressing to think about is war strategy. So, let us say that you are planning out an attack on the enemy camp. And what you are trying to ensure is that no useful supplies reach them from the other side. Then you may want to strategically destroy roads so that all connections are cut off. You either destroy roads or monitor them, whatever you do.\nNow, monitoring or destroying is expensive. So, you want to be able to identify the smallest number of key roads or locations that need this kind of attention. Minimum cuts are also interesting because they give you a sense of the weak points in your network. Right. So, if you have a minimum cut at hand, then you know that if these edges were to be destroyed, then you lose all contact between the source and the target.\nSo, by identifying such minimum cuts, you may get ideas for how to strengthen your network and make it more robust. That goes into the realm of something called network design, which is a very interesting topic if you want to find out more about it. In the meantime, let us go ahead and talk about the relationship between MaxFlows and MinCuts, which is the topic of this module here.\n(Refer Slide Time: 2:32)\n\nSo, what is a cut? Formally, it is a partition of the vertex set of a flow network into two parts, which we will typically denote by capital S and capital T. So, these capital letters correspond to vertex subsets. And the only thing that this partition must satisfy is the constraint that the source vertex belongs to one of the parts and the target vertex belongs to the other part. That is all that we need. Other than that, you could distribute the remaining vertices however you like, and it will still be a valid S-T cut. Let us take a look at an example of an S-T cut.\n(Refer Slide Time: 3:05 and 3:35)\n  \nHere is a flow network. The capacities are not shown here because they are not so relevant at the moment. You have the source vertex S, and the target vertex T on the extremes of your screen. And you will notice that all the green vertices, being the set capital S and all the red vertices being the set capital T forms a valid S-T cut in this particular flow network. Now, given a cut like this, we are specifically interested in edges that cross the cut. What do I mean by this?\nWell, an edge from u to v is set to cross the cut if u belongs to S and v belongs to T. So, in this example, once again, you can see that these are all the edges that cross the cut. They have been marked in pink. And hopefully, you agree that this is consistent with the definition that we just gave. Now, what is the capacity of this cut? Well, you just add up the capacities of the edges that cross the cut, and that is going to be the capacity of the cut. Okay.\n(Refer Slide Time: 3:59 and 4:08)\n \nNow, think about what happens when you delete all the edges that cross an S-T cut. Take a moment, if you would like to go back to the example and see what happens. And see if you notice something particularly spectacular that happens when you remove all the edges crossing any S-T cut.\n(Refer Slide Time: 4:25)\n  \nWell, let us actually look at what happens in this example. So, we have these edges that cross the cut. And here is what you get when you remove these edges. Notice that when you do this, you have removed all possible connections from S to T. So, I would like to claim that this is true not only for this example but in general. If you were to delete all the edges that cross an S-T cut, then you end up disconnecting S from T in this graph, which is to say that after these edges are gone, there is no way for you to travel from S to T along a valid path.\nTo see why this is true. Let us assume that all the edges in an S-T cut have been deleted. And let us suppose for the sake of contradiction, that you still have a path from S to T. And let us say that path looks like this. So, clearly, just by definition, this path starts from the source vertex and ends at the target vertex. Now, let us label the intermediate vertices of this path depending on which side of the garden they belong to. So, just for simplicity, you could think of coloring these vertices green or red, depending on whether they belong to capital S or capital T. Right.\n(Refer Slide Time: 5:07)\n \nSo, when we go ahead and do that, notice that at some point, you must change color on this path because it is starting with a green vertex, and you are ending at a red vertex. So, at some point, there must be two consecutive vertices on this path, which have opposite colors. Right. So, if you can find such a consecutive pair, then you have also found an edge that crosses the cut.\nBut remember that this edge is not there because we deleted all the edges that cross the cut. Therefore, this particular path has been destroyed and is in fact not there. So, depending on your taste, you can think of this as proof by contradiction, which simply says that this claimed path does not exist. Or you could think of it as a constructive proof, which says, well, let us go and examine every S-T path turn by turn.\nAnd let us argue that at least one of the edges on any of these paths was, in fact, destroyed when we deleted all the edges in an S-T cut. Either way, the point is that removing all the edges in an S-T cut disconnects S from T. And that is why a cut, which has the smallest number of edges that crosses it, would correspond to a minimum effort way of destroying all connections between the source and the target, which was sort of the original goal that we set out for ourselves when I was introducing the MinCut problem back at the beginning of this discussion.\nAlso, recall that we are working with edges that have capacities and you could think of these numbers as being a reflection of how expensive it is going to be to destroy a particular edge. You can imagine that if these edges are modeling a road network, then a six-lane road, which of course has a large capacity is going to be more effort to destroy compared to some kaccha-pakka road, which has a capacity of maybe one bicycle at a time or something like this. Right.\nSo, this naturally motivates the definition of a minimum cut as being a cut, which has the smallest capacity. Once again, remember that the capacity of a cut is simply the sum of the capacities of all the edges that cross the cut. Alright. Now, that the definitions are out of the way, it is time to make our first connection between flows and cuts. So, here is a preliminary claim.\n(Refer Slide Time: 7:43 and 8:23)\n \nI want to say that the value of any valid flow in a flow network is at most the capacity of any S-T cut. Please feel free to pause the video here and just absorb this statement and see if you find it intuitive. See if you can come up with your own reasoning for why something like this would be true. Come back once you are ready.\nAlright. So, we will not be proving this formally. If you are interested in proof that involves proper inequalities and everything, you can take a look at the references that have been linked to in the description. But what I will try to do instead is convey the main intuition for why you might expect this to be true.\nSo, let us consider any flow ‘f.’ Right. And let us fix an S-T cut, S-T, which is capital S capital T. Let us think about what happens if the value of ‘f’ exceeds the capacity of the cut S-T. Alright. So, let us go back to our example here.\n(Refer Slide Time: 8:39)\n\nSo, notice that the highlighted region on the left is the set capital S. Right. And we have that this cut has a certain capacity – could be whatever you like. And let us say that you have managed to push your flow from S to T, which is higher, the value of this flow is greater than the capacity of this cut. Now intuitively, you can think of the cut as being some sort of a bottleneck between S and T.\nIt tells you, remember, when we were working with the trucks, right, we said that, well, there is only so much that you can push from S to T if this is going to be the situation that all of your trucks have to take one of these three roads that have been marked in pink. So, that essentially gives you a ‘bound’ for how many trucks can go through from S to T. So, in other words, if you have managed to push a flow whose value is more than the capacity of these three pink edges combined, then some of that flow is actually stuck on the yellow side of this network.\nIt cannot get out, it cannot go to the other side. But remember when we introduced the flow problem, we also talked about how the flow that goes out of the source is the same as the flow that lands on the target. So, it cannot really be that some of your flow is stuck on one side of the graph and does not reach the target. If that is happening, then somewhere you have violated the conservation constraints.\nSo, if you write down a few equations that involve starting from the starting value of the flow and relating it to the capacity of the cross edges, and applying the conservation constraint, you will see that you will end up with a contradiction if you start off with a flow that is more than the capacity of this particular cut.\n(Refer Slide Time: 10:27)\n\nSo, what we know is that the value of any flow is bounded by the value of any cut. In particular, we could set this flow ‘f’ to be the MaxFlow, and we could choose this cut to be the MinCut, which tells us that the value of the maximum flow that you can achieve is bounded by the capacity of the minimum cut in this flow network. So, what we have discovered so far is that the capacity of a minimum cut gives us a target for the maximum value of the flow that we can hope to achieve. Right.\nSo, if you found a minimum cut and it has some capacity, then this is the best that you can hope for in terms of how much flow you can push from the source to the target. Now, the interesting question is, is this an achievable target? Can you always push this amount of flow corresponding to the capacity of our MinCut from S to T? And this is the question that we will try to address next. Now, let us take a look at the flow that we get from the Ford Fulkerson algorithm. The first thing I want to point out is that this algorithm already gives us an S-T cut.\n(Refer Slide Time: 11:35)\n\nSo, let us look at the residual graph that we get in the last iteration of Ford Fulkerson. Remember, we stop when we are not able to find an S-T path in the residual graph anymore. So, let us look at all the vertices that are reachable from S in the residual graph that we obtained at the last step, the step where we got stuck. Notice that this set of reachable vertices does not contain the target vertex T because if it did, then we would not be stuck here. We would have found a path, and we would have augmented the flow along this path. Right.\nSo, we know that the set of all vertices that are reachable from the source in the residual graph at the end of the Ford Fulkerson algorithm is actually a set that contains the source vertex, and it does not contain the target vertex. That sounds familiar. Right. So, that is essentially a cut. So, you know that this is a valid S-T cut. And this is going to be a particularly interesting cut to work with.\n(Refer Slide Time: 12:33 and 12:59)\n \nLet us say that this particular cut has a capacity of C. Now I want you to think about what is the value of the flow that the Ford Fulkerson algorithm has found in terms of this capacity C. Pause the video here for a moment and just think about whether there might be a connection. Alright. So, it turns out that the value of the flow that is found by the Ford Fulkerson algorithm is also C.\nOkay. Let us try to think about why this might be the case. But before we do that, let us say we believe this for the moment. Then notice that your algorithm has also found a minimum cut. Right. Because you have a flow whose value is C. You have a cut whose capacity is C. You know that this flow whose value is C is actually the maximum possible value of any flow in this flow network. So, you know that you cannot have a cat whose capacity is smaller than C. Right.\nBecause then this would violate the first inequality that we saw. So, in fact, the set of vertices that is reachable from S in the residual graph at the last iteration of Ford Fulkerson is also a minimum cut. The fact that that is a minimum cut, of course, relies on this observation here, which is that you have a flow whose value is equal to this capacity.\nSo, again, let us try and see why this is true. Like before, I will not be proving this formally, but hopefully, I will be able to share enough ideas based on which you can go and work out the details of a formal proof. So, to begin with, let us try to understand the value of a flow in terms of the edges that go between the parts of a cut.\n(Refer Slide Time: 14:18)\n \nSo, in particular, let us fix a flow ‘f’ and let us fix an S-T cut, capital S capital T. Right. Now, it turns out that the value of the flow is the sum of the flows on the edges that cross the cut, and you have to adjust for the flow that is coming back from T to S. So, you also add up the flows on the edges that originate in the set capital T and have the other endpoint in the set capital S. And all the flow that is coming on these so-called back edges, you need to subtract this from the total flow that is going on the cross edges.\nSo, if you do that, the resulting number that you get will equal (to) the value of the flow itself. Now, if you think about it, this is fairly intuitive. It is essentially because of the conservation constraints that the amount of flow that you were able to push from S, or the amount of flow that lands at T, can also be understood in terms of, you know, the amount of flow that crosses any of these intermediate cuts.\nAnd you really want to be looking at the net flow that crosses this intermediate cut, which is the flow that is on the cross edges adjusted for the flow that is coming back into the set capital S. So, again, this is something that you can confirm by a fairly straightforward calculation, which I will not get into. But once you understand that this is true, let us look at what is going on in the cut that is finally discovered by the Ford Fulkerson algorithm.\nSo, let us say that this cut that we are looking at is specifically the cut, which is obtained by considering all the vertices that are reachable from S in the residual graph in the last step of the Ford Fulkerson algorithm. So, now what is happening on the forward edges, which are the cross edges? Notice that each of these edges must be fully saturated by the flow. Because if they are not fully saturated by the flow, then in the residual graph, these edges would still be present with the residual capacity, which means that if you look at the vertices, which are sitting in T right now, at the other ends of these two blue edges, these vertices would not be in T, if these edges were not fully saturated.\nThey would still be reachable from S, and they would be pulled to the other side. So, hopefully, it is clear that the edges that are crossing this cut must be fully saturated by the flow. Again, if this was not the case, then your ‘cut’ would not be looking like this. Okay. So, we need all of these edges to be missing. The only way to make these edges vanish in the residual graph is by fully saturating them so that their residual capacities are 0.\nOn the other hand, let us look at these back edges in the flow network. Okay. So, these edges, I claim, cannot have any flow going through them. Because if you send any flow going through these edges, then in the residue graph, you would have introduced an artificial edge, which goes in the other direction, which would have a non-trivial capacity.\nAnd once again, this would not be an accurate picture of the cut that you obtain at the last step, and you would get a contradiction. So, in fact, if you look at the S-T cut that you obtain, at the very end of Ford Fulkerson, the cut that is obtained by looking at the vertices reachable from S in the residual graph at the last iteration, then it must be the case that your MaxFlow, again, as discovered by Ford Fulkerson, must have the following form.\nIt saturates fully all the edges that cross this cut, and it does not touch the edges that come back from this cut, which is to say, edges that start in T and end in S, these I just do not have any flow going through them. Again, the reason for this is that if the flow did not look like this, then this cut also would not look like this, okay, and that is what we just discussed.\n(Refer Slide Time: 18:18)\n \nSo, essentially, the value of this flow is in fact equal to the capacity of this cut. And both the flow and the cut have been discovered by this Ford Fulkerson algorithm. And we know from our previous discussions, that this flow is in fact, a max flow, from which we can conclude that this S-T cut must, in fact, be a MinCut.\nThis is something that we also mentioned a while ago because notice that if you have a cut, which was smaller than this, then this flow would have trouble getting through. Right. So, Ford Fulkerson witnesses the fact that the minimum cut target is, in fact, achievable. And it also finds this minimum cut for you. So, what more could you ask for? So, in the next module, where we look at a problem that requires you to find the MinCut, we will see how to adapt our implementation slightly, so that we can find this MinCut and work with it.\n(Refer Slide Time: 19:16)\n\nIn the meantime, if you had to have one major takeaway from this module, it would be this equality, the equality of the value of the MaxFlow, and the capacity of a MinCut. The fact that the value of the maximum flow is bounded above by the capacity of a minimum cut, I think, is pretty intuitive. And that is something that can be appreciated just pretty much directly from the definitions.\nBut the fact that this upper bound can always be achieved, and the fact that that is a consequence of Ford Fulkerson, you have a constructive way of getting there, I think, it is absolutely amazing. And this is one of the most elegant dualities in graph theory and it can be used as a basis for proving some other very interesting dualities as well. And we will see one example of that in the last module this week.\nIn the meantime, we would like to talk about how you can implement the process of finding a minimum cut. Because you have already implemented the MaxFlow algorithm, this turns out to be super easy to do. And that is what we are going to see in the context of this specific problem in the next module. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/W09/Lec49.html",
    "href": "materials/cpnotes/W09/Lec49.html",
    "title": "Police Chase",
    "section": "",
    "text": "Lecture - 49\nPolice Chase\n(Refer Slide Time: 0:11)\n\nWelcome back to the second module in the ninth week of Getting Started with Competitive Programming. So, in the previous module, we just saw (about) the deep relationship between the value of a maximum flow in a flow network and the capacity of a minimum cut in the same network. In this short follow-up module, I want to talk about a problem that will give us an opportunity to implement the minimum cut algorithm that we hinted at last time.\nSo, this one is called ‘police chase.’ It is a problem that you can find in the graph section of CSES. If this is the first time you are solving a problem on the CSES platform, you will need to set up an account, but that is very quick and easy to do. So, there is, as always, a link to the problem in the description of this video. So, I hope that you can check it out and follow along.\n(Refer Slide Time: 0:56)\n\nSo, here is the problem statement. Kaaleppi, I hope I am pronouncing that right. Kaaleppi has just robbed a bank and is now heading to the harbor. However, the police want to stop him by closing some of the streets of the city. What is the minimum number of streets that should be closed so that there is no route between the bank and the harbor? So, I am going to assume that our friend is just finished robbing the bank and is at the source vertex, which corresponds to the bank here, and the police want to shut off some of the roads so that no matter what our friend does, he is not going to be able to reach the harbor.\nSo, you can probably already see where this is going. You want to model the streets in the city as some sort of a flow network. And you want to think of the bank as the source and the harbor as the target. And, of course, your goal of closing off the smallest number of streets so as to cut off all the connections from the bank to the harbor is going to correspond to a minimum cut in this flow network. Let us take a look at the example that is given as the sample input in the problem statement.\n(Refer Slide Time: 1:57)\n\nSo, we have four locations. The bank is always the location with index 1. And the harbor is always the location which has index n, which is the number of vertices. In this case, n is 4. So, the source and the target are shown as the green and the red vertices here. The remaining edges are as shown. And if you like, you can pause here for a moment to think about what would be the best solution in terms of what would be the smallest number of roads that you can remove to disconnect the bank from the harbor.\nAlright. If you stare at this for a minute, you can probably conclude that it is not enough to remove just one edge. You could try each edge in turn, for instance, and realize that you are going to need at least two edges to disconnect the source from the target in this example. And it turns out that two edges are in fact enough. So, for example, you could try to delete these two edges here. And you will see that once you do that, you disconnect the harbor from the bank.\n(Refer Slide Time: 2:59)\n\nSo, pretty much just by definition, what you are looking for is a minimum cut between vertex-1 and vertex n. And as I said before, this is something that we are very well equipped to do by now because we already have an implementation of the Ford-Fulkerson algorithm. So, the idea is to find a maximum flow, and then look at the residual graph that you obtain at the end of this process. And look at all the vertices that are reachable from the source. And that is going to be your minimum cut. And what you want to return is the edges that cross this cut. So, let us take a look at how we are going to do this in the implementation.\n(Refer Slide Time: 3:39)\n\nSo, here is what we are going to do after we have finished reading (in) the graph and running the Max Flow algorithm on it. So, the process of reading the graph (in) and running Max Flow on it is completely straightforward. The input is given in a very convenient way. So, you just have to keep reading the edges and adding them to your Max Flow object. And you can simply invoke the Edmonds Karp function after you have built up the graph. So I am not showing you that part of the code.\nBut in case you would like to take a look, you can find it in the usual place in the official repository. And there is a link in the description as always. So, after (all) this is done, what we want to do is find the set of vertices that are reachable from the source vertex, which in this case is the vertex labeled 1. So, we are going to do this using a helper function called reachable_set.\nAnd I am going to talk about how reachable_set is implemented in just a moment. But again, if this is something that you want to try and do on your own, it is a very good exercise. All you have to do is copy-paste the BFS implementation, and just introduce a variable that can keep track of all the vertices that you encounter in the process of running the BFS from the source vertex. So, feel free to try that out on your own. This would be a good point to pause the video and play around with your own implementation, and you could come back and exchange notes.\nSo, let us say that we have some implementation of reachable_set. As I said, we are going to get to that next. But let us suppose that we stored in the variable ‘scomp,’ the set of all vertices that are reachable from the source. Now, the next thing that we do is run a little loop that goes through all the vertices, and figures out, which (are the ones that) do not belong to ‘scomp.’ This will be the set ‘t.’ The reason we want to build out ‘t’ explicitly is because it is just going to help us identify all the edges that cross the cut, which is, in fact, the solution that we are interested in.\nNotice that in the police chase problem, you are actually asked to output a set of edges corresponding to streets that the police can block off. So, if you just had to output the number of streets that need to be blocked off, you do not need to do any of this, you can simply return the value of the Max Flow, and you would be done. However, in this problem, and in many problems of this kind, you are often asked to explicitly output some valid solution.\nAnd fortunately, as we have discussed, the Ford–Fulkerson algorithm automatically gives us access to a minimum cut. And all that remains to be done is to identify all the edges that are crossing this cut. Now, of course, to do this, you do not have to explicitly identify the set ‘t’ like I am doing here. You could instead simply loop over all the vertices in s, look at the edges that are incident on these vertices, and identify all those edges that have their other endpoints, essentially not being in s.\nAnd that is an alternate way to discover all the edges that are crossing the cut. I just found this more convenient to just interpret visually. So, that is why I am doing it this way. So, the first for loop here essentially identifies all of those vertices that do not belong to ‘scomp,’ which is the part of the graph that is reachable from s in the last residual graph from Ford–Fulkerson. And this essentially constitutes our set ‘t,’ which we are calling ‘tcomp’ here.\nFinally, what we do is run a nested pair of ‘for’ loops, which essentially goes through all pairs of vertices, such that one of them is in s and the others in t. I have written a small helper function that just tells me whether a pair of vertices is an edge or not. So, if ‘i comma j’ is an edge, and i is in ‘s,’ and j is in ‘t,’ then I am going to add this to my cut. In this case, I am just printing it out directly.\nBut you could also store it in a solution in case you need to use the cut for something else going forward. For this problem, it is just enough to print this list of edges, and you are done. Now, let us just take a quick look at how reachable_set works.\n(Refer Slide Time: 7:39)\n\nSo, this should look very familiar because it is essentially the BFS sub-routine. But I have decluttered it a bit so that I do not have to keep track of parent information because that is not so relevant here. But instead, we have introduced an ‘answer’ variable, which essentially is going to just keep track of all the vertices that we meet as we do this BFS.\nSo, every time we see a new vertex, just after we push it back on the queue, we also add it to the answer vector. And we just return ‘answer’ that is the set of all the vertices that are reachable from s. By the way, if you are just following along on the video and writing your code, as we discuss, then notice that there are parts of this function that are missing. So, in particular, all of the initialization is missing.\nAnd you will need to declare the variables. Make sure that the queue has the word access, to begin with and that the distance vector has been initialized appropriately. And that the distance of the source vertex is set to 0. So, these are a few things that you do not see on the slide. But you can once again find the complete code in a link that is there in the description. So, you can refer to that instead if you are looking for a fully workable code, but ideally, you are just trying to write this out yourself as well. Just for good practice.\nHowever you choose to do it, I hope that you end up with a working implementation that makes you feel confident about tackling problems that are based on MinCut going forward. In the last module for this week, which is coming up next, we will look at a slightly more sophisticated application of MinCut. And while we are at it, we are going to learn about another fundamental and truly beautiful duality theorem in graph theory. So, I cannot wait to tell you about that. We will see you in the next video. Thanks for watching!"
  },
  {
    "objectID": "materials/cpnotes/W09/Lec50.html",
    "href": "materials/cpnotes/W09/Lec50.html",
    "title": "Minimum Vertex Cover via Max Flow | SAM I AM (UVA 11419)",
    "section": "",
    "text": "Lecture - 50\nMinimum Vertex Cover via Max Flow | SAM I AM (UVA 11419)\n(Refer Slide Time: 0:11)\n\nWelcome to the third and the final module in week 9 of Getting Started with Competitive Programming. So, we have been talking about network flows all along. And this week, the emphasis has been on the minimum cut problem, which by now we have learned is essentially the same as the maximum flow in terms of its value. And we also know how to use our Max Flow algorithm to actually find a minimum cut. So, now we are going to put all of this to some good use on a particular problem that does not directly ask for a minimum cut.\nBut it asks for a different quantity, which it turns out can be found quite nicely with the help of a minimum cut. So, let us take a look at this problem called SAM I AM, which is on the UVA platform. And there is a bit of a story and a background which I am going to kind of skip, but I will tell you what is going on in some sort of averaged form. If you want a little more background on the fictional part of it, then please take a look at the link in the description of this video.\n(Refer Slide Time: 1:12)\n \nSo, here is what is going on, there is some sort of war in the background. And at some point, our protagonist Sam has ended up in a temple, which has some of his enemies. So, it turns out that the temple has a rectangular shape. And Sam has the locations of all the enemies in the temple. It may sound like this is something to do with coordinate geometry because we are given a rectangular region and maybe the locations are points.\nBut it turns out and this is something that you will discover, if you take a closer look at the problem statement, that the situation is a lot more discrete. So, by this rectangle shape, what is meant is a grid. And by locations, we are simply given information about some specific cells in this grid. So, every cell is specified by a row number and a column number that pins down the address of that cell if you like.\nAnd we are given the addresses of all the cells in which we have enemies waiting for us. So, what are we going to do about these enemies? You might be thinking that this is going to involve going into the temple, and finding some sort of an optimal sequence to fight everybody off, and so on.\n(Refer Slide Time: 2:23)\n \nBut it turns out that our friend, Sam, realizes that he can kill all of these enemies without even entering the temple by using some special weaponry that he has access to. So, it turns out that he can attack the temple from the outside. And this machinery is going to essentially release a cannonball, which will be able to destroy everything that is on a single row or a single column of this grid in one shot. So, let us take a look at how this might work for our example from before.\n(Refer Slide Time: 2:53)\n  \nSo, you could shoot cannonballs through rows 2, 3, 5, and 6. And this would take care of all the enemy locations. Or you could shoot cannonballs through columns 2, 3, 5, and 6. And this would again, take care of all the enemy locations. Think about if there is a way that you can use a smaller number of cannonballs in total, and still take care of all the enemies. Remember that you are not obliged to only attack just the rows, or just the columns, as we have been doing here, you could mix them up, just see if you can find a more optimal solution in the sense of using fewer cannonballs.\nAlright. Hopefully, you had a chance to think about that. And it turns out that if you indeed combine the row and the column forces and take advantage of them simultaneously, then you can get away with just using 3 cannonballs. And this is one of the ways that you can do it. And perhaps you can come up with other ways of doing this as well. Now, think about whether you can do with fewer than 3 cannon balls. Is it possible to push this even further? Feel free to pause the video here at this point and think about this for a moment.\n(Refer Slide Time: 4:10)\n\nAlright. So, you might discover that there are these three enemy locations here that happen to not share a row or a column. Meaning that any two of these locations are on different rows as well as on different columns. Because there are three such locations, notice that you are going to need 3 distinct cannon balls to take care of these 3 locations because there is no cannonball that will be able to hit two of these locations at once, simply because they are neither share a row nor share a column.\nSo, this solution that we just had with three cannonballs is the best that you can hope for in terms of minimizing the number of cannonballs, which turns out to be the optimization objective that is handed out to us.\n(Refer Slide Time: 4:52)\n\nSo, the task in this problem is to come up with a solution that uses as few cannonballs as possible to eliminate all the enemies that are in the temple. So, that is the problem statement. And I hope that at this point, all the details, at least about the question, are clear. You might guess that we want to solve this by setting up some sort of a flow network that encodes all the information that is there in this problem.\nAnd hopefully, either a flow or a cut in this network will give us what we want. So, feel free to take a pause here and walk up and down a little bit and think about what would be a natural graph to associate with all the information that you have here. Now, our modeling of this problem as a flow network is going to set up the foundation for the success of the rest of the solution. It is also the part of the solution that I think requires the most imagination.\nSo, once somebody gives you the flow network, you might be wondering: How do you expect me to come up with something like this? So, that is a fairly natural question. And the best answer that I have at this point is to just practice a lot of these problems. Right. And you can find some more in the extras section of the course website. So, I definitely encourage you to take a look at that. And think about how the modeling will work.\nUnfortunately, there is no formulaic approach to this. So, you just get better at it with experience. The more examples you see, the more intuitive the process becomes. And over time, you will just get quicker at the process. And it is also perfectly fine to stumble around a bit and do work with a few ideas that do not work at first, and you keep needing to sort of nudge them and morph them into something that eventually works. It is all a part of the process, really.\nSo, once again, if you want to take this up as a bit of a challenge, you want to pause the video here and think about what would be a way to model the information in this problem as a graph. And when you are ready, just come back so we can exchange notes. Alright. So, at this point, I am going to introduce you to the flow network that we are going to build based on the information that we have about enemy locations in the grid.\n(Refer Slide Time: 6:58)\n \nSo, what I am going to do, to begin with, is I am going to introduce vertices corresponding to the rows and the columns of the grid. Okay. So, in this example, we have 7 rows and 7 columns. So, that corresponds to 7-row vertices and 7-column vertices. And that is what I will continue to call them throughout this discussion.\nNow, how do I want to introduce the edges? I would say this is pretty natural. I want the edges to capture information about the locations of where the enemies are. So, in particular, we are going to add an edge between the vertex that represents the ith row and the vertex that represents the jth column, if and only if there is an enemy at the location given by the intersection of the ith row and the jth column. So, just to be clear about this, let us play this out in this example by looping through all the enemy locations given to us.\n(Refer Slide Time: 7:46)\n  \n  \nSo, let us look at the one that is on the second row in the sixth column. To remember this location, I am going to add an edge between R2 and C6. Then we have the one that is on R3 and C2, so we are going to add an edge from R3 to C2. Then we have this one here, that is again on C2 and a row 5. So, we are going to add this edge between R5 and C2.\nAnd again, we have another location on the fifth row, this time on the fifth column. And that is again going to be remembered by adding this edge between R5 and C5. And finally, we have this location which is on the sixth row and the sixth column. And that is going to bring in this edge between R6 and C6. So, that is essentially the graph that we construct. And at this point, we can completely forget about the grid. This graph essentially captures or encodes all the information that we have about the enemy locations. So, this is the graph that we will be working with.\n(Refer Slide Time: 8:37 and 8:41)\n  \nAgain, just to recap, this is how we constructed the graph. The graph had a vertex for every row and a vertex for every column. And we dropped edges between row-column pairs whenever the corresponding locations had enemies between them. Now, let us also think about what we should be looking for in this graph. Remember, we are trying to fire the smallest number of cannonballs that takes care of all the enemies.\nThe cannonballs can be fired either on a row or on a column. So, naturally, cannonballs correspond to vertices. They correspond to the rows and the columns on which the shots are going to be fired. But now, what do we want to achieve by firing these cannonballs? We want to be able to knock out all the enemy locations. These enemy locations have been modeled as edges.\n(Refer Slide Time: 9:32 and 9:56)\n  \n\nSo, essentially, what we are looking for is a subset of vertices that is incident on all the edges in our graph, which is to say that if we remove these vertices, then all the edges would go with them. Okay. So that is what we are looking for. In graph theory parlance, such a subset of vertices is called a vertex cover. So, I might use that phrase now and then to refer to our solution.\nAlright. So, let us now go back to the graph. And remember, what we are looking for is a vertex cover of the minimum possible size. A vertex cover that involves the smallest number of vertices. Now to find this minimum vertex cover, we want to take help from the Max Flow algorithm. So, we have to expand on this graph and turn it into some sort of a flow network. So, let me give you a hint in terms of what sort of a flow network you might want to build.\nRemember that you have already seen how we can use flows to find maximum matchings. Why am I bringing up matchings? Well, remember what we said earlier about a lower bound on the number of cannonballs that we need to fire. We said that if you have a collection of enemy locations that share no common row or a common column, then all of these locations require their own cannonball to be fired to take care of them. Right.\nThat is how we said that the solution with three cannonballs was optimal for the example that we were looking at earlier. So, what does this sort of a collection of enemy locations that have no rows or columns in common correspond to in this graph? Take a minute here and think about this. I have already hinted at what it might be. But still, Pause the video here and come back when you have had a chance to think through this.\nAlright. If you have a collection of enemy locations, which have no column or no row in common, then that corresponds to a subset of edges that do not share any vertices. But this is precisely our notion of a maximum matching. Right. So, it is at least a notion of a matching. And if you wanted the best possible lower bound on your solution, you would want to find a maximum matching because that gives you the most information. It tells you well, you are definitely going to need at least so many cannonballs.\nSo, let us try and borrow from what we have seen before and build the kind of network that we would have built if we were looking for a maximum matching in this graph. So, remember, the way we did that was to introduce a source vertex that was adjacent to all the vertices on one side of this graph. And we also added our target vertex. And we said everybody on the other side was going to be adjacent to the target vertex. So, I did not say this explicitly, but it should be visually evident that we are working here with a bipartite graph.\nAnd all the edges, of course, have one endpoint in the row vertices and the other endpoint in the column vertices. So, it is pretty natural to set up this flow network. And we could start off by saying that all of the edges (that are) incident to the source and the target vertices have unit capacity. This was crucial to ensuring that what comes out of the flow corresponds to a matching. When we model the matching problem, we also said that all the edges that go in between have unit capacity as well because that did not make a difference.\nBut it turns out that because it does not make a difference, it is going to be more convenient for us to think of the interim edges as not having any capacity constraints at all. And we will see why this makes our lives easier a bit later. So, what we are going to do with the edges that are in between is that, as before, we will orient them from left to right, which is to say that all the edges are sourced on the row side and have their target on the column side.\nIn this case, by target, I just mean where the edges end. So the direction is that they are pointing from rows to the columns. So, we will orient them like that. But we will say that these edges all have infinite capacity. Now, let us think about what a flow looks like in this network.\n(Refer Slide Time: 13:36 and 14:29)\n \nSo, any flow and in particular, a maximum flow will end up picking out a matching from the middle of this network. Okay. So, if you look at all of the edges that go from the rows to the columns that have some flow going through them, this will still be a matching. And this is something that you can verify by just realizing that the capacities of the edges from the source, and the capacities of the edges incident on the target, all have unit capacity.\nSo, it is not possible for these edges to really have a degree more than one on either side. Remember that we are still working with flows that are integral. And that is something that you should find useful as well if you want to argue this a little more formally. Alright. So, we have a flow that identifies a matching for us. And in particular, a maximum flow will identify a maximum matching.\nSo, the value of the maximum flow automatically gives us a lower bound on the number of cannons that we need. So, we know that we are going to need so many cannons for sure because these edges will correspond to enemy locations that do not have any rows or columns in common. So this is a useful starting point, but it is not the solution that we are looking for.\nIf you go back and look at the problem statement, you are not only asked to identify the smallest number of cannonballs that you need (but) you are also asked to identify the specific rows and columns that you should target to get rid of all the enemies. So, we still have some way to go. But just as a teaser for what is coming up, let me tell you that this size of the maximum matching here, or the value of the Max Flow, is not just a lower bound on the answer. It is not just an indication of how much you need, it turns out that it is the answer.\n(Refer Slide Time: 15:20 and 15:55)\n \nNot only do you need at least so many, (but) it is also true that you can manage with so many. So, what we are going to do is use the maximum flow, but actually, more directly, we are going to use the minimum cut associated with this maximum flow to identify a certain number of rows and columns that we need to target. And it will turn out that this number exactly matches with the lower bound. And in fact therefore, that is an easy proof that what we have is, in fact, optimal. So, let us get started with trying to figure out how we can do this.\nSo, let us go back to the maximum flow that we had here. And let us take a look at the residual graph because that is where we get our minimum cut from, if you remember. So, in the residual graph, all the unit capacity edges that are in black will stay the same. All the unit capacity edges that are blue will get reversed. And all the infinite capacity edges that are in blue will, well they will become bi-directional edges because the forward edges will remain with an infinite residual capacity, but you will get some back edges, which have unit capacity. And all the black edges that have infinite capacity will just stay as black edges with infinite residual capacity.\n(Refer Slide Time: 16:34)\n \nSo, if you were to construct this residual graph, this is what it is going to look like, based on what we just discussed. Now, let us look at all the vertices that are reachable from S in this residual graph.\n(Refer Slide Time: 16:47)\n \nWe want to remember that what we are looking at is going to also be a minimum cut back in the original flow network. So, here is what the reachable set of S looks like in the residual graph. So, all of the vertices reachable from S have been marked green, and everything else has been marked red. You can pause the video here and confirm that this is, in fact, what you would obtain if you were to run, let us say a BFS starting from S.\nIn fact, in the very first step, you will catch hold of, say, R1, R6, and R7, and even R4, but you get R2 because there is going to be a path via, I believe, C6, which is reachable from R6. So, you are going to take the path from R6 to C6, and to R2. And essentially, after that you get stuck. So, this is all the vertices that are reachable from the source.\nNow, if you look at this and just think about whether there is something interesting going on here, then what is it that strikes you? Just take a moment here and see if there is anything that occurs to you as being a little bit unusual or interesting about what has just happened in this cut. Alright. So, I am going to think of the row vertices as being S loyalists and the column vertices as being the T loyalists.\nSo, the row vertices were in the original network very close to the source, and the column vertices were very close to the target. And it looks like after we run the MaxFlow and we obtained this cut, it looks like some of these vertices have changed parties. So, now there are these two-row vertices that are accessible, or from where you can go to the target vertex. And there is this column vertex, which is accessible from the source vertex.\n(Refer Slide Time: 18:34 and 19:05)\n \nSo, in some sense, some row vertices have gone away from S, and some column burgesses have joined S. And in some sense, you can think of them as having broken ties with T. Of course, I should emphasize that none of this language is formal or meaningful, as the formal definition would go. But hopefully, it gives you a picture of something that has happened, some upsets that have taken place that will hopefully give you some intuition for what is to come.\nSo, let us call these vertices the misfits, and let us highlight them here. So, remember, the row vertices are the ones that do not belong to S, the ones that have been highlighted, and the highlighted column vertices do belong to S. It is just not their natural state. But that is where we are.\n(Refer Slide Time: 19:24 and 19:35)\n \nNow, let us go ahead and take a look at what this cut looks like back in the original flow network. So, I am going to move things around. And instead of having the edges from the residual graph, you are now going to have the original edges of the flow network.\nSo, that is what this looks like. You have this column vertex that has come on the S side, these two-row vertices that have moved to the C side. And if you think about, well, what are the edges that are crossing this cut? You will see that these edges are exactly the unit capacity edges that are either incident on S or incident to T.\n(Refer Slide Time: 19:54 and 20:10)\n \n\nIn particular, I want to say that every misfit vertex contributes exactly one unit capacity edge to the cut. And, in fact, the capacity of the cut is equal to the number of misfits. There are no other edges that cross the cut.\nAnd the reason for that is, remember that we have a finite value at Max Flow, which is equal to the capacity of the min cut. And remember, every edge that was between a row and a column vertex had infinite capacity. So, such edges are definitely not going to cross the cut. Any edge that crosses the cut must be a unit capacity edge. The unit capacity edges are the ones that are incident to either S or T, and the ones that will cross will essentially have a misfit vertex on the other side. Right.\nSo, in particular, if you look at all the unit capacity edges incident on S, they were the row vertices. And if this edge is crossing the cut, then that is a row vertex that is gone over to the column side. Similarly, if you look at any unit capacity and incident on T, well, that was an edge that started off with a column vertex.\nAnd if this vertex is crossing the cut, then it must have moved over and joined the row side, which again, makes it a misfit vertex. So, hopefully, by staring at this example and thinking about some of the things we have said, you can convince yourself that these misfit vertices are exactly as many as the capacity of this cut. And therefore, in fact, the number of them is equal to the size of a maximum matching because that was equal to the value of the maximum flow.\nSo, in fact, at this point, the number of misfit vertices that we have, is equal to the lower bound that we have on our solution. So, would it not be really cool if the misfits formed a solution? Because then we would be done. And you can probably already sense it from this example. But the fascinating thing is that this is actually always true. The set of misfits actually forms a vertex cover in the original graph.\nSo, every edge in G is incident on a misfit vertex. Let us think about why this is true. How can an edge not be incident on a misfit vertex? Remember, every edge in our graph G that we care about is an edge that goes between a row vertex and a column vertex. Remember that because we are looking at a finite capacity cut, this edge cannot be crossing the cut. So, it is either completely contained on the left side, or it is completely contained on the right side, and it goes between a row and a column.\nSo, if you are on the left, and you add an edge that is between a row and a column, then the column side is a misfit vertex. If you are on the right, and you are an edge between a row and a column, then the row side is a misfit vertex. So, you can think about all the cases involved here. But hopefully, what I have said essentially captures everything that you need to consider.\nSo, the point here is that the set of misfits actually end up killing all the edges that you have, and it is exactly what you are looking for. So, the set of misfit vertices gives you the locations or the indices of the rows and the columns from which it is useful for you to fire cannonballs so that you can get rid of all the enemies in the grid.\n(Refer Slide Time: 23:10)\n \nSo, that is pretty much it, the misfits are the answer. And we just need to write some code to identify all the misfits. And we are going to get to that in a moment. But just to summarize how we came here, we said that the misfits are as many as the capacity of the minimum cut. By the max flow min cut duality, we know that the capacity of this minimum cut is equal to the value of the maximum flow.\nAnd because of our previous discussions, we also know that the value of the maximum flow is the same as the size of a maximum matching in this graph, which we know is a lower bound on the number of cannons. So, that is why we have found not only some solution but, in fact, a solution that is guaranteed to be optimal. I think this is very cool.\nAnd as I said, this is true in general, that in a bipartite graph, the size of a minimum vertex cover is equal to the size of a maximum matching. This may not hold in general. You can come up with examples of graphs; for example, a triangle would do. The size of a maximum match in a triangle is 1, but a minimum vertex cover needs two vertices. So, even though this may not be true in general, and that is something you should be careful about. It is a beautiful duality theorem that holds in the context of bipartite graphs.\nAnd if you want to look it up a little bit more, this often goes by the name of Konig’s theorem. And what we have seen effectively amounts to a proof of Konig’s theorem, based on the duality of the values of the maximum flow and the minimum cut in a flow network. I should say that this is typically not the traditional or the default proof that you will see of this theorem.\nAnd it turns out that this is one of those theorems that have many different proofs and many different approaches and different consequences. So, there is a lot to learn. If you are interested in something like this, please do check out the description of the video or the course website for more pointers. So, having discovered this structural duality, we still have a little bit of work left to do, which is to implement this in code. But knowing what we know by now, the implementation part is super easy once again. So, let us take a quick look.\n(Refer Slide Time: 25:18)\n\nSo, as before, we just read in all the information about the enemy locations, and we construct the appropriate graph. So, the construction of the graph is actually very similar to the construction that you have already seen for the maximum matching problem from last week. Nevertheless, if you want to take a look, as always, you can find the full code in the official repository for the course.\nSo, please take a look if you want to refer to the part of it where we take in the input and build up the flow network. But once you have done that, you just run the maximum flow algorithm. And just like we did with the minimum cut problem in the previous module, we identify the reachable set, this is the set of all vertices that you can reach from the source vertex.\nAnd now remember, we want to identify the misfits. So, we want to look at all the vertices that are reachable from S, which are column vertices, and we want to find out all the vertices that are not reachable from S and which are row vertices. Right. So, this is what we are doing here we are going through all the row vertices. And if a row vertex is not reachable from S, that is what the first ‘if’ condition does.\nSo, it is a row vertex that is not reachable from S. Then that is a misfit vertex. And that is what we are going to output. And similarly, we go over all the column vertices. And if a column vertex is reachable from S, and that is the second ‘if’ condition, then that is a misfit as well. And that is what we are going to report as the output. So, at this point, we have listed all the rows and columns that we need to attack to get rid of all the enemies. And because of all the discussion we have had so far, we know that this answer is. in fact, optimal.\nSo, I hope you enjoyed this, I think this was an elegant problem to think about. And the discovery about the minimum vertex cover being equal to the maximum matching in a bipartite graph, I think is a cool thing to know. And this is not something that you now have to come up with by yourself in a contest situation, now that you already know it. Hopefully, this is information that you can leverage for future problems in future contests. So good luck with that.\nAnd with this, we come to the end of our exploration of graph-based problems in this course, and I hope that you enjoyed this as much as I did. Please keep the conversation going either in the comments in this video or over the mailing list or the Discord community, especially if you are watching this during a live run of the course. For the last three weeks, we will be talking about dynamic programming, and I hope to see you back then. Thank you so much for watching, and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W08/Lec44.html",
    "href": "materials/cpnotes/W08/Lec44.html",
    "title": "M 1 (Ford-Fulkerson for Max Flow)",
    "section": "",
    "text": "Lecture - 44\nNetwork Flows - Module 1 (Ford-Fulkerson for Max Flow)\n(Refer Slide Time: 0:11)\n\nAlright. So, welcome back to the second segment of the first module in week 8, where we are talking about network flows. So, just to recap in the previous segment, we talked about what a flow network is. We also defined the notion of a flow. We talked about what it means for a flow to be feasible. We also described the value of a flow and we set ourselves the target of finding a maximum flow. So, that is what is happened so far.\n(Refer Slide Time: 0:20)\n \n  \nWe even proposed a natural-sounding algorithm or a natural approach to finding some sort of a flow, and the question of whether this approach actually produced a maximum flow was left as food for thought. So, I hope you did have a chance to play around with examples, and you have probably concluded, if you did that, that this algorithm may not actually work in all situations.\n(Refer Slide Time: 1:06 and 1:54)\n \nSo, here is a simple example of where the algorithm might fail. So, recall that what we were doing is, starting off, by finding an S-T path and basically pushing as much flow as we could along that path adjusting the capacities and repeating this for as long as we could. So, here is a graph and the capacities are as indicated in particular every edge, has unit capacity.\nAnd to begin with, for example, your algorithm could potentially find this particular S-T path. And if you choose to push as much flow as you can through this path, which is essentially one unit of flow, notice that, in this example, every edge is a bottleneck edge. So there is not really much to speculate here.\nSo, if we were to actually push flow along this path, then the capacities of all of these edges would be turned down to 0, which means that we effectively do not have these edges with us anymore because they are fully used up.\n(Refer Slide Time: 2:06)\n \nSo, we simply delete these edges from the graph as we said we would. And now you are left with a situation where S and T are completely disconnected and your algorithm comes to a grinding halt. And you, basically, found a valid flow whose value is one. On the other hand, if you go back to the input flow network, by just the algorithm of staring at the picture, you can probably see that there is, in fact, a flow whose value is 2, which is better than the one that is found by your algorithm.\nSo, in particular, you could send flow across the top and the bottom paths, from the factory to the shop, and you would be better off if you simply did not use the edge in the middle from X to Y. So, this shows that the algorithm that we developed is not flawless in terms of finding the maximum flow. But now, let us think about if there is some way that we can build on the ideas that we already had and somehow fix the issue that we were having.\n(Refer Slide Time: 3:10)\n \nSo, basically what we want to do is see if we can correct our mistakes as we go along. So it is possible that we found a path that was not quite the right one because remember what was happening here is that by essentially using up the path that went via the edge X-Y, we kind of blocked ourselves off from being able to leverage some of the other paths that would have put us in a better place. So, if that decision could somehow be rolled back, then that would allow us hopefully the opportunity of discovering the more meaningful paths that are available to us.\n(Refer Slide Time: 3:51)\n \nSo, just to summarize, what we have said so far, essentially if we make a mistake with respect to the S-T path that we choose in a particular round, we want to build up some sort of mechanism that allows us to actually undo the flow that we sent through this particular S-T path. So, you might want to take a moment here to think about how would you build-in this kind of undoing mechanism into your network. As such what we have been doing so far, is clearly not enough.\nBecause once we decide to pass some flow through an edge, in particular, especially, when it has an edge that is saturated to full capacity, what ends up happening is that, that edge simply disappears from that graph, which seems that we have really pushed ourselves into a corner with respect to this choice. There does not seem to be any mechanism for actually saying: No, let us go back and let us not send that flow through that edge. Let us re-route it some other way.\nSo, since that edge is completely gone, we need to really revisit what we are doing and see if we can set up some additional support systems that can guide the flow back if required later on. So, this is I think the place where you really need a little bit of imagination. So, do not worry if this is not something that you are able to see or come up with immediately. In fact, I am not even sure how to present any more intuition.\nSo, what I am going to switch to doing now, is describing what our algorithm is actually going to do. And I hope that it makes sense once it is actually presented to you. But if you want to play with this sort of general idea for a while, please feel free to pause here, and think things over a bit before I do reveal the algorithm that we will be working with. Alright. So, what we are going to do, is the following.\nWe will basically introduce carefully, some extra edges for ourselves, which will basically open up some additional routing options, which will correspond to an indication that some flow decisions should be rolled back.\n(Refer Slide Time: 6:00)\n\nSo, to be able to keep track of these extra edges that we want to be working with, we are going to introduce this notion of a residual graph, which you can basically think of as some sort of an auxiliary graph, which is very intimately connected with the flow network. But it has all of these extra mechanisms to help us with the rollbacks. So, a residual graph is based on both a flow network and a given flow, which right at the beginning, you can just imagine as being the trivial flow, which assigns 0 to every edge.\n(Refer Slide Time: 6:24)\n\nBut once you are given a flow network and a feasible flow ‘f’ then here is what the residual graph looks like. So, to begin with, the vertex set of the residual graph is exactly the same as the vertex set of the flow network. And then if we have an edge, let us say from A to B in the flow network which has a capacity of C and a flow of ‘f’ with respect to this given flow, then in the residual graph, we are going to introduce an edge from A to B with capacity C-f.\nNow, this may sound familiar because this is what, we were doing so far already. So, if you have a flow of ‘f’ going through an edge that has capacity C, then you want to record that by saying that you are now working with an edge of reduced capacity and the capacity is reduced by the amount of flow that you have assigned to that edge. So, so far, the residual network looks very natural.\n(Refer Slide Time: 7:27)\n\nBut the thing that actually allows us to fix our mistakes, is this other edge that we are going to introduce, which is commonly called a back edge. So we are going to introduce an edge also from B to A which has a capacity of F. So, this is, basically, telling us that okay look if you want you can pass a flow through this back edge.\nAnd whenever you do that I will basically know that I should go back to the original graph and reduce the flow that was being originally passed through the edge A to B by whatever amount of flow you are passing through this back edge. So, this mechanism will actually hopefully become clearer with an example. So, let us go back and try it out on the example on which our first algorithm failed and let us see if this construction can actually save that example and actually find the optimal flow.\n(Refer Slide Time: 8:13)\n\nSo, remember here is what we had. We made this bad choice of sending our first flow from S to T via the edge X-Y. So, these were all unit capacity edges that were being used up completely. And other than this we had these two edges as well, so we had edges from S to Y and from X to T.\nIt is drawn up a little bit differently here but if you like, you could just pause and go back to the example from before just to confirm that the structure of the edges is exactly the same. So, this is basically the flow that we have at the end of the first iteration. When we do our first S to T path. Now, let us go ahead and take a look at what the residual graph would look like.\n(Refer Slide Time: 9:03)\n\nFirst of all, for all the edges through which we are passing a flow, we are going to have the same edges but with a reduced capacity and this capacity is going to be 0. Notice that the capacity of the edges other than the three that were involved in the path remains the same. It is unaffected because there was no flow going through these edges in the first place. So, these are all the forward edges. These are the edges corresponding to the real edges in the graph.\nNow let us introduce the artificial back edges. So, notice that for each of the forward edges involved in the path S to X, X to Y, Y to T, we are going to get these back edges and the capacity of these back edges is actually going to be equal to the amount of flow that we were passing through them. Now the other two edges that we have here will also have back edges corresponding to them.\nBut because they had zero flow passing through them, these back edges will also have 0 capacity. So, I am not drawing them for clarity. In fact, we also have some of these forward edges that have 0 capacity, which are edges that are as good as not being there.\n(Refer Slide Time: 10:08)\n \nSo, let me remove those from the picture as well. So, this is the residual network. Just pause the video here and see if you can find an S to T path. And notice that if you can, then this is in contrast to what happened with our original algorithm, where we just got completely stuck after finding that first path. Okay. So, take a pause here and see if you can find an S to T path.\nAlright. So, notice that in this graph, you can in fact find an S to T path, and here is one that looks like this. And the dotted edge is just to remind us that that is actually an edge that is not present in the original graph. So, what does that really signify? What are we going to do if you were the manager at the factory? Then what instructions are you going to give, you know, the buses, the people who are going to be driving the buses across to the shop?\nWell, you are going to tell them that look we did plan to send one bus across from X to Y. But let us not do that anymore and the reason you are able to say that is because you see that in the residual network, you are passing a flow through the back edge, which means you have to roll back the flow through the corresponding real edge in the base flow network.\nSo, you are basically going to say, okay, let us actually take back that decision and let us instead route flow through the edges from S to Y and from X to T. So, you can check that this actually corresponds to the flow that we were hoping to find the one, where we said if we used the top path and the bottom one, ignoring the edge in the middle. Then we would actually have a flow of two units. This is really that flow.\nIn particular, notice that the back edges X to S and T to Y are not being used in this S to T path. So, we are not going to do any rollbacks there. So, originally we had from the previous iteration, one unit of flow (going from the edge) going on the edge from S to X and on the edge from Y to T and that flow is going to remain as it is. But what we have essentially done is, we have peeled off the flow from the edge X to Y and we have essentially rerouted it through these two edges from X to T and from S to Y.\nSo, if you write it out with respect to the older drawing you will see that this is exactly the flow that we were hoping to find. And this is the best that we can actually hope for. So, it is good to see that our intervention with the residual graph actually fixed up the situation for this small example. It actually turns out that this idea works in general, but actually proving this is going to be beyond the scope of this discussion.\nAs usual, if you are interested in the proof of correctness then you are certainly welcome to look up the resources that have been linked up (to) in the description of this video as well as on the course website. In the meantime, let me just recap and summarize the algorithm for you, so that we know at least the mechanics of what is going on here.\n(Refer Slide Time: 13:11)\n\nSo, what we have just been discussing so far, commonly goes by the Ford Fulkerson algorithm, and here is what it does. To begin with, you build the residual graph with respect to the trivial flow, which just assigns a value of 0 to every edge and you initialize an answer variable if you like or a max flow variable to 0 because right now the value of the trivial flow is just 0.\nThen basically you work with the residual graph as long as you can find a path from S to T in the residual graph. Here is what you do. You want to push a flow of ‘f’ units through P, where ‘f’ is the bottleneck capacity of the path P. Remember we said that if you want to push a flow along a path, you need to look at every edge in the path and identify the edge that has the smallest capacity. This is called the bottleneck capacity. And that is the amount of flow that we are going to send through this path. And we are going to increment max flow by ‘f’ because this is the additional amount of value that we gained in our resulting flow.\nNow let me just talk for a moment about this phrase, sending a flow, which is a bit loaded. So how do we send a flow of F units through this path? Well, we look at every edge of this path in turn. If it is an original edge that belongs to the flow network as well then what we do is simple, we take the old flow that we had through this edge and we simply increment it by ‘f.’\nOn the other hand, if it is a back edge in the residual graph that means that what we need to do is, a rollback action, which essentially means the following. We look at the corresponding forward edge in the original graph and what we do is, we look at the old flow and we decrement it by ‘f.’ We reduce it by ‘f.’ So, that is how our flow function is going to evolve based on the S-T path that we have found in the residual graph. So, that is it that is pretty much the entire algorithm.\n(Refer Slide Time: 15:07, 15:48 and 16:15)\n  \nLet me just give you a quick visual to hopefully reaffirm our intuition for how these capacities work. So, what you see with the green bar, is the original capacity of an edge that came with the input flow network. The blue bar tells you the amount of flow that we are sending through it currently with whatever flow we are working with, in the current iteration.\nAnd this will imply that in the residual graph, we have a back edge, which has the same capacity as the current flow. That is what allows us to roll back as much of the current flow as we want by simply sending a flow of that amount through this back edge in the residual graph. Right.\nSo, in particular, if we decide to increase the flow through the original graph (then through the edge of the original graph) then the capacity of the reverse edge will also accordingly increase to account for the possibility of rolling back all of this extra flow as well. On the other hand, if you decide to pass some flow through this reverse edge, in the residual graph that means that essentially you want to decrease the flow that you are passing through the original edge.\nAnd as you do that the capacity of the reverse edge will also correspondingly come down to basically remain in sync with the actual amount of flow that is passing through the edge. So, that is what is going on as you progress through this algorithm. Now when you actually implement this algorithm, you could choose to keep track of the capacities in this way if you like.\n(Refer Slide Time: 16:38)\n\nBut another way of doing it is, to simply fix the capacities upfront. So, every edge corresponding to an original edge in the network will have its given capacity. Whereas, each one of these artificially introduced back edges will always have a capacity of 0 throughout the run of the algorithm. And the way we keep track of what is going on is through the flow function.\nSo, notice that what we are actually interested in is the residual capacity, which is the difference between the capacity and the flow so that we can correctly calculate what is the bottleneck capacity on any S-T path. So, essentially for all the original edges, the capacities are anyway fixed and we just need to make sure that we are correctly keeping track of how much flow we are passing through these edges.\nFor any of the back edges, notice that the capacities are evolving based on what is the flow that is going through the corresponding forward edge. So, instead of letting the capacities change, what we are going to do is, essentially pretend that we are sending a negative flow through this edge.\nSo, for example, let us say that in the first iteration, we decide to send 10 units of flow through a real edge in the flow network, then the way we are going to record that is by saying: Okay, that is +10 units of flow through the real edge and it is -10 units of flow through the corresponding back edge.\nWhen you do that and when it comes to looking at the residual capacity, the capacity of this back edge is going to be 0. And then you are going to subtract -10 from it. So what you will be left with is 10 as the residual capacity. So, it is just enough to track the flows. You do not have to worry about also tracking the capacities. And this just makes your code a little bit cleaner, a little more convenient to work with.\nSo, remember that whenever you are passing a flow of ‘f’ through any edge, record that as an increment of ‘f’ through that edge and an increment of ‘-f,’ or a decrement of ‘f’ through the corresponding edge in the opposite direction. And you will see that this essentially works out exactly as you would like it to, in all possible cases. So, we will take a much more detailed look at the implementation in the last segment for this module. So, if this was not completely clear, hopefully, it will be more explicit and visible, when we get to that part of the discussion.\n(Refer Slide Time: 18:58)\n\nSo, before wrapping this up, let me make a few comments about the running time. So, essentially we know that the number of iterations is bounded by the value of the maximum flow. Because every iteration is guaranteed to increase the value of the flow that we are working with by at least one.\nNow, what is it that is happening in each of these iterations? Well, we do run a BFS. We do some backtracking to actually find the S-T path. And we make sure that we evaluate the bottleneck capacity on this path and adjust all the capacities or the flow values along this path appropriately. So, all of this is essentially linear time work – linear in the number of edges of the graph. So, the overall running time essentially is ‘m’ times the value of the max flow.\nNow, this sounds reasonable, but it can be really terrible if the numbers are large and your max flow value can be really huge. You can come up with adversarial examples where this algorithm takes a really really long time. It painstakingly increments the flow value by literally one in every iteration. I mean ideally, you want your flow to increase by large jumps so that it is not too many iterations.\nSo, notice that this max flow value is totally independent of the number of vertices in the number of edges. It could be a function of the weights or the capacities that you have on the edges, which means that this is a really dangerous sort of upper bound to be working with, especially if the upper bound is tight and it can actually be realized on certain instances.\nSo, it turns out that you can just continue using this framework for finding a max flow. But basically be a little more choosy about which S-T paths you work with, in each iteration, and that already can dramatically improve your running time.\n(Refer Slide Time: 20:42)\n\nSo, the first specific improvement to this is by ensuring that you pick the shortest S-T paths, using BFS. I guess we may have been implicitly doing this all along. But by choosing to pick the shortest S-T path in each iteration, it turns out that you actually guarantee that the number of iterations will not exceed V times E, which is the product of the number of vertices in the number of edges, which brings down the running time in some sense to n times m squared, where m is the number of edges and n is the number of vertices.\nNow, of course, this requires an explicit argument for why the number of iterations is bounded in this way. Once again the specifics of this argument are beyond the scope of this discussion, but there are some very nice explanations provided in other write-ups and videos, so you will find some pointers to those in the description of this video as well as once again on the course website.\nSo, please feel free to look these up. These are really nice arguments that establish these bounds. But for now, we are just going to take this as a given and this is the implementation that we will actually discuss in the last segment of this module.\n(Refer Slide Time: 22:00)\n\nIt turns out that in competitive programming, most people use what is called a Dinic’s algorithm, and this is a further improvement in the sense that it tries to squeeze (out) even more mileage out of each iteration. And it turns out that if you were to follow this approach, then the total number of iterations is actually bounded by n, as opposed to n times m. And the amount of work that you have to do to make each iteration actually succeed is n times m. So, the overall running time is now, n squared m, as opposed to n m squared from before. And this can again be a significant improvement.\nSo, again Dinic’s algorithm, as I said, tries to leverage more using this notion of blocking flows. So, you want to basically again just get more work done in every iteration somehow. I do not want to go into the details of this here because this is something that we will not be getting into.\nIt is a little bit beyond the scope of what I think our discussion here is about, but just for completeness, there is an implementation of the next algorithm that is given in the course repository. So, just in case that is something that you need to invoke as a black box, it is available for you. You can take a look at it and if you are curious, you can even familiarize yourself with what is actually going on. Now it turns out that there could be a few problems for which the Edmonds-Karp implementation will actually fail.\n(Refer Slide Time: 23:29)\n\nBut this one will go through. So on SPOJ, for instance, there is a problem called max flow, and if you try to run the Edmonds-Karp version that we have, it is going to time out. But Dinic’s variant will go through. So, basically, you could be in that situation, and as I said, many people will simply default to using the next algorithm, because that is just, you know, that is just the thing to do if you want to be on the safe side.\nSo, you are welcome to do that, as long as you know what you are doing, and you know how things plugin. Actually, the overall implementation is very similar. Because the way this works is that we are working with a class called max flow. So, the interface remains exactly the same. It is really the internals that has been swapped out. So, you should have no difficulty using this in implementation.\nBut the only thing I want to emphasize is that we are not really discussing how exactly this algorithm actually manages this improvement. And once again, if you are curious, there are some nice explanations that have been linked to in the description of this video. So please do go ahead and check that out if you would like to.\nAlright. So, with that, I believe we have enough information to get to the implementation. And that is going to happen in the last segment. As always, I welcome you to try it out on your own a little bit before actually following along. And I think that would be a good experience, even if you do not get all of it completely. It will be fun, I think, to give this a shot yourself. But one way or the other, I will look forward to meeting you again in the last segment of this first module. So, see you there!"
  },
  {
    "objectID": "materials/cpnotes/W08/Lec45.html",
    "href": "materials/cpnotes/W08/Lec45.html",
    "title": "M 1 (Implementing Edmonds-Karp)",
    "section": "",
    "text": "Lecture - 45\nNetwork Flows - Module 1 (Implementing Edmonds-Karp)\n(Refer Slide Time: 00:11)\n\nAlright. Welcome to the last and the final segment of the first module in week 8. And here, we are going to essentially implement the Edmonds-Karp approach to finding a maximum flow in a flow network. So, let us get right to it. You can look up this code, as usual, on the official repository for the website. And if you want something to test it against, you can do that. I mean this, the main function is really designed to take input for this problem, called internet bandwidth.\nThis is UVa 820, and that is something that you can try your code against as well. It is essentially very visibly a max flow problem. So, I am not even going to go through the problem statement for you because it is essentially telling you that there are computers and they are connected through wires. And each of these wires has a certain bandwidth, and what is the maximum browsing speed that you can achieve.\nSo essentially, once you read through it, you, basically, know that you have to set your computers as being the vertices and the connections being the edges, and the bandwidth of the connections are the capacities. And I think the source and the target vertices are given specific IDs. So essentially, it is very, very transparent that it is a max flow problem.\nSo because of this, we will focus our entire attention on basically solving the max flow problem. And will not talk about internet bandwidth specifically anymore. But if you have any difficulties in either parsing the input or passing on the input data into the max flow functions, or even presenting the output, you can always refer to the main function for this code that I will be presenting, which you can find at the usual place. It is the official code repository for this course.\nSo hopefully, that will help. And if anything is unclear despite that, then I always welcome you to post your questions as comments on this video. Or you could also use the Discord community if you are watching this during an active run of the course.\n(Refer Slide Time: 2:13 and 3:49)\n \nSo with that said, let us actually take a look at the implementation. So, to begin with, we have the max flow class, which has the following private entities. So, V is just the number of vertices in the graph, EL & AL, you might recognize the shorthands for edge lists and adjacency lists. The way we implement this here is probably slightly different from what you are already used to. So, you may want to pay attention as we go along.\nThen we have a vector d, which is essentially going to be the distance array for the BFS procedure. Now you also see something called ‘last.’ It is here because I just want to tell you to ignore it. It is something that is useful for Dinic’s implementation. But we would not really be going over that. But you might still see this variable in the code base, and you might wonder what it is about. So, I just left it in here to tell you to not worry about it.\nNow the last thing you see here is a vector of integer pairs called ‘p.’ This is some sort of a parent array, which will help us do the backtracking that we need to do for going along an S-T path, finding the bottleneck capacity and all of that. So, those are essentially the main entities that we will be working with.\nSo, the other thing that you see here is the constructor that is going to be called whenever you create a max flow object, and this essentially just sets the scene and clears the ground for other information to come in. And, in particular, it also makes sure that the adjacency list consists of n vectors of integers, one corresponding to each vertex in the graph.\nSo, all this is fairly standard. Let us look at the first helper function that we have, which is called add_edge. And by default, we are working with a directed graph. So, we are going to assume that when you are adding the edge u comma v, you really mean the edge from u to v. However, we do have a parameter at the end called ‘directed.’ It is a Boolean value, which you can set to false to indicate that you actually want to add an undirected edge.\nNow I did not mention this explicitly but everything we talked about goes through for undirected graphs in a natural way. All you have to do is basically treat the undirected edges as bi-directional edges, going both ways. And you set up their capacities to be equal to the capacity of the original undirected edge that you were working with.\nI am going to leave it as a bit of an exercise for you to figure out how everything plays out if you were working with an undirected graph instead of a directed one. But for the purposes of the discussion that we are going to have, what we are going to be thinking of working with is essentially the default setting of directed graphs.\nSo, essentially what we have here is a directive to add an edge from ‘u’ to ‘v,’ with a capacity of ‘w.’ That is what we want to do. And, okay, so, the first thing that we do here is a sanity check, which says that we do not want to permit self-loop. So, if ‘u’ is ‘v,’ we then do nothing. But otherwise what we want to do is, actually, add this edge to our system. And it is probably a little hard to tell what is going on here by just looking at the code. So, I am going to show you a picture.\n(Refer Slide Time: 5:29)\n\nAnd so here is what is going on. So, on the one hand, we have the edge list. What the edge list is storing is, it is storing the information about the tails of the edges and the capacity and the flow – it is storing these three pieces of information. And the adjacency list for the head of the edge, which is from where the edge is originating – that is essentially going to have a pointer to the entry in the edge list that is recording the tail of the edge.\nSo, you could now go back and tally this picture with the code. You can see that the edge list is getting v comma w comma 0. That basically corresponds to the tail of the edge, the capacity of this edge, whose head we do not know anything about so far. And the flow because we are just starting out is, the trivial flow and it has a value of 0. And now we complete the picture for this edge, by adding the index of this latest entry into the edge list, to the adjacency list of ‘u.’\nSo, that, basically, completes the connection from ‘u’ to ‘v’ essentially. And we do the same for the back edge actually. So, we do this in the other direction as well. But the way we do this is that we are just a little bit careful about what capacity we set for the edge. So, if it is a directed edge, then the back edge is going to have a capacity of 0, as we just discussed.\nBut on the other hand, if this is a bi-directional edge meaning that it is, basically, two sides of an undirected edge, then we want to set the capacity of the back edge to be the same as the capacity of the original one. So, that is why you see this little snippet here, which says that if directed is true, then set the capacity of this edge to 0. This is really an artificially introduced back edge.\nOn the other hand, if it is not directed, it is an undirected graph, then set the capacity of this edge to be w, which is the same as the capacity of the original undirected edge. So that is, essentially, how we add edges into this system. And now the next helper function I want to talk about is the BFS component. So, remember that at every iteration, one of the crucial things that we do is to check if the residual graph has an S-T path. And we do that by initiating a BFS from the source vertex S.\n(Refer Slide Time: 7:55)\n\nSo, I am skipping here the initializations, which are pretty standard. So, you initialize the distance array, the parent array, and make sure that the queue has the source vertex loaded onto it, to begin with. And that the distance of the source vertex is set to 0. So with that in place, really, the heart of the BFS algorithm is this ‘while’ loop here, which keeps going as long as the queue has something to offer.\nAnd the vertex u is now the vertex at the front of the queue which is being currently processed. And a lot of this should look familiar because we have talked about BFS before. So, this is more of both a recap as well as the adaptations that we have to make in our context here. So, the first thing, for example, is that if the vertex that is being processed currently is the vertex ‘t,’ which is the target vertex, then we can actually just break out of this loop.\nBecause we have found what we were looking for. We wanted to know if t was reachable from s, and so this is a done deal. Otherwise what we are going to do is continue in the normal BFS style. So, we explore every vertex on the adjacency list of u. These are original neighbors of u. And we are going to initialize the variables v capacity and flow to being the label of the neighbor or the capacity of the edge from u to v, and the current flow through this edge, respectively, by just looking up the information in the edge list, which actually has this tuple, and contains this information in this order.\nNow what we are going to do is, basically normally in BFS, we would check if v was a visited vertex and if it was not visited then we would process it and if it was already visited then we would continue. So, that is essentially what is happening here, except – so the d of v = -1 is the familiar condition of requiring that v is not a visited vertex. But you also see an additional condition which says that the residual capacity, which is given by the difference between the capacity and the flow is strictly greater than 0.\nSo, if you remember, when we were describing the algorithm, we said that if the residual capacity of some edge becomes 0, then we might as well just delete this edge to remember that this is not a usable edge anymore. And what we are going to do here is, whenever this happens we are not going to actually remove the edges from either the edge list or the adjacency lists because that is just painful to keep track of.\nBut because of this notice that we may therefore have a lot of junk edges in our system, edges that are not really usable because their residual capacities are currently 0. So, in the bargain of this convenience of not having to actually delete edges when their capacities come down to 0, what we have to do is, whenever we are about to use an edge, we have to sanity check first as to whether it is even a usable edge or not.\nSo, that is what the first component of this condition is doing. So, if both of these conditions are met then we have that v is an unvisited vertex. And the edge from ‘u’ to ‘v’ is an edge with non-trivial residual capacity. That means that this is an edge that we can work with. So, we are going to proceed and do the usual BFS things that we do. So, in particular, we set the distance we push v onto the queue. And we also set the parent information for v.\nSo, normally this would have just been the label of the vertex u: ‘u’ is the vertex that is responsible for bringing v onto the queue. But because of the funny way in which we are storing this information, which is spliced across the adjacency list and the edge list, for convenience, we are also going to store in the parent information, the value of the index of the edge from u to v, in the edge list.\nSo, as we will see later this will help us quickly retrieve all the relevant information about this edge that was really responsible for bringing v into the queue. And as you can imagine, this will be particularly useful when we are backtracking our way through an S-T path in due course.\nSo, now that BFS is done, let us talk about the function that will help us actually send an augmenting flow through an S-T path. So, remember the first thing that we do is, use BFS to check if t is reachable from s and if so, then what we want to do is actually look at an S-T path, a shortest S-T path, and find the bottleneck edge on that S-T path and update the values of the flows along all of the edges on this path. That is essentially what we want to do next.\n(Refer Slide Time: 12:33)\n\nAnd that is going to be handled for us with this function called ‘send_one_flow’ from s to t. And it has a third parameter f, which by default is initialized to infinity. This f is essentially what is going to keep track of the bottleneck capacity for us. So to begin with, we do not have any bottlenecks, we do not know what is going on at all.\nBut as we find our way through the path, this f will keep getting updated. And the reason it is being passed as a parameter to this function is because the easiest way to do this is essentially by using this function recursively as we will see. So, this f will essentially help us keep track of what we have found so far, in recursion.\nSo for now, let us actually ignore this base case, which is the opening line of this function. It basically says that if s and t are the same, then we return f and this will make more sense in the end. So, I promise that we will come back to this. So now, let us look at what is happening in the next line. It seems like we are trying to retrieve some information about the parent of t. Why might you want to do this?\nWell, it is reasonably natural because we said we want to do something along the shortest S-T path. We have just finished running BFS in the previous step. So, the parent pointers from t along this BFS tree will essentially help us climb back towards s, via the shortest path. So, that is why we are interested in the parent of t because it is going to help us, you know, start making progress on this S-T path that we are eventually trying to find.\nSo, just to understand how this works, remember how did we store the parent of t or the parent of any vertex when we were doing BFS, we stored it as a pair of integers. The first one was the label of the parent and the other one was a pointer to the, or it was the value of the index of the edge from the parent to the child, in the edge list.\n(Refer Slide Time: 14:33)\n\nSo, in particular, let us say, the parent of t was some vertex z, and let us say that this edge from z to t, had a capacity of 9. Well, what we know is that ‘u’ is going to take the value z.\n(Refer Slide Time: 14:47)\n \n \nAnd the index here is going to basically be the index of this row in the edge list. So, now that we know this we can use this information to retrieve the value of the flow going through this edge from the parent to t, and also the capacity of this edge. So, the next line of code does just that. So, it is going to look up the row or the entry in the edge list corresponding to this index ‘idx.’ And it is going to, that is a tuple involving three numbers or three values. And this ‘get of 1’ and ‘get of 2’ are going to get hold of the second and the third values respectively. And that corresponds to the capacity and the flow essentially by design.\nSo, hopefully, this line here makes sense. And then what we want to do is essentially recurse. So, what we want to say is, now let us try to push a flow from the source to the parent of t, right. And what we are going to do is, also make sure that this recursive call is aware of the bottleneck constraint that we have so far.\nSo, so far, we know that the bottleneck was supposed to be, you know, f, given by f that is the parameter that was passed to the current call. And we also know that the current edge that we are considering, that is the one from the parent of t to t, has a certain capacity and a certain flow and therefore it has a residual capacity of the difference between these two numbers.\nSo, in case that is a tighter value, if that is smaller than f then that is the new bottleneck. Otherwise, we just stick to f as being the best upper bound that we have on the bottleneck. So, that explains, why we are taking the min of these two values and passing that on as the fresh bottleneck information to this recursive call.\n(Refer Slide Time: 16:39)\n \nSo, just to see what is going on a bit visually. So, let us say that this is the S-T path along the BFS edges. Our first focus is on t, and we found the parent of t and we said that parent is z. And now we are performing recursion on s to z essentially. So, we are saying: Okay. Find, you know, the best flow that you can send from s to z, keeping in mind that so far, the bottleneck that we have discovered is 9. Right.\nSo essentially, this function call was initialized with an, you know, initial bottleneck of infinity, which is just to say that we do not know anything about the bottleneck. So, the difference between the capacity and the flow of the edge from z to t is 9 because the capacity is 9 and there is no flow through this edge currently.\n(Refer Slide Time: 17:33)\n \nSo, that is what is going to be passed on as the current best knowledge that we have about the bottleneck. So, it is a good exercise to check how the value of this parameter evolves, as you go further and further into the recursion basically. So, to begin with, as I said, the value of f was infinity. It got overridden by 9 and as you go further along, whenever you encounter an edge whose residual capacity is more than the value that was passed on or is equal, then the value of the parameter does not change.\nBut every time you encounter an edge whose residual capacity is smaller than the value that came in, then this parameter value is going to get overridden. At some point, you keep going back and you get to a point where the parent pointer points to S and that is the point when we know that S = T and the value of f that came in, at this stage is, in fact, the value of the residual capacity of the edge that had the smallest such value in this path. So, at this point, we have really found out the value of the bottleneck capacity.\n(Refer Slide Time: 18:37)\n\nAnd so now if you go back to the code hopefully that first line makes sense. So, when s = t that just means that you have come all the way to the start and you have finished exploring this path, and the value of f at this point is the bottleneck capacity. So, that is what we are going to return. So, you can imagine that the value of this variable ‘pushed’ here is going to be the value of the bottleneck capacity. And now that we have this value all that remains to be done is really to adjust the flows.\n(Refer Slide Time: 19:08)\n\nSo, in particular, the flow of the current edge that we are working with needs to be incremented by ‘pushed.’ So, as you can guess that is going to affect the value of this number here.\n(Refer Slide Time: 19:19)\n\nAnd in this example, this will have to be incremented by three units because that I believe was the bottleneck capacity of the path that we saw earlier. You could go back and confirm that that is indeed the case. But now apart from this remember what we need to do is also make sure that the edge that is going in the opposite direction has its flow decremented by the same amount. Remember we discussed that this is how everything stays nice and synced up exactly, as prescribed by the algorithm. So that is what we want to try and do next.\n(Refer Slide Time: 19:47)\n\nSo, notice here that we have introduced a variable called ‘rflow’, which is presumably the flow that is going through the reversed edge. And the way we do that is by looking up the edge list at the index that is given by ’XOR’ing the current index with 1.\n(Refer Slide Time: 20:10)\n\nSo, what is going on here? Well, notice that our edge list always comes in pairs. That is how we added the edges. Right. So, whenever we had to add an edge from u to v, we also added the edge from v to u. And the capacity of the edge from v to u was either set to being the capacity of the edge from u to v if the graph was undirected. Or it was set to 0 if the graph was directed in which case this would actually be modeling the back edge in the residual graph.\n(Refer Slide Time: 20:41)\n \n \nIn any case, the point is that when you want to be updating the value of the partner reverse edge then essentially you are looking for an adjacent entry in the edge list in one of the two directions, depending on which edge you started with. So, let us say that indexing starts from 0 and you are currently working with the edge whose index is 3, then the edge that you are looking for has an index of 2. On the other hand, if you start with an edge, whose index is 2 then you are looking for the edge whose index is 3.\n(Refer Slide Time: 21:06)\n\nSo, that is exactly what doing an XOR with one gives you. It gives you, essentially, the other partner edge by flipping the last bit. Okay. So, that is how you get to the partner edge succinctly. And all you have to do now is make sure that the flow through that partner edge is decremented by ‘pushed,’ essentially by the same value as the forward edge flow was incremented.\nAnd at this point, you can return ‘pushed’ and you would be done. So that is what is going on with the send_one_flow function. And so this enables us to actually push flow through the paths that we found from the BFS procedure that we did earlier.\n(Refer Slide Time: 21:51)\n\nSo, now it is time to piece everything together and actually look at the Edmonds-Karp algorithm now that we have all the specific pieces in place. So, as we said, to begin with, the maximum flow is initialized to 0. We have not really done anything yet. And now what the algorithm is basically saying is the following.\nFor as long as you can find a path from s to t in the residual graph, find the shortest such path and route as much flow as you can through that path and keep going for as long as possible. Right. So, the part about finding the shortest S-T path is handled by the BFS function. And it is written in such a way that if you cannot reach t from s then, this function returns a false value and that is when the lifetime of this while loop comes to an end.\nBut otherwise, it is going to keep going and what you do within the loop is, basically, execute the send_one_flow function, the recursive one that we just discussed. And what that is going to do is find the bottleneck capacity on this path from s to t. And it is going to route that much additional flow through this path, making adjustments as necessary for the edges that go in the opposite direction as well.\nAnd in this code, you can see that there is a redundant check. Notice that you do not really need to check if f is 0 because the only time that will happen is if you had an edge on the S-T path that actually had a residual capacity of 0. But remember that every edge that we have on this S-T path, is an edge that we discovered by following a parent pointer from the BFS traversal that we just did.\nAnd in the BFS traversal, we only explored those edges which had a non-trivial residual capacity. So, all of the edges on our S-T path are going to have a non-trivial residual capacity. So, this check here is really an extra and redundant check and the algorithm is going to work as advertised even without it.\nRemember to increment your max flow value by f because f is the amount of flow that you manage to push through the S-T path that you just discovered, and that is the amount by which the value of your flow has increased in this iteration. So, that is what is happening in the third line inside the while loop.\nOnce you break out of the while loop, there is nothing left to be done. You cannot implement the flow anymore and you can return max f as the final answer. Once again that this actually works correctly every time does require an argument, which we have skipped but, as always, you can look this up. There are some very interesting resources that have been linked to in the description of the video. So, please feel free to explore, if you are curious about why this actually works all the time, all right.\nSo, that is pretty much it that brings us to the end of the implementation of the Edmonds-Karp max flow algorithm. And now what we are going to do is, put this to good use by discussing a couple of problems. So, there will be one implementation-based problem that we will discuss and there will be one, which is just a problem I wanted to share with you in principle because it is so much fun. But I have not really seen a contest problem around it. So that is going to be just more of a theoretical discussion. But when we come back next week, we will again be able to expand on this algorithm and use it in some other ways as well, and there will be some more implementation to be talked about in week 9. But for now, let us immediately leverage this algorithm to solve a matching-based problem on Codeforces. That is up next in the second module. See you there!"
  },
  {
    "objectID": "materials/cpnotes/W08/Lec47.html",
    "href": "materials/cpnotes/W08/Lec47.html",
    "title": "Sport Elimination via MaxFlow",
    "section": "",
    "text": "Lecture - 47\nSport Elimination via MaxFlow\n(Refer Slide Time: 0:11)\n\nWelcome to the third and the final module of week 8 in Getting Started with Competitive Programming. So, we are still talking about network flows. And in this module, I want to talk about a textbook problem called ‘sport elimination.’ I could not find a programming contest problem that corresponds to this. So, we would not be doing any implementation.\nBut it is a fun problem to talk about, and goes to show how versatile MaxFlow can be in terms of modeling problems that may not sound like they have anything to do with graphs, at least to begin with. So, let us talk about the problem setting first, and then we will talk about how a flow network could be useful in determining a solution.\nSo, let us say that we have an IPL tournament going on, which is true at the time of this recording. And let us say that we are at some point in the middle of the tournament where some matches have been played. And some matches still remain. So, before going further, let me just clarify the format of the IPL although you probably know this better than me, but just to make sure that we are on the same page about the setting of the problem.\nLet me recall that the IPL tournament is typically a double round robin tournament with playoffs, which just means that in the beginning, we have the league matches where every team faces off every other team twice. So, there are usually 8 teams. And therefore, every team is going to play 14 matches because there are seven other teams. And there are going to be two matches with each team.\nSo, there are going to be 14 matches that every team plays. So, if you add up all the matches that every team is involved in, that is 14 times 8, which is 112. But of course, as an audience, you only get to see 56 matches, because every match just got counted twice the way I described it. So, there are 56 of these league matches. And then ultimately, there are 4 playoff matches, which will determine the ultimate winner of the tournament.\nSo, in this problem, I am just going to focus on the league games, not worry about the playoffs. And for simplicity, we are going to assume that no game ends in a tie. So, we are just interested in tracking the number of wins that every team has.\n(Refer Slide Time: 2:20)\n\nSo, let us say that some league matches have been played. And let us say that these are the four teams that are at the top of the leaderboard right now. So, we have KKR (Kolkata Knight Riders), and we have CSK (Chennai Super Kings), RCB (Royal Challengers Bangalore) and MI (Mumbai Indians). Right. And let us say that all of these 4 teams have played all of their matches against the remaining 4 teams that you do not see. So, which is to say that every team has played these 8 matches.\nAnd let us also assume that they have won all of those 8 matches, and the remaining four teams are at the bottom of the points table. So we are not going to worry about them right now. We are going to focus on just these four teams. And let us say the situation is that these are the matches that are remaining between these four teams. So, between these four teams also some matches have been played.\nFor example, KKR and CSK have played both of the matches that they had to play between them. RCB has played one match each with each of these teams, and it has one match remaining. Mumbai and KKR – they have played one match, and they have one match remaining between them. And Mumbai and CSK – they have played both of the matches that they had, so they have no matches remaining between them. So, I hope I accounted for all the parents, but if not, the information that you have here about the number of remaining matches tells you everything that you need to know.\nNow next, let me also tell you how many matches these teams have won among the games that they have played so far. So, these are the numbers corresponding to their total number of wins. Recall that each of these teams played 8 matches against the four teams that you do not see in this picture. And we assumed that they had won all of those 8 matches. But of course, these teams have played some more games. So, let us look at what may have happened in those. So, let us say that Bangalore lost all of its first matches against Kolkata, Chennai, and Mumbai.\nSo, its total number of wins just remains at 8 from those other games. It does not go beyond that at the moment. As for Kolkata, let us say that, of course, we already know that it won its first match against Bangalore. And let us say that it won both of the matches against Chennai, and it lost the one match that it had with Mumbai. So, that means that its total number of wins is 8+1 for Bangalore and two for Chennai, and 0 from the match with Mumbai. So, that is a +3 and that is 11.\nAs for Chennai, we already know that it has one win against Bangalore, and it has lost both of its matches to Kolkata. It also played two matches against Mumbai. And let us say that it won one of those two matches. So, it has one win against Bangalore and one against Mumbai. And that brings its total score up to 8+2 = 10. Now, for Mumbai you know exactly what has happened. So, it is basically a one-one match each against Kolkata, Bangalore, and Chennai. So, that brings its total score up to 8+3, 11. Okay. So, these are the total number of wins that these teams have accumulated.\n(Refer Slide Time: 5:23)\n\nAnd here is the question that we are interested in. This is what is called the sport elimination problem. What we want to know is for our favorite team, and for this example, I am going to say that, that is RCB, I want to know if there is some way that the remaining matches can be played out so that RCB ends up being on the top of the league table? So by that I mean that RCB accumulates at least as many wins as any other team.\nSo, it is possible that RCB ties for the top spot with some other team and that is fine. But I just want to make sure that there is no other team that scores strictly more wins than RCB. So, remember that this is a question of checking for feasibility. Our predictions for the upcoming matches do not have to be realistic.\nThey do not have to be based on past statistics of how these teams have fared against each other, or what has happened in a particular ground. None of that is relevant here. I just want to know, hypothetically, can I set the outcomes of the remaining games in such a way that RCB ends up as one of the teams on the top of the table? So, I hope that this question is well formed, and it makes sense.\n(Refer Slide Time: 6:28)\n\nLet us go back to the numbers here. I invite you to pause the video here and see if you can figure out the answer to the question that we just asked in the context of this specific example. I am sure all of us have done a lot of this kind of analysis when the actual IPL tournaments are going on. So, most of us have plenty of practice with this kind of question. So, hopefully, this is answerable just by inspection. And this is a particularly simple situation by design. So, pause the video for as long as you need to, and come back when you are ready.\nAlright, so since we want RCB to end up at the top, I think it makes sense that we plan for RCB to win all of its remaining matches. Remember, this is purely a hypothetical, and we get to decide the fate of all the remaining matches anyway we like. So, this seems like a greedy choice. But in this case, you can justify it quite easily.\nSo, what we are going to do is say that for these three matches that RCB is involved in, it is going to win all three of them. And this brings RCB’s total score up to 11. And notice that no matter what happens, RCB’s final score, in terms of its total number of wins, cannot be more than 11. Because among the matches that have already happened, whose fate you cannot change, it has accumulated 8 wins. And the team itself is involved in three more matches.\nAnd this is the best-case scenario estimate on those three matches. So, this is our final score for RCB. But now notice that there is one game that remains between Kolkata and Mumbai. And both of them have accumulated 11 wins so far. And remember, we said that there are no ties. So one of these two teams is going to, in fact, win this game. And whichever team that is, irrespective of how the match goes, you are going to find that you are in a situation where there is a team that has accumulated a score of 12, which is more than what RCB can hope to achieve.\nTherefore, in this particular example, the answer to our question is no. No matter how the future matches play out, it is impossible for RCB to end up at the top of the league table. Of course, with a different combination of numbers and with a different set of games that remain to be played, the story could well be different. So, we want to of course address this question in general.\nSo, given all of this information as input in terms of what are the remaining games, how many wins do these teams have in the games that have been played so far, we want to address the question of whether a team stands eliminated from being on the top or not. So, let us see how we can answer this question by setting up all of this information in an appropriately designed flow network.\n(Refer Slide Time: 9:15)\n\nBefore getting to the description of the network, the first step is going to be what we just did with this example as well, which is that we are going to assume that our favorite team wins all of its remaining games. So, in these matches, there are really no points for guessing which way it should go. It is clear that we want our team to win all the matches that remain for it.\nAnd we are going to use X to denote the maximum possible score that our team, the one that we are focused on saving from elimination, that is the best possible score that this team can achieve. So, that number is the total number of wins that it has had so far, and the number of matches that remain for it. So, in the previous example, this was essentially 8+3, and this final optimistic score was essentially 11. Now, let us take a look at what other information we have.\n(Refer Slide Time: 9:57)\n \nSo, given that X is the most optimal score for our favorite team, the remaining information that we have to deal with is who are all the other teams that we are worried about, and what are the matches that remain between them? So, in this case, we have three other teams: Kolkata, Mumbai, and Chennai. And we pair them up in all possible ways. So, in this case, we have three teams and three pairings. In general, it is going to be some n teams, and some n choose two pairings.\nAnd for each of those pairings, you have a number that has been given to you, which says that this is the number of matches that these two teams have left between them. So, in the IPL format, this number will be 1 of 0, 1, or 2. But in some other tournament in some other format, this could be any number of games really.\nSo, our task here boils down to the following. If you fix a pair of teams, let us say P and Q, and let us say they have some number of games remaining between them, let us say Z, then we want to know how to split Z as a sum of two numbers, A and B so that we can say that team P is going to win A of these games, and team Q is going to win the remaining B games. And we want to be able to say this for each pair in such a way that hopefully the total number of wins accumulated by any team does not exceed X. We want to know if this is possible. Right.\nWe want to know if each of these numbers of games that remain between every pair of teams can be split between them in a way that the total number of wins accumulated by any given team is not too much. So, we are going to try and do that by setting up a flow network on this information. And as a hint, let me tell you that this flow network will have a vertex corresponding to every pair of teams, and a vertex corresponding to every team. So, that is just like what you see on your screen right now.\nAnd apart from these vertices, we will also add two extra vertices, which are going to be our specially designated source and target witnesses. So, our flow network is going to have all of these witnesses. But of course, the description of the network is far from complete. I need to tell you what are the edges, and also what are the capacities of these edges. But this is a great point to pause the video and see if you can complete the design of the flow network for yourself.\nRemember that for every vertex that represents a pair of teams, we need to somehow figure out how to talk about the number of matches that remain for that pair. And how this number gets distributed between the two teams that are involved in that pair. Keeping this in mind, try to think about what kind of edges and what kind of capacities you want to add to this network.\nSo hopefully, you had a chance to pause the video and think through this a little bit. Let me first tell you about how we are going to construct the edges. Already the way that I have positioned the source and the target vertices on the screen might give you a hint about how I want the edges incident on these two vertices. So, we are going to add an edge from the source vertex to every vertex that corresponds to a pair of teams.\nAnd, I am also going to add an edge from every team vertex to the target vertex. This again has a flavor that is similar to what we were doing with the matching problem, although the details here in terms of how the capacities work out and what the flow represents is going to be quite different. So, let us take a look at what is going on between the vertices that represent team pairs, and the vertices that represent the teams.\nA very natural thing here would be to connect a team pair with the two teams that are involved in that pair, because the number of matches that remain between, say Mumbai, and Kolkata is none of anybody else’s business. It is going to be something that Mumbai and Kolkata have to figure out between them as to how many matches is going to be won by Mumbai, and how many by Kolkata.\nSo, with that spirit in mind, what we are going to do is add edges between team pairs and teams so that every team pair has two outgoing edges to the two teams that are involved in that pair. So, that is the construction of the edges in the network. These are all the edges that we are going to have. What still remains to be fixed, of course, is the capacities of all of these edges.\nSo, once again, if you had this already figured out, then that is great, but if not, then this is a good place to pause and think about what kinds of capacities you want to associate with all of these edges here. So, hopefully you had a chance to think this over. So, let us first look at the edges that go between the source vertex and vertices that represent team pairs.\nA natural capacity to impose on these edges is the number of matches that remain to be played by the corresponding team pairs. So, if we have an edge from S to say, the pair Kolkata-Chennai, then we are going to basically look at the number of games that Kolkata and Chennai have remaining between them, and we assign that as the capacity of the edge from the source vertex to the Kolkata-Chennai pair and similarly for all of the other pairs.\nNow next, let us consider the edges that connect a team vertex to the target vertex. Here, we somehow have this intuition that this edge is going to carry an amount of flow that is representative of the number of matches that this team has won. And we do not want to allow this number to be larger than X because once it is larger than X, then the fate of RCB comes under question.\nSo, for example, let us say that RBC’s best possible final score is going to be 11. And let us say that Kolkata has already won 9 matches before this point. In this case, we want to say that Kolkata should not win more than 2 matches among all the remaining games. And we are going to capture this thought, by having the edge from Kolkata to the target vertex have a capacity of 2.\nMore generally, if you have an edge from our Q to T, where Q is some team and T is the target vertex, then this capacity should be X minus the number of wins that Q has already had in the tournament. So, this is the number of matches that is safe for Team Q to win without putting RCB’s position at the top of the leaderboard at risk. So, this is the capacity of all the edges going from the team vertices to the target vertex.\nNow, as for all the remaining edges, it turns out that there is nearly no need to impose a specific capacity constraint on them. So, you could think of them as edges that have infinite capacity. In any case, the amount of flow that goes through these edges is going to be automatically bounded by the capacity of the incoming edges from the source side. So, if you think about it a little bit, then you will see that imposing an infinite capacity and imposing a capacity that is, let us say, a fixed quantity, like the total number of remaining games, essentially amounts to the same thing.\nFor now, we will just think of these edges as free edges that do not have any explicit capacity constraint. So, that completes our description of the flow network. And now let us think about what can we hope to get out of a maximum flow in this network. What we want is an answer to our question, which is, is it possible to set the outcomes of all the remaining games in such a way that our favorite team ends up at the top of the final leaderboard in terms of its total number of wins?\nWell, the claim is the following. If a maximum flow in this network is able to saturate all the edges that are coming out of the source vertex – (and remember that a flow saturates an edge, if it uses it to its full capacity) – so, if the maximum flow can do that, in other words, if the value of the maximum flow is equal to the total number of remaining matches, of course, not counting the ones that our favorite team participated in, because those have been accounted for.\nBut let us say that the maximum flow is the value is equal to the total number of matches other than these, then we claim that there is in fact, a way of setting the outcomes in such a way that the position of our favorite team is protected at the top of the leaderboard. On the other hand, let us say that the value of the maximum flow falls short of this amount. In other words, even the maximum flow fails to saturate every edge coming out of the source.\nThis is going to mean that no matter how the outcomes of the remaining games play out, there is no chance for our favorite team to end up at the top of the leaderboard or to tie for the top position in terms of the number of wins, there is going to be some team in every situation that overtakes our favorite team strictly in terms of the total number of wins. So, that is the claim. And let us at least establish some intuition for why this claim is true. First, suppose that there is a flow that saturates every edge that is coming out of the source. In this case, let us propose the following outcomes for the games.\nSo, in particular, let us look at the Kolkata-Chennai pair. So, there is a certain amount of flow coming into this vertex, which is equal to the number of matches that remain between these two teams, because we know that the flow is saturating every edge coming out of the source. Now, because of the conservation constraint, this number must be split between these two outgoing edges, because this flow has nowhere else to go.\nSo, let us say the incoming flow was something like 10, then it has to be split in some manner between the two blue edges that are going to the vertices corresponding to Kolkata and Chennai. So, this could be 7+3, it could be 5+5, it could be 1+9, but it is going to be some integral split. You remember from our previous module, that you can always assume that your MaxFlow is integral, it associates an integer with every edge, because our capacities here are integers as well.\nSo, that is what we have at this point. And you can probably guess, how we want to interpret this flow for the purposes of predicting outcomes. So, let us say, for instance, we had an incoming flow of 10 units and it got split as 7 and 3 with 7 units of flow going to the KKR vertex and three units of flow going to the CSK vertex. This means that we are going to say that Kolkata wins 7 of these remaining 10 matches, and Chennai wins 3 of the remaining 10 matches.\nSo, this is how we are going to set the outcomes for each of the remaining sets of games that are to be played out between pairs of teams. Now, how do we know that after the matches play out in this particular way, our favorite team is still going to be at the top of the leaderboard. The reason for this is the capacities that were set up on the other side on the edges that go to the target vertex.\nSo, for any team, notice that the total number of matches they win is equal to the total amount of incoming flow on that vertex with respect to the outcomes that we just described. Now, again, by the conservation constraint, all of this flow has to be pushed out along this edge, because there is only one outgoing edge from this vertex, and it goes to the target vertex. But remember that we carefully set the capacity of this edge to be something like X minus the number of wins that this team has already had.\nSo, Kolkata has already won a certain number of matches, and the total number of matches, it is going to win, under the predictions that we just established, is going to be some number that is at most X minus the number of wins that it has already had. So, if you add up these two numbers, you get a number that is at most X. And notice that this is true for every single team in this picture.\nSo, if you do have a flow that saturates every edge coming out of the source, then you can map out a prediction, or you can map out a set of outcomes for all the remaining games in such a way that your favorite team ends up having at least as many wins as any other team. Now on the other hand, it is also true that if somebody gives you a set of predictions, which has this property, that if the matches play out in this way, then your favorite team is at the top of the table, then you can also formulate a corresponding flow, which saturates all the edges coming out of S.\nSo, the process to do this is very similar to the process that we just used to convert a flow into a set of match outcomes. So, now you just go in the other direction, which is to say that you route the flow based on the information that somebody gives you about how the match outcome should play out. So, once you do that, you will see that the following statement is true, that the maximum flow in this network saturates every edge going out of S, if and only if there is a way for these remaining matches to be played out in a manner that puts our favorite team on the top of the leaderboard.\nTherefore, to answer the question, all you have to do is run the MaxFlow algorithm on this flow network. And check if the value of the maximum flow is equal to the number of matches that remain, not counting the ones involving our team, because those we set in the beginning greedily anyway. So, that is essentially the crux of this formulation. And there are a few interesting things that you can think about from here.\nThe first is, well, if we cannot get to the top of the leaderboard, what is the closest that we can come to the top? Does the MaxFlow give us any meaningful information about this version of the question? The other interesting question you can ask is, whenever your team cannot make it, does the MaxFlow algorithm give you some explainable evidence for why it is impossible for your team to make it to the top?\nSo, remember, like in the example that we had, we were able to point to two teams, which were, I think, Kolkata and Mumbai. And we said that, well, they have one match between them, and the scores are already threatening RCB. And no matter how this match goes, one of these teams will end up overtaking RCB score. So, this is an explanation that you can give to a friend who knows nothing about network flows.\nSo, can you use this flow network whenever the flow falls short of the number of remaining games? Or in other words, a flow that fails to saturate all edges coming out at the source – can you use such a flow to build up some explainable evidence for why your team is not going to make it? It turns out that the answer to this question is yes, but we probably do not have the language to talk about how to extract this information from the network flow yet.\nSo, for this, stay tuned to week 9, which is where we will talk about something called the duality of MaxFlow and MinCut. And once you see this sort of duality, you will be able to probably answer this particular question and hopefully a very interesting way. If you cannot wait to see how this works, then you could look up the pointers in the description of this video to find out more details about how to pull out an explainable piece of evidence for why your team will not make it to the top no matter how the matches play out, and this evidence does not involve detailed case analysis, saying, let us just enumerate all of the possibilities and see what happens.\nIt is a lot more elegant and succinct than that. So, hopefully, you will have a chance to check it out. Or the other option is to just wait till you are done with week 9 and think about it for yourself. So, with that, it is a wrap on week 8. And when we move on to week 9, it is still going to be about flows. But from a slightly different perspective, it is going to be from the perspective of a closely related problem called the MinCut problem.\n\nAnd we will look at a couple of examples where it is useful to find the MinCut, and we will do that using the MaxFlow algorithm that we already know. So, I look forward to seeing you there. Thanks so much for watching, and bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W08/Lec46.html",
    "href": "materials/cpnotes/W08/Lec46.html",
    "title": "M 2 (Maximum Matching via MaxFlow)",
    "section": "",
    "text": "Lecture - 46\nNetwork Flows - Module 2 (Maximum Matching via MaxFlow)\n(Refer Slide Time: 0:11)\n\nWelcome back to the second module of the eighth week in Getting Started with Competitive Programming. So, as you might remember, this week, we are talking about network flows. And in the first module, what we did was set up the problem of finding a maximum flow through a flow network.\nNow, in its own right, this may sound like a fairly specific problem to solve, so you might be wondering why it is presented as a technique. And I had mentioned that one of the reasons it is the case is because a whole host of problems can be essentially modeled as the problem of finding a maximum flow through a flow network, even if it is not, apparently, related to graphs and often many graph problems also can be modeled in this way.\nSo, I want to demonstrate that through a couple of examples. The one that we are going to see in this module is essentially a problem that can be thought of as a classic graph problem. And we are going to see how that essentially boils down to finding a maximum matching in an appropriately set up flow network. And in the next and the last module for this week, we will talk about a fun problem called SPORT elimination, which on the face of it, does not look like it has anything to do with graphs at all, and yet can be solved using maxflow once again.\nSo with that said, let us get started with the problem for this module. This one is called BerSU Ball if I am pronouncing that right. This is from Codeforces, and if you look at the tutorial for this problem, it says that there are like 10,500 ways of solving this problem. And this is going to be one of them. Some of this story might remind you of a problem called stable matching, which we talked about way back when we were doing greedy algorithms. But this turns out to be a much simpler setting.\n(Refer Slide Time: 2:00)\n \nSo, let us take a look at the problem statement. So, we are given n boys and m girls, as part of the inputs. So, let us meet them and let us say that they look like this. What we are also given is their dancing skill levels. So, this is just a number that is associated with every person in the problem. So, let us denote these skill levels by these numbers in the red boxes. We are told that a boy and a girl are a ‘compatible dancing pair’ if their skill levels differ at most by one.\n(Refer Slide Time: 2:30)\n\nSo, let us figure out who the compatible dancing pairs are in our example here. Now, as you can imagine, this is going to be convenient to think of as a graph. So, let us imagine that all the boys and the girls that we have here are vertices of a graph. And the construction of the edges basically reflects the compatibility in the sense that was just defined a moment ago, where we said that a boy and a girl form a compatible dancing pair if their skill levels differ by at most one. So, you could pause the video here and try and enumerate all the compatible dancing pairs, or you could just follow along and verify that, hopefully, we have drawn these correctly. So, we are going to draw an edge between a pair of vertices corresponding to a boy and a girl, if and only if the numbers that are associated with them differ by at most one. So, these are going to be the edges, for our example here.\n(Refer Slide Time: 3:27)\n\nSo, that is the input, and our goal is to form as many pairs as we can for an upcoming event. So, notice that these pairs should be disjoint. So, they are all going to go to this event and be involved in simultaneous dances. So, it is going to be very awkward if you have the same boy or the same girl being involved in multiple pairs. So, that is your main constraint – that you want the pairs to be disjoint.\n(Refer Slide Time: 3:50)\n\nAnd once again, let us take a look at our example. So, here you can see that, well, the maximum number of pairs you can form is actually four because there are only four boys even though there are five girls. So, one of the girls is necessarily going to be left out. And you might wonder if it is actually possible to form four pairs.\nSo, take a moment here and see if you are able to form 4 disjoint pairs of boys and girls who are mutually compatible when it comes to dancing together. Alright. So, if you had a chance to think about it, you will probably find that there is at least one way of forming these pairs so that you actually get four pairs, and as we said, that is the best that we could hope for in this example. So, this is the optimal answer.\nYou could think about if there are other ways of forming these pairs. And it is probably an interesting question to think about, how many ways you can form these pairs. But that is a question for a different occasion. We are just going to focus on the problem of finding the maximum number of compatible disjoint pairs that we can form.\nSo, what we are going to do is, we are going to set up a flow network around this graph or based on this graph and we want to set it up in such a way that the maximum flow through the network corresponds to the answer that we are looking for, which is the maximum number of disjoint pairs, which I will henceforth refer to as a maximum matching because the language of graphs collection of disjoint edges is called a ‘matching.’\nSo, here is the flow network that we are going to set up. I am going to reveal this in a moment. So, if you want to play around with this and try to come up with your own construction, then feel free to take a pause here and come back when you are ready.\n(Refer Slide Time: 5:34)\n\nSo, we are going to work with the graph that we have just built up. But remember that flow networks are directed graphs, and we actually do want to orient these edges. Of course, we have said before that we could work with undirected graphs by modeling them as bi-directional edges, but in this example, we would not really want to do that.\nSo, we are going to take all the edges that we have between boys and girls and orient them so that every edge is going from a girl to a boy. So, they are all oriented from left to right. I do not know if the arrows are clearly visible on your screen, but if not then just keep in mind that, that is the direction that we have associated with these edges. Now, remember that every flow network has two special designated vertices, which we call the source and the sink.\nSo, let us introduce a source vertex. This is an extra artificial vertex on top of what we already have. And what we are going to do is make the source vertex adjacent to all the vertices that are representing the girls. Similarly, we are going to introduce a sink vertex and we are going to make all the vertices representing the boys adjacent to the sink vertex. So, that is going to be the structure of our flow network. But this does not complete the description of the flow network. You want to think for a moment about what information is missing.\nSo, if you recall a flow network was a directed graph with two special designated vertices called the source and the target. But also we had a capacity function. So, our description of this flow network will be complete once we specify capacities for all the edges out here. And this is where, as somebody who is modeling the network, we have full freedom to specify whatever capacities we want.\nAnd we want to engineer the capacities in such a way that a maximum flow through the network actually picks up the solution that we wanted to find for us. So, usually, whenever you are modeling any problem as a flow network, you can think of the capacities as an opportunity to encode, whatever constraints you are working with. So, remember that in this problem our goal is to find the largest collection of matching pairs between the girls and the boys.\nSo, in some sense, I can already anticipate that I want the flow to help me find a solution. So, for instance, if I am routing one unit of flow from the source to a particular girl and from there it has to go to one of the boys and it will finally end up at the target vertex, I do want to be sure that this flow is not something that asks me to either choose two boys for the same girl or ends up going to the same boys starting from two different girls on the left-hand side.\nSo, somehow my mindset is that that is something that should be prevented. So, a flow should not be allowed to behave in that way, (to be) to give me solutions that do not make sense. So, you can think about this question for a moment here: What sort of capacity should you associate with the edges so (that) the flow corresponds in a very natural way to a matching? So, take a pause here and come back once you have had a chance to think through this a bit.\n(Refer Slide Time: 8:55 and 9:15)\n \nAlright. So, here is what we are going to do. We are going to set the capacities of all the edges to one. I should mention that this is not necessarily the only way of doing it. I am just putting it this way because it is easy for me to state what we are going to do. You do have some flexibility in how you design the capacities. You could do it slightly differently and it would still work.\nBut what is really crucial is that all the edges that emanate from the source vertex and all the edges that land on the target vertex – these two sets of edges must have ‘unit’ capacity for this network, to do what we wanted to do. So, we will see exactly how that plays out in a moment. But before we get to that I want to detour and make a small remark about the nature of max flows in networks that have integer capacities because this is a fact that will be useful for our upcoming discussion.\n(Refer Slide Time: 9:43)\n\nSo, it turns out that if all capacities are integers, then you can always find a maximum flow, which associates an integral value to every edge. This is not very hard to see from the behavior of the Ford-Fulkerson algorithm that we discussed in the previous module. So, if all your capacities are integers, then notice that the bottleneck capacity will also be an integer in every iteration.\nSo, the amount of flow that you push in every iteration, the amount by which your max flow gets incremented in every iteration, is also an integer. So, you can formally prove this using induction on the number of iterations and so on. But hopefully, for now, you find it believable that, this statement is true. Notice that all of our capacities are unit capacities.\nSo, essentially when you are looking at an integral maxflow, that just means that every edge is either completely used by the flow or it is not used at all. So, there are no fractional flow values. There is no edge that has a flow of 0.5 passing through it. So, because of this, it is kind of convenient to really describe this flow because every edge is going to either be fully saturated by the flow or is going to be completely avoided by the flow.\nSo, saturated is a term that we use when the flow passing through the edges is equal to the capacity. Because the maxflow is integral and the capacities are one, we are in a situation where every edge that has a flow passing through it is in fact, saturated. And every other edge is basically not used by the flow at all, it does not have any flow passing through it.\n(Refer Slide Time: 11:13 and 12:47)\n \nSo, let us take a look at an example here. So, this is some flow that has been proposed. So, the blue edges are the saturated edges and the other edges are not used by the flow. Pause the video here for a moment and think about whether this could be a maximum flow or whether you can do better.\nAlright. So, one way to check if this is a maximum flow or not is to do what our algorithm would have done, which is to say that you compute the residual graph, which looks like this. Essentially every edge that had a flow going through it gets reversed and all the other edges remain as it is. I have not shown you here, the edges that have a residual capacity of 0 because those edges are effectively missing from the network. We never use them when we find an S-T path. So, this is what the residual graph looks like and the question you are interested in is whether there is an S-T path in this graph.\nSo, if you think about it for a bit you will discover that there is indeed at least one S-T path, and here is one that looks like this. It is been highlighted by the orange edges. So, what happens when you push a unit flow? So, remember that all the edges have unit capacity. So, your bottleneck capacity will also automatically be one. So, you are going to pass a unit flow through this S-T path. Notice that this path has one back edge. So, that essentially means that we are going to reverse our decision of using the edge between the third girl on the left and the first boy on the right.\nSo, we do not want to pass the flow through that edge anymore, and instead, we are going to pass a flow through these other two edges that you can see here on your screen. Now notice two things about this particular flow. First of all, it has a value of four, which seems to be a bit of a coincidence. Remember that when we were working on finding a maximum matching on the example on which this flow network is based, we found that the largest matching that we could find had four edges.\nSo, that is one thing. The other one is, that notice that this is also a maximum flow because if you look at for example all the edges that are incident on the target vertex, the total capacity of these edges is four. So, you cannot possibly have any flow that has a value that is greater than four. So, the maxflow in this network has a value of four, and it seems to coincide with the value of the maximum matching that we found earlier in the graph on which this flow network is based. It turns out that this fact is not a coincidence for this example, and it is actually true in general.\nNow before we talk about why these two values are equal, let us talk about how we can use the flow to obtain a matching in the graph that we originally had. So, to do that, what we are going to do is, reverse the process that we used to construct the flow network from the graph. So, now I want to go back to the graph.\n(Refer Slide Time: 14:06)\n \nSo, I am going to start off by throwing away the source and the target vertices. And in what remains I still see the edges that have been saturated by the flow. So, let us just focus on these edges and notice that these edges actually form a valid matching. So, once again this is no coincidence. The fact that – the edges between the boys and the girls (that are) saturated by any flow form a matching – is something that you can actually prove.\nSo, if you like, take a moment here to think about why this always turns out to be the case, and when you are back, we will continue our discussion and actually establish this as a fact. Alright. So, here is, what we want to claim. We want to claim that any flow of value k in this flow network corresponds to a ‘matching’ with k edges in the graph on which this network is based.\n(Refer Slide Time: 14:44 and 14:52)\n \nTo see this, notice that we had these edges from the source and the edges incident on the target, which had capacities of one each. So, if you focus on the set of edges that are saturated by the flow that goes between the boys and the girls, think about what would happen if those edges had a structure that did not look like a matching.\nSo, that would mean that you either have a situation where you have one girl who is matched with two boys or more. Or you have one boy who has been matched with two girls or more. In the language of graphs, you would say that there is a vertex in the left column, corresponding to the girls, that has a degree of two or more. Or you have a vertex in the right column, which corresponds to the boys, that has again degree two or more, among just the edges that have been saturated by the flow.\nBut notice that this is impossible because, for instance, suppose you had a vertex corresponding to a girl which had degree 2 among the edges saturated by the flow, then you violate the conservation constraint at this vertex. Because notice that the maximum amount of flow that can come into this vertex is one and that means that there is only one unit of flow that you can route out of this vertex.\nAnd remember that every edge that is being used by the flow, is fully saturated because that is the kind of flow that we are working with without loss of generality. Right. So, it is not that you have these two outgoing edges where you are going to split the flow half-and-half because that is just not the kind of flow that we are working with.\nA very similar argument holds if you have a vertex corresponding to a boy that has degree two among the saturated edges. So once again you will violate the conservation constraint. In this case, you have too much flow coming into the vertex and you cannot shake it off because the only edge that is outgoing from this vertex is to the target vertex and that has a capacity of one.\nSo, if you have an incoming flow that is greater than one, then it will necessarily violate the conservation constraint. So, this shows that if you have a flow of value k then you can actually use the flow to obtain a matching on ‘k’ edges as well, by simply looking at those edges between the boys and the girls that are saturated by the flow. It will necessarily have a matching structure.\n(Refer Slide Time: 17:13 and 17:23)\n \nOn the other hand, if somebody gives you a ‘matching’ in the graph that we started with, then you can actually use that matching to also construct a flow whose value is the same as the number of edges in the matching.\nTo see that this is true let us begin by considering a matching in the graph that we started with. Now recall how we built the flow network. We essentially built it on top of this graph. So we oriented all the edges of this graph and then we added a source and a target vertex and some additional edges. The point is that every edge that you see here is in one-one correspondence, in a very natural way, with some edge in the flow network. So, essentially let us find this matching in our flow network.\n(Refer Slide Time: 17:49)\n\nAnd let us begin by saturating these edges. So, I have defined a partial flow, where we have essentially taken the edges of the matching and we have decided to pass one unit of flow through these edges. Now as you can see this is not a valid flow yet because we are violating conservation constraints at both endpoints of these matching edges. So, take a moment here to think about, how you will fix this issue with this partial flow that we have built up so far. This is really a very natural thing that you can do. So, see if you can find it and come back when you are ready.\nAlright. So, to turn this into a valid flow what we are going to do is basically extend it in both directions. So, for every girl who has been matched by this matching, we are going to add a flow of one unit, from the source vertex to the vertex corresponding to the girls. So, we have a flow going through these edges here.\nAnd similarly, for every boy that is matched by the matching, we are going to push one unit of flow through the edge, which has its endpoints as the vertex corresponding to that boy, and the target vertex on the other hand. So, that is a flow going through all of these edges here. So, you can see that this is a perfectly valid flow. And its value is clearly equal to the number of matching edges that we started off with.\nSo, that is how you go from a ‘matching’ to a ‘flow.’ Given both of these statements, you can see why the value of the maximum flow in this network is equal to the size of a maximum matching in the graph that we started with. So, here is what our algorithm is going to do for this problem.\nIt is going to build the flow network and then return the maximum flow by invoking a flow algorithm. Notice that this may not be the most efficient way of finding a maximum matching in a bipartite graph. So, for instance, in SPOJ, there is a problem called fast matching and if you try to use this approach to solve that problem, then you will time out on some of the larger tests.\nSo, there are more fine-tuned maximum matching algorithms and you can find out more about them separately. But it turns out that in many situations if the constraints are reasonable, this is a perfectly valid way of finding a maximum matching. Just keep in mind that if your constraints are crazy, then this may not always work. Alright. So, what does the code look like?\n(Refer Slide Time: 20:00)\n\nIt is actually really simple. You just have to essentially bring in the information about the skill levels of the boys and the girls and then we initialize this max flow object with the number of vertices being the number of boys + the number of girls + 2 because we need those two extra source and target vertices. And then what we do is, basically go over all boy-girl pairs, check if their skill levels differ by at most one, and if they do, then we add an edge from the vertex corresponding to the girl to the vertex corresponding to the boy or the other way around – it does not really matter as long as you are consistent.\nSo at this point, we have built up the bulk of the graph, the middle part. Now we need to add the source and the target vertices. These have been implicitly added just because we have the correct number of vertices. What we really need to add to the system is the edges that are incident on the source and the target vertices.\n(Refer Slide Time: 20:55)\n\nSo, let us go ahead and add these remaining edges. Remember to set these capacities to one. This is really crucial for the algorithm to have the desired behavior. Once you are done with these steps, you have actually completed building out the flow network. Now all you have to do is compute the maxflow and return the value of the maxflow.\nSo, what we are doing here is invoking Edmonds-Karp, which is the function that computes the maxflow the one that we discussed in the first module. So, all that you have to do now is output the value that is returned by this function, and you are done. So, as you can see all the heavy lifting is really done by this function call. All you have to do is really construct the appropriate flow network.\nSo, this is true for most problems that are based on modeling some other problem as an instance of maxflow. The work is really around finding the right construction and convincing yourself to some extent that the construction appropriately captures whatever it is that you are trying to find. But once you have that figured out the implementation typically is quite straightforward, especially assuming that you already have access to the maxflow functions in advance.\nSo, that is about it for this particular module here. We are going to continue our conversation with one more example of maxflow modeling, for a problem that is called sports elimination. So, that is the final module for this week and I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/W08/Lec43.html",
    "href": "materials/cpnotes/W08/Lec43.html",
    "title": "M 1 (Introduction)",
    "section": "",
    "text": "Lecture - 43\nNetwork Flows - Module 1 (Introduction)\n(Refer Slide Time: 0:11)\n\nWelcome to the eighth week of ‘Getting Started with Competitive Programming.’ For this week and the next, we are going to be focused on ‘network flow,’ which is our last major topic in the context of graph algorithms. If you are seeing the flow problem for the first time, then it may strike you as a really specific problem. And you may wonder if it is worth all the trouble to just learn one specific problem.\nSo, my hope is that through examples that we talk about this week and the next you will also see why it is not just this one problem but a really powerful technique in the sense that there can be so many other problems, which may not look like they have anything to do with flows and in fact they may not even look like they have anything to do with graphs, but they can still be in some sense modeled or converted as an instance of the flow problem and then everything that you have learned here will become really relevant.\nSo, in this module, we are going to start off by just setting up the problem introducing you to what the optimization goals are, and also describing one particularly popular solution to the problem, which we will implement in the context of a UVa problem called ‘internet bandwidth,’ which really very directly asks you to solve an instance of maximum flow.\nThere is not much going on here in terms of disguise. It is a pretty routine maximum flow problem. But the good thing is that it will give us an opportunity to test the correctness of our implementation. So, with that said let us get started. So, before giving you a bunch of formal definitions, let me begin with a story that will hopefully illustrate the major aspects of the flow problem, and then we will get to set it up in a more precise way.\n(Refer Slide Time: 1:55)\n  \nSo, let us say that we live in a city where there is a factory, and there is a shop, and the factory needs to send materials to the shop on a fairly regular basis. The way it has to do this is, by using the road network in the city and let us say that it looks something like this. So, there are four other, sort of, locations, and these locations are connected by one-way roads with directions specified by the arrows and the presence of the roads indicated by the edges that connect these locations.\nSo, as you can see, there is a truck that is waiting in the parking lot of the factory, and what it would normally do is just, you know, take up a path from the factory to the shop and perhaps find its way back. If you wanted to find, in some sense, the shortest path, if you have the length of the roads at hand, then you already know how to do this based on our discussions before about the shortest path problem and so on.\nLet us now imagine that sending one truck across is not really enough. A lot of supplies need to be sent. And they only fit in across multiple trucks, which need to get simultaneously to the destination.\n(Refer Slide Time: 2:46)\n \nSo, let us say that we now have three trucks and the drivers are friends and they just want to go through a common route. So, they all go a particular way that they like which just happens to be different from the one that we saw before. As you can see there are multiple ways of getting from the factory to the shop. And as of now, all of these roads are completely open and fully available to us. So, using any of these paths, from the shop to the factory would be perfectly fine.\nLet us say that at some point we have some construction work going on, on this road from C to B, because of which we are told that you cannot have more than one truck passing through this road at a time. Okay. So, this means that what we just did – have all the ‘three trucks’ that we have, use this road simultaneously – is no longer possible.\nAnd you should also imagine that these trucks are continuously moving. So you cannot say that, oh, I will have the first truck first take up the road and I will keep the other two waiting at C, and once the first truck has reached B, then I will send the second one. So, that is something that we do not really allow. You have to think of all the movement that happens across the road as being, in some sense, simultaneous. Or the other way to think about it is that the trucks are not going to wait. So, they are not permitted to actually stand at a particular location.\nSo, whatever comes into a particular vertex, has to immediately move out, along one of the outgoing edges from that vertex. Okay. But it is just this one road that is constrained, so in fact, we can still continue to send our trucks across other parts. And even if for some reason this was our lucky road and we want to make sure that we send at least one truck across this road, it is still okay because there are a few other options that are still available to us.\nSo, for instance, here we are sending even a collection of 5 trucks, by just exploiting the upper and the lower paths that are still available in an unconstrained sort of fashion. But let us say, a few days go along and now one of the other roads also becomes constrained in terms of how much traffic it can handle.\n(Refer Slide Time: 5:10)\n\nAnd let us say this keeps happening to the point where you are given numbers for every road in the network. And you are told that look this road can only handle so much traffic at a time. And now you are just back to the drawing board and you are trying to figure out, what is the maximum number of trucks that I can send simultaneously from the factory to the shop.\nIn fact just by looking at these numbers, can you come up with a quick upper bound on the maximum number of traffic that you can send from the factory to the shop? So for instance, like before, is it possible to send 5 trucks or 4 or 3? Just think about that for a moment and come back when you are ready. Alright. So, hopefully, you had a chance to think about this for a minute. You might have thought that, for example, if you look at the roads that are going out of S, they have capacities of 9 and 7. So, it is certainly not possible to send out more than 16 trucks at a time.\nBy similar logic, you may have observed that the two edges that come into the shop, which are the only two possible ways of reaching the shop, have capacities 2 and 3, which means that no matter what we do we will not be able to send more than 5 trucks at a time. So, of course, 5 is more informative than 16, so if you discovered that then that is definitely an improvement.\nBut if you looked at the numbers a little bit more, you may have observed that any way of going from the shop, from the factory to the shop, irrespective of how you choose to do it, you cannot avoid these 3 edges that are in the middle, which all have a constraint of one truck at a time. So, these edges are the edges from A to B, from C to B, and from C to D. There is no path from the factory to the shop that does not use one of these edges.\nSo, at any given point of time, let us say, if you are able to send 4 trucks simultaneously, then by the ‘pigeon hole principle,’ you must be sending, at least, two trucks on one of these roads. But then that is a violation of the capacity constraints that we are working with. So if we want to respect these numbers that are there alongside the roads, then well the maximum number of trucks that we can send across this network is certainly at most 3.\nAnd you can probably figure out that this bound is tight in the sense that you can actually find a way of sending 3 trucks across this network without encountering a problem. Notice that when you do come up with a way of doing this, there are going to be at least 3 but very likely 4 edges that you are using to their limit, in the sense that the number of trucks that you are sending across these edges is actually equal to the capacity of the road that they are traveling on.\nSo, in some sense, you can think of these edges as being saturated or as being tight. Different people use different terms to describe this situation, where a certain edge in the network is being completely used up to the brim. Okay. So hopefully, this setting gave you some intuition for the sort of thing that we want to do.\n(Refer Slide Time: 8:10 & 10:16)\n \nSo, let me now introduce the formal definition of a flow network. So, a flow network is simply a directed graph, which has two special vertices, which are called the source and the target. They are often denoted S and T. You can typically assume that the source is a vertex that has in-degree 0, which is to say that all the edges incident on the source, are going out of it. And you can also assume that the target is a vertex that has out-degree 0, which is to say that all the vertices incident on T, are in fact incoming edges, they are coming into T.\nSome people like to refer to this target vertex T as the destination or the sink vertex. So, you will often hear about a source and a sink in a flow network. So, it does not really matter which words you choose to use as long as you know what they mean. Now, apart from specifying these two special vertices, we are also given a ‘capacity’ function, which you can think of as a way of modeling the numbers that we just discussed in the example that we talked about earlier.\nSo, a capacity function simply assigns a non-negative number to every edge in the graph. And you want to allow for the possibility of assigning a so-called infinite capacity to your edges as well if you need to. That is just a way of modeling the idea that some edges do not even have a capacity constraint as such. You can pass as much flow through them as you want.\nNow, even though we have not formally defined what a flow is, hopefully, based on the discussion we have had so far, you know what I mean in an intuitive sense. Now in terms of, where these numbers come from, they could be real numbers. But often based on your application, they could just be integers.\nSo, you have to worry about this, when you have to declare the type of array that is going to store the capacity information. So, just remember to watch out that for a bit. We are going to usually default to integer capacities because for most applications that is, kind of, enough. But just do watch out for scenarios that may be different from this default. Alright. So, this is the input. This is what a flow network is. This is what is given to us.\nNow let us talk about what a flow actually is. So, a flow is also an assignment of numbers to the edges of a flow network, but unlike capacities, for instance, we do not really require these numbers to be non-negative. And we do require them to respect certain constraints. Okay. So, first of all, our concept of a flow needs to model this idea of things not waiting at the junctures.\nRemember when we were talking about having trucks move from the factory to the shop, we said that trucks are not going to wait around at the intersections. So, this idea is captured by what we call a conservation constraint, which roughly speaking says that all the flow that comes into a vertex must also leave that vertex. This is going to be true for all vertices, other than the specially designated source and target vertices.\nSo, what we want is that if we add up all the flow that comes into a vertex, which is the term that you see on the left-hand side of this equation, so, this is basically a sum over all the in neighbors of the vertex v and we are looking at all the flow that is on those edges, that must equal the total amount of flow that is going out of the vertex v, which is to say that this is now a sum over all the out neighbors of v. And we are basically adding up all the flow that has been assigned to all of these out edges.\n(Refer Slide Time: 11:41, 12:16 & 12:51)\n  \nSo, just to visualize this constraint here is a quick picture. So, we have a flow network here. The capacities have not been explicitly mentioned. But if you look at vertex A, then the edges of interest are marked in blue and red. And what we want is that whenever we assign a flow, we would want the total amount of flow on the blue edges to equal the total amount of flow on the pink edge. So, in this case, there is just one out-neighbor. In general, there could be more. And we just want all of these numbers to tally up.\nThe other thing that we are interested in is of course the role of the capacity function. So, we say that a flow is feasible, if it respects the capacity constraints. So, in particular, what we want is that for every edge, the flow that we assign to that edge must be, at most, the given capacity of that edge. Okay. So, that what a valid flow is, it is an assignment of flow values to every edge that respects conservation constraints on every vertex other than the source and the target, and respects capacity constraints on every edge.\nNow what is the optimization objective here? Well, in some sense we want to maximize the flow that we can pass through this network. Well, what does it mean to maximize the flow? What is the value of a flow?\nWell, one way of thinking about the value of the flow, if you go back to the example with the factory and the shop, is essentially how much material was the shop able to receive or how much material was the factory able to push out.\nIt turns out that these two quantities are actually always going to be the same if you are working with a valid flow. Intuitively the reason is that everything that gets out of the factory because there is no possibility of getting stuck at intersections, all of that material must move through the network and is compelled to really come to a halt at the target which is the shop.\nSo that is an intuitive way of imagining why these two quantities must be the same, but let us just look at it in a little more precise sort of language.\n(Refer Slide Time: 13:49 & 14:04)\n \nSo, in particular I am going to say that the value of a flow is just the total amount of flow that is coming out of the source. So, we sum the values of the flow on the edges that are incident to the source vertex.\nAnd what I was just saying is that this is the same as talking about the amount of flow that ends up at the target vertex. So, if we were to sum the flows on all the edges that are incident to the target, this would be the same thing.\n(Refer Slide Time: 14:18, 14:38 & 14:57)\n  \nTo see why this is the case, let us just look at this quantity, which is the sum of all the flows and all the edges written out twice and let us say we subtract one from the other then, of course, since we are subtracting two expressions which are exactly the same, the sum is 0. But let us look at the sum a little more closely. Notice that every edge is incoming for some vertex and outgoing for some vertex. So, every edge is incident on exactly two vertices. And from the point of view of one of these vertices, this is an out edge and from the point of view of the other vertex this is an incoming edge.\nSo basically, what we do is, let us just mark all the edges that are incoming on the vertex ‘u’ and mark all the edges that are outgoing for a vertex ‘u.’ Let us do this separately, for every vertex ‘u’ other than the source and the target. So, when you do this for a specific vertex, when you identify all the numbers corresponding to the flows on the edges incoming to that vertex, and all the edges that are outgoing, well, you will zone in on a subset of numbers which will essentially cancel out because of the fact that this is a flow and it respects the conservation law.\n(Refer Slide Time: 15:42)\n \nSo, these sets of numbers, will just keep cancelling out for every vertex that you consider. And once all the cancellations are done, what you will be left with, is the flow into the sink minus the flow out of the source. But now remember that we started with an expression that was equal to 0. So, this gives us the claim that the flow that comes into the sink or the target vertex is the same as the flow that got out of the source.\nSo, this is the quantity that we are looking to minimize. We are trying to find a maximum flow, a flow that maximizes its value, the value being how much were you able to push out of the source or equivalently, how much were you able to accumulate at the target. Alright. So, that is the goal and what we are going to do in the next segment of this module is to try and come up with an algorithm that actually finds the maximum flow.\nJust to leave you with something to think about, before you come back, let me propose a natural greedy algorithm for maximizing the flow. Remember that we are interested in getting materials across from the source to the target.\n(Refer Slide Time: 16:42 & 19:04)\n \nLet us just go back to the example that we were working with, with the factory and the shop. So, let me just try and see if I can find a path from the factory to the shop. So, for instance, here is a path which is highlighted in yellow and for these edges, I have also jotted down the capacities of these edges for you.\nSo, if you were the manager at the factory and you are considering this particular route to the shop, how many trucks do you think you would be able to send across this particular path? Well, you have probably observed that although the first road on this path can accommodate as many as nine trucks.\nIf you try to send 9 trucks, they would only be able to go as far as B and then after that seven of them would not know what to do because only two of them would be allowed to pass through. And since you know that you cannot have things waiting at interim locations, you know that nine is definitely not feasible. In fact no number larger than 2 is going to be feasible because that is, in some sense, the weakest link in this chain.\nSo, here of course we have assumed also that there is no pre-existing flow and these are the original capacities. In general you might be in a situation, where you have already designated a plan where some trucks may already be using certain edges, in which case you will have to work with the remaining capacity as opposed to the original capacity. But let us not worry about that for now.\nLet us just imagine that we are at the beginning of the process, where the full capacity is available to us. And in this setting, and also more generally, the idea that is worth remembering is that whenever you are thinking about pushing flow along a path, you have to worry about what we normally refer to as the ‘bottleneck’ edge, which is the edge that has the lowest capacity. Because this is what is going to determine the maximum amount of flow that you can actually push along this path.\nSo, applying this general principle to this particular example, we can conclude once again that the maximum amount of flow that you can push through this particular path is two units. So you can plan to send two trucks along this path, which means that one way of remembering that this is something that we decided to do is by adjusting the capacities to reflect our decision.\nSo, in particular, let us reduce all the capacities of these edges by two units, so that we know that, that is what this capacity was reserved for. So, at this point, the last edge on this path is as good as gone. It is a 0 capacity edge. And we will never be able to use it.\n(Refer Slide Time: 19:23)\n\nSo, it makes sense to go ahead and actually delete this edge. And now we could basically do the same thing. We could find a path from S to T, once again, in this graph with the adjusted capacities. And we could again determine the bottleneck capacity on that path and determine that, that is the amount of flow that we could push along this new path.\nWe could again adjust the capacities and we could keep doing this. At some point we are going to get stuck. And that is going to happen when you can no longer reach D from S. So, when S and T are disconnected from each other. That is when we can no longer continue to increment our flow, as I was just describing.\nNotice that you will get stuck at some point, you cannot go on forever. And the reason for that is that in every iteration, you are strictly increasing the value of the flow that you are working with. So, the maximum flow is a finite number that is the bound on the number of iterations that you will go through.\nSo, this is definitely a legitimate procedure for producing a valid flow. But we are interested in more than just coming up with some valid flow. We want a flow that has the maximum possible value. So, does this algorithm do that for you or did I just string you along on something that is potentially sub-optimal?\nI will let you think about that and if you want to find out, you should come back to the next segment of this module, where we will talk about this algorithm and we will build up on it in interesting ways. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/W01/Lec04.html",
    "href": "materials/cpnotes/W01/Lec04.html",
    "title": "M 4 (Will It Stop?)",
    "section": "",
    "text": "Lecture - 04\nAd hoc and Implementation - Module 4 (Will It Stop?)\nWelcome to the final module of the first week on AdHoc and Implementation-based problems. I do hope that you have had a good time solving the problems that we have showcased so far in this week. And, as usual, this is a friendly reminder that if you are stuck anywhere at all, then please do join us in the Discord community that has been set up exclusively for this course. Now, in this module, we will be talking about a fun problem called, Will It Stop?\n(Refer Slide Time: 00:43)\n\nThis problem features in a really nice compendium of contest problems called looking for a challenge, Volume 2. And at the time of this recording, this book is freely available from the book’s website. So, you can find the link in the description below, as well as on the course homepage. I should, perhaps, mention that this book consists of model solutions to problems that featured in the Polish College at programming contests, the ones that took place between 2011 and 2014.\nAnd while this is an excellent collection of problems, if you are just starting out on your competitive programming journey, you might find that they are a little more advanced than what you are prepared for right now. Do not worry about it, and definitely come back to them later, when you do have the background to appreciate some of the other problems. The problem that we are featuring in this video is problem C, and it, fortunately, requires no specific background. And it is a really cute problem. So, let us get right to it.\n(Refer Slide Time: 01:43)\nLet us begin by taking a look at the problem statement without the story for now. So, here is the task at hand. We are given the following program.\n\nYou can see that it is a snippet of code that involves a while loop and a number n. And it seems to be doing something different based on whether the number n is even or odd, to begin with. Specifically, if the number n is even then it seems to be getting halved. And if the number is odd, then it is roughly getting tripled. Specifically, it is transforming as 3 * n + 3.\nSo, at a high level, what is happening is that the number is either becoming smaller or bigger based on whether it was even or odd, to begin with. You can probably already imagine that there might be values of n for which this while loop just goes on forever and the program never terminates. It turns out that this is precisely our task.\nWe are given a number n as input. This number can range anywhere between 2 and 1014, which is just to say that this can be a pretty big number. And we have to identify whether this code that you are seeing on your screen right now terminates when n is given to it as input.\nWhat would be the most natural way of trying to solve this problem? Well, it might occur to you that we should just try to simulate this code snippet here on the given value of n and see if it terminates or not. That is fairly natural, but you can probably already see why it is going to be problematic. Of course, if your code actually terminates on n within a small number of steps, then you can confidently conclude that the program indeed terminates.\nHowever, suppose your code runs for, maybe, 1000 steps, 10,000 steps, or even 100,000 steps, and it is still not terminated. Now, can you still confidently conclude that the program will never terminate? Well, these early steps may not be a good indicator of what happens ultimately. It is possible that if you had waited for another 3 steps, the program would have terminated.\nIt is also possible that you needed to wait for another 10 billion steps before the program actually did terminate. So, you can see why this is going to be dicey. Fundamentally, the issue is that just because your program did not terminate in the first so many steps that is not enough evidence to conclude that it is never going to terminate. So, it seems like the real task for us is to identify some pattern on the numbers n for which this code does not terminate, and then use that pattern to answer the question.\nHow do we discover this pattern? Maybe, we can go back to the simulation approach we were discussing. Yes, I know I just said that it is not going to work. But it is not going to hurt for a bit of a trial-and-error approach. Let us replicate this code in Python or whatever programming language you are using right now. And just run it for some small values of n.\nPick a threshold that you like, say 100,000 steps, and let us just identify those values of n for which this program does not terminate even within 100,000 steps. We can flag those values as potentially being those for which the program never terminates. At this point, this is just going to be an educated guess. But it is going to be a good starting point to investigate further. I would really encourage you to try this yourself, and join me to discuss what we observed.\n(Refer Slide Time: 05:19)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEventually,\n\nI ran the program for values of n between 2 and 10. For n = 2, the program terminated in just 1 step. But for 3, it seems like the program is getting into the cycle of values between 3, 6, and 12. It is seemingly going on forever. For 4, the program terminates in just 2 steps. But for 5, again, the program eventually gets into the same cycle that we observed for the number 3.\nNow 6 was interesting because so far, the program seems to be terminating on even numbers and non-terminating on odd numbers. So, we may be tempted to conjecture that that is the pattern. But for 6, the program is again getting into this ‘3, 6, 12’ kind of cycle. For 7, the program again gets into the sort of a loop that shows no sign of stopping.\nBut for the next number, which is 8, the program again terminates in just 3 steps. For 9 and 10, you see that the program again gets into a cycle and shows no signs of stopping. So, at this point, can you identify a pattern to, at least, the 3 numbers that we have seen so far on which the program seems to terminate? If you run this program for even more values of n, then you may have a larger stash of numbers on which to guess a pattern.\nFrom what we have seen so far, it looks like all the numbers on which the program did terminate happened to be powers of 2. So that seems like a very tempting conjecture to make. Perhaps the program only terminates on powers of 2.\n(Refer Slide Time: 07:02)\n\nIt is reasonably easy to see that if you have a power of 2, then the program does terminate. It is because the program is successively shaving off powers of 2 from n, till the number becomes 1. For instance, if to begin with n was the rth power of 2, then after the first iteration, it will become the r-1th power of 2. After the second iteration, it will become the r-2th power of 2 and so on. And after r iterations, the number becomes 2 to the 0, which is 1, at which point the program terminates.\nTo summarize, if n was the rth power of 2, then the program terminates in r iterations. We also saw this with the examples. When n was equal to 2, then we terminated after 1 iteration. When n was 4, we terminated and 2, and when n was 8, we terminated in 3 iterations. So, this case is abundantly clear. Now let us consider the other possibility, which is that n is not a power of 2. When n is not a power of 2, let us split things up into 2 further scenarios.\n(Refer Slide Time: 08:04)\n\nWhat if n is not a power of 2, and is odd? In this case, notice that n is always going to be a multiple of 3. Indeed, in the very first step, n gets transformed into 3*n+3. At this point, it is clearly a multiple of 3. Since in future iterations, we never divide by 3, it should be clear that n is always going to be a multiple of 3. For this reason, it is never going to reach a value of 1, and the program is going to run forever.\nWhat happens if n is not a power of 2 but it is even, to begin with? Then well, let us just consider the prime factorization of n. It is going to have some powers of 2, and then some other factors as well, because we explicitly said that n is not just a power of 2. So, as long as n is divisible by 2, the program is going to enter the first branch of the if statement. It is going to, again, successively shave off the powers of 2. But when it has no factors of 2 left, you are left with a number that, by definition, is odd. You are back to the previous case, where n is not a power of 2, and it is odd. From here on out, it is going to go on forever.\nWhat we have argued after making an educated guess is that, indeed, the program does not stop if and only if n is not a power of 2. So, the program that you have to write at this point is really simple. You just have to check if n is a power of 2 or not. And one way to do that is to just try and successively divide by n and see where you get stuck.\nIf you go all the way to one then n was a power of 2, but if you stop short of something that is different from 1 then n is not a power of 2. If you are used to bit manipulation tricks, then there is a faster way of checking if n is a power of 2 or not. We will mention this when we get to the summary at the end. Before we go further though, let me just show you the original problem statement so that you can take a look at the story there.\nI know that normally we are in a big rush to just somehow get rid of this story and quickly identify the abstractions involved. But in this case, I think the story has a little bit of interesting trivia. So, I want to tell you about it, especially now that we have more or less solved the problem.\n(Refer Slide Time: 10:31)\n\nSo, here is how the problem statement goes. Byteasar was wandering around the library of the University of Warsaw. At one of its facades, he noticed a piece of a program with an inscription: Will it stop? The question seemed interesting, so Byteasar tried to tackle it after returning home. Unfortunately, when he was writing down the piece of code, he made a mistake. The rest of it is what we have discussed so far. But this might make you curious about a couple of things. First of all, is there such an inscription at the facades of the library of the University of Warsaw? It turns out that there is indeed such an inscription. Did Byteasar actually make a mistake while noting it down? It turns out that, yes, the original inscription, on the facade of the library is a slightly different code snippet. It is a really small mistake that Byteasar made while noting down this piece of code.\n(Refer Slide Time: 11:27)\n\nSo instead of a +3 in the else statement, we have a +1. That is the only difference, but it turns out that it massively changes the nature of the problem. The mathematician Lothar Collatz believes that this code stops for any value of n. It turns out that as of now, nobody really knows if this is true. Of course, people have tried this computationally, apart from in other ways.\nIt has been verified that the program does terminate for some fairly large values of n. But we do not know if this is the case for every n or not. This is a fascinating conjecture with a lot of history. If you are interested in this, then do look up the Collatz conjecture. I am sure it will be a very interesting rabbit hole for you to explore. But let us now recap what we have learned.\n(Refer Slide Time: 12:12)\n\n\nFor the version of the code that we saw in the problem statement, we can say yes, if n is a power of 2, and we can say no if n is not. I promised you a bit manipulation trick that would help you identify if n is a power of 2 or not. And here it is. You can test if n is a power of 2 or not by just taking the XOR of n and n-1, and doing an AND with n and check if that is n.\nSo, you can probably see right away that if n is a power of 2, then this equation is satisfied. When you do n XOR n-1, you get essentially all ones. When you add that with n, then only the first, the most significant bit is the only one that survives, and you get back n. However, it is a little more work to check that this equation actually fails for any value of n, which is not a power of 2.\nIt is a fun little exercise so I will not spoil it for you. But for now, if you just want to record it as a trick that you can use, then by all means, please do make a note of it. So, all that remains is to actually code this up. As you can imagine, for this problem, the coding bed is really simple, but let us just go through it.\n(Refer Slide Time: 13:33)\n\n\nSo, here is the page, which has the problem statement. This is a new platform compared to the ones that you have seen so far. If you are here for the first time, on the top right, you will see a link, which says login, as opposed to your username. If you do not have an account yet, then when you click on login, you will get a drop-down menu, which will also give you the opportunity to register.\nIt is a very simple registration form. So, you should have your account set up in a couple of minutes. It is completely automatic. Once you have done all that, please make sure to log in. The only reason I am recommending that you set up an account of your own is because you do need that to be able to actually make a submission. If you are not logged in, you will not be able to submit your code.\nLet us just quickly recap the problem statement. The contents of the problem itself are exactly as we have discussed. Let us take a note of the input. There is only one line of input and that is the integer n. And the output well is yes or no, but notice that it is in Polish. So let us just take a note of the words: It is going to be TAK or NIE. Let us just make sure that that is what we output in our program. Otherwise, the tests are not going to pass.\nLet us head over to the submission pane. Notice that you cannot, right away, select the programming language. But once you start typing in here, the drop-down does get activated. I am just going to pick Python because it is a simple program. It should not really make a difference, what programming language we use here. We take in the number n. Now we just have to test if it is a power of 2 or not. So let us use the bit manipulation trick that we just talked about. We want to do n XOR n-1. So, the bitwise XOR is the ^ symbol in Python, and the bitwise AND is a single & sign. We want to ask ourselves if this is true, and if it is, then we print TAK.\nIf it is not, then we print NIE. That should be the entire program. Notice that the editor interface here does not really have support for tabs. That is why, I am kind of typing out for spaces. You can, of course, also just code this in your favorite IDE and upload the file instead.\n(Refer Slide Time: 16:33)\n\nLet us just go ahead and make the submission to be sure. At this point, the status is pending. I have made a similar submission before. My current submission has run its course. It seems like it has a full score, which means all the tests passed, which is not surprising given that it was a really simple check that needed to be done.\nSo, there is not a whole lot of margin for error here. But do try this out, and see if you managed to also pass all the tests. You could try doing this the other way where you actually successively divide n by 2 and see if that is within the time limit. I believe that that approach also works just as well. Do give it a shot and let us know how it went for you. This was the final problem that we discussed in this week. We are looking forward to seeing you next week, and also over at Discord and the Google Groups. Thanks so much and talk soon. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W01/Lec01.html",
    "href": "materials/cpnotes/W01/Lec01.html",
    "title": "Ad hoc and Implementation",
    "section": "",
    "text": "Lecture - 01\nAd hoc and Implementation\n(Refer Slide Time: 00:11)\n\nHello, and welcome to the second module of the first week of getting started with competitive programming. Hopefully, you have, by now, set up your coding environment in a way that you like and are comfortable with. If you have seen the previous video, you have also had an overview of the various platforms that we will be submitting code to reading problems from.\nSo, just make sure that you have your accounts set up everywhere, and your basics sorted out about knowing where to submit your code, how to read input and write output, and so on. Also, do not get distracted with things like starter files that you might see from other more experienced competitive programmers.\nEspecially if you are just getting started, it is perfectly fine to keep it pretty basic and simple right now. As you go along and build up your own experience, you will build out your own setup and startup files. I think it is a much better approach than copy-pasting large chunks of code that you probably do not even fully understand or appreciate right now.\nSo, just feel free to keep it simple. If you are having any issues with the logistics of getting set up, please feel free to post a message on the Discord channel. If you are not on Discord, then you can send an email to the Google Groups set up for the course, and one of us will be sure to get back to you.\nSo, with all that said, I hope you are excited to get started on your first problem-solving experience in this course. As you probably have noticed, the first week is called Ad hoc and Implementation. It generally means that these problems do not require any special data structures or algorithms background. They are fairly generic puzzles. You can have a go at them even if you are not particularly familiar with specialized data structures or algorithms.\nUsually, all that is needed is basic programming competence. It is also a great way to learn a new programming language. You might want to just practice with a lot of these implementation-based problems that show up in programming contests.\nTypically, if you go to a CodeChef long challenge or a Codeforces contest, the first problem is of this sort. You need to spend some time just trying to understand the setup. There are probably usually one or two small things that you have to figure out. But after that, the part about translating your thought process into code is generally relatively straightforward.\nOf course, sometimes, there are challenging implementation problems with many annoying corner cases and similar things. However, it will not be the scope of what we do this week. We will just see some interesting problems with fairly simple implementations.\nSo, let us get started with a problem called Reversort. It will be a warm-up to another problem called Engineering Reversort that we will see in the next module. These problems appeared in the qualification round for Google Code Jam 2021. It is a fun problem!\nThe first part is a very direct implementation problem. You see a description of a specific algorithm, and you just have to implement it. It turns out to be a sorting algorithm. We will have a lot more to say about sorting and searching next week. So, it is probably a good trailer for that as well. Let us look at what the problem statement says, and we will take it from there.\n(Refer Slide Time: 03:45)\n\nSo, the problem statement introduces us to the Reversort algorithm. It is essentially a sorting algorithm designed to sort a list of distinct integers in ascending order. At the heart of the algorithm is the so-called reverse operation, which essentially takes a summary and reverses it completely. These summaries are carefully chosen so that after a certain number of iterations, the array ends up being fully sorted. So, we will take a look at the pseudocode for Reversort, understand how the algorithm works, and then we will get to the task that we are supposed to perform based on this algorithm.\n(Refer Slide Time: 04:21)\nHere is the pseudocode for Reversort. It is exactly as given in the problem statement. If you read it, you will discover that what the algorithm is doing is the following:\n\n\n\n\n\n\nThe algorithm goes through the array from beginning to end. At the ith stage, it is trying to figure out what is the smallest element in the array from the current position to the variant. It takes the sub-array from the current position to wherever that minimum element is located. Then, it flips that entire sub-array over.\nSo, this has the effect of bringing the ith smallest element to its correct place in the ith iteration. As a result, after n-1 iterations, your array is completely sorted. Notice that you do not need to do the last iteration explicitly because once you have sorted the first n-1 element, the last element automatically falls in place.\nNow, this may seem like a trivial thing to say, but for the task that we have to perform, these are the kinds of corner cases useful to observe and be careful about. Otherwise, you will end up getting these ‘off by 1’ errors, which can be silly and annoying. So, just be very careful in reading the algorithm down to these simple but minute details.\nNow we will simulate this algorithm on a couple of examples. My suggestion would be that once you see the example, pause the video and work through it yourself. Then resume the video to see if your execution tallied with ours. It is essential to go through these examples to build up your intuition for what the algorithm is doing. Having an accurate understanding of what the algorithm is doing will be crucial to being able to solve the task at hand correctly.\nWe have not yet talked about what we are supposed to do with this algorithm. We will get to that in a minute after working through these examples. So, let us look at the first example. It is an array with just four elements 4, 2, 1, 3, in that order. So, the first iteration discovers element 1, which is in the third position, and the array gets flipped. Notice that the second minimum element is already in its correct place in the second iteration. So, an array of length one effectively gets flipped.\nNotice that the last two elements need to be swapped for the third iteration. That is exactly what happens. As we discussed before, there are no more iterations after this because the fourth element is automatically sorted.\n(Refer Slide Time: 06:46)\nThe next example is going to be a slightly longer and nearly sorted array, in some sense. See if you can spot why I am saying it is nearly sorted.\n\n\n\n\n\n\n\nSo, in the first iteration, notice that the smallest element is right at the end of the array. When we reverse the array, the array becomes sorted. Because what happened was that the array, to begin with, was sorted in the reverse order. So, the very first reverse operation already sorted the array completely.\nBut we do not stop just because the array is sorted. There is no check in the beginning, which says if the array is sorted, then let us not do any more iterations. The algorithm will go through the remaining five iterations just to make sure that everything is in place. This is how the algorithm is going to run on these examples.\n(Refer Slide Time: 07:52)\nNow, let us define the cost of a reverse operation as the length of the sub-array that is being reversed.\n\nRemember, I was saying that we have not really defined the task that we are supposed to do. Now, this is the stage where we realize that we are supposed to compute the total cost of reversorting a given input array. Let us go back to some of our examples to actually calculate the corresponding costs. Remember that when you are sorting the sub-array that spans positions ‘i to j,’ the length of the array that is being reversed is j-i+1.\nOne way to compute the cost is to initialize a cost variable to 0 and just keep adding the lengths of the sub-arrays that are being reversed. This will involve implementing the Reversort algorithm and doing a little bit of extra book-keeping, just to see what is the length of the sub-array that is being reversed at every step. You just have to update your cost variable correctly and you would be done. Let us take a look at what the costs are for reversorting the two arrays that we just reversorted.\nSo, the first example was the array 4, 2, 1, 3.\n(Refer Slide Time: 07:49)\n\n\n\n\n\n\nNotice that in the first step we reversed a sub-array of length three, so that added a cost of 3. In the second step, the minimum element was in its correct position, but we still think of that as reversing an array of length 1. So, it does add one to the cost, it is not a step that comes for free. Do keep that in mind.\nIn the next step, we swapped the last two elements for a cost of 2 and notice there are no steps after this, you get the last element in the array for free. So, the total cost here added up to a total of six.\n(Refer Slide Time: 09:38)\nNow, let us look at the next example where the whole array got sorted in the very first step.\n\n\n\n\n\n\n\n\nThe first step is expensive. You end up reversing the entire array for a cost of 7. But after this, you have to painstakingly investigate every element in the array to find out that the elements are already in their proper position. So, the algorithm in this case will basically continue for the next five steps, adding a cost of 1 per step.\nRemember that the algorithm does not have any sanity check at any step, which says that we can break if the array is already sorted. So, the total cost, in this case, will end up being 7 for the first super expensive step and then 1 unit of cost for each of the remaining five iterations. Only five iterations because the last step is for free. So, the total cost is 12.\nFor the next problem that we will be discussing, we will be interested in constructing arrays whose cost of reversorting is some given number. That is a very interesting follow-up question. Here is a puzzle that you might want to play with. First of all, think about what is the maximum cost that you could incur as you reversort an array? Well, the maximum cost will be incurred, if at every step you need to reversort the entire remaining sub-array.\n(Refer Slide Time: 11:20)\n\nThe specifics of the numbers in this array are not so important. But what do you want to think about is how do you come up with an example like this? Here is an example with 5 numbers. Can you generalize this and, say, give me an array of length 20, where, in every step, you find that the algorithm is forced to reverse the whole sub-array that it is working with? You might also conclude that, maybe, such arrays do not exist. That would also be a valid point to make if that were to be true.\n(Refer Slide Time: 11:40)\n\n\n\n\n\n\n\n\n\nWhat you can see playing out in this example is that in every step, you had to sort out whatever was remaining till the end. So, you have the maximum possible cost. In this case, it turns out to be 14.\n(Refer Slide Time: 12:13)\n\nLet us recap what we have going on here. So, essentially, we simulate the Reversort algorithm and we just keep track of the costs as we go along. At this point, I think we are ready to implement this. So, let us switch to coding.\n(Refer Slide Time: 12:39)\n\nWelcome to the implementation segment of this discussion. I hope you are excited about writing the code for the very first problem that we have solved in this course. Because this is our first discussion about an implementation, I will go through every step of the process. But in the future videos, we might end up skipping some of the more routine paths, for example, taking input and things like that. In general, if you have any issues with the implementations of any programs that we discuss, please feel free to share your doubts in the Discord community that we have set up for this course.\nNotice that there is a separate channel for every week. We would really appreciate it if you could help us keep things streamlined by making sure that you are posting your questions in the correct channel. So, with all that said, I think we can get started here. Let me just walk you through the layout of the screen, which will be more or less the same in all the videos.\nI am using VS Code - that is my choice of ID. You could use anything that you are comfortable with. Just make sure that it is a plain text editor that has support for the basic features like syntax highlighting, and so on. I have divided my workspace into four panes. The main pane is the one that you see on the left, where I will be coding it. There is a floating screenshot of the section of the problem statement that I think will be relevant to us, because it has the details of the input and the output format. I will let that stay for a while, while we are still figuring out how to take the input and how to format the output.\nOn the right, you will see that there are three panes and there are three files, one in each of them. So, there is in.txt and out.txt. These are the files that my program will be reading from and writing to. I find it convenient to redirect the standard input and output to these file streams, and this way, I can see the output of my code in this pane right here as opposed to going back and forth between the terminal or just having a cluttered terminal with the output of the code.\nThis, of course, is a matter of purely personal preference. So, feel free to set up your environment in exactly whatever way you feel is the most comfortable for you. Importantly, I also have an expectedout.txt file. For now, it just has the output data from the sample output in the problem statement. But in general, you might want to be doing your own tests. In this case, you might have to generate this expected output file, either by working out the solutions by hand or in some other way. Or you have a brute force program that you are pretty confident about, which has generated the solutions for some instances. And, you want to compare if your algorithm which is doing something different is actually tallying with the solutions.\nSo, expectedout.txt is a file with solutions that one would be typically confident about for some reason. Then what do you want to do at the very end after you have written your program is to just run a quick diff, either from the terminal or visually. I would recommend doing it from the terminal. Run a diff between these two files to make sure that the output from your program tallies exactly with what is expected.\nSo, that is the overall setup. I will be using this terminal at the bottom to run the files. I have two very simple starter files. Here is the C starter file. And, I typically end up adding things based on what we need. This is some code that redirects the I/O to these file streams. This is something that is just recommended for speed and you will probably see it in many starter files. Most people would recommend using the scanf and printf style C input-output for speed.\nFor most of the problems that we will be tackling, we are not really concerned about that level of optimization. So, I am going to stick to just doing the standard I/O Stream when I am using C++, which is to say I will use Cin and Cout. If you are stuck with program whose efficiency you are really convinced about and you are still getting some sort of TLE error, just check if you are using efficient input-output or not.\nSimilarly, I also have a Python starter file, which I think looks even simpler. So, again, it is just redirecting the I/O Streams. I do have here a little bit of code that helps me track the time that my program is taking to actually produce its output. This is particularly useful for Python because it does tend to be the slower language. Sometimes, it just likes to sanity check that there is not a particular disadvantage. It is important to remember to remove any of these extra print statements.\nRemember that these would actually cause your tests to fail. On some platforms like Google Code Jam, for instance, you will end up just getting a runtime error if you submit your code with stuff like this. So, you just need to make sure that all of these extras are removed before you make your actual submission.\nSome people will have these macro-if statements to say that these things should execute only if you are not in a judging environment. I have personally found those to be a little bit unreliable. So, I just make sure that I manually clean up my files before I actually make a submission.\nOn the other hand, if you do not want to mess around with your files, and you want to keep them clean, but you still want the input to be read from a file and the output to be written to a file, you can also do this using the appropriate commands on the command line. So, I use ‘Bash,’ and I can simply redirect the output to a file quite easily by just appending a small command to the regular compiler invocation.\nThis is just to say that there are many ways of setting things up. I am not getting into any more specifics because the details will really vary based on your operating system, your compiler version and various other details. But there are a lot of resources online. I really encourage you to spend a little bit of time making sure that you have a comfortable working setup. So that you are not wasting any of your precious contest time on things like how to run your program and so forth. This is a small initial investment that is certainly worth making.\n(Refer Slide Time: 20:30)\n\n\n\n\n\nLet us go back to reversort and start the implementation that we were planning to get to. Let me switch back to the C starter file and just hope that the file names are correct, and everything is working fine. Let us test this with a small ‘Hello World’ output. There is ‘Hello World’ in the out file. So, that seems to be all right.\nLet us begin by taking the input. The first line gives the number of test cases T. By the way, before getting started, it is probably useful to just take a look at the limits for the input. Because, especially in languages like C++, one thing to be careful about is the types of the variables that you declare. So, you want to make sure that your variables types are conservatively large enough to hold the kind of values that are going to be thrown at them.\nFortunately, this being a warm-up problem, the limits are fairly small. So, this is not something that we have to worry about specifically right now. I am just going to declare an integer, which can store the value of the number of test cases. Now, T test cases follow. I guess we should have a loop that accounts for each of these test cases. I am just going to use c as the loop variable. C for cases, but it does not really matter so much.\nWhat is the format of each test case? The description says that each test case consists of two lines, the first line contains a single integer, N. Let us read that in. The next thing that we want to read is the actual list itself. The second line of every test case consists of N distinct integers. So, the number N that we just read in is actually the size of the list. We can certainly write a for loop that is going to run N times. We could use this to actually pick up these integers.\nAll the integers are on a single line, but they are separated by spaces. Although the description does not say it explicitly, if you look at the sample inputs right here, you can see that these are space-separated integers, which is going to be fairly convenient for us because we can just read them in like that, and we will be done.\nThese numbers are not going anywhere. So, we need to put them in an array or vector or something similar. I am going to use a vector of integers, because that is what I find convenient. If you would prefer using an array that should be perfectly fine too. We are going to use the push_back() method to add these numbers to the list. This is analogous to append in Python if that is something that you are more comfortable with.\nWe are done at this point in terms of reading the input. Just as a really basic sanity check, let us write this input back to make sure that we have it right, and we have not made any mistakes at this stage. Just remember to print some spaces, otherwise, the output will look unreadable. Let us just give a new line across test cases and tabs to distinguish between tests. If you look at the output file, now it looks like we have managed to read all the arrays correctly.\nNow, I do want to get rid of this floating screenshot. Let us also take care of the output. Of course, coming up with the answer is going to take some time. But let us just take care of it in terms of the formatting. What we want to do is print the case number. Google Code Jam is rather unusual in terms of its output format. Most other platforms would just require you to print the answer in some specified format. But Code Jam explicitly asks you to print the string involving the case number.\nSo, what do we print here? We could invoke a function that we may want to write to solve this instance, and we would be done. Let us actually go ahead and define this function. Let us say it returns an integer, which is the cost of reversorting the array in question. And, let us say for now that we just return a dummy number. We can see that the formatting, at least, is okay in the output file.\nSince we are done with reading the input, I got rid of the references to input and output formatting. Just for our recollection, here is the pseudocode for Reversort. This is a snapshot from the problem description. Remember, our plan was to just implement Reversort, as is suggested here, and use a cost variable to keep track of the costs as we go along.\nLet us begin by introducing that cost variable, which is sufficient to be an integer at the moment. Let us also remember to return the cost. Let us try to implement the Reversort algorithm. So, we are going to need a for loop, where the loop index varies from 1 to the length of L-1.\nThe one thing to keep in mind is that we probably should not be using 1-based indexing because that is not our scene here. So, let us start our loop variable from 0. This is going to go on until the length-1. Let us make sure that that makes sense.\nIf you are going to stop strictly short of the length-1, remember that in our array, the index of the last element is going to be this length-1. And since i will be less than length-1, it will indeed ignore the last element which is exactly as desired. So, I think for us the extreme points of the loop variables make sense.\nWhat is the first step here? We want to find the minimum element, but it has to be the minimum element in a certain sub-array. Then we need to find the position of this minimum element and then execute the reversals. It is essentially these three steps: find the minimum element, find where the minimum element is, and identify the relevant sub-array and perform the reversal. Of course, we also need to track the cost that was associated with that reversal.\nLet us do this one step at a time. So, for finding the minimum, let us use the variable name m to keep track of the minimum value. We are going to use the function min_element() to actually find the min element. What the min element takes as input, we can think of this as the boundaries within which we want to search for the minimum.\nWe are going to essentially say that we want to search from the start but offset by i. Of course, we want to go all the way till the end. You might want to just check that the indexing makes sense. So, in the very first step, you are looking for the minimum in the entire array. When i=0, for instance, notice that you are going to search for the minimum in the entire array. That is what it means to go from L.begin() to L.end(). These are essentially pointers to the start and the end of the list that we have.\nAs the values of i increase, you correctly identify the sub-array within which to search for the minimum. If you are not completely convinced, then you might want to add some print statements here, just to see what is going on. But I believe this to be okay. Let us move on and try to do the circus of figuring out where this minimum element occurs.\nSo, this is going to be an index, and we can use something called find() to find where the minimum element is. Since the elements of this list are all distinct, we can just search in the entire array. That will not hurt. If they were not all distinct, you will have to be a little bit careful in this step. So, I am just going to use the auto type here to keep things simple. And, that is going to keep track of the location of the minimum element. In the next step, we are going to actually perform the reversal.\nNow, you could probably write your own reversal function to do this from scratch. But in most languages, common operations like this are usually implemented through some built-in functions. I would generally recommend using a built-in function if it is accessible because that has been tried and tested and is likely to be more accurate than something that you code up from scratch. At least, for these really basic and fundamental operations.\nIf you are not sure about what that function is or you do not remember the syntax, then that is something that you should feel free to lookup. Even if you are recording this in Python, there are any number of ways to reverse, say, a part of a list. So, there should be no problem to do in either language using just the built-in mechanisms.\nIn C++, it turns out that the built-in function is just called reverse(). The one thing to be careful about, and where it is actually worth looking up the documentation a little bit, is to understand what is it that gets reversed. You probably give the reverse function two indices and it is quite natural that it is the sub-array that lies between those indices that gets reversed.\nThe detail to worry about is whether the indices are inclusive or exclusive or some combination of both. It turns out that the reverse() function considers the first index to be inclusive and the last index to be exclusive. With that in mind, what we should input the reverse function is at the start of the array offset by i, because that is from where we want to start the reversal operation.\nWe want to end at x, which is where the minimum element is located. Since the reverse() function is going to ignore that last index, if we had just given ‘begin plus i to x,’ then we would have reversed a shorter sub-array than what we intended. So, we need to add a plus 1 [L.begin()+i,x+1]. This performs the reversal that we require. Now we are ready for the final step, which is not present in the pseudocode. It is something that we have to do to solve the problem at hand.\nThe very last step is to actually upgrade the cost by the length of the sub-array that we just reversed. So, when we were discussing this a few minutes ago in the lecture, we said that the cost is just going to be j-i+1, where j and i are the indices of the array that got reversed. But here, we have these indices in the slightly awkward format. And, it is not clear if we can just directly do arithmetic here.\nSo, we are again going to use a built-in function to bail us out. So, there is this useful function called distance(), which does exactly what it sounds like it is supposed to do. If you essentially supply two locations, it will tell you how far apart they are. Let us find out how far apart the index of the minimum was from the start of the array. This essentially tells us the value of j in the pseudocode. We can now subtract i, which we know is the place that we are starting. That is our initial offset.\nOf course, this is over subtracting a bit, so I am just going to add a +1 as we had discussed earlier. This appends the right cost of reversing the sub-array that we encounter in the ith iteration. Let me get rid of the pseudocode here. Let us run the code and see what we get.\nIf you look at the output file, it seems to tally quite exactly with the file called expectedout.txt, which is always a good sign. It is quite visible that everything seems okay. But as a matter of general habit, you might just want to run a diff to be sure.\nWhen you are running a diff, no news is good news. If the output of the diff command is empty, it means that the files have matched exactly. Sometimes even though the files are visually matched, diff may still give you some output because, maybe, there was an extra newline in one of the files and things like that.\nFortunately, there seems to be no such indication here. So, nothing to worry about! I would recommend you try and run your code on a few different examples just to make sure that you identify some of the common edge cases, and they are accounted for properly before you actually upload your code.\nOf course, when you are practicing, you can upload your code as many times as you want and there is no penalty. It would be completely understandable if you are just keen to upload your code right away. Just be a little bit careful about making a habit out of this. When you are participating in an actual contest, you might incur penalties on these wrong submissions. So, you have to be a little bit more careful when you are participating in a live contest.\nIn any case, this was a fairly straightforward problem. We have good reason to be confident about this code. You can go ahead and try and submit this on the Code Jam servers and see how that works out for you. One thing to be careful about is the corner cases and the indices. So, do watch out for issues that might occur there.\nJust as a little bit of trivia, if you have seen the intro video for this course, it opened with a bit of frustration about the first version of the code not going through as expected. The problem that we were solving in that video was actually this one. The line of code that was missing I think was the line that involved actually reversing the array. That is a common mistake that can be made.\nYou keep track of everything else but forget to actually reverse your array in the process. Then your array has not been reversed and you are not tracking what you are supposed to be tracking. So, your answers end up being wildly different from what you expect.\nIt is certainly not impossible to make mistakes, even in simple problems. In fact, the simpler the problem, the more frustrating it is that you are getting a wrong-answer kind of status from the judge. So, it is never too early to get into the habit of being careful. Anytime that you are working with a lot of indices or corner cases, it is definitely worth working through some examples and just making sure that you have those down.\nSo, I hope you had a good time walking through this problem. I hope you will also get around to implementing it. As usual, we have the Discord community in case there is anything that you are stuck with, please do reach out there. We have a separate channel for every week. It would be great if you could keep your questions streamlined accordingly. This is week one and we have just finished the very first problem and the very first module. I hope you are all geared up for the next one, and I will see you there. Bye for now, and thanks for watching!"
  },
  {
    "objectID": "materials/cpnotes/W01/Lec03.html",
    "href": "materials/cpnotes/W01/Lec03.html",
    "title": "M 03 (Numbers Game)",
    "section": "",
    "text": "Lecture - 03\nAd hoc and Implementation - Module 03 (Numbers Game)\n(Refer Slide Time: 00:11)\n\nWelcome to the third module in the first week on AdHoc and Implementation-based problems. In this video, we will be talking about a problem called Numbers Game. This one is, again, a problem that featured in a Google Code Jam contest, this time from way back in 2010. This was the last problem in round 1A that year. Usually, round 1 is a contest that lasts for 2.5 hours.\nThis particular round had 3 problems that the contestants had to solve in that time. As you can probably tell from the name of the problem, it perhaps involves some sort of a game. I should mention that games are a fairly popular and recurring theme in contest programming. Usually solving these problems requires some background in combinatorial game theory.\nBut fortunately, this problem is an exception. You can unravel the solution pretty much by making observations from first principles. Although it does not hurt to be familiar with a little bit of game theory. So, if that is you, that is great. But if not, then, hopefully, this exploration motivates you to explore game theory more, because it is a really wonderful topic.\nIt is not something that we will be covering much more in this course. But certainly, I hope that you have a chance to investigate it more independently. With all that said, let us get started. I will, as usual, begin by presenting the problem statement to you. But this time, I will defer telling you about the actual task for some time, because I want to spend some of the initial time getting the hang of what is going on in the game. We will do a bunch of examples first to get a feel for what is happening. Then I will introduce you to the task that we actually have to perform. So, you might have to wait for it a little bit. Let us get started.\nSo, this is going to be a 2-player game. The names of the players are Arya and Bran. The situation is that they are given 2 positive integers A and B, which are written on a blackboard in front of them. It is a turn-based game of starting with Arya. So, first, Arya is going to make her move, then it is going to go to Bran and so on. There is no passing: When it is your turn, you have to make a move.\nWhat does a move constitute? What can you do when it is your turn? Well, you can do one of 2 things: You can either update A with ‘A-minus kB,’ or you can update B with ‘B minus kA,’ where k is some positive integer. In other words, you cannot leave the numbers the same as they were before. They have to strictly diminish. The question is, what do you want to achieve?\nYou might want to speculate about what would the goal of such a game be? Before I actually reveal it to you. For instance, could it be that the first player who makes one of these numbers 0 or negative wins the game? Well, if that is all that you had to do to win, then notice that this is not going to be a very interesting game to play.\nIf Arya is playing optimally, when it is her turn in the very first move, she is just going to subtract one copy of the larger number from the smaller one. If the numbers are both the same, then it does not matter which one you subtract from which. Either way, you will end up with a number that is either 0 or negative immediately. So, this is a game that will only last for a very short time, and it is perhaps not worth analyzing further.\nSo, what is the actual objective of this game? It is, in fact, the opposite. The first person who makes one of these numbers 0 or negative, actually loses the game. Now the whole situation is a lot more interesting. It is not obvious at all who is going to win given a pair of numbers. So, let us actually try to get a feel for this by going through some examples. To begin with, let us say that the 2 numbers we have are 12 and 51.\n(Refer Slide Time: 04:12)\n\n\n\n\n\n\n\n\n\nThe boxes around these numbers are color-coded based on whose turn it is. So, if the boxes are red, then it is Arya’s turn and if the boxes are green, then it is Bran’s turn. Let us say Arya makes her first move by subtracting 3 copies of 12 from 51. That is going to leave her with 15. Now it is Bran’s turn. Notice that he does not have much of a choice here.\nSo, he can either subtract one or more copies of 15 from 12. But if he does that, then he immediately loses the game. When he is subtracting k copies of 12 from 15, if k is bigger than 1, then he is again lost immediately. The only valid thing that he can do to stay in the game is to subtract one copy of 12 from 15. Let us say he does that. Then he is left with 12, 3, which is what gets passed on to Arya.\nPlease take a moment here to think about if Arya has a winning move at this stage. In particular, can she do something to ensure that in the next step, Bran is left with no choice, but to make a move that causes him to lose the game? Notice that Arya has limited options here, she can either subtract 1, 2, or 3 copies of 3 from 12. If she subtracts any more then she herself loses the game immediately.\nHowever, Arya does have 3 choices of valid moves that would still keep her in the game. By now, you have probably guessed that among these options, her optimal move is to subtract 3 copies of 3 from 12. Because when she does this, she is left with the configuration of 3, 3, which is what she hands over to Bran. Now you can tell that poor Bran in this situation is completely stuck.\nAny move that he makes will be a losing move. He has, as a result, lost the game and Arya has won. Before we go on to discuss more examples, I would like to introduce a very important concept, which is the notion of a winning position. This is actually a part of the problem statement and is going to be very important for us to understand the tasks that we have to perform later on.\nWe are going to say that A, B is a winning position if Arya can always win a game that starts with A, B on the blackboard, no matter what Bran does. In other words, no matter how cleverly Bran plays his moves, whenever it is his turn, Arya will always have a way to inch closer towards victory. That is when you say that A, B is a winning position. So, in more standard game-theoretic terminology, you would say that Arya has a winning strategy.\nA winning strategy gives Arya a way in which to respond to Bran’s every move in a way that, in the end, she emerges victorious. Of course, it may not always be possible for Arya to have a winning strategy. But it turns out that for games like these, if Arya is not in a winning position, then Bran is in a winning position. So, every conceivable state of the game can be identified as being either winning or losing for one of the players.\nIf you are hearing about the concept of a winning strategy for the first time, you might find it a bit confusing or puzzling. You might wonder how the state of the game determines whether a player is going to win or not? Does not it depend on their individual skill levels? Does not depend on whether they are having a good day or not, and things like that?\nLet me just clarify a couple of things briefly. One is that in such games, we always assume that the players are playing optimally and that they have the skills to make the best move that is theoretically possible, at any given point in the game. This is sort of a working assumption in all of our definitions. Also, notice a few interesting characteristics of this game we are playing that make it different from the games that you might be used to in your day-to-day life, like say, cricket or poker.\nOne thing is that this game does not have any element of chance in it. When either player is making a move, and for example, saying something like ‘reduce A by k*B,’ then that is going to happen. It happens in a very deterministic way. So, there is no element of randomness, unlike in, say, games of cricket, for instance, where you might plan to do something, but that may not happen depending on the circumstances, which are not completely in your control.\nThe other thing about this game is that it is a perfect information game. Everybody knows what is going on unlike, say, games of poker where you may not know what cards your opponent has in their hand. So, it makes these types of games quite special. You can find out more about these games by looking specifically for combinatorial games. The fact that the kinds of games we are discussing here, every position is either winning or losing for one of the players involved, follows by doing some kind of a backward induction argument on an object called the game tree.\n(Refer Slide Time: 09:21)\n\nThe game tree is built out by essentially mapping all the possible moves that can be legitimately made by one of the players from the starting state of the game. You just keep building this out till you reach states from where no more progress can be made. Those states are then labeled as being losing for whatever player is stuck in that state. From here, you can work your way backwards to say that, in general, if you are at a non-terminal state, then that state is winning if and only if you can make a move from here that is losing for the other player.\nIn other words, if you are at a state from where every possible move that you can make leads you to a position that is winning for the other player, then the current position is losing for you. You can fill in the details of this argument to see that every position in the game tree can be uniquely labeled as being winning or losing for one of the 2 players. It is a good idea to think about where our assumptions about things like perfect information, and the absence of randomization are useful in making this argument work. But for now, hopefully, you are convinced that this notion of a winning position is sensible. Let us try to get some practice with this by looking at a few examples.\n(Refer Slide Time: 10:33)\n\nSuppose you have 2 numbers: 1 and 42. It is Arya’s move. Do you think this position is winning for Arya? Well, if one of the numbers is 1, and the other number is some number that is greater than 1, let us say x, then you can simply subtract ‘x-1’ copies of 1 from x. This leads you to configuration 1, 1, which is losing for the other player. So, whenever one of the numbers is 1, the first player has an advantage and can, in fact, win the game in just one move.\n(Refer Slide Time: 11:16)\n\nThe next example is when you have 2 numbers that are identical. Is this a winning position for the first player or not? Hopefully, you have concluded that this is not a winning position. Notice that any move that the first player tries to make in this state is a losing move. There is no way that you can progress to a state where both of the numbers are positive. So, this is not a winning position.\n(Refer Slide Time: 11:43)\n\nWhat about if one of the numbers is a multiple of the other? Just to make sure that we are not in the previous case, let us say it is, the multiplier is strictly greater than 1. In this case, is this a winning position or a losing position? Take a moment to think about it. This scenario is actually winning for the first player, because notice that the first player can remove ‘r-1’ copies of a from ‘ra’ to go to the position ‘aa,’ and that is a position that we saw was losing for the first player. If the first player offers up this position to the second player then the second player is bound to lose. So, this is a winning position for the first player.\n(Refer Slide Time: 12:26)\n\nIn the next example, we have ‘a’ and ‘b’ with the property that ‘a’ lies between b and 2b strictly. Of course, if ‘a’ was equal to ‘b,’ we already know what happens. We will come back to the situation when ‘a’ is at least 2b. But what if ‘a’ is in the range strictly between b and 2b? In this case, can we conclude if this position is winning for the first player or not? I should confess that this was a bit of a trick question.\nWe do not have enough information here to conclude if this position is winning or not for the first player. In fact, you should be able to come up with examples with concrete numbers that satisfy the inequalities here. You could come up with 2 examples, one, which is winning for the first player and the other that is not winning for the first player.\nSo, there is not enough information here. But one thing that I do want to draw your attention to is the fact that this is a forced situation for the first player. There is only one interesting move that the first player can make here. By interesting, I just mean a move that keeps the player in the game.\nApart from removing one copy of ‘b’ from ‘a’ - so, notice that a is the larger number here, there is no other move, that is a valid move, in the sense that any other move is going to lead to the outcome that you lose the game immediately. So, there is only one interesting move here. In some sense, this is a forced configuration. This is a fact that we will make use of later. So, just keep it at the back of your mind.\n(Refer Slide Time: 14:12)\n\n\nLet us go to the final example, which is probably the most interesting of the ones that we have seen so far. What if ‘a’ is at least 2b? Is there something that we can say conclusively? I will give you a hint here. This is not a trick question like before. You can actually conclusively say if this is a winning position or not for the first player. Take your time and pause for a minute here to think about what might happen here.\nLike before, we are in a situation where ‘a’ is larger than ‘b’ but unlike before, it is now substantially larger than b. We have possibly multiple choices for valid moves that we can make. We can certainly remove at least 1 copy of ‘b’ from ‘a,’ but possibly we can remove 2, 3, or more. In fact, let us divide ‘a’ by ‘b’ and suppose it factors as ‘r*b+a remainder c.’\nIf that is what ‘a’ is going to be, then what should your move be? A tempting thing to say is that maybe just remove as many copies of ‘b’ as you can from ‘a,’ so that you are left with c, b. But if you have played around with enough examples, while we were thinking about this case, you may have realized that it may not always be the optimal move.\nHowever, I promised you that this is not a trick question. We can always identify if this is winning for the first player or not. So, let us think about this a little more, go ahead and do the greedy thing that felt natural to us. Let us say that we remove ‘r’ copies of ‘b’ from ‘a.’\n(Refer Slide Time: 15:53)\n\nLet us say we are left with the configuration c b, which goes to the other player. Now there could be 2 possible situations. Either c b is a losing position, in which case, this is great, because if c b is a losing position, then the greedy thing was actually the right thing to do. But suppose c b is not a losing position, then it is a winning position. Somehow, that is a position that we want for ourselves. But remember that since ‘a’ had at least 2 copies of b in it, what we can do is we can force the other player to give us the configuration c b. How can we do that?\n(Refer Slide Time: 16:31)\n\n\n\nWe can do that by subtracting ‘r-1’ copies of ‘b’ instead of r copies of b. When we do that, notice that the other player is left with a configuration b+c and b. Now, this is like the situation that we had before. It is a forced situation, simply because ‘c’ is strictly less than ‘b.’ Remember, c was the remainder we got when we divided ‘a’ by ‘b,’ so, c < b. The only move that is legitimate for the other player to make is removing one copy of b from the number b+c.\n(Refer Slide Time: 17:08)\n\nWhen that move is played by the second player, the first player gets back the configuration c b. But this is something the first player is very happy about because we were in the case when c b was a winning configuration. The point is that irrespective of whether c b is winning or losing, you have a move that you can use to turn the game in your favor.\nJust to summarize what we learned from the last example: We saw that if ‘a’ is at least 2*b, then the position is winning for the first player. This is by no means obvious, but it is going to be very useful. I hope you are convinced that this is actually the case. If not, then please go back and revisit the argument that we just made before moving on.\n(Refer Slide Time: 17:51)\n\nLet us summarize what we have learned so far. Remember, we are interested in understanding if A, B is a winning position or not. Let us assume that A is at least B. What we have done here as we have mapped the values of A on this number line, and we have highlighted the possibilities in terms of B. Notice that we know that if A = B, then it is actually a losing position. And if A is 2B or more, then it is a winning position.\nFor values of A that lie between B+1 and 2B-1, this is a mystery. We do not really know what is going on here. If we had to figure out algorithmically if A, B is a winning position, then what we have right here is a fairly natural recursive approach to determining if A, B is winning or not. So, the algorithm will go like this.\nIf A is at least 2B then say ‘yes,’ if A is B, then say ‘no.’ Of course, the interesting case is the one that remains what happens otherwise. If A is in the range B+1 2B-1 inclusive, then what can we do (at least algorithmically)? One hint at this point is to use some sort of recursive idea. Can you think about what would be a useful configuration to work with?\nTake a moment here just to recall what we have discussed so far, and the answer should be evident. Hopefully, you have identified that the configuration of interest here is A-B, B. The reason for this is that when A is in the range B+1 2B-1 inclusive, then the situation is forced for whichever player is playing this configuration.\nThe only valid move that you can make at this stage is to subtract 1 copy of B from A. What happens from here? Keep in mind that the positions ‘A, B’ and ‘A-B, B’ are being played by 2 different players. Just to make sure that we are on the same page, let me know what do you think should happen if ‘A-B, B’ turns out to be a losing position for whichever player is playing that position?\nWhat can you say about A, B? Well, hopefully, you have concluded that if ‘A-B, B’ is a losing configuration, then A, B is winning. Because from A, B, you are able to generate a configuration that is losing for the other player, which makes you win when you start from A, B. On the other hand, what if ‘A-B, B’ is a winning position? What can you say in this setting?\nIt is probably predictable but please still think through it before coming to an answer. So, if ‘A-B, B’ is a winning position, then in general, it is still possible that the first player can try to divert to a different position for the second player, which is not a winning position, hopefully. But notice that in this case, we have been pushed into a corner where this move has been essentially forced on us.\nTherefore, we can actually conclude that if ‘A-B, B’ is a winning position, then ‘A, B’ is a losing position. Because this is the only position that we can generate starting from A, B, whenever A is in this range. This completes the description of the recursive algorithm. What you do is you try to recursively identify if ‘A-B, B’ is winning or losing. Just remember to flip that outcome to report the correct situation with respect to A, B.\nWhat is the running time of this algorithm? Notice that in every step, if you are not immediately done, then you have generated an instance where the magnitude of the larger number has been reduced by half. As a result, the algorithm will terminate in logarithmically many steps, log of the larger of the 2 numbers that you started within the initial configuration.\nIn some sense, this seems like a nice approach to figuring out if A, B is winning or not. This is a good time to tell you about the actual task that we have to perform, in this problem. The work that we have done is going to be hugely relevant, but we still have some way to go.\n(Refer Slide Time: 22:27)\n\nHere is the problem statement, the rest of it. We are given is 4 integers: A1, A2, and B1, B2. We have to count the number of winning positions A, B, for A in the range, A1, A2, and B in the range B1, B2. You might say that let us just try and go over all possible choices of A, B and we have just described an algorithm to figure out if A, B is winning or not.\nWe can just employ that algorithm and our solution is done. This would be a perfectly valid solution for the smaller data set. But here is the clincher for this problem. If you look at the limits, then it turns out that the ranges of these numbers can be as large as a million. So, now if we were to try and explore the full range of pairs and try to do something for each of them, we are going to be in some serious trouble.\nIn particular, the algorithm that we just described is going to be way too expensive. So, we need a different approach here. In particular, it looks like since examining every pair of numbers is going to be too expensive, we probably need a way to be able to address multiple pairs at once, or to be able to draw a conclusion about a large collection of pairs somehow magically in one shot.\nSpecifically, suppose that we fix a choice of B. Let us say we are looping over the range of values of B between B1 and B2. If it were possible that we can identify somehow directly, the number of A’s for which A, B is winning. Keep in mind that B is fixed. We just want to know how many A’s are there for which A, B is a winning configuration.\nJust remember that the crux of the matter here is to be able to do this in a way that does not involve examining each of the A’s in turn. At this point, this intuition may seem very vague. So, let us just go back to the drawing board and try to understand the problem more, and see if we can make some sense of this very high-level intuition that we have at this point for what our approach should be.\n(Refer Slide Time: 24:39)\n\n\n\n\nLet us go back to the recursive approach that we were just talking about. Remember that this is the interesting range for A. This is the range that we call the mysterious range where we cannot immediately conclude if A, B is a winning position or not. Let us just unravel the recursion and see what it is going to do. The recursion is going to examine the position A, B, B from the perspective of the second player.\nFor the second player, we again know that A-B, B is going to be winning if B [which now remember that B is the larger of the 2 numbers here] is substantially larger than A-B. If that happens to be the case, then this configuration is going to be winning for the second player. And in all these cases, we can again directly conclude that ‘A, B’ was losing for the first player.\nLet us just expand this out a bit. What you will get is that A should be, at most, 3/2B or 1.5B for this position, the original position A, B to be losing for the first player. Notice that this is now strictly new information because earlier, the only case that we knew of where we could directly conclude that A, B is losing was when A=B. But now we are saying that if A is at most 1.5*B, then also, A, B is a losing position. So, that is interesting. But let us try to unravel the recursion even a little bit further.\n(Refer Slide Time: 26:13)\n\n\n\n\nSuppose even at the second layer, you are stuck, you are not able to really conclude anything. This happens when, again, B lies strictly in the range A-B 2*A-B. If B is stuck in this situation, remember that now B is the larger of the 2 numbers and B is in this range, we do not really know. So, we need to recurse further. How do we recurse? Well, of course, we have to remove 1 copy of A-B from B.\nThen we need to give this back to the first player. We need to now check out this configuration more closely. So, of course, B-(A-B) is the same as 2B-A. We know that this configuration is winning for the first player, if A-B, which remember that A-B is the larger the 2 numbers now that one copy of A-B has been stolen from B.\nIf A minus B is substantially larger than 2B-A, then this is winning for player 1. Again, you can do the arithmetic, rearrange the terms and so, on. You will see that this condition boils down to saying that A should be at least (5/3)B. Notice that this is fresh information. Earlier what we knew is that if A is at least 2B then we can do a one-shot answer saying that this is winning. But now we can say that A is winning even if A is at least (5/3)B, which is something like 1.66 or so. So, now we have narrowed down the range that we said was mysterious.\n(Refer Slide Time: 27:55)\n\nIn fact, let us try to summarize where we are in terms of the extra information that we have after unraveling 2 layers of recursion. Now we have 2 new thresholds. We can actually say more about what positions are winning and losing. This is an improvement. There are more cases in which we are able to directly knock out a conclusion for whether A, B is winning or not.\nIt seems tempting to wonder if this range of mystery can be made smaller and smaller by unraveling more and more layers of recursion. The current mystery band ranges between 1.5 B and 1.66 B or so. If you are curious, feel free to pause here and just pick up some pen and paper and unravel a couple of layers of recursion more to see if you can shrink this mystery zone a little bit further. You can come back to tally notes with me in the rest of this lecture.\n(Refer Slide Time: 28:59)\n  \nIf you have had to summarize what we learned by just going further and further into the recursion rabbit hole, these are the inequalities that we discover. These inequalities are color-coded by the situations that are good for the respective players. Whenever a red inequality holds, we have the configuration that is winning for the first player. Whenever a green inequality holds, then that configuration is winning for the second player.\nJust in case you are wondering where these inequalities came from, let me remind you that we obtain these by simply unraveling more and more layers of the recursive algorithm that we discussed a few moments ago. Let us rewrite these inequalities in terms of A and you will see a bunch of fractions emerging when we do this rearrangement of terms.\nBy just staring at these numbers, let me ask if any patterns seem to emerge or if these numbers generally look familiar? Well, if you have seen the Fibonacci numbers before, you might recognize that these fractions are just ratios of consecutive Fibonacci numbers. If you actually know about some properties of these ratios, then you can probably already make an educated guess about where this is going.\nBut if that is not something that strikes is anything significant, let us rewrite the fractions in terms of their decimal counterparts. At least you can see that it seems like we are closing in on the mystery zone. Remember that these numbers signify the ranges of values for which we already know what is happening. In particular, the last 2 inequalities are the tightest and they tell us that we completely understand what is happening when A is at most 1.615*B.\nWe also know what is happening when A at least 1.619*B. So, the values of A about which we are not sure, are values that lie between, these 2 ratios. So, I am not sure if you have, like, a favorite mathematical constant that lies between these 2 numbers. But if you have heard of the golden ratio before, then that might just come to your mind.\nSo, you might make at this point, an educated guess that perhaps it is true that the mystery zone actually shrinks and shrinks and meets at the golden ratio. It turns out that there is a reasonably formal sense in which this is actually true.\n(Refer Slide Time: 31:36)\n\n\n\n\n\n\n\n\nHere is the statement that you can formally prove. It turns out that A, B is a winning position if and only if A is at least Φ*B, where Φ is a mathematical constant known as the golden ratio. If you have not heard of the golden ratio before, do not worry about it. Although it is a really interesting constant to learn more about. You can look it up on Wikipedia, for example.\nFor now, though, let us just contemplate if this statement is useful for our algorithm. Remember, we said that suppose you fix a B, and if you had a one-shot way of figuring out how many A’s in the range A1, A2 are such that A, B is a winning configuration. That is simply a direct count, you just have to look at the quantity Φ*B. You know that all the values of A that are larger than Φ*B are the ones that form winning configurations along with B.\nIt is just a matter of counting how many numbers in this range exceed this threshold. We have been working with the assumption that A is at least B. So, when you write your code, you have to account for this kind of symmetry. We will see that more explicitly when we get to coding. But hopefully, it is clear that this statement is extremely useful in getting to the kind of algorithm that we were hoping to find.\nI think with this, we have the main pieces of the puzzle in place. The main crux of the idea is hopefully beginning to become quite clear. This is probably a good point to pause the lecture and try out your own implementation if you feel inclined. The rest of this video will do essentially 2 things. The first is to discuss why this claim is true. It is not going to be a ‘very formal’ proof.\nIt is just going to be an argument that substantiates why you might believe this claim to be true, and you can probably expand it to a more formal argument if you would like to do that. Then we will write some code and implement the solution that we have just discussed. Before we move on, though, let me just try and address a question that might be occurring to you.\nHow do people come up with such solutions? Especially when we were discussing this solution, the golden ratio seemed to come out of nowhere. You might be concerned if you have not heard of the golden ratio before or if you are not very familiar with the Fibonacci numbers. You might be worried that these intuitions will not emerge as naturally for you.\nLet me say 2 things in response to this question. The first is in the context of this particular problem. I should point out that you do not need the full leverage of this theorem to be able to solve the problem for the large tests. All you need is the intuition that there is some threshold, you do not need to really know what that threshold is, you can instead binary search to find it.\nFor this, you will actually need the algorithm that we discussed in the very beginning. The algorithm for checking if a particular pair is winning or not. Remember, we had a ‘log n’ type of algorithm for that, where n is the larger of the 2 numbers, A and B. So, using that algorithm, what you can do is take the range A1, A2. Take the middle element of this range, and try to figure out if this middle element with B is winning or not.\nIf it turns out to be winning, then you know that the threshold is lower, and if it is losing, then you know that the threshold is higher, and then you can continue your binary search. You just need to play around with enough examples to develop this intuition that there is some mystery interval, which keeps shrinking and shrinking. There is some threshold, which actually distinguishes the winning positions from the losing ones. You do not need to know what exactly that threshold is, although if you know it, your coding will become more convenient.\nWhile binary search is a very fundamental technique, it does require a bit of care in the implementation. We will be talking a lot more about binary search in the next week. But for now, this is actually a really fun exercise in binary search. If you want to go ahead and get some practice, this would be a good time to do it. The other thing that I wanted to say is not so specific to this problem, but just a more general comment, which is that if you have seen this lecture so far, then you are already somebody who is enthusiastic about learning new things.\nI would say that the more you practice, the more you expose yourself to new ideas and new techniques, the more you build up your own toolkit of ideas that you have seen. So, for example, if this happened to be your first encounter with the concept of the golden ratio, then instead of getting worried about the fact that you have not seen it before, approach it with a mindset of positivity by realizing that you have seen it now.\nSo, you can add it to your notes, or however, it is you keep track of all the new ideas that you learn. It is one more idea in your toolkit. That is how you will eventually develop your own creative flair. In short, my suggestion would be to practice as much as you can. Instead of feeling discouraged by the things that you may not know so far, I would suggest focusing on feeling encouraged by all the exciting new things that you are learning.\nNow let us just get back to the statement here. Let us try to figure out why something like this should be true. So, recall that we have the interesting range for A being that it stuck between B and 2B. In this case, we said that the only move that the first player can make is to reduce A to A-B and you go to the configuration A-B, B.\nThe formal framework that we will use to prove this statement here is the framework of mathematical induction, which you might already be familiar with. The idea is to assume that the statement holds for all configurations, which involves smaller values of A and B. Based on that assumption, we will show that it is true for the configuration ‘A, B.’\nThe only missing piece here is to say that the statement is true for some sort of a base case. But it turns out that for this statement, the base cases are trivial. I will leave it to you to validate them. But for now, notice that for the interesting range of values of A, we go into a situation, which we are forced to be in, and in this situation, we can apply the induction hypothesis to say that this position is winning for player 2, if B is at least Φ*A-B.\nWe are able to apply the statement of the theorem directly here. That is the advantage of being able to use what is called the induction hypothesis. We know that this is the condition for this configuration to be winning for player 2. Because this is an ‘if and only if,’ we can turn the inequality around to say that this is the condition for this configuration to be losing for player 2. You might be a bit annoyed that when I am doing not greater than or equal to, I am not saying strictly less than, but notice that A and B are integers and Φ is not an integer.\nThe inequalities do check out. Let us continue this line of argument and write this in terms of player 1. A configuration that is losing for player 2, is equivalently winning for player 1. So, this is the criteria that we have, if we want the original configuration A, B to be a winning configuration for player 1, except the criteria is written in terms of a condition on the configuration that we reach after one step.\nWhat we have here is that B is at most Φ*A-B. If we rearrange those terms, we see that we can rewrite it as Φ*A being at least 1+Φphi*B, or pushing the Φ to the other side, we have 1+Φ/Φ*B is at most A. That is the inequality that you get. It turns out that it is a property of the golden ratio that 1+Φ/Φ is Φ again.\nApplying that we arrive at exactly the statement that we wanted to prove, which is that, for this configuration to be winning for the first player, we need A to be at least Φ*B. With that, we conclude the supporting argument for our main claim. Let us quickly recap what the algorithm is going to do in preparation for the implementation.\n(Refer Slide Time: 40:32)\n\nRemember, we have A1, A2, B1, B2 as the ranges of values of A and B. Let us go over all the values of B from B1 through B2. For each of those values of B, we will directly try to identify the number of values of A in the range A1, A2, for which A, B is a winning position. To do that, we will crucially use this claim.\nWe will just keep adding these numbers to a running tally of the number of winning positions. That is the answer that we will return at the end. So, with this, we have everything we need to know to be able to start the implementation. So, let us just switch to coding.\n(Refer Slide Time: 41:06)\n\n\n\nHere we have the usual sort of setup. You will see that the data from the sample input, the sample output, and the problem description have been copied under these files for a sanity check when we need it. Here we have the input-output formats for our reference. The input is T lines and each line is these 4 numbers a1, a2, b1, b2, signifying the range for ‘a’ and ‘b,’ respectively.\nNow we need to figure out the number of winning positions ‘a, b,’ for ‘a’ and ‘b’ lying in these in these corresponding ranges. The output format is really simple. We just have to essentially print the case number and the answer. Let us just try to compute the answer based on everything that we have discussed so far. What we said is that we will look at all the values of ‘b,’ we will loop over all the possible values of ‘b.’\nLet us say that is ‘b’ in range b1, b2+1. Here, what we said is we will try to figure out how many elements in the range a1 to a2 actually meet the criteria that the ‘a’ is at least Φ*b. This was the threshold that we had. If this threshold is landing somewhere within this range a1 to a2, then you can simply compute the number of a’s, which form a winning position along with ‘b’ by subtracting the threshold Φb from a2 and then taking the seal so that you are left with an integer.\nJust keep in mind that the threshold may not actually land somewhere in the middle of this range. It is possible that for instance, the threshold is below a1 or above a2. If the threshold is above a2, then none of these numbers satisfy the criteria that we have in mind. So, none of them contribute to the count of winning positions.\nBut if the threshold falls below b1, then all the numbers in this range contribute. Let us just make sure that we account for that explicitly. Notice that it is important to account for this explicitly and separately. Because, at least, with the approach that I was describing, if you try to do it in one shot, you will end up overcounting the number of winning pairs.\nBefore we actually write down the conditionals, let us just do some preparation. I think we want to have a variable that represents Φ, the golden ratio. You might be tempted to write down, like, the actual constant, up to a few decimal places. But I found that it can be dangerous. Because you are working with really large numbers here, you may not get the precision that you want, by just listing out a few digits in the decimal version of the constant. We also, may have to do some floor-ceiling sort of thing.\nLet us make sure that the math library is imported. Now we can go back to trying to do the cases that we had in mind. The first thing we said is that if a1 is greater than this threshold, then the entire range of numbers from a1 to a2 actually contributes to the number of winning pairs. So, we need to make sure that our answer is incremented by a2-b1+1.\nThat is the number of numbers that are there in this range. Now let us look at the ‘else’ part. We want to count the number of numbers in the range a1 to a2, which actually exceeded the threshold, golden*b. A natural way to do that is to say a2-golden*b. You can probably already guess that this is going to be problematic because this expression is not even an integer.\nWe really want to be counting the number of pairs. So, this is not the right thing to do. It seems like the appropriate thing to do is to take a floor or a ceiling on this threshold. I have to confess that I am very slow with getting these kinds of things right. This is really where a lot of edge cases and corner cases happen. When I am in this situation, I will do something really silly, like take an example and ask myself, suppose the range a1 to a2 was the numbers from 1 to 10.\nSuppose the threshold was 7.5. It does not have to be a realistic threshold. It is just, let us say, some fractional number. What do we want now? We want to eliminate everything that is less than 7.5. We want to keep everything that is greater than 7.5. So, what should we subtract from 10? What is the correct thing to subtract from 10 for this to happen?\nWell, it happens to be 7. It makes sense to take the floor. That is probably a horribly, non-sort of formal way of saying it. But for these edge cases, I usually find that doing some quick and dirty examples is probably the quickest way of making sure that you got it right. If it is a more tricky corner case situation, you might want to actually really run through some examples like run your code through some test cases and so on before moving forward. But this seems reasonable here.\nSo, we go ahead and do this. Notice that this may still be a little bit problematic because, for example, what happens if your threshold is above a2? So, we said that, in this case, none of these numbers contribute to the number of winning pairs. But this expression does not reflect that. What are you going to get if, say, the threshold is 12 and the range you are looking at is 1 to 10?\nThen, this expression will give you something like 10 minus 12, which is a negative number. That will offset your count in a way that is not good. You just want to stop at 0. When the numbers are negative, you want to basically make sure that they get counted as 0. The simplest way to do that is to take a max with 0. That should work.\nThis seems like everything that we did discuss so far. But it turns out that if you try to submit this code, you will probably end up getting a wrong answer, which can be a little bit frustrating because it seems like exactly what we have discussed. If you remember during our discussion, I made some passing comments about how when we are actually coding, we should account for symmetries.\nNotice that in our entire discussion, we have been saying just assume that ‘a’ is at least ‘b’, and that is without loss of generality. But here, we are really looking at ordered pairs. There is no reason to believe that ‘a’ is at least ‘b’ for the numbers that we are looking at right now. To put this more generally, I would say that the thresholding condition is that max of ‘a, b’ should be at least Φ times min of ‘a, b.’\nNow, when it comes to ‘b’ being the larger of the 2 numbers, this translates to ‘b’ is at least Φ times ‘a.’ If you want to understand the criteria in terms of ‘a,’ then that is going to be ‘a’ is, at most, 1/Φ*b. It turns out that 1/Φ is just Φ-1. That is just a slightly more convenient way of writing this threshold. Now let us go to our cases and clean them up in light of this new information.\nThe other situation where you could have numbers contributing to winning pairs: if ‘a’ is at most Φ-1*b. Now, this is the threshold (Φ-1*b), which was greater than a2. What does that mean? That means that all the numbers from a1 to a2 actually meet this threshold’s criteria. Therefore, they should all contribute to the sum.\nWe need to enhance our first conditional to account for the situation. We want to say that if Φ-1*b is greater than a2, that means all the numbers in the a1 through a2 meet the criteria that we have written above. Therefore, they should all contribute to the sum. That is a fairly straightforward modification there.\nLet us clean up the ‘else’ branch as well. Previously, we had a lower threshold. We were counting everything that essentially went from that threshold, till the end of the range. Now, we have an upper threshold. So, we have to count all the numbers that essentially fall below the threshold, Φ-1*b. So, we need to increment our answer accordingly.\nSo, once again, we want everything to be below this threshold. Let us again, say, floor for now. If this is not clear, I will just come back and justify it in a minute. But let me just write out the threshold, to begin with. We need to take away minus a1, then we have taken away one more than we need to. So, let us compensate for that by adding 1.\nNotice that you might run into the same issue as before, with these numbers being negative. In this case, this could happen when the upper threshold is below a1. If that happens, then this expression will evaluate to a negative number and completely throw off your account. So, it is a simple but important fix to make sure that you take the max with 0.\nThese are the kind of small edge cases that can seem very mysterious when your code is returning some sort of a wrong answer status. Hopefully, the more practice that you have regarding thinking through this sort of thing, the more alert you will be to do the edge cases. Let us just go through the ritual of running this code and checking the output. It does seem like the output matched here.\nThis is a good time to remind ourselves that this does not mean very much. In most cases, the sample tests are not enough to account for all the edge cases. Sometimes they are even deliberately misleading, depending on the problem author and things like that. So, definitely, make sure to try and test a little more expansively, especially given that this is a problem involving large numbers. It is easy to generate some random tests, or even just throw in 4 numbers that match the thresholds of the problem, and see how long your code is going to take on this just to make sure, for example, that your code will not timeout when you submit it.\nIn fact, since this is a fairly easy thing to do, let us just try it right now. Let us say that we set our thresholds to be 1 and a million and run this code again. One of the most common issues that come up when we are discussing choices of programming languages is the issue of Python being slow.\nBut notice here that this code runs in well under a second. We have really pushed the input to its limits. That is kind of what a good algorithm can do for you. That is the leverage that it can buy. By the way, this reminds me that just in case, you are literally using the same start-up file, before you submit on Code Jam, just make sure to remove all of these operating systems specific things, because otherwise, you will end up getting a runtime error.\nSo, just submit the part of the code that is relevant to the problem. That is essentially about it. I think we have discussed this problem quite thoroughly. Hopefully, all aspects are clear. In case any of the floors or ceilings are throwing you off, just be sure to work with small examples. I think there is no shame in just doing some quick and dirty examples, no matter how simple, if they help you sanity check the corner cases of your code. So, thanks for watching all the way. If you are stuck with anything, as usual, do join us on Discord. I look forward to seeing you there as well as in the next lecture. Bye for now!"
  },
  {
    "objectID": "materials/cpnotes/W01/Lec02.html",
    "href": "materials/cpnotes/W01/Lec02.html",
    "title": "M 2 (Reversort Engineering)",
    "section": "",
    "text": "Lecture - 02\nAd hoc and Implementation - Module 2 (Reversort Engineering)\n(Refer Slide Time: 00:11)\n\nWelcome back to the second module of the first week of getting started with competitive programming. In this video, we will be talking about a problem called Reversort Engineering. This will be building upon the reversort algorithm that we discussed in the previous video. So, just in case you have not watched that, please make sure that you do before starting this video. Now, let us get started as usual with the problem statement.\n(Refer Slide Time: 00:36)\n\nIn the previous problem, which was reversort, we were given a list of numbers as input, and our task was to calculate the cost of reversorting that list. In this problem, our task is going to be exactly the opposite, which is to say that we are now given a cost as input, and our task is to produce a list, which has that cost.\n(Refer Slide Time: 00:52)\n\nSpecifically, we are given two integers n and C as input, and we have to find a list of n distinct integers between 1 and n, such that the cost of applying reversort to this list is exactly C or we conclude correctly that there is no such list. How do you go about tackling something like this? To begin with, notice that the question allows for the possibility that there might be some values of C for which this task is not feasible at all. So, maybe that is a good place to start - To try and understand what is a reasonable range of values for C where this task even makes sense.\n(Refer Slide Time: 01:36)\n\nLet us begin by recollecting what reversort actually does. Remember that it goes through N-1 iterations. In each iteration, it tries to locate the minimum element and reverses the sub-array from the current location all the way up to wherever the minimum element is.\nLet us recall a couple of minor but important details. The first is that if at any point, you are reversing a sub-array of length 1, it may not feel like you are doing any reversing at all, but it still has a cost of 1 unit. The other thing to remember is that the total number of iterations is N-1 for lists of length N. So, essentially, the last step is something you get for free.\nWith that in mind, let us try and come up with a lower bound for the cost C. In other words if you are reversorting some array of length N, is there a minimum cost that you have to pay, irrespective of what the array looks like? If you feel like it, take a moment here to pause and think about this question.\nSo you might notice that reversort has N-1 iterations and because of what we just said, the cost of every iteration is at least 1. There are no free lunches in this entire process at all. So, the cost of reversorting any array of length N is at least N-1. So, if the value of C is strictly less than N-1, then it is pretty safe to declare that there is no such list.\nOn the other hand, let us think about if there is a list whose cost is exactly N-1. Feel free to take a minute if you needed to think about this. So, if you did have a list whose cost was N-1, what would it look like? We already know that there are N-1 iterations and each of them has a cost of at least 1. So, if the total cost had to be exactly N-1, then we could not afford to have a cost of greater than 1 in any iteration.\n(Refer Slide Time: 03:36)\n\nEventually,\n\nIn other words, every iteration must have a cost of exactly 1. When does that happen? Notice that that can only happen if, at every step, the minimum element in that step is already in its correct position. Therefore, the only arrays who have a reversorting cost of N-1 are those which are already sorted, to begin with. In fact, it is interesting to know that for this value of C, the solution is in fact unique.\n(Refer Slide Time: 04:15)\n\n\nSo far, we have seen that the cost has to be at least N-1 for us to have a chance of constructing a list with cost C. Now, let us try to understand what is happening on the other end of the spectrum, which is to say, can we come up with an upper bound for the cost C? How large can C be for us to have some hope of constructing a list with cost C?\nThis time, you want to think about coming up with a scenario where the cost of reversals is as large as it can be in every single iteration. This will lead to some sort of an upper bound. Think about this for a minute and come back when you are ready. So, let us recall that there are N-1 iterations.\nBut notice that the length of the array that the algorithm is working with is shrinking in each step. So, in the very first step, you are looking at the entire array, and in the worst case, maybe you have to reverse the whole array. In fact, we have seen examples where this actually happens. Right?\nSo, in the first step, your cost could be as high as N. But in the second step, since the first element has fallen in place, the sub-array under consideration starts from the second index and goes all the way, till the end. Again here, in the worst case, it is possible that your cost of reversal is N-1, but it is certainly no more than N-1.\nMore generally, in the ith step, the cost of reversal can be as bad as N-i, but no more. And remember that the iterations only go on till the N-1th index. Putting everything together, we know that the cost of reversorting is no more than this sum. If you work it out, it turns out to be and into {[N(N+1)]/2}-1. This is the maximum cost of reversorting any array of length N.\nOnce again, like before, if the cost that we have is greater than this bound, then we can immediately conclude that there is no list of length N, whose cost is exactly C. But now the more interesting question is the issue of finding a list, which actually realizes this upper bound.\nFor a given N, can you come up with a list of numbers from 1 to N, whose cost of getting reversorted is exactly the expression that you see here? Feel free to try this out for some small values of N. I will say that this question is slightly harder than the question of coming up with a list whose cost was exactly N-1. So, take your time and come back to this lecture when you are ready.\n(Refer Slide Time: 06:36)\n\nAs I was suggesting, let us look at some small values of N. The smallest possible value of N that makes sense is 1. Notice that the cost of reversorting, the only array of length 1 is actually 0 because remember, we have N-1 iterations and here, therefore we will have none.\nThe next value of N is 2. There are only two arrays of length 2 over the numbers 1 and 2. So, the array ‘1, 2’ is already in its proper order and the cost of reversorting it is just 1. The array ‘2, 1’ requires a swap in the first step and has a reversort cost of 2. This, of course, is perfectly valid. But notice that we took a brute force approach to coming up with the solution. This is not likely to scale well for large values of N.\nLet us try to arrive at the same conclusion but in a slightly more general way. This may be a slightly funny exercise, because we are dealing with a really small array, but bear with me. We will also go through this when N=3. Hopefully, things will become clearer as we go along.\nLet us think in slightly more general terms about the task of coming up with a list whose cost is as high as it can be. What should we aim for in the first step? Well, in the first step, the maximum cost that we can have is N, which happens when you have to reverse the entire array. When would you reverse the entire array? You would do that if the minimum element is at the very end. So, we already know that in our array, we are forced to place the number 1 at the last position.\nNow, we have to fill up the rest of the array, just to say that we now turn our attention to the first N-1 slots of the array. Of course, with N being just 2, we only have one slot remaining and it is no surprise what should go in there. But bear with me, let us just continue thinking about a general strategy for filling up these first N-1 slots.\nNotice that in the row above, we already have an array of length N-1 whose cost is as high as it can be. So, it seems like a tempting idea to just copy-paste that array in these N-1 slots that we are yet to fill. What is the effect of this? The first thing is that we are no longer left with a valid permutation because we have copy-pasted an array that consists of numbers from 1 to N-1. We also have a 1 at the very end.\nBut as you will see, what really matters is not the specific numbers, but their relative order. So, to fix this and to turn the current array into a permutation, let us just bump up each of the first N-1 elements by a plus 1. This brings us to the array ‘2, 1,’ which is the solution that we had identified, to begin with, by just exploring both the possibilities that we had at hand.\nLet us just make a note of the cost here and move on to the case when N=3, where this whole process might be a little more visible. Notice that as before, to begin with, we have to place 1 at the very last position, if we want the first step to have the maximum possible cost. After this, to fill in the blanks like before, let us just pull down a copy of the array from the previous row. Noting that we do not have a permutation yet, let us just go ahead and upgrade each of those numbers by 1.\nNotice what happens when you run reversort on this array that we have. In the first step, as we predicted, the whole array gets reversed and that has a cost of 3. But after that, notice that we actually have a fully sorted array. So, in the second iteration, we would not get the maximum cost that we are looking for, it is just going to be a cost of 1 for a total cost of 4. That means that we still have some work to do.\nSo, what is going wrong here? Although we did copy-paste a full cost array from the previous row, notice that that array gets damaged after the first iteration. We have designed our array so that the first iteration reverses the whole list. So, as a result, the list that we carefully copied over from the previous step also gets reversed.\nBut the list that we had in the previous step is the list that we want to see at the start of this second iteration, after the first reversal. So, to ensure that is what happens, all we need to do is reverse the list in advance so that the first reversal will reverse it back to what we actually wanted to see.\nYou can pause the video here and convince yourself that this list that we have here has a cost of 5, which is the maximum cost that you can expect from an array of length 3. Now, you can repeat this process quite predictably for larger and larger values of N. Every time you will be able to leverage the list that you build in the previous step to obtain a full cost list in the current step.\n(Refer Slide Time: 11:38)\n\n\nLet us recap what we have learned so far. We have established some boundaries on the values of C. We said that C has to be at least N-1 and at most {[N(N+1)]/2}-1. Anything outside of this is already impossible. For these specific extreme values, we are also able to come up with strategies for building lists whose costs are these exact values.\nNotice, however, that we are still left with the question of what happens when C lies strictly between these two extremes. Then by just looking at these inequalities, it is not completely obvious if we can always build a list of length N whose cost is exactly C. Let us think about the recursive approach that we just used for building a list of the maximum possible cost. In fact, let us just play with a few scenarios to build up some intuition and from there, hopefully, we will be able to develop an actual algorithm.\n(Refer Slide Time: 12:18)\n\n\n\n\n\n\nEventually,\n\n\nSuppose somebody gifts you an array of numbers from 2 to N, whose cost is D. Can you use the array to build an array of numbers from 1 to N, whose cost is, say, D+1? Notice that that is easy, you can do that by just adding element 1 to the head of the array. This way, the first step essentially has cost 1, and the second step encounters the original array and from there on, the total cost of the algorithm will be D.\nWhat if you wanted to build an array of numbers from 1 to N, whose total cost was D+2, instead? Well, then the natural thing to do seems to be to push element 1 to the second position so that the first step will have a cost of 2. Then, again you are left with the original array that you started with. From the second iteration onwards, you will have a cost of D.\nThis array that you see right here has a total cost of D+2. What if you wanted to build an array whose total cost was D+3? It seems like the natural thing to do again would be to push 1 a little further up. But remember, just like we had this problem before, this particular array will not have a cost of D+3, because the first step will cause a reversal, which will mess up with the structure of the original array.\nIn particular, after the first step, the array is going to look like 1, x2, x1, x3, and so on. So, you have really lost the base array that you started with. To fix this, we should swap the elements x1 and x2. Now this array, overall, will have the desired behavior. Notice that in the first step, the reversal will give us the array 1, x1, x2, and so on. That is exactly what we were looking for.\nYou can probably see where this is headed. If somebody gives you a base array of numbers from 2 to N with the cost of D, then you can make use of this array to build an array of numbers from 1 to N, with a cost of, say, D+4, D+5, and so on. In fact, you can do this for any D+x, for any x in the range 1 to N.\n(Refer Slide Time: 14:33)\n\n\nLet us go back to the big picture and try and understand why all this is useful. To begin with, remember that when you are working with N, here is the valid range of values for C. C has to be at least N-1 and at most {[N(N+1)]/2}-1. Let us add to this picture the valid range of values for C relative to N-1.\nThat is going to be N-2 for the lower bound and {[N(N-1)]/2}-1 for the upper bound. So, the idea is that you are starting with a cost C that is in the green range, and if you can subtract from it some amount that will take you to the red range, then the recursive algorithm pretty much writes itself.\nBut the question is, can you always subtract something appropriate? Can you always subtract something that is workable? Well, notice that the difference between the two upper bounds is exactly N. What this means for us is that no matter where the original cost lies, as long as it is lying within the valid green range, we will always be able to subtract a quantity x, which is such that it is between 1 and N so that we get a cost which lies in the red range.\nThen we can pass this off to the recursion fairy, which will do its thing, and it will be able to give us an array whose elements are between 1 and N-1, and that has caused C-x. And of course, you can just add 1 to each of these elements to get an array of numbers between 2 and N, which have a cost of C-x to be reversorted.\nAs the final step, what you want to do is add the number 1 in the correct place to adjust for the cost of x. You want to add the number 1 at the exit position from the left, and everything that you have before the number 1 needs to be reversed so that when the first reversal happens, you recover the array that you obtained from recursion.\n(Refer Slide Time: 16:40)\n\nBy now, I think we have everything that we need to know to be able to implement this solution. Let us just do a super quick high-level recap, and then we will switch over to coding. The first thing we want to do is check the range of C. If C is not within the valid range, then we can immediately conclude that this is an impossible situation and we say as much. But if C is within the valid range, then we need to figure out how much we need to shave off from C to land in a valid recursive sub-instance.\nOnce we do that, we obtain the array from recursion, adjust its values, place one in the correct place, and execute one final reversal to get to the array that has the desired cost. With all this being said, I think it is time to start coding. If you want to do this yourself, by all means, this is your usual spoiler alert, you might want to pause the lecture here and come back to it after you have given it a shot yourself.\n(Refer Slide Time: 17:29)\n\n\n\n\n\n\n\n\n\n\nSo, we have our usual setup here. As before, I have pulled in the values of the sample input and outputs for your reference in the files to the right. Now, the sample outputs for this problem are a bit different from usual, in the sense that it is not going to be a character-by-character match as it usually is for most problems. Notice that, for some values of N and C there might be multiple arrays of numbers between 1 and N whose cost is exactly C.\nIn this case, the problem description says that as long as you print any one of them, your answer will be accepted. Your judge in this case is not going to be doing a character-by-character comparison with some sample output. But rather, it is going to take up the array that you output and it is going to compute the cost of reversorting it and check if it matches the expected cost.\nIf your output does not match with the sample output, maybe because you had a different way of generating these arrays, then do not worry about it too much. Although I would recommend writing down a function that computes the cost of reversorting an array. You have probably already done this if you have solved the previous problem.\nSo, you could use that function as a way to sanity-check your own answers. Once you are producing an array, just use this function to compute its cost, and see if it matches with the expected cost. Rather than trying to do a character-by-character comparison with the expected output, especially if it does not match.\nMoving on, I have already set up the parts about taking in the input. The output format is the usual Code Jam output format. You have to output case number x, followed by either the list or the word IMPOSSIBLE depending on the situation.\nLet me come back to the code. What is already done for you is the basic case analysis that we discussed in the beginning. So, if the cost C is not in the appropriate range that we discussed, then we just print IMPOSSIBLE directly. Otherwise, we have a helper function, which will actually construct this array for us, and you just print this array in the next step.\nLet us focus on building out this helper function because then we would pretty much be done. So, the construct function takes three parameters as input. The first two are quite natural: it is the length of the array you want to construct, that is N, and it is the cost that you want to achieve, that is C.\nThe third parameter tracks the current minimum value of the array. To begin with, of course, this is 1. But in general, as you unravel the recursion, you will want to increase the value of this minimum element. There are other ways of implementing this, but I just found this one to be the most convenient.\nLet us try and see how we would actually do this. Let me just begin by pasting the function signature to save time. N and C are defined as before and M is the variable that we will use to track the current minimum. Now, whenever I am writing a recursive function, I like to get the base case out of the way first, to avoid dangerous situations. So, the natural base case here is when N=1.\nSo, this is an array of length 1 where the minimum element has to be M. We do not have to worry about whether we are working with a valid cost because we kind of know that to be a precondition. So I am not going to really check for anything. The cost here must, in fact, be 0 by the time we have hit the base case.\nIf you want, you could write a condition to check for this. But I am reasonably confident that because the costs were within the valid range, to begin with, they will continue to be within the valid range when we come down to the base case. So, here, I am just going to return the trivial array with just the element M.\nAlright, the more interesting case is what follows. Let me just pull up the picture, which represents our main solution idea. These are the relevant ranges that we are working with. Just going to get one easy case out of the way, which is to say that, when you reduce the cost by just 1, if you already fall within the valid range for N-1, then let us just do that and add the number 1 in the beginning.\nJust to save time, I am going to copy-paste this section of the code here and just take a look at what we are doing. So, we are saying that if C-1 is at least N-2, and C-1 is at most {[N(N-1)]/2}-1, then let us just invoke this function with length N-1 cost C-1 and of course, the minimum upgraded to N+1. We get this array, and then we just add the current minimum to the start of the array. In the beginning, this will be 1, but in a generic situation, you want to add the minimum element in the beginning and append the constructed array at the end.\nHopefully, this case is clear. Otherwise, we just have a little bit of extra work to do, which is to say that, we have to figure out how much to subtract from the cost C, before delving into the recursion. This is the case when the current value is kind of between the right red point here and the right green point here. When you are here, you essentially know that you are within a length’ band N, but you need to figure out exactly where you fall so that you can subtract the right amount to get into the safe zone with respect to the red range, in some sense.\nLet us write down that difference. It is essentially going to be the current cost minus the lower bound. If you subtract {[N(N-1)]/2}-1 from the current cost, then you would have x, which is what do you want to subtract. So, I am going to call that difference delta.\nNow we want to construct an array whose cost is essentially C - delta, and an array of length N-1 and as usual with an upgraded minimum, which is N+1. So, we are going to invoke the current function. This is essentially the recursive step.\nNow, in the previous case, we could just place M at the head of the array. We have a little more work to do, which is to say that, we need to find the right place to place the minimum element M. Then we need to reverse everything that comes before it.\nLet us go ahead and do that. We will, first of all, convert this string into an array because that is going to be useful for the kind of manipulations that we will need to be doing later, in particular, reversing a part of the array and so on. Notice that this array has the minimum element at the first position because that is all that we have done so far.\nLet us see if we can perform the reversal that we need to do. Let us focus on what is inside the join function, which is the array-manipulation that we are doing. Notice that we are working with a new array, which just has the minimum element followed by everything we got from recursion, and we are walking up to the deltath element.\nRemember, that delta is excluded because of 0 based indexing. We essentially need to reverse that entire chunk. Then, we simply add on all the remaining elements of the array. Since construct needs to be returning a string, all we are doing here is converting this array back to a string. And at this point, we are actually done.\nNow, there are some small formalities that remain. Let us take care of them first. Notice that we have not yet returned the answer that we have so painstakingly created. One thing that is nice about VS Code is that it gives you this muted color for those variables that you have declared, but have not used yet. So, that is already a hint that I have left something hanging.\nLet us return the answer. At this point, all that remains to be done is to actually run this code and see how it works. Let me add the template to redirect the input-output to files. Let us run this program. So, we get some output. Notice that if I were to run a diff on my output with the expected output, then we do get some differences here. You can visibly see that the arrays that we are producing are a little bit different from the official outputs.\nAs I said, in the beginning, this has nothing to worry about. But I will leave it as a bit of an exercise for you to come up with a different way of generating these arrays that possibly match with the sample outputs. Although it is not clear to me if the sample outputs were driven by an algorithm that generated them or if they just wanted to deliberately throw us off by using solutions that are different from, perhaps, the natural algorithm.\nIn any case, what is really worth doing is sanity checking that the arrays that you are generating do have the cost that you expect them to have. So, for instance, for the first array here, we were supposed to have a cost of 6. Let us quickly see what reversort would do here.\nIn the first step, you will have a cost of 1 because the minimum element is sitting right there. The next step: You will have a cost of 3 because the minimum element is at the very end. At this point, your array would look like 1, 2, 4, 3. So, the last two elements would need to be swapped, in the last step. That is an additional cost of 2. This array does have a total cost of 6. You can also verify that the array that appears in case number three has a cost of 12.\nAgain, do try this out. Try writing a version of the solution on your own, and do upload it on the Code Jam platform and let us know how it went for you. I look forward to seeing you in the next video. That will be all for now. Thanks so much and have a great time!"
  },
  {
    "objectID": "materials/cpnotes/W06/Lec29.html",
    "href": "materials/cpnotes/W06/Lec29.html",
    "title": "M 1 (Dijkstra’s Algorithm)",
    "section": "",
    "text": "Lecture - 29\nShortest Paths - Module 1 (Dijkstra’s Algorithm)\n(Refer Slide Time: 0:11)\n\nHello, and welcome to the sixth week of Getting Started with Competitive Programming. So this week, our focus is going to be on the ‘shortest paths’ problem, which is both a very fundamental problem in graph algorithms as well as a really popular theme in contest programming. Typically, you are trying to figure out what is the fastest way of going from one vertex to another in a given graph.\nAnd in this module, which is broken up into four segments for your convenience, we are going to be leading up finally to this problem called ‘sending email,’ and we are going to see Djikstra’s algorithm along the way. But before we get started, let me give you a high-level overview of the different scenarios that we will be addressing this week.\n(Refer Slide Time: 01:02)\n\nSo, generally speaking, we will be working with graphs that are weighted and directed. To say that a graph is weighted, in this context, simply means that there is a weight function that maps every edge in the graph to some number. So actually your weights could be any collection of objects that you have the ability to add and compare. But specifically, we will typically be working with integers and sometimes rational weights.\nAnd to say that the graph is directed, we already know what this means from our discussions last week. But just to repeat, a graph is directed if we think of every edge as being oriented, or we think of the edges as being ordered pairs. So (we distinguish) for a pair of vertices x and y, we distinguish the pair x y from the pair y x.\nSo that is going to be the setting that we are working in. Now we are going to start this off by looking at the special case when all the edge weights are one. This is just another way of saying that you are working with an unweighted graph. Now in this situation, the nice thing is that the cost of a path is simply the number of edges on it.\nNotice that when you have weights, this need not be true because depending on how the weights are, it could be that you have a path with a small number of edges that is super expensive, and you have paths with a large number of edges which are cheap. Again, just because of the way the weights are. When all the weights are uniform, this is not something that you have to worry about.\nSo the lengths of the paths are actually a true reflection of the cost of the path as well. Now, this setting is simple enough that we have actually already seen an algorithm to resolve the problem in this case. And our first exercise will be, essentially, to recap a breadth-first search and consider how it helps us solve the shortest path problem in this special case.\nAfter this, we will allow for weights to enter the picture and we will see that BFS no longer quite works in its default form, and we will have to explore a different way of approaching the problem. But we will still restrict ourselves first to the setting when all edge weights are positive because that is a little bit easier to think about compared to the more general case when we allow for negative edge weights.\nThe thing about negative edge weight is that it can, again, mess up your intuition for what you expect to happen when you are dealing with the shortest paths. So we are going to explore this distinction as we go along. So to begin with, we will not allow for negative edge weights and then we will allow for them. But then we do allow for them again we are going to do it in two phases.\nFirst, we will allow for the presence of negative edge weights but we will disallow the presence of a negative weight cycle. Now a negative weight cycle in a graph is simply a cycle which is such that if you were to go around the cycle and add up all the weights of the edges that you encounter, then the cumulative rate is going to be negative. Now you will have to take my word for this at the moment that this distinction is actually important.\nThe presence of negative weight cycles can cause some substantial disruption in the notion of shortest paths. So we will need to handle them carefully and separately. So in the setting when we also allow for negative cycles, we are going to see an approach that is different from the one that we take when we know or we assume that there are no such cycles.\nSo this is going to be the essence of the three different approaches that we take to the shortest paths problem. First, we are going to see an approach when the graph is essentially unweighted, then we are going to look at an approach that works for positive edge weights, and we are going to modify that slightly to allow for negative arcs, but still, we assume that there are no negative cycles.\nSo I am thinking of this as the second broad approach, and the third approach is going to be when we also allow for negative weight cycles and we will talk about that more when we get to it. Finally, we will also deal with separately the problem of all pairs’ shortest paths.\nNow, it turns out that if you know how to do shortest paths, then you can more or less trivially also find shortest paths between all pairs, by simply running this algorithm as a sub-routine between all pairs. But it turns out that there is a slightly faster approach to this problem which is very elegant and, you know, we are going to explore that and implement it as well.\nSo, as is usually the case, we are going to describe these algorithms and describe their implementations, but we will not really have the time to get into proofs of correctness, which are also important to just have a feel for and to appreciate and understand. So if you are curious about which algorithms we are going to be learning so that you can go look them up in more detail after we are done, then I am just going to throw in the names here.\nSo, first, the case of unweighted graphs, as I mentioned, is really the breadth-first search traversal that we discussed last time. And the case when all edge weights are positive can be handled by Djikstra’s algorithm and a slight modification to Djikstra’s algorithm makes it work even when we have negative edge weights but we do not have negative weight cycles.\nOnce we do allow for the possibility of negative cycles, there is the Bellman-Ford algorithm which allows us to either determine the shortest paths correctly or detect the presence of such a cycle. And once again, when we get to this discussion in more detail, you will see why this sort of output actually makes sense. And for All-Pairs Shortest Path, the improvement that we are going to look at typically goes by Floyd Warshall.\nNow, I should mention that shortest paths being a really fundamental graph algorithms problem has been extensively studied, and some of these algorithms were proposed by several other researchers who are not mentioned on this slide. So if you are interested in the rich history of shortest path algorithms and how some of these really popular ones came about, I would highly recommend the chapter on shortest paths in the ‘algorithms text’ by Jeff Erickson.\nThis book is conveniently available from the textbook’s website and I am going to add a link that you can follow in the description of this video. So please do check it out. It has many more details about how these algorithms came about, and there is a nice historical perspective that you will gain if you were to go through this.\nIn the meantime, let us now get started with the special case when all edge weights are one. That will be the focus of this segment. And in the next two segments, we will consider Djikstra’s and modified Djikstra’s approaches, and we will round this off by looking at an implementation in the context of the sending email problems. So that is going to be the plan for this module.\nIn the next module, we will look at Bellman-Ford. Again, we will split it into two segments. In the first, we will study the algorithm itself and in the second we will implement it in the context of a problem. And then in the third and the final module, we are going to do the same for All-Pairs Shortest Paths as well.\n(Refer Slide Time: 09:04)\n \nOkay, so that is the outline. Now, let us get started with the first case, and let me just begin by recapping the definitions for you here. So as we said, we will be working with weighted, directed graphs.\nTypically you might imagine that you have been given two vertices, which we will usually refer to as the source and the target, and you are trying to figure out what is the path that connects the source to the target that has the cheapest cost.\nThe cost of a path is simply the sum of all the weights of the edges that participate in the path. So this quantity that we have just described here is often referred to as the distance. So we will talk about the distance of the vertex T from the source S as being the length of the shortest path that connects S to T.\n(Refer Slide Time: 09:51)\n\nNow this problem that we have just described is often just called the shortest path problem, so you are given two vertices S and T, and you want to find the length of the shortest path from S to T. A very popular variant is the single-source shortest path problem, SSSP, where you are given a source vertex and you want to know the distance of every other vertex from this source. And this is something that you can of course solve by just solving the shortest path individually on every vertex.\nThat is a valid algorithm. But sometimes it is just useful to think of this more holistically and you could come up with better ideas, which solve SSSP in one shot, so to speak. And the SSSP problem will pretty much be our focus for all of this module, and even the next one. But after that, we will turn our attention to this All-Pairs Shortest Path problem which is again a very popular variant. So here we want to know the distances between every pair of vertices in the graph.\nAnd once again, of course, if you know how to do SSSP, you can do APSP by simply running SSSP as a subroutine. Right. So you run an outer loop, which runs through every vertex, and for every vertex, you just run your SSSP algorithm, and you will then end up having discovered the distances between every pair of vertices.\nNow, that is going to have a certain complexity, which is basically the complexity of the SSSP algorithm with a multiplicative overhead of n, n being the number of vertices. And an interesting question is, can you do better? Can you somehow solve APSP directly? And it turns out that we will have some ideas to address that question as well.\nSo these are the three problems that we will be considering. And before we actually get to try to understand what happens when all edge weights are one, let me also get a little more terminology out of the way.\n(Refer Slide Time: 11:50 & 13:03)\n \nSo, you might remember from the previous week, that we defined a path as a sequence of vertices where every consecutive pair is connected by an edge. And in the context of directed graphs, you want the edge to be from say U I to U I +1 if you are looking at the ’i’th and the ’i+1’th vertices of the sequence. So they have to be oriented exactly in the way that you expect them to be. So that is a path.\nAnd notice that when we define a path, we do not really have any constraints on whether vertices can repeat or not. So by default in a path, you could have a repeating vertex. And if you insist that you do not want vertices to repeat, you want all the vertices on the path to be distinct, then you emphasize that by calling it a simple path.\nSo whenever we refer to paths, we will, generally speaking, allow for repetition of vertices. If we want to emphasize that vertices are not being repeated then we will use the phrase simple path instead. Now as long as you are working with non-negative edge weights and you want to observe shortest paths, this distinction is not very important because all of your shortest paths will automatically be certain paths only. To see this, let us look at an example of a path, which is not a simple path.\nSo here, for instance, starting from S, suppose we go to T in this way. So notice that the vertex x is getting repeated, and then we finally land up at T. And imagine that all the edge weights are one here. It should be reasonably obvious that this is not an optimal path from S to T because this whole detour that we did on the cycle X R Q P could have simply been avoided.\nSo whenever you have a path with these repeated vertices, if you just eliminate the detours then you will see that you always end up with a path that is better than the one that you started off with. So as long as your edge weights are non-negative, your shortest paths will automatically turn out to be simple paths. From this example, you can probably already start getting some sense of why negative cycles can be problematic for the definition of shortest paths.\nThis is something that we will explore more fully later but I just wanted to drop a hint in case you were curious about that. But just went back to our definition here, this is just a reminder that whenever we talk about paths, in general, we will allow for repeating vertices. And whenever you are working with non-negative edge weights, your shortest paths will automatically turn out to be simple paths, anyways.\n(Refer Slide Time: 14:23 & 14:54)\n \nNow, in terms of terminology, I should also point out that in some references, in some textbooks, especially graph theory textbooks, what we are calling a path is usually called a walk or a trail. Okay, and what we are calling a simple path is actually just called a path. So this can sometimes be confusing depending on where you are reading from.\nSo it is just useful, I think, to fix one terminology and stick to it in a particular discussion and since this is the tradition and most algorithms books that you will read, I will just stick to this terminology where a path is a sequence of vertices where the constitutive vertices have an edge between them and the vertices need not be distinct. And if I want to emphasize that the vertices are distinct, I will refer to it as a simple path.\n(Refer Slide Time: 15:18 & 15:42)\n \nSo, with that out of the way, let us finally talk about what can we do when all the edge weights are one. So for this special situation, as we have hinted to earlier, we already know an algorithm that determines the distances from any source vertex for us. And this is in fact the breadth-first search or the BFS traversal that we have seen in the previous week.\nSo, in fact, let us pull up the implementation to remind ourselves of what we were doing. So we had this distance array, which was initialized so that every vertex was initially at a distance of infinity from the source, meaning that these were all unexplored vertices and we do not know anything about how close or how far away they are from the source in the beginning. And the only thing that we know is that the source is immediately reachable from itself. So the distance from the source to itself is initialized to zero.\nAnd after this, we had an implementation where we essentially explored all the neighbors of the source first and then the neighbors of the neighbors, and so on and so forth. At every stage, we were careful to not revisit and already visited. And if you draw out a typical BFS traversal you will see that there is a natural layer-like progression. The BFS tree can be organized fairly naturally into layers and it turns out that all the vertices that are in the ‘k’th layer are in fact at a distance ’k’ from the source and this is something that you can prove.\nNow, although we will not be doing a formal proof of why BFS works as claimed, I would like to go through an example just to build some intuition for why you might expect to believe that this works out the way that it does. For this, it is crucial to understand how vertices enter the ’k’th layer in the BFS traversal.\nNow, our code here already has a trigger, which helps you understand when a new layer has started. This is the first time that the distance of the vertex that you are currently exploring mismatches with the layer number that you are currently storing. So when that happens you can print a statement saying that a new layer has just begun and, of course, after that, you update the layer variable, and so on.\n(Refer Slide Time: 17:42 & 18:38)\n \nBut to help our visualization along, I am just going to introduce a conceptual intervention here, which is the idea of using a token to keep track of what is going on with the layers. So this token is a completely artificial concept. It is just in our imagination. You do not have to change or update your code or anything like this. Just follow along with the example that I am going to show you.\nSo the way the tokens are going to work is that, to begin with, we are going to enqueue the source and a token right behind it. And in general at any step, if we pull a token from the head of the queue, then we will just take the token and push it back to the end.\nNow, the idea is that whatever vertices are sandwiched between these two token operations, so to speak, are the vertices that get into a common layer of the BFS traversal. I think this will become clearer as we go through an example. So let us do that.\nSo here is a graph with a source vertex that is been highlighted. So to begin with, as we said we have on the queue the source vertex followed by a token. Now, when we are currently processing the vertex at the head of the queue, what does BFS do? It is going to figure out what are all the neighbors of this vertex that is currently in the limelight, what are all of its neighbors that have not been visited yet.\nAnd we are going to collect all of those vertices and push them to the back of the queue. Now since this is the very beginning, no vertex has been visited so far. So we will just pick up all of the neighbors of S. In this case, there are three neighbors X, Y, and Z, and we are going to push all of these to the back of the queue, and we are going to mark them as visited.\nNow, as you can see, S left the queue and we pushed the token to the back because the token was the next thing on the queue. And now the next vertex to get processed – the vertex in the head of the queue is the vertex X, and X has two unvisited neighbors. I mean it has altogether four neighbors, but only two of those are unvisited so far. So we are going to queue these up, R and P at the end of the queue, and we are going to mark them as visited.\nLet us bring the queue a little bit to the left so we have a little more space. And at this point, we have finished processing the vertex X. So we will let X exit the queue. And now I am going to color code X with a different color because this is, notice, a shift in the layer numbers. So we have the first layer is, by default, just the source vertex.\nAnd now, until the next time that we see a token, all the other vertices are going to be on the first layer. So I am going to mark all of these vertices ‘yellow,’ just to remember that these have been processed, and they were members of the first layer. So the second vertex in the first layer is vertex Y. So this is our current active vertex. It has only one unvisited neighbor. So we are going to identify this neighbor T and push it to the back of the queue.\nNow, we will let go of Y and again mark it as a vertex that was processed as a part of the first layer. Now the last vertex in the first layer is the vertex Z, and Z has two unvisited neighbors. So let us identify U and V. So we go ahead and add U and V to the back of the queue. At this point, we are ready to let go of Z and we also remember to mark Z as the last vertex to be processed in the first layer.\nNow we see the token, which is a signal that we have finished processing all the vertices in the first layer. So we push the token to the back and we are now mindful of the fact that we have started off a new layer which in this case is going to be the second layer. So let us see what happens in the second layer. The first vertex at the head of the queue is the vertex R and R only has one unvisited neighbor, which is Q.\nSo we identify Q and add it to the back of the queue, and then we let go of R. When we look at P and T, which are the next vertices in the queue, they have no unvisited neighbors. So we simply mark them as being processed. And notice that now the color-coding has changed to denote the fact that we are processing vertices in, now, the second layer. So the next vertex is U and U does have an unvisited neighbor which is W.\nSo we add W to the back of the queue, let go of the vertex U, mark it as processed. And finally, we see V, which has no unvisited neighbors. So we simply let it go. And again mark it, as being processed. And the next thing on the queue is the token, which tells us that we have finished processing all the vertices on the second layer, and this marks the start of a new layer, which in our case is going to be the third layer.\nSo as before, we push the token to the back, and we process the two vertices that we have on the third layer. None of these vertices have any unvisited neighbors. So we are simply going to run through them and let them go and just mark them as being vertices in the third, and in our case, also the last layer because now the only thing left in the queue is the token, which is a sign that BFS has run its course and the algorithm is now complete.\nSo if you were to look at the sequence in which the vertices got processed, organized by layer, you will see that this is how everything panned out. So we started with the source which was on layer zero, and then on the first layer we saw its immediate neighbors X, Y, and Z. And X, Y, and Z were responsible for pulling in collectively the vertices R, P, T, U, V on the queue that constituted the second layer. And these guys brought in Q and W.\nHopefully, it is intuitive that when you are on layer number k, you are at a distance of k from the source. It is clear that you are definitely reachable within k steps. That is for sure because you can just follow your parent pointers and trace your way back to the source. The only question and the thing that actually requires proof is to say that you cannot do it any faster. You cannot do it with fewer steps.\n(Refer Slide Time: 24:23 & 25:07)\n \nAnd the intuition for that is that if you could do it with fewer steps, then you would have been recognized, and you could have been pulled in earlier in a previous layer. This is something that you can formalize using induction. And here are a couple of statements that you may want to think about proving if you have not seen formal proof of this in a previous class. It is worth sitting down and trying to work through this.\nSo essentially, we are saying that when you are at the end of the ’k’th phase when you look at a vertex, its distance is either infinity, so this is distance as recorded in the distance array. So either it is so far an unseen vertex, or if it is a seen vertex then the value that is recorded in the distance array is going to be at most k. And it is exactly k if and only if you are in the queue at the ’k’th phase.\nAlso, the correctness of BFS in the context of capturing distances is given by this claim here, which says that once BFS is done, the values in the distance array are a true reflection of the actual distances in the graph. This is something that you can prove using induction. As usual, I will not be going into proof here. But if you are interested, you could either try figuring this out on your own, or you can look up the pointers in the description of this video where you can read up on proof of this fact.\n(Refer Slide Time: 25:52 & 26:17)\n \nSo the main takeaway from our discussion so far is that if you have an unweighted graph, then BFS is your best choice in terms of computing distances between vertices. However, once edge weights come into play, then BFS might not work out. So in particular, you could try to pause the video here and come up with an example of a graph where BFS does not do the right thing in terms of capturing distances when edges have weights on them. So feel free to pause the video here and come back once you have had a chance to think about this.\nAlright so here is an example. It is a graph with just three vertices, and the edge weights are as shown. And you can see that if you are trying to figure out the distances from the source to all the remaining vertices, then the best way to get from S to B is not via the direct edge, but to actually take a detour and go via A because that is how the edge weights have been set up.\nOn the other hand, because the way BFS works is the algorithm is not really trained anywhere to account for the weights at all. It is just going to blindly pick up both the neighbors of S in the first layer of the exploration. So both A and B will have the same status as vertices on the first layer. And if you were to do backtracking to find the shortest path, then BFS would tell you that the best way to reach B is via the direct edge from S, which in this case is not quite right.\n(Refer Slide Time: 27:27 & 27:39)\n \nAnd it is not surprising once again because BFS is really not trained to look at weights at all. So you could try to fix this in some sense, by making BFS see the weights by potentially messing around with the graph a little bit. So one thing that you could do, which is actually a pretty common trick is to puncture the edges that have weights on them as many times as the weight, roughly.\nSo actually, ‘weight - 1’ many times, so that the edge, which previously was just a direct edge is now automatically elongated to reflect the actual weight of the edge. Now, of course, this will work as long as your weights are positive integer weights so that you can do this puncturing an appropriate number of times. And you can convince yourself that if you run BFS on this modified graph, things will actually work out and you will get the correct distance values.\n(Refer Slide Time: 28:47 & 29:02)\n \nSo this feels like a tempting way to prolong the usefulness of BFS. So at least when you have positive integer weights, maybe you can actually do this. Would I recommend it? Well, unfortunately, no, not really. The reason for that is that this operation of subdividing the edges and inserting these artificial dummy vertices can be extremely expensive. And, in particular, the graph that you generate by doing this trick – the number of vertices in this graph, as you can imagine, is going to be proportional to the weights of the vertices.\nSo if you have the weights of the edges, sorry, so if you have edges whose weights are rather large, you are going to be creating a humungous graph that you do not really want to deal with. Instead, what you might want to think about is – Come up with a way to predict the behavior of BFS. Really the key thing that you want to think about is, what is the next real vertex, not the dummy vertices, what is the next real vertex that BFS is going to add to the queue in this modified graph.\nAnd if you can distill the essence of BFS’ behavior on this graph, if you can predict properly which is the next vertex that gets added to the queue, then hopefully you can bypass the creation of this intermediate graph and you can directly write an algorithm that will do the right thing for graphs that have non-negative edge weights.\nSo that is more or less what we are going to do, and that is going to lead us to a discussion of Djikstra’s algorithm which is what is coming up in the next segment of this video. So before you watch that, maybe just think about what would be your strategy to deal with edge weights, especially when you do not have to worry about negative edge weights. I will see you back in the next segment!"
  },
  {
    "objectID": "materials/cpnotes/W06/Lec33.html",
    "href": "materials/cpnotes/W06/Lec33.html",
    "title": "M 2 (Wormholes [Bellman-Ford | Negative",
    "section": "",
    "text": "Lecture - 33\nShortest Paths - Module 2 (Wormholes [Bellman-Ford | Negative Cycles])\nWelcome back to the second module of week six and Getting Started with Competitive Programming. So, in this module, I want to focus on the single-source shortest path problem, even in the presence of negative cycles. So we are going to be learning about an algorithm that is popularly known as the Bellman-Ford algorithm.\nAnd we are going to implement this in the context of a problem called ‘wormholes,’ which is available from the UVa platform. So this module is in two segments. In the first one, we will talk about the general algorithmic approach and in the second segment, we will introduce the problem statement for wormholes and also work through its implementation.\n(Refer Slide Time: 00:59)\n \nOkay, so just to recap what we have seen so far – We have broadly identified four different scenarios based on the nature of the weights on the edges. So the first one which is the simplest is when there are no weights at all or you could think of this as all the weights being uniform or set to one. And the slightly more general case is when we have non-negative edge weights.\nAnd then we have a situation where we allow for negative edge weights but we do not have negative cycles, and the final situation is when anything goes and you could also have negative cycles. Now in terms of what we have seen about what we can do for these scenarios, we did say that breadth-first search traversal which you saw last week already is a nice linear time algorithm for the first case and is the preferred approach when you do have a situation without edge weights.\nNow when you do not have negative edge weights, then you could use Dijkstra’s algorithm even in its original form. And when you have negative edge weights but no negative cycles, then a small modification to Dijkstra’s algorithm works and makes it an accurate algorithm for the situation. But one thing to note is that that comes at the price of the algorithm being potentially more expensive, especially on instances that do have negative edge weights.\nIf you are looking at instances of the second category where there are no negative edge weights at all, then it does not matter which version you are working with, they have the same complexity. Okay, but we do know that even the modified version of Dijkstra’s algorithm will run into potentially an infinite loop if there is a negative weight cycle in the input graph.\nSo as we said, the focus of this module is to really address the issue of negative cycles, and why are negative cycles such a problem. Well, first of all, a fundamental issue is that even the very notion of shortest paths becomes ill-defined when you have a negative cycle in the graph. So let us take a look at an example.\n(Refer Slide Time: 03:23)\n\nSo here is a graph, and you can see that there is a cycle on the vertices S, A, C, B, in that order, and the total weight of the cycle is easily seen to be negative. In particular, it is, I think, -37. Now let us say that we want to find the shortest path from A to D. A perfectly reasonable way of reaching D from A seems to be to go via vertex A. So let us see what that would look like. You go from S to A.\nThen you go from A to C, and then the final leg of this journey is going to be from C to D. Now, this path has a total cost of 1 + 2 + 3, which is 6. But do you think you can do better? Pause the video here and try to figure this out for yourself. Is there a path whose cost is less than six? And remember, when we talk about paths, we are allowed to repeat vertices in our journey. That is not a problem.\nSo take a pause here and come back once you have had a chance to think about this whenever you are ready. Alright, so perhaps you were able to see that instead of taking this last hop from C to D, suppose we were to back up a little bit and we came back to the vertex C, and instead of going to D from here, let us say that we go to B instead. And from B we go to S, and then we go from S to A and A to C and then C to D.\nIf you were to do this then you would essentially end up with a path whose length is -37 + 3, which is, I think -34, which is certainly much cheaper than 6. And now the problem is that there is nothing that prevents you from doing this detour twice for instance, or doing it thrice, or doing it four times. In fact, you could do it as many times as you like and every time you will end up making your previous path even shorter.\nSo this could go on really forever and then you could ask yourself the question: What does it even mean to talk about the shortest path from S to D when you have this sort of a negative cycle detour on the way which can be taken as many times as you want to keep making the path shorter and shorter or cheaper and cheaper depending on how you want to think about it?\nSo now that we appreciate why negative cycles can be problematic in the context of shortest paths, in particular, we see that the presence of negative cycles can make the very notion of shortest paths ill-defined. Now we want to think about how do we tackle this kind of situation. So I think there are two natural workarounds.\nThe first is to, perhaps, even change the definition of the problem. One of the reasons we are able to do these infinitely many detours is because we are permitting ourselves to repeat vertices along our journey. We could say that this is intuitively wasteful and we could think about just trying to find the shortest path between S and T which happens to be a simple path, which is to say that we do not allow for vertices to repeat.\nI think this is a very interesting variant, and there is a good reason why it is considered to be a much harder problem than most of the shortest path variants that we are going to see here. So this is something that I am going to leave as food for thought. This is not the variant that we are going to consider.\nThe more standard approach is to simply say that when we do have negative cycles then the notion of the shortest path is not well defined. So in this case we have no obligation to report the shortest path. So we basically detect a negative cycle and produce that as a witness to why we could not find the shortest path, basically because the notion is not well defined.\nSo in this most general situation, our task essentially boils down to detecting the presence of a negative weight cycle if it exists, and if it does not then we just report the shortest paths as we have been doing so far.\n(Refer Slide Time: 08:00)\n\nSo just going back to the summary for the moment so that we can add to this picture: What we are going to look at now is the Bellman-Ford algorithm, which has a running time that is either order ‘n’ cubed or order ‘n’ * ‘m,’ depending on whether we model the graph is adjacency matrices, or adjacency lists, respectively. And this will algorithm will turn out to do exactly what we want, which is to say that it can identify negative cycles when they are present and compute shortest paths and absent.\n(Refer Slide Time: 08:38 & 08:56)\n \nNow, just like Dijkstra’s algorithm, Bellman-Ford also works by relaxing tense edges, in some sense for as long as it can. And before we get to a more explicit description of what the Bellman-Ford algorithm does, let is just quickly recap the notion of a tense edge, and what it means to relax one.\nSo an edge from ‘u’ to ‘v’ with weight ‘w’ is said to be tense if the following inequality holds: ‘t’ + ‘w’ < ‘d,’ where t and d are our current understanding of the distances of the vertices u and v, respectively, from the source. So t can be thought of as the value of d of ‘v,’ if d is the distance array. And d can be thought of as the value of d[v], again, d being the same distance array.\n(Refer Slide Time: 09:44 & 10:18)\n \nSo when this inequality holds, it is clear that we have discovered a better way of getting to v compared to whatever it is that we had in mind so far. So we are going to put that on the record by relaxing this edge, and what it means to relax this edge is to essentially get rid of the information that we had so far about v and replace it with this updated information about this new and better path from the source to the vertex v.\nSo the distance of v, the d array is going to reflect this new value, d + w. Now we have performed this kind of relaxation operation several times in the context of Dijkstra’s algorithm. Now let us take a look at how Bellman-Ford is going to perform these relaxations.\nSo it is really a very elegant and simple algorithm. So what we are going to do is initialize a distance array, as usual, and then what we are going to do is we are going to repeat the following process ‘n-1’ times, the process being: Just relax every tense edge. So you are going to basically go over every edge in the graph, and check if it is tense, and if it is, then you are just going to relax it. That is it.\nThat is pretty much the algorithm, except for one last step which I will come to in a moment, but you can probably already see where the running time is coming from. There is this outer loop that is going to run ‘n-1’ times, and the inner loop is going to run ‘m’ times because you are going to go through every edge to check if it is tense.\nSo just to understand what is happening let is think about what happens in the very first iteration of the outer loop. Now, at this point, you know that the distance array looks something like this. It is just a more visual representation of the first line of code that you see here or at least pseudocode. And basically what we have is that the distance of the source to itself is zero, and everything else is initialized to some very large number.\nAnd at this point, we are going to go through all edges and ask them if they are tense. So which edges are going to be tense at this stage of the algorithm? Take a moment to think about this and come back when you have an answer.\nOkay. So, hopefully, you have also concluded that at the very first stage, the only edges that are tense are the ones that are basically incident on ‘s.’ These edges are definitely tense because you have d[u] being zero, and the weight of u to v, in this case from the source to any other neighborhood of the source, is going to be some finite value. So this is going to definitely be better than this initial infinite value that we have in the array.\n(Refer Slide Time: 12:18 & 13:16)\n \nSo, all of the edges that are incident on s are tense. So every vertex v that is a direct neighbor of ‘s’ has its distance values updated by the end of the first phase. Notice also that none of the other edges are going to be tense in the very beginning because if you consider any edge ‘u v,’ where neither u nor v is the source, then both of the distance values are going to be the same large number that is depicting infinity.\nAnd therefore there is no reason for this image to be tense. So the picture at the end of the first round of Bellman-Ford actually looks pretty similar to what happens in the first round of Dijkstra, but we will see that things pan out a little bit differently as we go along. So in particular, you might want to spend a little bit of time thinking about what happens at the end of the second round, what happens to the end of the third round, and more generally, what happens at the end of ‘i’ iterations of the outer ‘for’ loop in the Bellman-Ford algorithm.\nSo here is a claim that I am going to make once again without proof, and as always, there are links in the description where you can find out more about why this is true, or you can try to prove it yourself using something like induction. So the claim is the following.\nAt the end of ‘i’th round, if there is a vertex v that is reachable from vertex s by a sequence of atmost ’i’ edges, then the value in the distance array for the vertex v is going to reflect the cost of the shortest path sequence on atmost ‘i’ edges. So, among all paths that have length atmost ‘i,’ the value in the distance array is going to be the cost of the cheapest such path or the shortest such path.\n(Refer Slide Time: 14:25 & 14:59)\n \nSo, that is the claim, and that is what happens at the end of the ‘i’th round. So in particular, if I were to just think about ’i’ as being n-1, which is the other extreme, that is the last round. So what we want to say is that if v is reachable from s by a sequence of atmost ‘n-1’ edges, then d[v] reflects the cost of the cheapest such sequence.\nThis is just the statement that we made a moment ago, but with ‘i’ being substituted for by ‘n-1.’ So this is what happens at the end of the algorithm. This is true when the algorithm has finished its course. So what can you say if there is a tense edge in the graph after all the ‘n-1’ rounds of Bellman-Ford have run their course, and have completed their work? What can you say if there is a tense edge after all of this?\n(Refer Slide Time: 15:31)\n \nPlease do think about this for a moment because the answer to this question holds a key insight with regards to this algorithm. So take a pause here and come back once you are ready. Alright, so I claim that if there is a tense edge after all the ‘n-1’ rounds are done, then they must in fact be in a negative weight cycle in the graph. And the reason for this, roughly speaking, is the following.\nIf you did not have negative weight cycles in the graph then all shortest paths would have, in fact, been simple paths. There would never be a reason to repeat a vertex because if you consider a path that repeats a vertex then you can look at the first time that you visit the vertex and the very next time that you visit the vertex.\nSo this subpath is going to be a cycle. And because there are no negative weight cycles, this cycle must have a weight of either zero or positive. Now, if you were to just completely avoid this detour then you obtain a path, which has fewer edges and the cost is either the same as before, which would happen if the cycle had zero weight or it is in fact better than before. So that tells you that in a graph that does not have negative weight cycles, essentially, all shortest paths are in fact simple paths.\nAnd in particular, they will only involve at most ‘v-1’ edges. So, if your graph did not have any negative weight cycles then because of the claim that we made here at the end of ‘n-1’ rounds, we would have, in fact, correctly computed all the shortest paths already. And since all shortest paths have been computed, no remaining edge should be tense anymore because there is nothing to improve on.\nNow, if you turn this around on its head, what this means is that if you still have a tense edge that is left after all of the ‘n-1’ rounds are done, then that implies that there must be a negative weight cycle. So that is essentially how Bellman-Ford works to detect negative weight cycles when they exist and to compute shortest paths correctly when they are not present.\nSo what we do is run ‘n-1’ iterations of this song and dance of identifying all tense edges. And when that is completed, we scan the set of all edges one more time. And in this last scrutiny, if any edge turns out to be tense, then we say: Okay, look, we have evidence that there is a negative weight cycle.\nSo, you could stop there, but if no edges are tense once you have finished the first ‘n minus iterations’ – if in this last scrutiny, all edges are perfectly happy, then we know that the distance array has correctly captured the costs of the shortest paths from the source to the respective vertices. And so, we are done as well.\nOf course, the correctness of this hinges on a claim that we made about what happens in the ’i’th round. And once again, I should emphasize that this claim was made without proof. And if that is something you are interested in, you can certainly read up on the references that accompany the description of this video.\nSo this brings us to the end of the description of the mechanics of Bellman-Ford. It is a really elegant idea, and it is also fairly easy to implement. And we are now going to study the implementation in the context of a problem called ‘wormholes.’ And, this was a problem that is available from the UVA platform, and we are going to continue this discussion in the next segment. I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/W06/Lec32.html",
    "href": "materials/cpnotes/W06/Lec32.html",
    "title": "M 1 (Modified Dijkstra)",
    "section": "",
    "text": "Lecture - 32\nShortest Paths - Module 1 (Modified Dijkstra)\n(Refer Slide Time: 00:11 & 01:29)\n \nSo welcome back to the last segment of the first module in week six on shortest paths. As you might recall, we have been talking about the single-source shortest path problem throughout this module. And so far, we have figured out what to do when all the edge weights are uniform, and also when all the edge weights are guaranteed to be non-negative. In fact, in the previous segment, we saw an implementation of Dijkstra’s algorithm, which is an algorithm designed to handle precisely this kind of situation.\nNow, the focus of this module is going to be the case when we do allow for negative edge weights, but we continue to avoid what are called negative cycles. So a negative cycle is simply a cycle whose total edge weight, when we just add up all the edges that are participating in the cycle, that total is negative. That is a negative cycle. And we are going to assume that we do not have such cycles in our graph.\nWe will have more to say about why negative cycles are problematic in the context of shortest paths in the next module. But for now, let us just take this as a given. So we are going to assume that our graphs do not have negative cycles, but they may still have edges with negative weights.\nAnd remember that where we stopped last time, we said that such edges could be problematic. The proof of correctness was really dependent on the assumption that the edge weights were non-negative. So we also said that you could come up with concrete examples that break the algorithm if you allowed for edges that have negative weight.\n(Refer Slide Time: 01:46 & 02:22)\n \nSo perhaps you have already come up with your own examples or you would like to come up with something yourself. So feel free to pause the video at this stage and play around a little bit because what I am going to do next to start off with an example just to make a point about the ways in which Dijkstra’s algorithm can fail in the form that we had discussed it last time. It could potentially give the wrong answer if you do allow for edges that have negative weights.\nSo let us go ahead and take a look at the following graph. So we have five vertices here. The source vertex is the leftmost vertex on your screen that is labeled S. And the edge weights are as given in the boxes. And what we have on top is the distance array that is going to be maintained by Dijkstra’s algorithm.\nAs we know in the beginning, S is the only vertex for which we know the distance from S, and that happens to be zero, and everything else is initialized to some very large number. So in the first iteration here, we can see that the edges from S to A and from S to B are the tense edges. So we are going to update their distance values to one and ten, respectively.\nAnd now the job of S is done. So we are going to look for the next minimum value that we can find in the distance array and that happens to be the value of A. So we are going to explore all the edges that go out of A and there is one such, which is the edge from A to C, and this is indeed a tense edge.\nSo when we relax it, we update the value of the distance of C to 3 because that is the distance of A plus the weight of the edge from A to C, 1 + 2. And so that is the current state of the distance array. And now that we have finished processing A, we are going to extract the minimum value in this array again and this time, that is owned by the vertex C. And then again we are going to explore the edges that are incident to C, and see if these edges need to be relaxed.\nSo one edge incident on C is the edge from C to D, and as you can see here, this edge could certainly use some relaxing. The new value of the distance of D should be the sum of the value of distance to C + the weight of the edge from C to D. So that would be 3 + 3, amounting to 6.\nThe next minimum value in the distance array is owned by D. So that is the vertex that we are going to process next. Notice that D does not have any edges incident to it. So there is no work to be done. And then we run our final ExtractMin operation and we are going to see that we have only one value left in the set or the priority queue, whatever you are working with. And that is the value corresponding to vertex B.\nSo let us consider vertex B. You will see that there is an edge that is incident on B, the edge from B to C. And one question here is, is this edge tense? So let us think about this. The current value of the distance of C is three. On the other hand, if you look at the distance of B + the weight of the edge from B to C, then you get a value of 10 ± 10. And that is zero. So in fact, it is quicker to reach C from S via B. But unfortunately, we decided to take the longer route based on whatever we have discovered so far.\nIntuitively, the issue with missing out on this edge is that, well, when we did discover B, that was already an expensive proposition and Dijkstra’s algorithm did not think that you are going to be able to do anything better in the future. And indeed if all the edge weights are guaranteed to be non-negative, then you can see here that there is no way that you could have improved on the distance of C by going via B because this edge from B to C would have had a weight of zero, at best, and then you could not possibly beat what you already have for C.\nBut somehow these negative edge weights coming in later could really mess around with your calculations. But at this point, notice that the algorithm cannot really do anything meaningful. The queue is empty. There is no way to actually register this improved distance and make sense of it.\n(Refer Slide Time: 06:46 & 07:38)\n \nSo you can see why Dijkstra’s algorithm is going to fail in the presence of negative edge weights, and this is one example to illustrate that. Now we are going to make a very simple modification to Dijkstra’s algorithm that will actually fix this issue. And once again, you could pause the video here and think about what sort of a modification would you attempt if you had to work around such issues.\nThe natural thing seems to be to somehow allow for these relaxations even after the vertices at the other end of the edges have left the priority queue. Perhaps there is some way of bringing them back in. So please think about this hint, which pretty much gives me the modification that needs to be made, but still feel free to pause here and think this through before you continue the conversation with me.\nOkay, so hopefully you have had a chance to think about this a little bit, and let us take a look at the modified version of Dijkstra’s algorithm here. So remember that previously, what we were doing was that we inserted all the values of the vertex distance pairs into our priority queue. Now what we are going to do is we are just going to insert ‘S,0,’ which is the only vertex about which we know anything at the start. And other than this, the priority queue is empty.\nThis is just a minor difference in the initialization. And what we are going to do going forward is that every time we relax a tense edge, we are going to ask ourselves – Is V, which is the vertex at the receiving end of the tense edge – we are gonna ask ourselves if V is already in the priority queue. If it is then as before, we decrease its value appropriately. And if it is not in the queue, we actually bring it back.\nI said queue and what I really meant was the priority queue or the set or whatever it is that we are using to maintain information. So what we want going to do is make sure that V makes a comeback if an edge incident on V has been relaxed. So this way, it is possible that a vertex gets out of the queue and then comes back and is extracted again, and so on and so forth.\nSo you do have to think about whether a running time analysis from before holds up in the same way. As a matter of fact, it does not. But in some sense, if your input does not have negative edges then there will be a vertex to make a come back into the queue. So, then the analysis is pretty much the same.\nBut in the presence of negative weight edges, what happens is that the previous algorithm is going to have the same running time as before but possibly a wrong answer. And this algorithm is going to have potentially a worse running time, but that is the price you pay for getting to the right answer.\nNow because the running times of both versions of Dijkstra’s algorithm are very similar in the absence of negative edges, you might as well always work with a modified version. Whenever you do not have negative edge weights, you are going to get a performance guarantee that is very similar to the original versions. You have nothing to worry about. And when you do have negative edge weights, then at least you do not have anything to worry about in terms of correctness, even though you are going to them may take longer to run.\nIn fact, it is a nice puzzle to think of adversarial examples for this version of Dijkstra’s algorithm. So you could try to come up with a graph where you have carefully engineered negative edge weights, which really forces this algorithm to take a really long time. I can tell you that the worst-case running time of this version of Dijkstra’s algorithm on graphs that do have negative eight edges is significantly worse than the worst-case running time when restricted to instances that do not have any negative edge weights.\nNow, let me just make a quick comment here about the implementation. In this version of Dijkstra’s algorithm, you could actually use a priority queue directly, even if you do not have a DecreaseKey method for it. We are going to practice something called ‘lazy deletion.’ So basically, whenever we decrease the key value for a particular vertex, the way we are going to do it is just by inserting the new value.\nAnd we are just going to let the old value be present in the priority queue, and we will just leave it there. And whenever we do an ExtractMin operation, we need to add a small check which basically tells us if this is the current value, or if it is one of those stale, older values that is lying around. And that check would essentially amount to comparing the value that we have in the priority queue with the value in the distance array.\nIf the value from the priority queue is higher than the value that we have in the distance array, then we know that this is a stale, old value and this just needs to be rejected from consideration. So let us just look at how this version works in code.\n(Refer Slide Time: 11:53)\n\nSo here is the operational version of the pseudocode that you just saw. So notice that instead of a set, we are here using a priority queue. And if you were using Python, for instance, you could use a heap or something like this from the standard Python libraries.\nAnd the way this works is pretty much the same as before, except that when you are updating, which is what is happening in the last line of code, when we were working with a set, what we said was that we will delete the old element and insert the new one. And here all that we are doing is we are inserting the new element without bothering to delete the old one.\nAnd the reason this works is that whenever we perform an ExtractMin, we are able to distinguish between whether or not we are working with a value that is the current value, or whether it is one of those old and obsolete values. So you can see the line where the accompanying comment is a very important check.\nThat is the line of code that is ensuring that we are always working with valid values when we are doing ExtractMin. So we do ExtractMin as usual in the line that is just before it, and we do a quick check of the value that we extracted. We compare that with the value in the distance array, and if the value is larger than what we have in the distance array, then we know that this value is not a current value. It is an obsolete value. So we just move on.\nSo this implicitly implements the deletion, but we call it ‘lazy deletion’ for this reason. It gets deleted automatically in due course. We do not have to necessarily do the deletion when we are also doing the insertion in the update step. So that is how this works.\nI should mention that this code is based on the code that is in the repository for the competitive programming book. And as usual, you will find a link to their repository in the description of this video, in case you would like to cross-refer it.\n(Refer Slide Time: 14:05)\n\nAlright, so with all this said, let me just summarize everything that we have learned so far. So, when all the edge weights are uniform then BFS works just fine. And this is your best bet, in terms of running time. So if you encounter a shortest path-based problem, if there is a problem that can be modeled as a shortest path situation, and all the edge weights happen to be uniform, by all means, go ahead and use BFS. It is elegant, it gets the job done, and it is fast. So that would be the right choice.\nNow in case you do have edge weights, then you could either use Dijkstra or modified Dijkstra. In particular, if you do have negative edge weights then you should not be using the original form of Dijkstra’s algorithm. Because as we saw, that could give you an answer. So in that case, you definitely want to make sure that you have the modification accounted for. Both of these versions have similar running times when all the edge weights are guaranteed to be positive.\nSo, if you like, you could always default to using what is called modified Dijkstra. In fact, if you look at the reference for this module, this shortest paths chapter in the ‘algorithms text’ by Erickson, the author in that text stays that he really prefers to call modified Dijkstra ‘Dijkstra’s algorithm’ because he thinks the algorithm that is correct for a larger class of graphs is probably the one that should be used by default. So you could certainly do that.\n(Refer Slide Time: 15:59)\n \nOn the other hand, if you do end up using the default version, then just remember to be careful about not using it if the weights can potentially be negative. Now, in terms of implementation, we saw that the original version of Dijkstra can be implemented using sets in C++ and this will also work in Java, for example. But the modified version can be implemented directly with a priority queue combined with this idea of lazy deletion.\nSo there is an important check that you have to do whenever you are extracting the minimum to make sure that you are not working with an obsolete value. But once you do that, everything works out great. And if you are a Python user then you might just want to stick to using this version because that is the one that can be implemented in a straightforward way.\nSo, all of this is great for up to the situation when you have graphs that have potentially negative edge weights but no negative cycles. How does the presence of negative weight cycles shake things up? Well, quite a bit actually. So if you think about modified Dijkstra’s algorithm and if you try to simulate it on graphs that have negative weight cycles, you might discover for yourself that this algorithm potentially gets into an infinite loop, which is of course, not a good thing and a situation that you want to definitely avoid.\nSo whenever you are working with a problem that is based on shortest paths, and you have negative edge weights being allowed, please do check for whether you have been told that there is a promise that there are no negative weight cycles. If such a promise is made explicit, then of course you can go ahead and use all the machinery that we have talked about so far.\nBut without this assumption and with the possibility that there may be negative weight cycles, you want to be a little more careful. And in the next module, we are going to talk about how we can detect the presence of negative weight cycles, and how we can compute the shortest paths when we are confident that the graph does not have negative weight cycles. So all of that is coming up. So this is a good place to stop here, and I will see you back in the next module!"
  },
  {
    "objectID": "materials/cpnotes/W06/Lec30.html",
    "href": "materials/cpnotes/W06/Lec30.html",
    "title": "M 1 (Dijkstra’s Algorithm)",
    "section": "",
    "text": "Lecture - 30\nShortest Paths - Module 1 (Dijkstra’s Algorithm)\n(Refer Slide Time: 00:11)\n\nWelcome back. Let us continue from where we left off in the last segment where if you recall we are talking about the single-source shortest path problem. And we said that, well, if you are dealing with an unweighted graph when all the edge weights can be thought of as one, then an algorithm that you have already seen from last week, which is breadth-first search, actually gives you the shortest path information that you are looking for.\nWe also saw that breadth-first search fails even on small examples once edge weights do come into the picture. We discussed a way of making BFS work when all the edge weights were positive integers, and we did this by puncturing the edges with artificial intermediate vertices so that BFS would be sensitized to these weights by having to go through these prolonged paths.\nHowever, we also observed that this can be an expensive trick. So we wanted to see if there was a more efficient way of achieving the same outcome, which is to say, having a way to determine the shortest paths but without having to go through this expensive route of creating these large number of artificial vertices. So that is going to be the focus for this segment. We are going to deal with the case when we have only positive edge weights to worry about, and we will see if we can essentially predict what BFS was doing on that modified graph but without having to go through the trouble of actually modifying the graph.\n(Refer Slide Time: 01:50)\n\nSo we are going to continue working with a distance array, which will typically be initialized in this way. So you have a fixed source vertex and the distance from the source to itself is going to be zero. And to begin with, you do not know anything about the distances of the other vertices. So we will typically initialize these values to infinity in principle. And in your code, you want this to be a sufficiently large number.\n(Refer Slide Time: 02:31)\n\nNow, let me introduce the concept of a tense edge, which is a notion that keeps coming up in many shortest path algorithms. So let us say that we have our source vertex here, and we have an edge from ‘u’ to ‘v’ whose weight happens to be ‘w.’ And let us say that we have some current understanding of how to get from the source to the vertex u, and this is reflected in the distance array with the value ‘t,’ which is to say that there is some path from ‘S’ to u, whose total cost is t.\nAnd similarly, we have some value in the distance array for the vertex v. That value – let us call it ‘d’ – which is again just to say that our current understanding is that the best way to get to v from the source S is via a path whose total cost is d. Now, we say that this edge here is tense if the following inequality holds. The inequality is t + w < d.\nNow, please feel free to pause here for a minute and think about: What does this inequality really mean? Does this inequality imply that there is something about the way you have stored your distances that does not seem quite right? And maybe that is why you are tense because something needs fixing. So please take a moment here and think about what is this inequality really telling you.\nAlright, so hopefully it is fairly visible that what this inequality is telling you is that there is a better way to get to v compared to whatever option you had in mind when you stored the value ‘d.’ And that better option is to simply come to u first in whatever way that you were able to come to u with a total cost of t, and then jump across the edge from u to v with an additional cost of w. Even when you put those two together, you are still better off than d.\nNow, let me just quickly point out that because of the way this picture is drawn, you might be tempted to believe that this definition only makes sense when t and d are finite values and that we actually have these paths that we know something about. But this is just a limitation of the picture. The definition does make sense even when t or d, or both happen to be infinite.\nSo let us consider what happens if t is infinite. Well, that just means that we have no idea about how to get to the vertex u. So, if we do not know how to get to u, then we are not going to be able to leverage the edge from u to v to find a shorter path to v via u. So if you have a vertex for whom the distance value right now is ∞ (infinity), none of the edges that go out of that vertex will ever be tense because infinity is never less than anything.\nSo that is what happens if t is ∞. But on the other hand, if t is finite, but d is ∞, that means that we do not know, anything about how to get to v, but we do know something about how to get to u. So that means that the edge from u to v is going to be tense whenever d of v, the distance value of v is ∞.\nAnd in particular, if you think about what happens in the first step, notice that the distance of S is zero and everything else is ∞. So think about: What you can see about all the edges that are going out of S? Well, as you might guess, all of these edges are going to be tense.\nLet us consider an edge from S to v with a weight of w. Well, we know that t in this example, which is the distance from S to itself, is zero. So what we have is zero + w on the left-hand side and ∞ on the right-hand side. So this equation certainly holds. So at the very first step at the beginning, you definitely have as many tense edges, as there are out neighbors of the source vertex S.\n(Refer Slide Time: 06:58 & 07:12)\n \nNow, what do you do when you see a tense edge? Intuitively, you want to resolve this tension. And this process is typically called relaxation. So whenever you see a tense edge, you probably want to account for the information that you have and somehow fix the situation with the distance array.\nSo the process of relaxing an edge is exactly what you expect it to be. So let us go back to this picture of what a tense edge looks like and what we want to do is get rid of this old information that we have with regards to the distance of the vertex v. So d is clearly outdated, and we can do better.\nSo what we do is we update the value of the distance of v with d + w, which is, as of now, the better way to get to the vertex v. And if you want to maintain a predecessor pointer which tells you, well, what was the previous vertex on the shortest path, you could do that. And you could update that to being the vertex u for the vertex v.\nSo predecessor of v is going to be u because that is the last edge on the current best path that you are working with. So now that we know what a tense edge is and we understand the process of relaxing it, let us present an algorithm, which is based on performing this operation a number of times in a systematic way.\n(Refer Slide Time: 08:24)\n\nSo here is what we are going to do. We are going to identify the vertex that is closest to the source and notice that in the beginning, this is just going to be the source vertex itself. And what we want to do is extract this vertex, which is to say we want to ultimately get rid of this vertex. Just like we do with BFS, we look at the vertex which is at the head of the queue, we put it in the limelight for some time, we process all of its neighbors, all of its unvisited neighbors, and then we get rid of the vertex.\nSo we want to do something analogous here, but in a way that is sensitive to the information about the edge weights. So what we are going to do is pull out the vertex that is closest to the source, and we are going to go to all of its neighbors and if any of those incident edges are tense, then we are going to relax them, and then we throw away this vertex.\n(Refer Slide Time: 09:24)\n\nSo this method is at the heart of what is popularly known as Djikstra’s algorithm and let me just present this to you in a slightly more explicit fashion, and this is still going to be pseudocode. So what we have is the distance array, which to begin with has a zero value for the source and values initialize to infinity for all the other vertices. And what we want to do is insert all of these values into some sort of a priority queue or a heap, which is essentially a data structure that supports fast extraction of the minimum value.\nSo that is why we are interested in using a heap. It is just going to be efficient for the most frequently performed operation in this algorithm. So as long as we have elements left on the heap, what we want to do is extract the element that has the smallest value – the value being the distance from the source. And what we want to do is relax all the tense edges that are incident to the extracted vertex.\nSo recall that what the relaxation step entails is an update in the distance array. You want to make sure that the distance of v is updated to the distance of u + the weight of the edge from u to v, whenever this sum is better than the current value of the distance of v. And also, if you are maintaining a predecessor array then you want to update the predecessor of v so that it becomes the vertex u.\nSo this is what you do with all the tense edges. And remember that whenever you do the relaxation, you also want to remember to update the value of v in the priority queue as well. So that is the decrease key operation here. And this is essentially the whole algorithm.\nSo the idea is to constantly find vertices that are currently the closest to the source, and keep relaxing all the edges that are incident on them. And by the time you have processed all the vertices once your queue becomes empty, then you are pretty much done.\nNow, the interesting claim of course is that once you have finished, then the distance array is a true reflection of the actual shortest path distances from the source to the corresponding vertices. The intuition for this is that this algorithm explores the graph in the order in which the vertices are being extracted.\nSo it is a lot like BFS but somehow has been sensitized to account for the edge weights. And if at the point when a vertex is being extracted, this is not the best way to get to the vertex. The value of the distance of that vertex is worse than the cost of some shortest path to that vertex. Then assuming that you had done everything right up to the previous step, which is like an induction hypothesis, you could argue that the better part would have been a witness for actually being a reason to pull up this vertex even earlier.\nSo in some sense, the framework for how you prove the correctness of this algorithm is the structure of it is similar to how you work out the correctness for the BFS algorithm. But now, you have to carefully account for the way it is, and really the fact that there are no negative weight edges does play a role in the proof of correctness.\nSo just in case you have not seen this proof before, I would encourage you to either puzzle it out on your own based on what we have discussed so far or you could look up the references in the description of this video and read up on the proof of correctness if you are interested. So now let us switch gears a little bit and focus on some implementation issues.\nSo naturally, we want to store the values of the distances in our priority queue so that we can extract the minimum element efficiently, and that is something that we do often. So it makes sense to use a priority queue. Unfortunately, in C++, the built-in priority queue data structure does not have native support for updating key values.\nSo notice that you do have to decrease key values often whenever you are relaxing edges, and there is not a way to do this directly. You might of course say that, well, what about just inserting a new value for v with the updated distance and getting rid of the old one. Well, in a priority queue getting rid of a value is not as easily done.\nYou can get rid of the thing that has the minimum value but getting rid of an arbitrary value is harder. However, this idea of simulating an update by first deleting the element that you are working with, and then inserting the new value for that element – that makes sense, and it can be implemented with what is called a set. So let us review our options in the C ++ STL.\n(Refer Slide Time: 14:15)\n\nSo we have a priority queue or a heap, which is what we were originally proposing to use. And with a priority queue, you get a constant time lookup for the largest element, and you have logarithmic complexity. So this is logarithmic in the size of the collection for either deleting this largest element or for inserting a new element. Right. So that is what you get with a priority queue.\nOn the other hand, you also have the possibility of using a set, which basically will keep track of a sorted collection of items. So you can still have quick access to either the largest or the smallest elements depending on the order in which you set up your sorting, and on top of that, you can also search for elements and insert and remove elements with again a logarithmic expense. So that is comparable to a priority queue.\nSo what we are going to do is essentially use a set instead of a priority queue. By the way, I should mention that although I am quoting the C++ documentation here in saying that you can look up the largest element but even for a priority queue you can pass an additional parameter and change that from largest to smallest.\n(Refer Slide Time: 16:02)\n\nSo that is not really the problem. The issue with using a priority queue is the fact that you cannot update the values after you have inserted them, and you cannot remove an arbitrary value quickly. You can delete the extreme value, but you cannot delete an arbitrary value. So that is why we will be using a set instead of a priority queue. So let us look at what that looks like.\nSo we are going to basically split this decrease key operation into two steps. So first delete the old value, and then insert the appropriate new distance that is going to be the distance of u + the weight of the edge from u to v. So hopefully that makes sense. And notice that extract min is also easy to simulate because the collection is sorted when you use a set, you can just access the first element and that is the one to remove.\n(Refer Slide Time: 17:00 & 17:30)\n \nSo you can also invoke the remove operation which is a part of the set interface on just the first element. So that is very much doable. So this brings us to the end of the description of what Djikstra’s algorithm does and I am going to wrap this discussion up by claiming that the algorithm works correctly when all edge weights are non-negative.\nI am going to state this without proof, but I would encourage you to try and come up with examples that break this algorithm when there are negative edge weights involved. So try to see if you can figure out where exactly the algorithm breaks down.\nSo now that you know the mechanics of what Djikstra’s algorithm does, there are a few things that you can do from here. The first is to play around with some examples, especially if you are seeing this algorithm for the first time, I think it is really helpful to build up your intuition by just working through a few examples simulating what the algorithm would do, and so on.\nSo for instance, on visualgo dot net, there is an entire module dedicated to SSSP algorithms, and you can see that they have both Djikstra and modified Djikstra featured here. So we will be discussing this modification to Djikstra’s algorithm in the last segment of this module. But in the meantime, you could just go ahead and play around with the original version, which is exactly what we have discussed so far. You can work with the prebuilt examples or you could generate your own. So feel free to have some fun doing this.\n(Refer Slide Time: 18:20)\n\nThe other thing is that you might be curious about the proof of the claim that we made about correctness. So we will not really have the time to get into this in these videos. But if you are curious, then I have a few pointers in the description of this video. You could either read up on the proof or watch some other videos to figure out what is going on.\nIf you do this then try and watch out for what part of the argument really uses the assumption about non-negative edge weights. It does come into play in a very specific part of most arguments. So it is interesting to try and identify why this assumption is so important to the correctness of the algorithm. The third thing, of course, is the implementation.\nSo that is what we are going to do in the next segment in the context of a problem. So you could just continue this conversation with me by switching over to the next segment, and we will be solving a problem, and implementing Djikstra’s algorithm at the same time. So I will see you there. And good luck, exploring various facets of this very interesting algorithm!"
  },
  {
    "objectID": "materials/cpnotes/W06/Lec31.html",
    "href": "materials/cpnotes/W06/Lec31.html",
    "title": "M 1 (Dijkstra’s Algorithm-Sending Email)",
    "section": "",
    "text": "Lecture - 31\nShortest Paths - Module 1 (Dijkstra’s Algorithm-Sending Email)\n(Refer Slide Time: 00:11)\n\nAlright, welcome back to the third segment of the first module in week six where we are talking about the ‘shortest paths’ problem. And in particular, we have been focused on the single-source shortest path problem. And so far in the first two segments, we have discussed the case when all the edge weights are uniform or the edge weights are one.\nThat is essentially the same as working with an unweighted graph. And here we said that the BFS algorithm, which we saw in fact last week, will do the job for you. And then, in the previous segment, we tackled this more general case when you could have arbitrary edge weights but they are all guaranteed to be non-negative.\n(Refer Slide Time: 00:55)\n\nAnd in this case, we said that we could use Dijkstra’s algorithm to solve the problem. And we made a small note about the implementation, where we said that, well, it is natural for the functioning of Dijkstra’s algorithm to use a priority queue to keep track of the values of the distances. But unfortunately, the C++ implementation of ‘priority queue’ does not give you access to a method that can modify the values that have already been entered into the priority queue.\nSo we said that we will, you know, basically simulate the change in key-value operation by simply deleting the value and replacing it with the new value and this is also a bit tricky to do directly within a priority queue. So we are going to be using the set data structure to do this instead.\nAnd this works also I believe in Java. But in Python, well, we do not really have an implementation of set that is internally based on balanced BSTs, which is what C++ uses to give you data structure that can maintain a sorted collection with insertion removal, lookups, or searches costing you only logarithmic time.\n(Refer Slide Time: 02:19)\n\nSo if you are a Python user then, well, you could experiment with using the built-in priority queue data structure. And if you look at the documentation for heaps in Python, you will see that there is some guidance on how to update key values but the idea seems to be very similar to what we have already discussed in the sense that whenever they want to update a particular key value, they would essentially mark it as being removed and they would insert the new value for that key.\nAnd then throughout your implementation, you have to just remember to check for whether an element has been marked as removed or not to be sure about whether it is a real element in the priority queue or not. So you could experiment with this, or you could just wait till the next segment where we talk about modified Dijkstra’s algorithm, where you could actually directly use a priority queue and it will not be a problem because we will never really have to actually decrease the key value.\nWe can do all of our work by simply inserting new values, and everything else will take care of itself. So you could wait till we discuss that. The only caveat is that in general, the modified version has a slightly worse complexity, especially in the worst case. But in practice, it tends to work out just fine.\nSo if you are a Python user then you could do one of two things. Either just stick to using the modified version where you will never have to do key updates. Or, you could use the original version and you could try and see if you can simulate updates with deletions using the method that has been described in the documentation.\nAt the time of this recording, the official repository only has the C++ version for the original Dijkstra’s algorithm. But I am optimistic that we might see some community contributions going forward. And if you just wait for a while, perhaps you will be able to also look at Python variants, which work just as well.\n(Refer Slide Time: 04:24 & 05:17)\n \nSo with all that said, let us move on to a discussion of our first problem this week, which will give us a backdrop in which we can implement and test Dijkstra’s algorithm. So this problem is called ‘Sending Email.’ It is on the UVA platform and the problem statement basically goes like this. We are given that there are ‘n’ SMTP servers connected by network cables.\nThis already screams for a graph formulation. So it seems like our servers should be vertices, and the cables should probably be edges. Indeed, each of the ‘m’ cables connects to computers and it has a certain latency measured in milliseconds, which is required to send an email message, presumably between the two servers that are connected by that cable.\nSo by now, we are even more confident that this looks like it is something that should be modeled using a graph. What is not clear at this stage is whether there should be a directed or an undirected graph. So we will get to that in a bit. But for now, let is go ahead and look at the task at hand. So the question is the following.\nWhat is the shortest time required to send a message from a server S to a server T along a sequence of cables? We are also told that we can assume that there is no delay incurred at the servers, which is to say that when an email arrives at a server, it can be instantly relayed to any other server that is directly connected to it via a cable.\n(Refer Slide Time: 05:59 & 06:03)\n \nSo from this description, I think it is fairly transparent that what we are looking for is a minimum weight path between S and T. And everything that we have learned so far with regards to Dijkstra’s algorithm for instance should be applicable here.\nWe could think of these latencies as the edge weights. And if you take a quick look at the constraints, the number of edges and the number of vertices are in the 10,000s. The edge weights, also range from zero to 10,000, and in particular, this means that we do not have any negative weights to worry about. So in terms of correctness, we are definitely in the clear.\nWe could apply the original version of Dijkstra’s algorithm, the one that we have discussed so far, and be assured that that is the safe thing to do. It will produce the right answer in such instances.\n(Refer Slide Time: 06:46)\n\nBut now, we also have to think about the complexity and for this, we have to understand the worst-case running time of Dijkstra’s algorithm. To do that, let is go back and look at what Dijkstra’s algorithm is actually doing. The two operations that have been highlighted here in the pseudocode are operations whose complexities will depend on the choice of the underlying data structure.\nAs we have discussed, if you were to use a heap or a priority queue, it is possible to implement both of these operations with a cost that is in the worst-case logarithmic in the size of the collection. But because the C++ STL does not provide a decreased key interface to its priority queue implementation, we said that we could also implement these operations using a set, in which case you get a similar guarantee.\nSo the worst-case complexity of running each of the ExtractMin and DecreaseKey operations can be assumed to be logarithmic in the size of the collection. Because the size of the connection is never more than the number of vertices, we see that these operations have a cost of order log n. So the only question that remains is how many times are these operations executed. Note that every vertex is extracted at most once.\nIn particular, if a vertex is reachable from the source, then it is extracted exactly once. And if it is not reachable from the source, then it is not extracted at all. Similarly, every edge is relaxed at most once. Every edge is considered for relaxation exactly once. But depending on how the numbers are, it may or may not actually be up for relaxation. But if it does get relaxed, that is when the DecreaseKey operation is invoked. And this happens at most once for every edge.\nSo if you just look at the algorithm in an overall way, you will see that the total complexity is m + n * log n because that is the product of the number of times that the operations are involved, and the cost of the operations themselves. Since m dominates n asymptotically, this can be simplified to just saying, order m log n. So if you go back and look at the constraints again because m and n are both in the order of 10,000, so you will see that this complexity breaks out just fine for this problem.\nThe one bit of detail that remains to be understood is if the edges that have been given to us are directed or not. Oddly enough, this is not specified in the problem statement, but if you carefully read the section where there is a description of how the input is given to us, you will notice this phrase which says that ‘the servers are connected by bidirectional cables.’\nSo from this, we realize that the edges are, in fact, undirected. And although all of our discussion about Dijkstra’s algorithm has been in the context of directed graphs, it turns out that when you do not have negative edge weights to worry about everything works exactly the same way. You just have to be careful when you take in your input to make sure that you record all of the edges as bidirectional or undirected edges.\n(Refer Slide Time: 09:51)\n\nNow, as is our tradition before we solve the problem, let us just work through an example. And here is an example from the sample input-output for this problem. The way it is formatted, there are multiple test cases one after the other. So I think I have picked the second one here, and the way the test cases are formatted, the first line gives you four numbers representing the number of vertices, the number of edges, and the IDs of the vertices S and T.\nThe vertices are labeled from zero through n-1. And here you can see that there are three vertices, three edges, and you want the distance between the first and the last vertex, the vertex that have IDs zero and two. The next m lines – in this case, of course, there are three edges so there are three lines – the next m lines give you the pairs of vertices corresponding to the ‘m’ edges.\nAnd the last number gives you the weight of that edge and in this case, it is the latency across that cable. So, if you were to draw a picture corresponding to this graph, this is what it would look like, and you are trying to find the distance between zero and two.\nNotice that the direct edge between zero and two has a cost of 200, and the only other option that you have is to go via the server that is labeled one. The total cost of doing that is 100 + 50. It should be reasonably clear that this is the better option and the answer that you are expected to output in this case is going to be 150.\nYou could try and play around with a few other examples but they will be exactly the same as any genetic shortest path instance. So feel free to take a break and consider doing that. And if you would like to give this a stab yourself, by all means, this is the time to do it, because the next thing that we are going to do is actually take a look at the implementation.\nSo we will be working here with an adjacency list representation and our code will be in C++. If you need a reminder of how the adjacency list representation works, then you can find that in our discussions from the previous week.\n(Refer Slide Time: 11:50 & 12:24)\n \nSo let us get started by leading the input in. Most of this is fairly standard stuff. But let me just note that because the edges are undirected, we want to make sure that we add V as a neighbor of U, and U as a neighbor of V. So that is why you will see that we are adding elements to two adjacency lists when we read in a single edge.\nSo this was just taking the input in and, you know, building up the graph. And now, let is get to the implementation of Dijkstra’s algorithm. Let us begin with the initialization. So we have this distance array, which if you remember the way we wanted to initialize that, was to say that, to begin with, we know that the distance from the source to itself is zero, and everything else is initialized to some very large numbers.\nSo we have this constant here, in short for infinity, which is defined to be a suitably large number. And the distance array of course is length ‘n,’ ‘n’ being the number of vertices. And the source vertex here, which is S, in this case, is the S that was given to us in the first line of the input. So we remember to set that to zero. Remember we are looking for the shortest path from S to T, or between S and T.\nAfter this, the next thing that we want to do is make sure that these V and distance V pairs are loaded into a priority queue. But again as we have discussed, instead of the built-in priority queue, we will be working with sets. So we have initialized a set, which we will call PQ. And what we want to do now, is just insert the V and distance V pairs, into this set.\n(Refer Slide Time: 13:24 & 14:08)\n \nSo that is exactly what is happening in these next two lines and remember that the way the set data structure works, it automatically sorts these pairs in the order of non-decreasing distances from S. Of course, to begin with, all this means is that as comma zero is going to be the first element and the others are all tied so, at the moment, there is going to be no special ordering on them.\nBut as we go along, the set will maintain its sortedness and you can always access the minimum element by trying to pull out the first element in the set and that is going to work.\nSo now that all the initializations are out of the way, let us get to the main body of the algorithm. Remember that this was the pseudocode that we had discussed some time ago, and now, this is what we want to translate into operational code. So the outer while loop just says: continue doing this for as long as you still have elements left in your set.\nSo that is just a non-emptiness check that we want to do at the outset. But inside this loop, the first thing that we want to do is extract the minimum element, which is to say we want to identify the element that is closest to the source that has the smallest value of distance. And then we want to remove this element from the set. So here are a couple of lines of code that do just that.\nIn the first step, we are identifying the smallest element. Remember that ‘set’ stores elements in sorted order. So in this case, this is just going to be the first element. And having identified this element and committed it to the variables D and U, D denoting the distance, and U denoting the vertex, we now want to make sure that we remove this element from the set. So that is what the ‘erase’ directive in the next line is doing for us here.\nSo this completes the implementation of the ExtractMin operation. And now, we want to run through all the edges that are incident to the vertex U. This is just a simple matter of going through all the vertices V in the adjacency list of U. And remember that the way we have set up the adjacency list: every vertex that is adjacent to U also comes tagged with the weight of the edge from U to V.\nSo here, V denotes the neighbor and W denotes the weight of the edge from U to V. So that is the for loop that we have going on here. Now, remember that for each of these edges that are going out of U, we want to consider if these edges need to be relaxed. So to implement the ‘if’ condition here, let us just recall what it means for an edge to be tense.\nSo an edge from U to V is tense if the method of getting to V via U is better than whatever method we have currently as given by the distance array. So in particular, if the distance of U + W, W being the weight of the edge from U to V, is smaller than the distance of V, then the edge is tense, and it needs to be relaxed. And on the other hand, if the distance of U + W is at least the distance of V then nothing needs to be done.\nSo that is the next ‘if’ statement here. It basically says that if this edge is not tense then you can move along, there is nothing to be done. But on the other hand, if the edge is tense, then we need to relax it, which is to say that we need to update the distance array with the new value of the distance, which is the distance of U + W. And we also need to update the priority queue pair accordingly.\nAnd since we are doing this with a set, we had agreed that we will simulate this decrease in the key-value with a ‘deletion’ and an ‘insertion.’ So the next few lines of code do exactly that. So first of all we remove the old value V, the distance of V. We update the distance array so that it now has the new value for the distance of V. And finally, we reinsert the new V and distance of V. So that is what is going on here. And this completes the implementation of the algorithm that we had discussed.\nOne useful addition here is to maintain a predecessor array, which gives you information about the penultimate vertex on the shortest path. It tells you where did you come from, to get to this optimal path. If you did have an explicit predecessor array, then this would be the point where you would set the predecessor of V to being U.\n(Refer Slide Time: 18:08 & 18:56)\n \nFor this problem, however, this is not really required because all you need to do is output the length of the shortest path. So let us go ahead and take a look at how we do that. This output is actually pretty straightforward. You just need to look up the value of the distance of T, which is the server that you wanted to reach.\nThe only thing to remember to do is to make sure that you have a check for unreachability because your output is going to be slightly different if T is completely unreachable from S, which is possible. That could happen. There is no promise that the graph is connected, to begin with, and so on. So making that distinction here is the only little detail to keep in mind.\nAnd with that, we are pretty much done here. Let me just make a quick follow-up comment about the detail of adding predecessor information. So if you want to test out Dijkstra in a setting where you have to also print the shortest path that you have found, then you could take a look at this problem on Codeforces, which asks you to do exactly that.\nI think this is a nice problem to again try out on your own based on the code that you have seen so far. But just for the sake of completeness, let me show you how you would print the path if you had maintained some sort of a predecessor array.\n(Refer Slide Time: 19:15)\n\nSo here is just a bit about the output. Once again, just like before, we want to distinguish the situation where the vertex is completely unreachable. In that case, you just print, for this problem, for instance, you just want to print a minus one. But if the vertex is reachable then what you want to do is basically keep moving along the predecessor array until you reach the source.\nSo in particular, in this problem, we have been asked to find the shortest path between the vertices labeled 1 and n. So one is our source vertex and n is the target or the destination vertex. So let us begin by setting a current variable to the vertex n. And now, we just keep moving along the predecessors as described. And as we do that, we want to just track the variables that we encounter, through this journey through the predecessor array. So we have a separate vector called path which will let us do that.\nSo as long as the current variable does not achieve the value one, which is an indication that you have in fact reached the source and that is your exit criteria from this while loop, as long as that does not happen just reset the current vertex to being the predecessor of whatever the current vertex was. And remember to just store the value of the predecessor that you encounter in the path array.\nSo this way the path array gets populated with all the vertices that you encounter in your journey from n to 1. And now, depending on whether the order matters or not, I think for this problem perhaps the order does matter and you want the path to be from 1 to n. So because of the way you have pushed the predecessor vertices that you encountered, you are kind of going backward. So you want to remember to reverse the path array so that you can print the vertices in the order in which they appear on the path from one to n.\nSo that is what is happening here. So I think this is a nice and simple way of just keeping track of an actual path. And whenever you need to do that, you can see that is quite easily doable just by tracking predecessor information as you run Dijkstra’s algorithm.\nSo do remember to also make the modification in the code that we saw for Dijkstra’s algorithm. Whenever you relax an edge from U to V, remember to set the predecessor of V = U. As always, you can find the complete code from which these snippets are being shared in this video on the official repository, a link to which you should find in the description of this video.\nSo with that, we come to the implementation of the original version of Dijkstra’s algorithm. And in the final segment for this module, we will talk about how negative edges impact this algorithm, and what can we do to fix it. So that is going to be a small modification to Dijkstra’s algorithm. And I will see you in the next segment for that discussion!"
  },
  {
    "objectID": "materials/cpnotes/W06/Lec35.html",
    "href": "materials/cpnotes/W06/Lec35.html",
    "title": "M 3 (APSP [Floyd-Warshall] | Page Hopping)",
    "section": "",
    "text": "Lecture - 35\nShortest Paths - Module 3 (APSP [Floyd-Warshall] | Page Hopping)\nWelcome to the third and the final module of the sixth week in Getting Started with Competitive Programming. So, far in this week, we have focused completely on the single-source shortest path problem in various scenarios ranging from unweighted graphs all the way to general edge rates, both positive, negative, and even the presence of negative cycles.\nNow in this final module, I want to introduce you to a different variant of the shortest path problem, called the All Pairs Shortest Path Problem, or APSP, for short. And we are going to see an algorithm for this, that popularly goes by the name Floyd Warshall. And are we going to implement this in the context of a problem called ‘page hopping,’ which appeared in the ICPC world finals way back in 2000!\n(Refer Slide Time: 01:05)\n\n \n \n\nSo, let us get started with the problem itself. So, we are trying to tackle all-pairs shortest paths. As usual, will assume that we are working with a directed and a weighted graph. And our goal, in this case, is to compute the shortest paths between every pair of vertices. Now, having worked so much on SSSP, which is ‘single-source shortest path,’ I think a very natural reaction is to say, well, what is the big deal? We just run SSSP from every vertex, and this way, we will end up calculating the length of the shortest paths between any pair of vertices. And that would be absolutely correct. Let us take a look at the SSSP algorithms that we have seen so far.\nAnd let us try to understand: What would be the running time of the APSP algorithm if we were to simply run these SSSP algorithms ‘n’ times? So, as you might guess, to obtain these running times, we simply have to add a multiplicative factor of n to the existing running times to account for this outer for loop, that is going to run n times.\nNow, let us consider these running times for the case when the number of edges is as bad as it can be. And let us say that it is a dense graph, the number of edges is roughly n squared. In that case, these running times end up looking like this. And you can see that it is only the case when we have no weights at all, that we get an n3 running time, which is what we obtained by running BFS n times.\nBut in everything else, we have something that is worse than n cubed. So, a natural question is if we can do all-pairs shortest paths in order n cubed time without having to worry about the extra log n factor in the case of Dijkstra or the extra factor of n that comes in, in Bellman-Ford. So, perhaps we can just try to figure this out.\nFor non-negative edge weights, just getting an improvement over Dijkstra, I think that would be pretty nice. And in fact, what we are going to see, well, we will describe it in the context of graphs that do not have negative edge weights. But you can adapt it. And I think it is a good exercise to do that, to also account for negative weight cycles. So let us go ahead and take a look at what the algorithm does.\nSo, as always, I will describe the mechanics of the algorithm without giving you formal proof of correctness. But hopefully, there will be enough intuition for it to be clear as to why you might expect it to work. And, as always, in case you have not seen this algorithm or its proof of correctness before, but you are curious, you can always look up the references given in the description of this video to find out more. Okay. So, in this algorithm, what we are going to do is, again, work in phases, much like Bellman-Ford.\n(Refer Slide Time: 04:05 & 05:44)\n \nSo, we are going to go through n phases, and at the end of the ’r’th phase, what are we hoping to do? We are hoping to track the cost of the shortest path from u to v that uses vertices that are numbered, at most r. So let us imagine that our vertices are labeled from 1 to n. And, in the ’r’th step, I am restricting you to only use vertices that are labeled with a number that is r or less. Now, notice that when r = n, this means that any vertex is fair game because all vertex labels are at most n any way. So, if you are able to figure out the values of P(u,v,r) correctly for every pair u v and for every value of r, then at the very end what we have is exactly what we are looking for.\nNow you might ask: Why are we slicing this in terms of these r’s? And this, basically, is a fundamental idea, which is to break down what you ultimately want into smaller digestible chunks. And we will see a lot more of this flavor of algorithm play out in the last three weeks of the scores when we work with the concept of dynamic programming.\nHowever, if you have not worked with dynamic programming-based algorithms before, do not worry about it. This description is going to be fairly self-contained. And you are going to feel right at home, as long as you have seen recursion, which you already have, even in the context of this course. So, I think this should be pretty easy to follow along with.\nSo, let us use the distance array to keep track of the costs of these paths that we have defined here. So, in particular, the distance u v r value is going to reflect the cost of the path that goes from u to v using vertices that are labeled at most r. And such paths may not even exist. In that case, these distance values are to be interpreted as being infinity.\nAnd in your code, that is just going to be a very large number. Okay. So, let us think about how do we compute these values? Well, one easy case is when r = 0. Can you think about what the value of distance u v 0 should be, given that vertices are labeled from 1 to n? Alright. So, if vertices are labeled from 1 to n, then we are saying: compute the length of the shortest path from u to v, which passes only through vertices numbered at most 0.\nNow there are no vertices numbered at most 0. So, this is just a twisted way of saying that you are not allowed to use any intermediate vertices. And notice that the only parts that do not use intermediate vertices are the direct edges. So, the distance of u v 0 is going to be the weight of the edge from u to v, if such an edge is available. And if such an edge is not available, then this distance just remains infinity.\nSo, that is what we have in what do you might think of as some sort of a base case for this recursion. Okay. So, we figured out what to do if r = 0. Now let us think about what should happen in a more general setting.\n(Refer Slide Time: 07:29)\n \nSo, here are the vertices u and v. And we are trying to figure out the value for distance u v r. Now, just like we do in an inductive proof, we are going to assume that we already have figured out the values of distance u v r prime, for r prime strictly < r. We can assume that this is true because, well, in general, we have figured it out for r = 0.\nAnd we are going to build our way upwards, step by step. So, if I tell you how to compute distance u v r, provided you already know distance u v r prime, for r prime < r, then you can use this mechanism to go from distance u v 0 to distance u v 1, and from distance u v 1 to distance u v 2, and so on all the way till the end.\nSo, just like we do in a proof by induction, my focus here will be on trying to explain how we compute distance u v r under the assumption that you already know the correct values for distance u v r prime, for r prime < r. So, hopefully, that makes sense. And now let us come back to the question that we were posing earlier.\nHow do we compute distance u v r? Well, we are trying to figure out what is the best path from u to v that uses vertices that are labeled at most r if such a path exists. Now, if such a path exists, there could be two possible scenarios. The first is that it uses the vertex labeled r. And the other is that it does not use the vertex label r.\nWell, if it does not use the vertex label r, and originally, all of the vertices on this path were supposed to have labels at most r, given that we are not using the vertex r, this path must in fact be a path where all the vertex labels are at most r-1. So, in this case, what can we say? Take a moment here and think about how you would compute distance u v r, if I told you that P(u,v,r), in fact, happens to not need the vertex labeled r. Okay. So, in this situation, P(u,v,r) is going to in fact be the same as P(u,v,r-1), because this path simply does not make use of the vertex r.\nSo, r best bet is to just borrow the knowledge that we have from the ’r-1’th phase. So, this is the best that we can do, if we assume that this path from u to v in the ’r’th phase, in fact, happens to not need the vertex labeled r.\n(Refer Slide Time: 10:19)\n\nOn the other hand, it could be that this part uses the vertex label r. In this case, what can we say? Can we somehow use the information that we have already computed to figure out the cost of this path? Remember that the vertex r has already been used. So, the question is what can we say about the paths that go from u to r and from r to v. Just think about breaking it down in that way.\nAnd, you know, take a pause, think about this and come back when you are ready. So, as I was hinting earlier, let us try and think about the path from u to r, and the path from r to v. What can we say about these paths? Well, we have assumed non-negative edge weights. So, we know that our shortest paths, the optimal ones, are also simple paths. So they are not going to really repeat any vertices. And in particular, they are not going to repeat the vertex r.\nSo, we know that the blue and the pink sub-paths – excluding the end vertices, which are u and r and r and v respectively – these paths only use vertices labeled at most r-1 as the intermediate nodes. For this reason, we know that the length or the costs of these paths respectively is given by values that we have already computed, namely, P(u,r,r-1), and P(r,v,r-1). So, we simply sum these two values to get to the cost of the path from u to v.\nNow, you might say that each of these two cases makes sense individually. But how do we figure out which case we are in? What do we know about the best part in the ’r’th phase, we do not really know if it uses the vertex r or not. Well, we do not know this. But we can anticipate this by pretending that we are in one case or the other. And trying to figure out the values that we just calculated here, comparing the two and taking the minimum. That will give us the right answer at the end of the ’r’th phase.\n(Refer Slide Time: 12:35)\n\nSo, let us summarize whatever we have said with this our case analysis. So, we are trying to figure out the distance value for u v r, and the first thing that we said was the base case. So, we said that if r is equal to 0, this is the weight of the edge from u to v. And this is written succinctly. It is to be interpreted as the weight of this edge if it exists, and infinity otherwise.\nNow in the next generic step, what we want to do is to compare these two situations. The first is when the path from u to v, the optimal path, which is supposed to restrict itself to labels at most r, happens to not care for the vertex labeled r. In this case, the answer is going to simply be the distance of u v r-1. But on the other hand, suppose it does use the vertex r, then you can split this path into two sub-paths – the one that goes from u to r, and the other that goes from r to v. And other costs of these paths, notice that they are only going to use vertices whose labels at most r-1 because as we just discussed, vertices are not going to repeat because we do not have negative edge weights so all optimal paths are simple.\nSo, just combining the weights of these two sub-paths, we have this expression here. Now, as we said a moment ago, we do not know which of these two cases we are in, so we just compare the values and take the minimum of the two knowing that is the best that we could have hoped for at this stage.\nNow, this calculation here translates beautifully into just four lines of code. You essentially have three nested loops. The outermost loop essentially goes through all of these phases r, and the two inner loops essentially work through u,v pairs. Now inside these nested loops, you have one line computation that simply handles the update for u v r. And at that point, you are done. So, we are going to look at this implementation but in the context of the page hopping problem, and I am going to take that to the next segment. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/W06/Lec34.html",
    "href": "materials/cpnotes/W06/Lec34.html",
    "title": "M 2 (Wormholes [Bellman-Ford | Negative",
    "section": "",
    "text": "Lecture - 34\nShortest Paths - Module 2 (Wormholes [Bellman-Ford | Negative Cycles])\nWelcome back to the second segment of the second module in the sixth week on shortest paths. So, what we have discussed so far in the previous segment is a method to deal with the most general situation when it comes to edge weights, where we even allowed for the presence of negative cycles.\nAnd the way things work here is that our obligation is to only detect a negative cycle if it exists because, in such a situation, the very notion of shortest paths becomes ill-defined anyway. And in the absence of negative cycles, we are supposed to return the shortest path information, as is usual. So, we saw how to do this using what is popularly known as the Bellman-Ford Algorithm.\nAnd essentially, this involves ‘n-1’ iterations of relaxing every tense edge. And at the very end, we simply check if there are any tense edges that still remain. And if they do, then that is a sure sign of the presence of a negative cycle, and we return as much. But otherwise, we would have, by then, correctly computed all the shortest path distances from the source.\nSo that is what I wanted to say by way of recap. If all of this went by too fast, chances are that is because you have not had a chance to go through the first segment of this module. So, please make sure to do that. Because here what we are going to do is implement whatever we have learned so far. And we are going to do that in the context of this problem called ‘wormholes.’ As usual, you can find a link to the problem statement in the description of this video. And let me begin by telling you about the problem.\n(Refer Slide Time: 02:02)\n\nSo, we are told that in the year 2163, which is when wormholes were discovered. A wormhole is a subspace tunnel through space and time connecting two star systems. And wormholes have a few peculiar properties. Now, you can probably already guess, given the context in which I am presenting this problem that we want to think about star systems as the vertices of some graph and a wormhole as an edge that connects them.\nSo, let us just keep that at the back of our minds, and then continue with the story here. Now, I should mention that in the original problem, these properties are given as a list. And I have taken the liberty of rearranging the items on the list in a way that the sequence is just more convenient for me to share with you; your experience may be slightly different if you are reading the problem statement directly.\n(Refer Slide Time: 2:59 & 03:19)\n \nAlright. So, the first thing that I want to tell you is that a wormhole has two endpoints, each situated in a star system. This sounds very convenient. And it confirms our earlier suspicion that we want to model wormholes as edges and star systems as vertices in some sort of a graph abstraction.\nAlright. The next thing we are told is that the wormholes are one way only. This also has a fairly natural interpretation in the language of graphs. We want to say here that our edges are directed.\n(Refer Slide Time: 03:31 & 04:22)\n \nNow the next thing that we have is the following. The time that it takes to travel through a wormhole is negligible. Now, wait a minute. This does sound a little bit funny. Because we are thinking of wormholes as edges, this is making it sound like we do not have any natural concept of edge weight.\nRemember, when we were working with the email problem, the cables that connected to servers had some latency going on. So, that was a natural notion of edge weight. But here, it seems like we are getting travel time through the wormhole for free. So, that does make you wonder: So, maybe edge weights are coming up in some other form that we have to watch out for – So, let us just keep this in mind that the wormhole travel comes for free, at least in terms of time.\nNow, we are told that a star system may have more than one wormhole endpoint within its boundaries. This just means that our vertices may have in-out degrees that are possibly greater than one. That is what it would mean for a single star system to accommodate more than one wormhole endpoint. So, this is perfectly fine.\n(Refer Slide Time: 4:44 & 05:13)\n \nThe next thing that we are told is that for some unknown reason, starting from our solar system, it is always possible to end up in any star system by following a sequence of wormholes. So, this means that there is a path starting from a particular vertex in a graph, the one that corresponds to our solar system to any other vertex in the graph. So, this is some sort of reachability promise in the graph structure.\nNext, we are told that between any pair of star systems there is at most one wormhole in either direction. So, this is essentially an assurance that there are no multiple edges. And there even are not any directed cycles of length. So, you cannot go and immediately come back. So, this is just that there are no multi edges.\n(Refer Slide Time: 5:37 & 06:05)\n \nThe next thing is that there are no wormholes with both endpoints in the same star system. Again, in the language of graphs, this simply means that there are no self-loops. And combined with the previous fact, what we have is that we are working with a simple graph here. So, far, so good. There does not seem to be a whole lot of drama. Everything seems to fall in place nicely with our anticipated graph model.\nLet us look at the next property. So, we are also told that all wormholes have a constant time difference between their endpoints. Let us elaborate on this a little bit further because this is now beginning to sound possibly a bit confusing.\n(Refer Slide Time: 6:20)\n \nSo, here are a couple of examples to illustrate what the previous property might mean. So, a specific wormhole may cause the person traveling through it to end up 15 years in the future. And another wormhole may cause the person to end up 42 years in the past. Okay. So, this could happen. And perhaps this is our first indication of some sort of edge weight concept. Maybe the weights have to somehow reflect these time differences.\nBut how exactly do we specify the weights? And to what end? Well, only time will tell I guess because we still have to figure out what our task is going to be. What are we supposed to do with all of this information about star systems and wormholes, and what not?\n(Refer Slide Time: 07:11 & 07:55)\n \nSo, what we are told next is that we have a brilliant physicist living on earth, who wants to use wormholes to study the Big Bang. Now, that does sound pretty ambitious. Let us look at what else we have in store. So, we are told that advanced means of transportation have not been invented yet. So, you cannot simply go from any star system to any other star system directly. But you can use these wormholes to find your way around.\nAnd this of course falls in line nicely with all the graph modeling that we have been doing in parallel. So, transportation between star systems seems to manifest naturally as paths in our graph. But with all that said, we still do not know what we are looking for. So, let us continue reading the problem statement here.\nSo, we are told that our scientist friend wants to reach a cycle of wormholes somewhere in the universe that causes her to end up in the past. And we are also told why this is of interest to her. Because once she finds such a cycle of wormholes, then she can keep going round and round around that cycle. And that will keep taking her back further and further in the past.\nAnd hopefully, ultimately, at some point, she will be so far back in the past that she would be witnessing the Big Bang, and that would presumably allow her to study it. Or so the story goes. So, that is what we are looking for. We are looking for a cycle of wormholes, that takes our scientist friend back in the past.\nNow, intuitively by now, this is probably ringing some bells. And perhaps, well, since we are told that we are looking for the cycle of wormholes, it is probably not very farfetched to imagine that we are looking for a cycle in our graph. And since we are told that this cycle of wormholes must have this property, that it takes the scientists back in the past, we probably want to imagine that this cycle is some sort of a negative weight cycle.\nBut for that to actually happen, we need to figure out how exactly we want to model our edge weights. So, this would be a good time to pause and think about how would you ascribe weights to the edges so that a cycle of wormholes that takes the scientist back in the past will correspond to a negative weight cycle in the graph that we have built up so far? Take a moment and come back once you are ready.\nSo, I think a fairly natural thing to do is to use the time difference as the edge weight. So, let us say that we have a wormhole that takes somebody ‘x’ years into the future, then we might want to associate a weight of x with the edge that represents this wormhole. Similarly, if we have a wormhole that takes somebody ‘x’ years in the past, then the edge corresponding to this wormhole should have a weight of -x to signify that you are moving backward in the passage of time.\nSo, now notice that if you just add up the edge weights of any sequence of wormholes, then that sum total will reflect the total amount of time travel that you have done if you were to actually embark on a journey that involves this particular sequence of wormholes. And in particular, you can check that a wormhole cycle that takes somebody in the past is going to be a negative weight cycle if we were to use these edge weights.\nSo, we know that with the appropriate graph model, this problem essentially boils down to the issue of detecting whether we have a negative weight cycle in our graph or not. And remember that Bellman-Ford is designed for precisely this purpose. So, we should be able to solve this by simply implementing Bellman-Ford. Before we do that, though, let us just do a quick sanity check on the constraints to be sure that we will be safely within the time limits.\n(Refer Slide Time: 11:11)\n\nSo, of course, the problem statement concludes by asking us to write a program to determine if we have a cycle of wormholes that takes our scientist friend back in the past. And we are also given that the number of star systems and the number of wormholes is at most 2000 each. This means that the product of the number of vertices and edges in our graph is of the order of 4 * 106, which means that we should be pretty safe in trying to implement Bellman-Ford for this problem. So, let us go ahead and take a look at the code.\n(Refer Slide Time: 11:47)\n \nTo begin with, I am going to implement this as an edge list, again, just for convenience because the inner loop in the Bellman-Ford Algorithm just goes over all the edges. So, having all the edges in a list, I felt was a fairly natural way to do things. But you can do this equally using adjacency lists, or even adjacency matrices.\nThe only thing to remember when you are working with adjacency matrices is that the inner loop where you go over all edges will essentially require a scan of the entire matrix. So, the running time of Bellman-Ford becomes order n3 when you are working with an adjacency matrix representation. So, in general, it would be better to stick to an adjacency list or an edge list representation.\nBut if you need to use an adjacency matrix for some other reason, just be mindful of the fact that the worst-case running time would be given by order n cubed. Okay. So, this is just a fairly standard reading-in of the input, let us just move along and talk about how we would present the output, assuming that we have written a function called Bellman-Ford, which returns one if there were no negative cycles, and it returns 0 otherwise.\nSo, here we are simply reporting our outcomes based on what Bellman-Ford tells us. Remember that we invoke the Bellman-Ford function with information about the source vertex, which in this case is the vertex that represents the solar system because that is where we are starting out. Let us move along and talk about how we implement Bellman-Ford.\n(Refer Slide Time: 13:26)\n \nHere is the Bellman-Ford function, which, again, takes just the identity of the source vertices on the parameter. The remaining variables that have the information about the graph are global anyway so that the function can freely access it. So, this is simply the initialization as always, we have a distance array, which is initialized so that every value is some very large number, which is identified by this constant INF.\nBut we always remember to initialize the distance of the source to 0. And here you could also say that the predecessor of the source is the source vertex itself. We are maintaining a predecessor array here, although we do not really need it for this problem.\nIt is very similar in behavior to Dijkstra in the sense that the predecessor array will allow you to go back and retrace a path in case you need to output one. Alright. So, this is the fairly standard initialization step. Let us move on to the main body of the Bellman-Ford algorithm. Remember that in this algorithm, all we do is relax every tense edge and we repeat this ‘n-1’ times.\nSo, the ‘n-1’ repetitions are being taken care of by the outermost ‘for’ loop. And the inner ‘for’ loop is essentially a loop that goes over every edge by simply traversing the edge list. And the logic that you see inside this nested ‘for’ loop is the logic for checking if the edge that is currently under consideration is tense or not.\nAnd if it is tense, then we just appropriately update the values in the distance array, and we also update the predecessor pointer. Remember that in this algorithm, you do not really need any additional special data structures to be storing the distance values because we do not need to keep looking up the minimum values or anything like that. So, this is really all that is there, do it. Now when you want to do the actual detection of the negative cycle, we do this check one final time.\n(Refer Slide Time: 15:40)\n\nSo, we go over the edge list once again, after we come out of this ‘for’ loop. And if we discover even one edge that is tense, then we return 0 to indicate that there is a negative weight cycle and nothing can be done here. But if we survive the slope if the control does not go back from inside this for loop that we have at the end, then we can return one to say that we have properly found all the distances from the source ‘s.’\nSo, this is the complete implementation of Bellman-Ford. And I think it is, again, a really elegant algorithm. And it handles this most general situation that we are working with really, really well. Now, the next thing that we want to consider is moving on from the single-source shortest paths problem to the All Pairs Shortest Path Problem.\nNow, this is where we want to compute the shortest paths between every pair of vertices in the graph. And you could say that is easy, we just run the SSSP algorithm, with every vertex, in turn, being the source. And you could absolutely do that.\nBut then the running time is going to be ‘n’ times the cost of your SSSP algorithm. And the question, as always, is if we can do something slightly better. So, we are going to see an interesting approach to this. And again, that is popularly known as the Floyd Warshall algorithm. And that is what is coming up in the last module for this week. So, I will see you there!"
  },
  {
    "objectID": "materials/cpnotes/W06/Lec36.html",
    "href": "materials/cpnotes/W06/Lec36.html",
    "title": "M 3 (APSP [Floyd-Warshall] | Page Hopping)",
    "section": "",
    "text": "Lecture - 36\nShortest Paths - Module 3 (APSP [Floyd-Warshall] | Page Hopping)\nWelcome back to the second in the last segment of the third and the last module in week six. And we have been discussing ‘shortest paths’ broadly. But in this module, our focus has been on the variant called All Pairs Shortest Paths. And in the previous segment, we described the Floyd-Warshall algorithm that gives us a slightly better running time compared to running, for example, Dijkstra’s algorithm n times, especially when the number of edges is proportional to n squared.\nSo, this is the algorithm that we want to implement in this segment. And to do that, we are going to use a problem called ‘page hopping,’ which was ICPC World Finals problem from 2000. This is probably one of the most straightforward problem statements that we have seen.\n(Refer Slide Time: 00:58)\n\nThis is from the problem statement for page hopping. We are told that you are given a graph in which all the nodes can be reached from any starting point. And your job is to find the average shortest path length between arbitrary pairs of nodes. Of course, the sentence is sandwiched between a bit of a story about the internet and so on. So, I am not going to get into the story. But if you are curious, then you can certainly lookup the link in the description and read the full problem statement. I will give you a few other snippets from the problem statement that will clarify the kind of graph that we are working with and what the constraints are.\n(Refer Slide Time: 01:35)\n\nSo, first of all, we are told that each test case will consist of an arbitrary number of pairs of integers a and b, each representing a link from a page numbered ‘a’ to a page numbered ‘b.’ So, again, we are talking about pages here because the nodes in this graph really correspond to internet pages.\nThat is part of the story. But you can see here that the edges are connecting pairs of vertices in a fashion that is clearly directed.\nAnd in fact, the problem statement even has a picture and an example that makes it quite clear that the graph that we are working with is a directed graph. So, that is the first thing to note.\n(Refer Slide Time: 02:10)\n \nWe are also told that the page numbers or as we know, the vertices, the vertex labels will be in the range 1 to 100. This tells us that this is a small graph. There are only 100 vertices tops. So it is going to be pretty safe to apply our order n cubed algorithm here.\nThe next thing that we are told is that there are no self-referential links, which is the same as saying that there are no self-loops. And we also told that there is at least one path from each node to every other node in the graph. So, in the context of directed graphs, this is essentially a promise of strong connectivity.\nNow, if you are hearing that term for the first time, do not worry about it. It is essentially the analog of connectivity from undirected graphs. And it is exactly what is being said here, which is that you can go from anywhere to anywhere else in the graph. So, this is also given to us. We never going to get stuck with these large infinite values for any better vertices, which is a useful promise to have as we go along.\nSo, with all that said, let us now turn to the implementation. I will say that in this problem, we are given a graph with at most 100 vertices. And we are also told that there are no edge weights involved. So, it would also be perfectly valid to take your BFS implementation from last week and just try to run that ‘n’ times.\nSo, I definitely encourage you to give that a shot. It is a valid alternate solution. But since we want to use this problem as an excuse to implement the Floyd-Warshall algorithm that we discussed in the previous segment, that is what we are going to go ahead and do now.\n(Refer Slide Time: 03:50)\n \nSo, the first part, as usual, is just taking the input in and doing some initializations. I will say that most things here are perfectly routine. But the way the input is specified here is a bit unusual, in that it is just given as a list of edges terminated by pair 00. In particular, you do not have the number of vertices or the number of edges given to you explicitly.\nNow you do need this information to compute the average shortest path distance because remember, in the end, you want to divide by the number of pairs of vertices that you have considered, which is pretty much all pairs here. So, you could essentially count the number of vertices in a number of different ways.\nWhat I am going to do here is just initialize a set. And every time we see an edge, we add both of its endpoints to the set. Notice that the vertices will not get repeated because we are using the set data structure here. And when you want to figure out the number of vertices at the very end, we can just look up the size of the set that we have built on the way and that should take care of it.\nSo, that is why you have this set – the ‘vertices variable’ here, which is in fact, a set. Alright, so we also have a distance array. This is declared, I think, in the global scope. And it is committed to having memory amounting to accommodating 100 vertices. We know that because that is the limit. That is all that we are going to need to reserve for ourselves. All of this is inside a ‘while’ loop, by the way.\nSo, these are just the relevant snippets that I am sharing here. But I think if you want to make sense of the whole thing, you might want to look up the code, the full code, in the repository. Again, as usual, the link is in the description. In any case, when we are processing afresh instances, which is what is happening in this part of the code, you want to initialize your distance array so that the values between pairs of vertices are just initialized to infinity.\nAnd of course, we also have ‘i to i’ being initialized to 0 because (it) does not take any work to go from a vertex to itself. Now, as we process the edges, we are going to update the values of this distance array. You can initially think of the distance array that is just being an adjacency matrix. That is what it is going to be when you read the input n for the first time.\nBut then you can just reuse this adjacency matrix as the distance values that we want to compute using Floyd-Warshall later on. So, let us just read in the input here. So, we get these pairs of vertices, and we keep reading them as long as we do not encounter the ‘00’ vertex. And as you can see, we are inserting these vertices into a set to just keep track of them.\nAnd we are initializing the distance of u-1, v-1 to 1. This is because I just wanted the vertex indices to range from 0 to n-1. You could do this differently. And it is not going to be a problem either way. So, now that we have the initial distances that are just given by the direct edges, remember that we have already implicitly carried out the base case for the Floyd Warshall algorithm.\n(Refer Slide Time: 07:14)\n\nSo, that is the ‘r = 0’ case. That is already done by simply reading in the values coming from the input for the information about the edges. The rest of it, these nested ‘for’ loops that we have here are implementing this reference that we discussed in the previous segment. So, the outermost ‘for’ loop is keeping track of the phases. We are going to then go through every pair of vertices and see if we need to update the value of the distance between i and j.\nSo, essentially, we want to know, do we really use the ’k’th vertex or not. And if we do, the new distance is going to be essentially the sum of the distances: distance [i][k], and distance [k][j]. If that is going to be better than whatever we have previously, then we need to update the value of distance [i][j]. So, you could also write this a little more succinctly as an update of distance [i][j] is being min of distance [i][j], the sum that you see here. Either way, it has the same effect.\nAnd that is essentially all of Floyd-Warshall. Okay. So, if you write it without the comments, and you write it in the style of recomputing a minimum, or overriding the value of distance [i][j] with the minimum between distance [i][j] and the sum that you see here, it is really going to be just four lines of code, which is what makes it an attractive proposition, especially in a contest situation if you just want to go something up quickly.\nJust remember here that the complexity of this approach is fixed at order n cubed because these three loops are going to run their course for sure, irrespective of how many edges are there in the graph, for example. So, just make sure that you apply this algorithm only when you are confident that your constraints can handle it.\nIn particular, watch out for the number of vertices being more than 450, then you might just be in a little bit of trouble with this approach. But if you have a small number of verses, then this is really a good option to have in your toolkit because of just how short the code is and how elegantly everything works out. So, with that, I think we come to an end to our discussion about shortest path algorithms.\n(Refer Slide Time: 09:45)\n \nI will just conclude here with one small comment about a bit of detail that I have not talked about very explicitly before, which is about how you set the value of infinity. So, sometimes you may find that not setting this value properly could lead to bugs, which are hard to detect. So, you want the value of infinity, which is what you initialize your distance array 2, to be on the one hand large enough, but also on the other hand, not too large.\nLet me explain what I mean by this. On the one hand, you do want it to be large enough because remember that when you are relaxing edges, this is the value that often your d of u plus w is going to be computing with. So, for instance, if you have a path, that is an actual path but it is really, really costly, when that is being compared against infinity, if your value of infinity is not large enough, your code might just say that ‘we are better off keeping the infinity-edge.’ Now, that is a problem because that infinity value really represents a path that does not exist.\nSo, you want to make sure that your value of infinity is greater than the sum of all the weights of the edges. So, typically, you will have some upper bound on the values of the weights of the individual edges. So, let us say that that upper bound is some x. And let us say you have m edges, you want to make sure that your value of infinity is set to something that is larger than m * x.\nNow, what did I mean when I said that it should not be too large. Sometimes you may be tempted to say that – let us just make this as large as we can. And particularly, you might be aware of the limits library, which gives you access to the largest possible value that you can store in a variable of a certain type.\nSo, for instance, you could invoke the built-in constant int Max to get the largest value that you can store in an integer variable, which would be something like 231 -1 or something like this. So, you might be tempted to initialize infinity to int Max. Now, what is the problem with this?\nWell, the thing here is that you could run into some really nasty overflow issues. When you are trying to evaluate the condition for relaxation, often, you might be comparing values that look like INF plus w. Because you are comparing d of u + w, and d of u, to begin with, may well be INF. Now, if INF is set to int Max, and you add a value W to it, what might end up happening is that you experience overflow, and this becomes a large negative number.\nAnd this will dominate whatever it is that is on the other side of the equation. This will appear to be smaller than d of v. So you will end up relaxing an edge that you really should not. Because what you want, the behavior that you want from your setting of INF is that INF any finite value should still be INF, it should not become accidentally a small value.\nSo setting your value of INF to be the very limit of the data type that is, you know, storing the value of INF – that is a dangerous thing to do. So, do not make it go all the way to the brink, because that is going to be problematic. Usually, a safe thing to do is to just set it to a value that is sufficiently large.\nSo, just look at your maximum weight limit multiplied by the number of edges, and pick a value that is a bit larger than that. Now, if int cannot handle it, or if that seems like it is going to be suspiciously close to the upper limit, and you might experience an overflow issue, just use a long int instead of an int or something like this.\nSo, just be a little bit careful about how you initialize your distance array. Because this can be a source of bugs that are hard to find. So just a very minor detail, but something that is worth being careful about. So, with that, we do come to an end of our discussion of shortest path algorithms.\nI hope you enjoyed this little journey through various cases starting from BFS all the way up to Floyd-Warshall. And in between, of course, we met Dijkstra’s algorithm, modified Dijkstra’s algorithm, and Bellman-Ford. It can be a lot to keep track of, so I would recommend just having a little bit of a cheat sheet with you, which just summarizes the various complexities and the scenarios in which these algorithms are applicable.\nSo, you know which one you want to use in a particular situation. Now, most of the problems that we saw in the videos were fairly direct applications of shortest paths because the goal really was to have an excuse to implement the algorithms that we were learning. On the other hand, there could be problems where it is not as transparent – that you want to be working with the shortest path algorithm.\nOr maybe you need to modify the shortest path algorithm that you have learned in some subtle way to account for whatever it is that needs to be done. So, there are a couple of examples of these kinds of problems in the ‘extras’ section. So if you have time, be sure to check them out. In the meantime, we will, as always, look forward to your contributions to the official repository.\nSo, once again, we have a week where all the official solutions are coded in C++. So, if you have versions of this that are written in Python or Java, we will really look forward to your pull requests in the repository. Thanks very much in advance. And of course, I hope that we will continue this conversation in Discord or over the Google mailing list, especially if you are listening to this during an active run of the course.\nSo, I will see you around there. Thanks very much for watching and I will see you back in the next module where we are going to talk about minimum spanning trees. Bye for now!"
  },
  {
    "objectID": "blog/note-taking-resources/index.html",
    "href": "blog/note-taking-resources/index.html",
    "title": "Note Taking Resources",
    "section": "",
    "text": "Here is a list of courses, books, essays, youtube playlists, and other miscellany about taking notes, with the act interpreted broadly to include things like systems for filing, organization, linking, and thinking. Please feel free to drop a line in the comments or send a PR my way if you have something to add!\nThanks to Abhinav for the prompt :)\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          type\n        \n     \n  \n    \n      \n      \n    \n\n\n\n    \n        Type\n        Link\n        Resource\n    \n    \n             \n            \n                 \n                   \n                 \n                 \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                1. Cognitive Productivity: Using Knowledge to Become Profoundly Effective\n                Book by Luc P. Beaudoin.  Official book summary: You distinguish yourself from others not so much by what you've read, viewed or listened to, but by the lasting impact that information has had upon you. How can you use knowledge to become a more effective person? Cognitive Productivity answers this question with cognitive science and practical strategies.\n            \n        \n             \n            \n                 \n                   \n                 \n                 \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                2. Cognitive Productivity with macOS: 7 Principles for Getting Smarter with Knowledge\n                Book by Luc P. Beaudoin.  Official book summary: In today's competitive knowledge economy, you always need to keep learning —and fast. But most information and apps get in the way. This book describes 7 principles for selecting, processing and mastering knowledge using potent Mac apps.\n            \n        \n             \n            \n                 \n                 \n                 \n                   \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                3. The Introduction to the Zettelkasten Method\n                Zettelkasten is a rather specific note-taking system (disclaimer: it is not something that I use, but I do find the principles vaguely intriguing). It relies heavily on tagging, linking, going with the flow, not overthinking, and somehow simultaneously keeps things systematic from a retrieval perspective. This overview page has a bunch of pointers that that should serve as a roadmap for the Zettelkasten for anyone inclined to find out more.\n            \n        \n             \n            \n                 \n                 \n                 \n                 \n                 \n                   \n                 \n            \n            \n                    \n            \n            \n                4. How can we develop transformative tools for thought?\n                Essay by Andy Matuschak and Michael Nielsen  Arguably not about taking notes per se, but about philosophies associated with systems and — as the title suggests — tools for thought.\n            \n        \n             \n            \n                 \n                 \n                 \n                 \n                 \n                   \n                 \n            \n            \n                    \n            \n            \n                5. Evergreen Notes\n                Thoughts from Andy Matuschak The OG 'digital garden', if I am not mistaken!\n            \n        \n             \n            \n                 \n                 \n                   \n                 \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                6. Obsidian for Everyone\n                Nicole van der Hoeven's course.  Nicole is a pro Obsidian user and a master expositor. This particular course is nice because it focuses on all the things you can achieve without the use of any plugins: just bare-bones Obsidian. You'd be surprised at how far you can go!\n            \n        \n             \n            \n                   \n                 \n                 \n                 \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                7. Youtube channel: Nicole van der Hoeven\n                Excellent content for pro and starter Obsidian users alike. Very accessible and engaging, and I believe most people will find something relevant and relatable here.\n            \n        \n             \n            \n                 \n                   \n                 \n                 \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                08. Grok TiddlyWiki\n                Grok TiddlyWiki is written and maintained by Soren Bjornstad.  Outstanding introduction to TiddlyWiki. Even non-TW users are likely to get some fun ideas from skimming this. And if you are a TW user, then this is one of the best journeys from starter to pro! Also check out Soren's own digital garden.\n            \n        \n             \n            \n                   \n                 \n                 \n                 \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                09. Youtube channel: Linking Your Thinking (LYT)\n                This is Nick Milo's Youtube channel. It is mostly principles around linking, but uses Obsidian as the tool of choice. Nick also organizes a LYT conference regularly that is hugely popular and not particularly restricted to Obsidian. He also has a cohort-based course around LYT principles, a great Obsidian starter playlist, and a course called Obsidian Flight School as well.\n            \n        \n             \n            \n                   \n                 \n                 \n                 \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                10. Youtube channel: August Bradley\n                This channel focuses on 'life design' as a broad concept, using Notion as the underlying tool of choice for organization. There is an extensive discussion of the 'PPV' system - Pillars, Pipelines, and Vaults. Lots of system thinking in here, and I think although all of it is done on Notion, several principles are tool-agnostic.\n            \n        \n             \n            \n                 \n                   \n                 \n                 \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                11. Building a Second Brain\n                This is a cohort-based course around the notion of building a second brain by Tiago Forte. The material is centered around the 'PARA' method - Projects, Areas, Resources, Archives: a fairly intuitive system that many have found useful. Tiago has one published and one upcoming [at the time of this writing] book on these methods. His blog and Youtube channel dive fairly deep into these concepts, and I think the cohorts are useful if you are building something out and are looking for ways to stay accountable on sticking a system, or want a community/platform to brainstorm ideas.\n            \n        \n             \n            \n                   \n                 \n                 \n                 \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                12. Youtube channel: Marie Poulin\n                Marie is an authority when it comes to adapting Notion in creative ways for both personal and business use. She has a very comprehensive course called Notion Mastery that covers a lot of ground in terms of both techniques and principles.\n            \n        \n             \n            \n                   \n                 \n                 \n                 \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                13. Youtube channel: Zsolt's Visual Personal Knowledge Management\n                This is the Zsolt's channel, who is behind tools like Excalibrain and Excalidraw for Obsidian and beyond. The channel emphasizes visual aspects of note-taking, while some of it is focused on Excalidraw/Excalibrain, a lot of content is also about general principles, examples, and so on.\n            \n        \n             \n            \n                   \n                 \n                 \n                 \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                14. Youtube channel: Thomas Frank\n                This channel is another one that pushes Notion to its limits. While overall this might be more productivity/systems/management territory than note-taking, I have found some great discussions about organizational principles here.\n            \n        \n             \n            \n                 \n                 \n                 \n                 \n                   \n                 \n                 \n            \n            \n                    \n            \n            \n                15. Johnny Decimal\n                This is purely about organization, but for me how notes are stored are an important piece of the puzzle. If you like folders, you might enjoy this system.\n            \n        \n             \n            \n                 \n                 \n                 \n                   \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                16. A list of PKM tools\n                A reddit post collecting a bunch of PKM software options, ranging from mainstream to exotic and everything in between!\n            \n        \n             \n            \n                 \n                 \n                   \n                 \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                17. To Obsidian and Beyond\n                A course by Mike Schmitz. From the official description: A master-course for Obsidian users (new and old alike). Finally organize your notes and ideas to make creative output easy.\n            \n        \n             \n            \n                   \n                 \n                 \n                 \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                18. Youtube channel: Red Gregory\n                A Notion-based channel: I have found some of the workflows here to be advanced and intriguing in equal measure. Many principles are tool-agnostic, although the focus here is mostly on Notion.\n            \n        \n             \n            \n                   \n                 \n                 \n                 \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                19. Youtube channel: Danny Hatcher\n                A channel focused on PKM and organizational systems broadly. I have mostly viewed the Obsidian-related material here: several demonstrations and tutorials have been very helpful.\n            \n        \n             \n            \n                 \n                 \n                   \n                 \n                 \n                 \n                 \n            \n            \n                    \n            \n            \n                20. Verbal to Visual\n                Lots of resources on sketchnoting and visual approaches to note-taking.\n            \n        \n\n\n\nNo matching items"
  },
  {
    "objectID": "materials/algorithms/matroids/definition/index.html",
    "href": "materials/algorithms/matroids/definition/index.html",
    "title": "2. The Definition",
    "section": "",
    "text": "Acknowledgements\n\n\n\nThe part of the write up that introduces terminology and examples is borrowed from Chapter E of Jeff Erickson’s textbook on Algorithms.\n\n\nRecall that from last time, we were dealing with:\n\na finite universe of elements \\cal U = \\{e_1, e_2, \\cdots, e_n\\}\na weight function w: \\cal U \\longrightarrow \\mathbb{Q}^{\\geqslant 0} that assigns a non-negative weight with every universe element\noracle access to a family \\cal F = \\{S_1, \\ldots, S_m\\} of subsets of \\cal U\n\nand we wanted to determine the maximum weight attained by any set in \\cal F, where the weight of a set is defined as the sum of the weights of the elements that belong to it. To this end, we proposed the following greedy algorithm:\n\n\n\n\n\n\nA Greedy Algorithm\n\n\n\n\nSort the elements of U in descending order of weight; i.e, WLOG w(e_1) \\geqslant \\cdots \\geqslant w(e_n).\nInitialize a solution: specifically, let X = \\emptyset.\nFor i \\in [n]: if X \\cup \\{e_i\\} \\in \\cal F, X \\longleftarrow X \\cup \\{e_i\\}.\n\n\n\nand concluded that it does not quite work, but might if the family came with the following promise:\nIf S and T are two subsets of \\cal U with T \\in \\cal F and |S| > |T|, then \\exists e \\in S \\setminus T such that T \\cup \\{e\\} \\in \\cal F.\nThis is exactly what we need to make our proof work out: recall that T corresponds to the greedy choices, which always correspond to a set in \\cal F, while S corresponds to a subset of the optimal solution, which has no obligation to be in \\cal F. Let us call a family fantastic if it satisfies the property above. It is not difficult to show that the greedy algorithm produces the correct output when the input is a fantastic family: we leave this as an exercise.\nHowever, notice that this is not a very interesting defintion. Consider any family \\cal F that is non-trivial, i.e, has at least one non-empty subset of U in it: call this X. Then, by triggering this property on X \\cup \\{e\\} for any e \\notin X, we see that all “immediate supersets” of X are forced to also belong to \\cal F. Carrying this argument forward, we see that all supersets of X are forced to belong to \\cal F. In particular, if \\emptyset \\in \\cal F — which will be the case for most applications of this framework — then the only family \\cal F that qualifies as fantastic is the family of all possible subsets of U. So… while our notion of a fantastic family is perfectly well-defined and even useful, it is also rather restrictive and therefore uninteresting.\nOur next step is to see if we can still get to our desired outcome (i.e, the correctness of the greedy algorithm), while not being so demanding with our definition. How about we modify our constraint to the following:\nIf S and T are two sets with S \\in \\cal F and T \\in \\cal F, and |S| > |T|, then \\exists e \\in S \\setminus T such that T \\cup \\{e\\} \\in \\cal F.\nSo let us say that a family is nice if it satisfies the property above. Can we now push our proof of correctness for the greedy algorithm above? Unfortunately, the answer is a negative. Can you come up with a counterexample before reading on?\n\n\n\n\n\n\nA Counterexample\n\n\n\n\n\nLet:\n\n\\cal U = \\{p,q\\}\nw(p) = 40, w(q) = 30\n\\cal F = \\{\\{q\\},\\{pq\\}\\}\n\nThe greedy output will be \\{q\\}, while the optimal output is \\{pq\\}. Notice that the family is nice!\n\n\n\nSo well, it is back to the drawing board. Let us recall how our proof was supposed to go. Let:\n\nT be the set of greedy choices up to the (i-1)^{th} iteration, and\nS be the set of optimal choices up to the i^{th} iteration,\n\nthen the hope was that the property above would rescue us and contradict the greedy choices, since |S| > |T|. However, in the counterexample above, we are unable to take advantage of the fact that \\cal F is a nice family because S \\notin \\cal F. Note that the optimal solution is obliged to only output a set in \\cal F, but the intermediate choices as we are viewing them now have no obligation to necessarily belong to \\cal F.\nOne way to force this is to insist that our family be heriditary, that is, the inclusion of a set S \\in \\cal F implies the inclusion of all subsets of S in \\cal F as well. If this were true, then S \\in \\cal F since S is a subset of the optimal solution, which we know to be in \\cal F. Note that the counterexample above did not involve a heriditary family. It turns out that this combination of properties is both: (a) permissive, in that a non-trivial number of families enjoy the property; and (b) useful, in that it gives us enough leverage to prove the correctness of the greedy algorithm.\nWith all this, we are now ready to bring up the official definition of a matroid.\n\n\n\n\n\n\nMatroids\n\n\n\nA matroid (\\cal U, \\cal F) consists of a finite ground set \\cal U and a collection \\mathcal{F} of subsets of \\cal U that satisfies three axioms:\n\nNon-emptiness. The empty set is in \\mathcal{F}. (Thus, \\mathcal{F} is not itself empty.)\nHeredity. If \\mathcal{F} contains a subset S \\subseteq \\cal U, then \\mathcal{F} contains every subset of S.\nExchange. If S and T are two sets in \\cal F where |S|>|T|, then T \\cup\\{e\\} \\in \\mathcal{F} for some element e \\in S \\backslash T.\n\n\n\nYou can think of the first property as a formality that excludes the empty family from being a matorid. The other two have independent historical motivations, but we have also just seen a good reason to find these properties particularly desirable: which is the way it plays into the proof of correctness of our greedy algorithm.\nSpeaking of history, let us introduce some terms commonly associated with matroids. Some of these words may ring familiar if you have encountered linear algebra before: and indeed, the crossover is not unintented — a fundamental type of matroid is one that is naturally associated with a matrix, and a lot of the terms are inspired from this setting.\nFirst, the sets of \\cal F are called independent sets, and all subsets of \\cal U that did not make it to \\cal F are called — you guessed it — dependent sets. Note that the exchange axiom ensures that all maximal sets of a matroid \\cal F have the same size. The maximal sets are called a basis, and their common size is called the rank of a matroid. A minimal dependent set is called a circuit.\nBefore moving on, we enlist some examples of matroids, to reaffirm the idea that the definition indeed allows for a variety of interesting set systems. We do not elaborate on the details of how these families satisfy the matroid axioms: the motivated reader is welcome to pursue this further as an exercise.\n\nUniform matroid U_{k, n}. A subset X \\subseteq\\{1,2, \\ldots, n\\} is independent if and only if |X| \\leq k. Any subset of \\{1,2, \\ldots, n\\} of size k is a basis; any subset of size k+1 is a circuit.\nGraphic/cycle matroid \\mathcal{M}(G). Let G=(V, E) be an arbitrary undirected graph. A subset of E is independent if it defines an acyclic subgraph of G. A basis in the graphic matroid is a spanning tree of G; a circuit in this matroid is a cycle in G.\nCographic/cocycle matroid \\mathcal{M}^*(G). Let G=(V, E) be an arbitrary undirected graph. A subset I \\subseteq E is independent if the complementary subgraph (V, E \\backslash I) of G is connected. A basis in this matroid is the complement of a spanning tree; a circuit in this matroid is a cocycle-a minimal set of edges that disconnects the graph.\nMatching matroid. Let G=(V, E) be an arbitrary undirected graph. A subset I \\subseteq V is independent if there is a matching in G that covers I.\nDisjoint path matroid. Let G=(V, E) be an arbitrary directed graph, and let s be a fixed vertex of G. A subset I \\subseteq V is independent if and only if there are edge-disjoint paths from s to each vertex in I.\n\nUp next, we consolidate our learnings, and present a proof that should strike the reader as at least slightly boring, given that it is completely predictable in the light of our discussion so far."
  },
  {
    "objectID": "materials/algorithms/matroids/deadline/index.html",
    "href": "materials/algorithms/matroids/deadline/index.html",
    "title": "4. Scheduling with Deadlines",
    "section": "",
    "text": "Acknowledgements\n\n\n\nThis write up is borrowed (with minor adaptations) from Chapter E of Jeff Erickson’s textbook on Algorithms.\n\n\n\nSuppose you have n tasks to complete in n days; each task requires your attention for a full day. Each task comes with a deadline, the last day by which the job should be completed, and a penalty that you must pay if you do not complete each task by its assigned deadline. What order should you perform your tasks in to minimize the total penalty you must pay?\nMore formally, you are given:\n\nan array D[1,...,n] of deadlines and\nan array P[1,...,n] of penalties.\n\nEach deadline D[i] is an integer between 1 and n, and each penalty P[i] is a non-negative real number. A schedule is a permutation of the integers \\{1,2, \\ldots, n\\}.\nThe scheduling problem asks you to find a schedule \\pi that minimizes the following cost: \n\\operatorname{cost}(\\pi):=\\sum_{i=1}^n P[i] \\cdot[\\pi(i)>D[i]].\n\nThis doesn’t look anything like a matroid optimization problem. For one thing, matroid optimization problems ask us to find an optimal set; this problem asks us to find an optimal permutation. Surprisingly, however, this scheduling problem is actually a matroid optimization in disguise!\nFor any schedule \\pi, call tasks i such that \\pi(i)>D[i] late or delayed, and all other tasks on time.\nTo see this, consider that two schedules are equivalent from a cost perspective if they delay the same set of tasks. In particular, let S \\subseteq [n] be some subset of tasks. Suppose we have a schedule \\pi_1 that delays all tasks in S and finishes all tasks that are not in S on time, and another schedule \\pi_2 \\neq \\pi_1 that also delays all tasks in S and finishes all tasks that are not in S on time. Observe that \\operatorname{cost}(\\pi_1) = \\operatorname{cost}(\\pi_2). Intuitively, we might as well turn our attention to subsets of completed tasks as opposed to the sequence in which we execute them. We summarize our discussion here in the following claim:\n\n\n\n\n\n\nClaim Relating Permutations to Subsets\n\n\n\nThe cost of a schedule is determined by the subset of tasks that are on time.\n\n\nCall a subset X of the tasks realistic if there is a schedule \\pi in which every task in X is on time. We can precisely characterize the realistic subsets as follows. Let X(t) denote the subset of tasks in X whose deadline is on before t :\n\nX(t):=\\{i \\in X \\mid D[i] \\leq t\\}\n\nIn particular, X(0)=\\varnothing and X(n)=X.\n\n\n\n\n\n\nLemma characterizing realistic sets\n\n\n\nLemma. Let X \\subseteq\\{1,2, \\ldots, n\\} be an arbitrary subset of the n tasks. X is realistic if and only if |X(t)| \\leq t for every integer t.\nProof. Let \\pi be a schedule in which every task in X is on time. Let i_t be the t th task in X to be completed. On the one hand, we have \\pi\\left(i_t\\right) \\geq t, since otherwise, we could not have completed t-1 other jobs in X before i_{\\mathrm{t}}. On the other hand, \\pi\\left(i_t\\right) \\leq D[i], because i_t is on time. We conclude that D\\left[i_t\\right] \\geq t, which immediately implies that |X(t)| \\leq t.\nNow suppose |X(t)| \\leq t for every integer t. If we perform the tasks in X in increasing order of deadline, then we complete all tasks in X with deadlines t or less by day t. In particular, for any i \\in X, we perform task i on or before its deadline D[i]. Thus, X is realistic.\n\n\nWe can now define a canonical schedule for any set X as follows: execute the tasks in X in increasing deadline order, and then execute the remaining tasks in any order. The previous proof implies that a set X is realistic if and only if every task in X is on time in the canonical schedule for X. Thus, our scheduling problem can be rephrased as follows:\n\n\n\n\n\n\nFind a realistic subset X such that \\sum_{i \\in X} P[i] is maximized.\n\n\n\nSo we’re looking for optimal subsets after all! Now we could describe a greedy algorithm and show that it works out, or…\n\n\n\n\n\n\nRealistic Sets have the Matroid Properties\n\n\n\nLemma. The collection of realistic sets of jobs forms a matroid.\nProof: The empty set is vacuously realistic, and any subset of a realistic set is clearly realistic. Thus, to prove the lemma, it suffices to show that the exchange property holds. Let X and Y be realistic sets of jobs with |X|>|Y|.\nConsider keeping two dated notebooks, where the cover page is day 0, and the last page is day n. In a thought experiment, let us go over the days one by one, starting from the 0-th day, and on each day, we make a note of the number of tasks in X(t) on the first notebook, and the number of tasks in Y(t) on the second notebook — and we keep doing this until we observe that the number on the first notebook is bigger than the second. Notice that this has to happen at some point, since |X(n)| > |Y(n)| and both notebooks start at zero.\nNow, let q \\leqslant n be the smallest integer for which |X(q)| > |Y(q)|. Notice that this means that there is at least one task in X with a deadline of q which is not in Y. Pick any one such — say t — for inclusion in Y: we claim that Y \\cup \\{t\\} is realistic. Indeed, on any day p that is before q, we can appeal to the fact that Y was realistic up to day p and we have introduced no new tasks in Y that have a deadline of p or earlier. On the fated day q, the number of tasks we have in Y is at most the number of tasks we have in X up to day q, and since that is at most q, we are done.  \n\n\nThis lemma implies that our scheduling problem is actually a matroid optimization problem, so the greedy algorithm finds the optimal schedule.\nGREEDYSCHEDULE(D[1 . . n], P[1 . . n]):\nSort P in increasing order, and permute D to match\nj = 0\nfor i in 1,n:\n    X[j+1] = i\n    if X[1,...,j+1] is realistic\n        j = j+1\nreturn the canonical schedule for X[1...j]\nWe leave as an exercise to the reader to figure out an implementation of the oracle access to the family of realistic sets. In particular, this involves coming up an efficient procedure to test whether a given subset of jobs is realistic. It is possible to do this in linear time based on the properties of realistic sets established from before."
  },
  {
    "objectID": "materials/algorithms/matroids/greedy-works/index.html",
    "href": "materials/algorithms/matroids/greedy-works/index.html",
    "title": "3. Greedy Works!",
    "section": "",
    "text": "Acknowledgements\n\n\n\nThis write up is borrowed (with minor adaptations) from Chapter 4 of Jeff Erickson’s textbook on Algorithms.\n\n\nRecall that from last time, we were dealing with:\n\na finite universe of elements \\cal U = \\{e_1, e_2, \\cdots, e_n\\}\na weight function w: \\cal U \\longrightarrow \\mathbb{Q}^{\\geqslant 0} that assigns a non-negative weight with every universe element\noracle access to a family \\cal F = \\{S_1, \\ldots, S_m\\} of subsets of \\cal U\n\nand we wanted to determine the maximum weight attained by any set in \\cal F, where the weight of a set is defined as the sum of the weights of the elements that belong to it.\nTo this end, we proposed the following greedy algorithm:\n\n\n\n\n\n\nA Greedy Algorithm\n\n\n\n\nSort the elements of U in descending order of weight; i.e, WLOG w(e_1) \\geqslant \\cdots \\geqslant w(e_n).\nInitialize a solution: specifically, let X = \\emptyset.\nFor i \\in [n]: if X \\cup \\{e_i\\} \\in \\cal F, X \\longleftarrow X \\cup \\{e_i\\}.\n\n\n\nSince the greedy algorithm did not work “at large”, we agreed that it might be interesting to impose some constraints on \\cal F and see if we could argue that the greedy algorithm works for all families that enjoy some additional structure. After some back and forth, here is what we came up with:\n\n\n\n\n\n\nMatroids\n\n\n\nA matroid (\\cal U, \\cal F) consists of a finite ground set \\cal U and a collection \\mathcal{F} of subsets of \\cal U that satisfies three axioms:\n\nNon-emptiness. The empty set is in \\mathcal{F}. (Thus, \\mathcal{F} is not itself empty.)\nHeredity. If \\mathcal{F} contains a subset S \\subseteq \\cal U, then \\mathcal{F} contains every subset of S.\nExchange. If S and T are two sets in \\cal F where |S|>|T|, then T \\cup\\{e\\} \\in \\mathcal{F} for some element e \\in S \\backslash T.\n\n\n\nAll this sets the stage for the main result that we want to get to:\n\n\n\n\n\n\nThe Greedy Algorithm Works\n\n\n\nTheorem. For any matroid \\mathcal{M}=(\\cal U, \\mathcal{F}) and any weight function w, the greedy algorithm that takes (\\cal U, \\mathcal{F}, w) as input returns a maximum-weight basis of \\mathcal{M}.\nProof. As you might anticipate, we use an exchange argument.\nLet T=\\left\\{f_1, f_2, \\ldots, f_k\\right\\} be the independent set returned by the greedy algorithm on input (\\cal U, \\mathcal{F}, w)).\nIf any other element of \\cal U could be added to T to obtain a larger independent set, the greedy algorithm would have added it. Thus, T is a basis.\nFor purposes of deriving a contradiction, suppose there is an independent set S=\\left\\{g_1, g_2, \\ldots, g_{\\ell}\\right\\} such that \n\\sum_{i=1}^k w\\left(f_i\\right)<\\sum_{j=1}^{\\ell} w\\left(g_i\\right) .\n Without loss of generality, assume that S is a basis. The exchange property now implies that k=\\ell.\nNow suppose the elements of T and S are indexed in order of decreasing weight. Let i be the smallest index such that w\\left(f_i\\right)<w\\left(g_i\\right), and consider the independent sets \nT_{i-1}=\\left\\{f_1, f_2, \\ldots, f_{i-1}\\right\\} \\quad \\text { and } \\quad S_i=\\left\\{g_1, g_2, \\ldots, g_{i-1}, g_i\\right\\}\n\nBy the exchange property, there is some element g_j \\in S_i such that T_{i-1} \\cup\\left\\{g_j\\right\\} is an independent set. We have:\nw\\left(g_j\\right) \\geqslant w\\left(g_i\\right)>w\\left(f_i\\right).\nThus, the greedy algorithm considers and rejects the heavier element g_j before it considers the lighter element f_i.\nBut this is impossible, since the greedy algorithm accepts elements in decreasing order of weight.\n \n\n\nThis result also has an interesting flip side, so to speak. When dealing with set systems that do not satisfy the exchange axiom, it turns out that we can adverserially choose a weight function that misleads the greedy algorithm into producing suboptimal output! The intuition is the following: a violation of the exchange axiom in a set system (\\cal U, \\cal F) amounts to saying the following:\n\\exists S, T \\in \\cal F such that |S| > |T| but for all e \\in S \\setminus T, T \\cup \\{e\\} \\notin \\cal F.\nNow our plan is the following.\nWe “tempt” greedy into picking all elements in T before anything in S, by making the elements of T just a little heavier than elements in, say, S \\setminus T. Note that once greedy chooses all of T, it cannot expand further into S because of the violation above combined with its own committment to navigating with \\cal F. So it will skip over all elements of S \\setminus T: which is an opportunity for us to create a better optimal solution.\nIn particular, our goal will be to assign weights to elements in S \\setminus T in such a way that w(S) > w(T) in spite of the fact that elements in T are heavier than those in S \\setminus T. Here, we can take advantage of the fact that |S| > |T|.\nWith these ideas in place, can you come up with the adverserial weight function?\n\n\n\n\n\n\nAdverserially Chosen Weights to Trip Greedy [Click to reveal.]\n\n\n\n\n\nUsing m to denote |T|, suppose we use the following scheme:\n\nEvery element of T has weight m+2.\nEvery element of S \\backslash T has weight m+1.\nEvery other element of the ground set has weight zero.\n\nWith these weights, the greedy algorithm will consider and accept every element of T, then consider and reject every element of S, and finally consider all the other elements. The algorithm returns a set with total weight m(m+2)=m^2+2 m. But the total weight of S is at least (m+1)^2=m^2+2 m+1. Thus, the output of the greedy algorithm is not the maximum-weight set in \\cal F.\n\n\n\nThis completes the argument for the following fact:\n\n\n\n\n\n\nTheorem. Greedy for set systems that do not satisfy the exchange axiom can be made to fail.\n\n\n\nFor any heriditary family (\\cal U, \\cal F) that is not a matroid, there is a weight function w such that the greedy algorithm fails to output the optimal answer.\n\n\nRecall the Dance Classes problem considered in Chapter 1. There is a natural subset system associated with this problem: A set of classes is independent if and only if no two classes overlap. This subset system is not a matroid, because there can be maximal independent sets of different sizes, which violates the exchange property. If we consider a weighted version of the class scheduling problem, where each class is worth a different number of hours, our result above implies that the greedy algorithm will not always find the optimal schedule.\nHowever, this result here does not contradict the correctness of the greedy algorithm for the original unweighted problem; that problem uses a particularly lucky choice of weights (all equal), whereas the claim here is simply that there exists particularly nasty choice of weights that is designed to mislead greedy into making suboptimal choices."
  },
  {
    "objectID": "materials/algorithms/matroids/index.html",
    "href": "materials/algorithms/matroids/index.html",
    "title": "Matroids",
    "section": "",
    "text": "We are going to explore a combinatorial construct called a matroid, that has exactly the structure that makes greedy algorithms work! Read on to find out more about:\n\nThe Motivation\nThe Definition\nGreedy Works!\nTasks on a Deadline"
  },
  {
    "objectID": "materials/algorithms/matroids/motivation/index.html",
    "href": "materials/algorithms/matroids/motivation/index.html",
    "title": "1. The Motivation",
    "section": "",
    "text": "A Generic Optimization Problem\nSuppose we have:\n\na finite universe of elements \\cal U = \\{e_1, e_2, \\cdots, e_n\\}\na weight function w: \\cal U \\longrightarrow \\mathbb{Q}^{\\geqslant 0} that assigns a non-negative weight with every universe element\na family \\cal F = \\{S_1, \\ldots, S_m\\} of subsets of \\cal U\n\nand we “lift” w to the sets in \\cal F as follows:\nw(S) = \\sum_{e \\in S} w(e).\nHere is, then, a natural optimization question: what is the maximum weight attained by a set in \\cal F?\nNotice that this need not be the set of the largest cardinality (a large number of light elements may fall short of a small number of heavy ones).\nNow, you may wonder why this is even an interesting question — do we not find the answer by computing the weights of all the sets, and tracking the maximum?\nThat would indeed work! However, the time we need to execute this is O(mn) in the worst case (accounting for the time we need to add O(n) weights), and note that m is potentially exponential in n, which — when it happens — will not be fun.\nYou can rebut this by suggesting that it does not matter how large m is as a function of n: it counts as input, and so our approach is polynomial in the size of the input.\nIndeed! So to make this problem interesting, and one that captures problems that you will actually encounter, let’s add the constraint that \\cal F is not given to us as explicit input, but rather via an oracle. What this means is that we do not have the luxury of direct access to the list of sets in \\cal F, but we can poke at the list indirectly: if we have a set at hand, we can feed it to the oracle, which will tell us if the set belongs in \\cal F or not.\nSo our goal is to now build a set that has the largest weight, with some help from the oracle. We want to do this as efficiently as possible, in particular using only polynomially-in-n many calls to the oracle. It is like navigating a room in the dark with a torch… we do not know most things, but we can get sneak peeks into the lay of the land using the torch, but we don’t want to overuse the torch or the battery will run out.\n\n\nA Greedy Approach\nIf you had to build the heaviest set greedily, how would you go about it? A natural idea is to favor heavier elements over lighter ones. In particular, let us line up the elements from heaviest to lightest, and keep picking them up one by one. Well, this will always end with us choosing U, which is a set that is as heavy as it gets: however we have a problem — this set may not be in \\cal F! We may have lost the plot well before reaching the end, so we need to introduce some sanity check here. How about ensuring, using the oracle, that we only choose elements that keep us rooted in \\cal F? Here’s what we would do:\n\n\n\n\n\n\nA Greedy Algorithm\n\n\n\n\nSort the elements of U in descending order of weight; i.e, WLOG w(e_1) \\geqslant \\cdots \\geqslant w(e_n).\nInitialize a solution: specifically, let X = \\emptyset.\nFor i \\in [n]: if X \\cup \\{e_i\\} \\in \\cal F, X \\longleftarrow X \\cup \\{e_i\\}.\n\n\n\nNotice that we invoke the oracle n times in step 3. This is a natural greedy approach, and it might remind you of, say, the mechanics of Kruskal’s algorithm for finding spanning trees of maximum weight. Indeed, for a particular choice of \\cal U and \\cal F, the algorithm above is exactly Kruskal’s algorithm1! Fix a graph G, and let \\cal U = E(G) and \\cal F consisting of all acyclic subsets of E(G). The “oracle” in this case just has to check if, given S \\subseteq E(G), the subgraph induced by S contains a cycle or not.\nNow the question is if the algorithm always works. A moment’s reflection will reveal that it in fact, does not.\n\n\n\n\n\n\nA Counterexample\n\n\n\n\n\nLet:\n\n\\cal U = \\{p,q,r\\}\nw(p) = 40, w(q) = 30, w(r) = 20\n\\cal F = \\{\\{p\\},\\{qr\\}\\}\n\nThe greedy output will be \\{p\\}, while the optimal output is \\{qr\\}.\n\n\n\nEven knowing that the algorithm fails, let us try to anticipate how a typical greedy exchange argument would have gone-and-gotten-stuck. Here’s the cliche line of reasoning:\nLet:\n\n\\{f_1,f_2,\\ldots,f_k\\} be the output of the greedy algorithm, and\n\\{g_1,g_2,\\ldots,g_\\ell\\} be the optimal solution.\n\nIf it exists, let i be the smallest index for which f_i < g_i. If not, i.e, f_i \\geqslant g_i for all 1 \\leq i \\leq k, then it must be the case that \\ell > k. In either case, we have an element in the optimal solution that was not chosen by the greedy algorithm, even though in terms of weight, it was favorable over the greedy choice (either f_i or early termination). Let us call this element g and denote by S the greedy choices made up to (and excluding) the point where “OPT trumped Greedy”.\nNote that the only reason the element g was not chosen by the greedy algorithm must have been that g was not compatible with the greedy choices we had made up to that point, i.e, S \\cup \\{g\\} \\notin \\cal F. Indeed, recall that this is what happened in the counterexample above as well!\nSo clearly, the greedy approach will not work in general for any input (\\cal U, \\cal F, w). However, what if \\cal F had some additional structure, which allowed us to push the key step in the proof above? In particular, let’s make our wishlist explicit. If\n\nT is the set of greedy choices up to the (i-1)^{th} iteration, and\nS is the set of optimal choices up to the i^{th} iteration,\n\nthen we would like to say that there is some element in S that is:\n\nnot yet chosen by the greedy algorithm, and\ncan be legitimately appended to the greedy choices made so far.\n\nIn other words, we want that \\exists e \\in S \\setminus T such that T \\cup \\{e\\} \\in \\cal F: why? Because such an element e will be guaranteed to be better in terms of weight than greedy choice at the i^{th} iteration (which is either the element f_i or no element at all due to termination). But this time, e is also compatible with the greedy choices… so the greedy algorithm really had no good reason to ignore e, and we have a contradiction!\nNext up, we are going to define the notion of a matroid motivated by the need for a property like the one we described above.\n\n\n\n\n\nFootnotes\n\n\nThis is a remark you can safely ignore if you have not encountered Kruskal’s algorithm yet.↩︎"
  },
  {
    "objectID": "materials/algorithms/dp/index.html",
    "href": "materials/algorithms/dp/index.html",
    "title": "Dynamic Programming",
    "section": "",
    "text": "Acknowledgements\n\n\n\nI borrow the phrasing “what to store/how to compute” from my classroom experience at IMSc, specifically in a class taught by Venkatesh Raman. Some of the checklist is inspired by Erik Demaine’s treatment of the material in his MIT OCW course. The choice of problems is a subset of Jeff Erickson’s chapter on Dynamic Programming, and a lot of the notation is borrowed from there as well.\n\n\nThe dynamic programming approach to a problem involves miniaturizing the problem in a way that the pieces fit together to reveal a useful big picture — i.e, the answer you are after. Here’s the checklist:\n\nWhat are the fragments (AKA, what do we want to store)?\nAre the fragments going to be useful (AKA, where is the final answer)?\nDo we have a kickstart (AKA, what are the base cases)?\nHow do the fragments come together (AKA, how do we compute the values that we have agreed to store)?\nCan we put the pieces together without getting stuck (AKA, are the dependencies in step #4 acyclic)?\n\nLet’s execute this checklist on a few problems:\n\nLongest Increasing Subsequence\nSubset Sum\nSet Cover\nOptimal BSTs\nMIS on Trees"
  },
  {
    "objectID": "materials/algorithms/dp/lis/index.html",
    "href": "materials/algorithms/dp/lis/index.html",
    "title": "1. Longest Increasing Subsequence",
    "section": "",
    "text": "Acknowledgements\n\n\n\nSome of this material is borrowed from Jeff Erickson’s chapters on Recursion, Backtracking, and Dynamic Programming. In particular, the (very nice) analogy with traffic lights is from Erickson. Check them out for a more detailed comparison between recursive and memoized implementations. Thanks to Arya for pointing out a correction.\n\n\n\nThe Problem\nFor any sequence Q, a subsequence of Q is another sequence obtained from Q by deleting zero or more elements, without changing the order of the remaining elements; the elements of the subsequence need not be contiguous in Q.\nFor example, when you drive down a major street in any city, you drive through a sequence of intersections with traffic lights, but you only have to stop at a subsequence of those intersections, where the traffic lights are red. If you’re very lucky, you never stop at all: the empty sequence is a subsequence of Q. On the other hand, if you’re very unlucky, you may have to stop at every intersection: Q is a subsequence of itself.\nHere are some examples:\n\nBOAT is a subsequence of BOX-OF-CHOCOLATES.\nOOF is a subsequence of BOX-OF-CHOCOLATES, but OO-F is not.\nO-O-OOLA is a subsequence of BOX-OF-CHOCOLATES, but FOX is not.\nFOOL and BHOLA are a subsequences of BOX-OF-CHOCOLATES, but LAX and BETA are not.\n\nNow suppose we are given a sequence of integers, and we need to find the length of a longest subsequence whose elements are in increasing order:\n\nthe input is an integer array A[1 .. n], and\nwe need to compute the length of a longest possible sequence of indices 1 \\leqslant i_1<i_2<\\cdots<i_{\\ell} \\leqslant n such that A\\left[i_k\\right]<A\\left[i_{k+1}\\right] for all k.\n\nWe will use LIS to refer to the phrase longest increasing subsequence. Note that there may be multiple increasing subsequences, and even multiple choices for increasing subsequences that are the longest. The approaches below that work correctly to find the length of a LIS are easily adaptable to finding a LIS as well.\n\n\nThe Solution — Take 0 (a dead end)\n\n\n\n\n\n\nWhat are the fragments (AKA, what do we want to store)?\n\n\n\nFor any 1 \\leqslant i \\leqslant n, let A[i\\ldots] denote the subarray of A starting at A[i], and let T[i] denote the length of a LIS of A[i\\ldots]. The T’s will be our fragments.\n\n\n\n\n\n\n\n\nAre the fragments going to be useful (AKA, where is the final answer)?\n\n\n\nT[1] is evidently the answer we are looking for!\n\n\n\n\n\n\n\n\nDo we have a kickstart (AKA, what are the base cases)?\n\n\n\nT[n] = 1, since there is only one increasing subsequence of A[n\\ldots]: no competition.\n\n\n\n\n\n\n\n\nHow do the fragments come together (AKA, how do we compute the values that we have agreed to store)?\n\n\n\nConsider the issue of computing the value of T[i]. Let S_i be the set of all the longest increasing subsequences of A[i\\ldots]. Let the common length of all the subsequences in S_i be k. We want to determine the value of k. In the spirit of magic1, let us assume that we know the values of T[j] for j > i.\nIn particular, say we know the value of T[i+1] to be \\ell. Observe that \\ell \\leqslant k \\leqslant \\ell+1:\n\nthe first inequality follows from the fact that every LIS of A[i+1\\ldots] is also an increasing subsequence of A[i\\ldots], and\nthe second inequality follows from the fact that if there was a LIS of A[i\\ldots] of length \\ell + 2 or more, then the tail of this subsequence (i.e, the subsequence without the first element) would be an increasing subsequence of length at least \\ell + 1 of A[i+1\\ldots], which contradicts T[i+1] = \\ell.\n\nSo all we need to figure out — for computing T[i] — is whether the value of T[i+1] should be incremented or not. How do figure this out?\nWell, let S_{i+1} be the set of all the longest increasing subsequences of A[i+1\\ldots]. Call a subsequence in S_{i+1} useful if the first value is bigger than A[i], and useless otherwise. Why is this notion of interest? Well, if all subsequences in S_{i+1} are useless, then we claim that k = \\ell! Indeed, if k = \\ell+1, then either:\n\nthere is an increasing subsequence of length \\ell + 1 that begins at an index j > i (this is not possible because T[i+1] = \\ell),\nthere is an increasing subsequence of length \\ell + 1 that begins with A[i] (this is not possible because then the tail of this sequence — all elements but A[i] — will belong to S_{i+1} and also be useful, contradicting our assumption that all subsequences in S_{i+1} are useless).\n\nOn the other hand, if even one subsequence in S_{i+1} is useful, then we know that we can “tag” A[i] to it as a prefix and we will have an increasing subsequence in A[i\\ldots] which is in fact the best we can hope for in terms of length: so this is when T[i] = \\ell + 1.\nHaving said all this, unfortunately, by just staring hard at the value of T[i+1], we have no way of knowing if S_{i+1} is full of useless subsequences or not. So it is not at all clear how we can determine if the increment should happen or not!\n\n\n\n\n\n\n\n\nCan we put the pieces together without getting stuck (AKA, are the dependencies in step #4 acyclic)?\n\n\n\nNot relevant, since step #2 is unspecified.\n\n\n\n\nThe Solution — Take 1 (building on the bad take)\n\n\n\n\n\n\nWhat are the fragments (AKA, what do we want to store)?\n\n\n\nWe were stuck before because we had no way of knowing if the set of longest increasing subsequences of A[i\\ldots] had a useful one, and useful subsequences were ones that started off with an element larger than A[i]. Let’s see if we can upgrade our fragments to incorporate this information explicitly: so given a starting index for a subarray (say j) and a target array location (say i < j), let us record the length of a longest increasing subsequence of A[j\\ldots] whose first element is larger than A[i].\nIn notation: for any 1 \\leqslant i < j \\leqslant n, let S_{(i,j)} denote the set of increasing subsequences of A[j\\ldots] that start with an element larger than A[i]. Now, let T[i,j] denote the length of a longest sequence in S_{(i,j)}. The T’s will be our fragments.\n\n\n\n\n\n\n\n\nAre the fragments going to be useful (AKA, where is the final answer)?\n\n\n\n\\max_{i \\in [n]} T[i,i+1] + 1 is the answer we are looking for: since we don’t know where the first element of an optimal solution is located in an array, so we hazard a guess properly by taking a \\max over all possiblities.\nYou could alternatively artificially expand the array to n+1 elements, with the last n elements being the same as A, and the first element being an element that’s smaller than \\min_{i \\in [n]} A[i]: then the final answer is simply T[1,1].\n\n\n\n\n\n\n\n\nDo we have a kickstart (AKA, what are the base cases)?\n\n\n\nFor all 1 \\leqslant i < n, we have:\n\nT[i,n] = 1 if A[n] > A[i].\nT[i,n] = 0 if A[n] \\leqslant A[i].\n\nThese equalities follow directly from the definition of T[i,j].\n\n\n\n\n\n\n\n\nHow do the fragments come together (AKA, how do we compute the values that we have agreed to store)?\n\n\n\nConsider the issue of computing the value of T[i,j] for 1 \\leqslant i \\leqslant n and i+1 \\leqslant j \\leqslant n-1.\nFirst, suppose A[i] \\geqslant A[j]. Then, if we have a subsequence in the set S_{(i,j)}, then it certainly does not begin with A[j]: since this would be a violation of the criteria for membership in S_{i,j}. Therefore, in this situation, every subsequence that belongs to S_{(i,j)} is also a subsequence in S_{(i,j+1)}. Therefore, we have: T[i,j] = T[i,j+1].\nOn the other hand, suppose A[i] < A[j]. Then the subsequences in S_{(i,j)} are of two kinds: those that begin with A[j] and those that do not. Let us denote these sets by X_{(i,j)} and Y_{(i,j)} respectively. Note that:\n\nAny longest increasing subsequence in X_{(i,j)} is the element A[j] followed by one of the longest increasing subsequences in S_{j,j+1}, and therefore the length of any longest subsequence in X_{(i,j)} is captured by T[j,j+1] + 1.\nAny longest increasing subsequence in X_{(i,j)} is a longest increasing subsequence in S_{(i,j+1)} (this is, in fact, similar to the previous case), and therefore the length of any longest subsequence in X_{(i,j)} is captured by T[i,j+1].\n\nNow, observing that if we have a set S that is partitioned into X and Y, then \\max(A) = \\max(\\max(X),\\max(Y)), we can summarize our observations above in the following recurrence.\n\\operatorname{T}(i, j)= \\begin{cases}\\text { T }(i, j+1) & \\text { if } A[i] \\geqslant A[j] \\\\ \\max \\left\\{\\begin{array}{c}\\text { T }(i, j+1) \\\\ 1+\\text { T }(j, j+1)\\end{array}\\right\\} & \\text { otherwise }\\end{cases}\n\n\n\n\n\n\n\n\nCan we put the pieces together without getting stuck (AKA, are the dependencies in step #4 acyclic)?\n\n\n\nNote that computing T[i,j] involves pinging two entries: T[i,j+1] and T[j,j+1]. So as long as all T[\\star,j+1] entries are computed before we get to T[i,j], then we are covered.\nRecall that the base case directly captures all entries of the form T[\\star,n], and one valid sequence of comptuations would involve working our way backwards along the second dimension: i.e, compute T[\\star,n-1], T[\\star,n-2],\\cdots, and so on.\n\n\n\nSequence of computations for the recurrence above.\n\n\n\n\n\n\nThe Solution — Take 2 (a different approach)\n\n\n\n\n\n\nWhat are the fragments (AKA, what do we want to store)?\n\n\n\nFor the sake of analysis, fix an optimal solution 1 \\leqslant i_1 < i_2 < \\cdots < i_k \\leqslant n. We don’t know i_1: but what if we try to guess i_1? That is, go over all possible choices for the starting point: 1,2,\\ldots,n? Fix such a choice.\nAt this point, we are asking ourselves the question: what is the length of a longest increasing subsequence in A that begins at index i? If we could answer this question correctly for every index i, then we are done, because we can simply output the best of all answers obtained.\nSo let S_i denote the set of all increasing subsequences of A that start at A[i] and let T[i] denote the length of a LIS in S_i. The T’s will be our fragments.\n\n\n\n\n\n\n\n\nAre the fragments going to be useful (AKA, where is the final answer)?\n\n\n\nAs hinted at above, \\max_{i \\in [n]} T[i] is the answer we are looking for.\n\n\n\n\n\n\n\n\nDo we have a kickstart (AKA, what are the base cases)?\n\n\n\nClearly, T[n] = 1.\n\n\n\n\n\n\n\n\nHow do the fragments come together (AKA, how do we compute the values that we have agreed to store)?\n\n\n\nConsider the issue of computing the value of T[i] for 1 \\leqslant i \\leqslant n.\nWe know that any optimal sequence of interest starts at A[i]. For the sake of analysis, fix an optimal solution 1 \\leqslant i_1 = i < i_2 < \\cdots < i_k \\leqslant n.\nNow, we don’t know i_2: but what if we try to guess i_2? That is, go over all possible choices for the starting point: all j > i such that A[j] > A[i]? For each such j, T[j] is the answer that we are looking for: since we don’t know which j is the right one a-priori, we simply consolidate all of them with a \\max as follows:\nT[i] = 1 + \\max_{\\{j | j > i, A[j] > A[i]\\}} T[j], \\text{ for any } i < n.\nNote that if the \\max is taken over an empty set (this would happen if A[j] < A[i] for all j > i), then the output of \\max(\\cdot) is 0.\n\n\n\n\n\n\n\n\nCan we put the pieces together without getting stuck (AKA, are the dependencies in step #4 acyclic)?\n\n\n\nNote that computing T[i] involves pinging a bunch of entries, but all of them are of the form T[j] for some j > i. Thus if we compute the entries T[i] in the order:\nT[n], T[n-1], \\cdots, T[1],\nthen we will be just fine.\n\n\n\n\nTime and Space Complexity\nFor the first approach:\n\nWe filled out O(n^2) entries at O(1) cost each, so the overall running time of the algorithm is O(n^2).\nWe store O(n^2) entries, although with a careful implementation the storage can be limited to O(n).\n\nFor the second approach:\n\nWe filled out O(n) entries at O(n) cost each, so the overall running time of the algorithm is O(n^2) again.\nWe store O(n) values.\n\n\n\nCorrectness\nThe correctness of the computations of the T-values specified by both approaches above is implicit in the design of the recurrence. However, we provide an explicit proof for the second approach here. The proof of correctness for most of the other recurrences that we will discuss can be established with a similar approach in spirit and is left as an exercise.\n\n\n\n\n\n\nCorrectness of the DP\n\n\n\nTheorem. Let T[i] be given by:\nT[i] = 1 + \\max_{\\{j | j > i, A[j] > A[i]\\}} T[j], \\text{ for any } i \\in [n],\nand let O[i] denote the length of a LIS in S_i. Then T[i] = O[i].\nProof.\nPart 1. The DP stores a value that is achievable.\nFirst, let us show that O[i] \\geqslant T[i], that is, there is an subsequence of length T[i] that begins at A[i]. We prove this by backward induction over i.\nThe base case. T[n] = 1, and this is witnessed by the subsequence \\{A[n]\\}.\nThe induction step. If \\{j | j > i, A[j] > A[i]\\} = \\emptyset, then T[i] = 1 and this is witnessed by the subsequence \\{A[i]\\}.\nOtherwise, Let j^\\star be the index that witnesses the \\max value (if there are multiple indices that fit this bill, choose any). Note that j^\\star > j. By the induction hypothesis, there is an subsequence of length T[j^\\star] that begins at A[j^\\star]. Prepend to this subsequence the value A[i], this is clearly an increasing subsequence of length 1 + T[j^\\star], and we are done.\nPart 2. The value computed by the DP cannot be beaten.\nFirst, let us show that O[i] \\leqslant T[i], that is, the length of any longest subsequence in S_i is at most T[i]. We prove this by backward induction over i.\nThe base case. O[n] = 1, and T[n] = 1, so there is nothing to prove.\nThe induction step. Here we proceed by contradiction. Suppose there is a subsequence (say \\sigma^\\star) in S_i whose length is k \\geqslant T[i] + 1.\nConsider the tail of \\sigma^\\star, that is, the entire subsequence with the first value — i.e, A[i] — omitted. Denote this subsequence by \\sigma.\nNote that \\sigma has k-1 elements. Suppose the first element of \\sigma is A[\\ell]. Then \\sigma \\in S_\\ell. Note also that \\ell > i and A[\\ell] > A[i], so T[\\ell] \\geqslant k-1 (by the induction hypothesis). Thus:\nT[i] =  1 + \\max_{\\{j | j > i, A[j] > A[i]\\}} T[j] \\geqslant 1 + T[\\ell] \\geqslant 1 + (k-1) = k \\geqslant T[i] + 1,\na contradiction.\n\n\n\n\n\n\n\nFootnotes\n\n\nIndeed, since we already have a kickstart at the fragment T[n], if we can figure out a way of recovering the value of T[i] assuming knowledge of T[j] for j > i, then we are done: we can use this method to go backwards starting from T[n] all the way back to T[1].↩︎"
  },
  {
    "objectID": "materials/algorithms/dp/set-cover/index.html",
    "href": "materials/algorithms/dp/set-cover/index.html",
    "title": "3. Set Cover",
    "section": "",
    "text": "Acknowledgements\n\n\n\nMuch of the material in this section is borrowed from Chapter 6 in Parameterized Algorithms.\n\n\n\nThe Problem\nLet \\mathcal{F} be a family of sets over a universe U. For a subfamily \\mathcal{F}^{\\prime} \\subseteq \\mathcal{F} and a subset U^{\\prime} \\subseteq U, we say that \\mathcal{F}^{\\prime} covers U^{\\prime} if every element of U^{\\prime} belongs to some set of \\mathcal{F}^{\\prime}.\nThe Set Cover problem is the following:\n\nThe input is a family of sets \\mathcal{F} over a universe U and a positive integer k.\nThe task is to check whether there exists a subfamily \\mathcal{F}^{\\prime} \\subseteq \\mathcal{F} of size at most k such that \\mathcal{F}^{\\prime} covers U.\n\nWe describe here a algorithm for Set Cover that runs in time 2^{|U|}(|U|+|\\mathcal{F}|)^{\\mathcal{O}(1)}. In fact, this algorithm does not use the value of k, and finds the minimum possible cardinality of a family \\mathcal{F}^{\\prime} \\subseteq \\mathcal{F} that covers U.\n\n\nThe Solution\n\n\n\n\n\n\nWhat are the fragments (AKA, what do we want to store)?\n\n\n\nLet us try projection again. Fix a subset X \\subseteq U and and an integer 0 \\leqslant j \\leqslant |\\mathcal{F}|.\nDefine T[X, j] as the minimum possible size of a subset \\mathcal{F}^{\\prime} \\subseteq\\left\\{F_1, F_2, \\ldots, F_j\\right\\} that covers X.\nThe T’s will be our fragments.\n\n\n\n\n\n\n\n\nAre the fragments going to be useful (AKA, where is the final answer)?\n\n\n\nBy definition, T[U,m], where m := |\\mathcal{F}|.\n\n\n\n\n\n\n\n\nDo we have a kickstart (AKA, what are the base cases)?\n\n\n\nObserve that T[\\emptyset, 0]=0 while T[X, 0]=+\\infty for X \\neq \\emptyset.\n\n\n\n\n\n\n\n\nHow do the fragments come together (AKA, how do we compute the values that we have agreed to store)?\n\n\n\nLet X \\subseteq U and 0<j \\leq|\\mathcal{F}|. We have that:\n\nT[X, j]=\\min \\left(T[X, j-1], 1+T\\left[X \\backslash F_j, j-1\\right]\\right),\n\ndepending on whether we decide to include F_j in our solution or not. If we do, then we adjust the set of elements that need to be covered, and if we don’t, we push the full responsibility of covering X to the smaller subfamily. As usual, we pick the best of both worlds.\n\n\n\n\n\n\n\n\nCan we put the pieces together without getting stuck (AKA, are the dependencies in step #4 acyclic)?\n\n\n\nThe entries can be computed by computing sets of smaller sizes before larger ones, and for sets of the same size, processing smaller indices before larger ones.\n\n\n\n\nAnalysis of Running Time\nBy using the recurrence, we compute all values T[X, j] for X \\subseteq U and 0 \\leqslant j \\leqslant |\\mathcal{F}|. The running time is therefore 2^{|U|}(|U|+|\\mathcal{F}|)^{\\mathcal{O}(1)}.\n\n\nProof of Correctness\n\n\n\n\n\n\nCorrectness of the DP\n\n\n\nTheorem. Given a SET COVER instance (U, \\mathcal{F}, k), the minimum possible size of a subfamily \\mathcal{F}^{\\prime} \\subseteq \\mathcal{F} that covers U can be found in time 2^{|U|}(|U|+|\\mathcal{F}|)^{\\mathcal{O}(1)}.\nProof. Let \\mathcal{F}=\\left\\{F_1, F_2, \\ldots, F_{|\\mathcal{F}|}\\right\\}. We prove the correctness of the recurrence by showing inequalities in both directions.\nIn one direction, let \\mathcal{F}^{\\prime} \\subseteq\\left\\{\\overline{F_1}, F_2, \\ldots, F_j\\right\\} be a family of minimum size that covers X. We distinguish two cases. If F_j \\notin \\mathcal{F}^{\\prime}, then note that \\mathcal{F}^{\\prime} is also a valid candidate for the entry T[X, j-1] (i.e., \\mathcal{F}^{\\prime} \\subseteq\\left\\{F_1, F_2, \\ldots, F_{j-1}\\right\\} and \\mathcal{F}^{\\prime} covers X ). If F_j \\in \\mathcal{F}^{\\prime}, then \\mathcal{F}^{\\prime} \\backslash\\left\\{F_j\\right\\} is a valid candidate for the entry T\\left[X \\backslash F_j, j-1\\right].\nIn the other direction, observe that any valid candidate \\mathcal{F}^{\\prime} for the entry T[X, j-1] is also a valid candidate for T[X, j] and, moreover, for every valid candidate \\mathcal{F}^{\\prime} for T\\left[X \\backslash F_j, j-1\\right], the family \\mathcal{F}^{\\prime} \\cup\\left\\{F_j\\right\\} is a valid candidate for T[X, j].\nThis completes the proof."
  },
  {
    "objectID": "materials/algorithms/dp/opt-bsts/index.html",
    "href": "materials/algorithms/dp/opt-bsts/index.html",
    "title": "4. Optimal BSTs",
    "section": "",
    "text": "Acknowledgements\n\n\n\nSome of this material is borrowed from Jeff Erickson’s chapters on Recursion, Backtracking, and Dynamic Programming. Check them out for a more detailed comparison between recursive and memoized implementations.\n\n\n\nThe Problem\n\nThe input is a sorted array A[1, \\ldots, n] of search keys and an array f[1, \\ldots, n] of frequency counts, where f[i] is the number of times we will search for A[i].\nOur task is to construct a binary search tree for that set such that the total cost of all the searches is as small as possible, where the cost of a search for a key is the the number of anscestors1 that the key has multiplied by its frequency.\n\nThis can be thought of as a non-linear version of the file storage problem. Food for thought: will a greedy strategy (insert in descending order of frequencies of access) work?\nHeads up: Note that the optimal solution may not be balanced at all.\n\n\nThe Solution\nThis section is coming soon.\n\n\n\n\n\n\nWhat are the fragments (AKA, what do we want to store)?\n\n\n\n\n\n\n\n\n\n\n\n\nAre the fragments going to be useful (AKA, where is the final answer)?\n\n\n\n\n\n\n\n\n\n\n\n\nDo we have a kickstart (AKA, what are the base cases)?\n\n\n\n\n\n\n\n\n\n\n\n\nHow do the fragments come together (AKA, how do we compute the values that we have agreed to store)?\n\n\n\n\n\n\n\n\n\n\n\n\nCan we put the pieces together without getting stuck (AKA, are the dependencies in step #4 acyclic)?\n\n\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\nThe root is the only anscestor of itself, so the cost of access is just one.↩︎"
  },
  {
    "objectID": "materials/algorithms/dp/mis-trees/index.html",
    "href": "materials/algorithms/dp/mis-trees/index.html",
    "title": "5. Maximum Independent Set on Trees",
    "section": "",
    "text": "Acknowledgements\n\n\n\nSome of this material is borrowed from Jeff Erickson’s chapters on Recursion, Backtracking, and Dynamic Programming. The fun factor at a party formulation can be found in an exercise of Erickson as well as these slides by Dàniel Marx. Thanks to Arya for pointing out a correction.\n\n\n\nThe Problem\nYou are planning a corporate party. Every employee e has an amount f(e) \\geqslant 0 of fun that they will bring to the party if invited. The total fun in the party is the sum of f(e) over all invited employees e. You want your party to be very fun. In fact, as fun as possible. However, it turns out that if you invite a manager and their direct report together, the party will be absolutely no fun, not for anyone. What’s the best you can do?\nConcretely, the problem is the following.\n\nWe are given a graph G = (V,E) that is a rooted tree on n vertices with a weight function w: V \\longrightarrow \\mathbb{N} and root r.\nWe want to output the weight of a max-weight independent set in G.\n\n\n\nThe Solution\n\n\n\n\n\n\nWhat are the fragments (AKA, what do we want to store)?\n\n\n\nFor v \\in V, let T[v] denote the weight of a max-weight independent set in G_v, which is the subtree of G rooted at v.\n\n\n\n\n\n\n\n\nAre the fragments going to be useful (AKA, where is the final answer)?\n\n\n\nIndeed, T[r] is what we want!\n\n\n\n\n\n\n\n\nDo we have a kickstart (AKA, what are the base cases)?\n\n\n\nIf v is a leaf node, then T[v] = w(v).\n\n\n\n\n\n\n\n\nHow do the fragments come together (AKA, how do we compute the values that we have agreed to store)?\n\n\n\nFor the sake of analysis, fix a max-weight independent set S of G_v. We have to wonder: does S contain v?\n\nIf the answer is no, then S can be viewed as a union of optimal solutions in all the subtrees rooted at the chindren of v.\nIf the answer is yes, then S can be viewed as a union of optimal solutions in all the subtrees rooted at the grandchindren of v (since the children are now forbidden), and the vertex v itself.\n\nAs always, we take the best of both worlds when we pen down our recurrence:\n\\operatorname{T}(v)=\\max \\left\\{\\sum_{w \\downarrow v} \\operatorname{T}(w), 1+\\sum_{w \\downarrow v} \\sum_{x \\downarrow w} \\operatorname{T}(x)\\right\\},\nwhere the notation w \\downarrow v means “w is a child of v”.\n\n\n\n\n\n\n\n\nCan we put the pieces together without getting stuck (AKA, are the dependencies in step #4 acyclic)?\n\n\n\nProceed from the leaves of the tree upwards."
  },
  {
    "objectID": "materials/algorithms/dp/ss/index.html",
    "href": "materials/algorithms/dp/ss/index.html",
    "title": "2. Subset Sum",
    "section": "",
    "text": "Acknowledgements\n\n\n\nSome of this material is borrowed from Jeff Erickson’s chapters on Recursion, Backtracking, and Dynamic Programming. Check them out for a more detailed comparison between recursive and memoized implementations.\n\n\n\nThe Problem\n\nThe Subset Sum takes as input an array X of n positive integers and a target Y > 0.\nThe output is YES if there is a subset of the array X[1 .. n] that sums to Y, and NO otheriwse.\n\n\n\nThe Solution\n\n\n\n\n\n\nWhat are the fragments (AKA, what do we want to store)?\n\n\n\nLet us try to project this problem on a prefix of the input array and a generic target.\nFor 1 \\leq i \\leq n and 1 \\leq j \\leq Y, let:\n$T[i,j] = $ TRUE if some subset of X[1,\\ldots,i] sums to j, and FALSE otherwise.\nThe T-values are our fragments.\n\n\n\n\n\n\n\n\nAre the fragments going to be useful (AKA, where is the final answer)?\n\n\n\nIndeed, when the projection covers the original input, we are done! So the answer we are looking for is the value of T[n,Y].\n\n\n\n\n\n\n\n\nDo we have a kickstart (AKA, what are the base cases)?\n\n\n\nNote that:\nT[1,j] is TRUE if and only if X[1] = j.\n\n\n\n\n\n\n\n\nHow do the fragments come together (AKA, how do we compute the values that we have agreed to store)?\n\n\n\nIf A[i] > j: then T[i,j] is TRUE if and only if (T[i-1,j]) is TRUE. Indeed, A[i] cannot participate in any solution here, since the array X only has positive integers, so we piggy back on whether a sum of j can be obtained from the subarray up to X[1,\\ldots,i-1].\nIf A[i] = j: the return TRUE already, we have a solution comprising just of A[i] and it is our lucky day!\nOtherwise: T[i,j] is TRUE if and only if (T[i-1,j-A[i]] \\lor T[i-1,j]) is TRUE. Here, we take the best of both worlds by speculating on whether A[i] contributes to the solution or not. If it does, we update the target to j - A[i] — and notice that this is a legitimate index to ping since j > A[i]. If it does not, then as in the first situation, we fall back entirely on A[1,\\ldots,i] to carry the burden of producing a solution. If netiher of these scenarios pan out, then observe that there is no solution at all.\n\n\n\n\n\n\n\n\nCan we put the pieces together without getting stuck (AKA, are the dependencies in step #4 acyclic)?\n\n\n\nIt is straightforward to check that these dependencies are indeed acyclic."
  },
  {
    "objectID": "materials/algorithms/flows/index.html",
    "href": "materials/algorithms/flows/index.html",
    "title": "Flows",
    "section": "",
    "text": "Acknowledgements\n\n\n\nThe choice of notation, material, and problems is a subset of Jeff Erickson’s chapters on Max Flows and Applications of Max Flows.\n\n\nThis week, we will learn about:\n\nThe problem of finding a maximum flow in a network,\nthe relationship between a maximum flow and a minimum cut,\na pseudo-polynomial-time algorithm for finding a maximum flow [Ford-Fulkerson],\na method to decompose a flow into a combination of path and cycle flows.\n\nWe will also apply the maxflow algorithm to solve the following problems:\n\nTuple Selection\nExam Scheduling\nIPL Elimination\n\nDetailed notes are coming soon (will be up by 5PM on 26 Jun)."
  },
  {
    "objectID": "blog/poems/dad/index.html",
    "href": "blog/poems/dad/index.html",
    "title": "Dad",
    "section": "",
    "text": "The vendor at the counter hands me a stapler, wondering why I need yet another.  Indeed, I didn’t, until I realized  that she giggles  when I get frantic about lost pencils, papers, and staplers  and she smiles indignantly whenever I look, exasperated,  at her tiny hands clutched around  the stuff she found.  I am just bringing home another situation inviting her indignation,  that eventually turns into a bear hug of pure love."
  }
]